CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 0][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://localhost:50070
Connecting to localhost/127.0.0.1:50070
Connection established 127.0.0.1:49411<->127.0.0.1:50070
Executing request PUT /webhdfs/v1/user/michaeljones/apache-empty.txt?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-0 >> PUT /webhdfs/v1/user/michaeljones/apache-empty.txt?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1
http-outgoing-0 >> Content-Length: 0
http-outgoing-0 >> Host: localhost:50070
http-outgoing-0 >> Connection: Keep-Alive
http-outgoing-0 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-0 >> Accept-Encoding: gzip,deflate
http-outgoing-0 >> "PUT /webhdfs/v1/user/michaeljones/apache-empty.txt?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1[\r][\n]"
http-outgoing-0 >> "Content-Length: 0[\r][\n]"
http-outgoing-0 >> "Host: localhost:50070[\r][\n]"
http-outgoing-0 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-0 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-0 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-0 >> "[\r][\n]"
http-outgoing-0 << "HTTP/1.1 307 TEMPORARY_REDIRECT[\r][\n]"
http-outgoing-0 << "Cache-Control: no-cache[\r][\n]"
http-outgoing-0 << "Expires: Fri, 12 Jun 2015 23:27:50 GMT[\r][\n]"
http-outgoing-0 << "Date: Fri, 12 Jun 2015 23:27:50 GMT[\r][\n]"
http-outgoing-0 << "Pragma: no-cache[\r][\n]"
http-outgoing-0 << "Expires: Fri, 12 Jun 2015 23:27:50 GMT[\r][\n]"
http-outgoing-0 << "Date: Fri, 12 Jun 2015 23:27:50 GMT[\r][\n]"
http-outgoing-0 << "Pragma: no-cache[\r][\n]"
http-outgoing-0 << "Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434187670406&s=wGU6kukG2QDsVim2ItSwFfwLVqU="; Path=/; Expires=Sat, 13-Jun-2015 09:27:50 GMT; HttpOnly[\r][\n]"
http-outgoing-0 << "Location: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true[\r][\n]"
http-outgoing-0 << "Content-Type: application/octet-stream[\r][\n]"
http-outgoing-0 << "Content-Length: 0[\r][\n]"
http-outgoing-0 << "Server: Jetty(6.1.26)[\r][\n]"
http-outgoing-0 << "[\r][\n]"
http-outgoing-0 << HTTP/1.1 307 TEMPORARY_REDIRECT
http-outgoing-0 << Cache-Control: no-cache
http-outgoing-0 << Expires: Fri, 12 Jun 2015 23:27:50 GMT
http-outgoing-0 << Date: Fri, 12 Jun 2015 23:27:50 GMT
http-outgoing-0 << Pragma: no-cache
http-outgoing-0 << Expires: Fri, 12 Jun 2015 23:27:50 GMT
http-outgoing-0 << Date: Fri, 12 Jun 2015 23:27:50 GMT
http-outgoing-0 << Pragma: no-cache
http-outgoing-0 << Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434187670406&s=wGU6kukG2QDsVim2ItSwFfwLVqU="; Path=/; Expires=Sat, 13-Jun-2015 09:27:50 GMT; HttpOnly
http-outgoing-0 << Location: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
http-outgoing-0 << Content-Type: application/octet-stream
http-outgoing-0 << Content-Length: 0
http-outgoing-0 << Server: Jetty(6.1.26)
Connection can be kept alive indefinitely
Cookie accepted [hadoop.auth=""u=michaeljones&p=michaeljones&t=simple&e=1434187670406&s=wGU6kukG2QDsVim2ItSwFfwLVqU="", version:0, domain:localhost, path:/, expiry:Sat Jun 13 19:27:50 AEST 2015]
Redirect to: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
http-outgoing-0: Shutdown connection
Connection discarded
http-outgoing-0: Close connection
Connection released: [id: 0][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
PUT file redirect: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 1][route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://michaels-air.bigpond:50075
Connecting to michaels-air.bigpond/10.0.0.2:50075
Connection established 10.0.0.2:49412<->10.0.0.2:50075
Executing request PUT /webhdfs/v1/user/michaeljones/apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-1 >> PUT /webhdfs/v1/user/michaeljones/apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1
http-outgoing-1 >> Content-Length: 0
http-outgoing-1 >> Host: michaels-air.bigpond:50075
http-outgoing-1 >> Connection: Keep-Alive
http-outgoing-1 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-1 >> Accept-Encoding: gzip,deflate
http-outgoing-1 >> "PUT /webhdfs/v1/user/michaeljones/apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1[\r][\n]"
http-outgoing-1 >> "Content-Length: 0[\r][\n]"
http-outgoing-1 >> "Host: michaels-air.bigpond:50075[\r][\n]"
http-outgoing-1 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-1 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-1 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-1 >> "[\r][\n]"
http-outgoing-1 << "HTTP/1.1 100 Continue[\r][\n]"
http-outgoing-1 << "[\r][\n]"
http-outgoing-1 << HTTP/1.1 100 Continue
http-outgoing-1 << "HTTP/1.1 201 Created[\r][\n]"
http-outgoing-1 << "Location: hdfs://localhost:9000/user/michaeljones/apache-empty.txt[\r][\n]"
http-outgoing-1 << "Content-Length: 0[\r][\n]"
http-outgoing-1 << "Connection: close[\r][\n]"
http-outgoing-1 << "[\r][\n]"
http-outgoing-1 << HTTP/1.1 201 Created
http-outgoing-1 << Location: hdfs://localhost:9000/user/michaeljones/apache-empty.txt
http-outgoing-1 << Content-Length: 0
http-outgoing-1 << Connection: close
http-outgoing-1: Shutdown connection
Connection discarded
http-outgoing-1: Close connection
Connection released: [id: 1][route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 2][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://localhost:50070
Connecting to localhost/127.0.0.1:50070
Connection established 127.0.0.1:49414<->127.0.0.1:50070
Executing request PUT /webhdfs/v1/user/michaeljones/pom.xml?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-2 >> PUT /webhdfs/v1/user/michaeljones/pom.xml?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1
http-outgoing-2 >> Content-Length: 0
http-outgoing-2 >> Host: localhost:50070
http-outgoing-2 >> Connection: Keep-Alive
http-outgoing-2 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-2 >> Accept-Encoding: gzip,deflate
http-outgoing-2 >> "PUT /webhdfs/v1/user/michaeljones/pom.xml?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1[\r][\n]"
http-outgoing-2 >> "Content-Length: 0[\r][\n]"
http-outgoing-2 >> "Host: localhost:50070[\r][\n]"
http-outgoing-2 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-2 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-2 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-2 >> "[\r][\n]"
http-outgoing-2 << "HTTP/1.1 307 TEMPORARY_REDIRECT[\r][\n]"
http-outgoing-2 << "Cache-Control: no-cache[\r][\n]"
http-outgoing-2 << "Expires: Fri, 12 Jun 2015 23:27:55 GMT[\r][\n]"
http-outgoing-2 << "Date: Fri, 12 Jun 2015 23:27:55 GMT[\r][\n]"
http-outgoing-2 << "Pragma: no-cache[\r][\n]"
http-outgoing-2 << "Expires: Fri, 12 Jun 2015 23:27:55 GMT[\r][\n]"
http-outgoing-2 << "Date: Fri, 12 Jun 2015 23:27:55 GMT[\r][\n]"
http-outgoing-2 << "Pragma: no-cache[\r][\n]"
http-outgoing-2 << "Content-Type: application/octet-stream[\r][\n]"
http-outgoing-2 << "Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434187675189&s=lis9U3ZwNirrp+LEdGClu8qiAdk="; Path=/; Expires=Sat, 13-Jun-2015 09:27:55 GMT; HttpOnly[\r][\n]"
http-outgoing-2 << "Location: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/pom.xml?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true[\r][\n]"
http-outgoing-2 << "Content-Length: 0[\r][\n]"
http-outgoing-2 << "Server: Jetty(6.1.26)[\r][\n]"
http-outgoing-2 << "[\r][\n]"
http-outgoing-2 << HTTP/1.1 307 TEMPORARY_REDIRECT
http-outgoing-2 << Cache-Control: no-cache
http-outgoing-2 << Expires: Fri, 12 Jun 2015 23:27:55 GMT
http-outgoing-2 << Date: Fri, 12 Jun 2015 23:27:55 GMT
http-outgoing-2 << Pragma: no-cache
http-outgoing-2 << Expires: Fri, 12 Jun 2015 23:27:55 GMT
http-outgoing-2 << Date: Fri, 12 Jun 2015 23:27:55 GMT
http-outgoing-2 << Pragma: no-cache
http-outgoing-2 << Content-Type: application/octet-stream
http-outgoing-2 << Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434187675189&s=lis9U3ZwNirrp+LEdGClu8qiAdk="; Path=/; Expires=Sat, 13-Jun-2015 09:27:55 GMT; HttpOnly
http-outgoing-2 << Location: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/pom.xml?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
http-outgoing-2 << Content-Length: 0
http-outgoing-2 << Server: Jetty(6.1.26)
Connection can be kept alive indefinitely
Cookie accepted [hadoop.auth=""u=michaeljones&p=michaeljones&t=simple&e=1434187675189&s=lis9U3ZwNirrp+LEdGClu8qiAdk="", version:0, domain:localhost, path:/, expiry:Sat Jun 13 19:27:55 AEST 2015]
Redirect to: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/pom.xml?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
http-outgoing-2: Shutdown connection
Connection discarded
http-outgoing-2: Close connection
Connection released: [id: 2][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
PUT file redirect: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/pom.xml?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 3][route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://michaels-air.bigpond:50075
Connecting to michaels-air.bigpond/10.0.0.2:50075
Connection established 10.0.0.2:49415<->10.0.0.2:50075
Executing request PUT /webhdfs/v1/user/michaeljones/pom.xml?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-3 >> PUT /webhdfs/v1/user/michaeljones/pom.xml?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1
http-outgoing-3 >> Transfer-Encoding: chunked
http-outgoing-3 >> Content-Type: application/octet-stream
http-outgoing-3 >> Host: michaels-air.bigpond:50075
http-outgoing-3 >> Connection: Keep-Alive
http-outgoing-3 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-3 >> Accept-Encoding: gzip,deflate
http-outgoing-3 >> "PUT /webhdfs/v1/user/michaeljones/pom.xml?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1[\r][\n]"
http-outgoing-3 >> "Transfer-Encoding: chunked[\r][\n]"
http-outgoing-3 >> "Content-Type: application/octet-stream[\r][\n]"
http-outgoing-3 >> "Host: michaels-air.bigpond:50075[\r][\n]"
http-outgoing-3 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-3 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-3 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-3 >> "[\r][\n]"
http-outgoing-3 >> "856[\r][\n]"
http-outgoing-3 >> "<?xml version="1.0" encoding="UTF-8"?>[\n]"
http-outgoing-3 >> "<project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">[\n]"
http-outgoing-3 >> "    <modelVersion>4.0.0</modelVersion>[\n]"
http-outgoing-3 >> "    <groupId>com.michaeljones</groupId>[\n]"
http-outgoing-3 >> "    <artifactId>HelloHadoopWorldMaven</artifactId>[\n]"
http-outgoing-3 >> "    <version>1.0-SNAPSHOT</version>[\n]"
http-outgoing-3 >> "    <packaging>jar</packaging>[\n]"
http-outgoing-3 >> "    <dependencies>[\n]"
http-outgoing-3 >> "        <!-- run bin/hadoop version to see the jar it was built with, which is this dependency -->[\n]"
http-outgoing-3 >> "        <dependency>[\n]"
http-outgoing-3 >> "            <groupId>org.apache.hadoop</groupId>[\n]"
http-outgoing-3 >> "            <artifactId>hadoop-common</artifactId>[\n]"
http-outgoing-3 >> "            <version>2.7.0</version>[\n]"
http-outgoing-3 >> "        </dependency>[\n]"
http-outgoing-3 >> "        <dependency>[\n]"
http-outgoing-3 >> "            <groupId>org.apache.hadoop</groupId>[\n]"
http-outgoing-3 >> "            <artifactId>hadoop-hdfs</artifactId>[\n]"
http-outgoing-3 >> "            <version>2.7.0</version>[\n]"
http-outgoing-3 >> "        </dependency>[\n]"
http-outgoing-3 >> "        <dependency>[\n]"
http-outgoing-3 >> "            <groupId>junit</groupId>[\n]"
http-outgoing-3 >> "            <artifactId>junit</artifactId>[\n]"
http-outgoing-3 >> "            <version>4.10</version>[\n]"
http-outgoing-3 >> "            <scope>test</scope>[\n]"
http-outgoing-3 >> "        </dependency>[\n]"
http-outgoing-3 >> "        <dependency>[\n]"
http-outgoing-3 >> "            <groupId>org.apache.hadoop</groupId>[\n]"
Connection manager is shutting down
http-outgoing-3 >> "            <artifactId>hadoop-mapreduce-client-core</artifactId>[\n]"
http-outgoing-3 >> "            <version>2.7.0</version>[\n]"
Connection manager shut down
http-outgoing-3 >> "        </dependency>[\n]"
http-outgoing-3 >> "        <dependency>[\n]"
http-outgoing-3 >> "            <groupId>org.apache.hadoop</groupId>[\n]"
http-outgoing-3 >> "            <artifactId>hadoop-mapreduce-client-common</artifactId>[\n]"
http-outgoing-3 >> "            <version>2.7.0</version>[\n]"
http-outgoing-3 >> "        </dependency>[\n]"
http-outgoing-3 >> "        <dependency>[\n]"
http-outgoing-3 >> "            <groupId>com.googlecode.json-simple</groupId>[\n]"
http-outgoing-3 >> "            <artifactId>json-simple</artifactId>[\n]"
http-outgoing-3 >> "            <version>1.1.1</version>[\n]"
http-outgoing-3 >> "        </dependency>[\n]"
http-outgoing-3 >> "        <dependency>[\n]"
http-outgoing-3 >> "            <groupId>org.apache.httpcomponents</groupId>[\n]"
http-outgoing-3 >> "            <artifactId>httpclient</artifactId>[\n]"
http-outgoing-3 >> "            <version>4.4-beta1</version>[\n]"
http-outgoing-3 >> "        </dependency>[\n]"
http-outgoing-3 >> "    </dependencies>[\n]"
http-outgoing-3 >> "    <properties>[\n]"
http-outgoing-3 >> "        <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>[\n]"
http-outgoing-3 >> "        <maven.compiler.source>1.7</maven.compiler.source>[\n]"
http-outgoing-3 >> "        <maven.compiler.target>1.7</maven.compiler.target>[\n]"
http-outgoing-3 >> "    </properties>[\n]"
http-outgoing-3 >> "</project>[\r][\n]"
http-outgoing-3 >> "0[\r][\n]"
http-outgoing-3 >> "[\r][\n]"
http-outgoing-3 << "HTTP/1.1 100 Continue[\r][\n]"
http-outgoing-3 << "[\r][\n]"
http-outgoing-3 << HTTP/1.1 100 Continue
http-outgoing-3 << "HTTP/1.1 201 Created[\r][\n]"
http-outgoing-3 << "Location: hdfs://localhost:9000/user/michaeljones/pom.xml[\r][\n]"
http-outgoing-3 << "Content-Length: 0[\r][\n]"
http-outgoing-3 << "Connection: close[\r][\n]"
http-outgoing-3 << "[\r][\n]"
http-outgoing-3 << HTTP/1.1 201 Created
http-outgoing-3 << Location: hdfs://localhost:9000/user/michaeljones/pom.xml
http-outgoing-3 << Content-Length: 0
http-outgoing-3 << Connection: close
http-outgoing-3: Shutdown connection
Connection discarded
http-outgoing-3: Close connection
Connection released: [id: 3][route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection manager is shutting down
Connection manager shut down
Connection manager is shutting down
Connection manager shut down
Failed to detect a valid hadoop home directory
java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:303)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:328)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:80)
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2807)
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2802)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2668)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:371)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:170)
	at com.michaeljones.hellohadoopworldmaven.HelloHdfs.<init>(HelloHdfs.java:48)
	at com.michaeljones.hellohadoopworldmaven.HelloHdfsTest.testIsOnline(HelloHdfsTest.java:49)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:20)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:28)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:30)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:263)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:68)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:47)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:28)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:30)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.apache.maven.surefire.junit4.JUnit4TestSet.execute(JUnit4TestSet.java:53)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:123)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:104)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:164)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:110)
	at org.apache.maven.surefire.booter.SurefireStarter.invokeProvider(SurefireStarter.java:175)
	at org.apache.maven.surefire.booter.SurefireStarter.runSuitesInProcessWhenForked(SurefireStarter.java:107)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:68)
setsid is not available on this machine. So not using it.
setsid exited with exit code 0
field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Rate of successful kerberos logins and latency (milliseconds)], valueName=Time)
field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Rate of failed kerberos logins and latency (milliseconds)], valueName=Time)
field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[GetGroups], valueName=Time)
UgiMetrics, User and group related metrics
Kerberos krb5 configuration not found, setting default realm to empty
 Creating new Groups object
Trying to load the custom-built native-hadoop library...
Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
java.library.path=/Applications/NetBeans/NetBeans 8.0.2.app/Contents/Resources/NetBeans/webcommon/bin::/Users/michaeljones/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:.
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Falling back to shell based
Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
hadoop login
hadoop login commit
using local user:UnixPrincipal: michaeljones
Using user: "UnixPrincipal: michaeljones" with name michaeljones
User entry: "michaeljones"
UGI loginUser:michaeljones (auth:SIMPLE)
dfs.client.use.legacy.blockreader.local = false
dfs.client.read.shortcircuit = false
dfs.client.domain.socket.data.traffic = false
dfs.domain.socket.path = 
multipleLinearRandomRetry = null
rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWrapper, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@1e1a0406
getting client out of cache: org.apache.hadoop.ipc.Client@47d9a273
Both short-circuit local reads and UNIX domain socket are disabled.
DataTransferProtocol not using SaslPropertiesResolver, no QOP found in configuration for dfs.data.transfer.protection
The ping interval is 60000 ms.
Connecting to localhost/127.0.0.1:9000
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones: starting, having connections 1
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones sending #0
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones got value #0
Call: getFileInfo took 166ms
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones sending #1
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones got value #1
Call: delete took 17ms
/user/michaeljones/hello.txt: masked=rw-r--r--
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones sending #2
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones got value #2
Call: create took 5ms
computePacketChunkSize: src=/user/michaeljones/hello.txt, chunkSize=516, chunksPerPacket=126, packetSize=65016
Lease renewer daemon for [DFSClient_NONMAPREDUCE_-1011479798_1] with renew id 1 started
DFSClient writeChunk allocating new packet seqno=0, src=/user/michaeljones/hello.txt, packetSize=65016, chunksPerPacket=126, bytesCurBlock=0
Queued packet 0
Allocating new block
Queued packet 1
Waiting for ack for: 1
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones sending #3
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones got value #3
Call: addBlock took 4ms
pipeline = DatanodeInfoWithStorage[127.0.0.1:50010,DS-b42c5705-9ba4-4b14-b00b-f9194bb036f0,DISK]
Connecting to datanode 127.0.0.1:50010
Send buf size 131072
SASL client skipping handshake in unsecured configuration for addr = /127.0.0.1, datanodeId = DatanodeInfoWithStorage[127.0.0.1:50010,DS-b42c5705-9ba4-4b14-b00b-f9194bb036f0,DISK]
DataStreamer block BP-1045030256-10.0.0.2-1433119149314:blk_1073742215_1392 sending packet packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 20
DFSClient seqno: 0 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
DataStreamer block BP-1045030256-10.0.0.2-1433119149314:blk_1073742215_1392 sending packet packet seqno: 1 offsetInBlock: 20 lastPacketInBlock: true lastByteOffsetInBlock: 20
DFSClient seqno: 1 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
Closing old block BP-1045030256-10.0.0.2-1433119149314:blk_1073742215_1392
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones sending #4
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones got value #4
Call: complete took 5ms
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones sending #5
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones got value #5
Call: getBlockLocations took 28ms
newInfo = LocatedBlocks{
  fileLength=20
  underConstruction=false
  blocks=[LocatedBlock{BP-1045030256-10.0.0.2-1433119149314:blk_1073742215_1392; getBlockSize()=20; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-b42c5705-9ba4-4b14-b00b-f9194bb036f0,DISK]]}]
  lastLocatedBlock=LocatedBlock{BP-1045030256-10.0.0.2-1433119149314:blk_1073742215_1392; getBlockSize()=20; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-b42c5705-9ba4-4b14-b00b-f9194bb036f0,DISK]]}
  isLastBlockComplete=true}
Connecting to datanode 127.0.0.1:50010
SASL client skipping handshake in unsecured configuration for addr = /127.0.0.1, datanodeId = DatanodeInfoWithStorage[127.0.0.1:50010,DS-b42c5705-9ba4-4b14-b00b-f9194bb036f0,DISK]
testMain
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones sending #6
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones got value #6
Call: getFileInfo took 4ms
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones sending #7
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones got value #7
Call: delete took 6ms
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.connect(Job.java:1256)
Trying ClientProtocolProvider : org.apache.hadoop.mapred.LocalClientProtocolProvider
session.id is deprecated. Instead, use dfs.metrics.session-id
Initializing JVM Metrics with processName=JobTracker, sessionId=
Picked org.apache.hadoop.mapred.LocalClientProtocolProvider as the ClientProtocolProvider
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Cluster.getFileSystem(Cluster.java:162)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.submit(Job.java:1287)
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones sending #8
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones got value #8
Call: getFileInfo took 2ms
Configuring job job_local1778575427_0001 with file:/tmp/hadoop-michaeljones/mapred/staging/michaeljones1778575427/.staging/job_local1778575427_0001 as the submit dir
adding the following namenodes' delegation tokens:[hdfs://localhost:9000]
Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
default FileSystem: file:///
No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
Creating splits at file:/tmp/hadoop-michaeljones/mapred/staging/michaeljones1778575427/.staging/job_local1778575427_0001
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones sending #9
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones got value #9
Call: getFileInfo took 4ms
Time taken to get FileStatuses: 11
Total input paths to process : 1
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones sending #10
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones got value #10
Call: getBlockLocations took 7ms
Total # of splits generated by getSplits: 1, TimeTaken: 72
number of splits:1
Handling deprecation for all properties in config...
Handling deprecation for mapreduce.jobtracker.address
Handling deprecation for yarn.resourcemanager.scheduler.monitor.policies
Handling deprecation for dfs.namenode.resource.check.interval
Handling deprecation for mapreduce.jobhistory.client.thread-count
Handling deprecation for yarn.app.mapreduce.am.containerlauncher.threadpool-initial-size
Handling deprecation for mapred.child.java.opts
Handling deprecation for mapreduce.jobtracker.retiredjobs.cache.size
Handling deprecation for dfs.client.https.need-auth
Handling deprecation for yarn.admin.acl
Handling deprecation for yarn.app.mapreduce.am.job.committer.cancel-timeout
Handling deprecation for mapreduce.job.emit-timeline-data
Handling deprecation for fs.ftp.host.port
Handling deprecation for dfs.namenode.avoid.read.stale.datanode
Handling deprecation for dfs.journalnode.rpc-address
Handling deprecation for mapreduce.job.end-notification.retry.attempts
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.ttl-interval-ms
Handling deprecation for yarn.resourcemanager.leveldb-state-store.path
Handling deprecation for mapred.mapper.new-api
Handling deprecation for yarn.ipc.rpc.class
Handling deprecation for ipc.client.connection.maxidletime
Handling deprecation for yarn.nodemanager.process-kill-wait.ms
Handling deprecation for mapreduce.cluster.acls.enabled
Handling deprecation for mapreduce.jobtracker.handler.count
Handling deprecation for io.map.index.interval
Handling deprecation for dfs.namenode.https-address
Handling deprecation for mapreduce.task.profile.reduces
Handling deprecation for fs.s3n.multipart.uploads.enabled
Handling deprecation for io.seqfile.sorter.recordlimit
Handling deprecation for mapreduce.job.ubertask.maxmaps
Handling deprecation for mapreduce.tasktracker.tasks.sleeptimebeforesigkill
Handling deprecation for hadoop.util.hash.type
Handling deprecation for dfs.namenode.replication.min
Handling deprecation for yarn.nodemanager.container-manager.thread-count
Handling deprecation for mapreduce.jobtracker.jobhistory.block.size
Handling deprecation for dfs.namenode.fs-limits.min-block-size
Handling deprecation for mapreduce.app-submission.cross-platform
Handling deprecation for fs.AbstractFileSystem.file.impl
Handling deprecation for net.topology.script.number.args
Handling deprecation for yarn.resourcemanager.container-tokens.master-key-rolling-interval-secs
Handling deprecation for mapreduce.map.output.compress.codec
Handling deprecation for mapreduce.job.reducer.preempt.delay.sec
Handling deprecation for s3native.bytes-per-checksum
Handling deprecation for dfs.namenode.path.based.cache.block.map.allocation.percent
Handling deprecation for yarn.nodemanager.windows-container.memory-limit.enabled
Handling deprecation for mapreduce.input.fileinputformat.split.minsize
Handling deprecation for hadoop.security.group.mapping
Handling deprecation for mapreduce.jobtracker.system.dir
Handling deprecation for mapreduce.job.end-notification.max.attempts
Handling deprecation for mapreduce.reduce.markreset.buffer.percent
Handling deprecation for dfs.datanode.cache.revocation.polling.ms
Handling deprecation for mapreduce.reduce.speculative
Handling deprecation for yarn.nodemanager.localizer.cache.cleanup.interval-ms
Handling deprecation for dfs.namenode.lazypersist.file.scrub.interval.sec
Handling deprecation for fs.s3a.threads.core
Handling deprecation for mapreduce.jobhistory.recovery.store.fs.uri
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.start-time-read-cache-size
Handling deprecation for hadoop.registry.zk.retry.interval.ms
Handling deprecation for yarn.nodemanager.keytab
Handling deprecation for dfs.namenode.replication.interval
Handling deprecation for yarn.resourcemanager.admin.address
Handling deprecation for mapreduce.job.maps
Handling deprecation for nfs.dump.dir
Handling deprecation for mapreduce.job.user.name
Handling deprecation for mapreduce.jobtracker.maxtasks.perjob
Handling deprecation for mapreduce.job.ubertask.enable
Handling deprecation for mapreduce.job.reduce.class
Handling deprecation for yarn.nodemanager.delete.debug-delay-sec
Handling deprecation for yarn.timeline-service.ttl-enable
Handling deprecation for yarn.resourcemanager.fs.state-store.retry-policy-spec
Handling deprecation for mapreduce.reduce.skip.maxgroups
Handling deprecation for dfs.client.use.datanode.hostname
Handling deprecation for fs.trash.interval
Handling deprecation for mapreduce.job.name
Handling deprecation for mapreduce.am.max-attempts
Handling deprecation for mapreduce.jobtracker.heartbeats.in.second
Handling deprecation for yarn.resourcemanager.zk-num-retries
Handling deprecation for s3.blocksize
Handling deprecation for dfs.datanode.data.dir
Handling deprecation for mapreduce.jobtracker.persist.jobstatus.active
Handling deprecation for mapreduce.reduce.shuffle.parallelcopies
Handling deprecation for fs.s3.buffer.dir
Handling deprecation for mapreduce.jobhistory.done-dir
Handling deprecation for hadoop.security.instrumentation.requires.admin
Handling deprecation for hadoop.registry.zk.retry.ceiling.ms
Handling deprecation for nfs.rtmax
Handling deprecation for dfs.datanode.data.dir.perm
Handling deprecation for yarn.resourcemanager.container.liveness-monitor.interval-ms
Handling deprecation for yarn.nodemanager.env-whitelist
Handling deprecation for dfs.namenode.backup.address
Handling deprecation for dfs.namenode.xattrs.enabled
Handling deprecation for dfs.datanode.readahead.bytes
Handling deprecation for mapreduce.jobhistory.cleaner.enable
Handling deprecation for dfs.client.block.write.retries
Handling deprecation for mapreduce.tasktracker.http.address
Handling deprecation for yarn.nodemanager.linux-container-executor.cgroups.hierarchy
Handling deprecation for ha.failover-controller.graceful-fence.connection.retries
Handling deprecation for yarn.resourcemanager.recovery.enabled
Handling deprecation for yarn.app.mapreduce.am.container.log.backups
Handling deprecation for dfs.namenode.safemode.threshold-pct
Handling deprecation for yarn.nodemanager.disk-health-checker.interval-ms
Handling deprecation for hadoop.security.java.secure.random.algorithm
Handling deprecation for dfs.namenode.list.cache.directives.num.responses
Handling deprecation for dfs.datanode.dns.nameserver
Handling deprecation for mapreduce.cluster.temp.dir
Handling deprecation for fs.s3a.max.total.tasks
Handling deprecation for mapreduce.reduce.maxattempts
Handling deprecation for mapreduce.client.submit.file.replication
Handling deprecation for mapreduce.shuffle.port
Handling deprecation for yarn.resourcemanager.resource-tracker.client.thread-count
Handling deprecation for dfs.namenode.replication.considerLoad
Handling deprecation for dfs.namenode.edits.journal-plugin.qjournal
Handling deprecation for dfs.client.write.exclude.nodes.cache.expiry.interval.millis
Handling deprecation for yarn.nodemanager.delete.thread-count
Handling deprecation for dfs.client.mmap.cache.timeout.ms
Handling deprecation for yarn.nodemanager.admin-env
Handling deprecation for io.skip.checksum.errors
Handling deprecation for yarn.timeline-service.hostname
Handling deprecation for yarn.resourcemanager.proxy-user-privileges.enabled
Handling deprecation for mapreduce.job.speculative.speculative-cap-total-tasks
Handling deprecation for yarn.acl.enable
Handling deprecation for fs.s3a.fast.upload
Handling deprecation for file.blocksize
Handling deprecation for mapreduce.job.speculative.slowtaskthreshold
Handling deprecation for ftp.replication
Handling deprecation for yarn.sharedcache.cleaner.initial-delay-mins
Handling deprecation for s3native.client-write-packet-size
Handling deprecation for hadoop.rpc.socket.factory.class.default
Handling deprecation for file.bytes-per-checksum
Handling deprecation for dfs.datanode.slow.io.warning.threshold.ms
Handling deprecation for io.seqfile.lazydecompress
Handling deprecation for mapreduce.task.skip.start.attempts
Handling deprecation for dfs.namenode.reject-unresolved-dn-topology-mapping
Handling deprecation for hadoop.common.configuration.version
Handling deprecation for yarn.resourcemanager.client.thread-count
Handling deprecation for dfs.datanode.drop.cache.behind.reads
Handling deprecation for yarn.sharedcache.admin.address
Handling deprecation for mapreduce.job.output.value.class
Handling deprecation for mapreduce.output.fileoutputformat.outputdir
Handling deprecation for mapreduce.jobtracker.taskcache.levels
Handling deprecation for yarn.nodemanager.linux-container-executor.nonsecure-mode.user-pattern
Handling deprecation for yarn.resourcemanager.zk-timeout-ms
Handling deprecation for yarn.resourcemanager.max-completed-applications
Handling deprecation for mapreduce.job.jvm.numtasks
Handling deprecation for yarn.sharedcache.cleaner.period-mins
Handling deprecation for mapreduce.jobtracker.tasktracker.maxblacklists
Handling deprecation for dfs.namenode.top.num.users
Handling deprecation for yarn.nodemanager.linux-container-executor.cgroups.mount
Handling deprecation for yarn.sharedcache.checksum.algo.impl
Handling deprecation for mapreduce.job.end-notification.max.retry.interval
Handling deprecation for mapreduce.job.acl-view-job
Handling deprecation for mapreduce.job.classloader
Handling deprecation for yarn.log-aggregation-enable
Handling deprecation for mapreduce.reduce.shuffle.fetch.retry.interval-ms
Handling deprecation for yarn.resourcemanager.nodemanager.minimum.version
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.size
Handling deprecation for yarn.app.mapreduce.am.job.task.listener.thread-count
Handling deprecation for yarn.app.mapreduce.am.resource.cpu-vcores
Handling deprecation for dfs.namenode.edit.log.autoroll.check.interval.ms
Handling deprecation for mapreduce.output.fileoutputformat.compress.type
Handling deprecation for hadoop.hdfs.configuration.version
Handling deprecation for hadoop.security.group.mapping.ldap.search.attr.member
Handling deprecation for yarn.nodemanager.log.retain-seconds
Handling deprecation for yarn.nodemanager.local-cache.max-files-per-directory
Handling deprecation for mapreduce.job.end-notification.retry.interval
Handling deprecation for hadoop.ssl.client.conf
Handling deprecation for yarn.sharedcache.root-dir
Handling deprecation for dfs.journalnode.https-address
Handling deprecation for mapreduce.reduce.shuffle.fetch.retry.timeout-ms
Handling deprecation for dfs.bytes-per-checksum
Handling deprecation for dfs.namenode.max.objects
Handling deprecation for mapreduce.tasktracker.instrumentation
Handling deprecation for dfs.datanode.max.transfer.threads
Handling deprecation for dfs.block.access.key.update.interval
Handling deprecation for mapreduce.jobtracker.jobhistory.task.numberprogresssplits
Handling deprecation for mapreduce.map.memory.mb
Handling deprecation for ha.failover-controller.new-active.rpc-timeout.ms
Handling deprecation for hadoop.ssl.hostname.verifier
Handling deprecation for dfs.client.read.shortcircuit
Handling deprecation for dfs.datanode.hdfs-blocks-metadata.enabled
Handling deprecation for mapreduce.tasktracker.healthchecker.interval
Handling deprecation for dfs.image.transfer.chunksize
Handling deprecation for mapreduce.tasktracker.taskmemorymanager.monitoringinterval
Handling deprecation for dfs.client.https.keystore.resource
Handling deprecation for yarn.resourcemanager.connect.retry-interval.ms
Handling deprecation for yarn.timeline-service.webapp.address
Handling deprecation for s3native.blocksize
Handling deprecation for yarn.scheduler.minimum-allocation-mb
Handling deprecation for yarn.sharedcache.cleaner.resource-sleep-ms
Handling deprecation for net.topology.impl
Handling deprecation for dfs.client.failover.sleep.base.millis
Handling deprecation for dfs.permissions.superusergroup
Handling deprecation for io.seqfile.compress.blocksize
Handling deprecation for hadoop.registry.zk.retry.times
Handling deprecation for fs.AbstractFileSystem.ftp.impl
Handling deprecation for dfs.namenode.checkpoint.edits.dir
Handling deprecation for mapreduce.job.running.reduce.limit
Handling deprecation for dfs.blockreport.initialDelay
Handling deprecation for dfs.namenode.heartbeat.recheck-interval
Handling deprecation for dfs.namenode.safemode.extension
Handling deprecation for yarn.scheduler.maximum-allocation-mb
Handling deprecation for mapreduce.job.reduce.shuffle.consumer.plugin.class
Handling deprecation for yarn.nodemanager.vmem-check-enabled
Handling deprecation for mapreduce.task.io.sort.factor
Handling deprecation for mapreduce.jobtracker.persist.jobstatus.dir
Handling deprecation for dfs.client.failover.sleep.max.millis
Handling deprecation for dfs.namenode.delegation.key.update-interval
Handling deprecation for hadoop.rpc.protection
Handling deprecation for fs.permissions.umask-mode
Handling deprecation for fs.s3.sleepTimeSeconds
Handling deprecation for ha.health-monitor.rpc-timeout.ms
Handling deprecation for hadoop.http.staticuser.user
Handling deprecation for fs.s3a.connection.maximum
Handling deprecation for yarn.nodemanager.linux-container-executor.nonsecure-mode.limit-users
Handling deprecation for fs.s3a.paging.maximum
Handling deprecation for fs.AbstractFileSystem.viewfs.impl
Handling deprecation for fs.ftp.host
Handling deprecation for yarn.nodemanager.linux-container-executor.nonsecure-mode.local-user
Handling deprecation for fs.s3a.impl
Handling deprecation for hadoop.http.authentication.kerberos.keytab
Handling deprecation for dfs.namenode.fs-limits.max-blocks-per-file
Handling deprecation for mapreduce.tasktracker.http.threads
Handling deprecation for mapreduce.tasktracker.dns.nameserver
Handling deprecation for yarn.resourcemanager.am-rm-tokens.master-key-rolling-interval-secs
Handling deprecation for dfs.client.block.write.replace-datanode-on-failure.enable
Handling deprecation for io.compression.codec.bzip2.library
Handling deprecation for mapreduce.map.skip.maxrecords
Handling deprecation for dfs.client.use.legacy.blockreader.local
Handling deprecation for dfs.namenode.checkpoint.dir
Handling deprecation for dfs.namenode.top.windows.minutes
Handling deprecation for mapreduce.job.maxtaskfailures.per.tracker
Handling deprecation for net.topology.node.switch.mapping.impl
Handling deprecation for mapreduce.shuffle.max.connections
Handling deprecation for mapreduce.jobhistory.loadedjobs.cache.size
Handling deprecation for dfs.storage.policy.enabled
Handling deprecation for yarn.client.application-client-protocol.poll-interval-ms
Handling deprecation for yarn.nodemanager.localizer.address
Handling deprecation for dfs.namenode.list.cache.pools.num.responses
Handling deprecation for nfs.server.port
Handling deprecation for mapreduce.client.output.filter
Handling deprecation for yarn.timeline-service.client.best-effort
Handling deprecation for ha.zookeeper.parent-znode
Handling deprecation for mapreduce.jobtracker.persist.jobstatus.hours
Handling deprecation for yarn.sharedcache.admin.thread-count
Handling deprecation for yarn.nodemanager.resource.cpu-vcores
Handling deprecation for dfs.datanode.block-pinning.enabled
Handling deprecation for mapreduce.jobhistory.http.policy
Handling deprecation for yarn.resourcemanager.webapp.delegation-token-auth-filter.enabled
Handling deprecation for mapreduce.job.speculative.retry-after-no-speculate
Handling deprecation for fs.s3a.attempts.maximum
Handling deprecation for s3native.stream-buffer-size
Handling deprecation for io.seqfile.local.dir
Handling deprecation for yarn.log-aggregation.retain-check-interval-seconds
Handling deprecation for fs.s3n.multipart.copy.block.size
Handling deprecation for dfs.encrypt.data.transfer.cipher.key.bitlength
Handling deprecation for dfs.datanode.sync.behind.writes
Handling deprecation for yarn.resourcemanager.zk-acl
Handling deprecation for hadoop.ssl.keystores.factory.class
Handling deprecation for mapreduce.job.split.metainfo.maxsize
Handling deprecation for fs.s3.maxRetries
Handling deprecation for hadoop.security.random.device.file.path
Handling deprecation for yarn.client.nodemanager-connect.max-wait-ms
Handling deprecation for dfs.namenode.stale.datanode.interval
Handling deprecation for mapreduce.task.io.sort.mb
Handling deprecation for yarn.resourcemanager.zk-state-store.parent-path
Handling deprecation for yarn.app.mapreduce.client-am.ipc.max-retries
Handling deprecation for fs.client.resolve.remote.symlinks
Handling deprecation for yarn.nodemanager.linux-container-executor.cgroups.strict-resource-usage
Handling deprecation for hadoop.ssl.enabled.protocols
Handling deprecation for mapreduce.reduce.cpu.vcores
Handling deprecation for yarn.client.failover-retries
Handling deprecation for mapreduce.jobhistory.address
Handling deprecation for hadoop.ssl.enabled
Handling deprecation for dfs.replication.max
Handling deprecation for dfs.namenode.name.dir
Handling deprecation for dfs.datanode.https.address
Handling deprecation for ipc.client.kill.max
Handling deprecation for mapreduce.job.committer.setup.cleanup.needed
Handling deprecation for dfs.client.domain.socket.data.traffic
Handling deprecation for yarn.nodemanager.localizer.cache.target-size-mb
Handling deprecation for yarn.resourcemanager.admin.client.thread-count
Handling deprecation for dfs.block.access.token.enable
Handling deprecation for mapreduce.job.speculative.retry-after-speculate
Handling deprecation for dfs.datanode.address
Handling deprecation for mapreduce.jobtracker.restart.recover
Handling deprecation for ipc.client.connect.max.retries
Handling deprecation for yarn.timeline-service.store-class
Handling deprecation for dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
Handling deprecation for hadoop.tmp.dir
Handling deprecation for dfs.datanode.handler.count
Handling deprecation for yarn.resourcemanager.ha.automatic-failover.embedded
Handling deprecation for yarn.timeline-service.ttl-ms
Handling deprecation for mapreduce.task.profile.map.params
Handling deprecation for yarn.resourcemanager.nodemanagers.heartbeat-interval-ms
Handling deprecation for mapreduce.map.speculative
Handling deprecation for yarn.timeline-service.recovery.enabled
Handling deprecation for mapreduce.job.map.class
Handling deprecation for dfs.namenode.resource.checked.volumes.minimum
Handling deprecation for yarn.nodemanager.recovery.dir
Handling deprecation for mapreduce.job.counters.max
Handling deprecation for yarn.resourcemanager.keytab
Handling deprecation for dfs.namenode.max.extra.edits.segments.retained
Handling deprecation for dfs.webhdfs.user.provider.user.pattern
Handling deprecation for dfs.client.mmap.enabled
Handling deprecation for mapreduce.map.log.level
Handling deprecation for dfs.client.file-block-storage-locations.timeout.millis
Handling deprecation for yarn.client.max-cached-nodemanagers-proxies
Handling deprecation for yarn.app.mapreduce.am.scheduler.heartbeat.interval-ms
Handling deprecation for hadoop.fuse.timer.period
Handling deprecation for fs.trash.checkpoint.interval
Handling deprecation for yarn.sharedcache.app-checker.class
Handling deprecation for dfs.journalnode.http-address
Handling deprecation for yarn.app.mapreduce.am.staging-dir
Handling deprecation for mapreduce.tasktracker.local.dir.minspacestart
Handling deprecation for yarn.nm.liveness-monitor.expiry-interval-ms
Handling deprecation for ha.health-monitor.check-interval.ms
Handling deprecation for mapreduce.reduce.shuffle.merge.percent
Handling deprecation for dfs.namenode.retrycache.heap.percent
Handling deprecation for yarn.nodemanager.docker-container-executor.exec-name
Handling deprecation for ipc.client.connect.timeout
Handling deprecation for yarn.resourcemanager.fs.state-store.retry-interval-ms
Handling deprecation for mapreduce.output.fileoutputformat.compress
Handling deprecation for yarn.nodemanager.local-dirs
Handling deprecation for yarn.nodemanager.recovery.enabled
Handling deprecation for io.native.lib.available
Handling deprecation for yarn.sharedcache.store.in-memory.staleness-period-mins
Handling deprecation for yarn.resourcemanager.am.max-attempts
Handling deprecation for s3.replication
Handling deprecation for mapreduce.input.fileinputformat.inputdir
Handling deprecation for fs.AbstractFileSystem.har.impl
Handling deprecation for dfs.image.compress
Handling deprecation for mapreduce.job.running.map.limit
Handling deprecation for mapreduce.reduce.input.buffer.percent
Handling deprecation for yarn.nodemanager.webapp.address
Handling deprecation for dfs.datanode.available-space-volume-choosing-policy.balanced-space-preference-fraction
Handling deprecation for dfs.namenode.edit.log.autoroll.multiplier.threshold
Handling deprecation for hadoop.security.group.mapping.ldap.ssl
Handling deprecation for dfs.namenode.checkpoint.check.period
Handling deprecation for fs.defaultFS
Handling deprecation for fs.s3a.multipart.size
Handling deprecation for dfs.client.slow.io.warning.threshold.ms
Handling deprecation for yarn.app.mapreduce.am.job.committer.commit-window
Handling deprecation for hadoop.security.group.mapping.ldap.search.attr.group.name
Handling deprecation for yarn.nodemanager.disk-health-checker.max-disk-utilization-per-disk-percentage
Handling deprecation for yarn.nodemanager.container-monitor.procfs-tree.smaps-based-rss.enabled
Handling deprecation for mapreduce.job.submithostname
Handling deprecation for mapreduce.map.sort.spill.percent
Handling deprecation for hadoop.security.crypto.codec.classes.aes.ctr.nopadding
Handling deprecation for dfs.namenode.http-address
Handling deprecation for hadoop.security.groups.negative-cache.secs
Handling deprecation for hadoop.ssl.server.conf
Handling deprecation for mapreduce.ifile.readahead
Handling deprecation for s3native.replication
Handling deprecation for yarn.client.nodemanager-client-async.thread-pool-max-size
Handling deprecation for mapreduce.jobtracker.staging.root.dir
Handling deprecation for mapreduce.jobhistory.admin.address
Handling deprecation for dfs.namenode.startup.delay.block.deletion.sec
Handling deprecation for yarn.nodemanager.health-checker.interval-ms
Handling deprecation for dfs.namenode.checkpoint.max-retries
Handling deprecation for s3.stream-buffer-size
Handling deprecation for ftp.client-write-packet-size
Handling deprecation for dfs.datanode.fsdatasetcache.max.threads.per.volume
Handling deprecation for mapreduce.output.fileoutputformat.compress.codec
Handling deprecation for yarn.timeline-service.keytab
Handling deprecation for yarn.sharedcache.store.in-memory.initial-delay-mins
Handling deprecation for mapreduce.jobhistory.webapp.address
Handling deprecation for mapreduce.task.userlog.limit.kb
Handling deprecation for mapreduce.reduce.shuffle.fetch.retry.enabled
Handling deprecation for yarn.app.mapreduce.task.container.log.backups
Handling deprecation for dfs.heartbeat.interval
Handling deprecation for ha.zookeeper.session-timeout.ms
Handling deprecation for fs.s3a.connection.ssl.enabled
Handling deprecation for yarn.sharedcache.webapp.address
Handling deprecation for hadoop.http.authentication.signature.secret.file
Handling deprecation for hadoop.fuse.connection.timeout
Handling deprecation for mapreduce.input.fileinputformat.numinputfiles
Handling deprecation for yarn.nodemanager.log-aggregation.compression-type
Handling deprecation for ipc.server.max.connections
Handling deprecation for yarn.resourcemanager.work-preserving-recovery.scheduling-wait-ms
Handling deprecation for yarn.nodemanager.log-dirs
Handling deprecation for yarn.app.mapreduce.am.resource.mb
Handling deprecation for hadoop.security.groups.cache.secs
Handling deprecation for mapreduce.job.speculative.minimum-allowed-tasks
Handling deprecation for yarn.nodemanager.container-monitor.interval-ms
Handling deprecation for dfs.datanode.cache.revocation.timeout.ms
Handling deprecation for mapreduce.jobhistory.recovery.store.class
Handling deprecation for mapreduce.task.combine.progress.records
Handling deprecation for s3.client-write-packet-size
Handling deprecation for mapreduce.jobtracker.instrumentation
Handling deprecation for dfs.replication
Handling deprecation for mapreduce.shuffle.transfer.buffer.size
Handling deprecation for hadoop.security.group.mapping.ldap.directory.search.timeout
Handling deprecation for dfs.datanode.available-space-volume-choosing-policy.balanced-space-threshold
Handling deprecation for hadoop.work.around.non.threadsafe.getpwuid
Handling deprecation for yarn.app.mapreduce.client-am.ipc.max-retries-on-timeouts
Handling deprecation for yarn.nodemanager.address
Handling deprecation for mapreduce.tasktracker.taskcontroller
Handling deprecation for mapreduce.tasktracker.indexcache.mb
Handling deprecation for yarn.scheduler.maximum-allocation-vcores
Handling deprecation for mapreduce.job.reduces
Handling deprecation for yarn.nodemanager.sleep-delay-before-sigkill.ms
Handling deprecation for yarn.timeline-service.address
Handling deprecation for yarn.resourcemanager.configuration.provider-class
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.expiry
Handling deprecation for yarn.sharedcache.enabled
Handling deprecation for tfile.io.chunk.size
Handling deprecation for mapreduce.job.acl-modify-job
Handling deprecation for hadoop.registry.zk.session.timeout.ms
Handling deprecation for fs.automatic.close
Handling deprecation for ha.health-monitor.sleep-after-disconnect.ms
Handling deprecation for mapreduce.tasktracker.reduce.tasks.maximum
Handling deprecation for mapreduce.input.fileinputformat.list-status.num-threads
Handling deprecation for dfs.datanode.directoryscan.threads
Handling deprecation for dfs.datanode.directoryscan.interval
Handling deprecation for dfs.namenode.acls.enabled
Handling deprecation for dfs.client.short.circuit.replica.stale.threshold.ms
Handling deprecation for hadoop.http.authentication.token.validity
Handling deprecation for fs.s3.block.size
Handling deprecation for ha.failover-controller.graceful-fence.rpc-timeout.ms
Handling deprecation for mapreduce.tasktracker.local.dir.minspacekill
Handling deprecation for dfs.namenode.resource.du.reserved
Handling deprecation for mapreduce.jobhistory.cleaner.interval-ms
Handling deprecation for dfs.namenode.datanode.registration.ip-hostname-check
Handling deprecation for mapreduce.jobhistory.intermediate-done-dir
Handling deprecation for mapreduce.jobtracker.http.address
Handling deprecation for dfs.namenode.backup.http-address
Handling deprecation for dfs.namenode.edits.noeditlogchannelflush
Handling deprecation for mapreduce.reduce.shuffle.input.buffer.percent
Handling deprecation for mapreduce.map.maxattempts
Handling deprecation for yarn.http.policy
Handling deprecation for dfs.namenode.audit.loggers
Handling deprecation for hadoop.security.groups.cache.warn.after.ms
Handling deprecation for io.serializations
Handling deprecation for mapreduce.tasktracker.outofband.heartbeat
Handling deprecation for mapreduce.reduce.shuffle.read.timeout
Handling deprecation for hadoop.security.crypto.buffer.size
Handling deprecation for mapreduce.reduce.skip.proc.count.autoincr
Handling deprecation for mapreduce.ifile.readahead.bytes
Handling deprecation for dfs.http.policy
Handling deprecation for hadoop.registry.secure
Handling deprecation for dfs.namenode.safemode.min.datanodes
Handling deprecation for dfs.client.file-block-storage-locations.num-threads
Handling deprecation for mapreduce.cluster.local.dir
Handling deprecation for mapreduce.tasktracker.report.address
Handling deprecation for dfs.namenode.secondary.https-address
Handling deprecation for hadoop.kerberos.kinit.command
Handling deprecation for yarn.timeline-service.http-authentication.type
Handling deprecation for dfs.block.access.token.lifetime
Handling deprecation for dfs.webhdfs.enabled
Handling deprecation for dfs.namenode.delegation.token.max-lifetime
Handling deprecation for dfs.namenode.avoid.write.stale.datanode
Handling deprecation for dfs.datanode.drop.cache.behind.writes
Handling deprecation for yarn.log-aggregation.retain-seconds
Handling deprecation for mapreduce.job.complete.cancel.delegation.tokens
Handling deprecation for mapreduce.local.clientfactory.class.name
Handling deprecation for mapreduce.shuffle.connection-keep-alive.timeout
Handling deprecation for dfs.namenode.num.extra.edits.retained
Handling deprecation for yarn.scheduler.minimum-allocation-vcores
Handling deprecation for ipc.client.connect.max.retries.on.timeouts
Handling deprecation for yarn.timeline-service.client.retry-interval-ms
Handling deprecation for yarn.timeline-service.client.max-retries
Handling deprecation for fs.s3n.block.size
Handling deprecation for mapreduce.job.map.output.collector.class
Handling deprecation for ha.health-monitor.connect-retry-interval.ms
Handling deprecation for mapreduce.shuffle.max.threads
Handling deprecation for nfs.exports.allowed.hosts
Handling deprecation for dfs.client.mmap.cache.size
Handling deprecation for mapreduce.tasktracker.map.tasks.maximum
Handling deprecation for io.file.buffer.size
Handling deprecation for dfs.client.datanode-restart.timeout
Handling deprecation for io.mapfile.bloom.size
Handling deprecation for hadoop.security.kms.client.authentication.retry-count
Handling deprecation for dfs.namenode.checkpoint.txns
Handling deprecation for ipc.client.connect.retry.interval
Handling deprecation for dfs.client-write-packet-size
Handling deprecation for mapreduce.reduce.shuffle.connect.timeout
Handling deprecation for yarn.resourcemanager.fs.state-store.uri
Handling deprecation for fs.swift.impl
Handling deprecation for hadoop.registry.zk.connection.timeout.ms
Handling deprecation for mapred.queue.default.acl-administer-jobs
Handling deprecation for mapreduce.job.submithostaddress
Handling deprecation for dfs.cachereport.intervalMsec
Handling deprecation for yarn.app.mapreduce.shuffle.log.backups
Handling deprecation for yarn.app.mapreduce.am.container.log.limit.kb
Handling deprecation for yarn.nodemanager.resourcemanager.minimum.version
Handling deprecation for ftp.blocksize
Handling deprecation for yarn.resourcemanager.address
Handling deprecation for file.stream-buffer-size
Handling deprecation for yarn.resourcemanager.scheduler.monitor.enable
Handling deprecation for mapreduce.job.ubertask.maxreduces
Handling deprecation for nfs.allow.insecure.ports
Handling deprecation for yarn.sharedcache.nm.uploader.thread-count
Handling deprecation for ipc.client.idlethreshold
Handling deprecation for ftp.stream-buffer-size
Handling deprecation for yarn.sharedcache.client-server.address
Handling deprecation for dfs.client.failover.connection.retries.on.timeouts
Handling deprecation for dfs.namenode.replication.work.multiplier.per.iteration
Handling deprecation for hadoop.http.authentication.simple.anonymous.allowed
Handling deprecation for hadoop.security.authorization
Handling deprecation for yarn.client.nodemanager-connect.retry-interval-ms
Handling deprecation for yarn.am.liveness-monitor.expiry-interval-ms
Handling deprecation for fs.har.impl.disable.cache
Handling deprecation for yarn.nodemanager.linux-container-executor.resources-handler.class
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.read-cache-size
Handling deprecation for hadoop.security.authentication
Handling deprecation for dfs.image.compression.codec
Handling deprecation for mapreduce.task.files.preserve.failedtasks
Handling deprecation for dfs.client.read.shortcircuit.streams.cache.size
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.path
Handling deprecation for mapreduce.job.reduce.slowstart.completedmaps
Handling deprecation for mapreduce.jobhistory.minicluster.fixed.ports
Handling deprecation for file.replication
Handling deprecation for yarn.resourcemanager.ha.automatic-failover.enabled
Handling deprecation for mapreduce.job.userlog.retain.hours
Handling deprecation for mapreduce.jobhistory.joblist.cache.size
Handling deprecation for dfs.namenode.accesstime.precision
Handling deprecation for yarn.resourcemanager.work-preserving-recovery.enabled
Handling deprecation for dfs.namenode.fs-limits.max-xattrs-per-inode
Handling deprecation for io.mapfile.bloom.error.rate
Handling deprecation for yarn.resourcemanager.store.class
Handling deprecation for dfs.image.transfer.timeout
Handling deprecation for yarn.timeline-service.leveldb-state-store.path
Handling deprecation for nfs.wtmax
Handling deprecation for mapreduce.job.combine.class
Handling deprecation for dfs.namenode.support.allow.format
Handling deprecation for fs.s3a.multipart.purge
Handling deprecation for dfs.secondary.namenode.kerberos.internal.spnego.principal
Handling deprecation for fs.s3a.connection.establish.timeout
Handling deprecation for dfs.stream-buffer-size
Handling deprecation for dfs.namenode.invalidate.work.pct.per.iteration
Handling deprecation for yarn.nodemanager.container-executor.class
Handling deprecation for fs.s3a.multipart.purge.age
Handling deprecation for yarn.resourcemanager.scheduler.client.thread-count
Handling deprecation for dfs.namenode.top.enabled
Handling deprecation for yarn.app.mapreduce.shuffle.log.separate
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.low-watermark
Handling deprecation for fs.s3a.fast.buffer.size
Handling deprecation for hadoop.user.group.static.mapping.overrides
Handling deprecation for tfile.fs.input.buffer.size
Handling deprecation for dfs.client.cached.conn.retry
Handling deprecation for hadoop.http.authentication.type
Handling deprecation for dfs.namenode.list.encryption.zones.num.responses
Handling deprecation for mapreduce.map.cpu.vcores
Handling deprecation for dfs.namenode.path.based.cache.refresh.interval.ms
Handling deprecation for dfs.namenode.decommission.interval
Handling deprecation for dfs.namenode.fs-limits.max-directory-items
Handling deprecation for yarn.resourcemanager.zk-retry-interval-ms
Handling deprecation for ftp.bytes-per-checksum
Handling deprecation for dfs.ha.log-roll.period
Handling deprecation for dfs.user.home.dir.prefix
Handling deprecation for ipc.client.fallback-to-simple-auth-allowed
Handling deprecation for yarn.nodemanager.pmem-check-enabled
Handling deprecation for yarn.nodemanager.remote-app-log-dir
Handling deprecation for dfs.namenode.inotify.max.events.per.rpc
Handling deprecation for mapreduce.task.profile.maps
Handling deprecation for mapreduce.shuffle.ssl.file.buffer.size
Handling deprecation for mapreduce.tasktracker.healthchecker.script.timeout
Handling deprecation for yarn.timeline-service.webapp.https.address
Handling deprecation for yarn.nodemanager.resource.percentage-physical-cpu-limit
Handling deprecation for yarn.app.mapreduce.am.command-opts
Handling deprecation for dfs.namenode.fs-limits.max-xattr-size
Handling deprecation for dfs.datanode.http.address
Handling deprecation for dfs.namenode.blocks.per.postponedblocks.rescan
Handling deprecation for yarn.sharedcache.nm.uploader.replication.factor
Handling deprecation for hadoop.registry.zk.root
Handling deprecation for hadoop.jetty.logs.serve.aliases
Handling deprecation for yarn.client.failover-proxy-provider
Handling deprecation for mapreduce.jobhistory.admin.acl
Handling deprecation for yarn.app.mapreduce.am.hard-kill-timeout-ms
Handling deprecation for yarn.nodemanager.remote-app-log-dir-suffix
Handling deprecation for mapreduce.jobhistory.principal
Handling deprecation for yarn.resourcemanager.webapp.address
Handling deprecation for mapreduce.jobhistory.recovery.enable
Handling deprecation for yarn.sharedcache.store.in-memory.check-period-mins
Handling deprecation for nfs.mountd.port
Handling deprecation for mapreduce.reduce.merge.inmem.threshold
Handling deprecation for fs.df.interval
Handling deprecation for yarn.timeline-service.enabled
Handling deprecation for mapreduce.jobtracker.jobhistory.lru.cache.size
Handling deprecation for mapreduce.task.profile
Handling deprecation for mapreduce.job.output.key.class
Handling deprecation for yarn.nodemanager.hostname
Handling deprecation for dfs.namenode.num.checkpoints.retained
Handling deprecation for mapreduce.job.queuename
Handling deprecation for mapreduce.jobhistory.max-age-ms
Handling deprecation for mapreduce.job.token.tracking.ids.enabled
Handling deprecation for yarn.nodemanager.localizer.client.thread-count
Handling deprecation for yarn.sharedcache.uploader.server.thread-count
Handling deprecation for dfs.client.mmap.retry.timeout.ms
Handling deprecation for mapreduce.jobhistory.move.thread-count
Handling deprecation for dfs.permissions.enabled
Handling deprecation for dfs.blockreport.split.threshold
Handling deprecation for fs.AbstractFileSystem.hdfs.impl
Handling deprecation for dfs.datanode.balance.bandwidthPerSec
Handling deprecation for dfs.block.scanner.volume.bytes.per.second
Handling deprecation for hadoop.http.filter.initializers
Handling deprecation for yarn.timeline-service.http-authentication.simple.anonymous.allowed
Handling deprecation for dfs.default.chunk.view.size
Handling deprecation for yarn.sharedcache.client-server.thread-count
Handling deprecation for yarn.resourcemanager.resource-tracker.address
Handling deprecation for mapreduce.job.working.dir
Handling deprecation for mapreduce.jobhistory.datestring.cache.size
Handling deprecation for mapreduce.task.profile.params
Handling deprecation for dfs.namenode.decommission.blocks.per.interval
Handling deprecation for dfs.namenode.handler.count
Handling deprecation for dfs.image.transfer.bandwidthPerSec
Handling deprecation for rpc.metrics.quantile.enable
Handling deprecation for mapreduce.jobtracker.expire.trackers.interval
Handling deprecation for mapreduce.task.timeout
Handling deprecation for yarn.app.mapreduce.client.max-retries
Handling deprecation for yarn.nodemanager.resource.memory-mb
Handling deprecation for yarn.nodemanager.disk-health-checker.min-healthy-disks
Handling deprecation for dfs.datanode.failed.volumes.tolerated
Handling deprecation for yarn.timeline-service.handler-thread-count
Handling deprecation for ipc.server.listen.queue.size
Handling deprecation for fs.s3a.threads.max
Handling deprecation for yarn.resourcemanager.connect.max-wait.ms
Handling deprecation for mapreduce.fileoutputcommitter.algorithm.version
Handling deprecation for mapreduce.framework.name
Handling deprecation for mapreduce.map.skip.proc.count.autoincr
Handling deprecation for mapreduce.job.max.split.locations
Handling deprecation for yarn.resourcemanager.scheduler.class
Handling deprecation for yarn.resourcemanager.system-metrics-publisher.enabled
Handling deprecation for dfs.blocksize
Handling deprecation for yarn.sharedcache.nested-level
Handling deprecation for mapreduce.shuffle.connection-keep-alive.enable
Handling deprecation for fs.s3a.threads.keepalivetime
Handling deprecation for fs.s3a.connection.timeout
Handling deprecation for file.client-write-packet-size
Handling deprecation for ha.failover-controller.cli-check.rpc-timeout.ms
Handling deprecation for ha.zookeeper.acl
Handling deprecation for dfs.namenode.write.stale.datanode.ratio
Handling deprecation for dfs.encrypt.data.transfer
Handling deprecation for dfs.datanode.shared.file.descriptor.paths
Handling deprecation for mapreduce.input.lineinputformat.linespermap
Handling deprecation for yarn.resourcemanager.delayed.delegation-token.removal-interval-ms
Handling deprecation for yarn.nodemanager.localizer.fetch.thread-count
Handling deprecation for dfs.client.failover.max.attempts
Handling deprecation for yarn.resourcemanager.scheduler.address
Handling deprecation for dfs.client.read.shortcircuit.streams.cache.expiry.ms
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.start-time-write-cache-size
Handling deprecation for yarn.nodemanager.health-checker.script.timeout-ms
Handling deprecation for yarn.resourcemanager.fs.state-store.num-retries
Handling deprecation for hadoop.ssl.require.client.cert
Handling deprecation for hadoop.security.uid.cache.secs
Handling deprecation for mapreduce.jobhistory.keytab
Handling deprecation for dfs.client.read.shortcircuit.skip.checksum
Handling deprecation for yarn.resourcemanager.ha.automatic-failover.zk-base-path
Handling deprecation for mapreduce.shuffle.ssl.enabled
Handling deprecation for mapreduce.reduce.log.level
Handling deprecation for hadoop.registry.rm.enabled
Handling deprecation for mapreduce.tasktracker.dns.interface
Handling deprecation for yarn.resourcemanager.system-metrics-publisher.dispatcher.pool-size
Handling deprecation for mapreduce.job.speculative.speculative-cap-running-tasks
Handling deprecation for dfs.datanode.block.id.layout.upgrade.threads
Handling deprecation for dfs.datanode.use.datanode.hostname
Handling deprecation for dfs.client.context
Handling deprecation for yarn.resourcemanager.ha.enabled
Handling deprecation for mapred.reducer.new-api
Handling deprecation for dfs.namenode.delegation.token.renew-interval
Handling deprecation for dfs.blockreport.intervalMsec
Handling deprecation for fs.s3a.multipart.threshold
Handling deprecation for mapreduce.reduce.shuffle.memory.limit.percent
Handling deprecation for dfs.https.server.keystore.resource
Handling deprecation for io.map.index.skip
Handling deprecation for mapreduce.job.hdfs-servers
Handling deprecation for mapreduce.jobtracker.taskscheduler
Handling deprecation for dfs.namenode.kerberos.internal.spnego.principal
Handling deprecation for yarn.resourcemanager.state-store.max-completed-applications
Handling deprecation for mapreduce.map.output.compress
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.num.refill.threads
Handling deprecation for fs.s3n.multipart.uploads.block.size
Handling deprecation for mapreduce.task.merge.progress.records
Handling deprecation for dfs.datanode.dns.interface
Handling deprecation for map.sort.class
Handling deprecation for yarn.nodemanager.aux-services.mapreduce_shuffle.class
Handling deprecation for tfile.fs.output.buffer.size
Handling deprecation for fs.du.interval
Handling deprecation for dfs.client.failover.connection.retries
Handling deprecation for dfs.namenode.top.window.num.buckets
Handling deprecation for mapreduce.job.dir
Handling deprecation for fs.s3a.buffer.dir
Handling deprecation for mapreduce.reduce.shuffle.retry-delay.max.ms
Handling deprecation for yarn.sharedcache.uploader.server.address
Handling deprecation for mapreduce.client.progressmonitor.pollinterval
Handling deprecation for yarn.app.mapreduce.shuffle.log.limit.kb
Handling deprecation for dfs.datanode.max.locked.memory
Handling deprecation for dfs.namenode.retrycache.expirytime.millis
Handling deprecation for dfs.datanode.scan.period.hours
Handling deprecation for dfs.client.block.write.replace-datanode-on-failure.best-effort
Handling deprecation for mapreduce.jobhistory.move.interval-ms
Handling deprecation for dfs.ha.fencing.ssh.connect-timeout
Handling deprecation for yarn.nodemanager.log-aggregation.roll-monitoring-interval-seconds
Handling deprecation for dfs.namenode.fs-limits.max-component-length
Handling deprecation for hadoop.registry.zk.quorum
Handling deprecation for dfs.namenode.enable.retrycache
Handling deprecation for dfs.datanode.du.reserved
Handling deprecation for yarn.timeline-service.state-store-class
Handling deprecation for dfs.datanode.ipc.address
Handling deprecation for hadoop.registry.system.acls
Handling deprecation for dfs.client.block.write.replace-datanode-on-failure.policy
Handling deprecation for dfs.namenode.path.based.cache.retry.interval.ms
Handling deprecation for hadoop.security.crypto.cipher.suite
Handling deprecation for dfs.ha.tail-edits.period
Handling deprecation for mapreduce.task.profile.reduce.params
Handling deprecation for hadoop.registry.jaas.context
Handling deprecation for yarn.resourcemanager.hostname
Handling deprecation for mapreduce.reduce.memory.mb
Handling deprecation for hadoop.security.group.mapping.ldap.search.filter.group
Handling deprecation for hadoop.http.authentication.kerberos.principal
Handling deprecation for hadoop.security.group.mapping.ldap.search.filter.user
Handling deprecation for yarn.nodemanager.disk-health-checker.min-free-space-per-disk-mb
Handling deprecation for dfs.namenode.edits.dir
Handling deprecation for yarn.client.failover-retries-on-socket-timeouts
Handling deprecation for dfs.namenode.decommission.max.concurrent.tracked.nodes
Handling deprecation for mapreduce.client.completion.pollinterval
Handling deprecation for dfs.namenode.name.dir.restore
Handling deprecation for dfs.namenode.secondary.http-address
Handling deprecation for mapreduce.jobhistory.recovery.store.leveldb.path
Handling deprecation for yarn.sharedcache.store.class
Handling deprecation for s3.bytes-per-checksum
Handling deprecation for yarn.nodemanager.windows-container.cpu-limit.enabled
Handling deprecation for yarn.resourcemanager.webapp.https.address
Handling deprecation for yarn.nodemanager.vmem-pmem-ratio
Handling deprecation for dfs.namenode.checkpoint.period
Handling deprecation for dfs.ha.automatic-failover.enabled
Submitting tokens for job: job_local1778575427_0001
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.fs.FileContext.getAbstractFileSystem(FileContext.java:331)
Handling deprecation for all properties in config...
Handling deprecation for mapreduce.jobtracker.address
Handling deprecation for yarn.resourcemanager.scheduler.monitor.policies
Handling deprecation for dfs.namenode.resource.check.interval
Handling deprecation for mapreduce.jobhistory.client.thread-count
Handling deprecation for yarn.app.mapreduce.am.containerlauncher.threadpool-initial-size
Handling deprecation for mapred.child.java.opts
Handling deprecation for mapreduce.jobtracker.retiredjobs.cache.size
Handling deprecation for dfs.client.https.need-auth
Handling deprecation for yarn.admin.acl
Handling deprecation for yarn.app.mapreduce.am.job.committer.cancel-timeout
Handling deprecation for mapreduce.job.emit-timeline-data
Handling deprecation for fs.ftp.host.port
Handling deprecation for dfs.namenode.avoid.read.stale.datanode
Handling deprecation for dfs.journalnode.rpc-address
Handling deprecation for mapreduce.job.end-notification.retry.attempts
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.ttl-interval-ms
Handling deprecation for yarn.resourcemanager.leveldb-state-store.path
Handling deprecation for mapred.mapper.new-api
Handling deprecation for yarn.ipc.rpc.class
Handling deprecation for ipc.client.connection.maxidletime
Handling deprecation for yarn.nodemanager.process-kill-wait.ms
Handling deprecation for mapreduce.cluster.acls.enabled
Handling deprecation for mapreduce.jobtracker.handler.count
Handling deprecation for io.map.index.interval
Handling deprecation for dfs.namenode.https-address
Handling deprecation for mapreduce.task.profile.reduces
Handling deprecation for fs.s3n.multipart.uploads.enabled
Handling deprecation for io.seqfile.sorter.recordlimit
Handling deprecation for mapreduce.job.ubertask.maxmaps
Handling deprecation for mapreduce.tasktracker.tasks.sleeptimebeforesigkill
Handling deprecation for hadoop.util.hash.type
Handling deprecation for dfs.namenode.replication.min
Handling deprecation for yarn.nodemanager.container-manager.thread-count
Handling deprecation for mapreduce.jobtracker.jobhistory.block.size
Handling deprecation for dfs.namenode.fs-limits.min-block-size
Handling deprecation for mapreduce.app-submission.cross-platform
Handling deprecation for fs.AbstractFileSystem.file.impl
Handling deprecation for net.topology.script.number.args
Handling deprecation for yarn.resourcemanager.container-tokens.master-key-rolling-interval-secs
Handling deprecation for mapreduce.map.output.compress.codec
Handling deprecation for mapreduce.job.reducer.preempt.delay.sec
Handling deprecation for s3native.bytes-per-checksum
Handling deprecation for dfs.namenode.path.based.cache.block.map.allocation.percent
Handling deprecation for yarn.nodemanager.windows-container.memory-limit.enabled
Handling deprecation for mapreduce.input.fileinputformat.split.minsize
Handling deprecation for hadoop.security.group.mapping
Handling deprecation for mapreduce.jobtracker.system.dir
Handling deprecation for mapreduce.job.end-notification.max.attempts
Handling deprecation for mapreduce.reduce.markreset.buffer.percent
Handling deprecation for dfs.datanode.cache.revocation.polling.ms
Handling deprecation for mapreduce.reduce.speculative
Handling deprecation for yarn.nodemanager.localizer.cache.cleanup.interval-ms
Handling deprecation for dfs.namenode.lazypersist.file.scrub.interval.sec
Handling deprecation for fs.s3a.threads.core
Handling deprecation for mapreduce.jobhistory.recovery.store.fs.uri
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.start-time-read-cache-size
Handling deprecation for hadoop.registry.zk.retry.interval.ms
Handling deprecation for yarn.nodemanager.keytab
Handling deprecation for dfs.namenode.replication.interval
Handling deprecation for yarn.resourcemanager.admin.address
Handling deprecation for mapreduce.job.maps
Handling deprecation for nfs.dump.dir
Handling deprecation for mapreduce.job.user.name
Handling deprecation for mapreduce.jobtracker.maxtasks.perjob
Handling deprecation for mapreduce.job.ubertask.enable
Handling deprecation for mapreduce.job.reduce.class
Handling deprecation for yarn.nodemanager.delete.debug-delay-sec
Handling deprecation for yarn.timeline-service.ttl-enable
Handling deprecation for yarn.resourcemanager.fs.state-store.retry-policy-spec
Handling deprecation for mapreduce.reduce.skip.maxgroups
Handling deprecation for dfs.client.use.datanode.hostname
Handling deprecation for fs.trash.interval
Handling deprecation for mapreduce.job.name
Handling deprecation for mapreduce.am.max-attempts
Handling deprecation for mapreduce.jobtracker.heartbeats.in.second
Handling deprecation for yarn.resourcemanager.zk-num-retries
Handling deprecation for s3.blocksize
Handling deprecation for dfs.datanode.data.dir
Handling deprecation for mapreduce.jobtracker.persist.jobstatus.active
Handling deprecation for mapreduce.reduce.shuffle.parallelcopies
Handling deprecation for fs.s3.buffer.dir
Handling deprecation for mapreduce.jobhistory.done-dir
Handling deprecation for hadoop.security.instrumentation.requires.admin
Handling deprecation for hadoop.registry.zk.retry.ceiling.ms
Handling deprecation for nfs.rtmax
Handling deprecation for dfs.datanode.data.dir.perm
Handling deprecation for yarn.resourcemanager.container.liveness-monitor.interval-ms
Handling deprecation for yarn.nodemanager.env-whitelist
Handling deprecation for dfs.namenode.backup.address
Handling deprecation for dfs.namenode.xattrs.enabled
Handling deprecation for dfs.datanode.readahead.bytes
Handling deprecation for mapreduce.jobhistory.cleaner.enable
Handling deprecation for dfs.client.block.write.retries
Handling deprecation for mapreduce.tasktracker.http.address
Handling deprecation for yarn.nodemanager.linux-container-executor.cgroups.hierarchy
Handling deprecation for ha.failover-controller.graceful-fence.connection.retries
Handling deprecation for yarn.resourcemanager.recovery.enabled
Handling deprecation for yarn.app.mapreduce.am.container.log.backups
Handling deprecation for dfs.namenode.safemode.threshold-pct
Handling deprecation for yarn.nodemanager.disk-health-checker.interval-ms
Handling deprecation for hadoop.security.java.secure.random.algorithm
Handling deprecation for dfs.namenode.list.cache.directives.num.responses
Handling deprecation for dfs.datanode.dns.nameserver
Handling deprecation for mapreduce.cluster.temp.dir
Handling deprecation for fs.s3a.max.total.tasks
Handling deprecation for mapreduce.reduce.maxattempts
Handling deprecation for mapreduce.client.submit.file.replication
Handling deprecation for mapreduce.shuffle.port
Handling deprecation for yarn.resourcemanager.resource-tracker.client.thread-count
Handling deprecation for dfs.namenode.replication.considerLoad
Handling deprecation for dfs.namenode.edits.journal-plugin.qjournal
Handling deprecation for dfs.client.write.exclude.nodes.cache.expiry.interval.millis
Handling deprecation for yarn.nodemanager.delete.thread-count
Handling deprecation for dfs.client.mmap.cache.timeout.ms
Handling deprecation for yarn.nodemanager.admin-env
Handling deprecation for io.skip.checksum.errors
Handling deprecation for yarn.timeline-service.hostname
Handling deprecation for yarn.resourcemanager.proxy-user-privileges.enabled
Handling deprecation for mapreduce.job.speculative.speculative-cap-total-tasks
Handling deprecation for yarn.acl.enable
Handling deprecation for fs.s3a.fast.upload
Handling deprecation for file.blocksize
Handling deprecation for mapreduce.job.speculative.slowtaskthreshold
Handling deprecation for ftp.replication
Handling deprecation for yarn.sharedcache.cleaner.initial-delay-mins
Handling deprecation for s3native.client-write-packet-size
Handling deprecation for hadoop.rpc.socket.factory.class.default
Handling deprecation for file.bytes-per-checksum
Handling deprecation for dfs.datanode.slow.io.warning.threshold.ms
Handling deprecation for io.seqfile.lazydecompress
Handling deprecation for mapreduce.task.skip.start.attempts
Handling deprecation for dfs.namenode.reject-unresolved-dn-topology-mapping
Handling deprecation for hadoop.common.configuration.version
Handling deprecation for yarn.resourcemanager.client.thread-count
Handling deprecation for dfs.datanode.drop.cache.behind.reads
Handling deprecation for yarn.sharedcache.admin.address
Handling deprecation for mapreduce.job.output.value.class
Handling deprecation for mapreduce.output.fileoutputformat.outputdir
Handling deprecation for mapreduce.jobtracker.taskcache.levels
Handling deprecation for yarn.nodemanager.linux-container-executor.nonsecure-mode.user-pattern
Handling deprecation for yarn.resourcemanager.zk-timeout-ms
Handling deprecation for yarn.resourcemanager.max-completed-applications
Handling deprecation for mapreduce.job.jvm.numtasks
Handling deprecation for yarn.sharedcache.cleaner.period-mins
Handling deprecation for mapreduce.jobtracker.tasktracker.maxblacklists
Handling deprecation for dfs.namenode.top.num.users
Handling deprecation for yarn.nodemanager.linux-container-executor.cgroups.mount
Handling deprecation for yarn.sharedcache.checksum.algo.impl
Handling deprecation for mapreduce.job.end-notification.max.retry.interval
Handling deprecation for mapreduce.job.acl-view-job
Handling deprecation for mapreduce.job.classloader
Handling deprecation for yarn.log-aggregation-enable
Handling deprecation for mapreduce.reduce.shuffle.fetch.retry.interval-ms
Handling deprecation for yarn.resourcemanager.nodemanager.minimum.version
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.size
Handling deprecation for yarn.app.mapreduce.am.job.task.listener.thread-count
Handling deprecation for yarn.app.mapreduce.am.resource.cpu-vcores
Handling deprecation for dfs.namenode.edit.log.autoroll.check.interval.ms
Handling deprecation for mapreduce.output.fileoutputformat.compress.type
Handling deprecation for hadoop.hdfs.configuration.version
Handling deprecation for hadoop.security.group.mapping.ldap.search.attr.member
Handling deprecation for yarn.nodemanager.log.retain-seconds
Handling deprecation for yarn.nodemanager.local-cache.max-files-per-directory
Handling deprecation for mapreduce.job.end-notification.retry.interval
Handling deprecation for hadoop.ssl.client.conf
Handling deprecation for yarn.sharedcache.root-dir
Handling deprecation for dfs.journalnode.https-address
Handling deprecation for mapreduce.reduce.shuffle.fetch.retry.timeout-ms
Handling deprecation for dfs.bytes-per-checksum
Handling deprecation for dfs.namenode.max.objects
Handling deprecation for mapreduce.tasktracker.instrumentation
Handling deprecation for dfs.datanode.max.transfer.threads
Handling deprecation for dfs.block.access.key.update.interval
Handling deprecation for mapreduce.jobtracker.jobhistory.task.numberprogresssplits
Handling deprecation for mapreduce.map.memory.mb
Handling deprecation for ha.failover-controller.new-active.rpc-timeout.ms
Handling deprecation for hadoop.ssl.hostname.verifier
Handling deprecation for dfs.client.read.shortcircuit
Handling deprecation for dfs.datanode.hdfs-blocks-metadata.enabled
Handling deprecation for mapreduce.tasktracker.healthchecker.interval
Handling deprecation for dfs.image.transfer.chunksize
Handling deprecation for mapreduce.tasktracker.taskmemorymanager.monitoringinterval
Handling deprecation for dfs.client.https.keystore.resource
Handling deprecation for yarn.resourcemanager.connect.retry-interval.ms
Handling deprecation for yarn.timeline-service.webapp.address
Handling deprecation for s3native.blocksize
Handling deprecation for yarn.scheduler.minimum-allocation-mb
Handling deprecation for yarn.sharedcache.cleaner.resource-sleep-ms
Handling deprecation for net.topology.impl
Handling deprecation for dfs.client.failover.sleep.base.millis
Handling deprecation for dfs.permissions.superusergroup
Handling deprecation for io.seqfile.compress.blocksize
Handling deprecation for hadoop.registry.zk.retry.times
Handling deprecation for fs.AbstractFileSystem.ftp.impl
Handling deprecation for dfs.namenode.checkpoint.edits.dir
Handling deprecation for mapreduce.job.running.reduce.limit
Handling deprecation for dfs.blockreport.initialDelay
Handling deprecation for dfs.namenode.heartbeat.recheck-interval
Handling deprecation for dfs.namenode.safemode.extension
Handling deprecation for yarn.scheduler.maximum-allocation-mb
Handling deprecation for mapreduce.job.reduce.shuffle.consumer.plugin.class
Handling deprecation for yarn.nodemanager.vmem-check-enabled
Handling deprecation for mapreduce.task.io.sort.factor
Handling deprecation for mapreduce.jobtracker.persist.jobstatus.dir
Handling deprecation for dfs.client.failover.sleep.max.millis
Handling deprecation for dfs.namenode.delegation.key.update-interval
Handling deprecation for hadoop.rpc.protection
Handling deprecation for fs.permissions.umask-mode
Handling deprecation for fs.s3.sleepTimeSeconds
Handling deprecation for ha.health-monitor.rpc-timeout.ms
Handling deprecation for hadoop.http.staticuser.user
Handling deprecation for fs.s3a.connection.maximum
Handling deprecation for yarn.nodemanager.linux-container-executor.nonsecure-mode.limit-users
Handling deprecation for fs.s3a.paging.maximum
Handling deprecation for fs.AbstractFileSystem.viewfs.impl
Handling deprecation for fs.ftp.host
Handling deprecation for yarn.nodemanager.linux-container-executor.nonsecure-mode.local-user
Handling deprecation for fs.s3a.impl
Handling deprecation for hadoop.http.authentication.kerberos.keytab
Handling deprecation for dfs.namenode.fs-limits.max-blocks-per-file
Handling deprecation for mapreduce.tasktracker.http.threads
Handling deprecation for mapreduce.tasktracker.dns.nameserver
Handling deprecation for yarn.resourcemanager.am-rm-tokens.master-key-rolling-interval-secs
Handling deprecation for dfs.client.block.write.replace-datanode-on-failure.enable
Handling deprecation for io.compression.codec.bzip2.library
Handling deprecation for mapreduce.map.skip.maxrecords
Handling deprecation for dfs.client.use.legacy.blockreader.local
Handling deprecation for dfs.namenode.checkpoint.dir
Handling deprecation for dfs.namenode.top.windows.minutes
Handling deprecation for mapreduce.job.maxtaskfailures.per.tracker
Handling deprecation for net.topology.node.switch.mapping.impl
Handling deprecation for mapreduce.shuffle.max.connections
Handling deprecation for mapreduce.jobhistory.loadedjobs.cache.size
Handling deprecation for dfs.storage.policy.enabled
Handling deprecation for yarn.client.application-client-protocol.poll-interval-ms
Handling deprecation for yarn.nodemanager.localizer.address
Handling deprecation for dfs.namenode.list.cache.pools.num.responses
Handling deprecation for nfs.server.port
Handling deprecation for mapreduce.client.output.filter
Handling deprecation for yarn.timeline-service.client.best-effort
Handling deprecation for ha.zookeeper.parent-znode
Handling deprecation for mapreduce.jobtracker.persist.jobstatus.hours
Handling deprecation for yarn.sharedcache.admin.thread-count
Handling deprecation for yarn.nodemanager.resource.cpu-vcores
Handling deprecation for dfs.datanode.block-pinning.enabled
Handling deprecation for mapreduce.jobhistory.http.policy
Handling deprecation for yarn.resourcemanager.webapp.delegation-token-auth-filter.enabled
Handling deprecation for mapreduce.job.speculative.retry-after-no-speculate
Handling deprecation for fs.s3a.attempts.maximum
Handling deprecation for s3native.stream-buffer-size
Handling deprecation for io.seqfile.local.dir
Handling deprecation for yarn.log-aggregation.retain-check-interval-seconds
Handling deprecation for fs.s3n.multipart.copy.block.size
Handling deprecation for dfs.encrypt.data.transfer.cipher.key.bitlength
Handling deprecation for dfs.datanode.sync.behind.writes
Handling deprecation for yarn.resourcemanager.zk-acl
Handling deprecation for hadoop.ssl.keystores.factory.class
Handling deprecation for mapreduce.job.split.metainfo.maxsize
Handling deprecation for fs.s3.maxRetries
Handling deprecation for hadoop.security.random.device.file.path
Handling deprecation for yarn.client.nodemanager-connect.max-wait-ms
Handling deprecation for dfs.namenode.stale.datanode.interval
Handling deprecation for mapreduce.task.io.sort.mb
Handling deprecation for yarn.resourcemanager.zk-state-store.parent-path
Handling deprecation for yarn.app.mapreduce.client-am.ipc.max-retries
Handling deprecation for fs.client.resolve.remote.symlinks
Handling deprecation for yarn.nodemanager.linux-container-executor.cgroups.strict-resource-usage
Handling deprecation for hadoop.ssl.enabled.protocols
Handling deprecation for mapreduce.reduce.cpu.vcores
Handling deprecation for yarn.client.failover-retries
Handling deprecation for mapreduce.jobhistory.address
Handling deprecation for hadoop.ssl.enabled
Handling deprecation for dfs.replication.max
Handling deprecation for dfs.namenode.name.dir
Handling deprecation for dfs.datanode.https.address
Handling deprecation for ipc.client.kill.max
Handling deprecation for mapreduce.job.committer.setup.cleanup.needed
Handling deprecation for dfs.client.domain.socket.data.traffic
Handling deprecation for yarn.nodemanager.localizer.cache.target-size-mb
Handling deprecation for yarn.resourcemanager.admin.client.thread-count
Handling deprecation for dfs.block.access.token.enable
Handling deprecation for mapreduce.job.speculative.retry-after-speculate
Handling deprecation for dfs.datanode.address
Handling deprecation for mapreduce.jobtracker.restart.recover
Handling deprecation for ipc.client.connect.max.retries
Handling deprecation for yarn.timeline-service.store-class
Handling deprecation for dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
Handling deprecation for hadoop.tmp.dir
Handling deprecation for dfs.datanode.handler.count
Handling deprecation for yarn.resourcemanager.ha.automatic-failover.embedded
Handling deprecation for yarn.timeline-service.ttl-ms
Handling deprecation for mapreduce.task.profile.map.params
Handling deprecation for yarn.resourcemanager.nodemanagers.heartbeat-interval-ms
Handling deprecation for mapreduce.map.speculative
Handling deprecation for yarn.timeline-service.recovery.enabled
Handling deprecation for mapreduce.job.map.class
Handling deprecation for dfs.namenode.resource.checked.volumes.minimum
Handling deprecation for yarn.nodemanager.recovery.dir
Handling deprecation for mapreduce.job.counters.max
Handling deprecation for yarn.resourcemanager.keytab
Handling deprecation for dfs.namenode.max.extra.edits.segments.retained
Handling deprecation for dfs.webhdfs.user.provider.user.pattern
Handling deprecation for dfs.client.mmap.enabled
Handling deprecation for mapreduce.map.log.level
Handling deprecation for dfs.client.file-block-storage-locations.timeout.millis
Handling deprecation for yarn.client.max-cached-nodemanagers-proxies
Handling deprecation for yarn.app.mapreduce.am.scheduler.heartbeat.interval-ms
Handling deprecation for hadoop.fuse.timer.period
Handling deprecation for fs.trash.checkpoint.interval
Handling deprecation for yarn.sharedcache.app-checker.class
Handling deprecation for dfs.journalnode.http-address
Handling deprecation for yarn.app.mapreduce.am.staging-dir
Handling deprecation for mapreduce.tasktracker.local.dir.minspacestart
Handling deprecation for yarn.nm.liveness-monitor.expiry-interval-ms
Handling deprecation for ha.health-monitor.check-interval.ms
Handling deprecation for mapreduce.reduce.shuffle.merge.percent
Handling deprecation for dfs.namenode.retrycache.heap.percent
Handling deprecation for yarn.nodemanager.docker-container-executor.exec-name
Handling deprecation for ipc.client.connect.timeout
Handling deprecation for yarn.resourcemanager.fs.state-store.retry-interval-ms
Handling deprecation for mapreduce.output.fileoutputformat.compress
Handling deprecation for yarn.nodemanager.local-dirs
Handling deprecation for yarn.nodemanager.recovery.enabled
Handling deprecation for io.native.lib.available
Handling deprecation for yarn.sharedcache.store.in-memory.staleness-period-mins
Handling deprecation for yarn.resourcemanager.am.max-attempts
Handling deprecation for s3.replication
Handling deprecation for mapreduce.input.fileinputformat.inputdir
Handling deprecation for fs.AbstractFileSystem.har.impl
Handling deprecation for dfs.image.compress
Handling deprecation for mapreduce.job.running.map.limit
Handling deprecation for mapreduce.reduce.input.buffer.percent
Handling deprecation for yarn.nodemanager.webapp.address
Handling deprecation for dfs.datanode.available-space-volume-choosing-policy.balanced-space-preference-fraction
Handling deprecation for dfs.namenode.edit.log.autoroll.multiplier.threshold
Handling deprecation for hadoop.security.group.mapping.ldap.ssl
Handling deprecation for dfs.namenode.checkpoint.check.period
Handling deprecation for fs.defaultFS
Handling deprecation for fs.s3a.multipart.size
Handling deprecation for dfs.client.slow.io.warning.threshold.ms
Handling deprecation for yarn.app.mapreduce.am.job.committer.commit-window
Handling deprecation for hadoop.security.group.mapping.ldap.search.attr.group.name
Handling deprecation for yarn.nodemanager.disk-health-checker.max-disk-utilization-per-disk-percentage
Handling deprecation for yarn.nodemanager.container-monitor.procfs-tree.smaps-based-rss.enabled
Handling deprecation for mapreduce.job.submithostname
Handling deprecation for mapreduce.map.sort.spill.percent
Handling deprecation for hadoop.security.crypto.codec.classes.aes.ctr.nopadding
Handling deprecation for dfs.namenode.http-address
Handling deprecation for hadoop.security.groups.negative-cache.secs
Handling deprecation for hadoop.ssl.server.conf
Handling deprecation for mapreduce.ifile.readahead
Handling deprecation for s3native.replication
Handling deprecation for yarn.client.nodemanager-client-async.thread-pool-max-size
Handling deprecation for mapreduce.jobtracker.staging.root.dir
Handling deprecation for mapreduce.jobhistory.admin.address
Handling deprecation for dfs.namenode.startup.delay.block.deletion.sec
Handling deprecation for yarn.nodemanager.health-checker.interval-ms
Handling deprecation for dfs.namenode.checkpoint.max-retries
Handling deprecation for s3.stream-buffer-size
Handling deprecation for ftp.client-write-packet-size
Handling deprecation for dfs.datanode.fsdatasetcache.max.threads.per.volume
Handling deprecation for mapreduce.output.fileoutputformat.compress.codec
Handling deprecation for yarn.timeline-service.keytab
Handling deprecation for yarn.sharedcache.store.in-memory.initial-delay-mins
Handling deprecation for mapreduce.jobhistory.webapp.address
Handling deprecation for mapreduce.task.userlog.limit.kb
Handling deprecation for mapreduce.reduce.shuffle.fetch.retry.enabled
Handling deprecation for yarn.app.mapreduce.task.container.log.backups
Handling deprecation for dfs.heartbeat.interval
Handling deprecation for ha.zookeeper.session-timeout.ms
Handling deprecation for fs.s3a.connection.ssl.enabled
Handling deprecation for yarn.sharedcache.webapp.address
Handling deprecation for hadoop.http.authentication.signature.secret.file
Handling deprecation for hadoop.fuse.connection.timeout
Handling deprecation for mapreduce.input.fileinputformat.numinputfiles
Handling deprecation for yarn.nodemanager.log-aggregation.compression-type
Handling deprecation for ipc.server.max.connections
Handling deprecation for yarn.resourcemanager.work-preserving-recovery.scheduling-wait-ms
Handling deprecation for yarn.nodemanager.log-dirs
Handling deprecation for yarn.app.mapreduce.am.resource.mb
Handling deprecation for hadoop.security.groups.cache.secs
Handling deprecation for mapreduce.job.speculative.minimum-allowed-tasks
Handling deprecation for yarn.nodemanager.container-monitor.interval-ms
Handling deprecation for dfs.datanode.cache.revocation.timeout.ms
Handling deprecation for mapreduce.jobhistory.recovery.store.class
Handling deprecation for mapreduce.task.combine.progress.records
Handling deprecation for s3.client-write-packet-size
Handling deprecation for mapreduce.jobtracker.instrumentation
Handling deprecation for dfs.replication
Handling deprecation for mapreduce.shuffle.transfer.buffer.size
Handling deprecation for hadoop.security.group.mapping.ldap.directory.search.timeout
Handling deprecation for dfs.datanode.available-space-volume-choosing-policy.balanced-space-threshold
Handling deprecation for hadoop.work.around.non.threadsafe.getpwuid
Handling deprecation for yarn.app.mapreduce.client-am.ipc.max-retries-on-timeouts
Handling deprecation for yarn.nodemanager.address
Handling deprecation for mapreduce.tasktracker.taskcontroller
Handling deprecation for mapreduce.tasktracker.indexcache.mb
Handling deprecation for yarn.scheduler.maximum-allocation-vcores
Handling deprecation for mapreduce.job.reduces
Handling deprecation for yarn.nodemanager.sleep-delay-before-sigkill.ms
Handling deprecation for yarn.timeline-service.address
Handling deprecation for yarn.resourcemanager.configuration.provider-class
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.expiry
Handling deprecation for yarn.sharedcache.enabled
Handling deprecation for tfile.io.chunk.size
Handling deprecation for mapreduce.job.acl-modify-job
Handling deprecation for hadoop.registry.zk.session.timeout.ms
Handling deprecation for fs.automatic.close
Handling deprecation for ha.health-monitor.sleep-after-disconnect.ms
Handling deprecation for mapreduce.tasktracker.reduce.tasks.maximum
Handling deprecation for mapreduce.input.fileinputformat.list-status.num-threads
Handling deprecation for dfs.datanode.directoryscan.threads
Handling deprecation for dfs.datanode.directoryscan.interval
Handling deprecation for dfs.namenode.acls.enabled
Handling deprecation for dfs.client.short.circuit.replica.stale.threshold.ms
Handling deprecation for hadoop.http.authentication.token.validity
Handling deprecation for fs.s3.block.size
Handling deprecation for ha.failover-controller.graceful-fence.rpc-timeout.ms
Handling deprecation for mapreduce.tasktracker.local.dir.minspacekill
Handling deprecation for dfs.namenode.resource.du.reserved
Handling deprecation for mapreduce.jobhistory.cleaner.interval-ms
Handling deprecation for dfs.namenode.datanode.registration.ip-hostname-check
Handling deprecation for mapreduce.jobhistory.intermediate-done-dir
Handling deprecation for mapreduce.jobtracker.http.address
Handling deprecation for dfs.namenode.backup.http-address
Handling deprecation for dfs.namenode.edits.noeditlogchannelflush
Handling deprecation for mapreduce.reduce.shuffle.input.buffer.percent
Handling deprecation for mapreduce.map.maxattempts
Handling deprecation for yarn.http.policy
Handling deprecation for dfs.namenode.audit.loggers
Handling deprecation for hadoop.security.groups.cache.warn.after.ms
Handling deprecation for io.serializations
Handling deprecation for mapreduce.tasktracker.outofband.heartbeat
Handling deprecation for mapreduce.reduce.shuffle.read.timeout
Handling deprecation for hadoop.security.crypto.buffer.size
Handling deprecation for mapreduce.reduce.skip.proc.count.autoincr
Handling deprecation for mapreduce.ifile.readahead.bytes
Handling deprecation for dfs.http.policy
Handling deprecation for hadoop.registry.secure
Handling deprecation for dfs.namenode.safemode.min.datanodes
Handling deprecation for dfs.client.file-block-storage-locations.num-threads
Handling deprecation for mapreduce.cluster.local.dir
Handling deprecation for mapreduce.tasktracker.report.address
Handling deprecation for dfs.namenode.secondary.https-address
Handling deprecation for hadoop.kerberos.kinit.command
Handling deprecation for yarn.timeline-service.http-authentication.type
Handling deprecation for dfs.block.access.token.lifetime
Handling deprecation for dfs.webhdfs.enabled
Handling deprecation for dfs.namenode.delegation.token.max-lifetime
Handling deprecation for dfs.namenode.avoid.write.stale.datanode
Handling deprecation for dfs.datanode.drop.cache.behind.writes
Handling deprecation for yarn.log-aggregation.retain-seconds
Handling deprecation for mapreduce.job.complete.cancel.delegation.tokens
Handling deprecation for mapreduce.local.clientfactory.class.name
Handling deprecation for mapreduce.shuffle.connection-keep-alive.timeout
Handling deprecation for dfs.namenode.num.extra.edits.retained
Handling deprecation for yarn.scheduler.minimum-allocation-vcores
Handling deprecation for ipc.client.connect.max.retries.on.timeouts
Handling deprecation for yarn.timeline-service.client.retry-interval-ms
Handling deprecation for yarn.timeline-service.client.max-retries
Handling deprecation for fs.s3n.block.size
Handling deprecation for mapreduce.job.map.output.collector.class
Handling deprecation for ha.health-monitor.connect-retry-interval.ms
Handling deprecation for mapreduce.shuffle.max.threads
Handling deprecation for nfs.exports.allowed.hosts
Handling deprecation for dfs.client.mmap.cache.size
Handling deprecation for mapreduce.tasktracker.map.tasks.maximum
Handling deprecation for io.file.buffer.size
Handling deprecation for dfs.client.datanode-restart.timeout
Handling deprecation for io.mapfile.bloom.size
Handling deprecation for hadoop.security.kms.client.authentication.retry-count
Handling deprecation for dfs.namenode.checkpoint.txns
Handling deprecation for ipc.client.connect.retry.interval
Handling deprecation for dfs.client-write-packet-size
Handling deprecation for mapreduce.reduce.shuffle.connect.timeout
Handling deprecation for yarn.resourcemanager.fs.state-store.uri
Handling deprecation for fs.swift.impl
Handling deprecation for hadoop.registry.zk.connection.timeout.ms
Handling deprecation for mapred.queue.default.acl-administer-jobs
Handling deprecation for mapreduce.job.submithostaddress
Handling deprecation for dfs.cachereport.intervalMsec
Handling deprecation for yarn.app.mapreduce.shuffle.log.backups
Handling deprecation for yarn.app.mapreduce.am.container.log.limit.kb
Handling deprecation for yarn.nodemanager.resourcemanager.minimum.version
Handling deprecation for ftp.blocksize
Handling deprecation for yarn.resourcemanager.address
Handling deprecation for file.stream-buffer-size
Handling deprecation for yarn.resourcemanager.scheduler.monitor.enable
Handling deprecation for mapreduce.job.ubertask.maxreduces
Handling deprecation for nfs.allow.insecure.ports
Handling deprecation for yarn.sharedcache.nm.uploader.thread-count
Handling deprecation for ipc.client.idlethreshold
Handling deprecation for ftp.stream-buffer-size
Handling deprecation for yarn.sharedcache.client-server.address
Handling deprecation for dfs.client.failover.connection.retries.on.timeouts
Handling deprecation for dfs.namenode.replication.work.multiplier.per.iteration
Handling deprecation for hadoop.http.authentication.simple.anonymous.allowed
Handling deprecation for hadoop.security.authorization
Handling deprecation for yarn.client.nodemanager-connect.retry-interval-ms
Handling deprecation for yarn.am.liveness-monitor.expiry-interval-ms
Handling deprecation for fs.har.impl.disable.cache
Handling deprecation for yarn.nodemanager.linux-container-executor.resources-handler.class
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.read-cache-size
Handling deprecation for hadoop.security.authentication
Handling deprecation for dfs.image.compression.codec
Handling deprecation for mapreduce.task.files.preserve.failedtasks
Handling deprecation for dfs.client.read.shortcircuit.streams.cache.size
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.path
Handling deprecation for mapreduce.job.reduce.slowstart.completedmaps
Handling deprecation for mapreduce.jobhistory.minicluster.fixed.ports
Handling deprecation for file.replication
Handling deprecation for yarn.resourcemanager.ha.automatic-failover.enabled
Handling deprecation for mapreduce.job.userlog.retain.hours
Handling deprecation for mapreduce.jobhistory.joblist.cache.size
Handling deprecation for dfs.namenode.accesstime.precision
Handling deprecation for yarn.resourcemanager.work-preserving-recovery.enabled
Handling deprecation for dfs.namenode.fs-limits.max-xattrs-per-inode
Handling deprecation for io.mapfile.bloom.error.rate
Handling deprecation for yarn.resourcemanager.store.class
Handling deprecation for dfs.image.transfer.timeout
Handling deprecation for yarn.timeline-service.leveldb-state-store.path
Handling deprecation for nfs.wtmax
Handling deprecation for mapreduce.job.combine.class
Handling deprecation for dfs.namenode.support.allow.format
Handling deprecation for fs.s3a.multipart.purge
Handling deprecation for dfs.secondary.namenode.kerberos.internal.spnego.principal
Handling deprecation for fs.s3a.connection.establish.timeout
Handling deprecation for dfs.stream-buffer-size
Handling deprecation for dfs.namenode.invalidate.work.pct.per.iteration
Handling deprecation for yarn.nodemanager.container-executor.class
Handling deprecation for fs.s3a.multipart.purge.age
Handling deprecation for yarn.resourcemanager.scheduler.client.thread-count
Handling deprecation for dfs.namenode.top.enabled
Handling deprecation for yarn.app.mapreduce.shuffle.log.separate
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.low-watermark
Handling deprecation for fs.s3a.fast.buffer.size
Handling deprecation for hadoop.user.group.static.mapping.overrides
Handling deprecation for tfile.fs.input.buffer.size
Handling deprecation for dfs.client.cached.conn.retry
Handling deprecation for hadoop.http.authentication.type
Handling deprecation for dfs.namenode.list.encryption.zones.num.responses
Handling deprecation for mapreduce.map.cpu.vcores
Handling deprecation for dfs.namenode.path.based.cache.refresh.interval.ms
Handling deprecation for dfs.namenode.decommission.interval
Handling deprecation for dfs.namenode.fs-limits.max-directory-items
Handling deprecation for yarn.resourcemanager.zk-retry-interval-ms
Handling deprecation for ftp.bytes-per-checksum
Handling deprecation for dfs.ha.log-roll.period
Handling deprecation for dfs.user.home.dir.prefix
Handling deprecation for ipc.client.fallback-to-simple-auth-allowed
Handling deprecation for yarn.nodemanager.pmem-check-enabled
Handling deprecation for yarn.nodemanager.remote-app-log-dir
Handling deprecation for dfs.namenode.inotify.max.events.per.rpc
Handling deprecation for mapreduce.task.profile.maps
Handling deprecation for mapreduce.shuffle.ssl.file.buffer.size
Handling deprecation for mapreduce.tasktracker.healthchecker.script.timeout
Handling deprecation for yarn.timeline-service.webapp.https.address
Handling deprecation for yarn.nodemanager.resource.percentage-physical-cpu-limit
Handling deprecation for yarn.app.mapreduce.am.command-opts
Handling deprecation for dfs.namenode.fs-limits.max-xattr-size
Handling deprecation for dfs.datanode.http.address
Handling deprecation for dfs.namenode.blocks.per.postponedblocks.rescan
Handling deprecation for yarn.sharedcache.nm.uploader.replication.factor
Handling deprecation for hadoop.registry.zk.root
Handling deprecation for hadoop.jetty.logs.serve.aliases
Handling deprecation for yarn.client.failover-proxy-provider
Handling deprecation for mapreduce.jobhistory.admin.acl
Handling deprecation for yarn.app.mapreduce.am.hard-kill-timeout-ms
Handling deprecation for yarn.nodemanager.remote-app-log-dir-suffix
Handling deprecation for mapreduce.jobhistory.principal
Handling deprecation for yarn.resourcemanager.webapp.address
Handling deprecation for mapreduce.jobhistory.recovery.enable
Handling deprecation for yarn.sharedcache.store.in-memory.check-period-mins
Handling deprecation for nfs.mountd.port
Handling deprecation for mapreduce.reduce.merge.inmem.threshold
Handling deprecation for fs.df.interval
Handling deprecation for yarn.timeline-service.enabled
Handling deprecation for mapreduce.jobtracker.jobhistory.lru.cache.size
Handling deprecation for mapreduce.task.profile
Handling deprecation for mapreduce.job.output.key.class
Handling deprecation for yarn.nodemanager.hostname
Handling deprecation for dfs.namenode.num.checkpoints.retained
Handling deprecation for mapreduce.job.queuename
Handling deprecation for mapreduce.jobhistory.max-age-ms
Handling deprecation for mapreduce.job.token.tracking.ids.enabled
Handling deprecation for yarn.nodemanager.localizer.client.thread-count
Handling deprecation for yarn.sharedcache.uploader.server.thread-count
Handling deprecation for dfs.client.mmap.retry.timeout.ms
Handling deprecation for mapreduce.jobhistory.move.thread-count
Handling deprecation for dfs.permissions.enabled
Handling deprecation for dfs.blockreport.split.threshold
Handling deprecation for fs.AbstractFileSystem.hdfs.impl
Handling deprecation for dfs.datanode.balance.bandwidthPerSec
Handling deprecation for dfs.block.scanner.volume.bytes.per.second
Handling deprecation for hadoop.http.filter.initializers
Handling deprecation for yarn.timeline-service.http-authentication.simple.anonymous.allowed
Handling deprecation for dfs.default.chunk.view.size
Handling deprecation for yarn.sharedcache.client-server.thread-count
Handling deprecation for yarn.resourcemanager.resource-tracker.address
Handling deprecation for mapreduce.job.working.dir
Handling deprecation for mapreduce.jobhistory.datestring.cache.size
Handling deprecation for mapreduce.task.profile.params
Handling deprecation for dfs.namenode.decommission.blocks.per.interval
Handling deprecation for dfs.namenode.handler.count
Handling deprecation for dfs.image.transfer.bandwidthPerSec
Handling deprecation for rpc.metrics.quantile.enable
Handling deprecation for mapreduce.jobtracker.expire.trackers.interval
Handling deprecation for mapreduce.task.timeout
Handling deprecation for yarn.app.mapreduce.client.max-retries
Handling deprecation for yarn.nodemanager.resource.memory-mb
Handling deprecation for yarn.nodemanager.disk-health-checker.min-healthy-disks
Handling deprecation for dfs.datanode.failed.volumes.tolerated
Handling deprecation for yarn.timeline-service.handler-thread-count
Handling deprecation for ipc.server.listen.queue.size
Handling deprecation for fs.s3a.threads.max
Handling deprecation for yarn.resourcemanager.connect.max-wait.ms
Handling deprecation for mapreduce.fileoutputcommitter.algorithm.version
Handling deprecation for mapreduce.framework.name
Handling deprecation for mapreduce.map.skip.proc.count.autoincr
Handling deprecation for mapreduce.job.max.split.locations
Handling deprecation for yarn.resourcemanager.scheduler.class
Handling deprecation for yarn.resourcemanager.system-metrics-publisher.enabled
Handling deprecation for dfs.blocksize
Handling deprecation for yarn.sharedcache.nested-level
Handling deprecation for mapreduce.shuffle.connection-keep-alive.enable
Handling deprecation for fs.s3a.threads.keepalivetime
Handling deprecation for fs.s3a.connection.timeout
Handling deprecation for file.client-write-packet-size
Handling deprecation for ha.failover-controller.cli-check.rpc-timeout.ms
Handling deprecation for ha.zookeeper.acl
Handling deprecation for dfs.namenode.write.stale.datanode.ratio
Handling deprecation for dfs.encrypt.data.transfer
Handling deprecation for dfs.datanode.shared.file.descriptor.paths
Handling deprecation for mapreduce.input.lineinputformat.linespermap
Handling deprecation for yarn.resourcemanager.delayed.delegation-token.removal-interval-ms
Handling deprecation for yarn.nodemanager.localizer.fetch.thread-count
Handling deprecation for dfs.client.failover.max.attempts
Handling deprecation for yarn.resourcemanager.scheduler.address
Handling deprecation for dfs.client.read.shortcircuit.streams.cache.expiry.ms
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.start-time-write-cache-size
Handling deprecation for yarn.nodemanager.health-checker.script.timeout-ms
Handling deprecation for yarn.resourcemanager.fs.state-store.num-retries
Handling deprecation for hadoop.ssl.require.client.cert
Handling deprecation for hadoop.security.uid.cache.secs
Handling deprecation for mapreduce.jobhistory.keytab
Handling deprecation for dfs.client.read.shortcircuit.skip.checksum
Handling deprecation for yarn.resourcemanager.ha.automatic-failover.zk-base-path
Handling deprecation for mapreduce.shuffle.ssl.enabled
Handling deprecation for mapreduce.reduce.log.level
Handling deprecation for hadoop.registry.rm.enabled
Handling deprecation for mapreduce.tasktracker.dns.interface
Handling deprecation for yarn.resourcemanager.system-metrics-publisher.dispatcher.pool-size
Handling deprecation for mapreduce.job.speculative.speculative-cap-running-tasks
Handling deprecation for dfs.datanode.block.id.layout.upgrade.threads
Handling deprecation for dfs.datanode.use.datanode.hostname
Handling deprecation for dfs.client.context
Handling deprecation for yarn.resourcemanager.ha.enabled
Handling deprecation for mapred.reducer.new-api
Handling deprecation for dfs.namenode.delegation.token.renew-interval
Handling deprecation for dfs.blockreport.intervalMsec
Handling deprecation for fs.s3a.multipart.threshold
Handling deprecation for mapreduce.reduce.shuffle.memory.limit.percent
Handling deprecation for dfs.https.server.keystore.resource
Handling deprecation for io.map.index.skip
Handling deprecation for mapreduce.job.hdfs-servers
Handling deprecation for mapreduce.jobtracker.taskscheduler
Handling deprecation for dfs.namenode.kerberos.internal.spnego.principal
Handling deprecation for yarn.resourcemanager.state-store.max-completed-applications
Handling deprecation for mapreduce.map.output.compress
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.num.refill.threads
Handling deprecation for fs.s3n.multipart.uploads.block.size
Handling deprecation for mapreduce.task.merge.progress.records
Handling deprecation for dfs.datanode.dns.interface
Handling deprecation for map.sort.class
Handling deprecation for yarn.nodemanager.aux-services.mapreduce_shuffle.class
Handling deprecation for tfile.fs.output.buffer.size
Handling deprecation for fs.du.interval
Handling deprecation for dfs.client.failover.connection.retries
Handling deprecation for dfs.namenode.top.window.num.buckets
Handling deprecation for mapreduce.job.dir
Handling deprecation for fs.s3a.buffer.dir
Handling deprecation for mapreduce.reduce.shuffle.retry-delay.max.ms
Handling deprecation for yarn.sharedcache.uploader.server.address
Handling deprecation for mapreduce.client.progressmonitor.pollinterval
Handling deprecation for yarn.app.mapreduce.shuffle.log.limit.kb
Handling deprecation for dfs.datanode.max.locked.memory
Handling deprecation for dfs.namenode.retrycache.expirytime.millis
Handling deprecation for dfs.datanode.scan.period.hours
Handling deprecation for dfs.client.block.write.replace-datanode-on-failure.best-effort
Handling deprecation for mapreduce.jobhistory.move.interval-ms
Handling deprecation for dfs.ha.fencing.ssh.connect-timeout
Handling deprecation for yarn.nodemanager.log-aggregation.roll-monitoring-interval-seconds
Handling deprecation for dfs.namenode.fs-limits.max-component-length
Handling deprecation for hadoop.registry.zk.quorum
Handling deprecation for dfs.namenode.enable.retrycache
Handling deprecation for dfs.datanode.du.reserved
Handling deprecation for yarn.timeline-service.state-store-class
Handling deprecation for dfs.datanode.ipc.address
Handling deprecation for hadoop.registry.system.acls
Handling deprecation for dfs.client.block.write.replace-datanode-on-failure.policy
Handling deprecation for dfs.namenode.path.based.cache.retry.interval.ms
Handling deprecation for hadoop.security.crypto.cipher.suite
Handling deprecation for dfs.ha.tail-edits.period
Handling deprecation for mapreduce.task.profile.reduce.params
Handling deprecation for hadoop.registry.jaas.context
Handling deprecation for yarn.resourcemanager.hostname
Handling deprecation for mapreduce.reduce.memory.mb
Handling deprecation for hadoop.security.group.mapping.ldap.search.filter.group
Handling deprecation for hadoop.http.authentication.kerberos.principal
Handling deprecation for hadoop.security.group.mapping.ldap.search.filter.user
Handling deprecation for yarn.nodemanager.disk-health-checker.min-free-space-per-disk-mb
Handling deprecation for dfs.namenode.edits.dir
Handling deprecation for yarn.client.failover-retries-on-socket-timeouts
Handling deprecation for dfs.namenode.decommission.max.concurrent.tracked.nodes
Handling deprecation for mapreduce.client.completion.pollinterval
Handling deprecation for dfs.namenode.name.dir.restore
Handling deprecation for dfs.namenode.secondary.http-address
Handling deprecation for mapreduce.jobhistory.recovery.store.leveldb.path
Handling deprecation for yarn.sharedcache.store.class
Handling deprecation for s3.bytes-per-checksum
Handling deprecation for yarn.nodemanager.windows-container.cpu-limit.enabled
Handling deprecation for yarn.resourcemanager.webapp.https.address
Handling deprecation for yarn.nodemanager.vmem-pmem-ratio
Handling deprecation for dfs.namenode.checkpoint.period
Handling deprecation for dfs.ha.automatic-failover.enabled
The url to track the job: http://localhost:8080/
OutputCommitter set in config null
Running job: job_local1778575427_0001
File Output Committer Algorithm version is 1
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
/user/michaeljones/wcOutputMain/_temporary/0: masked=rwxr-xr-x
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones sending #11
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones got value #11
Call: mkdirs took 157ms
Starting mapper thread pool executor.
Max local threads: 1
Map tasks to process: 1
Waiting for map tasks
Starting task: attempt_local1778575427_0001_m_000000_0
currentIndex 0   0:0
mapreduce.cluster.local.dir for child : /tmp/hadoop-michaeljones/mapred/local/localRunner//michaeljones/jobcache/job_local1778575427_0001/attempt_local1778575427_0001_m_000000_0
using new api for output committer
File Output Committer Algorithm version is 1
ProcfsBasedProcessTree currently is supported only on Linux.
 Using ResourceCalculatorProcessTree : null
Processing split: hdfs://localhost:9000/user/michaeljones/wcInput:0+50
Trying map output collector class: org.apache.hadoop.mapred.MapTask$MapOutputBuffer
(EQUATOR) 0 kvi 26214396(104857584)
mapreduce.task.io.sort.mb: 100
soft limit at 83886080
bufstart = 0; bufvoid = 104857600
kvstart = 26214396; length = 6553600
Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones sending #12
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones got value #12
Call: getBlockLocations took 3ms
newInfo = LocatedBlocks{
  fileLength=50
  underConstruction=false
  blocks=[LocatedBlock{BP-1045030256-10.0.0.2-1433119149314:blk_1073741825_1002; getBlockSize()=50; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-b42c5705-9ba4-4b14-b00b-f9194bb036f0,DISK]]}]
  lastLocatedBlock=LocatedBlock{BP-1045030256-10.0.0.2-1433119149314:blk_1073741825_1002; getBlockSize()=50; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-b42c5705-9ba4-4b14-b00b-f9194bb036f0,DISK]]}
  isLastBlockComplete=true}
Connecting to datanode 127.0.0.1:50010

Starting flush of map output
Spilling map output
bufstart = 0; bufend = 82; bufvoid = 104857600
kvstart = 26214396(104857584); kvend = 26214368(104857472); length = 29/6553600
Finished spill 0
Task:attempt_local1778575427_0001_m_000000_0 is done. And is in the process of committing
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones sending #13
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones got value #13
Call: getFileInfo took 3ms
map
Task 'attempt_local1778575427_0001_m_000000_0' done.
Finishing task: attempt_local1778575427_0001_m_000000_0
map task executor complete.
Starting reduce thread pool executor.
Max local threads: 1
Reduce tasks to process: 1
Waiting for reduce tasks
Starting task: attempt_local1778575427_0001_r_000000_0
currentIndex 0   0:0
mapreduce.cluster.local.dir for child : /tmp/hadoop-michaeljones/mapred/local/localRunner//michaeljones/jobcache/job_local1778575427_0001/attempt_local1778575427_0001_r_000000_0
using new api for output committer
File Output Committer Algorithm version is 1
ProcfsBasedProcessTree currently is supported only on Linux.
 Using ResourceCalculatorProcessTree : null
Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@6db89c52
MergerManager: memoryLimit=668309888, maxSingleShuffleLimit=167077472, mergeThreshold=441084544, ioSortFactor=10, memToMemMergeOutputsThreshold=10
attempt_local1778575427_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
Got 0 map completion events from 0
GetMapEventsThread about to sleep for 1000
LocalFetcher 1 going to fetch: attempt_local1778575427_0001_m_000000_0
attempt_local1778575427_0001_m_000000_0: Proceeding with shuffle since usedMemory (0) is lesser than memoryLimit (668309888).CommitMemory is (0)
localfetcher#1 about to shuffle output of map attempt_local1778575427_0001_m_000000_0 decomp: 63 len: 67 to MEMORY
Read 63 bytes from map-output for attempt_local1778575427_0001_m_000000_0
closeInMemoryFile -> map-output of size: 63, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->63
map attempt_local1778575427_0001_m_000000_0 done 1 / 1 copied.
EventFetcher is interrupted.. Returning
1 / 1 copied.
finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
Merging 1 sorted segments
Down to the last merge-pass, with 1 segments left of total size: 57 bytes
Merged 1 segments, 63 bytes to disk to satisfy reduce memory limit
Disk file: /tmp/hadoop-michaeljones/mapred/local/localRunner/michaeljones/jobcache/job_local1778575427_0001/attempt_local1778575427_0001_r_000000_0/output/map_0.out.merged Length is 67
Merging 1 files, 67 bytes from disk
Merging 0 segments, 0 bytes from memory into reduce
Merging 1 sorted segments
Down to the last merge-pass, with 1 segments left of total size: 57 bytes
1 / 1 copied.
/user/michaeljones/wcOutputMain/_temporary/0/_temporary/attempt_local1778575427_0001_r_000000_0/part-r-00000: masked=rw-r--r--
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones sending #14
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones got value #14
Call: create took 7ms
computePacketChunkSize: src=/user/michaeljones/wcOutputMain/_temporary/0/_temporary/attempt_local1778575427_0001_r_000000_0/part-r-00000, chunkSize=516, chunksPerPacket=126, packetSize=65016
mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
DFSClient writeChunk allocating new packet seqno=0, src=/user/michaeljones/wcOutputMain/_temporary/0/_temporary/attempt_local1778575427_0001_r_000000_0/part-r-00000, packetSize=65016, chunksPerPacket=126, bytesCurBlock=0
Queued packet 0
Allocating new block
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones sending #15
Queued packet 1
Waiting for ack for: 1
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones got value #15
Call: addBlock took 6ms
pipeline = DatanodeInfoWithStorage[127.0.0.1:50010,DS-b42c5705-9ba4-4b14-b00b-f9194bb036f0,DISK]
Connecting to datanode 127.0.0.1:50010
Send buf size 131072
SASL client skipping handshake in unsecured configuration for addr = /127.0.0.1, datanodeId = DatanodeInfoWithStorage[127.0.0.1:50010,DS-b42c5705-9ba4-4b14-b00b-f9194bb036f0,DISK]
DataStreamer block BP-1045030256-10.0.0.2-1433119149314:blk_1073742216_1393 sending packet packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 41
DFSClient seqno: 0 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
DataStreamer block BP-1045030256-10.0.0.2-1433119149314:blk_1073742216_1393 sending packet packet seqno: 1 offsetInBlock: 41 lastPacketInBlock: true lastByteOffsetInBlock: 41
DFSClient seqno: 1 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones sending #16
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones got value #16
Call: complete took 4ms
Task:attempt_local1778575427_0001_r_000000_0 is done. And is in the process of committing
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones sending #17
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones got value #17
Call: getFileInfo took 2ms
1 / 1 copied.
Task attempt_local1778575427_0001_r_000000_0 is allowed to commit now
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones sending #18
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones got value #18
Call: getFileInfo took 3ms
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones sending #19
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones got value #19
Call: getFileInfo took 2ms
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones sending #20
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones got value #20
Call: rename took 25ms
Saved output of task 'attempt_local1778575427_0001_r_000000_0' to hdfs://localhost:9000/user/michaeljones/wcOutputMain/_temporary/0/task_local1778575427_0001_r_000000
reduce > reduce
Task 'attempt_local1778575427_0001_r_000000_0' done.
Finishing task: attempt_local1778575427_0001_r_000000_0
reduce task executor complete.
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones sending #21
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones got value #21
Call: getListing took 3ms
Merging data from FileStatus{path=hdfs://localhost:9000/user/michaeljones/wcOutputMain/_temporary/0/task_local1778575427_0001_r_000000; isDirectory=true; modification_time=1434151725316; access_time=0; owner=michaeljones; group=supergroup; permission=rwxr-xr-x; isSymlink=false} to hdfs://localhost:9000/user/michaeljones/wcOutputMain
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones sending #22
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones got value #22
Call: getFileInfo took 2ms
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones sending #23
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones got value #23
Call: getListing took 3ms
Merging data from FileStatus{path=hdfs://localhost:9000/user/michaeljones/wcOutputMain/_temporary/0/task_local1778575427_0001_r_000000/part-r-00000; isDirectory=false; length=41; replication=1; blocksize=134217728; modification_time=1434151725344; access_time=1434151725316; owner=michaeljones; group=supergroup; permission=rw-r--r--; isSymlink=false} to hdfs://localhost:9000/user/michaeljones/wcOutputMain/part-r-00000
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones sending #24
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones got value #24
Call: getFileInfo took 2ms
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones sending #25
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones got value #25
Call: rename took 4ms
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones sending #26
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones got value #26
Call: delete took 3ms
/user/michaeljones/wcOutputMain/_SUCCESS: masked=rw-r--r--
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones sending #27
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones got value #27
Call: create took 3ms
computePacketChunkSize: src=/user/michaeljones/wcOutputMain/_SUCCESS, chunkSize=516, chunksPerPacket=126, packetSize=65016
Waiting for ack for: -1
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones sending #28
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones got value #28
Call: complete took 2ms
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.fs.FileContext.getAbstractFileSystem(FileContext.java:331)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
Job job_local1778575427_0001 running in uber mode : false
 map 100% reduce 100%
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.getTaskCompletionEvents(Job.java:670)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.getTaskCompletionEvents(Job.java:670)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
Job job_local1778575427_0001 completed successfully
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.getCounters(Job.java:758)
Counters: 35
	File System Counters
		FILE: Number of bytes read=520
		FILE: Number of bytes written=565643
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=140
		HDFS: Number of bytes written=81
		HDFS: Number of read operations=19
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=10
	Map-Reduce Framework
		Map input records=2
		Map output records=8
		Map output bytes=82
		Map output materialized bytes=67
		Input split bytes=112
		Combine input records=8
		Combine output records=5
		Reduce input groups=5
		Reduce shuffle bytes=67
		Reduce input records=5
		Reduce output records=5
		Spilled Records=10
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=500170752
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=50
	File Output Format Counters 
		Bytes Written=41
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
RunJobAsync
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones sending #29
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones got value #29
Call: getFileInfo took 2ms
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones sending #30
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones got value #30
Call: delete took 5ms
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.connect(Job.java:1256)
Trying ClientProtocolProvider : org.apache.hadoop.mapred.LocalClientProtocolProvider
Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
Picked org.apache.hadoop.mapred.LocalClientProtocolProvider as the ClientProtocolProvider
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Cluster.getFileSystem(Cluster.java:162)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.submit(Job.java:1287)
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones sending #31
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones got value #31
Call: getFileInfo took 2ms
Configuring job job_local530807718_0002 with file:/tmp/hadoop-michaeljones/mapred/staging/michaeljones530807718/.staging/job_local530807718_0002 as the submit dir
adding the following namenodes' delegation tokens:[hdfs://localhost:9000]
Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
default FileSystem: file:///
No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
Creating splits at file:/tmp/hadoop-michaeljones/mapred/staging/michaeljones530807718/.staging/job_local530807718_0002
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones sending #32
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones got value #32
Call: getFileInfo took 2ms
Time taken to get FileStatuses: 3
Total input paths to process : 1
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones sending #33
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones got value #33
Call: getBlockLocations took 3ms
Total # of splits generated by getSplits: 1, TimeTaken: 8
number of splits:1
Handling deprecation for all properties in config...
Handling deprecation for mapreduce.jobtracker.address
Handling deprecation for yarn.resourcemanager.scheduler.monitor.policies
Handling deprecation for dfs.namenode.resource.check.interval
Handling deprecation for mapreduce.jobhistory.client.thread-count
Handling deprecation for yarn.app.mapreduce.am.containerlauncher.threadpool-initial-size
Handling deprecation for mapred.child.java.opts
Handling deprecation for mapreduce.jobtracker.retiredjobs.cache.size
Handling deprecation for dfs.client.https.need-auth
Handling deprecation for yarn.admin.acl
Handling deprecation for yarn.app.mapreduce.am.job.committer.cancel-timeout
Handling deprecation for mapreduce.job.emit-timeline-data
Handling deprecation for fs.ftp.host.port
Handling deprecation for dfs.namenode.avoid.read.stale.datanode
Handling deprecation for dfs.journalnode.rpc-address
Handling deprecation for mapreduce.job.end-notification.retry.attempts
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.ttl-interval-ms
Handling deprecation for yarn.resourcemanager.leveldb-state-store.path
Handling deprecation for mapred.mapper.new-api
Handling deprecation for yarn.ipc.rpc.class
Handling deprecation for ipc.client.connection.maxidletime
Handling deprecation for yarn.nodemanager.process-kill-wait.ms
Handling deprecation for mapreduce.cluster.acls.enabled
Handling deprecation for mapreduce.jobtracker.handler.count
Handling deprecation for io.map.index.interval
Handling deprecation for dfs.namenode.https-address
Handling deprecation for mapreduce.task.profile.reduces
Handling deprecation for fs.s3n.multipart.uploads.enabled
Handling deprecation for io.seqfile.sorter.recordlimit
Handling deprecation for mapreduce.job.ubertask.maxmaps
Handling deprecation for mapreduce.tasktracker.tasks.sleeptimebeforesigkill
Handling deprecation for hadoop.util.hash.type
Handling deprecation for dfs.namenode.replication.min
Handling deprecation for yarn.nodemanager.container-manager.thread-count
Handling deprecation for mapreduce.jobtracker.jobhistory.block.size
Handling deprecation for dfs.namenode.fs-limits.min-block-size
Handling deprecation for mapreduce.app-submission.cross-platform
Handling deprecation for fs.AbstractFileSystem.file.impl
Handling deprecation for net.topology.script.number.args
Handling deprecation for yarn.resourcemanager.container-tokens.master-key-rolling-interval-secs
Handling deprecation for mapreduce.map.output.compress.codec
Handling deprecation for mapreduce.job.reducer.preempt.delay.sec
Handling deprecation for s3native.bytes-per-checksum
Handling deprecation for dfs.namenode.path.based.cache.block.map.allocation.percent
Handling deprecation for yarn.nodemanager.windows-container.memory-limit.enabled
Handling deprecation for mapreduce.input.fileinputformat.split.minsize
Handling deprecation for hadoop.security.group.mapping
Handling deprecation for mapreduce.jobtracker.system.dir
Handling deprecation for mapreduce.job.end-notification.max.attempts
Handling deprecation for mapreduce.reduce.markreset.buffer.percent
Handling deprecation for dfs.datanode.cache.revocation.polling.ms
Handling deprecation for mapreduce.reduce.speculative
Handling deprecation for yarn.nodemanager.localizer.cache.cleanup.interval-ms
Handling deprecation for dfs.namenode.lazypersist.file.scrub.interval.sec
Handling deprecation for fs.s3a.threads.core
Handling deprecation for mapreduce.jobhistory.recovery.store.fs.uri
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.start-time-read-cache-size
Handling deprecation for hadoop.registry.zk.retry.interval.ms
Handling deprecation for yarn.nodemanager.keytab
Handling deprecation for dfs.namenode.replication.interval
Handling deprecation for yarn.resourcemanager.admin.address
Handling deprecation for mapreduce.job.maps
Handling deprecation for nfs.dump.dir
Handling deprecation for mapreduce.job.user.name
Handling deprecation for mapreduce.jobtracker.maxtasks.perjob
Handling deprecation for mapreduce.job.ubertask.enable
Handling deprecation for mapreduce.job.reduce.class
Handling deprecation for yarn.nodemanager.delete.debug-delay-sec
Handling deprecation for yarn.timeline-service.ttl-enable
Handling deprecation for yarn.resourcemanager.fs.state-store.retry-policy-spec
Handling deprecation for mapreduce.reduce.skip.maxgroups
Handling deprecation for dfs.client.use.datanode.hostname
Handling deprecation for fs.trash.interval
Handling deprecation for mapreduce.job.name
Handling deprecation for mapreduce.am.max-attempts
Handling deprecation for mapreduce.jobtracker.heartbeats.in.second
Handling deprecation for yarn.resourcemanager.zk-num-retries
Handling deprecation for s3.blocksize
Handling deprecation for dfs.datanode.data.dir
Handling deprecation for mapreduce.jobtracker.persist.jobstatus.active
Handling deprecation for mapreduce.reduce.shuffle.parallelcopies
Handling deprecation for fs.s3.buffer.dir
Handling deprecation for mapreduce.jobhistory.done-dir
Handling deprecation for hadoop.security.instrumentation.requires.admin
Handling deprecation for hadoop.registry.zk.retry.ceiling.ms
Handling deprecation for nfs.rtmax
Handling deprecation for dfs.datanode.data.dir.perm
Handling deprecation for yarn.resourcemanager.container.liveness-monitor.interval-ms
Handling deprecation for yarn.nodemanager.env-whitelist
Handling deprecation for dfs.namenode.backup.address
Handling deprecation for dfs.namenode.xattrs.enabled
Handling deprecation for dfs.datanode.readahead.bytes
Handling deprecation for mapreduce.jobhistory.cleaner.enable
Handling deprecation for dfs.client.block.write.retries
Handling deprecation for mapreduce.tasktracker.http.address
Handling deprecation for yarn.nodemanager.linux-container-executor.cgroups.hierarchy
Handling deprecation for ha.failover-controller.graceful-fence.connection.retries
Handling deprecation for yarn.resourcemanager.recovery.enabled
Handling deprecation for yarn.app.mapreduce.am.container.log.backups
Handling deprecation for dfs.namenode.safemode.threshold-pct
Handling deprecation for yarn.nodemanager.disk-health-checker.interval-ms
Handling deprecation for hadoop.security.java.secure.random.algorithm
Handling deprecation for dfs.namenode.list.cache.directives.num.responses
Handling deprecation for dfs.datanode.dns.nameserver
Handling deprecation for mapreduce.cluster.temp.dir
Handling deprecation for fs.s3a.max.total.tasks
Handling deprecation for mapreduce.reduce.maxattempts
Handling deprecation for mapreduce.client.submit.file.replication
Handling deprecation for mapreduce.shuffle.port
Handling deprecation for yarn.resourcemanager.resource-tracker.client.thread-count
Handling deprecation for dfs.namenode.replication.considerLoad
Handling deprecation for dfs.namenode.edits.journal-plugin.qjournal
Handling deprecation for dfs.client.write.exclude.nodes.cache.expiry.interval.millis
Handling deprecation for yarn.nodemanager.delete.thread-count
Handling deprecation for dfs.client.mmap.cache.timeout.ms
Handling deprecation for yarn.nodemanager.admin-env
Handling deprecation for io.skip.checksum.errors
Handling deprecation for yarn.timeline-service.hostname
Handling deprecation for yarn.resourcemanager.proxy-user-privileges.enabled
Handling deprecation for mapreduce.job.speculative.speculative-cap-total-tasks
Handling deprecation for yarn.acl.enable
Handling deprecation for fs.s3a.fast.upload
Handling deprecation for file.blocksize
Handling deprecation for mapreduce.job.speculative.slowtaskthreshold
Handling deprecation for ftp.replication
Handling deprecation for yarn.sharedcache.cleaner.initial-delay-mins
Handling deprecation for s3native.client-write-packet-size
Handling deprecation for hadoop.rpc.socket.factory.class.default
Handling deprecation for file.bytes-per-checksum
Handling deprecation for dfs.datanode.slow.io.warning.threshold.ms
Handling deprecation for io.seqfile.lazydecompress
Handling deprecation for mapreduce.task.skip.start.attempts
Handling deprecation for dfs.namenode.reject-unresolved-dn-topology-mapping
Handling deprecation for hadoop.common.configuration.version
Handling deprecation for yarn.resourcemanager.client.thread-count
Handling deprecation for dfs.datanode.drop.cache.behind.reads
Handling deprecation for yarn.sharedcache.admin.address
Handling deprecation for mapreduce.job.output.value.class
Handling deprecation for mapreduce.output.fileoutputformat.outputdir
Handling deprecation for mapreduce.jobtracker.taskcache.levels
Handling deprecation for yarn.nodemanager.linux-container-executor.nonsecure-mode.user-pattern
Handling deprecation for yarn.resourcemanager.zk-timeout-ms
Handling deprecation for yarn.resourcemanager.max-completed-applications
Handling deprecation for mapreduce.job.jvm.numtasks
Handling deprecation for yarn.sharedcache.cleaner.period-mins
Handling deprecation for mapreduce.jobtracker.tasktracker.maxblacklists
Handling deprecation for dfs.namenode.top.num.users
Handling deprecation for yarn.nodemanager.linux-container-executor.cgroups.mount
Handling deprecation for yarn.sharedcache.checksum.algo.impl
Handling deprecation for mapreduce.job.end-notification.max.retry.interval
Handling deprecation for mapreduce.job.acl-view-job
Handling deprecation for mapreduce.job.classloader
Handling deprecation for yarn.log-aggregation-enable
Handling deprecation for mapreduce.reduce.shuffle.fetch.retry.interval-ms
Handling deprecation for yarn.resourcemanager.nodemanager.minimum.version
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.size
Handling deprecation for yarn.app.mapreduce.am.job.task.listener.thread-count
Handling deprecation for yarn.app.mapreduce.am.resource.cpu-vcores
Handling deprecation for dfs.namenode.edit.log.autoroll.check.interval.ms
Handling deprecation for mapreduce.output.fileoutputformat.compress.type
Handling deprecation for hadoop.hdfs.configuration.version
Handling deprecation for hadoop.security.group.mapping.ldap.search.attr.member
Handling deprecation for yarn.nodemanager.log.retain-seconds
Handling deprecation for yarn.nodemanager.local-cache.max-files-per-directory
Handling deprecation for mapreduce.job.end-notification.retry.interval
Handling deprecation for hadoop.ssl.client.conf
Handling deprecation for yarn.sharedcache.root-dir
Handling deprecation for dfs.journalnode.https-address
Handling deprecation for mapreduce.reduce.shuffle.fetch.retry.timeout-ms
Handling deprecation for dfs.bytes-per-checksum
Handling deprecation for dfs.namenode.max.objects
Handling deprecation for mapreduce.tasktracker.instrumentation
Handling deprecation for dfs.datanode.max.transfer.threads
Handling deprecation for dfs.block.access.key.update.interval
Handling deprecation for mapreduce.jobtracker.jobhistory.task.numberprogresssplits
Handling deprecation for mapreduce.map.memory.mb
Handling deprecation for ha.failover-controller.new-active.rpc-timeout.ms
Handling deprecation for hadoop.ssl.hostname.verifier
Handling deprecation for dfs.client.read.shortcircuit
Handling deprecation for dfs.datanode.hdfs-blocks-metadata.enabled
Handling deprecation for mapreduce.tasktracker.healthchecker.interval
Handling deprecation for dfs.image.transfer.chunksize
Handling deprecation for mapreduce.tasktracker.taskmemorymanager.monitoringinterval
Handling deprecation for dfs.client.https.keystore.resource
Handling deprecation for yarn.resourcemanager.connect.retry-interval.ms
Handling deprecation for yarn.timeline-service.webapp.address
Handling deprecation for s3native.blocksize
Handling deprecation for yarn.scheduler.minimum-allocation-mb
Handling deprecation for yarn.sharedcache.cleaner.resource-sleep-ms
Handling deprecation for net.topology.impl
Handling deprecation for dfs.client.failover.sleep.base.millis
Handling deprecation for dfs.permissions.superusergroup
Handling deprecation for io.seqfile.compress.blocksize
Handling deprecation for hadoop.registry.zk.retry.times
Handling deprecation for fs.AbstractFileSystem.ftp.impl
Handling deprecation for dfs.namenode.checkpoint.edits.dir
Handling deprecation for mapreduce.job.running.reduce.limit
Handling deprecation for dfs.blockreport.initialDelay
Handling deprecation for dfs.namenode.heartbeat.recheck-interval
Handling deprecation for dfs.namenode.safemode.extension
Handling deprecation for yarn.scheduler.maximum-allocation-mb
Handling deprecation for mapreduce.job.reduce.shuffle.consumer.plugin.class
Handling deprecation for yarn.nodemanager.vmem-check-enabled
Handling deprecation for mapreduce.task.io.sort.factor
Handling deprecation for mapreduce.jobtracker.persist.jobstatus.dir
Handling deprecation for dfs.client.failover.sleep.max.millis
Handling deprecation for dfs.namenode.delegation.key.update-interval
Handling deprecation for hadoop.rpc.protection
Handling deprecation for fs.permissions.umask-mode
Handling deprecation for fs.s3.sleepTimeSeconds
Handling deprecation for ha.health-monitor.rpc-timeout.ms
Handling deprecation for hadoop.http.staticuser.user
Handling deprecation for fs.s3a.connection.maximum
Handling deprecation for yarn.nodemanager.linux-container-executor.nonsecure-mode.limit-users
Handling deprecation for fs.s3a.paging.maximum
Handling deprecation for fs.AbstractFileSystem.viewfs.impl
Handling deprecation for fs.ftp.host
Handling deprecation for yarn.nodemanager.linux-container-executor.nonsecure-mode.local-user
Handling deprecation for fs.s3a.impl
Handling deprecation for hadoop.http.authentication.kerberos.keytab
Handling deprecation for dfs.namenode.fs-limits.max-blocks-per-file
Handling deprecation for mapreduce.tasktracker.http.threads
Handling deprecation for mapreduce.tasktracker.dns.nameserver
Handling deprecation for yarn.resourcemanager.am-rm-tokens.master-key-rolling-interval-secs
Handling deprecation for dfs.client.block.write.replace-datanode-on-failure.enable
Handling deprecation for io.compression.codec.bzip2.library
Handling deprecation for mapreduce.map.skip.maxrecords
Handling deprecation for dfs.client.use.legacy.blockreader.local
Handling deprecation for dfs.namenode.checkpoint.dir
Handling deprecation for dfs.namenode.top.windows.minutes
Handling deprecation for mapreduce.job.maxtaskfailures.per.tracker
Handling deprecation for net.topology.node.switch.mapping.impl
Handling deprecation for mapreduce.shuffle.max.connections
Handling deprecation for mapreduce.jobhistory.loadedjobs.cache.size
Handling deprecation for dfs.storage.policy.enabled
Handling deprecation for yarn.client.application-client-protocol.poll-interval-ms
Handling deprecation for yarn.nodemanager.localizer.address
Handling deprecation for dfs.namenode.list.cache.pools.num.responses
Handling deprecation for nfs.server.port
Handling deprecation for mapreduce.client.output.filter
Handling deprecation for yarn.timeline-service.client.best-effort
Handling deprecation for ha.zookeeper.parent-znode
Handling deprecation for mapreduce.jobtracker.persist.jobstatus.hours
Handling deprecation for yarn.sharedcache.admin.thread-count
Handling deprecation for yarn.nodemanager.resource.cpu-vcores
Handling deprecation for dfs.datanode.block-pinning.enabled
Handling deprecation for mapreduce.jobhistory.http.policy
Handling deprecation for yarn.resourcemanager.webapp.delegation-token-auth-filter.enabled
Handling deprecation for mapreduce.job.speculative.retry-after-no-speculate
Handling deprecation for fs.s3a.attempts.maximum
Handling deprecation for s3native.stream-buffer-size
Handling deprecation for io.seqfile.local.dir
Handling deprecation for yarn.log-aggregation.retain-check-interval-seconds
Handling deprecation for fs.s3n.multipart.copy.block.size
Handling deprecation for dfs.encrypt.data.transfer.cipher.key.bitlength
Handling deprecation for dfs.datanode.sync.behind.writes
Handling deprecation for yarn.resourcemanager.zk-acl
Handling deprecation for hadoop.ssl.keystores.factory.class
Handling deprecation for mapreduce.job.split.metainfo.maxsize
Handling deprecation for fs.s3.maxRetries
Handling deprecation for hadoop.security.random.device.file.path
Handling deprecation for yarn.client.nodemanager-connect.max-wait-ms
Handling deprecation for dfs.namenode.stale.datanode.interval
Handling deprecation for mapreduce.task.io.sort.mb
Handling deprecation for yarn.resourcemanager.zk-state-store.parent-path
Handling deprecation for yarn.app.mapreduce.client-am.ipc.max-retries
Handling deprecation for fs.client.resolve.remote.symlinks
Handling deprecation for yarn.nodemanager.linux-container-executor.cgroups.strict-resource-usage
Handling deprecation for hadoop.ssl.enabled.protocols
Handling deprecation for mapreduce.reduce.cpu.vcores
Handling deprecation for yarn.client.failover-retries
Handling deprecation for mapreduce.jobhistory.address
Handling deprecation for hadoop.ssl.enabled
Handling deprecation for dfs.replication.max
Handling deprecation for dfs.namenode.name.dir
Handling deprecation for dfs.datanode.https.address
Handling deprecation for ipc.client.kill.max
Handling deprecation for mapreduce.job.committer.setup.cleanup.needed
Handling deprecation for dfs.client.domain.socket.data.traffic
Handling deprecation for yarn.nodemanager.localizer.cache.target-size-mb
Handling deprecation for yarn.resourcemanager.admin.client.thread-count
Handling deprecation for dfs.block.access.token.enable
Handling deprecation for mapreduce.job.speculative.retry-after-speculate
Handling deprecation for dfs.datanode.address
Handling deprecation for mapreduce.jobtracker.restart.recover
Handling deprecation for ipc.client.connect.max.retries
Handling deprecation for yarn.timeline-service.store-class
Handling deprecation for dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
Handling deprecation for hadoop.tmp.dir
Handling deprecation for dfs.datanode.handler.count
Handling deprecation for yarn.resourcemanager.ha.automatic-failover.embedded
Handling deprecation for yarn.timeline-service.ttl-ms
Handling deprecation for mapreduce.task.profile.map.params
Handling deprecation for yarn.resourcemanager.nodemanagers.heartbeat-interval-ms
Handling deprecation for mapreduce.map.speculative
Handling deprecation for yarn.timeline-service.recovery.enabled
Handling deprecation for mapreduce.job.map.class
Handling deprecation for dfs.namenode.resource.checked.volumes.minimum
Handling deprecation for yarn.nodemanager.recovery.dir
Handling deprecation for mapreduce.job.counters.max
Handling deprecation for yarn.resourcemanager.keytab
Handling deprecation for dfs.namenode.max.extra.edits.segments.retained
Handling deprecation for dfs.webhdfs.user.provider.user.pattern
Handling deprecation for dfs.client.mmap.enabled
Handling deprecation for mapreduce.map.log.level
Handling deprecation for dfs.client.file-block-storage-locations.timeout.millis
Handling deprecation for yarn.client.max-cached-nodemanagers-proxies
Handling deprecation for yarn.app.mapreduce.am.scheduler.heartbeat.interval-ms
Handling deprecation for hadoop.fuse.timer.period
Handling deprecation for fs.trash.checkpoint.interval
Handling deprecation for yarn.sharedcache.app-checker.class
Handling deprecation for dfs.journalnode.http-address
Handling deprecation for yarn.app.mapreduce.am.staging-dir
Handling deprecation for mapreduce.tasktracker.local.dir.minspacestart
Handling deprecation for yarn.nm.liveness-monitor.expiry-interval-ms
Handling deprecation for ha.health-monitor.check-interval.ms
Handling deprecation for mapreduce.reduce.shuffle.merge.percent
Handling deprecation for dfs.namenode.retrycache.heap.percent
Handling deprecation for yarn.nodemanager.docker-container-executor.exec-name
Handling deprecation for ipc.client.connect.timeout
Handling deprecation for yarn.resourcemanager.fs.state-store.retry-interval-ms
Handling deprecation for mapreduce.output.fileoutputformat.compress
Handling deprecation for yarn.nodemanager.local-dirs
Handling deprecation for yarn.nodemanager.recovery.enabled
Handling deprecation for io.native.lib.available
Handling deprecation for yarn.sharedcache.store.in-memory.staleness-period-mins
Handling deprecation for yarn.resourcemanager.am.max-attempts
Handling deprecation for s3.replication
Handling deprecation for mapreduce.input.fileinputformat.inputdir
Handling deprecation for fs.AbstractFileSystem.har.impl
Handling deprecation for dfs.image.compress
Handling deprecation for mapreduce.job.running.map.limit
Handling deprecation for mapreduce.reduce.input.buffer.percent
Handling deprecation for yarn.nodemanager.webapp.address
Handling deprecation for dfs.datanode.available-space-volume-choosing-policy.balanced-space-preference-fraction
Handling deprecation for dfs.namenode.edit.log.autoroll.multiplier.threshold
Handling deprecation for hadoop.security.group.mapping.ldap.ssl
Handling deprecation for dfs.namenode.checkpoint.check.period
Handling deprecation for fs.defaultFS
Handling deprecation for fs.s3a.multipart.size
Handling deprecation for dfs.client.slow.io.warning.threshold.ms
Handling deprecation for yarn.app.mapreduce.am.job.committer.commit-window
Handling deprecation for hadoop.security.group.mapping.ldap.search.attr.group.name
Handling deprecation for yarn.nodemanager.disk-health-checker.max-disk-utilization-per-disk-percentage
Handling deprecation for yarn.nodemanager.container-monitor.procfs-tree.smaps-based-rss.enabled
Handling deprecation for mapreduce.job.submithostname
Handling deprecation for mapreduce.map.sort.spill.percent
Handling deprecation for hadoop.security.crypto.codec.classes.aes.ctr.nopadding
Handling deprecation for dfs.namenode.http-address
Handling deprecation for hadoop.security.groups.negative-cache.secs
Handling deprecation for hadoop.ssl.server.conf
Handling deprecation for mapreduce.ifile.readahead
Handling deprecation for s3native.replication
Handling deprecation for yarn.client.nodemanager-client-async.thread-pool-max-size
Handling deprecation for mapreduce.jobtracker.staging.root.dir
Handling deprecation for mapreduce.jobhistory.admin.address
Handling deprecation for dfs.namenode.startup.delay.block.deletion.sec
Handling deprecation for yarn.nodemanager.health-checker.interval-ms
Handling deprecation for dfs.namenode.checkpoint.max-retries
Handling deprecation for s3.stream-buffer-size
Handling deprecation for ftp.client-write-packet-size
Handling deprecation for dfs.datanode.fsdatasetcache.max.threads.per.volume
Handling deprecation for mapreduce.output.fileoutputformat.compress.codec
Handling deprecation for yarn.timeline-service.keytab
Handling deprecation for yarn.sharedcache.store.in-memory.initial-delay-mins
Handling deprecation for mapreduce.jobhistory.webapp.address
Handling deprecation for mapreduce.task.userlog.limit.kb
Handling deprecation for mapreduce.reduce.shuffle.fetch.retry.enabled
Handling deprecation for yarn.app.mapreduce.task.container.log.backups
Handling deprecation for dfs.heartbeat.interval
Handling deprecation for ha.zookeeper.session-timeout.ms
Handling deprecation for fs.s3a.connection.ssl.enabled
Handling deprecation for yarn.sharedcache.webapp.address
Handling deprecation for hadoop.http.authentication.signature.secret.file
Handling deprecation for hadoop.fuse.connection.timeout
Handling deprecation for mapreduce.input.fileinputformat.numinputfiles
Handling deprecation for yarn.nodemanager.log-aggregation.compression-type
Handling deprecation for ipc.server.max.connections
Handling deprecation for yarn.resourcemanager.work-preserving-recovery.scheduling-wait-ms
Handling deprecation for yarn.nodemanager.log-dirs
Handling deprecation for yarn.app.mapreduce.am.resource.mb
Handling deprecation for hadoop.security.groups.cache.secs
Handling deprecation for mapreduce.job.speculative.minimum-allowed-tasks
Handling deprecation for yarn.nodemanager.container-monitor.interval-ms
Handling deprecation for dfs.datanode.cache.revocation.timeout.ms
Handling deprecation for mapreduce.jobhistory.recovery.store.class
Handling deprecation for mapreduce.task.combine.progress.records
Handling deprecation for s3.client-write-packet-size
Handling deprecation for mapreduce.jobtracker.instrumentation
Handling deprecation for dfs.replication
Handling deprecation for mapreduce.shuffle.transfer.buffer.size
Handling deprecation for hadoop.security.group.mapping.ldap.directory.search.timeout
Handling deprecation for dfs.datanode.available-space-volume-choosing-policy.balanced-space-threshold
Handling deprecation for hadoop.work.around.non.threadsafe.getpwuid
Handling deprecation for yarn.app.mapreduce.client-am.ipc.max-retries-on-timeouts
Handling deprecation for yarn.nodemanager.address
Handling deprecation for mapreduce.tasktracker.taskcontroller
Handling deprecation for mapreduce.tasktracker.indexcache.mb
Handling deprecation for yarn.scheduler.maximum-allocation-vcores
Handling deprecation for mapreduce.job.reduces
Handling deprecation for yarn.nodemanager.sleep-delay-before-sigkill.ms
Handling deprecation for yarn.timeline-service.address
Handling deprecation for yarn.resourcemanager.configuration.provider-class
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.expiry
Handling deprecation for yarn.sharedcache.enabled
Handling deprecation for tfile.io.chunk.size
Handling deprecation for mapreduce.job.acl-modify-job
Handling deprecation for hadoop.registry.zk.session.timeout.ms
Handling deprecation for fs.automatic.close
Handling deprecation for ha.health-monitor.sleep-after-disconnect.ms
Handling deprecation for mapreduce.tasktracker.reduce.tasks.maximum
Handling deprecation for mapreduce.input.fileinputformat.list-status.num-threads
Handling deprecation for dfs.datanode.directoryscan.threads
Handling deprecation for dfs.datanode.directoryscan.interval
Handling deprecation for dfs.namenode.acls.enabled
Handling deprecation for dfs.client.short.circuit.replica.stale.threshold.ms
Handling deprecation for hadoop.http.authentication.token.validity
Handling deprecation for fs.s3.block.size
Handling deprecation for ha.failover-controller.graceful-fence.rpc-timeout.ms
Handling deprecation for mapreduce.tasktracker.local.dir.minspacekill
Handling deprecation for dfs.namenode.resource.du.reserved
Handling deprecation for mapreduce.jobhistory.cleaner.interval-ms
Handling deprecation for dfs.namenode.datanode.registration.ip-hostname-check
Handling deprecation for mapreduce.jobhistory.intermediate-done-dir
Handling deprecation for mapreduce.jobtracker.http.address
Handling deprecation for dfs.namenode.backup.http-address
Handling deprecation for dfs.namenode.edits.noeditlogchannelflush
Handling deprecation for mapreduce.reduce.shuffle.input.buffer.percent
Handling deprecation for mapreduce.map.maxattempts
Handling deprecation for yarn.http.policy
Handling deprecation for dfs.namenode.audit.loggers
Handling deprecation for hadoop.security.groups.cache.warn.after.ms
Handling deprecation for io.serializations
Handling deprecation for mapreduce.tasktracker.outofband.heartbeat
Handling deprecation for mapreduce.reduce.shuffle.read.timeout
Handling deprecation for hadoop.security.crypto.buffer.size
Handling deprecation for mapreduce.reduce.skip.proc.count.autoincr
Handling deprecation for mapreduce.ifile.readahead.bytes
Handling deprecation for dfs.http.policy
Handling deprecation for hadoop.registry.secure
Handling deprecation for dfs.namenode.safemode.min.datanodes
Handling deprecation for dfs.client.file-block-storage-locations.num-threads
Handling deprecation for mapreduce.cluster.local.dir
Handling deprecation for mapreduce.tasktracker.report.address
Handling deprecation for dfs.namenode.secondary.https-address
Handling deprecation for hadoop.kerberos.kinit.command
Handling deprecation for yarn.timeline-service.http-authentication.type
Handling deprecation for dfs.block.access.token.lifetime
Handling deprecation for dfs.webhdfs.enabled
Handling deprecation for dfs.namenode.delegation.token.max-lifetime
Handling deprecation for dfs.namenode.avoid.write.stale.datanode
Handling deprecation for dfs.datanode.drop.cache.behind.writes
Handling deprecation for yarn.log-aggregation.retain-seconds
Handling deprecation for mapreduce.job.complete.cancel.delegation.tokens
Handling deprecation for mapreduce.local.clientfactory.class.name
Handling deprecation for mapreduce.shuffle.connection-keep-alive.timeout
Handling deprecation for dfs.namenode.num.extra.edits.retained
Handling deprecation for yarn.scheduler.minimum-allocation-vcores
Handling deprecation for ipc.client.connect.max.retries.on.timeouts
Handling deprecation for yarn.timeline-service.client.retry-interval-ms
Handling deprecation for yarn.timeline-service.client.max-retries
Handling deprecation for fs.s3n.block.size
Handling deprecation for mapreduce.job.map.output.collector.class
Handling deprecation for ha.health-monitor.connect-retry-interval.ms
Handling deprecation for mapreduce.shuffle.max.threads
Handling deprecation for nfs.exports.allowed.hosts
Handling deprecation for dfs.client.mmap.cache.size
Handling deprecation for mapreduce.tasktracker.map.tasks.maximum
Handling deprecation for io.file.buffer.size
Handling deprecation for dfs.client.datanode-restart.timeout
Handling deprecation for io.mapfile.bloom.size
Handling deprecation for hadoop.security.kms.client.authentication.retry-count
Handling deprecation for dfs.namenode.checkpoint.txns
Handling deprecation for ipc.client.connect.retry.interval
Handling deprecation for dfs.client-write-packet-size
Handling deprecation for mapreduce.reduce.shuffle.connect.timeout
Handling deprecation for yarn.resourcemanager.fs.state-store.uri
Handling deprecation for fs.swift.impl
Handling deprecation for hadoop.registry.zk.connection.timeout.ms
Handling deprecation for mapred.queue.default.acl-administer-jobs
Handling deprecation for mapreduce.job.submithostaddress
Handling deprecation for dfs.cachereport.intervalMsec
Handling deprecation for yarn.app.mapreduce.shuffle.log.backups
Handling deprecation for yarn.app.mapreduce.am.container.log.limit.kb
Handling deprecation for yarn.nodemanager.resourcemanager.minimum.version
Handling deprecation for ftp.blocksize
Handling deprecation for yarn.resourcemanager.address
Handling deprecation for file.stream-buffer-size
Handling deprecation for yarn.resourcemanager.scheduler.monitor.enable
Handling deprecation for mapreduce.job.ubertask.maxreduces
Handling deprecation for nfs.allow.insecure.ports
Handling deprecation for yarn.sharedcache.nm.uploader.thread-count
Handling deprecation for ipc.client.idlethreshold
Handling deprecation for ftp.stream-buffer-size
Handling deprecation for yarn.sharedcache.client-server.address
Handling deprecation for dfs.client.failover.connection.retries.on.timeouts
Handling deprecation for dfs.namenode.replication.work.multiplier.per.iteration
Handling deprecation for hadoop.http.authentication.simple.anonymous.allowed
Handling deprecation for hadoop.security.authorization
Handling deprecation for yarn.client.nodemanager-connect.retry-interval-ms
Handling deprecation for yarn.am.liveness-monitor.expiry-interval-ms
Handling deprecation for fs.har.impl.disable.cache
Handling deprecation for yarn.nodemanager.linux-container-executor.resources-handler.class
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.read-cache-size
Handling deprecation for hadoop.security.authentication
Handling deprecation for dfs.image.compression.codec
Handling deprecation for mapreduce.task.files.preserve.failedtasks
Handling deprecation for dfs.client.read.shortcircuit.streams.cache.size
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.path
Handling deprecation for mapreduce.job.reduce.slowstart.completedmaps
Handling deprecation for mapreduce.jobhistory.minicluster.fixed.ports
Handling deprecation for file.replication
Handling deprecation for yarn.resourcemanager.ha.automatic-failover.enabled
Handling deprecation for mapreduce.job.userlog.retain.hours
Handling deprecation for mapreduce.jobhistory.joblist.cache.size
Handling deprecation for dfs.namenode.accesstime.precision
Handling deprecation for yarn.resourcemanager.work-preserving-recovery.enabled
Handling deprecation for dfs.namenode.fs-limits.max-xattrs-per-inode
Handling deprecation for io.mapfile.bloom.error.rate
Handling deprecation for yarn.resourcemanager.store.class
Handling deprecation for dfs.image.transfer.timeout
Handling deprecation for yarn.timeline-service.leveldb-state-store.path
Handling deprecation for nfs.wtmax
Handling deprecation for mapreduce.job.combine.class
Handling deprecation for dfs.namenode.support.allow.format
Handling deprecation for fs.s3a.multipart.purge
Handling deprecation for dfs.secondary.namenode.kerberos.internal.spnego.principal
Handling deprecation for fs.s3a.connection.establish.timeout
Handling deprecation for dfs.stream-buffer-size
Handling deprecation for dfs.namenode.invalidate.work.pct.per.iteration
Handling deprecation for yarn.nodemanager.container-executor.class
Handling deprecation for fs.s3a.multipart.purge.age
Handling deprecation for yarn.resourcemanager.scheduler.client.thread-count
Handling deprecation for dfs.namenode.top.enabled
Handling deprecation for yarn.app.mapreduce.shuffle.log.separate
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.low-watermark
Handling deprecation for fs.s3a.fast.buffer.size
Handling deprecation for hadoop.user.group.static.mapping.overrides
Handling deprecation for tfile.fs.input.buffer.size
Handling deprecation for dfs.client.cached.conn.retry
Handling deprecation for hadoop.http.authentication.type
Handling deprecation for dfs.namenode.list.encryption.zones.num.responses
Handling deprecation for mapreduce.map.cpu.vcores
Handling deprecation for dfs.namenode.path.based.cache.refresh.interval.ms
Handling deprecation for dfs.namenode.decommission.interval
Handling deprecation for dfs.namenode.fs-limits.max-directory-items
Handling deprecation for yarn.resourcemanager.zk-retry-interval-ms
Handling deprecation for ftp.bytes-per-checksum
Handling deprecation for dfs.ha.log-roll.period
Handling deprecation for dfs.user.home.dir.prefix
Handling deprecation for ipc.client.fallback-to-simple-auth-allowed
Handling deprecation for yarn.nodemanager.pmem-check-enabled
Handling deprecation for yarn.nodemanager.remote-app-log-dir
Handling deprecation for dfs.namenode.inotify.max.events.per.rpc
Handling deprecation for mapreduce.task.profile.maps
Handling deprecation for mapreduce.shuffle.ssl.file.buffer.size
Handling deprecation for mapreduce.tasktracker.healthchecker.script.timeout
Handling deprecation for yarn.timeline-service.webapp.https.address
Handling deprecation for yarn.nodemanager.resource.percentage-physical-cpu-limit
Handling deprecation for yarn.app.mapreduce.am.command-opts
Handling deprecation for dfs.namenode.fs-limits.max-xattr-size
Handling deprecation for dfs.datanode.http.address
Handling deprecation for dfs.namenode.blocks.per.postponedblocks.rescan
Handling deprecation for yarn.sharedcache.nm.uploader.replication.factor
Handling deprecation for hadoop.registry.zk.root
Handling deprecation for hadoop.jetty.logs.serve.aliases
Handling deprecation for yarn.client.failover-proxy-provider
Handling deprecation for mapreduce.jobhistory.admin.acl
Handling deprecation for yarn.app.mapreduce.am.hard-kill-timeout-ms
Handling deprecation for yarn.nodemanager.remote-app-log-dir-suffix
Handling deprecation for mapreduce.jobhistory.principal
Handling deprecation for yarn.resourcemanager.webapp.address
Handling deprecation for mapreduce.jobhistory.recovery.enable
Handling deprecation for yarn.sharedcache.store.in-memory.check-period-mins
Handling deprecation for nfs.mountd.port
Handling deprecation for mapreduce.reduce.merge.inmem.threshold
Handling deprecation for fs.df.interval
Handling deprecation for yarn.timeline-service.enabled
Handling deprecation for mapreduce.jobtracker.jobhistory.lru.cache.size
Handling deprecation for mapreduce.task.profile
Handling deprecation for mapreduce.job.output.key.class
Handling deprecation for yarn.nodemanager.hostname
Handling deprecation for dfs.namenode.num.checkpoints.retained
Handling deprecation for mapreduce.job.queuename
Handling deprecation for mapreduce.jobhistory.max-age-ms
Handling deprecation for mapreduce.job.token.tracking.ids.enabled
Handling deprecation for yarn.nodemanager.localizer.client.thread-count
Handling deprecation for yarn.sharedcache.uploader.server.thread-count
Handling deprecation for dfs.client.mmap.retry.timeout.ms
Handling deprecation for mapreduce.jobhistory.move.thread-count
Handling deprecation for dfs.permissions.enabled
Handling deprecation for dfs.blockreport.split.threshold
Handling deprecation for fs.AbstractFileSystem.hdfs.impl
Handling deprecation for dfs.datanode.balance.bandwidthPerSec
Handling deprecation for dfs.block.scanner.volume.bytes.per.second
Handling deprecation for hadoop.http.filter.initializers
Handling deprecation for yarn.timeline-service.http-authentication.simple.anonymous.allowed
Handling deprecation for dfs.default.chunk.view.size
Handling deprecation for yarn.sharedcache.client-server.thread-count
Handling deprecation for yarn.resourcemanager.resource-tracker.address
Handling deprecation for mapreduce.job.working.dir
Handling deprecation for mapreduce.jobhistory.datestring.cache.size
Handling deprecation for mapreduce.task.profile.params
Handling deprecation for dfs.namenode.decommission.blocks.per.interval
Handling deprecation for dfs.namenode.handler.count
Handling deprecation for dfs.image.transfer.bandwidthPerSec
Handling deprecation for rpc.metrics.quantile.enable
Handling deprecation for mapreduce.jobtracker.expire.trackers.interval
Handling deprecation for mapreduce.task.timeout
Handling deprecation for yarn.app.mapreduce.client.max-retries
Handling deprecation for yarn.nodemanager.resource.memory-mb
Handling deprecation for yarn.nodemanager.disk-health-checker.min-healthy-disks
Handling deprecation for dfs.datanode.failed.volumes.tolerated
Handling deprecation for yarn.timeline-service.handler-thread-count
Handling deprecation for ipc.server.listen.queue.size
Handling deprecation for fs.s3a.threads.max
Handling deprecation for yarn.resourcemanager.connect.max-wait.ms
Handling deprecation for mapreduce.fileoutputcommitter.algorithm.version
Handling deprecation for mapreduce.framework.name
Handling deprecation for mapreduce.map.skip.proc.count.autoincr
Handling deprecation for mapreduce.job.max.split.locations
Handling deprecation for yarn.resourcemanager.scheduler.class
Handling deprecation for yarn.resourcemanager.system-metrics-publisher.enabled
Handling deprecation for dfs.blocksize
Handling deprecation for yarn.sharedcache.nested-level
Handling deprecation for mapreduce.shuffle.connection-keep-alive.enable
Handling deprecation for fs.s3a.threads.keepalivetime
Handling deprecation for fs.s3a.connection.timeout
Handling deprecation for file.client-write-packet-size
Handling deprecation for ha.failover-controller.cli-check.rpc-timeout.ms
Handling deprecation for ha.zookeeper.acl
Handling deprecation for dfs.namenode.write.stale.datanode.ratio
Handling deprecation for dfs.encrypt.data.transfer
Handling deprecation for dfs.datanode.shared.file.descriptor.paths
Handling deprecation for mapreduce.input.lineinputformat.linespermap
Handling deprecation for yarn.resourcemanager.delayed.delegation-token.removal-interval-ms
Handling deprecation for yarn.nodemanager.localizer.fetch.thread-count
Handling deprecation for dfs.client.failover.max.attempts
Handling deprecation for yarn.resourcemanager.scheduler.address
Handling deprecation for dfs.client.read.shortcircuit.streams.cache.expiry.ms
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.start-time-write-cache-size
Handling deprecation for yarn.nodemanager.health-checker.script.timeout-ms
Handling deprecation for yarn.resourcemanager.fs.state-store.num-retries
Handling deprecation for hadoop.ssl.require.client.cert
Handling deprecation for hadoop.security.uid.cache.secs
Handling deprecation for mapreduce.jobhistory.keytab
Handling deprecation for dfs.client.read.shortcircuit.skip.checksum
Handling deprecation for yarn.resourcemanager.ha.automatic-failover.zk-base-path
Handling deprecation for mapreduce.shuffle.ssl.enabled
Handling deprecation for mapreduce.reduce.log.level
Handling deprecation for hadoop.registry.rm.enabled
Handling deprecation for mapreduce.tasktracker.dns.interface
Handling deprecation for yarn.resourcemanager.system-metrics-publisher.dispatcher.pool-size
Handling deprecation for mapreduce.job.speculative.speculative-cap-running-tasks
Handling deprecation for dfs.datanode.block.id.layout.upgrade.threads
Handling deprecation for dfs.datanode.use.datanode.hostname
Handling deprecation for dfs.client.context
Handling deprecation for yarn.resourcemanager.ha.enabled
Handling deprecation for mapred.reducer.new-api
Handling deprecation for dfs.namenode.delegation.token.renew-interval
Handling deprecation for dfs.blockreport.intervalMsec
Handling deprecation for fs.s3a.multipart.threshold
Handling deprecation for mapreduce.reduce.shuffle.memory.limit.percent
Handling deprecation for dfs.https.server.keystore.resource
Handling deprecation for io.map.index.skip
Handling deprecation for mapreduce.job.hdfs-servers
Handling deprecation for mapreduce.jobtracker.taskscheduler
Handling deprecation for dfs.namenode.kerberos.internal.spnego.principal
Handling deprecation for yarn.resourcemanager.state-store.max-completed-applications
Handling deprecation for mapreduce.map.output.compress
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.num.refill.threads
Handling deprecation for fs.s3n.multipart.uploads.block.size
Handling deprecation for mapreduce.task.merge.progress.records
Handling deprecation for dfs.datanode.dns.interface
Handling deprecation for map.sort.class
Handling deprecation for yarn.nodemanager.aux-services.mapreduce_shuffle.class
Handling deprecation for tfile.fs.output.buffer.size
Handling deprecation for fs.du.interval
Handling deprecation for dfs.client.failover.connection.retries
Handling deprecation for dfs.namenode.top.window.num.buckets
Handling deprecation for mapreduce.job.dir
Handling deprecation for fs.s3a.buffer.dir
Handling deprecation for mapreduce.reduce.shuffle.retry-delay.max.ms
Handling deprecation for yarn.sharedcache.uploader.server.address
Handling deprecation for mapreduce.client.progressmonitor.pollinterval
Handling deprecation for yarn.app.mapreduce.shuffle.log.limit.kb
Handling deprecation for dfs.datanode.max.locked.memory
Handling deprecation for dfs.namenode.retrycache.expirytime.millis
Handling deprecation for dfs.datanode.scan.period.hours
Handling deprecation for dfs.client.block.write.replace-datanode-on-failure.best-effort
Handling deprecation for mapreduce.jobhistory.move.interval-ms
Handling deprecation for dfs.ha.fencing.ssh.connect-timeout
Handling deprecation for yarn.nodemanager.log-aggregation.roll-monitoring-interval-seconds
Handling deprecation for dfs.namenode.fs-limits.max-component-length
Handling deprecation for hadoop.registry.zk.quorum
Handling deprecation for dfs.namenode.enable.retrycache
Handling deprecation for dfs.datanode.du.reserved
Handling deprecation for yarn.timeline-service.state-store-class
Handling deprecation for dfs.datanode.ipc.address
Handling deprecation for hadoop.registry.system.acls
Handling deprecation for dfs.client.block.write.replace-datanode-on-failure.policy
Handling deprecation for dfs.namenode.path.based.cache.retry.interval.ms
Handling deprecation for hadoop.security.crypto.cipher.suite
Handling deprecation for dfs.ha.tail-edits.period
Handling deprecation for mapreduce.task.profile.reduce.params
Handling deprecation for hadoop.registry.jaas.context
Handling deprecation for yarn.resourcemanager.hostname
Handling deprecation for mapreduce.reduce.memory.mb
Handling deprecation for hadoop.security.group.mapping.ldap.search.filter.group
Handling deprecation for hadoop.http.authentication.kerberos.principal
Handling deprecation for hadoop.security.group.mapping.ldap.search.filter.user
Handling deprecation for yarn.nodemanager.disk-health-checker.min-free-space-per-disk-mb
Handling deprecation for dfs.namenode.edits.dir
Handling deprecation for yarn.client.failover-retries-on-socket-timeouts
Handling deprecation for dfs.namenode.decommission.max.concurrent.tracked.nodes
Handling deprecation for mapreduce.client.completion.pollinterval
Handling deprecation for dfs.namenode.name.dir.restore
Handling deprecation for dfs.namenode.secondary.http-address
Handling deprecation for mapreduce.jobhistory.recovery.store.leveldb.path
Handling deprecation for yarn.sharedcache.store.class
Handling deprecation for s3.bytes-per-checksum
Handling deprecation for yarn.nodemanager.windows-container.cpu-limit.enabled
Handling deprecation for yarn.resourcemanager.webapp.https.address
Handling deprecation for yarn.nodemanager.vmem-pmem-ratio
Handling deprecation for dfs.namenode.checkpoint.period
Handling deprecation for dfs.ha.automatic-failover.enabled
Submitting tokens for job: job_local530807718_0002
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.fs.FileContext.getAbstractFileSystem(FileContext.java:331)
Handling deprecation for all properties in config...
Handling deprecation for mapreduce.jobtracker.address
Handling deprecation for yarn.resourcemanager.scheduler.monitor.policies
Handling deprecation for dfs.namenode.resource.check.interval
Handling deprecation for mapreduce.jobhistory.client.thread-count
Handling deprecation for yarn.app.mapreduce.am.containerlauncher.threadpool-initial-size
Handling deprecation for mapred.child.java.opts
Handling deprecation for mapreduce.jobtracker.retiredjobs.cache.size
Handling deprecation for dfs.client.https.need-auth
Handling deprecation for yarn.admin.acl
Handling deprecation for yarn.app.mapreduce.am.job.committer.cancel-timeout
Handling deprecation for mapreduce.job.emit-timeline-data
Handling deprecation for fs.ftp.host.port
Handling deprecation for dfs.namenode.avoid.read.stale.datanode
Handling deprecation for dfs.journalnode.rpc-address
Handling deprecation for mapreduce.job.end-notification.retry.attempts
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.ttl-interval-ms
Handling deprecation for yarn.resourcemanager.leveldb-state-store.path
Handling deprecation for mapred.mapper.new-api
Handling deprecation for yarn.ipc.rpc.class
Handling deprecation for ipc.client.connection.maxidletime
Handling deprecation for yarn.nodemanager.process-kill-wait.ms
Handling deprecation for mapreduce.cluster.acls.enabled
Handling deprecation for mapreduce.jobtracker.handler.count
Handling deprecation for io.map.index.interval
Handling deprecation for dfs.namenode.https-address
Handling deprecation for mapreduce.task.profile.reduces
Handling deprecation for fs.s3n.multipart.uploads.enabled
Handling deprecation for io.seqfile.sorter.recordlimit
Handling deprecation for mapreduce.job.ubertask.maxmaps
Handling deprecation for mapreduce.tasktracker.tasks.sleeptimebeforesigkill
Handling deprecation for hadoop.util.hash.type
Handling deprecation for dfs.namenode.replication.min
Handling deprecation for yarn.nodemanager.container-manager.thread-count
Handling deprecation for mapreduce.jobtracker.jobhistory.block.size
Handling deprecation for dfs.namenode.fs-limits.min-block-size
Handling deprecation for mapreduce.app-submission.cross-platform
Handling deprecation for fs.AbstractFileSystem.file.impl
Handling deprecation for net.topology.script.number.args
Handling deprecation for yarn.resourcemanager.container-tokens.master-key-rolling-interval-secs
Handling deprecation for mapreduce.map.output.compress.codec
Handling deprecation for mapreduce.job.reducer.preempt.delay.sec
Handling deprecation for s3native.bytes-per-checksum
Handling deprecation for dfs.namenode.path.based.cache.block.map.allocation.percent
Handling deprecation for yarn.nodemanager.windows-container.memory-limit.enabled
Handling deprecation for mapreduce.input.fileinputformat.split.minsize
Handling deprecation for hadoop.security.group.mapping
Handling deprecation for mapreduce.jobtracker.system.dir
Handling deprecation for mapreduce.job.end-notification.max.attempts
Handling deprecation for mapreduce.reduce.markreset.buffer.percent
Handling deprecation for dfs.datanode.cache.revocation.polling.ms
Handling deprecation for mapreduce.reduce.speculative
Handling deprecation for yarn.nodemanager.localizer.cache.cleanup.interval-ms
Handling deprecation for dfs.namenode.lazypersist.file.scrub.interval.sec
Handling deprecation for fs.s3a.threads.core
Handling deprecation for mapreduce.jobhistory.recovery.store.fs.uri
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.start-time-read-cache-size
Handling deprecation for hadoop.registry.zk.retry.interval.ms
Handling deprecation for yarn.nodemanager.keytab
Handling deprecation for dfs.namenode.replication.interval
Handling deprecation for yarn.resourcemanager.admin.address
Handling deprecation for mapreduce.job.maps
Handling deprecation for nfs.dump.dir
Handling deprecation for mapreduce.job.user.name
Handling deprecation for mapreduce.jobtracker.maxtasks.perjob
Handling deprecation for mapreduce.job.ubertask.enable
Handling deprecation for mapreduce.job.reduce.class
Handling deprecation for yarn.nodemanager.delete.debug-delay-sec
Handling deprecation for yarn.timeline-service.ttl-enable
Handling deprecation for yarn.resourcemanager.fs.state-store.retry-policy-spec
Handling deprecation for mapreduce.reduce.skip.maxgroups
Handling deprecation for dfs.client.use.datanode.hostname
Handling deprecation for fs.trash.interval
Handling deprecation for mapreduce.job.name
Handling deprecation for mapreduce.am.max-attempts
Handling deprecation for mapreduce.jobtracker.heartbeats.in.second
Handling deprecation for yarn.resourcemanager.zk-num-retries
Handling deprecation for s3.blocksize
Handling deprecation for dfs.datanode.data.dir
Handling deprecation for mapreduce.jobtracker.persist.jobstatus.active
Handling deprecation for mapreduce.reduce.shuffle.parallelcopies
Handling deprecation for fs.s3.buffer.dir
Handling deprecation for mapreduce.jobhistory.done-dir
Handling deprecation for hadoop.security.instrumentation.requires.admin
Handling deprecation for hadoop.registry.zk.retry.ceiling.ms
Handling deprecation for nfs.rtmax
Handling deprecation for dfs.datanode.data.dir.perm
Handling deprecation for yarn.resourcemanager.container.liveness-monitor.interval-ms
Handling deprecation for yarn.nodemanager.env-whitelist
Handling deprecation for dfs.namenode.backup.address
Handling deprecation for dfs.namenode.xattrs.enabled
Handling deprecation for dfs.datanode.readahead.bytes
Handling deprecation for mapreduce.jobhistory.cleaner.enable
Handling deprecation for dfs.client.block.write.retries
Handling deprecation for mapreduce.tasktracker.http.address
Handling deprecation for yarn.nodemanager.linux-container-executor.cgroups.hierarchy
Handling deprecation for ha.failover-controller.graceful-fence.connection.retries
Handling deprecation for yarn.resourcemanager.recovery.enabled
Handling deprecation for yarn.app.mapreduce.am.container.log.backups
Handling deprecation for dfs.namenode.safemode.threshold-pct
Handling deprecation for yarn.nodemanager.disk-health-checker.interval-ms
Handling deprecation for hadoop.security.java.secure.random.algorithm
Handling deprecation for dfs.namenode.list.cache.directives.num.responses
Handling deprecation for dfs.datanode.dns.nameserver
Handling deprecation for mapreduce.cluster.temp.dir
Handling deprecation for fs.s3a.max.total.tasks
Handling deprecation for mapreduce.reduce.maxattempts
Handling deprecation for mapreduce.client.submit.file.replication
Handling deprecation for mapreduce.shuffle.port
Handling deprecation for yarn.resourcemanager.resource-tracker.client.thread-count
Handling deprecation for dfs.namenode.replication.considerLoad
Handling deprecation for dfs.namenode.edits.journal-plugin.qjournal
Handling deprecation for dfs.client.write.exclude.nodes.cache.expiry.interval.millis
Handling deprecation for yarn.nodemanager.delete.thread-count
Handling deprecation for dfs.client.mmap.cache.timeout.ms
Handling deprecation for yarn.nodemanager.admin-env
Handling deprecation for io.skip.checksum.errors
Handling deprecation for yarn.timeline-service.hostname
Handling deprecation for yarn.resourcemanager.proxy-user-privileges.enabled
Handling deprecation for mapreduce.job.speculative.speculative-cap-total-tasks
Handling deprecation for yarn.acl.enable
Handling deprecation for fs.s3a.fast.upload
Handling deprecation for file.blocksize
Handling deprecation for mapreduce.job.speculative.slowtaskthreshold
Handling deprecation for ftp.replication
Handling deprecation for yarn.sharedcache.cleaner.initial-delay-mins
Handling deprecation for s3native.client-write-packet-size
Handling deprecation for hadoop.rpc.socket.factory.class.default
Handling deprecation for file.bytes-per-checksum
Handling deprecation for dfs.datanode.slow.io.warning.threshold.ms
Handling deprecation for io.seqfile.lazydecompress
Handling deprecation for mapreduce.task.skip.start.attempts
Handling deprecation for dfs.namenode.reject-unresolved-dn-topology-mapping
Handling deprecation for hadoop.common.configuration.version
Handling deprecation for yarn.resourcemanager.client.thread-count
Handling deprecation for dfs.datanode.drop.cache.behind.reads
Handling deprecation for yarn.sharedcache.admin.address
Handling deprecation for mapreduce.job.output.value.class
Handling deprecation for mapreduce.output.fileoutputformat.outputdir
Handling deprecation for mapreduce.jobtracker.taskcache.levels
Handling deprecation for yarn.nodemanager.linux-container-executor.nonsecure-mode.user-pattern
Handling deprecation for yarn.resourcemanager.zk-timeout-ms
Handling deprecation for yarn.resourcemanager.max-completed-applications
Handling deprecation for mapreduce.job.jvm.numtasks
Handling deprecation for yarn.sharedcache.cleaner.period-mins
Handling deprecation for mapreduce.jobtracker.tasktracker.maxblacklists
Handling deprecation for dfs.namenode.top.num.users
Handling deprecation for yarn.nodemanager.linux-container-executor.cgroups.mount
Handling deprecation for yarn.sharedcache.checksum.algo.impl
Handling deprecation for mapreduce.job.end-notification.max.retry.interval
Handling deprecation for mapreduce.job.acl-view-job
Handling deprecation for mapreduce.job.classloader
Handling deprecation for yarn.log-aggregation-enable
Handling deprecation for mapreduce.reduce.shuffle.fetch.retry.interval-ms
Handling deprecation for yarn.resourcemanager.nodemanager.minimum.version
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.size
Handling deprecation for yarn.app.mapreduce.am.job.task.listener.thread-count
Handling deprecation for yarn.app.mapreduce.am.resource.cpu-vcores
Handling deprecation for dfs.namenode.edit.log.autoroll.check.interval.ms
Handling deprecation for mapreduce.output.fileoutputformat.compress.type
Handling deprecation for hadoop.hdfs.configuration.version
Handling deprecation for hadoop.security.group.mapping.ldap.search.attr.member
Handling deprecation for yarn.nodemanager.log.retain-seconds
Handling deprecation for yarn.nodemanager.local-cache.max-files-per-directory
Handling deprecation for mapreduce.job.end-notification.retry.interval
Handling deprecation for hadoop.ssl.client.conf
Handling deprecation for yarn.sharedcache.root-dir
Handling deprecation for dfs.journalnode.https-address
Handling deprecation for mapreduce.reduce.shuffle.fetch.retry.timeout-ms
Handling deprecation for dfs.bytes-per-checksum
Handling deprecation for dfs.namenode.max.objects
Handling deprecation for mapreduce.tasktracker.instrumentation
Handling deprecation for dfs.datanode.max.transfer.threads
Handling deprecation for dfs.block.access.key.update.interval
Handling deprecation for mapreduce.jobtracker.jobhistory.task.numberprogresssplits
Handling deprecation for mapreduce.map.memory.mb
Handling deprecation for ha.failover-controller.new-active.rpc-timeout.ms
Handling deprecation for hadoop.ssl.hostname.verifier
Handling deprecation for dfs.client.read.shortcircuit
Handling deprecation for dfs.datanode.hdfs-blocks-metadata.enabled
Handling deprecation for mapreduce.tasktracker.healthchecker.interval
Handling deprecation for dfs.image.transfer.chunksize
Handling deprecation for mapreduce.tasktracker.taskmemorymanager.monitoringinterval
Handling deprecation for dfs.client.https.keystore.resource
Handling deprecation for yarn.resourcemanager.connect.retry-interval.ms
Handling deprecation for yarn.timeline-service.webapp.address
Handling deprecation for s3native.blocksize
Handling deprecation for yarn.scheduler.minimum-allocation-mb
Handling deprecation for yarn.sharedcache.cleaner.resource-sleep-ms
Handling deprecation for net.topology.impl
Handling deprecation for dfs.client.failover.sleep.base.millis
Handling deprecation for dfs.permissions.superusergroup
Handling deprecation for io.seqfile.compress.blocksize
Handling deprecation for hadoop.registry.zk.retry.times
Handling deprecation for fs.AbstractFileSystem.ftp.impl
Handling deprecation for dfs.namenode.checkpoint.edits.dir
Handling deprecation for mapreduce.job.running.reduce.limit
Handling deprecation for dfs.blockreport.initialDelay
Handling deprecation for dfs.namenode.heartbeat.recheck-interval
Handling deprecation for dfs.namenode.safemode.extension
Handling deprecation for yarn.scheduler.maximum-allocation-mb
Handling deprecation for mapreduce.job.reduce.shuffle.consumer.plugin.class
Handling deprecation for yarn.nodemanager.vmem-check-enabled
Handling deprecation for mapreduce.task.io.sort.factor
Handling deprecation for mapreduce.jobtracker.persist.jobstatus.dir
Handling deprecation for dfs.client.failover.sleep.max.millis
Handling deprecation for dfs.namenode.delegation.key.update-interval
Handling deprecation for hadoop.rpc.protection
Handling deprecation for fs.permissions.umask-mode
Handling deprecation for fs.s3.sleepTimeSeconds
Handling deprecation for ha.health-monitor.rpc-timeout.ms
Handling deprecation for hadoop.http.staticuser.user
Handling deprecation for fs.s3a.connection.maximum
Handling deprecation for yarn.nodemanager.linux-container-executor.nonsecure-mode.limit-users
Handling deprecation for fs.s3a.paging.maximum
Handling deprecation for fs.AbstractFileSystem.viewfs.impl
Handling deprecation for fs.ftp.host
Handling deprecation for yarn.nodemanager.linux-container-executor.nonsecure-mode.local-user
Handling deprecation for fs.s3a.impl
Handling deprecation for hadoop.http.authentication.kerberos.keytab
Handling deprecation for dfs.namenode.fs-limits.max-blocks-per-file
Handling deprecation for mapreduce.tasktracker.http.threads
Handling deprecation for mapreduce.tasktracker.dns.nameserver
Handling deprecation for yarn.resourcemanager.am-rm-tokens.master-key-rolling-interval-secs
Handling deprecation for dfs.client.block.write.replace-datanode-on-failure.enable
Handling deprecation for io.compression.codec.bzip2.library
Handling deprecation for mapreduce.map.skip.maxrecords
Handling deprecation for dfs.client.use.legacy.blockreader.local
Handling deprecation for dfs.namenode.checkpoint.dir
Handling deprecation for dfs.namenode.top.windows.minutes
Handling deprecation for mapreduce.job.maxtaskfailures.per.tracker
Handling deprecation for net.topology.node.switch.mapping.impl
Handling deprecation for mapreduce.shuffle.max.connections
Handling deprecation for mapreduce.jobhistory.loadedjobs.cache.size
Handling deprecation for dfs.storage.policy.enabled
Handling deprecation for yarn.client.application-client-protocol.poll-interval-ms
Handling deprecation for yarn.nodemanager.localizer.address
Handling deprecation for dfs.namenode.list.cache.pools.num.responses
Handling deprecation for nfs.server.port
Handling deprecation for mapreduce.client.output.filter
Handling deprecation for yarn.timeline-service.client.best-effort
Handling deprecation for ha.zookeeper.parent-znode
Handling deprecation for mapreduce.jobtracker.persist.jobstatus.hours
Handling deprecation for yarn.sharedcache.admin.thread-count
Handling deprecation for yarn.nodemanager.resource.cpu-vcores
Handling deprecation for dfs.datanode.block-pinning.enabled
Handling deprecation for mapreduce.jobhistory.http.policy
Handling deprecation for yarn.resourcemanager.webapp.delegation-token-auth-filter.enabled
Handling deprecation for mapreduce.job.speculative.retry-after-no-speculate
Handling deprecation for fs.s3a.attempts.maximum
Handling deprecation for s3native.stream-buffer-size
Handling deprecation for io.seqfile.local.dir
Handling deprecation for yarn.log-aggregation.retain-check-interval-seconds
Handling deprecation for fs.s3n.multipart.copy.block.size
Handling deprecation for dfs.encrypt.data.transfer.cipher.key.bitlength
Handling deprecation for dfs.datanode.sync.behind.writes
Handling deprecation for yarn.resourcemanager.zk-acl
Handling deprecation for hadoop.ssl.keystores.factory.class
Handling deprecation for mapreduce.job.split.metainfo.maxsize
Handling deprecation for fs.s3.maxRetries
Handling deprecation for hadoop.security.random.device.file.path
Handling deprecation for yarn.client.nodemanager-connect.max-wait-ms
Handling deprecation for dfs.namenode.stale.datanode.interval
Handling deprecation for mapreduce.task.io.sort.mb
Handling deprecation for yarn.resourcemanager.zk-state-store.parent-path
Handling deprecation for yarn.app.mapreduce.client-am.ipc.max-retries
Handling deprecation for fs.client.resolve.remote.symlinks
Handling deprecation for yarn.nodemanager.linux-container-executor.cgroups.strict-resource-usage
Handling deprecation for hadoop.ssl.enabled.protocols
Handling deprecation for mapreduce.reduce.cpu.vcores
Handling deprecation for yarn.client.failover-retries
Handling deprecation for mapreduce.jobhistory.address
Handling deprecation for hadoop.ssl.enabled
Handling deprecation for dfs.replication.max
Handling deprecation for dfs.namenode.name.dir
Handling deprecation for dfs.datanode.https.address
Handling deprecation for ipc.client.kill.max
Handling deprecation for mapreduce.job.committer.setup.cleanup.needed
Handling deprecation for dfs.client.domain.socket.data.traffic
Handling deprecation for yarn.nodemanager.localizer.cache.target-size-mb
Handling deprecation for yarn.resourcemanager.admin.client.thread-count
Handling deprecation for dfs.block.access.token.enable
Handling deprecation for mapreduce.job.speculative.retry-after-speculate
Handling deprecation for dfs.datanode.address
Handling deprecation for mapreduce.jobtracker.restart.recover
Handling deprecation for ipc.client.connect.max.retries
Handling deprecation for yarn.timeline-service.store-class
Handling deprecation for dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
Handling deprecation for hadoop.tmp.dir
Handling deprecation for dfs.datanode.handler.count
Handling deprecation for yarn.resourcemanager.ha.automatic-failover.embedded
Handling deprecation for yarn.timeline-service.ttl-ms
Handling deprecation for mapreduce.task.profile.map.params
Handling deprecation for yarn.resourcemanager.nodemanagers.heartbeat-interval-ms
Handling deprecation for mapreduce.map.speculative
Handling deprecation for yarn.timeline-service.recovery.enabled
Handling deprecation for mapreduce.job.map.class
Handling deprecation for dfs.namenode.resource.checked.volumes.minimum
Handling deprecation for yarn.nodemanager.recovery.dir
Handling deprecation for mapreduce.job.counters.max
Handling deprecation for yarn.resourcemanager.keytab
Handling deprecation for dfs.namenode.max.extra.edits.segments.retained
Handling deprecation for dfs.webhdfs.user.provider.user.pattern
Handling deprecation for dfs.client.mmap.enabled
Handling deprecation for mapreduce.map.log.level
Handling deprecation for dfs.client.file-block-storage-locations.timeout.millis
Handling deprecation for yarn.client.max-cached-nodemanagers-proxies
Handling deprecation for yarn.app.mapreduce.am.scheduler.heartbeat.interval-ms
Handling deprecation for hadoop.fuse.timer.period
Handling deprecation for fs.trash.checkpoint.interval
Handling deprecation for yarn.sharedcache.app-checker.class
Handling deprecation for dfs.journalnode.http-address
Handling deprecation for yarn.app.mapreduce.am.staging-dir
Handling deprecation for mapreduce.tasktracker.local.dir.minspacestart
Handling deprecation for yarn.nm.liveness-monitor.expiry-interval-ms
Handling deprecation for ha.health-monitor.check-interval.ms
Handling deprecation for mapreduce.reduce.shuffle.merge.percent
Handling deprecation for dfs.namenode.retrycache.heap.percent
Handling deprecation for yarn.nodemanager.docker-container-executor.exec-name
Handling deprecation for ipc.client.connect.timeout
Handling deprecation for yarn.resourcemanager.fs.state-store.retry-interval-ms
Handling deprecation for mapreduce.output.fileoutputformat.compress
Handling deprecation for yarn.nodemanager.local-dirs
Handling deprecation for yarn.nodemanager.recovery.enabled
Handling deprecation for io.native.lib.available
Handling deprecation for yarn.sharedcache.store.in-memory.staleness-period-mins
Handling deprecation for yarn.resourcemanager.am.max-attempts
Handling deprecation for s3.replication
Handling deprecation for mapreduce.input.fileinputformat.inputdir
Handling deprecation for fs.AbstractFileSystem.har.impl
Handling deprecation for dfs.image.compress
Handling deprecation for mapreduce.job.running.map.limit
Handling deprecation for mapreduce.reduce.input.buffer.percent
Handling deprecation for yarn.nodemanager.webapp.address
Handling deprecation for dfs.datanode.available-space-volume-choosing-policy.balanced-space-preference-fraction
Handling deprecation for dfs.namenode.edit.log.autoroll.multiplier.threshold
Handling deprecation for hadoop.security.group.mapping.ldap.ssl
Handling deprecation for dfs.namenode.checkpoint.check.period
Handling deprecation for fs.defaultFS
Handling deprecation for fs.s3a.multipart.size
Handling deprecation for dfs.client.slow.io.warning.threshold.ms
Handling deprecation for yarn.app.mapreduce.am.job.committer.commit-window
Handling deprecation for hadoop.security.group.mapping.ldap.search.attr.group.name
Handling deprecation for yarn.nodemanager.disk-health-checker.max-disk-utilization-per-disk-percentage
Handling deprecation for yarn.nodemanager.container-monitor.procfs-tree.smaps-based-rss.enabled
Handling deprecation for mapreduce.job.submithostname
Handling deprecation for mapreduce.map.sort.spill.percent
Handling deprecation for hadoop.security.crypto.codec.classes.aes.ctr.nopadding
Handling deprecation for dfs.namenode.http-address
Handling deprecation for hadoop.security.groups.negative-cache.secs
Handling deprecation for hadoop.ssl.server.conf
Handling deprecation for mapreduce.ifile.readahead
Handling deprecation for s3native.replication
Handling deprecation for yarn.client.nodemanager-client-async.thread-pool-max-size
Handling deprecation for mapreduce.jobtracker.staging.root.dir
Handling deprecation for mapreduce.jobhistory.admin.address
Handling deprecation for dfs.namenode.startup.delay.block.deletion.sec
Handling deprecation for yarn.nodemanager.health-checker.interval-ms
Handling deprecation for dfs.namenode.checkpoint.max-retries
Handling deprecation for s3.stream-buffer-size
Handling deprecation for ftp.client-write-packet-size
Handling deprecation for dfs.datanode.fsdatasetcache.max.threads.per.volume
Handling deprecation for mapreduce.output.fileoutputformat.compress.codec
Handling deprecation for yarn.timeline-service.keytab
Handling deprecation for yarn.sharedcache.store.in-memory.initial-delay-mins
Handling deprecation for mapreduce.jobhistory.webapp.address
Handling deprecation for mapreduce.task.userlog.limit.kb
Handling deprecation for mapreduce.reduce.shuffle.fetch.retry.enabled
Handling deprecation for yarn.app.mapreduce.task.container.log.backups
Handling deprecation for dfs.heartbeat.interval
Handling deprecation for ha.zookeeper.session-timeout.ms
Handling deprecation for fs.s3a.connection.ssl.enabled
Handling deprecation for yarn.sharedcache.webapp.address
Handling deprecation for hadoop.http.authentication.signature.secret.file
Handling deprecation for hadoop.fuse.connection.timeout
Handling deprecation for mapreduce.input.fileinputformat.numinputfiles
Handling deprecation for yarn.nodemanager.log-aggregation.compression-type
Handling deprecation for ipc.server.max.connections
Handling deprecation for yarn.resourcemanager.work-preserving-recovery.scheduling-wait-ms
Handling deprecation for yarn.nodemanager.log-dirs
Handling deprecation for yarn.app.mapreduce.am.resource.mb
Handling deprecation for hadoop.security.groups.cache.secs
Handling deprecation for mapreduce.job.speculative.minimum-allowed-tasks
Handling deprecation for yarn.nodemanager.container-monitor.interval-ms
Handling deprecation for dfs.datanode.cache.revocation.timeout.ms
Handling deprecation for mapreduce.jobhistory.recovery.store.class
Handling deprecation for mapreduce.task.combine.progress.records
Handling deprecation for s3.client-write-packet-size
Handling deprecation for mapreduce.jobtracker.instrumentation
Handling deprecation for dfs.replication
Handling deprecation for mapreduce.shuffle.transfer.buffer.size
Handling deprecation for hadoop.security.group.mapping.ldap.directory.search.timeout
Handling deprecation for dfs.datanode.available-space-volume-choosing-policy.balanced-space-threshold
Handling deprecation for hadoop.work.around.non.threadsafe.getpwuid
Handling deprecation for yarn.app.mapreduce.client-am.ipc.max-retries-on-timeouts
Handling deprecation for yarn.nodemanager.address
Handling deprecation for mapreduce.tasktracker.taskcontroller
Handling deprecation for mapreduce.tasktracker.indexcache.mb
Handling deprecation for yarn.scheduler.maximum-allocation-vcores
Handling deprecation for mapreduce.job.reduces
Handling deprecation for yarn.nodemanager.sleep-delay-before-sigkill.ms
Handling deprecation for yarn.timeline-service.address
Handling deprecation for yarn.resourcemanager.configuration.provider-class
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.expiry
Handling deprecation for yarn.sharedcache.enabled
Handling deprecation for tfile.io.chunk.size
Handling deprecation for mapreduce.job.acl-modify-job
Handling deprecation for hadoop.registry.zk.session.timeout.ms
Handling deprecation for fs.automatic.close
Handling deprecation for ha.health-monitor.sleep-after-disconnect.ms
Handling deprecation for mapreduce.tasktracker.reduce.tasks.maximum
Handling deprecation for mapreduce.input.fileinputformat.list-status.num-threads
Handling deprecation for dfs.datanode.directoryscan.threads
Handling deprecation for dfs.datanode.directoryscan.interval
Handling deprecation for dfs.namenode.acls.enabled
Handling deprecation for dfs.client.short.circuit.replica.stale.threshold.ms
Handling deprecation for hadoop.http.authentication.token.validity
Handling deprecation for fs.s3.block.size
Handling deprecation for ha.failover-controller.graceful-fence.rpc-timeout.ms
Handling deprecation for mapreduce.tasktracker.local.dir.minspacekill
Handling deprecation for dfs.namenode.resource.du.reserved
Handling deprecation for mapreduce.jobhistory.cleaner.interval-ms
Handling deprecation for dfs.namenode.datanode.registration.ip-hostname-check
Handling deprecation for mapreduce.jobhistory.intermediate-done-dir
Handling deprecation for mapreduce.jobtracker.http.address
Handling deprecation for dfs.namenode.backup.http-address
Handling deprecation for dfs.namenode.edits.noeditlogchannelflush
Handling deprecation for mapreduce.reduce.shuffle.input.buffer.percent
Handling deprecation for mapreduce.map.maxattempts
Handling deprecation for yarn.http.policy
Handling deprecation for dfs.namenode.audit.loggers
Handling deprecation for hadoop.security.groups.cache.warn.after.ms
Handling deprecation for io.serializations
Handling deprecation for mapreduce.tasktracker.outofband.heartbeat
Handling deprecation for mapreduce.reduce.shuffle.read.timeout
Handling deprecation for hadoop.security.crypto.buffer.size
Handling deprecation for mapreduce.reduce.skip.proc.count.autoincr
Handling deprecation for mapreduce.ifile.readahead.bytes
Handling deprecation for dfs.http.policy
Handling deprecation for hadoop.registry.secure
Handling deprecation for dfs.namenode.safemode.min.datanodes
Handling deprecation for dfs.client.file-block-storage-locations.num-threads
Handling deprecation for mapreduce.cluster.local.dir
Handling deprecation for mapreduce.tasktracker.report.address
Handling deprecation for dfs.namenode.secondary.https-address
Handling deprecation for hadoop.kerberos.kinit.command
Handling deprecation for yarn.timeline-service.http-authentication.type
Handling deprecation for dfs.block.access.token.lifetime
Handling deprecation for dfs.webhdfs.enabled
Handling deprecation for dfs.namenode.delegation.token.max-lifetime
Handling deprecation for dfs.namenode.avoid.write.stale.datanode
Handling deprecation for dfs.datanode.drop.cache.behind.writes
Handling deprecation for yarn.log-aggregation.retain-seconds
Handling deprecation for mapreduce.job.complete.cancel.delegation.tokens
Handling deprecation for mapreduce.local.clientfactory.class.name
Handling deprecation for mapreduce.shuffle.connection-keep-alive.timeout
Handling deprecation for dfs.namenode.num.extra.edits.retained
Handling deprecation for yarn.scheduler.minimum-allocation-vcores
Handling deprecation for ipc.client.connect.max.retries.on.timeouts
Handling deprecation for yarn.timeline-service.client.retry-interval-ms
Handling deprecation for yarn.timeline-service.client.max-retries
Handling deprecation for fs.s3n.block.size
Handling deprecation for mapreduce.job.map.output.collector.class
Handling deprecation for ha.health-monitor.connect-retry-interval.ms
Handling deprecation for mapreduce.shuffle.max.threads
Handling deprecation for nfs.exports.allowed.hosts
Handling deprecation for dfs.client.mmap.cache.size
Handling deprecation for mapreduce.tasktracker.map.tasks.maximum
Handling deprecation for io.file.buffer.size
Handling deprecation for dfs.client.datanode-restart.timeout
Handling deprecation for io.mapfile.bloom.size
Handling deprecation for hadoop.security.kms.client.authentication.retry-count
Handling deprecation for dfs.namenode.checkpoint.txns
Handling deprecation for ipc.client.connect.retry.interval
Handling deprecation for dfs.client-write-packet-size
Handling deprecation for mapreduce.reduce.shuffle.connect.timeout
Handling deprecation for yarn.resourcemanager.fs.state-store.uri
Handling deprecation for fs.swift.impl
Handling deprecation for hadoop.registry.zk.connection.timeout.ms
Handling deprecation for mapred.queue.default.acl-administer-jobs
Handling deprecation for mapreduce.job.submithostaddress
Handling deprecation for dfs.cachereport.intervalMsec
Handling deprecation for yarn.app.mapreduce.shuffle.log.backups
Handling deprecation for yarn.app.mapreduce.am.container.log.limit.kb
Handling deprecation for yarn.nodemanager.resourcemanager.minimum.version
Handling deprecation for ftp.blocksize
Handling deprecation for yarn.resourcemanager.address
Handling deprecation for file.stream-buffer-size
Handling deprecation for yarn.resourcemanager.scheduler.monitor.enable
Handling deprecation for mapreduce.job.ubertask.maxreduces
Handling deprecation for nfs.allow.insecure.ports
Handling deprecation for yarn.sharedcache.nm.uploader.thread-count
Handling deprecation for ipc.client.idlethreshold
Handling deprecation for ftp.stream-buffer-size
Handling deprecation for yarn.sharedcache.client-server.address
Handling deprecation for dfs.client.failover.connection.retries.on.timeouts
Handling deprecation for dfs.namenode.replication.work.multiplier.per.iteration
Handling deprecation for hadoop.http.authentication.simple.anonymous.allowed
Handling deprecation for hadoop.security.authorization
Handling deprecation for yarn.client.nodemanager-connect.retry-interval-ms
Handling deprecation for yarn.am.liveness-monitor.expiry-interval-ms
Handling deprecation for fs.har.impl.disable.cache
Handling deprecation for yarn.nodemanager.linux-container-executor.resources-handler.class
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.read-cache-size
Handling deprecation for hadoop.security.authentication
Handling deprecation for dfs.image.compression.codec
Handling deprecation for mapreduce.task.files.preserve.failedtasks
Handling deprecation for dfs.client.read.shortcircuit.streams.cache.size
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.path
Handling deprecation for mapreduce.job.reduce.slowstart.completedmaps
Handling deprecation for mapreduce.jobhistory.minicluster.fixed.ports
Handling deprecation for file.replication
Handling deprecation for yarn.resourcemanager.ha.automatic-failover.enabled
Handling deprecation for mapreduce.job.userlog.retain.hours
Handling deprecation for mapreduce.jobhistory.joblist.cache.size
Handling deprecation for dfs.namenode.accesstime.precision
Handling deprecation for yarn.resourcemanager.work-preserving-recovery.enabled
Handling deprecation for dfs.namenode.fs-limits.max-xattrs-per-inode
Handling deprecation for io.mapfile.bloom.error.rate
Handling deprecation for yarn.resourcemanager.store.class
Handling deprecation for dfs.image.transfer.timeout
Handling deprecation for yarn.timeline-service.leveldb-state-store.path
Handling deprecation for nfs.wtmax
Handling deprecation for mapreduce.job.combine.class
Handling deprecation for dfs.namenode.support.allow.format
Handling deprecation for fs.s3a.multipart.purge
Handling deprecation for dfs.secondary.namenode.kerberos.internal.spnego.principal
Handling deprecation for fs.s3a.connection.establish.timeout
Handling deprecation for dfs.stream-buffer-size
Handling deprecation for dfs.namenode.invalidate.work.pct.per.iteration
Handling deprecation for yarn.nodemanager.container-executor.class
Handling deprecation for fs.s3a.multipart.purge.age
Handling deprecation for yarn.resourcemanager.scheduler.client.thread-count
Handling deprecation for dfs.namenode.top.enabled
Handling deprecation for yarn.app.mapreduce.shuffle.log.separate
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.low-watermark
Handling deprecation for fs.s3a.fast.buffer.size
Handling deprecation for hadoop.user.group.static.mapping.overrides
Handling deprecation for tfile.fs.input.buffer.size
Handling deprecation for dfs.client.cached.conn.retry
Handling deprecation for hadoop.http.authentication.type
Handling deprecation for dfs.namenode.list.encryption.zones.num.responses
Handling deprecation for mapreduce.map.cpu.vcores
Handling deprecation for dfs.namenode.path.based.cache.refresh.interval.ms
Handling deprecation for dfs.namenode.decommission.interval
Handling deprecation for dfs.namenode.fs-limits.max-directory-items
Handling deprecation for yarn.resourcemanager.zk-retry-interval-ms
Handling deprecation for ftp.bytes-per-checksum
Handling deprecation for dfs.ha.log-roll.period
Handling deprecation for dfs.user.home.dir.prefix
Handling deprecation for ipc.client.fallback-to-simple-auth-allowed
Handling deprecation for yarn.nodemanager.pmem-check-enabled
Handling deprecation for yarn.nodemanager.remote-app-log-dir
Handling deprecation for dfs.namenode.inotify.max.events.per.rpc
Handling deprecation for mapreduce.task.profile.maps
Handling deprecation for mapreduce.shuffle.ssl.file.buffer.size
Handling deprecation for mapreduce.tasktracker.healthchecker.script.timeout
Handling deprecation for yarn.timeline-service.webapp.https.address
Handling deprecation for yarn.nodemanager.resource.percentage-physical-cpu-limit
Handling deprecation for yarn.app.mapreduce.am.command-opts
Handling deprecation for dfs.namenode.fs-limits.max-xattr-size
Handling deprecation for dfs.datanode.http.address
Handling deprecation for dfs.namenode.blocks.per.postponedblocks.rescan
Handling deprecation for yarn.sharedcache.nm.uploader.replication.factor
Handling deprecation for hadoop.registry.zk.root
Handling deprecation for hadoop.jetty.logs.serve.aliases
Handling deprecation for yarn.client.failover-proxy-provider
Handling deprecation for mapreduce.jobhistory.admin.acl
Handling deprecation for yarn.app.mapreduce.am.hard-kill-timeout-ms
Handling deprecation for yarn.nodemanager.remote-app-log-dir-suffix
Handling deprecation for mapreduce.jobhistory.principal
Handling deprecation for yarn.resourcemanager.webapp.address
Handling deprecation for mapreduce.jobhistory.recovery.enable
Handling deprecation for yarn.sharedcache.store.in-memory.check-period-mins
Handling deprecation for nfs.mountd.port
Handling deprecation for mapreduce.reduce.merge.inmem.threshold
Handling deprecation for fs.df.interval
Handling deprecation for yarn.timeline-service.enabled
Handling deprecation for mapreduce.jobtracker.jobhistory.lru.cache.size
Handling deprecation for mapreduce.task.profile
Handling deprecation for mapreduce.job.output.key.class
Handling deprecation for yarn.nodemanager.hostname
Handling deprecation for dfs.namenode.num.checkpoints.retained
Handling deprecation for mapreduce.job.queuename
Handling deprecation for mapreduce.jobhistory.max-age-ms
Handling deprecation for mapreduce.job.token.tracking.ids.enabled
Handling deprecation for yarn.nodemanager.localizer.client.thread-count
Handling deprecation for yarn.sharedcache.uploader.server.thread-count
Handling deprecation for dfs.client.mmap.retry.timeout.ms
Handling deprecation for mapreduce.jobhistory.move.thread-count
Handling deprecation for dfs.permissions.enabled
Handling deprecation for dfs.blockreport.split.threshold
Handling deprecation for fs.AbstractFileSystem.hdfs.impl
Handling deprecation for dfs.datanode.balance.bandwidthPerSec
Handling deprecation for dfs.block.scanner.volume.bytes.per.second
Handling deprecation for hadoop.http.filter.initializers
Handling deprecation for yarn.timeline-service.http-authentication.simple.anonymous.allowed
Handling deprecation for dfs.default.chunk.view.size
Handling deprecation for yarn.sharedcache.client-server.thread-count
Handling deprecation for yarn.resourcemanager.resource-tracker.address
Handling deprecation for mapreduce.job.working.dir
Handling deprecation for mapreduce.jobhistory.datestring.cache.size
Handling deprecation for mapreduce.task.profile.params
Handling deprecation for dfs.namenode.decommission.blocks.per.interval
Handling deprecation for dfs.namenode.handler.count
Handling deprecation for dfs.image.transfer.bandwidthPerSec
Handling deprecation for rpc.metrics.quantile.enable
Handling deprecation for mapreduce.jobtracker.expire.trackers.interval
Handling deprecation for mapreduce.task.timeout
Handling deprecation for yarn.app.mapreduce.client.max-retries
Handling deprecation for yarn.nodemanager.resource.memory-mb
Handling deprecation for yarn.nodemanager.disk-health-checker.min-healthy-disks
Handling deprecation for dfs.datanode.failed.volumes.tolerated
Handling deprecation for yarn.timeline-service.handler-thread-count
Handling deprecation for ipc.server.listen.queue.size
Handling deprecation for fs.s3a.threads.max
Handling deprecation for yarn.resourcemanager.connect.max-wait.ms
Handling deprecation for mapreduce.fileoutputcommitter.algorithm.version
Handling deprecation for mapreduce.framework.name
Handling deprecation for mapreduce.map.skip.proc.count.autoincr
Handling deprecation for mapreduce.job.max.split.locations
Handling deprecation for yarn.resourcemanager.scheduler.class
Handling deprecation for yarn.resourcemanager.system-metrics-publisher.enabled
Handling deprecation for dfs.blocksize
Handling deprecation for yarn.sharedcache.nested-level
Handling deprecation for mapreduce.shuffle.connection-keep-alive.enable
Handling deprecation for fs.s3a.threads.keepalivetime
Handling deprecation for fs.s3a.connection.timeout
Handling deprecation for file.client-write-packet-size
Handling deprecation for ha.failover-controller.cli-check.rpc-timeout.ms
Handling deprecation for ha.zookeeper.acl
Handling deprecation for dfs.namenode.write.stale.datanode.ratio
Handling deprecation for dfs.encrypt.data.transfer
Handling deprecation for dfs.datanode.shared.file.descriptor.paths
Handling deprecation for mapreduce.input.lineinputformat.linespermap
Handling deprecation for yarn.resourcemanager.delayed.delegation-token.removal-interval-ms
Handling deprecation for yarn.nodemanager.localizer.fetch.thread-count
Handling deprecation for dfs.client.failover.max.attempts
Handling deprecation for yarn.resourcemanager.scheduler.address
Handling deprecation for dfs.client.read.shortcircuit.streams.cache.expiry.ms
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.start-time-write-cache-size
Handling deprecation for yarn.nodemanager.health-checker.script.timeout-ms
Handling deprecation for yarn.resourcemanager.fs.state-store.num-retries
Handling deprecation for hadoop.ssl.require.client.cert
Handling deprecation for hadoop.security.uid.cache.secs
Handling deprecation for mapreduce.jobhistory.keytab
Handling deprecation for dfs.client.read.shortcircuit.skip.checksum
Handling deprecation for yarn.resourcemanager.ha.automatic-failover.zk-base-path
Handling deprecation for mapreduce.shuffle.ssl.enabled
Handling deprecation for mapreduce.reduce.log.level
Handling deprecation for hadoop.registry.rm.enabled
Handling deprecation for mapreduce.tasktracker.dns.interface
Handling deprecation for yarn.resourcemanager.system-metrics-publisher.dispatcher.pool-size
Handling deprecation for mapreduce.job.speculative.speculative-cap-running-tasks
Handling deprecation for dfs.datanode.block.id.layout.upgrade.threads
Handling deprecation for dfs.datanode.use.datanode.hostname
Handling deprecation for dfs.client.context
Handling deprecation for yarn.resourcemanager.ha.enabled
Handling deprecation for mapred.reducer.new-api
Handling deprecation for dfs.namenode.delegation.token.renew-interval
Handling deprecation for dfs.blockreport.intervalMsec
Handling deprecation for fs.s3a.multipart.threshold
Handling deprecation for mapreduce.reduce.shuffle.memory.limit.percent
Handling deprecation for dfs.https.server.keystore.resource
Handling deprecation for io.map.index.skip
Handling deprecation for mapreduce.job.hdfs-servers
Handling deprecation for mapreduce.jobtracker.taskscheduler
Handling deprecation for dfs.namenode.kerberos.internal.spnego.principal
Handling deprecation for yarn.resourcemanager.state-store.max-completed-applications
Handling deprecation for mapreduce.map.output.compress
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.num.refill.threads
Handling deprecation for fs.s3n.multipart.uploads.block.size
Handling deprecation for mapreduce.task.merge.progress.records
Handling deprecation for dfs.datanode.dns.interface
Handling deprecation for map.sort.class
Handling deprecation for yarn.nodemanager.aux-services.mapreduce_shuffle.class
Handling deprecation for tfile.fs.output.buffer.size
Handling deprecation for fs.du.interval
Handling deprecation for dfs.client.failover.connection.retries
Handling deprecation for dfs.namenode.top.window.num.buckets
Handling deprecation for mapreduce.job.dir
Handling deprecation for fs.s3a.buffer.dir
Handling deprecation for mapreduce.reduce.shuffle.retry-delay.max.ms
Handling deprecation for yarn.sharedcache.uploader.server.address
Handling deprecation for mapreduce.client.progressmonitor.pollinterval
Handling deprecation for yarn.app.mapreduce.shuffle.log.limit.kb
Handling deprecation for dfs.datanode.max.locked.memory
Handling deprecation for dfs.namenode.retrycache.expirytime.millis
Handling deprecation for dfs.datanode.scan.period.hours
Handling deprecation for dfs.client.block.write.replace-datanode-on-failure.best-effort
Handling deprecation for mapreduce.jobhistory.move.interval-ms
Handling deprecation for dfs.ha.fencing.ssh.connect-timeout
Handling deprecation for yarn.nodemanager.log-aggregation.roll-monitoring-interval-seconds
Handling deprecation for dfs.namenode.fs-limits.max-component-length
Handling deprecation for hadoop.registry.zk.quorum
Handling deprecation for dfs.namenode.enable.retrycache
Handling deprecation for dfs.datanode.du.reserved
Handling deprecation for yarn.timeline-service.state-store-class
Handling deprecation for dfs.datanode.ipc.address
Handling deprecation for hadoop.registry.system.acls
Handling deprecation for dfs.client.block.write.replace-datanode-on-failure.policy
Handling deprecation for dfs.namenode.path.based.cache.retry.interval.ms
Handling deprecation for hadoop.security.crypto.cipher.suite
Handling deprecation for dfs.ha.tail-edits.period
Handling deprecation for mapreduce.task.profile.reduce.params
Handling deprecation for hadoop.registry.jaas.context
Handling deprecation for yarn.resourcemanager.hostname
Handling deprecation for mapreduce.reduce.memory.mb
Handling deprecation for hadoop.security.group.mapping.ldap.search.filter.group
Handling deprecation for hadoop.http.authentication.kerberos.principal
Handling deprecation for hadoop.security.group.mapping.ldap.search.filter.user
Handling deprecation for yarn.nodemanager.disk-health-checker.min-free-space-per-disk-mb
Handling deprecation for dfs.namenode.edits.dir
Handling deprecation for yarn.client.failover-retries-on-socket-timeouts
Handling deprecation for dfs.namenode.decommission.max.concurrent.tracked.nodes
Handling deprecation for mapreduce.client.completion.pollinterval
Handling deprecation for dfs.namenode.name.dir.restore
Handling deprecation for dfs.namenode.secondary.http-address
Handling deprecation for mapreduce.jobhistory.recovery.store.leveldb.path
Handling deprecation for yarn.sharedcache.store.class
Handling deprecation for s3.bytes-per-checksum
Handling deprecation for yarn.nodemanager.windows-container.cpu-limit.enabled
Handling deprecation for yarn.resourcemanager.webapp.https.address
Handling deprecation for yarn.nodemanager.vmem-pmem-ratio
Handling deprecation for dfs.namenode.checkpoint.period
Handling deprecation for dfs.ha.automatic-failover.enabled
The url to track the job: http://localhost:8080/
Running job: job_local530807718_0002
OutputCommitter set in config null
File Output Committer Algorithm version is 1
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
/user/michaeljones/wcOutput/_temporary/0: masked=rwxr-xr-x
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones sending #34
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones got value #34
Call: mkdirs took 6ms
Starting mapper thread pool executor.
Max local threads: 1
Map tasks to process: 1
Waiting for map tasks
Starting task: attempt_local530807718_0002_m_000000_0
currentIndex 0   0:0
mapreduce.cluster.local.dir for child : /tmp/hadoop-michaeljones/mapred/local/localRunner//michaeljones/jobcache/job_local530807718_0002/attempt_local530807718_0002_m_000000_0
using new api for output committer
File Output Committer Algorithm version is 1
ProcfsBasedProcessTree currently is supported only on Linux.
 Using ResourceCalculatorProcessTree : null
Processing split: hdfs://localhost:9000/user/michaeljones/wcInput:0+50
Trying map output collector class: org.apache.hadoop.mapred.MapTask$MapOutputBuffer
(EQUATOR) 0 kvi 26214396(104857584)
mapreduce.task.io.sort.mb: 100
soft limit at 83886080
bufstart = 0; bufvoid = 104857600
kvstart = 26214396; length = 6553600
Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones sending #35
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones got value #35
Call: getBlockLocations took 3ms
newInfo = LocatedBlocks{
  fileLength=50
  underConstruction=false
  blocks=[LocatedBlock{BP-1045030256-10.0.0.2-1433119149314:blk_1073741825_1002; getBlockSize()=50; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-b42c5705-9ba4-4b14-b00b-f9194bb036f0,DISK]]}]
  lastLocatedBlock=LocatedBlock{BP-1045030256-10.0.0.2-1433119149314:blk_1073741825_1002; getBlockSize()=50; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-b42c5705-9ba4-4b14-b00b-f9194bb036f0,DISK]]}
  isLastBlockComplete=true}
Connecting to datanode 127.0.0.1:50010

Starting flush of map output
Spilling map output
bufstart = 0; bufend = 82; bufvoid = 104857600
kvstart = 26214396(104857584); kvend = 26214368(104857472); length = 29/6553600
Finished spill 0
Task:attempt_local530807718_0002_m_000000_0 is done. And is in the process of committing
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones sending #36
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones got value #36
Call: getFileInfo took 2ms
map
Task 'attempt_local530807718_0002_m_000000_0' done.
Finishing task: attempt_local530807718_0002_m_000000_0
map task executor complete.
Starting reduce thread pool executor.
Max local threads: 1
Reduce tasks to process: 1
Waiting for reduce tasks
Starting task: attempt_local530807718_0002_r_000000_0
currentIndex 0   0:0
mapreduce.cluster.local.dir for child : /tmp/hadoop-michaeljones/mapred/local/localRunner//michaeljones/jobcache/job_local530807718_0002/attempt_local530807718_0002_r_000000_0
using new api for output committer
File Output Committer Algorithm version is 1
ProcfsBasedProcessTree currently is supported only on Linux.
 Using ResourceCalculatorProcessTree : null
Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@7a94d3d0
MergerManager: memoryLimit=668309888, maxSingleShuffleLimit=167077472, mergeThreshold=441084544, ioSortFactor=10, memToMemMergeOutputsThreshold=10
attempt_local530807718_0002_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
Got 0 map completion events from 0
GetMapEventsThread about to sleep for 1000
LocalFetcher 2 going to fetch: attempt_local530807718_0002_m_000000_0
attempt_local530807718_0002_m_000000_0: Proceeding with shuffle since usedMemory (0) is lesser than memoryLimit (668309888).CommitMemory is (0)
localfetcher#2 about to shuffle output of map attempt_local530807718_0002_m_000000_0 decomp: 63 len: 67 to MEMORY
Read 63 bytes from map-output for attempt_local530807718_0002_m_000000_0
closeInMemoryFile -> map-output of size: 63, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->63
map attempt_local530807718_0002_m_000000_0 done 1 / 1 copied.
EventFetcher is interrupted.. Returning
1 / 1 copied.
finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
Merging 1 sorted segments
Down to the last merge-pass, with 1 segments left of total size: 57 bytes
Merged 1 segments, 63 bytes to disk to satisfy reduce memory limit
Disk file: /tmp/hadoop-michaeljones/mapred/local/localRunner/michaeljones/jobcache/job_local530807718_0002/attempt_local530807718_0002_r_000000_0/output/map_0.out.merged Length is 67
Merging 1 files, 67 bytes from disk
Merging 0 segments, 0 bytes from memory into reduce
Merging 1 sorted segments
Down to the last merge-pass, with 1 segments left of total size: 57 bytes
1 / 1 copied.
/user/michaeljones/wcOutput/_temporary/0/_temporary/attempt_local530807718_0002_r_000000_0/part-r-00000: masked=rw-r--r--
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones sending #37
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones got value #37
Call: create took 7ms
computePacketChunkSize: src=/user/michaeljones/wcOutput/_temporary/0/_temporary/attempt_local530807718_0002_r_000000_0/part-r-00000, chunkSize=516, chunksPerPacket=126, packetSize=65016
DFSClient writeChunk allocating new packet seqno=0, src=/user/michaeljones/wcOutput/_temporary/0/_temporary/attempt_local530807718_0002_r_000000_0/part-r-00000, packetSize=65016, chunksPerPacket=126, bytesCurBlock=0
Queued packet 0
Queued packet 1
Waiting for ack for: 1
Allocating new block
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones sending #38
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones got value #38
Call: addBlock took 5ms
pipeline = DatanodeInfoWithStorage[127.0.0.1:50010,DS-b42c5705-9ba4-4b14-b00b-f9194bb036f0,DISK]
Connecting to datanode 127.0.0.1:50010
Send buf size 131072
SASL client skipping handshake in unsecured configuration for addr = /127.0.0.1, datanodeId = DatanodeInfoWithStorage[127.0.0.1:50010,DS-b42c5705-9ba4-4b14-b00b-f9194bb036f0,DISK]
DataStreamer block BP-1045030256-10.0.0.2-1433119149314:blk_1073742217_1394 sending packet packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 41
DFSClient seqno: 0 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
DataStreamer block BP-1045030256-10.0.0.2-1433119149314:blk_1073742217_1394 sending packet packet seqno: 1 offsetInBlock: 41 lastPacketInBlock: true lastByteOffsetInBlock: 41
DFSClient seqno: 1 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
Closing old block BP-1045030256-10.0.0.2-1433119149314:blk_1073742217_1394
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones sending #39
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones got value #39
Call: complete took 4ms
Task:attempt_local530807718_0002_r_000000_0 is done. And is in the process of committing
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones sending #40
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones got value #40
Call: getFileInfo took 3ms
1 / 1 copied.
Task attempt_local530807718_0002_r_000000_0 is allowed to commit now
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones sending #41
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones got value #41
Call: getFileInfo took 2ms
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones sending #42
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones got value #42
Call: getFileInfo took 2ms
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones sending #43
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones got value #43
Call: rename took 4ms
Saved output of task 'attempt_local530807718_0002_r_000000_0' to hdfs://localhost:9000/user/michaeljones/wcOutput/_temporary/0/task_local530807718_0002_r_000000
reduce > reduce
Task 'attempt_local530807718_0002_r_000000_0' done.
Finishing task: attempt_local530807718_0002_r_000000_0
reduce task executor complete.
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones sending #44
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones got value #44
Call: getListing took 2ms
Merging data from FileStatus{path=hdfs://localhost:9000/user/michaeljones/wcOutput/_temporary/0/task_local530807718_0002_r_000000; isDirectory=true; modification_time=1434151726361; access_time=0; owner=michaeljones; group=supergroup; permission=rwxr-xr-x; isSymlink=false} to hdfs://localhost:9000/user/michaeljones/wcOutput
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones sending #45
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones got value #45
Call: getFileInfo took 2ms
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones sending #46
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones got value #46
Call: getListing took 2ms
Merging data from FileStatus{path=hdfs://localhost:9000/user/michaeljones/wcOutput/_temporary/0/task_local530807718_0002_r_000000/part-r-00000; isDirectory=false; length=41; replication=1; blocksize=134217728; modification_time=1434151726387; access_time=1434151726361; owner=michaeljones; group=supergroup; permission=rw-r--r--; isSymlink=false} to hdfs://localhost:9000/user/michaeljones/wcOutput/part-r-00000
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones sending #47
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones got value #47
Call: getFileInfo took 2ms
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones sending #48
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones got value #48
Call: rename took 3ms
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones sending #49
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones got value #49
Call: delete took 3ms
/user/michaeljones/wcOutput/_SUCCESS: masked=rw-r--r--
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones sending #50
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones got value #50
Call: create took 6ms
computePacketChunkSize: src=/user/michaeljones/wcOutput/_SUCCESS, chunkSize=516, chunksPerPacket=126, packetSize=65016
Waiting for ack for: -1
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones sending #51
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones got value #51
Call: complete took 3ms
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.fs.FileContext.getAbstractFileSystem(FileContext.java:331)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
Job job_local530807718_0002 running in uber mode : false
 map 100% reduce 100%
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.getTaskCompletionEvents(Job.java:670)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.getTaskCompletionEvents(Job.java:670)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
Job job_local530807718_0002 completed successfully
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.getCounters(Job.java:758)
Counters: 35
	File System Counters
		FILE: Number of bytes read=1206
		FILE: Number of bytes written=1128413
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=240
		HDFS: Number of bytes written=163
		HDFS: Number of read operations=45
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=24
	Map-Reduce Framework
		Map input records=2
		Map output records=8
		Map output bytes=82
		Map output materialized bytes=67
		Input split bytes=112
		Combine input records=8
		Combine output records=5
		Reduce input groups=5
		Reduce shuffle bytes=67
		Reduce input records=5
		Reduce output records=5
		Spilled Records=10
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=12
		Total committed heap usage (bytes)=546308096
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=50
	File Output Format Counters 
		Bytes Written=41
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
RunJobAnalysisAsync
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones sending #52
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones got value #52
Call: getFileInfo took 2ms
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones sending #53
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones got value #53
Call: delete took 5ms
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.connect(Job.java:1256)
Trying ClientProtocolProvider : org.apache.hadoop.mapred.LocalClientProtocolProvider
Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
Picked org.apache.hadoop.mapred.LocalClientProtocolProvider as the ClientProtocolProvider
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Cluster.getFileSystem(Cluster.java:162)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.submit(Job.java:1287)
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones sending #54
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones got value #54
Call: getFileInfo took 2ms
Configuring job job_local222123804_0003 with file:/tmp/hadoop-michaeljones/mapred/staging/michaeljones222123804/.staging/job_local222123804_0003 as the submit dir
adding the following namenodes' delegation tokens:[hdfs://localhost:9000]
Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
default FileSystem: file:///
No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
Creating splits at file:/tmp/hadoop-michaeljones/mapred/staging/michaeljones222123804/.staging/job_local222123804_0003
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones sending #55
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones got value #55
Call: getFileInfo took 2ms
Time taken to get FileStatuses: 3
Total input paths to process : 1
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones sending #56
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones got value #56
Call: getBlockLocations took 3ms
Total # of splits generated by getSplits: 1, TimeTaken: 8
number of splits:1
Handling deprecation for all properties in config...
Handling deprecation for mapreduce.jobtracker.address
Handling deprecation for yarn.resourcemanager.scheduler.monitor.policies
Handling deprecation for dfs.namenode.resource.check.interval
Handling deprecation for mapreduce.jobhistory.client.thread-count
Handling deprecation for yarn.app.mapreduce.am.containerlauncher.threadpool-initial-size
Handling deprecation for mapred.child.java.opts
Handling deprecation for mapreduce.jobtracker.retiredjobs.cache.size
Handling deprecation for dfs.client.https.need-auth
Handling deprecation for yarn.admin.acl
Handling deprecation for yarn.app.mapreduce.am.job.committer.cancel-timeout
Handling deprecation for mapreduce.job.emit-timeline-data
Handling deprecation for fs.ftp.host.port
Handling deprecation for dfs.namenode.avoid.read.stale.datanode
Handling deprecation for dfs.journalnode.rpc-address
Handling deprecation for mapreduce.job.end-notification.retry.attempts
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.ttl-interval-ms
Handling deprecation for yarn.resourcemanager.leveldb-state-store.path
Handling deprecation for mapred.mapper.new-api
Handling deprecation for yarn.ipc.rpc.class
Handling deprecation for ipc.client.connection.maxidletime
Handling deprecation for yarn.nodemanager.process-kill-wait.ms
Handling deprecation for mapreduce.cluster.acls.enabled
Handling deprecation for mapreduce.jobtracker.handler.count
Handling deprecation for io.map.index.interval
Handling deprecation for dfs.namenode.https-address
Handling deprecation for mapreduce.task.profile.reduces
Handling deprecation for fs.s3n.multipart.uploads.enabled
Handling deprecation for io.seqfile.sorter.recordlimit
Handling deprecation for mapreduce.job.ubertask.maxmaps
Handling deprecation for mapreduce.tasktracker.tasks.sleeptimebeforesigkill
Handling deprecation for hadoop.util.hash.type
Handling deprecation for dfs.namenode.replication.min
Handling deprecation for yarn.nodemanager.container-manager.thread-count
Handling deprecation for mapreduce.jobtracker.jobhistory.block.size
Handling deprecation for dfs.namenode.fs-limits.min-block-size
Handling deprecation for mapreduce.app-submission.cross-platform
Handling deprecation for fs.AbstractFileSystem.file.impl
Handling deprecation for net.topology.script.number.args
Handling deprecation for yarn.resourcemanager.container-tokens.master-key-rolling-interval-secs
Handling deprecation for mapreduce.map.output.compress.codec
Handling deprecation for mapreduce.job.reducer.preempt.delay.sec
Handling deprecation for s3native.bytes-per-checksum
Handling deprecation for dfs.namenode.path.based.cache.block.map.allocation.percent
Handling deprecation for yarn.nodemanager.windows-container.memory-limit.enabled
Handling deprecation for mapreduce.input.fileinputformat.split.minsize
Handling deprecation for hadoop.security.group.mapping
Handling deprecation for mapreduce.jobtracker.system.dir
Handling deprecation for mapreduce.job.end-notification.max.attempts
Handling deprecation for mapreduce.reduce.markreset.buffer.percent
Handling deprecation for dfs.datanode.cache.revocation.polling.ms
Handling deprecation for mapreduce.reduce.speculative
Handling deprecation for yarn.nodemanager.localizer.cache.cleanup.interval-ms
Handling deprecation for dfs.namenode.lazypersist.file.scrub.interval.sec
Handling deprecation for fs.s3a.threads.core
Handling deprecation for mapreduce.jobhistory.recovery.store.fs.uri
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.start-time-read-cache-size
Handling deprecation for hadoop.registry.zk.retry.interval.ms
Handling deprecation for yarn.nodemanager.keytab
Handling deprecation for dfs.namenode.replication.interval
Handling deprecation for yarn.resourcemanager.admin.address
Handling deprecation for mapreduce.job.maps
Handling deprecation for nfs.dump.dir
Handling deprecation for mapreduce.job.user.name
Handling deprecation for mapreduce.jobtracker.maxtasks.perjob
Handling deprecation for mapreduce.job.ubertask.enable
Handling deprecation for mapreduce.job.reduce.class
Handling deprecation for yarn.nodemanager.delete.debug-delay-sec
Handling deprecation for yarn.timeline-service.ttl-enable
Handling deprecation for yarn.resourcemanager.fs.state-store.retry-policy-spec
Handling deprecation for mapreduce.reduce.skip.maxgroups
Handling deprecation for dfs.client.use.datanode.hostname
Handling deprecation for fs.trash.interval
Handling deprecation for mapreduce.job.name
Handling deprecation for mapreduce.am.max-attempts
Handling deprecation for mapreduce.jobtracker.heartbeats.in.second
Handling deprecation for yarn.resourcemanager.zk-num-retries
Handling deprecation for s3.blocksize
Handling deprecation for dfs.datanode.data.dir
Handling deprecation for mapreduce.jobtracker.persist.jobstatus.active
Handling deprecation for mapreduce.reduce.shuffle.parallelcopies
Handling deprecation for fs.s3.buffer.dir
Handling deprecation for mapreduce.jobhistory.done-dir
Handling deprecation for hadoop.security.instrumentation.requires.admin
Handling deprecation for hadoop.registry.zk.retry.ceiling.ms
Handling deprecation for nfs.rtmax
Handling deprecation for dfs.datanode.data.dir.perm
Handling deprecation for yarn.resourcemanager.container.liveness-monitor.interval-ms
Handling deprecation for yarn.nodemanager.env-whitelist
Handling deprecation for dfs.namenode.backup.address
Handling deprecation for dfs.namenode.xattrs.enabled
Handling deprecation for dfs.datanode.readahead.bytes
Handling deprecation for mapreduce.jobhistory.cleaner.enable
Handling deprecation for dfs.client.block.write.retries
Handling deprecation for mapreduce.tasktracker.http.address
Handling deprecation for yarn.nodemanager.linux-container-executor.cgroups.hierarchy
Handling deprecation for ha.failover-controller.graceful-fence.connection.retries
Handling deprecation for yarn.resourcemanager.recovery.enabled
Handling deprecation for yarn.app.mapreduce.am.container.log.backups
Handling deprecation for dfs.namenode.safemode.threshold-pct
Handling deprecation for yarn.nodemanager.disk-health-checker.interval-ms
Handling deprecation for hadoop.security.java.secure.random.algorithm
Handling deprecation for dfs.namenode.list.cache.directives.num.responses
Handling deprecation for dfs.datanode.dns.nameserver
Handling deprecation for mapreduce.cluster.temp.dir
Handling deprecation for fs.s3a.max.total.tasks
Handling deprecation for mapreduce.reduce.maxattempts
Handling deprecation for mapreduce.client.submit.file.replication
Handling deprecation for mapreduce.shuffle.port
Handling deprecation for yarn.resourcemanager.resource-tracker.client.thread-count
Handling deprecation for dfs.namenode.replication.considerLoad
Handling deprecation for dfs.namenode.edits.journal-plugin.qjournal
Handling deprecation for dfs.client.write.exclude.nodes.cache.expiry.interval.millis
Handling deprecation for yarn.nodemanager.delete.thread-count
Handling deprecation for dfs.client.mmap.cache.timeout.ms
Handling deprecation for yarn.nodemanager.admin-env
Handling deprecation for io.skip.checksum.errors
Handling deprecation for yarn.timeline-service.hostname
Handling deprecation for yarn.resourcemanager.proxy-user-privileges.enabled
Handling deprecation for mapreduce.job.speculative.speculative-cap-total-tasks
Handling deprecation for yarn.acl.enable
Handling deprecation for fs.s3a.fast.upload
Handling deprecation for file.blocksize
Handling deprecation for mapreduce.job.speculative.slowtaskthreshold
Handling deprecation for ftp.replication
Handling deprecation for yarn.sharedcache.cleaner.initial-delay-mins
Handling deprecation for s3native.client-write-packet-size
Handling deprecation for hadoop.rpc.socket.factory.class.default
Handling deprecation for file.bytes-per-checksum
Handling deprecation for dfs.datanode.slow.io.warning.threshold.ms
Handling deprecation for io.seqfile.lazydecompress
Handling deprecation for mapreduce.task.skip.start.attempts
Handling deprecation for dfs.namenode.reject-unresolved-dn-topology-mapping
Handling deprecation for hadoop.common.configuration.version
Handling deprecation for yarn.resourcemanager.client.thread-count
Handling deprecation for dfs.datanode.drop.cache.behind.reads
Handling deprecation for yarn.sharedcache.admin.address
Handling deprecation for mapreduce.job.output.value.class
Handling deprecation for mapreduce.output.fileoutputformat.outputdir
Handling deprecation for mapreduce.jobtracker.taskcache.levels
Handling deprecation for yarn.nodemanager.linux-container-executor.nonsecure-mode.user-pattern
Handling deprecation for yarn.resourcemanager.zk-timeout-ms
Handling deprecation for yarn.resourcemanager.max-completed-applications
Handling deprecation for mapreduce.job.jvm.numtasks
Handling deprecation for yarn.sharedcache.cleaner.period-mins
Handling deprecation for mapreduce.jobtracker.tasktracker.maxblacklists
Handling deprecation for dfs.namenode.top.num.users
Handling deprecation for yarn.nodemanager.linux-container-executor.cgroups.mount
Handling deprecation for yarn.sharedcache.checksum.algo.impl
Handling deprecation for mapreduce.job.end-notification.max.retry.interval
Handling deprecation for mapreduce.job.acl-view-job
Handling deprecation for mapreduce.job.classloader
Handling deprecation for yarn.log-aggregation-enable
Handling deprecation for mapreduce.reduce.shuffle.fetch.retry.interval-ms
Handling deprecation for yarn.resourcemanager.nodemanager.minimum.version
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.size
Handling deprecation for yarn.app.mapreduce.am.job.task.listener.thread-count
Handling deprecation for yarn.app.mapreduce.am.resource.cpu-vcores
Handling deprecation for dfs.namenode.edit.log.autoroll.check.interval.ms
Handling deprecation for mapreduce.output.fileoutputformat.compress.type
Handling deprecation for hadoop.hdfs.configuration.version
Handling deprecation for hadoop.security.group.mapping.ldap.search.attr.member
Handling deprecation for yarn.nodemanager.log.retain-seconds
Handling deprecation for yarn.nodemanager.local-cache.max-files-per-directory
Handling deprecation for mapreduce.job.end-notification.retry.interval
Handling deprecation for hadoop.ssl.client.conf
Handling deprecation for yarn.sharedcache.root-dir
Handling deprecation for dfs.journalnode.https-address
Handling deprecation for mapreduce.reduce.shuffle.fetch.retry.timeout-ms
Handling deprecation for dfs.bytes-per-checksum
Handling deprecation for dfs.namenode.max.objects
Handling deprecation for mapreduce.tasktracker.instrumentation
Handling deprecation for dfs.datanode.max.transfer.threads
Handling deprecation for dfs.block.access.key.update.interval
Handling deprecation for mapreduce.jobtracker.jobhistory.task.numberprogresssplits
Handling deprecation for mapreduce.map.memory.mb
Handling deprecation for ha.failover-controller.new-active.rpc-timeout.ms
Handling deprecation for hadoop.ssl.hostname.verifier
Handling deprecation for dfs.client.read.shortcircuit
Handling deprecation for dfs.datanode.hdfs-blocks-metadata.enabled
Handling deprecation for mapreduce.tasktracker.healthchecker.interval
Handling deprecation for dfs.image.transfer.chunksize
Handling deprecation for mapreduce.tasktracker.taskmemorymanager.monitoringinterval
Handling deprecation for dfs.client.https.keystore.resource
Handling deprecation for yarn.resourcemanager.connect.retry-interval.ms
Handling deprecation for yarn.timeline-service.webapp.address
Handling deprecation for s3native.blocksize
Handling deprecation for yarn.scheduler.minimum-allocation-mb
Handling deprecation for yarn.sharedcache.cleaner.resource-sleep-ms
Handling deprecation for net.topology.impl
Handling deprecation for dfs.client.failover.sleep.base.millis
Handling deprecation for dfs.permissions.superusergroup
Handling deprecation for io.seqfile.compress.blocksize
Handling deprecation for hadoop.registry.zk.retry.times
Handling deprecation for fs.AbstractFileSystem.ftp.impl
Handling deprecation for dfs.namenode.checkpoint.edits.dir
Handling deprecation for mapreduce.job.running.reduce.limit
Handling deprecation for dfs.blockreport.initialDelay
Handling deprecation for dfs.namenode.heartbeat.recheck-interval
Handling deprecation for dfs.namenode.safemode.extension
Handling deprecation for yarn.scheduler.maximum-allocation-mb
Handling deprecation for mapreduce.job.reduce.shuffle.consumer.plugin.class
Handling deprecation for yarn.nodemanager.vmem-check-enabled
Handling deprecation for mapreduce.task.io.sort.factor
Handling deprecation for mapreduce.jobtracker.persist.jobstatus.dir
Handling deprecation for dfs.client.failover.sleep.max.millis
Handling deprecation for dfs.namenode.delegation.key.update-interval
Handling deprecation for hadoop.rpc.protection
Handling deprecation for fs.permissions.umask-mode
Handling deprecation for fs.s3.sleepTimeSeconds
Handling deprecation for ha.health-monitor.rpc-timeout.ms
Handling deprecation for hadoop.http.staticuser.user
Handling deprecation for fs.s3a.connection.maximum
Handling deprecation for yarn.nodemanager.linux-container-executor.nonsecure-mode.limit-users
Handling deprecation for fs.s3a.paging.maximum
Handling deprecation for fs.AbstractFileSystem.viewfs.impl
Handling deprecation for fs.ftp.host
Handling deprecation for yarn.nodemanager.linux-container-executor.nonsecure-mode.local-user
Handling deprecation for fs.s3a.impl
Handling deprecation for hadoop.http.authentication.kerberos.keytab
Handling deprecation for dfs.namenode.fs-limits.max-blocks-per-file
Handling deprecation for mapreduce.tasktracker.http.threads
Handling deprecation for mapreduce.tasktracker.dns.nameserver
Handling deprecation for yarn.resourcemanager.am-rm-tokens.master-key-rolling-interval-secs
Handling deprecation for dfs.client.block.write.replace-datanode-on-failure.enable
Handling deprecation for io.compression.codec.bzip2.library
Handling deprecation for mapreduce.map.skip.maxrecords
Handling deprecation for dfs.client.use.legacy.blockreader.local
Handling deprecation for dfs.namenode.checkpoint.dir
Handling deprecation for dfs.namenode.top.windows.minutes
Handling deprecation for mapreduce.job.maxtaskfailures.per.tracker
Handling deprecation for net.topology.node.switch.mapping.impl
Handling deprecation for mapreduce.shuffle.max.connections
Handling deprecation for mapreduce.jobhistory.loadedjobs.cache.size
Handling deprecation for dfs.storage.policy.enabled
Handling deprecation for yarn.client.application-client-protocol.poll-interval-ms
Handling deprecation for yarn.nodemanager.localizer.address
Handling deprecation for dfs.namenode.list.cache.pools.num.responses
Handling deprecation for nfs.server.port
Handling deprecation for mapreduce.client.output.filter
Handling deprecation for yarn.timeline-service.client.best-effort
Handling deprecation for ha.zookeeper.parent-znode
Handling deprecation for mapreduce.jobtracker.persist.jobstatus.hours
Handling deprecation for yarn.sharedcache.admin.thread-count
Handling deprecation for yarn.nodemanager.resource.cpu-vcores
Handling deprecation for dfs.datanode.block-pinning.enabled
Handling deprecation for mapreduce.jobhistory.http.policy
Handling deprecation for yarn.resourcemanager.webapp.delegation-token-auth-filter.enabled
Handling deprecation for mapreduce.job.speculative.retry-after-no-speculate
Handling deprecation for fs.s3a.attempts.maximum
Handling deprecation for s3native.stream-buffer-size
Handling deprecation for io.seqfile.local.dir
Handling deprecation for yarn.log-aggregation.retain-check-interval-seconds
Handling deprecation for fs.s3n.multipart.copy.block.size
Handling deprecation for dfs.encrypt.data.transfer.cipher.key.bitlength
Handling deprecation for dfs.datanode.sync.behind.writes
Handling deprecation for yarn.resourcemanager.zk-acl
Handling deprecation for hadoop.ssl.keystores.factory.class
Handling deprecation for mapreduce.job.split.metainfo.maxsize
Handling deprecation for fs.s3.maxRetries
Handling deprecation for hadoop.security.random.device.file.path
Handling deprecation for yarn.client.nodemanager-connect.max-wait-ms
Handling deprecation for dfs.namenode.stale.datanode.interval
Handling deprecation for mapreduce.task.io.sort.mb
Handling deprecation for yarn.resourcemanager.zk-state-store.parent-path
Handling deprecation for yarn.app.mapreduce.client-am.ipc.max-retries
Handling deprecation for fs.client.resolve.remote.symlinks
Handling deprecation for yarn.nodemanager.linux-container-executor.cgroups.strict-resource-usage
Handling deprecation for hadoop.ssl.enabled.protocols
Handling deprecation for mapreduce.reduce.cpu.vcores
Handling deprecation for yarn.client.failover-retries
Handling deprecation for mapreduce.jobhistory.address
Handling deprecation for hadoop.ssl.enabled
Handling deprecation for dfs.replication.max
Handling deprecation for dfs.namenode.name.dir
Handling deprecation for dfs.datanode.https.address
Handling deprecation for ipc.client.kill.max
Handling deprecation for mapreduce.job.committer.setup.cleanup.needed
Handling deprecation for dfs.client.domain.socket.data.traffic
Handling deprecation for yarn.nodemanager.localizer.cache.target-size-mb
Handling deprecation for yarn.resourcemanager.admin.client.thread-count
Handling deprecation for dfs.block.access.token.enable
Handling deprecation for mapreduce.job.speculative.retry-after-speculate
Handling deprecation for dfs.datanode.address
Handling deprecation for mapreduce.jobtracker.restart.recover
Handling deprecation for ipc.client.connect.max.retries
Handling deprecation for yarn.timeline-service.store-class
Handling deprecation for dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
Handling deprecation for hadoop.tmp.dir
Handling deprecation for dfs.datanode.handler.count
Handling deprecation for yarn.resourcemanager.ha.automatic-failover.embedded
Handling deprecation for yarn.timeline-service.ttl-ms
Handling deprecation for mapreduce.task.profile.map.params
Handling deprecation for yarn.resourcemanager.nodemanagers.heartbeat-interval-ms
Handling deprecation for mapreduce.map.speculative
Handling deprecation for yarn.timeline-service.recovery.enabled
Handling deprecation for mapreduce.job.map.class
Handling deprecation for dfs.namenode.resource.checked.volumes.minimum
Handling deprecation for yarn.nodemanager.recovery.dir
Handling deprecation for mapreduce.job.counters.max
Handling deprecation for yarn.resourcemanager.keytab
Handling deprecation for dfs.namenode.max.extra.edits.segments.retained
Handling deprecation for dfs.webhdfs.user.provider.user.pattern
Handling deprecation for dfs.client.mmap.enabled
Handling deprecation for mapreduce.map.log.level
Handling deprecation for dfs.client.file-block-storage-locations.timeout.millis
Handling deprecation for yarn.client.max-cached-nodemanagers-proxies
Handling deprecation for yarn.app.mapreduce.am.scheduler.heartbeat.interval-ms
Handling deprecation for hadoop.fuse.timer.period
Handling deprecation for fs.trash.checkpoint.interval
Handling deprecation for yarn.sharedcache.app-checker.class
Handling deprecation for dfs.journalnode.http-address
Handling deprecation for yarn.app.mapreduce.am.staging-dir
Handling deprecation for mapreduce.tasktracker.local.dir.minspacestart
Handling deprecation for yarn.nm.liveness-monitor.expiry-interval-ms
Handling deprecation for ha.health-monitor.check-interval.ms
Handling deprecation for mapreduce.reduce.shuffle.merge.percent
Handling deprecation for dfs.namenode.retrycache.heap.percent
Handling deprecation for yarn.nodemanager.docker-container-executor.exec-name
Handling deprecation for ipc.client.connect.timeout
Handling deprecation for yarn.resourcemanager.fs.state-store.retry-interval-ms
Handling deprecation for mapreduce.output.fileoutputformat.compress
Handling deprecation for yarn.nodemanager.local-dirs
Handling deprecation for yarn.nodemanager.recovery.enabled
Handling deprecation for io.native.lib.available
Handling deprecation for yarn.sharedcache.store.in-memory.staleness-period-mins
Handling deprecation for yarn.resourcemanager.am.max-attempts
Handling deprecation for s3.replication
Handling deprecation for mapreduce.input.fileinputformat.inputdir
Handling deprecation for fs.AbstractFileSystem.har.impl
Handling deprecation for dfs.image.compress
Handling deprecation for mapreduce.job.running.map.limit
Handling deprecation for mapreduce.reduce.input.buffer.percent
Handling deprecation for yarn.nodemanager.webapp.address
Handling deprecation for dfs.datanode.available-space-volume-choosing-policy.balanced-space-preference-fraction
Handling deprecation for dfs.namenode.edit.log.autoroll.multiplier.threshold
Handling deprecation for hadoop.security.group.mapping.ldap.ssl
Handling deprecation for dfs.namenode.checkpoint.check.period
Handling deprecation for fs.defaultFS
Handling deprecation for fs.s3a.multipart.size
Handling deprecation for dfs.client.slow.io.warning.threshold.ms
Handling deprecation for yarn.app.mapreduce.am.job.committer.commit-window
Handling deprecation for hadoop.security.group.mapping.ldap.search.attr.group.name
Handling deprecation for yarn.nodemanager.disk-health-checker.max-disk-utilization-per-disk-percentage
Handling deprecation for yarn.nodemanager.container-monitor.procfs-tree.smaps-based-rss.enabled
Handling deprecation for mapreduce.job.submithostname
Handling deprecation for mapreduce.map.sort.spill.percent
Handling deprecation for hadoop.security.crypto.codec.classes.aes.ctr.nopadding
Handling deprecation for dfs.namenode.http-address
Handling deprecation for hadoop.security.groups.negative-cache.secs
Handling deprecation for hadoop.ssl.server.conf
Handling deprecation for mapreduce.ifile.readahead
Handling deprecation for s3native.replication
Handling deprecation for yarn.client.nodemanager-client-async.thread-pool-max-size
Handling deprecation for mapreduce.jobtracker.staging.root.dir
Handling deprecation for mapreduce.jobhistory.admin.address
Handling deprecation for dfs.namenode.startup.delay.block.deletion.sec
Handling deprecation for yarn.nodemanager.health-checker.interval-ms
Handling deprecation for dfs.namenode.checkpoint.max-retries
Handling deprecation for s3.stream-buffer-size
Handling deprecation for ftp.client-write-packet-size
Handling deprecation for dfs.datanode.fsdatasetcache.max.threads.per.volume
Handling deprecation for mapreduce.output.fileoutputformat.compress.codec
Handling deprecation for yarn.timeline-service.keytab
Handling deprecation for yarn.sharedcache.store.in-memory.initial-delay-mins
Handling deprecation for mapreduce.jobhistory.webapp.address
Handling deprecation for mapreduce.task.userlog.limit.kb
Handling deprecation for mapreduce.reduce.shuffle.fetch.retry.enabled
Handling deprecation for yarn.app.mapreduce.task.container.log.backups
Handling deprecation for dfs.heartbeat.interval
Handling deprecation for ha.zookeeper.session-timeout.ms
Handling deprecation for fs.s3a.connection.ssl.enabled
Handling deprecation for yarn.sharedcache.webapp.address
Handling deprecation for hadoop.http.authentication.signature.secret.file
Handling deprecation for hadoop.fuse.connection.timeout
Handling deprecation for mapreduce.input.fileinputformat.numinputfiles
Handling deprecation for yarn.nodemanager.log-aggregation.compression-type
Handling deprecation for ipc.server.max.connections
Handling deprecation for yarn.resourcemanager.work-preserving-recovery.scheduling-wait-ms
Handling deprecation for yarn.nodemanager.log-dirs
Handling deprecation for yarn.app.mapreduce.am.resource.mb
Handling deprecation for hadoop.security.groups.cache.secs
Handling deprecation for mapreduce.job.speculative.minimum-allowed-tasks
Handling deprecation for yarn.nodemanager.container-monitor.interval-ms
Handling deprecation for dfs.datanode.cache.revocation.timeout.ms
Handling deprecation for mapreduce.jobhistory.recovery.store.class
Handling deprecation for mapreduce.task.combine.progress.records
Handling deprecation for s3.client-write-packet-size
Handling deprecation for mapreduce.jobtracker.instrumentation
Handling deprecation for dfs.replication
Handling deprecation for mapreduce.shuffle.transfer.buffer.size
Handling deprecation for hadoop.security.group.mapping.ldap.directory.search.timeout
Handling deprecation for dfs.datanode.available-space-volume-choosing-policy.balanced-space-threshold
Handling deprecation for hadoop.work.around.non.threadsafe.getpwuid
Handling deprecation for yarn.app.mapreduce.client-am.ipc.max-retries-on-timeouts
Handling deprecation for yarn.nodemanager.address
Handling deprecation for mapreduce.tasktracker.taskcontroller
Handling deprecation for mapreduce.tasktracker.indexcache.mb
Handling deprecation for yarn.scheduler.maximum-allocation-vcores
Handling deprecation for mapreduce.job.reduces
Handling deprecation for yarn.nodemanager.sleep-delay-before-sigkill.ms
Handling deprecation for yarn.timeline-service.address
Handling deprecation for yarn.resourcemanager.configuration.provider-class
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.expiry
Handling deprecation for yarn.sharedcache.enabled
Handling deprecation for tfile.io.chunk.size
Handling deprecation for mapreduce.job.acl-modify-job
Handling deprecation for hadoop.registry.zk.session.timeout.ms
Handling deprecation for fs.automatic.close
Handling deprecation for ha.health-monitor.sleep-after-disconnect.ms
Handling deprecation for mapreduce.tasktracker.reduce.tasks.maximum
Handling deprecation for mapreduce.input.fileinputformat.list-status.num-threads
Handling deprecation for dfs.datanode.directoryscan.threads
Handling deprecation for dfs.datanode.directoryscan.interval
Handling deprecation for dfs.namenode.acls.enabled
Handling deprecation for dfs.client.short.circuit.replica.stale.threshold.ms
Handling deprecation for hadoop.http.authentication.token.validity
Handling deprecation for fs.s3.block.size
Handling deprecation for ha.failover-controller.graceful-fence.rpc-timeout.ms
Handling deprecation for mapreduce.tasktracker.local.dir.minspacekill
Handling deprecation for dfs.namenode.resource.du.reserved
Handling deprecation for mapreduce.jobhistory.cleaner.interval-ms
Handling deprecation for dfs.namenode.datanode.registration.ip-hostname-check
Handling deprecation for mapreduce.jobhistory.intermediate-done-dir
Handling deprecation for mapreduce.jobtracker.http.address
Handling deprecation for dfs.namenode.backup.http-address
Handling deprecation for dfs.namenode.edits.noeditlogchannelflush
Handling deprecation for mapreduce.reduce.shuffle.input.buffer.percent
Handling deprecation for mapreduce.map.maxattempts
Handling deprecation for yarn.http.policy
Handling deprecation for dfs.namenode.audit.loggers
Handling deprecation for hadoop.security.groups.cache.warn.after.ms
Handling deprecation for io.serializations
Handling deprecation for mapreduce.tasktracker.outofband.heartbeat
Handling deprecation for mapreduce.reduce.shuffle.read.timeout
Handling deprecation for hadoop.security.crypto.buffer.size
Handling deprecation for mapreduce.reduce.skip.proc.count.autoincr
Handling deprecation for mapreduce.ifile.readahead.bytes
Handling deprecation for dfs.http.policy
Handling deprecation for hadoop.registry.secure
Handling deprecation for dfs.namenode.safemode.min.datanodes
Handling deprecation for dfs.client.file-block-storage-locations.num-threads
Handling deprecation for mapreduce.cluster.local.dir
Handling deprecation for mapreduce.tasktracker.report.address
Handling deprecation for dfs.namenode.secondary.https-address
Handling deprecation for hadoop.kerberos.kinit.command
Handling deprecation for yarn.timeline-service.http-authentication.type
Handling deprecation for dfs.block.access.token.lifetime
Handling deprecation for dfs.webhdfs.enabled
Handling deprecation for dfs.namenode.delegation.token.max-lifetime
Handling deprecation for dfs.namenode.avoid.write.stale.datanode
Handling deprecation for dfs.datanode.drop.cache.behind.writes
Handling deprecation for yarn.log-aggregation.retain-seconds
Handling deprecation for mapreduce.job.complete.cancel.delegation.tokens
Handling deprecation for mapreduce.local.clientfactory.class.name
Handling deprecation for mapreduce.shuffle.connection-keep-alive.timeout
Handling deprecation for dfs.namenode.num.extra.edits.retained
Handling deprecation for yarn.scheduler.minimum-allocation-vcores
Handling deprecation for ipc.client.connect.max.retries.on.timeouts
Handling deprecation for yarn.timeline-service.client.retry-interval-ms
Handling deprecation for yarn.timeline-service.client.max-retries
Handling deprecation for fs.s3n.block.size
Handling deprecation for mapreduce.job.map.output.collector.class
Handling deprecation for ha.health-monitor.connect-retry-interval.ms
Handling deprecation for mapreduce.shuffle.max.threads
Handling deprecation for nfs.exports.allowed.hosts
Handling deprecation for dfs.client.mmap.cache.size
Handling deprecation for mapreduce.tasktracker.map.tasks.maximum
Handling deprecation for io.file.buffer.size
Handling deprecation for dfs.client.datanode-restart.timeout
Handling deprecation for io.mapfile.bloom.size
Handling deprecation for hadoop.security.kms.client.authentication.retry-count
Handling deprecation for dfs.namenode.checkpoint.txns
Handling deprecation for ipc.client.connect.retry.interval
Handling deprecation for dfs.client-write-packet-size
Handling deprecation for mapreduce.reduce.shuffle.connect.timeout
Handling deprecation for yarn.resourcemanager.fs.state-store.uri
Handling deprecation for fs.swift.impl
Handling deprecation for hadoop.registry.zk.connection.timeout.ms
Handling deprecation for mapred.queue.default.acl-administer-jobs
Handling deprecation for mapreduce.job.submithostaddress
Handling deprecation for dfs.cachereport.intervalMsec
Handling deprecation for yarn.app.mapreduce.shuffle.log.backups
Handling deprecation for yarn.app.mapreduce.am.container.log.limit.kb
Handling deprecation for yarn.nodemanager.resourcemanager.minimum.version
Handling deprecation for ftp.blocksize
Handling deprecation for yarn.resourcemanager.address
Handling deprecation for file.stream-buffer-size
Handling deprecation for yarn.resourcemanager.scheduler.monitor.enable
Handling deprecation for mapreduce.job.ubertask.maxreduces
Handling deprecation for nfs.allow.insecure.ports
Handling deprecation for yarn.sharedcache.nm.uploader.thread-count
Handling deprecation for ipc.client.idlethreshold
Handling deprecation for ftp.stream-buffer-size
Handling deprecation for yarn.sharedcache.client-server.address
Handling deprecation for dfs.client.failover.connection.retries.on.timeouts
Handling deprecation for dfs.namenode.replication.work.multiplier.per.iteration
Handling deprecation for hadoop.http.authentication.simple.anonymous.allowed
Handling deprecation for hadoop.security.authorization
Handling deprecation for yarn.client.nodemanager-connect.retry-interval-ms
Handling deprecation for yarn.am.liveness-monitor.expiry-interval-ms
Handling deprecation for fs.har.impl.disable.cache
Handling deprecation for yarn.nodemanager.linux-container-executor.resources-handler.class
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.read-cache-size
Handling deprecation for hadoop.security.authentication
Handling deprecation for dfs.image.compression.codec
Handling deprecation for mapreduce.task.files.preserve.failedtasks
Handling deprecation for dfs.client.read.shortcircuit.streams.cache.size
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.path
Handling deprecation for mapreduce.job.reduce.slowstart.completedmaps
Handling deprecation for mapreduce.jobhistory.minicluster.fixed.ports
Handling deprecation for file.replication
Handling deprecation for yarn.resourcemanager.ha.automatic-failover.enabled
Handling deprecation for mapreduce.job.userlog.retain.hours
Handling deprecation for mapreduce.jobhistory.joblist.cache.size
Handling deprecation for dfs.namenode.accesstime.precision
Handling deprecation for yarn.resourcemanager.work-preserving-recovery.enabled
Handling deprecation for dfs.namenode.fs-limits.max-xattrs-per-inode
Handling deprecation for io.mapfile.bloom.error.rate
Handling deprecation for yarn.resourcemanager.store.class
Handling deprecation for dfs.image.transfer.timeout
Handling deprecation for yarn.timeline-service.leveldb-state-store.path
Handling deprecation for nfs.wtmax
Handling deprecation for mapreduce.job.combine.class
Handling deprecation for dfs.namenode.support.allow.format
Handling deprecation for fs.s3a.multipart.purge
Handling deprecation for dfs.secondary.namenode.kerberos.internal.spnego.principal
Handling deprecation for fs.s3a.connection.establish.timeout
Handling deprecation for dfs.stream-buffer-size
Handling deprecation for dfs.namenode.invalidate.work.pct.per.iteration
Handling deprecation for yarn.nodemanager.container-executor.class
Handling deprecation for fs.s3a.multipart.purge.age
Handling deprecation for yarn.resourcemanager.scheduler.client.thread-count
Handling deprecation for dfs.namenode.top.enabled
Handling deprecation for yarn.app.mapreduce.shuffle.log.separate
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.low-watermark
Handling deprecation for fs.s3a.fast.buffer.size
Handling deprecation for hadoop.user.group.static.mapping.overrides
Handling deprecation for tfile.fs.input.buffer.size
Handling deprecation for dfs.client.cached.conn.retry
Handling deprecation for hadoop.http.authentication.type
Handling deprecation for dfs.namenode.list.encryption.zones.num.responses
Handling deprecation for mapreduce.map.cpu.vcores
Handling deprecation for dfs.namenode.path.based.cache.refresh.interval.ms
Handling deprecation for dfs.namenode.decommission.interval
Handling deprecation for dfs.namenode.fs-limits.max-directory-items
Handling deprecation for yarn.resourcemanager.zk-retry-interval-ms
Handling deprecation for ftp.bytes-per-checksum
Handling deprecation for dfs.ha.log-roll.period
Handling deprecation for dfs.user.home.dir.prefix
Handling deprecation for ipc.client.fallback-to-simple-auth-allowed
Handling deprecation for yarn.nodemanager.pmem-check-enabled
Handling deprecation for yarn.nodemanager.remote-app-log-dir
Handling deprecation for dfs.namenode.inotify.max.events.per.rpc
Handling deprecation for mapreduce.task.profile.maps
Handling deprecation for mapreduce.shuffle.ssl.file.buffer.size
Handling deprecation for mapreduce.tasktracker.healthchecker.script.timeout
Handling deprecation for yarn.timeline-service.webapp.https.address
Handling deprecation for yarn.nodemanager.resource.percentage-physical-cpu-limit
Handling deprecation for yarn.app.mapreduce.am.command-opts
Handling deprecation for dfs.namenode.fs-limits.max-xattr-size
Handling deprecation for dfs.datanode.http.address
Handling deprecation for dfs.namenode.blocks.per.postponedblocks.rescan
Handling deprecation for yarn.sharedcache.nm.uploader.replication.factor
Handling deprecation for hadoop.registry.zk.root
Handling deprecation for hadoop.jetty.logs.serve.aliases
Handling deprecation for yarn.client.failover-proxy-provider
Handling deprecation for mapreduce.jobhistory.admin.acl
Handling deprecation for yarn.app.mapreduce.am.hard-kill-timeout-ms
Handling deprecation for yarn.nodemanager.remote-app-log-dir-suffix
Handling deprecation for mapreduce.jobhistory.principal
Handling deprecation for yarn.resourcemanager.webapp.address
Handling deprecation for mapreduce.jobhistory.recovery.enable
Handling deprecation for yarn.sharedcache.store.in-memory.check-period-mins
Handling deprecation for nfs.mountd.port
Handling deprecation for mapreduce.reduce.merge.inmem.threshold
Handling deprecation for fs.df.interval
Handling deprecation for yarn.timeline-service.enabled
Handling deprecation for mapreduce.jobtracker.jobhistory.lru.cache.size
Handling deprecation for mapreduce.task.profile
Handling deprecation for mapreduce.job.output.key.class
Handling deprecation for yarn.nodemanager.hostname
Handling deprecation for dfs.namenode.num.checkpoints.retained
Handling deprecation for mapreduce.job.queuename
Handling deprecation for mapreduce.jobhistory.max-age-ms
Handling deprecation for mapreduce.job.token.tracking.ids.enabled
Handling deprecation for yarn.nodemanager.localizer.client.thread-count
Handling deprecation for yarn.sharedcache.uploader.server.thread-count
Handling deprecation for dfs.client.mmap.retry.timeout.ms
Handling deprecation for mapreduce.jobhistory.move.thread-count
Handling deprecation for dfs.permissions.enabled
Handling deprecation for dfs.blockreport.split.threshold
Handling deprecation for fs.AbstractFileSystem.hdfs.impl
Handling deprecation for dfs.datanode.balance.bandwidthPerSec
Handling deprecation for dfs.block.scanner.volume.bytes.per.second
Handling deprecation for hadoop.http.filter.initializers
Handling deprecation for yarn.timeline-service.http-authentication.simple.anonymous.allowed
Handling deprecation for dfs.default.chunk.view.size
Handling deprecation for yarn.sharedcache.client-server.thread-count
Handling deprecation for yarn.resourcemanager.resource-tracker.address
Handling deprecation for mapreduce.job.working.dir
Handling deprecation for mapreduce.jobhistory.datestring.cache.size
Handling deprecation for mapreduce.task.profile.params
Handling deprecation for dfs.namenode.decommission.blocks.per.interval
Handling deprecation for dfs.namenode.handler.count
Handling deprecation for dfs.image.transfer.bandwidthPerSec
Handling deprecation for rpc.metrics.quantile.enable
Handling deprecation for mapreduce.jobtracker.expire.trackers.interval
Handling deprecation for mapreduce.task.timeout
Handling deprecation for yarn.app.mapreduce.client.max-retries
Handling deprecation for yarn.nodemanager.resource.memory-mb
Handling deprecation for yarn.nodemanager.disk-health-checker.min-healthy-disks
Handling deprecation for dfs.datanode.failed.volumes.tolerated
Handling deprecation for yarn.timeline-service.handler-thread-count
Handling deprecation for ipc.server.listen.queue.size
Handling deprecation for fs.s3a.threads.max
Handling deprecation for yarn.resourcemanager.connect.max-wait.ms
Handling deprecation for mapreduce.fileoutputcommitter.algorithm.version
Handling deprecation for mapreduce.framework.name
Handling deprecation for mapreduce.map.skip.proc.count.autoincr
Handling deprecation for mapreduce.job.max.split.locations
Handling deprecation for yarn.resourcemanager.scheduler.class
Handling deprecation for yarn.resourcemanager.system-metrics-publisher.enabled
Handling deprecation for dfs.blocksize
Handling deprecation for yarn.sharedcache.nested-level
Handling deprecation for mapreduce.shuffle.connection-keep-alive.enable
Handling deprecation for fs.s3a.threads.keepalivetime
Handling deprecation for fs.s3a.connection.timeout
Handling deprecation for file.client-write-packet-size
Handling deprecation for ha.failover-controller.cli-check.rpc-timeout.ms
Handling deprecation for ha.zookeeper.acl
Handling deprecation for dfs.namenode.write.stale.datanode.ratio
Handling deprecation for dfs.encrypt.data.transfer
Handling deprecation for dfs.datanode.shared.file.descriptor.paths
Handling deprecation for mapreduce.input.lineinputformat.linespermap
Handling deprecation for yarn.resourcemanager.delayed.delegation-token.removal-interval-ms
Handling deprecation for yarn.nodemanager.localizer.fetch.thread-count
Handling deprecation for dfs.client.failover.max.attempts
Handling deprecation for yarn.resourcemanager.scheduler.address
Handling deprecation for dfs.client.read.shortcircuit.streams.cache.expiry.ms
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.start-time-write-cache-size
Handling deprecation for yarn.nodemanager.health-checker.script.timeout-ms
Handling deprecation for yarn.resourcemanager.fs.state-store.num-retries
Handling deprecation for hadoop.ssl.require.client.cert
Handling deprecation for hadoop.security.uid.cache.secs
Handling deprecation for mapreduce.jobhistory.keytab
Handling deprecation for dfs.client.read.shortcircuit.skip.checksum
Handling deprecation for yarn.resourcemanager.ha.automatic-failover.zk-base-path
Handling deprecation for mapreduce.shuffle.ssl.enabled
Handling deprecation for mapreduce.reduce.log.level
Handling deprecation for hadoop.registry.rm.enabled
Handling deprecation for mapreduce.tasktracker.dns.interface
Handling deprecation for yarn.resourcemanager.system-metrics-publisher.dispatcher.pool-size
Handling deprecation for mapreduce.job.speculative.speculative-cap-running-tasks
Handling deprecation for dfs.datanode.block.id.layout.upgrade.threads
Handling deprecation for dfs.datanode.use.datanode.hostname
Handling deprecation for dfs.client.context
Handling deprecation for yarn.resourcemanager.ha.enabled
Handling deprecation for mapred.reducer.new-api
Handling deprecation for dfs.namenode.delegation.token.renew-interval
Handling deprecation for dfs.blockreport.intervalMsec
Handling deprecation for fs.s3a.multipart.threshold
Handling deprecation for mapreduce.reduce.shuffle.memory.limit.percent
Handling deprecation for dfs.https.server.keystore.resource
Handling deprecation for io.map.index.skip
Handling deprecation for mapreduce.job.hdfs-servers
Handling deprecation for mapreduce.jobtracker.taskscheduler
Handling deprecation for dfs.namenode.kerberos.internal.spnego.principal
Handling deprecation for yarn.resourcemanager.state-store.max-completed-applications
Handling deprecation for mapreduce.map.output.compress
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.num.refill.threads
Handling deprecation for fs.s3n.multipart.uploads.block.size
Handling deprecation for mapreduce.task.merge.progress.records
Handling deprecation for dfs.datanode.dns.interface
Handling deprecation for map.sort.class
Handling deprecation for yarn.nodemanager.aux-services.mapreduce_shuffle.class
Handling deprecation for tfile.fs.output.buffer.size
Handling deprecation for fs.du.interval
Handling deprecation for dfs.client.failover.connection.retries
Handling deprecation for dfs.namenode.top.window.num.buckets
Handling deprecation for mapreduce.job.dir
Handling deprecation for fs.s3a.buffer.dir
Handling deprecation for mapreduce.reduce.shuffle.retry-delay.max.ms
Handling deprecation for yarn.sharedcache.uploader.server.address
Handling deprecation for mapreduce.client.progressmonitor.pollinterval
Handling deprecation for yarn.app.mapreduce.shuffle.log.limit.kb
Handling deprecation for dfs.datanode.max.locked.memory
Handling deprecation for dfs.namenode.retrycache.expirytime.millis
Handling deprecation for dfs.datanode.scan.period.hours
Handling deprecation for dfs.client.block.write.replace-datanode-on-failure.best-effort
Handling deprecation for mapreduce.jobhistory.move.interval-ms
Handling deprecation for dfs.ha.fencing.ssh.connect-timeout
Handling deprecation for yarn.nodemanager.log-aggregation.roll-monitoring-interval-seconds
Handling deprecation for dfs.namenode.fs-limits.max-component-length
Handling deprecation for hadoop.registry.zk.quorum
Handling deprecation for dfs.namenode.enable.retrycache
Handling deprecation for dfs.datanode.du.reserved
Handling deprecation for yarn.timeline-service.state-store-class
Handling deprecation for dfs.datanode.ipc.address
Handling deprecation for hadoop.registry.system.acls
Handling deprecation for dfs.client.block.write.replace-datanode-on-failure.policy
Handling deprecation for dfs.namenode.path.based.cache.retry.interval.ms
Handling deprecation for hadoop.security.crypto.cipher.suite
Handling deprecation for dfs.ha.tail-edits.period
Handling deprecation for mapreduce.task.profile.reduce.params
Handling deprecation for hadoop.registry.jaas.context
Handling deprecation for yarn.resourcemanager.hostname
Handling deprecation for mapreduce.reduce.memory.mb
Handling deprecation for hadoop.security.group.mapping.ldap.search.filter.group
Handling deprecation for hadoop.http.authentication.kerberos.principal
Handling deprecation for hadoop.security.group.mapping.ldap.search.filter.user
Handling deprecation for yarn.nodemanager.disk-health-checker.min-free-space-per-disk-mb
Handling deprecation for dfs.namenode.edits.dir
Handling deprecation for yarn.client.failover-retries-on-socket-timeouts
Handling deprecation for dfs.namenode.decommission.max.concurrent.tracked.nodes
Handling deprecation for mapreduce.client.completion.pollinterval
Handling deprecation for dfs.namenode.name.dir.restore
Handling deprecation for dfs.namenode.secondary.http-address
Handling deprecation for mapreduce.jobhistory.recovery.store.leveldb.path
Handling deprecation for yarn.sharedcache.store.class
Handling deprecation for s3.bytes-per-checksum
Handling deprecation for yarn.nodemanager.windows-container.cpu-limit.enabled
Handling deprecation for yarn.resourcemanager.webapp.https.address
Handling deprecation for yarn.nodemanager.vmem-pmem-ratio
Handling deprecation for dfs.namenode.checkpoint.period
Handling deprecation for dfs.ha.automatic-failover.enabled
Submitting tokens for job: job_local222123804_0003
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.fs.FileContext.getAbstractFileSystem(FileContext.java:331)
Handling deprecation for all properties in config...
Handling deprecation for mapreduce.jobtracker.address
Handling deprecation for yarn.resourcemanager.scheduler.monitor.policies
Handling deprecation for dfs.namenode.resource.check.interval
Handling deprecation for mapreduce.jobhistory.client.thread-count
Handling deprecation for yarn.app.mapreduce.am.containerlauncher.threadpool-initial-size
Handling deprecation for mapred.child.java.opts
Handling deprecation for mapreduce.jobtracker.retiredjobs.cache.size
Handling deprecation for dfs.client.https.need-auth
Handling deprecation for yarn.admin.acl
Handling deprecation for yarn.app.mapreduce.am.job.committer.cancel-timeout
Handling deprecation for mapreduce.job.emit-timeline-data
Handling deprecation for fs.ftp.host.port
Handling deprecation for dfs.namenode.avoid.read.stale.datanode
Handling deprecation for dfs.journalnode.rpc-address
Handling deprecation for mapreduce.job.end-notification.retry.attempts
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.ttl-interval-ms
Handling deprecation for yarn.resourcemanager.leveldb-state-store.path
Handling deprecation for mapred.mapper.new-api
Handling deprecation for yarn.ipc.rpc.class
Handling deprecation for ipc.client.connection.maxidletime
Handling deprecation for yarn.nodemanager.process-kill-wait.ms
Handling deprecation for mapreduce.cluster.acls.enabled
Handling deprecation for mapreduce.jobtracker.handler.count
Handling deprecation for io.map.index.interval
Handling deprecation for dfs.namenode.https-address
Handling deprecation for mapreduce.task.profile.reduces
Handling deprecation for fs.s3n.multipart.uploads.enabled
Handling deprecation for io.seqfile.sorter.recordlimit
Handling deprecation for mapreduce.job.ubertask.maxmaps
Handling deprecation for mapreduce.tasktracker.tasks.sleeptimebeforesigkill
Handling deprecation for hadoop.util.hash.type
Handling deprecation for dfs.namenode.replication.min
Handling deprecation for yarn.nodemanager.container-manager.thread-count
Handling deprecation for mapreduce.jobtracker.jobhistory.block.size
Handling deprecation for dfs.namenode.fs-limits.min-block-size
Handling deprecation for mapreduce.app-submission.cross-platform
Handling deprecation for fs.AbstractFileSystem.file.impl
Handling deprecation for net.topology.script.number.args
Handling deprecation for yarn.resourcemanager.container-tokens.master-key-rolling-interval-secs
Handling deprecation for mapreduce.map.output.compress.codec
Handling deprecation for mapreduce.job.reducer.preempt.delay.sec
Handling deprecation for s3native.bytes-per-checksum
Handling deprecation for dfs.namenode.path.based.cache.block.map.allocation.percent
Handling deprecation for yarn.nodemanager.windows-container.memory-limit.enabled
Handling deprecation for mapreduce.input.fileinputformat.split.minsize
Handling deprecation for hadoop.security.group.mapping
Handling deprecation for mapreduce.jobtracker.system.dir
Handling deprecation for mapreduce.job.end-notification.max.attempts
Handling deprecation for mapreduce.reduce.markreset.buffer.percent
Handling deprecation for dfs.datanode.cache.revocation.polling.ms
Handling deprecation for mapreduce.reduce.speculative
Handling deprecation for yarn.nodemanager.localizer.cache.cleanup.interval-ms
Handling deprecation for dfs.namenode.lazypersist.file.scrub.interval.sec
Handling deprecation for fs.s3a.threads.core
Handling deprecation for mapreduce.jobhistory.recovery.store.fs.uri
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.start-time-read-cache-size
Handling deprecation for hadoop.registry.zk.retry.interval.ms
Handling deprecation for yarn.nodemanager.keytab
Handling deprecation for dfs.namenode.replication.interval
Handling deprecation for yarn.resourcemanager.admin.address
Handling deprecation for mapreduce.job.maps
Handling deprecation for nfs.dump.dir
Handling deprecation for mapreduce.job.user.name
Handling deprecation for mapreduce.jobtracker.maxtasks.perjob
Handling deprecation for mapreduce.job.ubertask.enable
Handling deprecation for mapreduce.job.reduce.class
Handling deprecation for yarn.nodemanager.delete.debug-delay-sec
Handling deprecation for yarn.timeline-service.ttl-enable
Handling deprecation for yarn.resourcemanager.fs.state-store.retry-policy-spec
Handling deprecation for mapreduce.reduce.skip.maxgroups
Handling deprecation for dfs.client.use.datanode.hostname
Handling deprecation for fs.trash.interval
Handling deprecation for mapreduce.job.name
Handling deprecation for mapreduce.am.max-attempts
Handling deprecation for mapreduce.jobtracker.heartbeats.in.second
Handling deprecation for yarn.resourcemanager.zk-num-retries
Handling deprecation for s3.blocksize
Handling deprecation for dfs.datanode.data.dir
Handling deprecation for mapreduce.jobtracker.persist.jobstatus.active
Handling deprecation for mapreduce.reduce.shuffle.parallelcopies
Handling deprecation for fs.s3.buffer.dir
Handling deprecation for mapreduce.jobhistory.done-dir
Handling deprecation for hadoop.security.instrumentation.requires.admin
Handling deprecation for hadoop.registry.zk.retry.ceiling.ms
Handling deprecation for nfs.rtmax
Handling deprecation for dfs.datanode.data.dir.perm
Handling deprecation for yarn.resourcemanager.container.liveness-monitor.interval-ms
Handling deprecation for yarn.nodemanager.env-whitelist
Handling deprecation for dfs.namenode.backup.address
Handling deprecation for dfs.namenode.xattrs.enabled
Handling deprecation for dfs.datanode.readahead.bytes
Handling deprecation for mapreduce.jobhistory.cleaner.enable
Handling deprecation for dfs.client.block.write.retries
Handling deprecation for mapreduce.tasktracker.http.address
Handling deprecation for yarn.nodemanager.linux-container-executor.cgroups.hierarchy
Handling deprecation for ha.failover-controller.graceful-fence.connection.retries
Handling deprecation for yarn.resourcemanager.recovery.enabled
Handling deprecation for yarn.app.mapreduce.am.container.log.backups
Handling deprecation for dfs.namenode.safemode.threshold-pct
Handling deprecation for yarn.nodemanager.disk-health-checker.interval-ms
Handling deprecation for hadoop.security.java.secure.random.algorithm
Handling deprecation for dfs.namenode.list.cache.directives.num.responses
Handling deprecation for dfs.datanode.dns.nameserver
Handling deprecation for mapreduce.cluster.temp.dir
Handling deprecation for fs.s3a.max.total.tasks
Handling deprecation for mapreduce.reduce.maxattempts
Handling deprecation for mapreduce.client.submit.file.replication
Handling deprecation for mapreduce.shuffle.port
Handling deprecation for yarn.resourcemanager.resource-tracker.client.thread-count
Handling deprecation for dfs.namenode.replication.considerLoad
Handling deprecation for dfs.namenode.edits.journal-plugin.qjournal
Handling deprecation for dfs.client.write.exclude.nodes.cache.expiry.interval.millis
Handling deprecation for yarn.nodemanager.delete.thread-count
Handling deprecation for dfs.client.mmap.cache.timeout.ms
Handling deprecation for yarn.nodemanager.admin-env
Handling deprecation for io.skip.checksum.errors
Handling deprecation for yarn.timeline-service.hostname
Handling deprecation for yarn.resourcemanager.proxy-user-privileges.enabled
Handling deprecation for mapreduce.job.speculative.speculative-cap-total-tasks
Handling deprecation for yarn.acl.enable
Handling deprecation for fs.s3a.fast.upload
Handling deprecation for file.blocksize
Handling deprecation for mapreduce.job.speculative.slowtaskthreshold
Handling deprecation for ftp.replication
Handling deprecation for yarn.sharedcache.cleaner.initial-delay-mins
Handling deprecation for s3native.client-write-packet-size
Handling deprecation for hadoop.rpc.socket.factory.class.default
Handling deprecation for file.bytes-per-checksum
Handling deprecation for dfs.datanode.slow.io.warning.threshold.ms
Handling deprecation for io.seqfile.lazydecompress
Handling deprecation for mapreduce.task.skip.start.attempts
Handling deprecation for dfs.namenode.reject-unresolved-dn-topology-mapping
Handling deprecation for hadoop.common.configuration.version
Handling deprecation for yarn.resourcemanager.client.thread-count
Handling deprecation for dfs.datanode.drop.cache.behind.reads
Handling deprecation for yarn.sharedcache.admin.address
Handling deprecation for mapreduce.job.output.value.class
Handling deprecation for mapreduce.output.fileoutputformat.outputdir
Handling deprecation for mapreduce.jobtracker.taskcache.levels
Handling deprecation for yarn.nodemanager.linux-container-executor.nonsecure-mode.user-pattern
Handling deprecation for yarn.resourcemanager.zk-timeout-ms
Handling deprecation for yarn.resourcemanager.max-completed-applications
Handling deprecation for mapreduce.job.jvm.numtasks
Handling deprecation for yarn.sharedcache.cleaner.period-mins
Handling deprecation for mapreduce.jobtracker.tasktracker.maxblacklists
Handling deprecation for dfs.namenode.top.num.users
Handling deprecation for yarn.nodemanager.linux-container-executor.cgroups.mount
Handling deprecation for yarn.sharedcache.checksum.algo.impl
Handling deprecation for mapreduce.job.end-notification.max.retry.interval
Handling deprecation for mapreduce.job.acl-view-job
Handling deprecation for mapreduce.job.classloader
Handling deprecation for yarn.log-aggregation-enable
Handling deprecation for mapreduce.reduce.shuffle.fetch.retry.interval-ms
Handling deprecation for yarn.resourcemanager.nodemanager.minimum.version
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.size
Handling deprecation for yarn.app.mapreduce.am.job.task.listener.thread-count
Handling deprecation for yarn.app.mapreduce.am.resource.cpu-vcores
Handling deprecation for dfs.namenode.edit.log.autoroll.check.interval.ms
Handling deprecation for mapreduce.output.fileoutputformat.compress.type
Handling deprecation for hadoop.hdfs.configuration.version
Handling deprecation for hadoop.security.group.mapping.ldap.search.attr.member
Handling deprecation for yarn.nodemanager.log.retain-seconds
Handling deprecation for yarn.nodemanager.local-cache.max-files-per-directory
Handling deprecation for mapreduce.job.end-notification.retry.interval
Handling deprecation for hadoop.ssl.client.conf
Handling deprecation for yarn.sharedcache.root-dir
Handling deprecation for dfs.journalnode.https-address
Handling deprecation for mapreduce.reduce.shuffle.fetch.retry.timeout-ms
Handling deprecation for dfs.bytes-per-checksum
Handling deprecation for dfs.namenode.max.objects
Handling deprecation for mapreduce.tasktracker.instrumentation
Handling deprecation for dfs.datanode.max.transfer.threads
Handling deprecation for dfs.block.access.key.update.interval
Handling deprecation for mapreduce.jobtracker.jobhistory.task.numberprogresssplits
Handling deprecation for mapreduce.map.memory.mb
Handling deprecation for ha.failover-controller.new-active.rpc-timeout.ms
Handling deprecation for hadoop.ssl.hostname.verifier
Handling deprecation for dfs.client.read.shortcircuit
Handling deprecation for dfs.datanode.hdfs-blocks-metadata.enabled
Handling deprecation for mapreduce.tasktracker.healthchecker.interval
Handling deprecation for dfs.image.transfer.chunksize
Handling deprecation for mapreduce.tasktracker.taskmemorymanager.monitoringinterval
Handling deprecation for dfs.client.https.keystore.resource
Handling deprecation for yarn.resourcemanager.connect.retry-interval.ms
Handling deprecation for yarn.timeline-service.webapp.address
Handling deprecation for s3native.blocksize
Handling deprecation for yarn.scheduler.minimum-allocation-mb
Handling deprecation for yarn.sharedcache.cleaner.resource-sleep-ms
Handling deprecation for net.topology.impl
Handling deprecation for dfs.client.failover.sleep.base.millis
Handling deprecation for dfs.permissions.superusergroup
Handling deprecation for io.seqfile.compress.blocksize
Handling deprecation for hadoop.registry.zk.retry.times
Handling deprecation for fs.AbstractFileSystem.ftp.impl
Handling deprecation for dfs.namenode.checkpoint.edits.dir
Handling deprecation for mapreduce.job.running.reduce.limit
Handling deprecation for dfs.blockreport.initialDelay
Handling deprecation for dfs.namenode.heartbeat.recheck-interval
Handling deprecation for dfs.namenode.safemode.extension
Handling deprecation for yarn.scheduler.maximum-allocation-mb
Handling deprecation for mapreduce.job.reduce.shuffle.consumer.plugin.class
Handling deprecation for yarn.nodemanager.vmem-check-enabled
Handling deprecation for mapreduce.task.io.sort.factor
Handling deprecation for mapreduce.jobtracker.persist.jobstatus.dir
Handling deprecation for dfs.client.failover.sleep.max.millis
Handling deprecation for dfs.namenode.delegation.key.update-interval
Handling deprecation for hadoop.rpc.protection
Handling deprecation for fs.permissions.umask-mode
Handling deprecation for fs.s3.sleepTimeSeconds
Handling deprecation for ha.health-monitor.rpc-timeout.ms
Handling deprecation for hadoop.http.staticuser.user
Handling deprecation for fs.s3a.connection.maximum
Handling deprecation for yarn.nodemanager.linux-container-executor.nonsecure-mode.limit-users
Handling deprecation for fs.s3a.paging.maximum
Handling deprecation for fs.AbstractFileSystem.viewfs.impl
Handling deprecation for fs.ftp.host
Handling deprecation for yarn.nodemanager.linux-container-executor.nonsecure-mode.local-user
Handling deprecation for fs.s3a.impl
Handling deprecation for hadoop.http.authentication.kerberos.keytab
Handling deprecation for dfs.namenode.fs-limits.max-blocks-per-file
Handling deprecation for mapreduce.tasktracker.http.threads
Handling deprecation for mapreduce.tasktracker.dns.nameserver
Handling deprecation for yarn.resourcemanager.am-rm-tokens.master-key-rolling-interval-secs
Handling deprecation for dfs.client.block.write.replace-datanode-on-failure.enable
Handling deprecation for io.compression.codec.bzip2.library
Handling deprecation for mapreduce.map.skip.maxrecords
Handling deprecation for dfs.client.use.legacy.blockreader.local
Handling deprecation for dfs.namenode.checkpoint.dir
Handling deprecation for dfs.namenode.top.windows.minutes
Handling deprecation for mapreduce.job.maxtaskfailures.per.tracker
Handling deprecation for net.topology.node.switch.mapping.impl
Handling deprecation for mapreduce.shuffle.max.connections
Handling deprecation for mapreduce.jobhistory.loadedjobs.cache.size
Handling deprecation for dfs.storage.policy.enabled
Handling deprecation for yarn.client.application-client-protocol.poll-interval-ms
Handling deprecation for yarn.nodemanager.localizer.address
Handling deprecation for dfs.namenode.list.cache.pools.num.responses
Handling deprecation for nfs.server.port
Handling deprecation for mapreduce.client.output.filter
Handling deprecation for yarn.timeline-service.client.best-effort
Handling deprecation for ha.zookeeper.parent-znode
Handling deprecation for mapreduce.jobtracker.persist.jobstatus.hours
Handling deprecation for yarn.sharedcache.admin.thread-count
Handling deprecation for yarn.nodemanager.resource.cpu-vcores
Handling deprecation for dfs.datanode.block-pinning.enabled
Handling deprecation for mapreduce.jobhistory.http.policy
Handling deprecation for yarn.resourcemanager.webapp.delegation-token-auth-filter.enabled
Handling deprecation for mapreduce.job.speculative.retry-after-no-speculate
Handling deprecation for fs.s3a.attempts.maximum
Handling deprecation for s3native.stream-buffer-size
Handling deprecation for io.seqfile.local.dir
Handling deprecation for yarn.log-aggregation.retain-check-interval-seconds
Handling deprecation for fs.s3n.multipart.copy.block.size
Handling deprecation for dfs.encrypt.data.transfer.cipher.key.bitlength
Handling deprecation for dfs.datanode.sync.behind.writes
Handling deprecation for yarn.resourcemanager.zk-acl
Handling deprecation for hadoop.ssl.keystores.factory.class
Handling deprecation for mapreduce.job.split.metainfo.maxsize
Handling deprecation for fs.s3.maxRetries
Handling deprecation for hadoop.security.random.device.file.path
Handling deprecation for yarn.client.nodemanager-connect.max-wait-ms
Handling deprecation for dfs.namenode.stale.datanode.interval
Handling deprecation for mapreduce.task.io.sort.mb
Handling deprecation for yarn.resourcemanager.zk-state-store.parent-path
Handling deprecation for yarn.app.mapreduce.client-am.ipc.max-retries
Handling deprecation for fs.client.resolve.remote.symlinks
Handling deprecation for yarn.nodemanager.linux-container-executor.cgroups.strict-resource-usage
Handling deprecation for hadoop.ssl.enabled.protocols
Handling deprecation for mapreduce.reduce.cpu.vcores
Handling deprecation for yarn.client.failover-retries
Handling deprecation for mapreduce.jobhistory.address
Handling deprecation for hadoop.ssl.enabled
Handling deprecation for dfs.replication.max
Handling deprecation for dfs.namenode.name.dir
Handling deprecation for dfs.datanode.https.address
Handling deprecation for ipc.client.kill.max
Handling deprecation for mapreduce.job.committer.setup.cleanup.needed
Handling deprecation for dfs.client.domain.socket.data.traffic
Handling deprecation for yarn.nodemanager.localizer.cache.target-size-mb
Handling deprecation for yarn.resourcemanager.admin.client.thread-count
Handling deprecation for dfs.block.access.token.enable
Handling deprecation for mapreduce.job.speculative.retry-after-speculate
Handling deprecation for dfs.datanode.address
Handling deprecation for mapreduce.jobtracker.restart.recover
Handling deprecation for ipc.client.connect.max.retries
Handling deprecation for yarn.timeline-service.store-class
Handling deprecation for dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
Handling deprecation for hadoop.tmp.dir
Handling deprecation for dfs.datanode.handler.count
Handling deprecation for yarn.resourcemanager.ha.automatic-failover.embedded
Handling deprecation for yarn.timeline-service.ttl-ms
Handling deprecation for mapreduce.task.profile.map.params
Handling deprecation for yarn.resourcemanager.nodemanagers.heartbeat-interval-ms
Handling deprecation for mapreduce.map.speculative
Handling deprecation for yarn.timeline-service.recovery.enabled
Handling deprecation for mapreduce.job.map.class
Handling deprecation for dfs.namenode.resource.checked.volumes.minimum
Handling deprecation for yarn.nodemanager.recovery.dir
Handling deprecation for mapreduce.job.counters.max
Handling deprecation for yarn.resourcemanager.keytab
Handling deprecation for dfs.namenode.max.extra.edits.segments.retained
Handling deprecation for dfs.webhdfs.user.provider.user.pattern
Handling deprecation for dfs.client.mmap.enabled
Handling deprecation for mapreduce.map.log.level
Handling deprecation for dfs.client.file-block-storage-locations.timeout.millis
Handling deprecation for yarn.client.max-cached-nodemanagers-proxies
Handling deprecation for yarn.app.mapreduce.am.scheduler.heartbeat.interval-ms
Handling deprecation for hadoop.fuse.timer.period
Handling deprecation for fs.trash.checkpoint.interval
Handling deprecation for yarn.sharedcache.app-checker.class
Handling deprecation for dfs.journalnode.http-address
Handling deprecation for yarn.app.mapreduce.am.staging-dir
Handling deprecation for mapreduce.tasktracker.local.dir.minspacestart
Handling deprecation for yarn.nm.liveness-monitor.expiry-interval-ms
Handling deprecation for ha.health-monitor.check-interval.ms
Handling deprecation for mapreduce.reduce.shuffle.merge.percent
Handling deprecation for dfs.namenode.retrycache.heap.percent
Handling deprecation for yarn.nodemanager.docker-container-executor.exec-name
Handling deprecation for ipc.client.connect.timeout
Handling deprecation for yarn.resourcemanager.fs.state-store.retry-interval-ms
Handling deprecation for mapreduce.output.fileoutputformat.compress
Handling deprecation for yarn.nodemanager.local-dirs
Handling deprecation for yarn.nodemanager.recovery.enabled
Handling deprecation for io.native.lib.available
Handling deprecation for yarn.sharedcache.store.in-memory.staleness-period-mins
Handling deprecation for yarn.resourcemanager.am.max-attempts
Handling deprecation for s3.replication
Handling deprecation for mapreduce.input.fileinputformat.inputdir
Handling deprecation for fs.AbstractFileSystem.har.impl
Handling deprecation for dfs.image.compress
Handling deprecation for mapreduce.job.running.map.limit
Handling deprecation for mapreduce.reduce.input.buffer.percent
Handling deprecation for yarn.nodemanager.webapp.address
Handling deprecation for dfs.datanode.available-space-volume-choosing-policy.balanced-space-preference-fraction
Handling deprecation for dfs.namenode.edit.log.autoroll.multiplier.threshold
Handling deprecation for hadoop.security.group.mapping.ldap.ssl
Handling deprecation for dfs.namenode.checkpoint.check.period
Handling deprecation for fs.defaultFS
Handling deprecation for fs.s3a.multipart.size
Handling deprecation for dfs.client.slow.io.warning.threshold.ms
Handling deprecation for yarn.app.mapreduce.am.job.committer.commit-window
Handling deprecation for hadoop.security.group.mapping.ldap.search.attr.group.name
Handling deprecation for yarn.nodemanager.disk-health-checker.max-disk-utilization-per-disk-percentage
Handling deprecation for yarn.nodemanager.container-monitor.procfs-tree.smaps-based-rss.enabled
Handling deprecation for mapreduce.job.submithostname
Handling deprecation for mapreduce.map.sort.spill.percent
Handling deprecation for hadoop.security.crypto.codec.classes.aes.ctr.nopadding
Handling deprecation for dfs.namenode.http-address
Handling deprecation for hadoop.security.groups.negative-cache.secs
Handling deprecation for hadoop.ssl.server.conf
Handling deprecation for mapreduce.ifile.readahead
Handling deprecation for s3native.replication
Handling deprecation for yarn.client.nodemanager-client-async.thread-pool-max-size
Handling deprecation for mapreduce.jobtracker.staging.root.dir
Handling deprecation for mapreduce.jobhistory.admin.address
Handling deprecation for dfs.namenode.startup.delay.block.deletion.sec
Handling deprecation for yarn.nodemanager.health-checker.interval-ms
Handling deprecation for dfs.namenode.checkpoint.max-retries
Handling deprecation for s3.stream-buffer-size
Handling deprecation for ftp.client-write-packet-size
Handling deprecation for dfs.datanode.fsdatasetcache.max.threads.per.volume
Handling deprecation for mapreduce.output.fileoutputformat.compress.codec
Handling deprecation for yarn.timeline-service.keytab
Handling deprecation for yarn.sharedcache.store.in-memory.initial-delay-mins
Handling deprecation for mapreduce.jobhistory.webapp.address
Handling deprecation for mapreduce.task.userlog.limit.kb
Handling deprecation for mapreduce.reduce.shuffle.fetch.retry.enabled
Handling deprecation for yarn.app.mapreduce.task.container.log.backups
Handling deprecation for dfs.heartbeat.interval
Handling deprecation for ha.zookeeper.session-timeout.ms
Handling deprecation for fs.s3a.connection.ssl.enabled
Handling deprecation for yarn.sharedcache.webapp.address
Handling deprecation for hadoop.http.authentication.signature.secret.file
Handling deprecation for hadoop.fuse.connection.timeout
Handling deprecation for mapreduce.input.fileinputformat.numinputfiles
Handling deprecation for yarn.nodemanager.log-aggregation.compression-type
Handling deprecation for ipc.server.max.connections
Handling deprecation for yarn.resourcemanager.work-preserving-recovery.scheduling-wait-ms
Handling deprecation for yarn.nodemanager.log-dirs
Handling deprecation for yarn.app.mapreduce.am.resource.mb
Handling deprecation for hadoop.security.groups.cache.secs
Handling deprecation for mapreduce.job.speculative.minimum-allowed-tasks
Handling deprecation for yarn.nodemanager.container-monitor.interval-ms
Handling deprecation for dfs.datanode.cache.revocation.timeout.ms
Handling deprecation for mapreduce.jobhistory.recovery.store.class
Handling deprecation for mapreduce.task.combine.progress.records
Handling deprecation for s3.client-write-packet-size
Handling deprecation for mapreduce.jobtracker.instrumentation
Handling deprecation for dfs.replication
Handling deprecation for mapreduce.shuffle.transfer.buffer.size
Handling deprecation for hadoop.security.group.mapping.ldap.directory.search.timeout
Handling deprecation for dfs.datanode.available-space-volume-choosing-policy.balanced-space-threshold
Handling deprecation for hadoop.work.around.non.threadsafe.getpwuid
Handling deprecation for yarn.app.mapreduce.client-am.ipc.max-retries-on-timeouts
Handling deprecation for yarn.nodemanager.address
Handling deprecation for mapreduce.tasktracker.taskcontroller
Handling deprecation for mapreduce.tasktracker.indexcache.mb
Handling deprecation for yarn.scheduler.maximum-allocation-vcores
Handling deprecation for mapreduce.job.reduces
Handling deprecation for yarn.nodemanager.sleep-delay-before-sigkill.ms
Handling deprecation for yarn.timeline-service.address
Handling deprecation for yarn.resourcemanager.configuration.provider-class
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.expiry
Handling deprecation for yarn.sharedcache.enabled
Handling deprecation for tfile.io.chunk.size
Handling deprecation for mapreduce.job.acl-modify-job
Handling deprecation for hadoop.registry.zk.session.timeout.ms
Handling deprecation for fs.automatic.close
Handling deprecation for ha.health-monitor.sleep-after-disconnect.ms
Handling deprecation for mapreduce.tasktracker.reduce.tasks.maximum
Handling deprecation for mapreduce.input.fileinputformat.list-status.num-threads
Handling deprecation for dfs.datanode.directoryscan.threads
Handling deprecation for dfs.datanode.directoryscan.interval
Handling deprecation for dfs.namenode.acls.enabled
Handling deprecation for dfs.client.short.circuit.replica.stale.threshold.ms
Handling deprecation for hadoop.http.authentication.token.validity
Handling deprecation for fs.s3.block.size
Handling deprecation for ha.failover-controller.graceful-fence.rpc-timeout.ms
Handling deprecation for mapreduce.tasktracker.local.dir.minspacekill
Handling deprecation for dfs.namenode.resource.du.reserved
Handling deprecation for mapreduce.jobhistory.cleaner.interval-ms
Handling deprecation for dfs.namenode.datanode.registration.ip-hostname-check
Handling deprecation for mapreduce.jobhistory.intermediate-done-dir
Handling deprecation for mapreduce.jobtracker.http.address
Handling deprecation for dfs.namenode.backup.http-address
Handling deprecation for dfs.namenode.edits.noeditlogchannelflush
Handling deprecation for mapreduce.reduce.shuffle.input.buffer.percent
Handling deprecation for mapreduce.map.maxattempts
Handling deprecation for yarn.http.policy
Handling deprecation for dfs.namenode.audit.loggers
Handling deprecation for hadoop.security.groups.cache.warn.after.ms
Handling deprecation for io.serializations
Handling deprecation for mapreduce.tasktracker.outofband.heartbeat
Handling deprecation for mapreduce.reduce.shuffle.read.timeout
Handling deprecation for hadoop.security.crypto.buffer.size
Handling deprecation for mapreduce.reduce.skip.proc.count.autoincr
Handling deprecation for mapreduce.ifile.readahead.bytes
Handling deprecation for dfs.http.policy
Handling deprecation for hadoop.registry.secure
Handling deprecation for dfs.namenode.safemode.min.datanodes
Handling deprecation for dfs.client.file-block-storage-locations.num-threads
Handling deprecation for mapreduce.cluster.local.dir
Handling deprecation for mapreduce.tasktracker.report.address
Handling deprecation for dfs.namenode.secondary.https-address
Handling deprecation for hadoop.kerberos.kinit.command
Handling deprecation for yarn.timeline-service.http-authentication.type
Handling deprecation for dfs.block.access.token.lifetime
Handling deprecation for dfs.webhdfs.enabled
Handling deprecation for dfs.namenode.delegation.token.max-lifetime
Handling deprecation for dfs.namenode.avoid.write.stale.datanode
Handling deprecation for dfs.datanode.drop.cache.behind.writes
Handling deprecation for yarn.log-aggregation.retain-seconds
Handling deprecation for mapreduce.job.complete.cancel.delegation.tokens
Handling deprecation for mapreduce.local.clientfactory.class.name
Handling deprecation for mapreduce.shuffle.connection-keep-alive.timeout
Handling deprecation for dfs.namenode.num.extra.edits.retained
Handling deprecation for yarn.scheduler.minimum-allocation-vcores
Handling deprecation for ipc.client.connect.max.retries.on.timeouts
Handling deprecation for yarn.timeline-service.client.retry-interval-ms
Handling deprecation for yarn.timeline-service.client.max-retries
Handling deprecation for fs.s3n.block.size
Handling deprecation for mapreduce.job.map.output.collector.class
Handling deprecation for ha.health-monitor.connect-retry-interval.ms
Handling deprecation for mapreduce.shuffle.max.threads
Handling deprecation for nfs.exports.allowed.hosts
Handling deprecation for dfs.client.mmap.cache.size
Handling deprecation for mapreduce.tasktracker.map.tasks.maximum
Handling deprecation for io.file.buffer.size
Handling deprecation for dfs.client.datanode-restart.timeout
Handling deprecation for io.mapfile.bloom.size
Handling deprecation for hadoop.security.kms.client.authentication.retry-count
Handling deprecation for dfs.namenode.checkpoint.txns
Handling deprecation for ipc.client.connect.retry.interval
Handling deprecation for dfs.client-write-packet-size
Handling deprecation for mapreduce.reduce.shuffle.connect.timeout
Handling deprecation for yarn.resourcemanager.fs.state-store.uri
Handling deprecation for fs.swift.impl
Handling deprecation for hadoop.registry.zk.connection.timeout.ms
Handling deprecation for mapred.queue.default.acl-administer-jobs
Handling deprecation for mapreduce.job.submithostaddress
Handling deprecation for dfs.cachereport.intervalMsec
Handling deprecation for yarn.app.mapreduce.shuffle.log.backups
Handling deprecation for yarn.app.mapreduce.am.container.log.limit.kb
Handling deprecation for yarn.nodemanager.resourcemanager.minimum.version
Handling deprecation for ftp.blocksize
Handling deprecation for yarn.resourcemanager.address
Handling deprecation for file.stream-buffer-size
Handling deprecation for yarn.resourcemanager.scheduler.monitor.enable
Handling deprecation for mapreduce.job.ubertask.maxreduces
Handling deprecation for nfs.allow.insecure.ports
Handling deprecation for yarn.sharedcache.nm.uploader.thread-count
Handling deprecation for ipc.client.idlethreshold
Handling deprecation for ftp.stream-buffer-size
Handling deprecation for yarn.sharedcache.client-server.address
Handling deprecation for dfs.client.failover.connection.retries.on.timeouts
Handling deprecation for dfs.namenode.replication.work.multiplier.per.iteration
Handling deprecation for hadoop.http.authentication.simple.anonymous.allowed
Handling deprecation for hadoop.security.authorization
Handling deprecation for yarn.client.nodemanager-connect.retry-interval-ms
Handling deprecation for yarn.am.liveness-monitor.expiry-interval-ms
Handling deprecation for fs.har.impl.disable.cache
Handling deprecation for yarn.nodemanager.linux-container-executor.resources-handler.class
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.read-cache-size
Handling deprecation for hadoop.security.authentication
Handling deprecation for dfs.image.compression.codec
Handling deprecation for mapreduce.task.files.preserve.failedtasks
Handling deprecation for dfs.client.read.shortcircuit.streams.cache.size
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.path
Handling deprecation for mapreduce.job.reduce.slowstart.completedmaps
Handling deprecation for mapreduce.jobhistory.minicluster.fixed.ports
Handling deprecation for file.replication
Handling deprecation for yarn.resourcemanager.ha.automatic-failover.enabled
Handling deprecation for mapreduce.job.userlog.retain.hours
Handling deprecation for mapreduce.jobhistory.joblist.cache.size
Handling deprecation for dfs.namenode.accesstime.precision
Handling deprecation for yarn.resourcemanager.work-preserving-recovery.enabled
Handling deprecation for dfs.namenode.fs-limits.max-xattrs-per-inode
Handling deprecation for io.mapfile.bloom.error.rate
Handling deprecation for yarn.resourcemanager.store.class
Handling deprecation for dfs.image.transfer.timeout
Handling deprecation for yarn.timeline-service.leveldb-state-store.path
Handling deprecation for nfs.wtmax
Handling deprecation for mapreduce.job.combine.class
Handling deprecation for dfs.namenode.support.allow.format
Handling deprecation for fs.s3a.multipart.purge
Handling deprecation for dfs.secondary.namenode.kerberos.internal.spnego.principal
Handling deprecation for fs.s3a.connection.establish.timeout
Handling deprecation for dfs.stream-buffer-size
Handling deprecation for dfs.namenode.invalidate.work.pct.per.iteration
Handling deprecation for yarn.nodemanager.container-executor.class
Handling deprecation for fs.s3a.multipart.purge.age
Handling deprecation for yarn.resourcemanager.scheduler.client.thread-count
Handling deprecation for dfs.namenode.top.enabled
Handling deprecation for yarn.app.mapreduce.shuffle.log.separate
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.low-watermark
Handling deprecation for fs.s3a.fast.buffer.size
Handling deprecation for hadoop.user.group.static.mapping.overrides
Handling deprecation for tfile.fs.input.buffer.size
Handling deprecation for dfs.client.cached.conn.retry
Handling deprecation for hadoop.http.authentication.type
Handling deprecation for dfs.namenode.list.encryption.zones.num.responses
Handling deprecation for mapreduce.map.cpu.vcores
Handling deprecation for dfs.namenode.path.based.cache.refresh.interval.ms
Handling deprecation for dfs.namenode.decommission.interval
Handling deprecation for dfs.namenode.fs-limits.max-directory-items
Handling deprecation for yarn.resourcemanager.zk-retry-interval-ms
Handling deprecation for ftp.bytes-per-checksum
Handling deprecation for dfs.ha.log-roll.period
Handling deprecation for dfs.user.home.dir.prefix
Handling deprecation for ipc.client.fallback-to-simple-auth-allowed
Handling deprecation for yarn.nodemanager.pmem-check-enabled
Handling deprecation for yarn.nodemanager.remote-app-log-dir
Handling deprecation for dfs.namenode.inotify.max.events.per.rpc
Handling deprecation for mapreduce.task.profile.maps
Handling deprecation for mapreduce.shuffle.ssl.file.buffer.size
Handling deprecation for mapreduce.tasktracker.healthchecker.script.timeout
Handling deprecation for yarn.timeline-service.webapp.https.address
Handling deprecation for yarn.nodemanager.resource.percentage-physical-cpu-limit
Handling deprecation for yarn.app.mapreduce.am.command-opts
Handling deprecation for dfs.namenode.fs-limits.max-xattr-size
Handling deprecation for dfs.datanode.http.address
Handling deprecation for dfs.namenode.blocks.per.postponedblocks.rescan
Handling deprecation for yarn.sharedcache.nm.uploader.replication.factor
Handling deprecation for hadoop.registry.zk.root
Handling deprecation for hadoop.jetty.logs.serve.aliases
Handling deprecation for yarn.client.failover-proxy-provider
Handling deprecation for mapreduce.jobhistory.admin.acl
Handling deprecation for yarn.app.mapreduce.am.hard-kill-timeout-ms
Handling deprecation for yarn.nodemanager.remote-app-log-dir-suffix
Handling deprecation for mapreduce.jobhistory.principal
Handling deprecation for yarn.resourcemanager.webapp.address
Handling deprecation for mapreduce.jobhistory.recovery.enable
Handling deprecation for yarn.sharedcache.store.in-memory.check-period-mins
Handling deprecation for nfs.mountd.port
Handling deprecation for mapreduce.reduce.merge.inmem.threshold
Handling deprecation for fs.df.interval
Handling deprecation for yarn.timeline-service.enabled
Handling deprecation for mapreduce.jobtracker.jobhistory.lru.cache.size
Handling deprecation for mapreduce.task.profile
Handling deprecation for mapreduce.job.output.key.class
Handling deprecation for yarn.nodemanager.hostname
Handling deprecation for dfs.namenode.num.checkpoints.retained
Handling deprecation for mapreduce.job.queuename
Handling deprecation for mapreduce.jobhistory.max-age-ms
Handling deprecation for mapreduce.job.token.tracking.ids.enabled
Handling deprecation for yarn.nodemanager.localizer.client.thread-count
Handling deprecation for yarn.sharedcache.uploader.server.thread-count
Handling deprecation for dfs.client.mmap.retry.timeout.ms
Handling deprecation for mapreduce.jobhistory.move.thread-count
Handling deprecation for dfs.permissions.enabled
Handling deprecation for dfs.blockreport.split.threshold
Handling deprecation for fs.AbstractFileSystem.hdfs.impl
Handling deprecation for dfs.datanode.balance.bandwidthPerSec
Handling deprecation for dfs.block.scanner.volume.bytes.per.second
Handling deprecation for hadoop.http.filter.initializers
Handling deprecation for yarn.timeline-service.http-authentication.simple.anonymous.allowed
Handling deprecation for dfs.default.chunk.view.size
Handling deprecation for yarn.sharedcache.client-server.thread-count
Handling deprecation for yarn.resourcemanager.resource-tracker.address
Handling deprecation for mapreduce.job.working.dir
Handling deprecation for mapreduce.jobhistory.datestring.cache.size
Handling deprecation for mapreduce.task.profile.params
Handling deprecation for dfs.namenode.decommission.blocks.per.interval
Handling deprecation for dfs.namenode.handler.count
Handling deprecation for dfs.image.transfer.bandwidthPerSec
Handling deprecation for rpc.metrics.quantile.enable
Handling deprecation for mapreduce.jobtracker.expire.trackers.interval
Handling deprecation for mapreduce.task.timeout
Handling deprecation for yarn.app.mapreduce.client.max-retries
Handling deprecation for yarn.nodemanager.resource.memory-mb
Handling deprecation for yarn.nodemanager.disk-health-checker.min-healthy-disks
Handling deprecation for dfs.datanode.failed.volumes.tolerated
Handling deprecation for yarn.timeline-service.handler-thread-count
Handling deprecation for ipc.server.listen.queue.size
Handling deprecation for fs.s3a.threads.max
Handling deprecation for yarn.resourcemanager.connect.max-wait.ms
Handling deprecation for mapreduce.fileoutputcommitter.algorithm.version
Handling deprecation for mapreduce.framework.name
Handling deprecation for mapreduce.map.skip.proc.count.autoincr
Handling deprecation for mapreduce.job.max.split.locations
Handling deprecation for yarn.resourcemanager.scheduler.class
Handling deprecation for yarn.resourcemanager.system-metrics-publisher.enabled
Handling deprecation for dfs.blocksize
Handling deprecation for yarn.sharedcache.nested-level
Handling deprecation for mapreduce.shuffle.connection-keep-alive.enable
Handling deprecation for fs.s3a.threads.keepalivetime
Handling deprecation for fs.s3a.connection.timeout
Handling deprecation for file.client-write-packet-size
Handling deprecation for ha.failover-controller.cli-check.rpc-timeout.ms
Handling deprecation for ha.zookeeper.acl
Handling deprecation for dfs.namenode.write.stale.datanode.ratio
Handling deprecation for dfs.encrypt.data.transfer
Handling deprecation for dfs.datanode.shared.file.descriptor.paths
Handling deprecation for mapreduce.input.lineinputformat.linespermap
Handling deprecation for yarn.resourcemanager.delayed.delegation-token.removal-interval-ms
Handling deprecation for yarn.nodemanager.localizer.fetch.thread-count
Handling deprecation for dfs.client.failover.max.attempts
Handling deprecation for yarn.resourcemanager.scheduler.address
Handling deprecation for dfs.client.read.shortcircuit.streams.cache.expiry.ms
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.start-time-write-cache-size
Handling deprecation for yarn.nodemanager.health-checker.script.timeout-ms
Handling deprecation for yarn.resourcemanager.fs.state-store.num-retries
Handling deprecation for hadoop.ssl.require.client.cert
Handling deprecation for hadoop.security.uid.cache.secs
Handling deprecation for mapreduce.jobhistory.keytab
Handling deprecation for dfs.client.read.shortcircuit.skip.checksum
Handling deprecation for yarn.resourcemanager.ha.automatic-failover.zk-base-path
Handling deprecation for mapreduce.shuffle.ssl.enabled
Handling deprecation for mapreduce.reduce.log.level
Handling deprecation for hadoop.registry.rm.enabled
Handling deprecation for mapreduce.tasktracker.dns.interface
Handling deprecation for yarn.resourcemanager.system-metrics-publisher.dispatcher.pool-size
Handling deprecation for mapreduce.job.speculative.speculative-cap-running-tasks
Handling deprecation for dfs.datanode.block.id.layout.upgrade.threads
Handling deprecation for dfs.datanode.use.datanode.hostname
Handling deprecation for dfs.client.context
Handling deprecation for yarn.resourcemanager.ha.enabled
Handling deprecation for mapred.reducer.new-api
Handling deprecation for dfs.namenode.delegation.token.renew-interval
Handling deprecation for dfs.blockreport.intervalMsec
Handling deprecation for fs.s3a.multipart.threshold
Handling deprecation for mapreduce.reduce.shuffle.memory.limit.percent
Handling deprecation for dfs.https.server.keystore.resource
Handling deprecation for io.map.index.skip
Handling deprecation for mapreduce.job.hdfs-servers
Handling deprecation for mapreduce.jobtracker.taskscheduler
Handling deprecation for dfs.namenode.kerberos.internal.spnego.principal
Handling deprecation for yarn.resourcemanager.state-store.max-completed-applications
Handling deprecation for mapreduce.map.output.compress
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.num.refill.threads
Handling deprecation for fs.s3n.multipart.uploads.block.size
Handling deprecation for mapreduce.task.merge.progress.records
Handling deprecation for dfs.datanode.dns.interface
Handling deprecation for map.sort.class
Handling deprecation for yarn.nodemanager.aux-services.mapreduce_shuffle.class
Handling deprecation for tfile.fs.output.buffer.size
Handling deprecation for fs.du.interval
Handling deprecation for dfs.client.failover.connection.retries
Handling deprecation for dfs.namenode.top.window.num.buckets
Handling deprecation for mapreduce.job.dir
Handling deprecation for fs.s3a.buffer.dir
Handling deprecation for mapreduce.reduce.shuffle.retry-delay.max.ms
Handling deprecation for yarn.sharedcache.uploader.server.address
Handling deprecation for mapreduce.client.progressmonitor.pollinterval
Handling deprecation for yarn.app.mapreduce.shuffle.log.limit.kb
Handling deprecation for dfs.datanode.max.locked.memory
Handling deprecation for dfs.namenode.retrycache.expirytime.millis
Handling deprecation for dfs.datanode.scan.period.hours
Handling deprecation for dfs.client.block.write.replace-datanode-on-failure.best-effort
Handling deprecation for mapreduce.jobhistory.move.interval-ms
Handling deprecation for dfs.ha.fencing.ssh.connect-timeout
Handling deprecation for yarn.nodemanager.log-aggregation.roll-monitoring-interval-seconds
Handling deprecation for dfs.namenode.fs-limits.max-component-length
Handling deprecation for hadoop.registry.zk.quorum
Handling deprecation for dfs.namenode.enable.retrycache
Handling deprecation for dfs.datanode.du.reserved
Handling deprecation for yarn.timeline-service.state-store-class
Handling deprecation for dfs.datanode.ipc.address
Handling deprecation for hadoop.registry.system.acls
Handling deprecation for dfs.client.block.write.replace-datanode-on-failure.policy
Handling deprecation for dfs.namenode.path.based.cache.retry.interval.ms
Handling deprecation for hadoop.security.crypto.cipher.suite
Handling deprecation for dfs.ha.tail-edits.period
Handling deprecation for mapreduce.task.profile.reduce.params
Handling deprecation for hadoop.registry.jaas.context
Handling deprecation for yarn.resourcemanager.hostname
Handling deprecation for mapreduce.reduce.memory.mb
Handling deprecation for hadoop.security.group.mapping.ldap.search.filter.group
Handling deprecation for hadoop.http.authentication.kerberos.principal
Handling deprecation for hadoop.security.group.mapping.ldap.search.filter.user
Handling deprecation for yarn.nodemanager.disk-health-checker.min-free-space-per-disk-mb
Handling deprecation for dfs.namenode.edits.dir
Handling deprecation for yarn.client.failover-retries-on-socket-timeouts
Handling deprecation for dfs.namenode.decommission.max.concurrent.tracked.nodes
Handling deprecation for mapreduce.client.completion.pollinterval
Handling deprecation for dfs.namenode.name.dir.restore
Handling deprecation for dfs.namenode.secondary.http-address
Handling deprecation for mapreduce.jobhistory.recovery.store.leveldb.path
Handling deprecation for yarn.sharedcache.store.class
Handling deprecation for s3.bytes-per-checksum
Handling deprecation for yarn.nodemanager.windows-container.cpu-limit.enabled
Handling deprecation for yarn.resourcemanager.webapp.https.address
Handling deprecation for yarn.nodemanager.vmem-pmem-ratio
Handling deprecation for dfs.namenode.checkpoint.period
Handling deprecation for dfs.ha.automatic-failover.enabled
The url to track the job: http://localhost:8080/
OutputCommitter set in config null
File Output Committer Algorithm version is 1
OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
Running job: job_local222123804_0003
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
/user/michaeljones/wcOutputAnalysis/_temporary/0: masked=rwxr-xr-x
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones sending #57
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones got value #57
Call: mkdirs took 9ms
Starting mapper thread pool executor.
Max local threads: 1
Map tasks to process: 1
Waiting for map tasks
Starting task: attempt_local222123804_0003_m_000000_0
currentIndex 0   0:0
mapreduce.cluster.local.dir for child : /tmp/hadoop-michaeljones/mapred/local/localRunner//michaeljones/jobcache/job_local222123804_0003/attempt_local222123804_0003_m_000000_0
using new api for output committer
File Output Committer Algorithm version is 1
ProcfsBasedProcessTree currently is supported only on Linux.
 Using ResourceCalculatorProcessTree : null
Processing split: hdfs://localhost:9000/user/michaeljones/wcInput:0+50
Trying map output collector class: org.apache.hadoop.mapred.MapTask$MapOutputBuffer
(EQUATOR) 0 kvi 26214396(104857584)
mapreduce.task.io.sort.mb: 100
soft limit at 83886080
bufstart = 0; bufvoid = 104857600
kvstart = 26214396; length = 6553600
Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones sending #58
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones got value #58
Call: getBlockLocations took 6ms
newInfo = LocatedBlocks{
  fileLength=50
  underConstruction=false
  blocks=[LocatedBlock{BP-1045030256-10.0.0.2-1433119149314:blk_1073741825_1002; getBlockSize()=50; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-b42c5705-9ba4-4b14-b00b-f9194bb036f0,DISK]]}]
  lastLocatedBlock=LocatedBlock{BP-1045030256-10.0.0.2-1433119149314:blk_1073741825_1002; getBlockSize()=50; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-b42c5705-9ba4-4b14-b00b-f9194bb036f0,DISK]]}
  isLastBlockComplete=true}
Connecting to datanode 127.0.0.1:50010

Starting flush of map output
Spilling map output
bufstart = 0; bufend = 82; bufvoid = 104857600
kvstart = 26214396(104857584); kvend = 26214368(104857472); length = 29/6553600
IntSumCombinerAnalyser-Bye[1]
IntSumCombinerAnalyser-Goodbye[1]
IntSumCombinerAnalyser-Hadoop[1,1]
IntSumCombinerAnalyser-Hello[1,1]
IntSumCombinerAnalyser-World[1,1]
Finished spill 0
Task:attempt_local222123804_0003_m_000000_0 is done. And is in the process of committing
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones sending #59
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones got value #59
Call: getFileInfo took 2ms
map
Task 'attempt_local222123804_0003_m_000000_0' done.
Finishing task: attempt_local222123804_0003_m_000000_0
map task executor complete.
Starting reduce thread pool executor.
Max local threads: 1
Reduce tasks to process: 1
Waiting for reduce tasks
Starting task: attempt_local222123804_0003_r_000000_0
currentIndex 0   0:0
mapreduce.cluster.local.dir for child : /tmp/hadoop-michaeljones/mapred/local/localRunner//michaeljones/jobcache/job_local222123804_0003/attempt_local222123804_0003_r_000000_0
using new api for output committer
File Output Committer Algorithm version is 1
ProcfsBasedProcessTree currently is supported only on Linux.
 Using ResourceCalculatorProcessTree : null
Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@184cb058
MergerManager: memoryLimit=668309888, maxSingleShuffleLimit=167077472, mergeThreshold=441084544, ioSortFactor=10, memToMemMergeOutputsThreshold=10
attempt_local222123804_0003_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
Got 0 map completion events from 0
GetMapEventsThread about to sleep for 1000
LocalFetcher 3 going to fetch: attempt_local222123804_0003_m_000000_0
attempt_local222123804_0003_m_000000_0: Proceeding with shuffle since usedMemory (0) is lesser than memoryLimit (668309888).CommitMemory is (0)
localfetcher#3 about to shuffle output of map attempt_local222123804_0003_m_000000_0 decomp: 63 len: 67 to MEMORY
Read 63 bytes from map-output for attempt_local222123804_0003_m_000000_0
closeInMemoryFile -> map-output of size: 63, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->63
map attempt_local222123804_0003_m_000000_0 done 1 / 1 copied.
EventFetcher is interrupted.. Returning
1 / 1 copied.
finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
Merging 1 sorted segments
Down to the last merge-pass, with 1 segments left of total size: 57 bytes
Merged 1 segments, 63 bytes to disk to satisfy reduce memory limit
Disk file: /tmp/hadoop-michaeljones/mapred/local/localRunner/michaeljones/jobcache/job_local222123804_0003/attempt_local222123804_0003_r_000000_0/output/map_0.out.merged Length is 67
Merging 1 files, 67 bytes from disk
Merging 0 segments, 0 bytes from memory into reduce
Merging 1 sorted segments
Down to the last merge-pass, with 1 segments left of total size: 57 bytes
1 / 1 copied.
/user/michaeljones/wcOutputAnalysis/_temporary/0/_temporary/attempt_local222123804_0003_r_000000_0/part-r-00000: masked=rw-r--r--
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones sending #60
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones got value #60
Call: create took 5ms
computePacketChunkSize: src=/user/michaeljones/wcOutputAnalysis/_temporary/0/_temporary/attempt_local222123804_0003_r_000000_0/part-r-00000, chunkSize=516, chunksPerPacket=126, packetSize=65016
IntSumReducerAnalyser-Bye[1]
IntSumReducerAnalyser-Goodbye[1]
IntSumReducerAnalyser-Hadoop[2]
IntSumReducerAnalyser-Hello[2]
IntSumReducerAnalyser-World[2]
DFSClient writeChunk allocating new packet seqno=0, src=/user/michaeljones/wcOutputAnalysis/_temporary/0/_temporary/attempt_local222123804_0003_r_000000_0/part-r-00000, packetSize=65016, chunksPerPacket=126, bytesCurBlock=0
Queued packet 0
Queued packet 1
Waiting for ack for: 1
Allocating new block
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones sending #61
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones got value #61
Call: addBlock took 6ms
pipeline = DatanodeInfoWithStorage[127.0.0.1:50010,DS-b42c5705-9ba4-4b14-b00b-f9194bb036f0,DISK]
Connecting to datanode 127.0.0.1:50010
Send buf size 131072
SASL client skipping handshake in unsecured configuration for addr = /127.0.0.1, datanodeId = DatanodeInfoWithStorage[127.0.0.1:50010,DS-b42c5705-9ba4-4b14-b00b-f9194bb036f0,DISK]
DataStreamer block BP-1045030256-10.0.0.2-1433119149314:blk_1073742218_1395 sending packet packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 41
DFSClient seqno: 0 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
DataStreamer block BP-1045030256-10.0.0.2-1433119149314:blk_1073742218_1395 sending packet packet seqno: 1 offsetInBlock: 41 lastPacketInBlock: true lastByteOffsetInBlock: 41
DFSClient seqno: 1 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
Closing old block BP-1045030256-10.0.0.2-1433119149314:blk_1073742218_1395
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones sending #62
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones got value #62
Call: complete took 3ms
Task:attempt_local222123804_0003_r_000000_0 is done. And is in the process of committing
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones sending #63
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones got value #63
Call: getFileInfo took 2ms
1 / 1 copied.
Task attempt_local222123804_0003_r_000000_0 is allowed to commit now
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones sending #64
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones got value #64
Call: getFileInfo took 2ms
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones sending #65
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones got value #65
Call: getFileInfo took 2ms
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones sending #66
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones got value #66
Call: rename took 4ms
Saved output of task 'attempt_local222123804_0003_r_000000_0' to hdfs://localhost:9000/user/michaeljones/wcOutputAnalysis/_temporary/0/task_local222123804_0003_r_000000
reduce > reduce
Task 'attempt_local222123804_0003_r_000000_0' done.
Finishing task: attempt_local222123804_0003_r_000000_0
reduce task executor complete.
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones sending #67
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones got value #67
Call: getListing took 2ms
Merging data from FileStatus{path=hdfs://localhost:9000/user/michaeljones/wcOutputAnalysis/_temporary/0/task_local222123804_0003_r_000000; isDirectory=true; modification_time=1434151727989; access_time=0; owner=michaeljones; group=supergroup; permission=rwxr-xr-x; isSymlink=false} to hdfs://localhost:9000/user/michaeljones/wcOutputAnalysis
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones sending #68
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones got value #68
Call: getFileInfo took 2ms
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones sending #69
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones got value #69
Call: getListing took 1ms
Merging data from FileStatus{path=hdfs://localhost:9000/user/michaeljones/wcOutputAnalysis/_temporary/0/task_local222123804_0003_r_000000/part-r-00000; isDirectory=false; length=41; replication=1; blocksize=134217728; modification_time=1434151728015; access_time=1434151727989; owner=michaeljones; group=supergroup; permission=rw-r--r--; isSymlink=false} to hdfs://localhost:9000/user/michaeljones/wcOutputAnalysis/part-r-00000
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones sending #70
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones got value #70
Call: getFileInfo took 2ms
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones sending #71
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones got value #71
Call: rename took 3ms
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones sending #72
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones got value #72
Call: delete took 4ms
/user/michaeljones/wcOutputAnalysis/_SUCCESS: masked=rw-r--r--
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones sending #73
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones got value #73
Call: create took 3ms
computePacketChunkSize: src=/user/michaeljones/wcOutputAnalysis/_SUCCESS, chunkSize=516, chunksPerPacket=126, packetSize=65016
Waiting for ack for: -1
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones sending #74
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones got value #74
Call: complete took 2ms
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.fs.FileContext.getAbstractFileSystem(FileContext.java:331)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
Job job_local222123804_0003 running in uber mode : false
 map 100% reduce 100%
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.getTaskCompletionEvents(Job.java:670)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.getTaskCompletionEvents(Job.java:670)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
Job job_local222123804_0003 completed successfully
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.getCounters(Job.java:758)
Counters: 35
	File System Counters
		FILE: Number of bytes read=1892
		FILE: Number of bytes written=1691283
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=340
		HDFS: Number of bytes written=245
		HDFS: Number of read operations=71
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=38
	Map-Reduce Framework
		Map input records=2
		Map output records=8
		Map output bytes=82
		Map output materialized bytes=67
		Input split bytes=112
		Combine input records=8
		Combine output records=5
		Reduce input groups=5
		Reduce shuffle bytes=67
		Reduce input records=5
		Reduce output records=5
		Spilled Records=10
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=633339904
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=50
	File Output Format Counters 
		Bytes Written=41
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 0][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://localhost:50070
Connecting to localhost/127.0.0.1:50070
Connection established 127.0.0.1:49427<->127.0.0.1:50070
Executing request PUT /webhdfs/v1/user/michaeljones/apache-empty.txt?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-0 >> PUT /webhdfs/v1/user/michaeljones/apache-empty.txt?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1
http-outgoing-0 >> Content-Length: 0
http-outgoing-0 >> Host: localhost:50070
http-outgoing-0 >> Connection: Keep-Alive
http-outgoing-0 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-0 >> Accept-Encoding: gzip,deflate
http-outgoing-0 >> "PUT /webhdfs/v1/user/michaeljones/apache-empty.txt?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1[\r][\n]"
http-outgoing-0 >> "Content-Length: 0[\r][\n]"
http-outgoing-0 >> "Host: localhost:50070[\r][\n]"
http-outgoing-0 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-0 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-0 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-0 >> "[\r][\n]"
http-outgoing-0 << "HTTP/1.1 307 TEMPORARY_REDIRECT[\r][\n]"
http-outgoing-0 << "Cache-Control: no-cache[\r][\n]"
http-outgoing-0 << "Expires: Fri, 12 Jun 2015 23:28:49 GMT[\r][\n]"
http-outgoing-0 << "Date: Fri, 12 Jun 2015 23:28:49 GMT[\r][\n]"
http-outgoing-0 << "Pragma: no-cache[\r][\n]"
http-outgoing-0 << "Expires: Fri, 12 Jun 2015 23:28:49 GMT[\r][\n]"
http-outgoing-0 << "Date: Fri, 12 Jun 2015 23:28:49 GMT[\r][\n]"
http-outgoing-0 << "Pragma: no-cache[\r][\n]"
http-outgoing-0 << "Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434187729085&s=mYqqL4wnTWII5o/mkKfB8Ga/HZ8="; Path=/; Expires=Sat, 13-Jun-2015 09:28:49 GMT; HttpOnly[\r][\n]"
http-outgoing-0 << "Location: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true[\r][\n]"
http-outgoing-0 << "Content-Type: application/octet-stream[\r][\n]"
http-outgoing-0 << "Content-Length: 0[\r][\n]"
http-outgoing-0 << "Server: Jetty(6.1.26)[\r][\n]"
http-outgoing-0 << "[\r][\n]"
http-outgoing-0 << HTTP/1.1 307 TEMPORARY_REDIRECT
http-outgoing-0 << Cache-Control: no-cache
http-outgoing-0 << Expires: Fri, 12 Jun 2015 23:28:49 GMT
http-outgoing-0 << Date: Fri, 12 Jun 2015 23:28:49 GMT
http-outgoing-0 << Pragma: no-cache
http-outgoing-0 << Expires: Fri, 12 Jun 2015 23:28:49 GMT
http-outgoing-0 << Date: Fri, 12 Jun 2015 23:28:49 GMT
http-outgoing-0 << Pragma: no-cache
http-outgoing-0 << Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434187729085&s=mYqqL4wnTWII5o/mkKfB8Ga/HZ8="; Path=/; Expires=Sat, 13-Jun-2015 09:28:49 GMT; HttpOnly
http-outgoing-0 << Location: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
http-outgoing-0 << Content-Type: application/octet-stream
http-outgoing-0 << Content-Length: 0
http-outgoing-0 << Server: Jetty(6.1.26)
Connection can be kept alive indefinitely
Cookie accepted [hadoop.auth=""u=michaeljones&p=michaeljones&t=simple&e=1434187729085&s=mYqqL4wnTWII5o/mkKfB8Ga/HZ8="", version:0, domain:localhost, path:/, expiry:Sat Jun 13 19:28:49 AEST 2015]
Redirect to: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
http-outgoing-0: Shutdown connection
Connection discarded
http-outgoing-0: Close connection
Connection released: [id: 0][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
PUT file redirect: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 1][route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://michaels-air.bigpond:50075
Connecting to Michaels-Air.BigPond/10.0.0.2:50075
Connection established 10.0.0.2:49428<->10.0.0.2:50075
Executing request PUT /webhdfs/v1/user/michaeljones/apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-1 >> PUT /webhdfs/v1/user/michaeljones/apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1
http-outgoing-1 >> Content-Length: 0
http-outgoing-1 >> Host: michaels-air.bigpond:50075
http-outgoing-1 >> Connection: Keep-Alive
http-outgoing-1 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-1 >> Accept-Encoding: gzip,deflate
http-outgoing-1 >> "PUT /webhdfs/v1/user/michaeljones/apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1[\r][\n]"
http-outgoing-1 >> "Content-Length: 0[\r][\n]"
http-outgoing-1 >> "Host: michaels-air.bigpond:50075[\r][\n]"
http-outgoing-1 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-1 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-1 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-1 >> "[\r][\n]"
http-outgoing-1 << "HTTP/1.1 100 Continue[\r][\n]"
http-outgoing-1 << "[\r][\n]"
http-outgoing-1 << HTTP/1.1 100 Continue
http-outgoing-1 << "HTTP/1.1 201 Created[\r][\n]"
http-outgoing-1 << "Location: hdfs://localhost:9000/user/michaeljones/apache-empty.txt[\r][\n]"
http-outgoing-1 << "Content-Length: 0[\r][\n]"
http-outgoing-1 << "Connection: close[\r][\n]"
http-outgoing-1 << "[\r][\n]"
http-outgoing-1 << HTTP/1.1 201 Created
http-outgoing-1 << Location: hdfs://localhost:9000/user/michaeljones/apache-empty.txt
http-outgoing-1 << Content-Length: 0
http-outgoing-1 << Connection: close
http-outgoing-1: Shutdown connection
Connection discarded
http-outgoing-1: Close connection
Connection released: [id: 1][route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 2][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://localhost:50070
Connecting to localhost/127.0.0.1:50070
Connection established 127.0.0.1:49430<->127.0.0.1:50070
Executing request PUT /webhdfs/v1/user/michaeljones/pom.xml?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-2 >> PUT /webhdfs/v1/user/michaeljones/pom.xml?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1
http-outgoing-2 >> Content-Length: 0
http-outgoing-2 >> Host: localhost:50070
http-outgoing-2 >> Connection: Keep-Alive
http-outgoing-2 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-2 >> Accept-Encoding: gzip,deflate
http-outgoing-2 >> "PUT /webhdfs/v1/user/michaeljones/pom.xml?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1[\r][\n]"
http-outgoing-2 >> "Content-Length: 0[\r][\n]"
http-outgoing-2 >> "Host: localhost:50070[\r][\n]"
http-outgoing-2 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-2 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-2 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-2 >> "[\r][\n]"
http-outgoing-2 << "HTTP/1.1 307 TEMPORARY_REDIRECT[\r][\n]"
http-outgoing-2 << "Cache-Control: no-cache[\r][\n]"
http-outgoing-2 << "Expires: Fri, 12 Jun 2015 23:28:49 GMT[\r][\n]"
http-outgoing-2 << "Date: Fri, 12 Jun 2015 23:28:49 GMT[\r][\n]"
http-outgoing-2 << "Pragma: no-cache[\r][\n]"
http-outgoing-2 << "Expires: Fri, 12 Jun 2015 23:28:49 GMT[\r][\n]"
http-outgoing-2 << "Date: Fri, 12 Jun 2015 23:28:49 GMT[\r][\n]"
http-outgoing-2 << "Pragma: no-cache[\r][\n]"
http-outgoing-2 << "Content-Type: application/octet-stream[\r][\n]"
http-outgoing-2 << "Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434187729239&s=WqBi4Elx0gdHyoU9+rPdjDJQoCM="; Path=/; Expires=Sat, 13-Jun-2015 09:28:49 GMT; HttpOnly[\r][\n]"
http-outgoing-2 << "Location: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/pom.xml?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true[\r][\n]"
http-outgoing-2 << "Content-Length: 0[\r][\n]"
http-outgoing-2 << "Server: Jetty(6.1.26)[\r][\n]"
http-outgoing-2 << "[\r][\n]"
http-outgoing-2 << HTTP/1.1 307 TEMPORARY_REDIRECT
http-outgoing-2 << Cache-Control: no-cache
http-outgoing-2 << Expires: Fri, 12 Jun 2015 23:28:49 GMT
http-outgoing-2 << Date: Fri, 12 Jun 2015 23:28:49 GMT
http-outgoing-2 << Pragma: no-cache
http-outgoing-2 << Expires: Fri, 12 Jun 2015 23:28:49 GMT
http-outgoing-2 << Date: Fri, 12 Jun 2015 23:28:49 GMT
http-outgoing-2 << Pragma: no-cache
http-outgoing-2 << Content-Type: application/octet-stream
http-outgoing-2 << Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434187729239&s=WqBi4Elx0gdHyoU9+rPdjDJQoCM="; Path=/; Expires=Sat, 13-Jun-2015 09:28:49 GMT; HttpOnly
http-outgoing-2 << Location: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/pom.xml?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
http-outgoing-2 << Content-Length: 0
http-outgoing-2 << Server: Jetty(6.1.26)
Connection can be kept alive indefinitely
Cookie accepted [hadoop.auth=""u=michaeljones&p=michaeljones&t=simple&e=1434187729239&s=WqBi4Elx0gdHyoU9+rPdjDJQoCM="", version:0, domain:localhost, path:/, expiry:Sat Jun 13 19:28:49 AEST 2015]
Redirect to: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/pom.xml?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
http-outgoing-2: Shutdown connection
Connection discarded
http-outgoing-2: Close connection
Connection released: [id: 2][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
PUT file redirect: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/pom.xml?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 3][route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://michaels-air.bigpond:50075
Connecting to Michaels-Air.BigPond/10.0.0.2:50075
Connection established 10.0.0.2:49431<->10.0.0.2:50075
Executing request PUT /webhdfs/v1/user/michaeljones/pom.xml?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-3 >> PUT /webhdfs/v1/user/michaeljones/pom.xml?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1
http-outgoing-3 >> Transfer-Encoding: chunked
http-outgoing-3 >> Content-Type: application/octet-stream
http-outgoing-3 >> Host: michaels-air.bigpond:50075
http-outgoing-3 >> Connection: Keep-Alive
http-outgoing-3 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-3 >> Accept-Encoding: gzip,deflate
http-outgoing-3 >> "PUT /webhdfs/v1/user/michaeljones/pom.xml?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1[\r][\n]"
http-outgoing-3 >> "Transfer-Encoding: chunked[\r][\n]"
http-outgoing-3 >> "Content-Type: application/octet-stream[\r][\n]"
http-outgoing-3 >> "Host: michaels-air.bigpond:50075[\r][\n]"
http-outgoing-3 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-3 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-3 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-3 >> "[\r][\n]"
http-outgoing-3 >> "856[\r][\n]"
http-outgoing-3 >> "<?xml version="1.0" encoding="UTF-8"?>[\n]"
http-outgoing-3 >> "<project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">[\n]"
http-outgoing-3 >> "    <modelVersion>4.0.0</modelVersion>[\n]"
http-outgoing-3 >> "    <groupId>com.michaeljones</groupId>[\n]"
http-outgoing-3 >> "    <artifactId>HelloHadoopWorldMaven</artifactId>[\n]"
http-outgoing-3 >> "    <version>1.0-SNAPSHOT</version>[\n]"
http-outgoing-3 >> "    <packaging>jar</packaging>[\n]"
http-outgoing-3 >> "    <dependencies>[\n]"
http-outgoing-3 >> "        <!-- run bin/hadoop version to see the jar it was built with, which is this dependency -->[\n]"
http-outgoing-3 >> "        <dependency>[\n]"
http-outgoing-3 >> "            <groupId>org.apache.hadoop</groupId>[\n]"
http-outgoing-3 >> "            <artifactId>hadoop-common</artifactId>[\n]"
http-outgoing-3 >> "            <version>2.7.0</version>[\n]"
http-outgoing-3 >> "        </dependency>[\n]"
http-outgoing-3 >> "        <dependency>[\n]"
http-outgoing-3 >> "            <groupId>org.apache.hadoop</groupId>[\n]"
http-outgoing-3 >> "            <artifactId>hadoop-hdfs</artifactId>[\n]"
http-outgoing-3 >> "            <version>2.7.0</version>[\n]"
http-outgoing-3 >> "        </dependency>[\n]"
http-outgoing-3 >> "        <dependency>[\n]"
http-outgoing-3 >> "            <groupId>junit</groupId>[\n]"
http-outgoing-3 >> "            <artifactId>junit</artifactId>[\n]"
http-outgoing-3 >> "            <version>4.10</version>[\n]"
http-outgoing-3 >> "            <scope>test</scope>[\n]"
http-outgoing-3 >> "        </dependency>[\n]"
http-outgoing-3 >> "        <dependency>[\n]"
http-outgoing-3 >> "            <groupId>org.apache.hadoop</groupId>[\n]"
http-outgoing-3 >> "            <artifactId>hadoop-mapreduce-client-core</artifactId>[\n]"
http-outgoing-3 >> "            <version>2.7.0</version>[\n]"
http-outgoing-3 >> "        </dependency>[\n]"
http-outgoing-3 >> "        <dependency>[\n]"
http-outgoing-3 >> "            <groupId>org.apache.hadoop</groupId>[\n]"
http-outgoing-3 >> "            <artifactId>hadoop-mapreduce-client-common</artifactId>[\n]"
http-outgoing-3 >> "            <version>2.7.0</version>[\n]"
http-outgoing-3 >> "        </dependency>[\n]"
http-outgoing-3 >> "        <dependency>[\n]"
http-outgoing-3 >> "            <groupId>com.googlecode.json-simple</groupId>[\n]"
http-outgoing-3 >> "            <artifactId>json-simple</artifactId>[\n]"
http-outgoing-3 >> "            <version>1.1.1</version>[\n]"
http-outgoing-3 >> "        </dependency>[\n]"
http-outgoing-3 >> "        <dependency>[\n]"
http-outgoing-3 >> "            <groupId>org.apache.httpcomponents</groupId>[\n]"
http-outgoing-3 >> "            <artifactId>httpclient</artifactId>[\n]"
http-outgoing-3 >> "            <version>4.4-beta1</version>[\n]"
http-outgoing-3 >> "        </dependency>[\n]"
http-outgoing-3 >> "    </dependencies>[\n]"
http-outgoing-3 >> "    <properties>[\n]"
http-outgoing-3 >> "        <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>[\n]"
http-outgoing-3 >> "        <maven.compiler.source>1.7</maven.compiler.source>[\n]"
http-outgoing-3 >> "        <maven.compiler.target>1.7</maven.compiler.target>[\n]"
http-outgoing-3 >> "    </properties>[\n]"
http-outgoing-3 >> "</project>[\r][\n]"
http-outgoing-3 >> "0[\r][\n]"
http-outgoing-3 >> "[\r][\n]"
http-outgoing-3 << "HTTP/1.1 100 Continue[\r][\n]"
http-outgoing-3 << "[\r][\n]"
http-outgoing-3 << HTTP/1.1 100 Continue
http-outgoing-3 << "HTTP/1.1 201 Created[\r][\n]"
http-outgoing-3 << "Location: hdfs://localhost:9000/user/michaeljones/pom.xml[\r][\n]"
http-outgoing-3 << "Content-Length: 0[\r][\n]"
http-outgoing-3 << "Connection: close[\r][\n]"
http-outgoing-3 << "[\r][\n]"
http-outgoing-3 << HTTP/1.1 201 Created
http-outgoing-3 << Location: hdfs://localhost:9000/user/michaeljones/pom.xml
http-outgoing-3 << Content-Length: 0
http-outgoing-3 << Connection: close
http-outgoing-3: Shutdown connection
Connection discarded
http-outgoing-3: Close connection
Connection released: [id: 3][route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection manager is shutting down
Connection manager shut down
stopping client from cache: org.apache.hadoop.ipc.Client@47d9a273
removing client from cache: org.apache.hadoop.ipc.Client@47d9a273
stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@47d9a273
Stopping client
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones: closed
IPC Client (1932274274) connection to localhost/127.0.0.1:9000 from michaeljones: stopped, remaining connections 0
Connection manager is shutting down
Connection manager shut down
Connection manager is shutting down
Connection manager shut down
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 0][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://localhost:50070
Connecting to localhost/127.0.0.1:50070
Connection established 127.0.0.1:49438<->127.0.0.1:50070
Executing request PUT /webhdfs/v1/user/michaeljones/apache-empty.txt?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-0 >> PUT /webhdfs/v1/user/michaeljones/apache-empty.txt?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1
http-outgoing-0 >> Content-Length: 0
http-outgoing-0 >> Host: localhost:50070
http-outgoing-0 >> Connection: Keep-Alive
http-outgoing-0 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-0 >> Accept-Encoding: gzip,deflate
http-outgoing-0 >> "PUT /webhdfs/v1/user/michaeljones/apache-empty.txt?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1[\r][\n]"
http-outgoing-0 >> "Content-Length: 0[\r][\n]"
http-outgoing-0 >> "Host: localhost:50070[\r][\n]"
http-outgoing-0 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-0 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-0 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-0 >> "[\r][\n]"
http-outgoing-0 << "HTTP/1.1 307 TEMPORARY_REDIRECT[\r][\n]"
http-outgoing-0 << "Cache-Control: no-cache[\r][\n]"
http-outgoing-0 << "Expires: Fri, 12 Jun 2015 23:29:59 GMT[\r][\n]"
http-outgoing-0 << "Date: Fri, 12 Jun 2015 23:29:59 GMT[\r][\n]"
http-outgoing-0 << "Pragma: no-cache[\r][\n]"
http-outgoing-0 << "Expires: Fri, 12 Jun 2015 23:29:59 GMT[\r][\n]"
http-outgoing-0 << "Date: Fri, 12 Jun 2015 23:29:59 GMT[\r][\n]"
http-outgoing-0 << "Pragma: no-cache[\r][\n]"
http-outgoing-0 << "Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434187799902&s=lWEBI3E4JDYtjgx9qTVzXqeIOc0="; Path=/; Expires=Sat, 13-Jun-2015 09:29:59 GMT; HttpOnly[\r][\n]"
http-outgoing-0 << "Location: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true[\r][\n]"
http-outgoing-0 << "Content-Type: application/octet-stream[\r][\n]"
http-outgoing-0 << "Content-Length: 0[\r][\n]"
http-outgoing-0 << "Server: Jetty(6.1.26)[\r][\n]"
http-outgoing-0 << "[\r][\n]"
http-outgoing-0 << HTTP/1.1 307 TEMPORARY_REDIRECT
http-outgoing-0 << Cache-Control: no-cache
http-outgoing-0 << Expires: Fri, 12 Jun 2015 23:29:59 GMT
http-outgoing-0 << Date: Fri, 12 Jun 2015 23:29:59 GMT
http-outgoing-0 << Pragma: no-cache
http-outgoing-0 << Expires: Fri, 12 Jun 2015 23:29:59 GMT
http-outgoing-0 << Date: Fri, 12 Jun 2015 23:29:59 GMT
http-outgoing-0 << Pragma: no-cache
http-outgoing-0 << Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434187799902&s=lWEBI3E4JDYtjgx9qTVzXqeIOc0="; Path=/; Expires=Sat, 13-Jun-2015 09:29:59 GMT; HttpOnly
http-outgoing-0 << Location: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
http-outgoing-0 << Content-Type: application/octet-stream
http-outgoing-0 << Content-Length: 0
http-outgoing-0 << Server: Jetty(6.1.26)
Connection can be kept alive indefinitely
Cookie accepted [hadoop.auth=""u=michaeljones&p=michaeljones&t=simple&e=1434187799902&s=lWEBI3E4JDYtjgx9qTVzXqeIOc0="", version:0, domain:localhost, path:/, expiry:Sat Jun 13 19:29:59 AEST 2015]
Redirect to: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
http-outgoing-0: Shutdown connection
Connection discarded
http-outgoing-0: Close connection
Connection released: [id: 0][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
PUT file redirect: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 1][route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://michaels-air.bigpond:50075
Connecting to michaels-air.bigpond/10.0.0.2:50075
Connection established 10.0.0.2:49439<->10.0.0.2:50075
Executing request PUT /webhdfs/v1/user/michaeljones/apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-1 >> PUT /webhdfs/v1/user/michaeljones/apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1
http-outgoing-1 >> Content-Length: 0
http-outgoing-1 >> Host: michaels-air.bigpond:50075
http-outgoing-1 >> Connection: Keep-Alive
http-outgoing-1 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-1 >> Accept-Encoding: gzip,deflate
http-outgoing-1 >> "PUT /webhdfs/v1/user/michaeljones/apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1[\r][\n]"
http-outgoing-1 >> "Content-Length: 0[\r][\n]"
http-outgoing-1 >> "Host: michaels-air.bigpond:50075[\r][\n]"
http-outgoing-1 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-1 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-1 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-1 >> "[\r][\n]"
http-outgoing-1 << "HTTP/1.1 100 Continue[\r][\n]"
http-outgoing-1 << "[\r][\n]"
http-outgoing-1 << HTTP/1.1 100 Continue
http-outgoing-1 << "HTTP/1.1 201 Created[\r][\n]"
http-outgoing-1 << "Location: hdfs://localhost:9000/user/michaeljones/apache-empty.txt[\r][\n]"
http-outgoing-1 << "Content-Length: 0[\r][\n]"
http-outgoing-1 << "Connection: close[\r][\n]"
http-outgoing-1 << "[\r][\n]"
http-outgoing-1 << HTTP/1.1 201 Created
http-outgoing-1 << Location: hdfs://localhost:9000/user/michaeljones/apache-empty.txt
http-outgoing-1 << Content-Length: 0
http-outgoing-1 << Connection: close
http-outgoing-1: Shutdown connection
Connection discarded
http-outgoing-1: Close connection
Connection released: [id: 1][route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 2][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://localhost:50070
Connecting to localhost/127.0.0.1:50070
Connection established 127.0.0.1:49441<->127.0.0.1:50070
Executing request PUT /webhdfs/v1/user/michaeljones/pom.xml?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-2 >> PUT /webhdfs/v1/user/michaeljones/pom.xml?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1
http-outgoing-2 >> Content-Length: 0
http-outgoing-2 >> Host: localhost:50070
http-outgoing-2 >> Connection: Keep-Alive
http-outgoing-2 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-2 >> Accept-Encoding: gzip,deflate
http-outgoing-2 >> "PUT /webhdfs/v1/user/michaeljones/pom.xml?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1[\r][\n]"
http-outgoing-2 >> "Content-Length: 0[\r][\n]"
http-outgoing-2 >> "Host: localhost:50070[\r][\n]"
http-outgoing-2 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-2 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-2 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-2 >> "[\r][\n]"
http-outgoing-2 << "HTTP/1.1 307 TEMPORARY_REDIRECT[\r][\n]"
http-outgoing-2 << "Cache-Control: no-cache[\r][\n]"
http-outgoing-2 << "Expires: Fri, 12 Jun 2015 23:30:00 GMT[\r][\n]"
http-outgoing-2 << "Date: Fri, 12 Jun 2015 23:30:00 GMT[\r][\n]"
http-outgoing-2 << "Pragma: no-cache[\r][\n]"
http-outgoing-2 << "Expires: Fri, 12 Jun 2015 23:30:00 GMT[\r][\n]"
http-outgoing-2 << "Date: Fri, 12 Jun 2015 23:30:00 GMT[\r][\n]"
http-outgoing-2 << "Pragma: no-cache[\r][\n]"
http-outgoing-2 << "Content-Type: application/octet-stream[\r][\n]"
http-outgoing-2 << "Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434187800155&s=Js4etfgSPVt0dlv60GH4QtGezik="; Path=/; Expires=Sat, 13-Jun-2015 09:30:00 GMT; HttpOnly[\r][\n]"
http-outgoing-2 << "Location: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/pom.xml?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true[\r][\n]"
http-outgoing-2 << "Content-Length: 0[\r][\n]"
http-outgoing-2 << "Server: Jetty(6.1.26)[\r][\n]"
http-outgoing-2 << "[\r][\n]"
http-outgoing-2 << HTTP/1.1 307 TEMPORARY_REDIRECT
http-outgoing-2 << Cache-Control: no-cache
http-outgoing-2 << Expires: Fri, 12 Jun 2015 23:30:00 GMT
http-outgoing-2 << Date: Fri, 12 Jun 2015 23:30:00 GMT
http-outgoing-2 << Pragma: no-cache
http-outgoing-2 << Expires: Fri, 12 Jun 2015 23:30:00 GMT
http-outgoing-2 << Date: Fri, 12 Jun 2015 23:30:00 GMT
http-outgoing-2 << Pragma: no-cache
http-outgoing-2 << Content-Type: application/octet-stream
http-outgoing-2 << Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434187800155&s=Js4etfgSPVt0dlv60GH4QtGezik="; Path=/; Expires=Sat, 13-Jun-2015 09:30:00 GMT; HttpOnly
http-outgoing-2 << Location: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/pom.xml?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
http-outgoing-2 << Content-Length: 0
http-outgoing-2 << Server: Jetty(6.1.26)
Connection can be kept alive indefinitely
Cookie accepted [hadoop.auth=""u=michaeljones&p=michaeljones&t=simple&e=1434187800155&s=Js4etfgSPVt0dlv60GH4QtGezik="", version:0, domain:localhost, path:/, expiry:Sat Jun 13 19:30:00 AEST 2015]
Redirect to: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/pom.xml?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
http-outgoing-2: Shutdown connection
Connection discarded
http-outgoing-2: Close connection
Connection released: [id: 2][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
PUT file redirect: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/pom.xml?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 3][route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://michaels-air.bigpond:50075
Connecting to michaels-air.bigpond/10.0.0.2:50075
Connection established 10.0.0.2:49442<->10.0.0.2:50075
Executing request PUT /webhdfs/v1/user/michaeljones/pom.xml?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-3 >> PUT /webhdfs/v1/user/michaeljones/pom.xml?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1
http-outgoing-3 >> Transfer-Encoding: chunked
http-outgoing-3 >> Content-Type: application/octet-stream
http-outgoing-3 >> Host: michaels-air.bigpond:50075
http-outgoing-3 >> Connection: Keep-Alive
http-outgoing-3 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-3 >> Accept-Encoding: gzip,deflate
http-outgoing-3 >> "PUT /webhdfs/v1/user/michaeljones/pom.xml?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1[\r][\n]"
http-outgoing-3 >> "Transfer-Encoding: chunked[\r][\n]"
http-outgoing-3 >> "Content-Type: application/octet-stream[\r][\n]"
http-outgoing-3 >> "Host: michaels-air.bigpond:50075[\r][\n]"
http-outgoing-3 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-3 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-3 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-3 >> "[\r][\n]"
http-outgoing-3 >> "856[\r][\n]"
http-outgoing-3 >> "<?xml version="1.0" encoding="UTF-8"?>[\n]"
http-outgoing-3 >> "<project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">[\n]"
http-outgoing-3 >> "    <modelVersion>4.0.0</modelVersion>[\n]"
http-outgoing-3 >> "    <groupId>com.michaeljones</groupId>[\n]"
http-outgoing-3 >> "    <artifactId>HelloHadoopWorldMaven</artifactId>[\n]"
http-outgoing-3 >> "    <version>1.0-SNAPSHOT</version>[\n]"
http-outgoing-3 >> "    <packaging>jar</packaging>[\n]"
http-outgoing-3 >> "    <dependencies>[\n]"
http-outgoing-3 >> "        <!-- run bin/hadoop version to see the jar it was built with, which is this dependency -->[\n]"
http-outgoing-3 >> "        <dependency>[\n]"
http-outgoing-3 >> "            <groupId>org.apache.hadoop</groupId>[\n]"
http-outgoing-3 >> "            <artifactId>hadoop-common</artifactId>[\n]"
http-outgoing-3 >> "            <version>2.7.0</version>[\n]"
http-outgoing-3 >> "        </dependency>[\n]"
http-outgoing-3 >> "        <dependency>[\n]"
http-outgoing-3 >> "            <groupId>org.apache.hadoop</groupId>[\n]"
http-outgoing-3 >> "            <artifactId>hadoop-hdfs</artifactId>[\n]"
http-outgoing-3 >> "            <version>2.7.0</version>[\n]"
http-outgoing-3 >> "        </dependency>[\n]"
http-outgoing-3 >> "        <dependency>[\n]"
Connection manager is shutting down
http-outgoing-3 >> "            <groupId>junit</groupId>[\n]"
Connection manager shut down
http-outgoing-3 >> "            <artifactId>junit</artifactId>[\n]"
http-outgoing-3 >> "            <version>4.10</version>[\n]"
http-outgoing-3 >> "            <scope>test</scope>[\n]"
http-outgoing-3 >> "        </dependency>[\n]"
http-outgoing-3 >> "        <dependency>[\n]"
http-outgoing-3 >> "            <groupId>org.apache.hadoop</groupId>[\n]"
http-outgoing-3 >> "            <artifactId>hadoop-mapreduce-client-core</artifactId>[\n]"
http-outgoing-3 >> "            <version>2.7.0</version>[\n]"
http-outgoing-3 >> "        </dependency>[\n]"
http-outgoing-3 >> "        <dependency>[\n]"
http-outgoing-3 >> "            <groupId>org.apache.hadoop</groupId>[\n]"
http-outgoing-3 >> "            <artifactId>hadoop-mapreduce-client-common</artifactId>[\n]"
http-outgoing-3 >> "            <version>2.7.0</version>[\n]"
http-outgoing-3 >> "        </dependency>[\n]"
http-outgoing-3 >> "        <dependency>[\n]"
http-outgoing-3 >> "            <groupId>com.googlecode.json-simple</groupId>[\n]"
http-outgoing-3 >> "            <artifactId>json-simple</artifactId>[\n]"
http-outgoing-3 >> "            <version>1.1.1</version>[\n]"
http-outgoing-3 >> "        </dependency>[\n]"
http-outgoing-3 >> "        <dependency>[\n]"
http-outgoing-3 >> "            <groupId>org.apache.httpcomponents</groupId>[\n]"
http-outgoing-3 >> "            <artifactId>httpclient</artifactId>[\n]"
http-outgoing-3 >> "            <version>4.4-beta1</version>[\n]"
http-outgoing-3 >> "        </dependency>[\n]"
http-outgoing-3 >> "    </dependencies>[\n]"
http-outgoing-3 >> "    <properties>[\n]"
http-outgoing-3 >> "        <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>[\n]"
http-outgoing-3 >> "        <maven.compiler.source>1.7</maven.compiler.source>[\n]"
http-outgoing-3 >> "        <maven.compiler.target>1.7</maven.compiler.target>[\n]"
http-outgoing-3 >> "    </properties>[\n]"
http-outgoing-3 >> "</project>[\r][\n]"
http-outgoing-3 >> "0[\r][\n]"
http-outgoing-3 >> "[\r][\n]"
http-outgoing-3 << "HTTP/1.1 100 Continue[\r][\n]"
http-outgoing-3 << "[\r][\n]"
http-outgoing-3 << HTTP/1.1 100 Continue
http-outgoing-3 << "HTTP/1.1 201 Created[\r][\n]"
http-outgoing-3 << "Location: hdfs://localhost:9000/user/michaeljones/pom.xml[\r][\n]"
http-outgoing-3 << "Content-Length: 0[\r][\n]"
http-outgoing-3 << "Connection: close[\r][\n]"
http-outgoing-3 << "[\r][\n]"
http-outgoing-3 << HTTP/1.1 201 Created
http-outgoing-3 << Location: hdfs://localhost:9000/user/michaeljones/pom.xml
http-outgoing-3 << Content-Length: 0
http-outgoing-3 << Connection: close
http-outgoing-3: Shutdown connection
Connection discarded
http-outgoing-3: Close connection
Connection released: [id: 3][route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection manager is shutting down
Connection manager shut down
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 0][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://localhost:50070
Connecting to localhost/127.0.0.1:50070
Connection established 127.0.0.1:49447<->127.0.0.1:50070
Executing request GET /webhdfs/v1/user/michaeljones/?op=LISTSTATUS HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-0 >> GET /webhdfs/v1/user/michaeljones/?op=LISTSTATUS HTTP/1.1
http-outgoing-0 >> accept: application/json
http-outgoing-0 >> Host: localhost:50070
http-outgoing-0 >> Connection: Keep-Alive
http-outgoing-0 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-0 >> Accept-Encoding: gzip,deflate
http-outgoing-0 >> "GET /webhdfs/v1/user/michaeljones/?op=LISTSTATUS HTTP/1.1[\r][\n]"
http-outgoing-0 >> "accept: application/json[\r][\n]"
http-outgoing-0 >> "Host: localhost:50070[\r][\n]"
http-outgoing-0 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-0 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-0 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-0 >> "[\r][\n]"
http-outgoing-0 << "HTTP/1.1 200 OK[\r][\n]"
http-outgoing-0 << "Cache-Control: no-cache[\r][\n]"
http-outgoing-0 << "Expires: Fri, 12 Jun 2015 23:32:15 GMT[\r][\n]"
http-outgoing-0 << "Date: Fri, 12 Jun 2015 23:32:15 GMT[\r][\n]"
http-outgoing-0 << "Pragma: no-cache[\r][\n]"
http-outgoing-0 << "Expires: Fri, 12 Jun 2015 23:32:15 GMT[\r][\n]"
http-outgoing-0 << "Date: Fri, 12 Jun 2015 23:32:15 GMT[\r][\n]"
http-outgoing-0 << "Pragma: no-cache[\r][\n]"
http-outgoing-0 << "Content-Type: application/json[\r][\n]"
http-outgoing-0 << "Transfer-Encoding: chunked[\r][\n]"
http-outgoing-0 << "Server: Jetty(6.1.26)[\r][\n]"
http-outgoing-0 << "[\r][\n]"
http-outgoing-0 << "E9D[\r][\n]"
http-outgoing-0 << "{"FileStatuses":{"FileStatus":[[\n]"
http-outgoing-0 << "{"accessTime":1434094518288,"blockSize":134217728,"childrenNum":0,"fileId":18364,"group":"supergroup","length":10899,"modificationTime":1434094518324,"owner":"michaeljones","pathSuffix":"README.md","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434151800072,"blockSize":134217728,"childrenNum":0,"fileId":18417,"group":"supergroup","length":0,"modificationTime":1434151800078,"owner":"michaeljones","pathSuffix":"apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434094529413,"blockSize":134217728,"childrenNum":0,"fileId":18389,"group":"supergroup","length":0,"modificationTime":1434094529419,"owner":"michaeljones","pathSuffix":"empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434094517691,"blockSize":134217728,"childrenNum":0,"fileId":18362,"group":"supergroup","length":0,"modificationTime":1434094517697,"owner":"michaeljones","pathSuffix":"hello-apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434091626279,"blockSize":134217728,"childrenNum":0,"fileId":18298,"group":"supergroup","length":0,"modificationTime":1434091626286,"owner":"michaeljones","pathSuffix":"hello-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434094517577,"blockSize":134217728,"childrenNum":0,"fileId":18361,"group":"supergroup","length":0,"modificationTime":1434094517584,"owner":"michaeljones","pathSuffix":"hello-jersey-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434094529626,"blockSize":134217728,"childrenNum":0,"fileId":18390,"group":"supergroup","length":3678408,"modificationTime":1434094529811,"owner":"michaeljones","pathSuffix":"hello.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434151721877,"blockSize":134217728,"childrenNum":0,"fileId":18393,"group":"supergroup","length":20,"modificationTime":1434151722436,"owner":"michaeljones","pathSuffix":"hello.txt","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434094518094,"blockSize":134217728,"childrenNum":0,"fileId":18363,"group":"supergroup","length":93997,"modificationTime":1434094518134,"owner":"michaeljones","pathSuffix":"hellohadoop.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434151800262,"blockSize":134217728,"childrenNum":0,"fileId":18418,"group":"supergroup","length":2134,"modificationTime":1434151800285,"owner":"michaeljones","pathSuffix":"pom.xml","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434151723254,"blockSize":134217728,"childrenNum":0,"fileId":16388,"group":"supergroup","length":50,"modificationTime":1433119638967,"owner":"michaeljones","pathSuffix":"wcInput","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18401,"group":"supergroup","length":0,"modificationTime":1434151726430,"owner":"michaeljones","pathSuffix":"wcOutput","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},[\n]"
http-outgoing-0 << "{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18408,"group":"supergroup","length":0,"modificationTime":1434151728052,"owner":"michaeljones","pathSuffix":"wcOutputAnalysis","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},[\n]"
http-outgoing-0 << "{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18394,"group":"supergroup","length":0,"modificationTime":1434151725436,"owner":"michaeljones","pathSuffix":"wcOutputMain","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"}[\n]"
http-outgoing-0 << "]}}[\n]"
http-outgoing-0 << "[\r][\n]"
http-outgoing-0 << HTTP/1.1 200 OK
http-outgoing-0 << Cache-Control: no-cache
http-outgoing-0 << Expires: Fri, 12 Jun 2015 23:32:15 GMT
http-outgoing-0 << Date: Fri, 12 Jun 2015 23:32:15 GMT
http-outgoing-0 << Pragma: no-cache
http-outgoing-0 << Expires: Fri, 12 Jun 2015 23:32:15 GMT
http-outgoing-0 << Date: Fri, 12 Jun 2015 23:32:15 GMT
http-outgoing-0 << Pragma: no-cache
http-outgoing-0 << Content-Type: application/json
http-outgoing-0 << Transfer-Encoding: chunked
http-outgoing-0 << Server: Jetty(6.1.26)
Connection can be kept alive indefinitely
http-outgoing-0 << "0[\r][\n]"
http-outgoing-0 << "[\r][\n]"
Connection [id: 0][route: {}->http://localhost:50070] can be kept alive indefinitely
Connection released: [id: 0][route: {}->http://localhost:50070][total kept alive: 1; route allocated: 1 of 2; total allocated: 1 of 20]
Apache client testGetStringContent
{"FileStatuses":{"FileStatus":[
{"accessTime":1434094518288,"blockSize":134217728,"childrenNum":0,"fileId":18364,"group":"supergroup","length":10899,"modificationTime":1434094518324,"owner":"michaeljones","pathSuffix":"README.md","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434151800072,"blockSize":134217728,"childrenNum":0,"fileId":18417,"group":"supergroup","length":0,"modificationTime":1434151800078,"owner":"michaeljones","pathSuffix":"apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434094529413,"blockSize":134217728,"childrenNum":0,"fileId":18389,"group":"supergroup","length":0,"modificationTime":1434094529419,"owner":"michaeljones","pathSuffix":"empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434094517691,"blockSize":134217728,"childrenNum":0,"fileId":18362,"group":"supergroup","length":0,"modificationTime":1434094517697,"owner":"michaeljones","pathSuffix":"hello-apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434091626279,"blockSize":134217728,"childrenNum":0,"fileId":18298,"group":"supergroup","length":0,"modificationTime":1434091626286,"owner":"michaeljones","pathSuffix":"hello-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434094517577,"blockSize":134217728,"childrenNum":0,"fileId":18361,"group":"supergroup","length":0,"modificationTime":1434094517584,"owner":"michaeljones","pathSuffix":"hello-jersey-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434094529626,"blockSize":134217728,"childrenNum":0,"fileId":18390,"group":"supergroup","length":3678408,"modificationTime":1434094529811,"owner":"michaeljones","pathSuffix":"hello.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434151721877,"blockSize":134217728,"childrenNum":0,"fileId":18393,"group":"supergroup","length":20,"modificationTime":1434151722436,"owner":"michaeljones","pathSuffix":"hello.txt","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434094518094,"blockSize":134217728,"childrenNum":0,"fileId":18363,"group":"supergroup","length":93997,"modificationTime":1434094518134,"owner":"michaeljones","pathSuffix":"hellohadoop.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434151800262,"blockSize":134217728,"childrenNum":0,"fileId":18418,"group":"supergroup","length":2134,"modificationTime":1434151800285,"owner":"michaeljones","pathSuffix":"pom.xml","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434151723254,"blockSize":134217728,"childrenNum":0,"fileId":16388,"group":"supergroup","length":50,"modificationTime":1433119638967,"owner":"michaeljones","pathSuffix":"wcInput","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18401,"group":"supergroup","length":0,"modificationTime":1434151726430,"owner":"michaeljones","pathSuffix":"wcOutput","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},
{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18408,"group":"supergroup","length":0,"modificationTime":1434151728052,"owner":"michaeljones","pathSuffix":"wcOutputAnalysis","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},
{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18394,"group":"supergroup","length":0,"modificationTime":1434151725436,"owner":"michaeljones","pathSuffix":"wcOutputMain","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"}
]}}

CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 1][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://localhost:50070
Connecting to localhost/127.0.0.1:50070
Connection established 127.0.0.1:49448<->127.0.0.1:50070
Executing request PUT /webhdfs/v1/user/michaeljones/apache-empty.txt?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-1 >> PUT /webhdfs/v1/user/michaeljones/apache-empty.txt?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1
http-outgoing-1 >> Content-Length: 0
http-outgoing-1 >> Host: localhost:50070
http-outgoing-1 >> Connection: Keep-Alive
http-outgoing-1 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-1 >> Accept-Encoding: gzip,deflate
http-outgoing-1 >> "PUT /webhdfs/v1/user/michaeljones/apache-empty.txt?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1[\r][\n]"
http-outgoing-1 >> "Content-Length: 0[\r][\n]"
http-outgoing-1 >> "Host: localhost:50070[\r][\n]"
http-outgoing-1 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-1 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-1 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-1 >> "[\r][\n]"
http-outgoing-1 << "HTTP/1.1 307 TEMPORARY_REDIRECT[\r][\n]"
http-outgoing-1 << "Cache-Control: no-cache[\r][\n]"
http-outgoing-1 << "Expires: Fri, 12 Jun 2015 23:32:15 GMT[\r][\n]"
http-outgoing-1 << "Date: Fri, 12 Jun 2015 23:32:15 GMT[\r][\n]"
http-outgoing-1 << "Pragma: no-cache[\r][\n]"
http-outgoing-1 << "Expires: Fri, 12 Jun 2015 23:32:15 GMT[\r][\n]"
http-outgoing-1 << "Date: Fri, 12 Jun 2015 23:32:15 GMT[\r][\n]"
http-outgoing-1 << "Pragma: no-cache[\r][\n]"
http-outgoing-1 << "Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434187935725&s=UONfy12L7rfCJNqqDenD1ZuX/QM="; Path=/; Expires=Sat, 13-Jun-2015 09:32:15 GMT; HttpOnly[\r][\n]"
http-outgoing-1 << "Location: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true[\r][\n]"
http-outgoing-1 << "Content-Type: application/octet-stream[\r][\n]"
http-outgoing-1 << "Content-Length: 0[\r][\n]"
http-outgoing-1 << "Server: Jetty(6.1.26)[\r][\n]"
http-outgoing-1 << "[\r][\n]"
http-outgoing-1 << HTTP/1.1 307 TEMPORARY_REDIRECT
http-outgoing-1 << Cache-Control: no-cache
http-outgoing-1 << Expires: Fri, 12 Jun 2015 23:32:15 GMT
http-outgoing-1 << Date: Fri, 12 Jun 2015 23:32:15 GMT
http-outgoing-1 << Pragma: no-cache
http-outgoing-1 << Expires: Fri, 12 Jun 2015 23:32:15 GMT
http-outgoing-1 << Date: Fri, 12 Jun 2015 23:32:15 GMT
http-outgoing-1 << Pragma: no-cache
http-outgoing-1 << Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434187935725&s=UONfy12L7rfCJNqqDenD1ZuX/QM="; Path=/; Expires=Sat, 13-Jun-2015 09:32:15 GMT; HttpOnly
http-outgoing-1 << Location: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
http-outgoing-1 << Content-Type: application/octet-stream
http-outgoing-1 << Content-Length: 0
http-outgoing-1 << Server: Jetty(6.1.26)
Connection can be kept alive indefinitely
Cookie accepted [hadoop.auth=""u=michaeljones&p=michaeljones&t=simple&e=1434187935725&s=UONfy12L7rfCJNqqDenD1ZuX/QM="", version:0, domain:localhost, path:/, expiry:Sat Jun 13 19:32:15 AEST 2015]
Redirect to: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
http-outgoing-1: Shutdown connection
Connection discarded
http-outgoing-1: Close connection
Connection released: [id: 1][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
PUT file redirect: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 2][route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://michaels-air.bigpond:50075
Connecting to michaels-air.bigpond/10.0.0.2:50075
Connection established 10.0.0.2:49449<->10.0.0.2:50075
Executing request PUT /webhdfs/v1/user/michaeljones/apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-2 >> PUT /webhdfs/v1/user/michaeljones/apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1
http-outgoing-2 >> Content-Length: 0
http-outgoing-2 >> Host: michaels-air.bigpond:50075
http-outgoing-2 >> Connection: Keep-Alive
http-outgoing-2 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-2 >> Accept-Encoding: gzip,deflate
http-outgoing-2 >> "PUT /webhdfs/v1/user/michaeljones/apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1[\r][\n]"
http-outgoing-2 >> "Content-Length: 0[\r][\n]"
http-outgoing-2 >> "Host: michaels-air.bigpond:50075[\r][\n]"
http-outgoing-2 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-2 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-2 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-2 >> "[\r][\n]"
http-outgoing-2 << "HTTP/1.1 100 Continue[\r][\n]"
http-outgoing-2 << "[\r][\n]"
http-outgoing-2 << HTTP/1.1 100 Continue
http-outgoing-2 << "HTTP/1.1 201 Created[\r][\n]"
http-outgoing-2 << "Location: hdfs://localhost:9000/user/michaeljones/apache-empty.txt[\r][\n]"
http-outgoing-2 << "Content-Length: 0[\r][\n]"
http-outgoing-2 << "Connection: close[\r][\n]"
http-outgoing-2 << "[\r][\n]"
http-outgoing-2 << HTTP/1.1 201 Created
http-outgoing-2 << Location: hdfs://localhost:9000/user/michaeljones/apache-empty.txt
http-outgoing-2 << Content-Length: 0
http-outgoing-2 << Connection: close
http-outgoing-2: Shutdown connection
Connection discarded
http-outgoing-2: Close connection
Connection released: [id: 2][route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 3][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://localhost:50070
Connecting to localhost/127.0.0.1:50070
Connection established 127.0.0.1:49451<->127.0.0.1:50070
Executing request PUT /webhdfs/v1/user/michaeljones/pom.xml?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-3 >> PUT /webhdfs/v1/user/michaeljones/pom.xml?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1
http-outgoing-3 >> Content-Length: 0
http-outgoing-3 >> Host: localhost:50070
http-outgoing-3 >> Connection: Keep-Alive
http-outgoing-3 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-3 >> Accept-Encoding: gzip,deflate
http-outgoing-3 >> "PUT /webhdfs/v1/user/michaeljones/pom.xml?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1[\r][\n]"
http-outgoing-3 >> "Content-Length: 0[\r][\n]"
http-outgoing-3 >> "Host: localhost:50070[\r][\n]"
http-outgoing-3 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-3 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-3 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-3 >> "[\r][\n]"
http-outgoing-3 << "HTTP/1.1 307 TEMPORARY_REDIRECT[\r][\n]"
http-outgoing-3 << "Cache-Control: no-cache[\r][\n]"
http-outgoing-3 << "Expires: Fri, 12 Jun 2015 23:32:15 GMT[\r][\n]"
http-outgoing-3 << "Date: Fri, 12 Jun 2015 23:32:15 GMT[\r][\n]"
http-outgoing-3 << "Pragma: no-cache[\r][\n]"
http-outgoing-3 << "Expires: Fri, 12 Jun 2015 23:32:15 GMT[\r][\n]"
Connection manager is shutting down
http-outgoing-3 << "Date: Fri, 12 Jun 2015 23:32:15 GMT[\r][\n]"
http-outgoing-0: Close connection
http-outgoing-3 << "Pragma: no-cache[\r][\n]"
http-outgoing-0: Close connection
Connection manager shut down
Connection manager is shutting down
Connection manager shut down
http-outgoing-3 << "Content-Type: application/octet-stream[\r][\n]"
http-outgoing-3 << "Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434187935924&s=0UZ7vmwwVPlN7glzJNX0PvyQpN4="; Path=/; Expires=Sat, 13-Jun-2015 09:32:15 GMT; HttpOnly[\r][\n]"
http-outgoing-3 << "Location: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/pom.xml?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true[\r][\n]"
http-outgoing-3 << "Content-Length: 0[\r][\n]"
http-outgoing-3 << "Server: Jetty(6.1.26)[\r][\n]"
http-outgoing-3 << "[\r][\n]"
http-outgoing-3 << HTTP/1.1 307 TEMPORARY_REDIRECT
http-outgoing-3 << Cache-Control: no-cache
http-outgoing-3 << Expires: Fri, 12 Jun 2015 23:32:15 GMT
http-outgoing-3 << Date: Fri, 12 Jun 2015 23:32:15 GMT
http-outgoing-3 << Pragma: no-cache
http-outgoing-3 << Expires: Fri, 12 Jun 2015 23:32:15 GMT
http-outgoing-3 << Date: Fri, 12 Jun 2015 23:32:15 GMT
http-outgoing-3 << Pragma: no-cache
http-outgoing-3 << Content-Type: application/octet-stream
http-outgoing-3 << Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434187935924&s=0UZ7vmwwVPlN7glzJNX0PvyQpN4="; Path=/; Expires=Sat, 13-Jun-2015 09:32:15 GMT; HttpOnly
http-outgoing-3 << Location: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/pom.xml?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
http-outgoing-3 << Content-Length: 0
http-outgoing-3 << Server: Jetty(6.1.26)
Connection can be kept alive indefinitely
Cookie accepted [hadoop.auth=""u=michaeljones&p=michaeljones&t=simple&e=1434187935924&s=0UZ7vmwwVPlN7glzJNX0PvyQpN4="", version:0, domain:localhost, path:/, expiry:Sat Jun 13 19:32:15 AEST 2015]
Redirect to: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/pom.xml?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
http-outgoing-3: Shutdown connection
Connection discarded
http-outgoing-3: Close connection
Connection released: [id: 3][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
PUT file redirect: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/pom.xml?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 4][route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://michaels-air.bigpond:50075
Connecting to michaels-air.bigpond/10.0.0.2:50075
Connection established 10.0.0.2:49452<->10.0.0.2:50075
Executing request PUT /webhdfs/v1/user/michaeljones/pom.xml?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-4 >> PUT /webhdfs/v1/user/michaeljones/pom.xml?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1
http-outgoing-4 >> Transfer-Encoding: chunked
http-outgoing-4 >> Content-Type: application/octet-stream
http-outgoing-4 >> Host: michaels-air.bigpond:50075
http-outgoing-4 >> Connection: Keep-Alive
http-outgoing-4 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-4 >> Accept-Encoding: gzip,deflate
http-outgoing-4 >> "PUT /webhdfs/v1/user/michaeljones/pom.xml?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1[\r][\n]"
http-outgoing-4 >> "Transfer-Encoding: chunked[\r][\n]"
http-outgoing-4 >> "Content-Type: application/octet-stream[\r][\n]"
http-outgoing-4 >> "Host: michaels-air.bigpond:50075[\r][\n]"
http-outgoing-4 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-4 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-4 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-4 >> "[\r][\n]"
http-outgoing-4 >> "856[\r][\n]"
http-outgoing-4 >> "<?xml version="1.0" encoding="UTF-8"?>[\n]"
http-outgoing-4 >> "<project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">[\n]"
http-outgoing-4 >> "    <modelVersion>4.0.0</modelVersion>[\n]"
http-outgoing-4 >> "    <groupId>com.michaeljones</groupId>[\n]"
http-outgoing-4 >> "    <artifactId>HelloHadoopWorldMaven</artifactId>[\n]"
http-outgoing-4 >> "    <version>1.0-SNAPSHOT</version>[\n]"
http-outgoing-4 >> "    <packaging>jar</packaging>[\n]"
http-outgoing-4 >> "    <dependencies>[\n]"
http-outgoing-4 >> "        <!-- run bin/hadoop version to see the jar it was built with, which is this dependency -->[\n]"
http-outgoing-4 >> "        <dependency>[\n]"
http-outgoing-4 >> "            <groupId>org.apache.hadoop</groupId>[\n]"
http-outgoing-4 >> "            <artifactId>hadoop-common</artifactId>[\n]"
http-outgoing-4 >> "            <version>2.7.0</version>[\n]"
http-outgoing-4 >> "        </dependency>[\n]"
http-outgoing-4 >> "        <dependency>[\n]"
http-outgoing-4 >> "            <groupId>org.apache.hadoop</groupId>[\n]"
http-outgoing-4 >> "            <artifactId>hadoop-hdfs</artifactId>[\n]"
http-outgoing-4 >> "            <version>2.7.0</version>[\n]"
http-outgoing-4 >> "        </dependency>[\n]"
http-outgoing-4 >> "        <dependency>[\n]"
http-outgoing-4 >> "            <groupId>junit</groupId>[\n]"
http-outgoing-4 >> "            <artifactId>junit</artifactId>[\n]"
http-outgoing-4 >> "            <version>4.10</version>[\n]"
http-outgoing-4 >> "            <scope>test</scope>[\n]"
http-outgoing-4 >> "        </dependency>[\n]"
http-outgoing-4 >> "        <dependency>[\n]"
http-outgoing-4 >> "            <groupId>org.apache.hadoop</groupId>[\n]"
http-outgoing-4 >> "            <artifactId>hadoop-mapreduce-client-core</artifactId>[\n]"
http-outgoing-4 >> "            <version>2.7.0</version>[\n]"
http-outgoing-4 >> "        </dependency>[\n]"
http-outgoing-4 >> "        <dependency>[\n]"
http-outgoing-4 >> "            <groupId>org.apache.hadoop</groupId>[\n]"
http-outgoing-4 >> "            <artifactId>hadoop-mapreduce-client-common</artifactId>[\n]"
http-outgoing-4 >> "            <version>2.7.0</version>[\n]"
http-outgoing-4 >> "        </dependency>[\n]"
http-outgoing-4 >> "        <dependency>[\n]"
http-outgoing-4 >> "            <groupId>com.googlecode.json-simple</groupId>[\n]"
http-outgoing-4 >> "            <artifactId>json-simple</artifactId>[\n]"
http-outgoing-4 >> "            <version>1.1.1</version>[\n]"
http-outgoing-4 >> "        </dependency>[\n]"
http-outgoing-4 >> "        <dependency>[\n]"
http-outgoing-4 >> "            <groupId>org.apache.httpcomponents</groupId>[\n]"
http-outgoing-4 >> "            <artifactId>httpclient</artifactId>[\n]"
http-outgoing-4 >> "            <version>4.4-beta1</version>[\n]"
http-outgoing-4 >> "        </dependency>[\n]"
http-outgoing-4 >> "    </dependencies>[\n]"
http-outgoing-4 >> "    <properties>[\n]"
http-outgoing-4 >> "        <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>[\n]"
http-outgoing-4 >> "        <maven.compiler.source>1.7</maven.compiler.source>[\n]"
http-outgoing-4 >> "        <maven.compiler.target>1.7</maven.compiler.target>[\n]"
http-outgoing-4 >> "    </properties>[\n]"
http-outgoing-4 >> "</project>[\r][\n]"
http-outgoing-4 >> "0[\r][\n]"
http-outgoing-4 >> "[\r][\n]"
http-outgoing-4 << "HTTP/1.1 100 Continue[\r][\n]"
http-outgoing-4 << "[\r][\n]"
http-outgoing-4 << "HTTP/1.1 201 Created[\r][\n]"
http-outgoing-4 << "Location: hdfs://localhost:9000/user/michaeljones/pom.xml[\r][\n]"
http-outgoing-4 << "Content-Length: 0[\r][\n]"
http-outgoing-4 << "Connection: close[\r][\n]"
http-outgoing-4 << "[\r][\n]"
http-outgoing-4 << HTTP/1.1 100 Continue
http-outgoing-4 << HTTP/1.1 201 Created
http-outgoing-4 << Location: hdfs://localhost:9000/user/michaeljones/pom.xml
http-outgoing-4 << Content-Length: 0
http-outgoing-4 << Connection: close
http-outgoing-4: Shutdown connection
Connection discarded
http-outgoing-4: Close connection
Connection released: [id: 4][route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection manager is shutting down
Connection manager shut down
Jersey client testGetStringContent
{"FileStatuses":{"FileStatus":[
{"accessTime":1434094518288,"blockSize":134217728,"childrenNum":0,"fileId":18364,"group":"supergroup","length":10899,"modificationTime":1434094518324,"owner":"michaeljones","pathSuffix":"README.md","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434151935882,"blockSize":134217728,"childrenNum":0,"fileId":18419,"group":"supergroup","length":0,"modificationTime":1434151935894,"owner":"michaeljones","pathSuffix":"apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434094529413,"blockSize":134217728,"childrenNum":0,"fileId":18389,"group":"supergroup","length":0,"modificationTime":1434094529419,"owner":"michaeljones","pathSuffix":"empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434094517691,"blockSize":134217728,"childrenNum":0,"fileId":18362,"group":"supergroup","length":0,"modificationTime":1434094517697,"owner":"michaeljones","pathSuffix":"hello-apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434091626279,"blockSize":134217728,"childrenNum":0,"fileId":18298,"group":"supergroup","length":0,"modificationTime":1434091626286,"owner":"michaeljones","pathSuffix":"hello-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434094517577,"blockSize":134217728,"childrenNum":0,"fileId":18361,"group":"supergroup","length":0,"modificationTime":1434094517584,"owner":"michaeljones","pathSuffix":"hello-jersey-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434094529626,"blockSize":134217728,"childrenNum":0,"fileId":18390,"group":"supergroup","length":3678408,"modificationTime":1434094529811,"owner":"michaeljones","pathSuffix":"hello.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434151721877,"blockSize":134217728,"childrenNum":0,"fileId":18393,"group":"supergroup","length":20,"modificationTime":1434151722436,"owner":"michaeljones","pathSuffix":"hello.txt","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434094518094,"blockSize":134217728,"childrenNum":0,"fileId":18363,"group":"supergroup","length":93997,"modificationTime":1434094518134,"owner":"michaeljones","pathSuffix":"hellohadoop.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434151935993,"blockSize":134217728,"childrenNum":0,"fileId":18420,"group":"supergroup","length":2134,"modificationTime":1434151936019,"owner":"michaeljones","pathSuffix":"pom.xml","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434151723254,"blockSize":134217728,"childrenNum":0,"fileId":16388,"group":"supergroup","length":50,"modificationTime":1433119638967,"owner":"michaeljones","pathSuffix":"wcInput","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18401,"group":"supergroup","length":0,"modificationTime":1434151726430,"owner":"michaeljones","pathSuffix":"wcOutput","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},
{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18408,"group":"supergroup","length":0,"modificationTime":1434151728052,"owner":"michaeljones","pathSuffix":"wcOutputAnalysis","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},
{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18394,"group":"supergroup","length":0,"modificationTime":1434151725436,"owner":"michaeljones","pathSuffix":"wcOutputMain","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"}
]}}

Jersey client testGetStringContent
{"FileStatuses":{"FileStatus":[
{"accessTime":1434094518288,"blockSize":134217728,"childrenNum":0,"fileId":18364,"group":"supergroup","length":10899,"modificationTime":1434094518324,"owner":"michaeljones","pathSuffix":"README.md","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434151935882,"blockSize":134217728,"childrenNum":0,"fileId":18419,"group":"supergroup","length":0,"modificationTime":1434151935894,"owner":"michaeljones","pathSuffix":"apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434152149065,"blockSize":134217728,"childrenNum":0,"fileId":18421,"group":"supergroup","length":0,"modificationTime":1434152149071,"owner":"michaeljones","pathSuffix":"empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434094517691,"blockSize":134217728,"childrenNum":0,"fileId":18362,"group":"supergroup","length":0,"modificationTime":1434094517697,"owner":"michaeljones","pathSuffix":"hello-apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434091626279,"blockSize":134217728,"childrenNum":0,"fileId":18298,"group":"supergroup","length":0,"modificationTime":1434091626286,"owner":"michaeljones","pathSuffix":"hello-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434094517577,"blockSize":134217728,"childrenNum":0,"fileId":18361,"group":"supergroup","length":0,"modificationTime":1434094517584,"owner":"michaeljones","pathSuffix":"hello-jersey-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434094529626,"blockSize":134217728,"childrenNum":0,"fileId":18390,"group":"supergroup","length":3678408,"modificationTime":1434094529811,"owner":"michaeljones","pathSuffix":"hello.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434151721877,"blockSize":134217728,"childrenNum":0,"fileId":18393,"group":"supergroup","length":20,"modificationTime":1434151722436,"owner":"michaeljones","pathSuffix":"hello.txt","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434094518094,"blockSize":134217728,"childrenNum":0,"fileId":18363,"group":"supergroup","length":93997,"modificationTime":1434094518134,"owner":"michaeljones","pathSuffix":"hellohadoop.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434151935993,"blockSize":134217728,"childrenNum":0,"fileId":18420,"group":"supergroup","length":2134,"modificationTime":1434151936019,"owner":"michaeljones","pathSuffix":"pom.xml","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434151723254,"blockSize":134217728,"childrenNum":0,"fileId":16388,"group":"supergroup","length":50,"modificationTime":1433119638967,"owner":"michaeljones","pathSuffix":"wcInput","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18401,"group":"supergroup","length":0,"modificationTime":1434151726430,"owner":"michaeljones","pathSuffix":"wcOutput","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},
{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18408,"group":"supergroup","length":0,"modificationTime":1434151728052,"owner":"michaeljones","pathSuffix":"wcOutputAnalysis","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},
{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18394,"group":"supergroup","length":0,"modificationTime":1434151725436,"owner":"michaeljones","pathSuffix":"wcOutputMain","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"}
]}}

Jersey client testGetStringContent
{"FileStatuses":{"FileStatus":[
{"accessTime":1434094518288,"blockSize":134217728,"childrenNum":0,"fileId":18364,"group":"supergroup","length":10899,"modificationTime":1434094518324,"owner":"michaeljones","pathSuffix":"README.md","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434151935882,"blockSize":134217728,"childrenNum":0,"fileId":18419,"group":"supergroup","length":0,"modificationTime":1434151935894,"owner":"michaeljones","pathSuffix":"apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434152233030,"blockSize":134217728,"childrenNum":0,"fileId":18424,"group":"supergroup","length":0,"modificationTime":1434152233036,"owner":"michaeljones","pathSuffix":"empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434094517691,"blockSize":134217728,"childrenNum":0,"fileId":18362,"group":"supergroup","length":0,"modificationTime":1434094517697,"owner":"michaeljones","pathSuffix":"hello-apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434091626279,"blockSize":134217728,"childrenNum":0,"fileId":18298,"group":"supergroup","length":0,"modificationTime":1434091626286,"owner":"michaeljones","pathSuffix":"hello-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434094517577,"blockSize":134217728,"childrenNum":0,"fileId":18361,"group":"supergroup","length":0,"modificationTime":1434094517584,"owner":"michaeljones","pathSuffix":"hello-jersey-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434152196676,"blockSize":134217728,"childrenNum":0,"fileId":18423,"group":"supergroup","length":418360,"modificationTime":1434152196732,"owner":"michaeljones","pathSuffix":"hello.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434151721877,"blockSize":134217728,"childrenNum":0,"fileId":18393,"group":"supergroup","length":20,"modificationTime":1434151722436,"owner":"michaeljones","pathSuffix":"hello.txt","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434094518094,"blockSize":134217728,"childrenNum":0,"fileId":18363,"group":"supergroup","length":93997,"modificationTime":1434094518134,"owner":"michaeljones","pathSuffix":"hellohadoop.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434151935993,"blockSize":134217728,"childrenNum":0,"fileId":18420,"group":"supergroup","length":2134,"modificationTime":1434151936019,"owner":"michaeljones","pathSuffix":"pom.xml","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434151723254,"blockSize":134217728,"childrenNum":0,"fileId":16388,"group":"supergroup","length":50,"modificationTime":1433119638967,"owner":"michaeljones","pathSuffix":"wcInput","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18401,"group":"supergroup","length":0,"modificationTime":1434151726430,"owner":"michaeljones","pathSuffix":"wcOutput","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},
{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18408,"group":"supergroup","length":0,"modificationTime":1434151728052,"owner":"michaeljones","pathSuffix":"wcOutputAnalysis","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},
{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18394,"group":"supergroup","length":0,"modificationTime":1434151725436,"owner":"michaeljones","pathSuffix":"wcOutputMain","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"}
]}}

Jersey client testGetStringContent
{"FileStatuses":{"FileStatus":[
{"accessTime":1434094518288,"blockSize":134217728,"childrenNum":0,"fileId":18364,"group":"supergroup","length":10899,"modificationTime":1434094518324,"owner":"michaeljones","pathSuffix":"README.md","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434151935882,"blockSize":134217728,"childrenNum":0,"fileId":18419,"group":"supergroup","length":0,"modificationTime":1434151935894,"owner":"michaeljones","pathSuffix":"apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434152233030,"blockSize":134217728,"childrenNum":0,"fileId":18424,"group":"supergroup","length":0,"modificationTime":1434152233036,"owner":"michaeljones","pathSuffix":"empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434094517691,"blockSize":134217728,"childrenNum":0,"fileId":18362,"group":"supergroup","length":0,"modificationTime":1434094517697,"owner":"michaeljones","pathSuffix":"hello-apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434091626279,"blockSize":134217728,"childrenNum":0,"fileId":18298,"group":"supergroup","length":0,"modificationTime":1434091626286,"owner":"michaeljones","pathSuffix":"hello-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434094517577,"blockSize":134217728,"childrenNum":0,"fileId":18361,"group":"supergroup","length":0,"modificationTime":1434094517584,"owner":"michaeljones","pathSuffix":"hello-jersey-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434152196676,"blockSize":134217728,"childrenNum":0,"fileId":18423,"group":"supergroup","length":418360,"modificationTime":1434152196732,"owner":"michaeljones","pathSuffix":"hello.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434151721877,"blockSize":134217728,"childrenNum":0,"fileId":18393,"group":"supergroup","length":20,"modificationTime":1434151722436,"owner":"michaeljones","pathSuffix":"hello.txt","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434094518094,"blockSize":134217728,"childrenNum":0,"fileId":18363,"group":"supergroup","length":93997,"modificationTime":1434094518134,"owner":"michaeljones","pathSuffix":"hellohadoop.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434151935993,"blockSize":134217728,"childrenNum":0,"fileId":18420,"group":"supergroup","length":2134,"modificationTime":1434151936019,"owner":"michaeljones","pathSuffix":"pom.xml","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434151723254,"blockSize":134217728,"childrenNum":0,"fileId":16388,"group":"supergroup","length":50,"modificationTime":1433119638967,"owner":"michaeljones","pathSuffix":"wcInput","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18401,"group":"supergroup","length":0,"modificationTime":1434151726430,"owner":"michaeljones","pathSuffix":"wcOutput","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},
{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18408,"group":"supergroup","length":0,"modificationTime":1434151728052,"owner":"michaeljones","pathSuffix":"wcOutputAnalysis","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},
{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18394,"group":"supergroup","length":0,"modificationTime":1434151725436,"owner":"michaeljones","pathSuffix":"wcOutputMain","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"}
]}}

com.sun.jersey.client.property.chunkedEncodingSize: 1000000
com.sun.jersey.client.property.chunkedEncodingSize: 1000000
com.sun.jersey.client.property.chunkedEncodingSize: 1000000
Jersey client testGetStringContent
{"FileStatuses":{"FileStatus":[
{"accessTime":1434094518288,"blockSize":134217728,"childrenNum":0,"fileId":18364,"group":"supergroup","length":10899,"modificationTime":1434094518324,"owner":"michaeljones","pathSuffix":"README.md","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434151935882,"blockSize":134217728,"childrenNum":0,"fileId":18419,"group":"supergroup","length":0,"modificationTime":1434151935894,"owner":"michaeljones","pathSuffix":"apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434152668744,"blockSize":134217728,"childrenNum":0,"fileId":18426,"group":"supergroup","length":0,"modificationTime":1434152668752,"owner":"michaeljones","pathSuffix":"empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434094517691,"blockSize":134217728,"childrenNum":0,"fileId":18362,"group":"supergroup","length":0,"modificationTime":1434094517697,"owner":"michaeljones","pathSuffix":"hello-apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434091626279,"blockSize":134217728,"childrenNum":0,"fileId":18298,"group":"supergroup","length":0,"modificationTime":1434091626286,"owner":"michaeljones","pathSuffix":"hello-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434094517577,"blockSize":134217728,"childrenNum":0,"fileId":18361,"group":"supergroup","length":0,"modificationTime":1434094517584,"owner":"michaeljones","pathSuffix":"hello-jersey-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434152196676,"blockSize":134217728,"childrenNum":0,"fileId":18423,"group":"supergroup","length":418360,"modificationTime":1434152196732,"owner":"michaeljones","pathSuffix":"hello.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434151721877,"blockSize":134217728,"childrenNum":0,"fileId":18393,"group":"supergroup","length":20,"modificationTime":1434151722436,"owner":"michaeljones","pathSuffix":"hello.txt","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434094518094,"blockSize":134217728,"childrenNum":0,"fileId":18363,"group":"supergroup","length":93997,"modificationTime":1434094518134,"owner":"michaeljones","pathSuffix":"hellohadoop.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434151935993,"blockSize":134217728,"childrenNum":0,"fileId":18420,"group":"supergroup","length":2134,"modificationTime":1434151936019,"owner":"michaeljones","pathSuffix":"pom.xml","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434151723254,"blockSize":134217728,"childrenNum":0,"fileId":16388,"group":"supergroup","length":50,"modificationTime":1433119638967,"owner":"michaeljones","pathSuffix":"wcInput","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18401,"group":"supergroup","length":0,"modificationTime":1434151726430,"owner":"michaeljones","pathSuffix":"wcOutput","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},
{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18408,"group":"supergroup","length":0,"modificationTime":1434151728052,"owner":"michaeljones","pathSuffix":"wcOutputAnalysis","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},
{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18394,"group":"supergroup","length":0,"modificationTime":1434151725436,"owner":"michaeljones","pathSuffix":"wcOutputMain","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"}
]}}

com.sun.jersey.client.property.chunkedEncodingSize: 1000000
Jersey client testGetStringContent
{"FileStatuses":{"FileStatus":[
{"accessTime":1434094518288,"blockSize":134217728,"childrenNum":0,"fileId":18364,"group":"supergroup","length":10899,"modificationTime":1434094518324,"owner":"michaeljones","pathSuffix":"README.md","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434151935882,"blockSize":134217728,"childrenNum":0,"fileId":18419,"group":"supergroup","length":0,"modificationTime":1434151935894,"owner":"michaeljones","pathSuffix":"apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434152668744,"blockSize":134217728,"childrenNum":0,"fileId":18426,"group":"supergroup","length":0,"modificationTime":1434152668752,"owner":"michaeljones","pathSuffix":"empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434094517691,"blockSize":134217728,"childrenNum":0,"fileId":18362,"group":"supergroup","length":0,"modificationTime":1434094517697,"owner":"michaeljones","pathSuffix":"hello-apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434091626279,"blockSize":134217728,"childrenNum":0,"fileId":18298,"group":"supergroup","length":0,"modificationTime":1434091626286,"owner":"michaeljones","pathSuffix":"hello-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434094517577,"blockSize":134217728,"childrenNum":0,"fileId":18361,"group":"supergroup","length":0,"modificationTime":1434094517584,"owner":"michaeljones","pathSuffix":"hello-jersey-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434152196676,"blockSize":134217728,"childrenNum":0,"fileId":18423,"group":"supergroup","length":418360,"modificationTime":1434152196732,"owner":"michaeljones","pathSuffix":"hello.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434151721877,"blockSize":134217728,"childrenNum":0,"fileId":18393,"group":"supergroup","length":20,"modificationTime":1434151722436,"owner":"michaeljones","pathSuffix":"hello.txt","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434094518094,"blockSize":134217728,"childrenNum":0,"fileId":18363,"group":"supergroup","length":93997,"modificationTime":1434094518134,"owner":"michaeljones","pathSuffix":"hellohadoop.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434151935993,"blockSize":134217728,"childrenNum":0,"fileId":18420,"group":"supergroup","length":2134,"modificationTime":1434151936019,"owner":"michaeljones","pathSuffix":"pom.xml","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434151723254,"blockSize":134217728,"childrenNum":0,"fileId":16388,"group":"supergroup","length":50,"modificationTime":1433119638967,"owner":"michaeljones","pathSuffix":"wcInput","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18401,"group":"supergroup","length":0,"modificationTime":1434151726430,"owner":"michaeljones","pathSuffix":"wcOutput","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},
{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18408,"group":"supergroup","length":0,"modificationTime":1434151728052,"owner":"michaeljones","pathSuffix":"wcOutputAnalysis","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},
{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18394,"group":"supergroup","length":0,"modificationTime":1434151725436,"owner":"michaeljones","pathSuffix":"wcOutputMain","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"}
]}}

com.sun.jersey.client.property.chunkedEncodingSize: 1000000
com.sun.jersey.client.property.chunkedEncodingSize: 1000000
Requested Chunk size: 1000000 returned property: 1000000
Requested Chunk size: 1000000 returned property: 1000000
Requested Chunk size: 1000000 returned property: 1000000
Jersey client testGetStringContent
{"FileStatuses":{"FileStatus":[
{"accessTime":1434094518288,"blockSize":134217728,"childrenNum":0,"fileId":18364,"group":"supergroup","length":10899,"modificationTime":1434094518324,"owner":"michaeljones","pathSuffix":"README.md","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434151935882,"blockSize":134217728,"childrenNum":0,"fileId":18419,"group":"supergroup","length":0,"modificationTime":1434151935894,"owner":"michaeljones","pathSuffix":"apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434152956390,"blockSize":134217728,"childrenNum":0,"fileId":18428,"group":"supergroup","length":0,"modificationTime":1434152956401,"owner":"michaeljones","pathSuffix":"empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434094517691,"blockSize":134217728,"childrenNum":0,"fileId":18362,"group":"supergroup","length":0,"modificationTime":1434094517697,"owner":"michaeljones","pathSuffix":"hello-apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434091626279,"blockSize":134217728,"childrenNum":0,"fileId":18298,"group":"supergroup","length":0,"modificationTime":1434091626286,"owner":"michaeljones","pathSuffix":"hello-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434094517577,"blockSize":134217728,"childrenNum":0,"fileId":18361,"group":"supergroup","length":0,"modificationTime":1434094517584,"owner":"michaeljones","pathSuffix":"hello-jersey-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434152196676,"blockSize":134217728,"childrenNum":0,"fileId":18423,"group":"supergroup","length":418360,"modificationTime":1434152196732,"owner":"michaeljones","pathSuffix":"hello.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434151721877,"blockSize":134217728,"childrenNum":0,"fileId":18393,"group":"supergroup","length":20,"modificationTime":1434151722436,"owner":"michaeljones","pathSuffix":"hello.txt","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434094518094,"blockSize":134217728,"childrenNum":0,"fileId":18363,"group":"supergroup","length":93997,"modificationTime":1434094518134,"owner":"michaeljones","pathSuffix":"hellohadoop.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434151935993,"blockSize":134217728,"childrenNum":0,"fileId":18420,"group":"supergroup","length":2134,"modificationTime":1434151936019,"owner":"michaeljones","pathSuffix":"pom.xml","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434151723254,"blockSize":134217728,"childrenNum":0,"fileId":16388,"group":"supergroup","length":50,"modificationTime":1433119638967,"owner":"michaeljones","pathSuffix":"wcInput","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18401,"group":"supergroup","length":0,"modificationTime":1434151726430,"owner":"michaeljones","pathSuffix":"wcOutput","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},
{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18408,"group":"supergroup","length":0,"modificationTime":1434151728052,"owner":"michaeljones","pathSuffix":"wcOutputAnalysis","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},
{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18394,"group":"supergroup","length":0,"modificationTime":1434151725436,"owner":"michaeljones","pathSuffix":"wcOutputMain","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"}
]}}

Requested Chunk size: 1000000 returned property: 1000000
Jersey client testGetStringContent
{"FileStatuses":{"FileStatus":[
{"accessTime":1434094518288,"blockSize":134217728,"childrenNum":0,"fileId":18364,"group":"supergroup","length":10899,"modificationTime":1434094518324,"owner":"michaeljones","pathSuffix":"README.md","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434151935882,"blockSize":134217728,"childrenNum":0,"fileId":18419,"group":"supergroup","length":0,"modificationTime":1434151935894,"owner":"michaeljones","pathSuffix":"apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434152956390,"blockSize":134217728,"childrenNum":0,"fileId":18428,"group":"supergroup","length":0,"modificationTime":1434152956401,"owner":"michaeljones","pathSuffix":"empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434094517691,"blockSize":134217728,"childrenNum":0,"fileId":18362,"group":"supergroup","length":0,"modificationTime":1434094517697,"owner":"michaeljones","pathSuffix":"hello-apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434091626279,"blockSize":134217728,"childrenNum":0,"fileId":18298,"group":"supergroup","length":0,"modificationTime":1434091626286,"owner":"michaeljones","pathSuffix":"hello-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434094517577,"blockSize":134217728,"childrenNum":0,"fileId":18361,"group":"supergroup","length":0,"modificationTime":1434094517584,"owner":"michaeljones","pathSuffix":"hello-jersey-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434152196676,"blockSize":134217728,"childrenNum":0,"fileId":18423,"group":"supergroup","length":418360,"modificationTime":1434152196732,"owner":"michaeljones","pathSuffix":"hello.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434151721877,"blockSize":134217728,"childrenNum":0,"fileId":18393,"group":"supergroup","length":20,"modificationTime":1434151722436,"owner":"michaeljones","pathSuffix":"hello.txt","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434094518094,"blockSize":134217728,"childrenNum":0,"fileId":18363,"group":"supergroup","length":93997,"modificationTime":1434094518134,"owner":"michaeljones","pathSuffix":"hellohadoop.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434151935993,"blockSize":134217728,"childrenNum":0,"fileId":18420,"group":"supergroup","length":2134,"modificationTime":1434151936019,"owner":"michaeljones","pathSuffix":"pom.xml","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434151723254,"blockSize":134217728,"childrenNum":0,"fileId":16388,"group":"supergroup","length":50,"modificationTime":1433119638967,"owner":"michaeljones","pathSuffix":"wcInput","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18401,"group":"supergroup","length":0,"modificationTime":1434151726430,"owner":"michaeljones","pathSuffix":"wcOutput","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},
{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18408,"group":"supergroup","length":0,"modificationTime":1434151728052,"owner":"michaeljones","pathSuffix":"wcOutputAnalysis","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},
{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18394,"group":"supergroup","length":0,"modificationTime":1434151725436,"owner":"michaeljones","pathSuffix":"wcOutputMain","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"}
]}}

Requested Chunk size: 1000000 returned property: 1000000
Requested Chunk size: 1000000 returned property: 1000000
com.sun.jersey.client.property.chunkedEncodingSize: 1000000
Jersey client testGetStringContent
{"FileStatuses":{"FileStatus":[
{"accessTime":1434094518288,"blockSize":134217728,"childrenNum":0,"fileId":18364,"group":"supergroup","length":10899,"modificationTime":1434094518324,"owner":"michaeljones","pathSuffix":"README.md","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434151935882,"blockSize":134217728,"childrenNum":0,"fileId":18419,"group":"supergroup","length":0,"modificationTime":1434151935894,"owner":"michaeljones","pathSuffix":"apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434153478291,"blockSize":134217728,"childrenNum":0,"fileId":18429,"group":"supergroup","length":0,"modificationTime":1434153478298,"owner":"michaeljones","pathSuffix":"empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434094517691,"blockSize":134217728,"childrenNum":0,"fileId":18362,"group":"supergroup","length":0,"modificationTime":1434094517697,"owner":"michaeljones","pathSuffix":"hello-apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434091626279,"blockSize":134217728,"childrenNum":0,"fileId":18298,"group":"supergroup","length":0,"modificationTime":1434091626286,"owner":"michaeljones","pathSuffix":"hello-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434094517577,"blockSize":134217728,"childrenNum":0,"fileId":18361,"group":"supergroup","length":0,"modificationTime":1434094517584,"owner":"michaeljones","pathSuffix":"hello-jersey-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434152196676,"blockSize":134217728,"childrenNum":0,"fileId":18423,"group":"supergroup","length":418360,"modificationTime":1434152196732,"owner":"michaeljones","pathSuffix":"hello.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434151721877,"blockSize":134217728,"childrenNum":0,"fileId":18393,"group":"supergroup","length":20,"modificationTime":1434151722436,"owner":"michaeljones","pathSuffix":"hello.txt","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434094518094,"blockSize":134217728,"childrenNum":0,"fileId":18363,"group":"supergroup","length":93997,"modificationTime":1434094518134,"owner":"michaeljones","pathSuffix":"hellohadoop.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434151935993,"blockSize":134217728,"childrenNum":0,"fileId":18420,"group":"supergroup","length":2134,"modificationTime":1434151936019,"owner":"michaeljones","pathSuffix":"pom.xml","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434151723254,"blockSize":134217728,"childrenNum":0,"fileId":16388,"group":"supergroup","length":50,"modificationTime":1433119638967,"owner":"michaeljones","pathSuffix":"wcInput","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18401,"group":"supergroup","length":0,"modificationTime":1434151726430,"owner":"michaeljones","pathSuffix":"wcOutput","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},
{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18408,"group":"supergroup","length":0,"modificationTime":1434151728052,"owner":"michaeljones","pathSuffix":"wcOutputAnalysis","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},
{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18394,"group":"supergroup","length":0,"modificationTime":1434151725436,"owner":"michaeljones","pathSuffix":"wcOutputMain","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"}
]}}

com.sun.jersey.client.property.chunkedEncodingSize: 1000000
com.sun.jersey.client.property.chunkedEncodingSize: 1000000
com.sun.jersey.client.property.chunkedEncodingSize: 1048576
Jersey client testGetStringContent
{"FileStatuses":{"FileStatus":[
{"accessTime":1434094518288,"blockSize":134217728,"childrenNum":0,"fileId":18364,"group":"supergroup","length":10899,"modificationTime":1434094518324,"owner":"michaeljones","pathSuffix":"README.md","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434151935882,"blockSize":134217728,"childrenNum":0,"fileId":18419,"group":"supergroup","length":0,"modificationTime":1434151935894,"owner":"michaeljones","pathSuffix":"apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434153693402,"blockSize":134217728,"childrenNum":0,"fileId":18430,"group":"supergroup","length":0,"modificationTime":1434153693421,"owner":"michaeljones","pathSuffix":"empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434094517691,"blockSize":134217728,"childrenNum":0,"fileId":18362,"group":"supergroup","length":0,"modificationTime":1434094517697,"owner":"michaeljones","pathSuffix":"hello-apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434091626279,"blockSize":134217728,"childrenNum":0,"fileId":18298,"group":"supergroup","length":0,"modificationTime":1434091626286,"owner":"michaeljones","pathSuffix":"hello-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434094517577,"blockSize":134217728,"childrenNum":0,"fileId":18361,"group":"supergroup","length":0,"modificationTime":1434094517584,"owner":"michaeljones","pathSuffix":"hello-jersey-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434152196676,"blockSize":134217728,"childrenNum":0,"fileId":18423,"group":"supergroup","length":418360,"modificationTime":1434152196732,"owner":"michaeljones","pathSuffix":"hello.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434151721877,"blockSize":134217728,"childrenNum":0,"fileId":18393,"group":"supergroup","length":20,"modificationTime":1434151722436,"owner":"michaeljones","pathSuffix":"hello.txt","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434094518094,"blockSize":134217728,"childrenNum":0,"fileId":18363,"group":"supergroup","length":93997,"modificationTime":1434094518134,"owner":"michaeljones","pathSuffix":"hellohadoop.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434151935993,"blockSize":134217728,"childrenNum":0,"fileId":18420,"group":"supergroup","length":2134,"modificationTime":1434151936019,"owner":"michaeljones","pathSuffix":"pom.xml","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434151723254,"blockSize":134217728,"childrenNum":0,"fileId":16388,"group":"supergroup","length":50,"modificationTime":1433119638967,"owner":"michaeljones","pathSuffix":"wcInput","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18401,"group":"supergroup","length":0,"modificationTime":1434151726430,"owner":"michaeljones","pathSuffix":"wcOutput","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},
{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18408,"group":"supergroup","length":0,"modificationTime":1434151728052,"owner":"michaeljones","pathSuffix":"wcOutputAnalysis","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},
{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18394,"group":"supergroup","length":0,"modificationTime":1434151725436,"owner":"michaeljones","pathSuffix":"wcOutputMain","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"}
]}}

com.sun.jersey.client.property.chunkedEncodingSize: 1048576
com.sun.jersey.client.property.chunkedEncodingSize: 1048576
com.sun.jersey.client.property.chunkedEncodingSize: 1048576
Jersey client testGetStringContent
{"FileStatuses":{"FileStatus":[
{"accessTime":1434094518288,"blockSize":134217728,"childrenNum":0,"fileId":18364,"group":"supergroup","length":10899,"modificationTime":1434094518324,"owner":"michaeljones","pathSuffix":"README.md","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434151935882,"blockSize":134217728,"childrenNum":0,"fileId":18419,"group":"supergroup","length":0,"modificationTime":1434151935894,"owner":"michaeljones","pathSuffix":"apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434153959661,"blockSize":134217728,"childrenNum":0,"fileId":18431,"group":"supergroup","length":0,"modificationTime":1434153959668,"owner":"michaeljones","pathSuffix":"empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434094517691,"blockSize":134217728,"childrenNum":0,"fileId":18362,"group":"supergroup","length":0,"modificationTime":1434094517697,"owner":"michaeljones","pathSuffix":"hello-apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434091626279,"blockSize":134217728,"childrenNum":0,"fileId":18298,"group":"supergroup","length":0,"modificationTime":1434091626286,"owner":"michaeljones","pathSuffix":"hello-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434094517577,"blockSize":134217728,"childrenNum":0,"fileId":18361,"group":"supergroup","length":0,"modificationTime":1434094517584,"owner":"michaeljones","pathSuffix":"hello-jersey-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434152196676,"blockSize":134217728,"childrenNum":0,"fileId":18423,"group":"supergroup","length":418360,"modificationTime":1434152196732,"owner":"michaeljones","pathSuffix":"hello.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434151721877,"blockSize":134217728,"childrenNum":0,"fileId":18393,"group":"supergroup","length":20,"modificationTime":1434151722436,"owner":"michaeljones","pathSuffix":"hello.txt","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434094518094,"blockSize":134217728,"childrenNum":0,"fileId":18363,"group":"supergroup","length":93997,"modificationTime":1434094518134,"owner":"michaeljones","pathSuffix":"hellohadoop.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434151935993,"blockSize":134217728,"childrenNum":0,"fileId":18420,"group":"supergroup","length":2134,"modificationTime":1434151936019,"owner":"michaeljones","pathSuffix":"pom.xml","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434151723254,"blockSize":134217728,"childrenNum":0,"fileId":16388,"group":"supergroup","length":50,"modificationTime":1433119638967,"owner":"michaeljones","pathSuffix":"wcInput","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18401,"group":"supergroup","length":0,"modificationTime":1434151726430,"owner":"michaeljones","pathSuffix":"wcOutput","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},
{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18408,"group":"supergroup","length":0,"modificationTime":1434151728052,"owner":"michaeljones","pathSuffix":"wcOutputAnalysis","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},
{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18394,"group":"supergroup","length":0,"modificationTime":1434151725436,"owner":"michaeljones","pathSuffix":"wcOutputMain","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"}
]}}

com.sun.jersey.client.property.chunkedEncodingSize: 1048576
com.sun.jersey.client.property.chunkedEncodingSize: 1048576
Jersey client testGetStringContent
{"FileStatuses":{"FileStatus":[
{"accessTime":1434094518288,"blockSize":134217728,"childrenNum":0,"fileId":18364,"group":"supergroup","length":10899,"modificationTime":1434094518324,"owner":"michaeljones","pathSuffix":"README.md","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434151935882,"blockSize":134217728,"childrenNum":0,"fileId":18419,"group":"supergroup","length":0,"modificationTime":1434151935894,"owner":"michaeljones","pathSuffix":"apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434158380974,"blockSize":134217728,"childrenNum":0,"fileId":18432,"group":"supergroup","length":0,"modificationTime":1434158380995,"owner":"michaeljones","pathSuffix":"empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434094517691,"blockSize":134217728,"childrenNum":0,"fileId":18362,"group":"supergroup","length":0,"modificationTime":1434094517697,"owner":"michaeljones","pathSuffix":"hello-apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434091626279,"blockSize":134217728,"childrenNum":0,"fileId":18298,"group":"supergroup","length":0,"modificationTime":1434091626286,"owner":"michaeljones","pathSuffix":"hello-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434094517577,"blockSize":134217728,"childrenNum":0,"fileId":18361,"group":"supergroup","length":0,"modificationTime":1434094517584,"owner":"michaeljones","pathSuffix":"hello-jersey-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434152196676,"blockSize":134217728,"childrenNum":0,"fileId":18423,"group":"supergroup","length":418360,"modificationTime":1434152196732,"owner":"michaeljones","pathSuffix":"hello.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434151721877,"blockSize":134217728,"childrenNum":0,"fileId":18393,"group":"supergroup","length":20,"modificationTime":1434151722436,"owner":"michaeljones","pathSuffix":"hello.txt","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434094518094,"blockSize":134217728,"childrenNum":0,"fileId":18363,"group":"supergroup","length":93997,"modificationTime":1434094518134,"owner":"michaeljones","pathSuffix":"hellohadoop.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434151935993,"blockSize":134217728,"childrenNum":0,"fileId":18420,"group":"supergroup","length":2134,"modificationTime":1434151936019,"owner":"michaeljones","pathSuffix":"pom.xml","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434151723254,"blockSize":134217728,"childrenNum":0,"fileId":16388,"group":"supergroup","length":50,"modificationTime":1433119638967,"owner":"michaeljones","pathSuffix":"wcInput","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18401,"group":"supergroup","length":0,"modificationTime":1434151726430,"owner":"michaeljones","pathSuffix":"wcOutput","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},
{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18408,"group":"supergroup","length":0,"modificationTime":1434151728052,"owner":"michaeljones","pathSuffix":"wcOutputAnalysis","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},
{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18394,"group":"supergroup","length":0,"modificationTime":1434151725436,"owner":"michaeljones","pathSuffix":"wcOutputMain","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"}
]}}

Jersey client testGetStringContent
{"FileStatuses":{"FileStatus":[
{"accessTime":1434094518288,"blockSize":134217728,"childrenNum":0,"fileId":18364,"group":"supergroup","length":10899,"modificationTime":1434094518324,"owner":"michaeljones","pathSuffix":"README.md","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434151935882,"blockSize":134217728,"childrenNum":0,"fileId":18419,"group":"supergroup","length":0,"modificationTime":1434151935894,"owner":"michaeljones","pathSuffix":"apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434158536867,"blockSize":134217728,"childrenNum":0,"fileId":18433,"group":"supergroup","length":0,"modificationTime":1434158536874,"owner":"michaeljones","pathSuffix":"empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434094517691,"blockSize":134217728,"childrenNum":0,"fileId":18362,"group":"supergroup","length":0,"modificationTime":1434094517697,"owner":"michaeljones","pathSuffix":"hello-apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434091626279,"blockSize":134217728,"childrenNum":0,"fileId":18298,"group":"supergroup","length":0,"modificationTime":1434091626286,"owner":"michaeljones","pathSuffix":"hello-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434094517577,"blockSize":134217728,"childrenNum":0,"fileId":18361,"group":"supergroup","length":0,"modificationTime":1434094517584,"owner":"michaeljones","pathSuffix":"hello-jersey-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434158537112,"blockSize":134217728,"childrenNum":0,"fileId":18434,"group":"supergroup","length":457362,"modificationTime":1434158537273,"owner":"michaeljones","pathSuffix":"hello.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434151721877,"blockSize":134217728,"childrenNum":0,"fileId":18393,"group":"supergroup","length":20,"modificationTime":1434151722436,"owner":"michaeljones","pathSuffix":"hello.txt","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434094518094,"blockSize":134217728,"childrenNum":0,"fileId":18363,"group":"supergroup","length":93997,"modificationTime":1434094518134,"owner":"michaeljones","pathSuffix":"hellohadoop.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434151935993,"blockSize":134217728,"childrenNum":0,"fileId":18420,"group":"supergroup","length":2134,"modificationTime":1434151936019,"owner":"michaeljones","pathSuffix":"pom.xml","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434151723254,"blockSize":134217728,"childrenNum":0,"fileId":16388,"group":"supergroup","length":50,"modificationTime":1433119638967,"owner":"michaeljones","pathSuffix":"wcInput","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18401,"group":"supergroup","length":0,"modificationTime":1434151726430,"owner":"michaeljones","pathSuffix":"wcOutput","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},
{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18408,"group":"supergroup","length":0,"modificationTime":1434151728052,"owner":"michaeljones","pathSuffix":"wcOutputAnalysis","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},
{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18394,"group":"supergroup","length":0,"modificationTime":1434151725436,"owner":"michaeljones","pathSuffix":"wcOutputMain","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"}
]}}

com.sun.jersey.client.property.chunkedEncodingSize: 1048576
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 0][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://localhost:50070
Connecting to localhost/127.0.0.1:50070
Connection established 127.0.0.1:50345<->127.0.0.1:50070
Executing request GET /webhdfs/v1/user/michaeljones/?user.name=michaeljones&op=LISTSTATUS HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-0 >> GET /webhdfs/v1/user/michaeljones/?user.name=michaeljones&op=LISTSTATUS HTTP/1.1
http-outgoing-0 >> accept: application/json
http-outgoing-0 >> Host: localhost:50070
http-outgoing-0 >> Connection: Keep-Alive
http-outgoing-0 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-0 >> Accept-Encoding: gzip,deflate
http-outgoing-0 >> "GET /webhdfs/v1/user/michaeljones/?user.name=michaeljones&op=LISTSTATUS HTTP/1.1[\r][\n]"
http-outgoing-0 >> "accept: application/json[\r][\n]"
http-outgoing-0 >> "Host: localhost:50070[\r][\n]"
http-outgoing-0 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-0 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-0 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-0 >> "[\r][\n]"
http-outgoing-0 << "HTTP/1.1 200 OK[\r][\n]"
http-outgoing-0 << "Cache-Control: no-cache[\r][\n]"
http-outgoing-0 << "Expires: Sat, 13 Jun 2015 01:30:09 GMT[\r][\n]"
http-outgoing-0 << "Date: Sat, 13 Jun 2015 01:30:09 GMT[\r][\n]"
http-outgoing-0 << "Pragma: no-cache[\r][\n]"
http-outgoing-0 << "Expires: Sat, 13 Jun 2015 01:30:09 GMT[\r][\n]"
http-outgoing-0 << "Date: Sat, 13 Jun 2015 01:30:09 GMT[\r][\n]"
http-outgoing-0 << "Pragma: no-cache[\r][\n]"
http-outgoing-0 << "Content-Type: application/json[\r][\n]"
http-outgoing-0 << "Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434195009674&s=7zIkDOOIPqbm7vdpe5YDkvypITs="; Path=/; Expires=Sat, 13-Jun-2015 11:30:09 GMT; HttpOnly[\r][\n]"
http-outgoing-0 << "Transfer-Encoding: chunked[\r][\n]"
http-outgoing-0 << "Server: Jetty(6.1.26)[\r][\n]"
http-outgoing-0 << "[\r][\n]"
http-outgoing-0 << "E9C[\r][\n]"
http-outgoing-0 << "{"FileStatuses":{"FileStatus":[[\n]"
http-outgoing-0 << "{"accessTime":1434094518288,"blockSize":134217728,"childrenNum":0,"fileId":18364,"group":"supergroup","length":10899,"modificationTime":1434094518324,"owner":"michaeljones","pathSuffix":"README.md","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434151935882,"blockSize":134217728,"childrenNum":0,"fileId":18419,"group":"supergroup","length":0,"modificationTime":1434151935894,"owner":"michaeljones","pathSuffix":"apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434158893981,"blockSize":134217728,"childrenNum":0,"fileId":18435,"group":"supergroup","length":0,"modificationTime":1434158893986,"owner":"michaeljones","pathSuffix":"empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434094517691,"blockSize":134217728,"childrenNum":0,"fileId":18362,"group":"supergroup","length":0,"modificationTime":1434094517697,"owner":"michaeljones","pathSuffix":"hello-apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434091626279,"blockSize":134217728,"childrenNum":0,"fileId":18298,"group":"supergroup","length":0,"modificationTime":1434091626286,"owner":"michaeljones","pathSuffix":"hello-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434094517577,"blockSize":134217728,"childrenNum":0,"fileId":18361,"group":"supergroup","length":0,"modificationTime":1434094517584,"owner":"michaeljones","pathSuffix":"hello-jersey-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434158894531,"blockSize":134217728,"childrenNum":0,"fileId":18437,"group":"supergroup","length":461138,"modificationTime":1434158894573,"owner":"michaeljones","pathSuffix":"hello.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434151721877,"blockSize":134217728,"childrenNum":0,"fileId":18393,"group":"supergroup","length":20,"modificationTime":1434151722436,"owner":"michaeljones","pathSuffix":"hello.txt","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434094518094,"blockSize":134217728,"childrenNum":0,"fileId":18363,"group":"supergroup","length":93997,"modificationTime":1434094518134,"owner":"michaeljones","pathSuffix":"hellohadoop.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434151935993,"blockSize":134217728,"childrenNum":0,"fileId":18420,"group":"supergroup","length":2134,"modificationTime":1434151936019,"owner":"michaeljones","pathSuffix":"pom.xml","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434151723254,"blockSize":134217728,"childrenNum":0,"fileId":16388,"group":"supergroup","length":50,"modificationTime":1433119638967,"owner":"michaeljones","pathSuffix":"wcInput","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18401,"group":"supergroup","length":0,"modificationTime":1434151726430,"owner":"michaeljones","pathSuffix":"wcOutput","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},[\n]"
http-outgoing-0 << "{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18408,"group":"supergroup","length":0,"modificationTime":1434151728052,"owner":"michaeljones","pathSuffix":"wcOutputAnalysis","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},[\n]"
http-outgoing-0 << "{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18394,"group":"supergroup","length":0,"modificationTime":1434151725436,"owner":"michaeljones","pathSuffix":"wcOutputMain","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"}[\n]"
http-outgoing-0 << "]}}[\n]"
http-outgoing-0 << "[\r][\n]"
http-outgoing-0 << "0[\r][\n]"
http-outgoing-0 << "[\r][\n]"
http-outgoing-0 << HTTP/1.1 200 OK
http-outgoing-0 << Cache-Control: no-cache
http-outgoing-0 << Expires: Sat, 13 Jun 2015 01:30:09 GMT
http-outgoing-0 << Date: Sat, 13 Jun 2015 01:30:09 GMT
http-outgoing-0 << Pragma: no-cache
http-outgoing-0 << Expires: Sat, 13 Jun 2015 01:30:09 GMT
http-outgoing-0 << Date: Sat, 13 Jun 2015 01:30:09 GMT
http-outgoing-0 << Pragma: no-cache
http-outgoing-0 << Content-Type: application/json
http-outgoing-0 << Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434195009674&s=7zIkDOOIPqbm7vdpe5YDkvypITs="; Path=/; Expires=Sat, 13-Jun-2015 11:30:09 GMT; HttpOnly
http-outgoing-0 << Transfer-Encoding: chunked
http-outgoing-0 << Server: Jetty(6.1.26)
Connection can be kept alive indefinitely
Cookie accepted [hadoop.auth=""u=michaeljones&p=michaeljones&t=simple&e=1434195009674&s=7zIkDOOIPqbm7vdpe5YDkvypITs="", version:0, domain:localhost, path:/, expiry:Sat Jun 13 21:30:09 AEST 2015]
Connection [id: 0][route: {}->http://localhost:50070] can be kept alive indefinitely
Connection released: [id: 0][route: {}->http://localhost:50070][total kept alive: 1; route allocated: 1 of 2; total allocated: 1 of 20]
Connection manager is shutting down
http-outgoing-0: Close connection
http-outgoing-0: Close connection
Connection manager shut down
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 1][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://localhost:50070
Connecting to localhost/127.0.0.1:50070
Connection established 127.0.0.1:50348<->127.0.0.1:50070
Executing request PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-1 >> PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1
http-outgoing-1 >> Content-Length: 0
http-outgoing-1 >> Host: localhost:50070
http-outgoing-1 >> Connection: Keep-Alive
http-outgoing-1 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-1 >> Accept-Encoding: gzip,deflate
http-outgoing-1 >> "PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1[\r][\n]"
http-outgoing-1 >> "Content-Length: 0[\r][\n]"
http-outgoing-1 >> "Host: localhost:50070[\r][\n]"
http-outgoing-1 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-1 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-1 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-1 >> "[\r][\n]"
http-outgoing-1 << "HTTP/1.1 307 TEMPORARY_REDIRECT[\r][\n]"
http-outgoing-1 << "Cache-Control: no-cache[\r][\n]"
http-outgoing-1 << "Expires: Sat, 13 Jun 2015 01:30:10 GMT[\r][\n]"
http-outgoing-1 << "Date: Sat, 13 Jun 2015 01:30:10 GMT[\r][\n]"
http-outgoing-1 << "Pragma: no-cache[\r][\n]"
http-outgoing-1 << "Expires: Sat, 13 Jun 2015 01:30:10 GMT[\r][\n]"
http-outgoing-1 << "Date: Sat, 13 Jun 2015 01:30:10 GMT[\r][\n]"
http-outgoing-1 << "Pragma: no-cache[\r][\n]"
http-outgoing-1 << "Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434195010174&s=OyPciL3alRnnpz7DnYEWV3HgUkA="; Path=/; Expires=Sat, 13-Jun-2015 11:30:10 GMT; HttpOnly[\r][\n]"
http-outgoing-1 << "Location: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true[\r][\n]"
http-outgoing-1 << "Content-Type: application/octet-stream[\r][\n]"
http-outgoing-1 << "Content-Length: 0[\r][\n]"
http-outgoing-1 << "Server: Jetty(6.1.26)[\r][\n]"
http-outgoing-1 << "[\r][\n]"
http-outgoing-1 << HTTP/1.1 307 TEMPORARY_REDIRECT
http-outgoing-1 << Cache-Control: no-cache
http-outgoing-1 << Expires: Sat, 13 Jun 2015 01:30:10 GMT
http-outgoing-1 << Date: Sat, 13 Jun 2015 01:30:10 GMT
http-outgoing-1 << Pragma: no-cache
http-outgoing-1 << Expires: Sat, 13 Jun 2015 01:30:10 GMT
http-outgoing-1 << Date: Sat, 13 Jun 2015 01:30:10 GMT
http-outgoing-1 << Pragma: no-cache
http-outgoing-1 << Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434195010174&s=OyPciL3alRnnpz7DnYEWV3HgUkA="; Path=/; Expires=Sat, 13-Jun-2015 11:30:10 GMT; HttpOnly
http-outgoing-1 << Location: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
http-outgoing-1 << Content-Type: application/octet-stream
http-outgoing-1 << Content-Length: 0
http-outgoing-1 << Server: Jetty(6.1.26)
Connection can be kept alive indefinitely
Cookie accepted [hadoop.auth=""u=michaeljones&p=michaeljones&t=simple&e=1434195010174&s=OyPciL3alRnnpz7DnYEWV3HgUkA="", version:0, domain:localhost, path:/, expiry:Sat Jun 13 21:30:10 AEST 2015]
Redirect to: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
http-outgoing-1: Shutdown connection
Connection discarded
http-outgoing-1: Close connection
Connection released: [id: 1][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 2][route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://michaels-air.bigpond:50075
Connecting to michaels-air.bigpond/10.0.0.2:50075
Connection established 10.0.0.2:50349<->10.0.0.2:50075
Executing request PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-2 >> PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1
http-outgoing-2 >> Content-Length: 0
http-outgoing-2 >> Host: michaels-air.bigpond:50075
http-outgoing-2 >> Connection: Keep-Alive
http-outgoing-2 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-2 >> Accept-Encoding: gzip,deflate
http-outgoing-2 >> "PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1[\r][\n]"
http-outgoing-2 >> "Content-Length: 0[\r][\n]"
http-outgoing-2 >> "Host: michaels-air.bigpond:50075[\r][\n]"
http-outgoing-2 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-2 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-2 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-2 >> "[\r][\n]"
http-outgoing-2 << "HTTP/1.1 100 Continue[\r][\n]"
http-outgoing-2 << "[\r][\n]"
http-outgoing-2 << HTTP/1.1 100 Continue
http-outgoing-2 << "HTTP/1.1 201 Created[\r][\n]"
http-outgoing-2 << "Location: hdfs://localhost:9000/user/michaeljones/hello-apache-empty.txt[\r][\n]"
http-outgoing-2 << "Content-Length: 0[\r][\n]"
http-outgoing-2 << "Connection: close[\r][\n]"
http-outgoing-2 << "[\r][\n]"
http-outgoing-2 << HTTP/1.1 201 Created
http-outgoing-2 << Location: hdfs://localhost:9000/user/michaeljones/hello-apache-empty.txt
http-outgoing-2 << Content-Length: 0
http-outgoing-2 << Connection: close
http-outgoing-2: Shutdown connection
Connection discarded
http-outgoing-2: Close connection
Connection released: [id: 2][route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection manager is shutting down
Connection manager shut down
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 3][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://localhost:50070
Connecting to localhost/127.0.0.1:50070
Connection established 127.0.0.1:50355<->127.0.0.1:50070
Executing request PUT /webhdfs/v1/user/michaeljones/README.md?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-3 >> PUT /webhdfs/v1/user/michaeljones/README.md?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1
http-outgoing-3 >> Transfer-Encoding: chunked
http-outgoing-3 >> Content-Type: application/octet-stream
http-outgoing-3 >> Host: localhost:50070
http-outgoing-3 >> Connection: Keep-Alive
http-outgoing-3 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-3 >> Accept-Encoding: gzip,deflate
http-outgoing-3 >> "PUT /webhdfs/v1/user/michaeljones/README.md?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1[\r][\n]"
http-outgoing-3 >> "Transfer-Encoding: chunked[\r][\n]"
http-outgoing-3 >> "Content-Type: application/octet-stream[\r][\n]"
http-outgoing-3 >> "Host: localhost:50070[\r][\n]"
http-outgoing-3 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-3 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-3 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-3 >> "[\r][\n]"
http-outgoing-3 >> "1000[\r][\n]"
http-outgoing-3 >> "# Hello-Hadoop-netbeans-OS-X[\n]"
http-outgoing-3 >> "Java Maven project for playing with the HDFS API without any 3rd party hadoop plugins.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## Aim of project[\n]"
http-outgoing-3 >> "Hello world/tutorial level for programmatically operating with a pseudo distributed hadoop configuration on OS X. Hadoop 2.7 on Yosemite.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## What this project demonstrates[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "This is work in progress and so far the following functionality is demonstrated:[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "1. Direct programmatic control of the HDFS and running map reduce jobs - all unit tests run from the IDE with hadoop configuration built into this project and under git control.[\n]"
http-outgoing-3 >> "2. Uploading of files to the HDFS by implementing a Web REST API client.[\n]"
http-outgoing-3 >> "3. Layered application code for maximum re-use and ease of test driven development. The client I wrote uses an interface which has allowed me to provide both a Jersey HTTP client implementation and an Apache HTTP client implementation for comparison between the two toolkits.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "The initial difficulty was working out how to run the program in the IDE and talk to the local pseudo distributed setup without using a 3rd party Hadoop plugin. Apparently there used to be a plugin for netbeans, but it has been discontinued. I am a newbie with this technology.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "The Apache Hadoop instructions for building and running java programs are via their command line build/run utility only. Getting the yahoo hadoop HDFS tutorial program to build in the IDE wasn't too hard. However, by default it will ignore the local Hadoop configuration and only operate with the local file system in local debug mode.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## Wading through the configuration[\n]"
http-outgoing-3 >> "Hadoop is designed to work with a number of different topologies, directory locations, levels of replication, simulated environments etc. so as we would expect nothing works unless the configuration is right.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "First Hadoop needs to be installed and configured in pseudo distributed mode such that it builds and runs test programs on the command line. The hadoop documentation has instructions for doing this. Documentation is online and also included in the installation: share/doc/hadoop/index.html. However this is not enough to get it to work in the IDE.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## The netbeans project settings that are needed to run with the HDFS from the IDE:[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "1. Get log4j configured to work in the IDE. Absence of log4j configuration won't stop hadoop from running, but we won't get to see useful error messages from hadoop without it.[\n]"
http-outgoing-3 >> "2. HADOOP_HOME environment variable project run (and test) property.[\n]"
http-outgoing-3 >> "3. Duplicate hadoop configuration in the classpath. The above environment variable does not pick up the hadoop configuration from its usual place. Yahoo's only suggestion is to run from the command line via the hadoop script. The Apache HDFS API documention says that configuration is looked for in the classpath, so I took the approach of duplicating the configuration (just 2 files) instead of figuring out how to get it to look in the installation path.[\n]"
http-outgoing-3 >> "4. The correct Maven dependencies. If not all the jar depenencies are there the program may build and run, but it won't talk to the HDFS if it doesn't load the HDFS jars.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "I think that the setup of this project would probably work on Linux too.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## Working through trouble shooting the HDFS project settings[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "Issue 1 above shows up as:[\n]"
http-outgoing-3 >> "<pre><code>[\n]"
http-outgoing-3 >> "log4j:WARN No appenders could be found for logger (org.apache.hadoop.util.Shell).[\n]"
http-outgoing-3 >> "log4j:WARN Please initialize the log4j system properly.[\n]"
http-outgoing-3 >> "log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.[\n]"
http-outgoing-3 >> "</pre></code>[\n]"
http-outgoing-3 >> "This is solved by putting a log4j.properties configuration file in the classpath. For a Maven build getting files into the classpath can be achieved by putting them in src/main/resources. I don't think this is in the classpath, but the build will then copy the file into ./target/classes/ which is in the classpath.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "Issue 2 above shows up as:[\n]"
http-outgoing-3 >> "<pre><code>[\n]"
http-outgoing-3 >> "Failed to detect a valid hadoop home directory[\n]"
http-outgoing-3 >> "java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.[\n]"
http-outgoing-3 >> "</code></pre>[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "This is fixed by going into the project properties => Build => Actions => Run Project and adding the environmen[\r][\n]"
http-outgoing-3 >> "1000[\r][\n]"
http-outgoing-3 >> "t variable for HADOOP_HOME. This will result in an entry in the Maven POM. Repeat for "Test Project", "Debug Project" etc.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "Issue 3. shows up as running, but creating a file on the local file system instead of the HDFS. This was fixed       looking at the HDFS API documentation for org.apache.hadoop.conf.Configuration. This documentation is under the chapter: C API libhdfs HDFS which has a link to the HDFS API under "The APIs" (I strangely cannot find this in the main index). On my installation the HDFS API documentation link is file:///opt/local/hadoop-2.7.0/share/doc/hadoop/api/org/apache/hadoop/fs/FileSystem.html.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "This documentation told me that hadoop loads core-site.xml and core-default.xml in the classpath. Classpath for a Maven build can be reached by placing these files in the directory src/main/resources (see logging configuration above). I added hdfs-site instead of core-default (which doesn't exist on my 2.7 install) into the src/main/resources project directory.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "Issue 3 shows up as:[\n]"
http-outgoing-3 >> "<pre><code>[\n]"
http-outgoing-3 >> "java.io.IOException: "hadoop No FileSystem for scheme: hdfs".[\n]"
http-outgoing-3 >> "</code></pre>[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "This is part of the build dependency problem. The various threads on stackoverflow etc. suggested that a minimum dependency was the jar for hadoop-core. However, there is no such jar on 2.7. I ran the hadoop command to dump version and got this:[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "<pre><code>[\n]"
http-outgoing-3 >> "bin/hadoop version[\n]"
http-outgoing-3 >> "Hadoop 2.7.0[\n]"
http-outgoing-3 >> "Subversion https://git-wip-us.apache.org/repos/asf/hadoop.git -r d4c8d4d4d203c934e8074b31289a28724c0842cf[\n]"
http-outgoing-3 >> "Compiled by jenkins on 2015-04-10T18:40Z[\n]"
http-outgoing-3 >> "Compiled with protoc 2.5.0[\n]"
http-outgoing-3 >> "From source with checksum a9e90912c37a35c3195d23951fd18f[\n]"
http-outgoing-3 >> "This command was run using /opt/local/hadoop-2.7.0/share/hadoop/common/hadoop-common-2.7.0.jar[\n]"
http-outgoing-3 >> "</code></pre>[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "I noted the jar name at the end and added it as a dependency to the POM. This can either be hand coded in or right click pom.xml => Insert Code => Add Dependency => Search => query hadoop-common and select version which was 2.7.0 [jar] - central. Maven will then add dependencies to other hadoop jars in the "Dependencies" group in the project explorer. Netbeans will then download these dependencies before the next build. They go into ~/.m2/repository should they ever need to be cleaned out (Netbeans doesn't seem to have an IDE remove dependency option).[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "After doing the above project built, but showed up the "no filesystem error". I noticed that Maven had not pulled in any hdfs jars matching the jars in my share/hadoop/hdfs installation directory. So I took a guess that it needed only the top level hadoop-hdfs-2.7.0.jar and added this as a dependency to the POM and all was good :)[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## Working through trouble shooting the Map Reduce project settings[\n]"
http-outgoing-3 >> "After getting the HDFS API working in the IDE it was time to move on to getting the famous Word Count map-reduce tutorial running.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "So coded it, set the main program to the word count main as the one to run. From the IDE: project Properties => Run => Main Class. Provide input and output arguments for the word count program. I noted that the netbeans properties pop-up window does not persist these settings next time it pops up. However this setting is persistant and ends up in nbactions.xml.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "However, running the word count map reduce program resulted in an ioException:[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "<pre><code>[\n]"
http-outgoing-3 >> "Please check your configuration for mapreduce.framework.name and the correspond server addresses.[\n]"
http-outgoing-3 >> "</pre></code>[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "Because the resources directory only contains 2 configuration files from my hadoop installation I thought maybe I was missing a map reduce one. So the first thing I did was go into the configuration directory of my installation and grep all files to see if there was a configuration file with mapreduce framework property. There was not. I checked my programatic configuration dump from my test program. This property was not mentioned either. The only map reduce configuration was to do with some environment variables for heap size in one of the shell scripts. Note to self: this may be relevant and I can consider setting this in the IDE. However, that didn't look like the problem.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "I then chec[\r][\n]"
http-outgoing-3 >> "a93[\r][\n]"
http-outgoing-3 >> "ked my dependencies and noted there were no map reduce jars pulled in by Maven. So I added hadoop-mapreduce-client-core. Still not running. Checked the web and a thread on stackoverflow mentioned a number of other jars: hadoop-mapreduce-client-common and hadoop-mapreduce-client shuffle. I added just the hadoop-mapreduce-client-common and it runs :) I have a feeling that I might need some of the other jars for other API calls and that there must be a better way of working out dependencies than this trial and error. As mentioned I am a newbie with this, so if anyone has any comments feel free to email me.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## Logging from application code[\n]"
http-outgoing-3 >> "Although the hadoop libraries log correctly with a properly located log4.properties file, application code calling the log4j logger seems to ignore this file. Using the log4j logger as per instructions in the log4j manual and many online tutorials did not result in getting any logging redirected to file configured in the properties file. Instead console output only is obtained. A clue to this mystery was that a most basic of hello world netbeans maven projects which did not import any hadoop stuff also failed to log to a file and did not even give the "No appenders" warning. Then I noticed that there were org.sl4j depencies in the hadoop build, so using sl4j instead solved the problem. Once my hello world project used sl4j's LoggerFactory and had sl4j-api and sl4j-12 as a dependencies it started to use the properties file. See http://www.slf4j.org/manual.html[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## Upload a file from local storage to the HDFS via the REST API[\n]"
http-outgoing-3 >> "The WebHDFS REST API documentation which came with the installation specifies that file creation is a two stage operation where an initial PUT to the namenode is sent. This responds with a redirect to the datanode and another PUT should be made to this redirection which can contain the chunked data stream. This does not sound REST to me as it relies on holding redirection state (a fully distributed configuration could presumably return a redirection to any one of the datanodes). Hadoop say this is because of a bug in some HTTP client implementations - incorrect implementation of [0xe2][0x80][0x9c]Expect: 100-continue[0xe2][0x80][0x9d].[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "However, the 2 stage PUT not being REST seems to be a moot point, at least with the Jersey client. I do not get a redirection and a file creates/uploads all in one go.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "Since writing the above paragraph I have implemented the Apache Client back end option to my HDFS Web client interface and this client behaves differently. It does indeed cause a redirect as per Hadoop documentation. The follow up PUT to the redirected location with the chunked file stream works as per documentation.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "To be continued ...[\n]"
http-outgoing-3 >> "[\r][\n]"
http-outgoing-3 >> "0[\r][\n]"
http-outgoing-3 >> "[\r][\n]"
http-outgoing-3 << "HTTP/1.1 307 TEMPORARY_REDIRECT[\r][\n]"
http-outgoing-3 << "Cache-Control: no-cache[\r][\n]"
http-outgoing-3 << "Expires: Sat, 13 Jun 2015 01:30:10 GMT[\r][\n]"
http-outgoing-3 << "Date: Sat, 13 Jun 2015 01:30:10 GMT[\r][\n]"
http-outgoing-3 << "Pragma: no-cache[\r][\n]"
http-outgoing-3 << "Expires: Sat, 13 Jun 2015 01:30:10 GMT[\r][\n]"
http-outgoing-3 << "Date: Sat, 13 Jun 2015 01:30:10 GMT[\r][\n]"
http-outgoing-3 << "Pragma: no-cache[\r][\n]"
http-outgoing-3 << "Content-Type: application/octet-stream[\r][\n]"
http-outgoing-3 << "Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434195010693&s=U5uGYvazW8XOiLbrSJGw96QIprc="; Path=/; Expires=Sat, 13-Jun-2015 11:30:10 GMT; HttpOnly[\r][\n]"
http-outgoing-3 << "Location: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/README.md?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true[\r][\n]"
http-outgoing-3 << "Content-Length: 0[\r][\n]"
http-outgoing-3 << "Server: Jetty(6.1.26)[\r][\n]"
http-outgoing-3 << "[\r][\n]"
http-outgoing-3 << HTTP/1.1 307 TEMPORARY_REDIRECT
http-outgoing-3 << Cache-Control: no-cache
http-outgoing-3 << Expires: Sat, 13 Jun 2015 01:30:10 GMT
http-outgoing-3 << Date: Sat, 13 Jun 2015 01:30:10 GMT
http-outgoing-3 << Pragma: no-cache
http-outgoing-3 << Expires: Sat, 13 Jun 2015 01:30:10 GMT
http-outgoing-3 << Date: Sat, 13 Jun 2015 01:30:10 GMT
http-outgoing-3 << Pragma: no-cache
http-outgoing-3 << Content-Type: application/octet-stream
http-outgoing-3 << Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434195010693&s=U5uGYvazW8XOiLbrSJGw96QIprc="; Path=/; Expires=Sat, 13-Jun-2015 11:30:10 GMT; HttpOnly
http-outgoing-3 << Location: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/README.md?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
http-outgoing-3 << Content-Length: 0
http-outgoing-3 << Server: Jetty(6.1.26)
Connection can be kept alive indefinitely
Cookie accepted [hadoop.auth=""u=michaeljones&p=michaeljones&t=simple&e=1434195010693&s=U5uGYvazW8XOiLbrSJGw96QIprc="", version:0, domain:localhost, path:/, expiry:Sat Jun 13 21:30:10 AEST 2015]
Redirect to: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/README.md?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
http-outgoing-3: Shutdown connection
Connection discarded
http-outgoing-3: Close connection
Connection released: [id: 3][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 4][route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://michaels-air.bigpond:50075
Connecting to michaels-air.bigpond/10.0.0.2:50075
Connection established 10.0.0.2:50356<->10.0.0.2:50075
Executing request PUT /webhdfs/v1/user/michaeljones/README.md?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-4 >> PUT /webhdfs/v1/user/michaeljones/README.md?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1
http-outgoing-4 >> Transfer-Encoding: chunked
http-outgoing-4 >> Content-Type: application/octet-stream
http-outgoing-4 >> Host: michaels-air.bigpond:50075
http-outgoing-4 >> Connection: Keep-Alive
http-outgoing-4 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-4 >> Accept-Encoding: gzip,deflate
http-outgoing-4 >> "PUT /webhdfs/v1/user/michaeljones/README.md?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1[\r][\n]"
http-outgoing-4 >> "Transfer-Encoding: chunked[\r][\n]"
http-outgoing-4 >> "Content-Type: application/octet-stream[\r][\n]"
http-outgoing-4 >> "Host: michaels-air.bigpond:50075[\r][\n]"
http-outgoing-4 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-4 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-4 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-4 >> "[\r][\n]"
http-outgoing-4 >> "1000[\r][\n]"
http-outgoing-4 >> "# Hello-Hadoop-netbeans-OS-X[\n]"
http-outgoing-4 >> "Java Maven project for playing with the HDFS API without any 3rd party hadoop plugins.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## Aim of project[\n]"
http-outgoing-4 >> "Hello world/tutorial level for programmatically operating with a pseudo distributed hadoop configuration on OS X. Hadoop 2.7 on Yosemite.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## What this project demonstrates[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "This is work in progress and so far the following functionality is demonstrated:[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "1. Direct programmatic control of the HDFS and running map reduce jobs - all unit tests run from the IDE with hadoop configuration built into this project and under git control.[\n]"
http-outgoing-4 >> "2. Uploading of files to the HDFS by implementing a Web REST API client.[\n]"
http-outgoing-4 >> "3. Layered application code for maximum re-use and ease of test driven development. The client I wrote uses an interface which has allowed me to provide both a Jersey HTTP client implementation and an Apache HTTP client implementation for comparison between the two toolkits.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "The initial difficulty was working out how to run the program in the IDE and talk to the local pseudo distributed setup without using a 3rd party Hadoop plugin. Apparently there used to be a plugin for netbeans, but it has been discontinued. I am a newbie with this technology.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "The Apache Hadoop instructions for building and running java programs are via their command line build/run utility only. Getting the yahoo hadoop HDFS tutorial program to build in the IDE wasn't too hard. However, by default it will ignore the local Hadoop configuration and only operate with the local file system in local debug mode.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## Wading through the configuration[\n]"
http-outgoing-4 >> "Hadoop is designed to work with a number of different topologies, directory locations, levels of replication, simulated environments etc. so as we would expect nothing works unless the configuration is right.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "First Hadoop needs to be installed and configured in pseudo distributed mode such that it builds and runs test programs on the command line. The hadoop documentation has instructions for doing this. Documentation is online and also included in the installation: share/doc/hadoop/index.html. However this is not enough to get it to work in the IDE.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## The netbeans project settings that are needed to run with the HDFS from the IDE:[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "1. Get log4j configured to work in the IDE. Absence of log4j configuration won't stop hadoop from running, but we won't get to see useful error messages from hadoop without it.[\n]"
http-outgoing-4 >> "2. HADOOP_HOME environment variable project run (and test) property.[\n]"
http-outgoing-4 >> "3. Duplicate hadoop configuration in the classpath. The above environment variable does not pick up the hadoop configuration from its usual place. Yahoo's only suggestion is to run from the command line via the hadoop script. The Apache HDFS API documention says that configuration is looked for in the classpath, so I took the approach of duplicating the configuration (just 2 files) instead of figuring out how to get it to look in the installation path.[\n]"
http-outgoing-4 >> "4. The correct Maven dependencies. If not all the jar depenencies are there the program may build and run, but it won't talk to the HDFS if it doesn't load the HDFS jars.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "I think that the setup of this project would probably work on Linux too.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## Working through trouble shooting the HDFS project settings[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "Issue 1 above shows up as:[\n]"
http-outgoing-4 >> "<pre><code>[\n]"
http-outgoing-4 >> "log4j:WARN No appenders could be found for logger (org.apache.hadoop.util.Shell).[\n]"
http-outgoing-4 >> "log4j:WARN Please initialize the log4j system properly.[\n]"
http-outgoing-4 >> "log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.[\n]"
http-outgoing-4 >> "</pre></code>[\n]"
http-outgoing-4 >> "This is solved by putting a log4j.properties configuration file in the classpath. For a Maven build getting files into the classpath can be achieved by putting them in src/main/resources. I don't think this is in the classpath, but the build will then copy the file into ./target/classes/ which is in the classpath.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "Issue 2 above shows up as:[\n]"
http-outgoing-4 >> "<pre><code>[\n]"
http-outgoing-4 >> "Failed to detect a valid hadoop home directory[\n]"
http-outgoing-4 >> "java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.[\n]"
http-outgoing-4 >> "</code></pre>[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "This is fixed by going into the project properties => Build => Actions => Run Project and adding the environmen[\r][\n]"
http-outgoing-4 >> "1000[\r][\n]"
http-outgoing-4 >> "t variable for HADOOP_HOME. This will result in an entry in the Maven POM. Repeat for "Test Project", "Debug Project" etc.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "Issue 3. shows up as running, but creating a file on the local file system instead of the HDFS. This was fixed       looking at the HDFS API documentation for org.apache.hadoop.conf.Configuration. This documentation is under the chapter: C API libhdfs HDFS which has a link to the HDFS API under "The APIs" (I strangely cannot find this in the main index). On my installation the HDFS API documentation link is file:///opt/local/hadoop-2.7.0/share/doc/hadoop/api/org/apache/hadoop/fs/FileSystem.html.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "This documentation told me that hadoop loads core-site.xml and core-default.xml in the classpath. Classpath for a Maven build can be reached by placing these files in the directory src/main/resources (see logging configuration above). I added hdfs-site instead of core-default (which doesn't exist on my 2.7 install) into the src/main/resources project directory.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "Issue 3 shows up as:[\n]"
http-outgoing-4 >> "<pre><code>[\n]"
http-outgoing-4 >> "java.io.IOException: "hadoop No FileSystem for scheme: hdfs".[\n]"
http-outgoing-4 >> "</code></pre>[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "This is part of the build dependency problem. The various threads on stackoverflow etc. suggested that a minimum dependency was the jar for hadoop-core. However, there is no such jar on 2.7. I ran the hadoop command to dump version and got this:[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "<pre><code>[\n]"
http-outgoing-4 >> "bin/hadoop version[\n]"
http-outgoing-4 >> "Hadoop 2.7.0[\n]"
http-outgoing-4 >> "Subversion https://git-wip-us.apache.org/repos/asf/hadoop.git -r d4c8d4d4d203c934e8074b31289a28724c0842cf[\n]"
http-outgoing-4 >> "Compiled by jenkins on 2015-04-10T18:40Z[\n]"
http-outgoing-4 >> "Compiled with protoc 2.5.0[\n]"
http-outgoing-4 >> "From source with checksum a9e90912c37a35c3195d23951fd18f[\n]"
http-outgoing-4 >> "This command was run using /opt/local/hadoop-2.7.0/share/hadoop/common/hadoop-common-2.7.0.jar[\n]"
http-outgoing-4 >> "</code></pre>[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "I noted the jar name at the end and added it as a dependency to the POM. This can either be hand coded in or right click pom.xml => Insert Code => Add Dependency => Search => query hadoop-common and select version which was 2.7.0 [jar] - central. Maven will then add dependencies to other hadoop jars in the "Dependencies" group in the project explorer. Netbeans will then download these dependencies before the next build. They go into ~/.m2/repository should they ever need to be cleaned out (Netbeans doesn't seem to have an IDE remove dependency option).[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "After doing the above project built, but showed up the "no filesystem error". I noticed that Maven had not pulled in any hdfs jars matching the jars in my share/hadoop/hdfs installation directory. So I took a guess that it needed only the top level hadoop-hdfs-2.7.0.jar and added this as a dependency to the POM and all was good :)[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## Working through trouble shooting the Map Reduce project settings[\n]"
http-outgoing-4 >> "After getting the HDFS API working in the IDE it was time to move on to getting the famous Word Count map-reduce tutorial running.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "So coded it, set the main program to the word count main as the one to run. From the IDE: project Properties => Run => Main Class. Provide input and output arguments for the word count program. I noted that the netbeans properties pop-up window does not persist these settings next time it pops up. However this setting is persistant and ends up in nbactions.xml.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "However, running the word count map reduce program resulted in an ioException:[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "<pre><code>[\n]"
http-outgoing-4 >> "Please check your configuration for mapreduce.framework.name and the correspond server addresses.[\n]"
http-outgoing-4 >> "</pre></code>[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "Because the resources directory only contains 2 configuration files from my hadoop installation I thought maybe I was missing a map reduce one. So the first thing I did was go into the configuration directory of my installation and grep all files to see if there was a configuration file with mapreduce framework property. There was not. I checked my programatic configuration dump from my test program. This property was not mentioned either. The only map reduce configuration was to do with some environment variables for heap size in one of the shell scripts. Note to self: this may be relevant and I can consider setting this in the IDE. However, that didn't look like the problem.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "I then chec[\r][\n]"
http-outgoing-4 >> "a93[\r][\n]"
http-outgoing-4 >> "ked my dependencies and noted there were no map reduce jars pulled in by Maven. So I added hadoop-mapreduce-client-core. Still not running. Checked the web and a thread on stackoverflow mentioned a number of other jars: hadoop-mapreduce-client-common and hadoop-mapreduce-client shuffle. I added just the hadoop-mapreduce-client-common and it runs :) I have a feeling that I might need some of the other jars for other API calls and that there must be a better way of working out dependencies than this trial and error. As mentioned I am a newbie with this, so if anyone has any comments feel free to email me.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## Logging from application code[\n]"
http-outgoing-4 >> "Although the hadoop libraries log correctly with a properly located log4.properties file, application code calling the log4j logger seems to ignore this file. Using the log4j logger as per instructions in the log4j manual and many online tutorials did not result in getting any logging redirected to file configured in the properties file. Instead console output only is obtained. A clue to this mystery was that a most basic of hello world netbeans maven projects which did not import any hadoop stuff also failed to log to a file and did not even give the "No appenders" warning. Then I noticed that there were org.sl4j depencies in the hadoop build, so using sl4j instead solved the problem. Once my hello world project used sl4j's LoggerFactory and had sl4j-api and sl4j-12 as a dependencies it started to use the properties file. See http://www.slf4j.org/manual.html[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## Upload a file from local storage to the HDFS via the REST API[\n]"
http-outgoing-4 >> "The WebHDFS REST API documentation which came with the installation specifies that file creation is a two stage operation where an initial PUT to the namenode is sent. This responds with a redirect to the datanode and another PUT should be made to this redirection which can contain the chunked data stream. This does not sound REST to me as it relies on holding redirection state (a fully distributed configuration could presumably return a redirection to any one of the datanodes). Hadoop say this is because of a bug in some HTTP client implementations - incorrect implementation of [0xe2][0x80][0x9c]Expect: 100-continue[0xe2][0x80][0x9d].[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "However, the 2 stage PUT not being REST seems to be a moot point, at least with the Jersey client. I do not get a redirection and a file creates/uploads all in one go.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "Since writing the above paragraph I have implemented the Apache Client back end option to my HDFS Web client interface and this client behaves differently. It does indeed cause a redirect as per Hadoop documentation. The follow up PUT to the redirected location with the chunked file stream works as per documentation.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "To be continued ...[\n]"
http-outgoing-4 >> "[\r][\n]"
http-outgoing-4 >> "0[\r][\n]"
http-outgoing-4 >> "[\r][\n]"
http-outgoing-4 << "HTTP/1.1 100 Continue[\r][\n]"
http-outgoing-4 << "[\r][\n]"
http-outgoing-4 << HTTP/1.1 100 Continue
http-outgoing-4 << "HTTP/1.1 201 Created[\r][\n]"
http-outgoing-4 << "Location: hdfs://localhost:9000/user/michaeljones/README.md[\r][\n]"
http-outgoing-4 << "Content-Length: 0[\r][\n]"
http-outgoing-4 << "Connection: close[\r][\n]"
http-outgoing-4 << "[\r][\n]"
http-outgoing-4 << HTTP/1.1 201 Created
http-outgoing-4 << Location: hdfs://localhost:9000/user/michaeljones/README.md
http-outgoing-4 << Content-Length: 0
http-outgoing-4 << Connection: close
http-outgoing-4: Shutdown connection
Connection discarded
http-outgoing-4: Close connection
Connection released: [id: 4][route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection manager is shutting down
Connection manager shut down
Connection manager is shutting down
Connection manager shut down
setsid is not available on this machine. So not using it.
setsid exited with exit code 0
field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName=Ops, always=false, about=, type=DEFAULT, value=[Rate of successful kerberos logins and latency (milliseconds)], valueName=Time)
field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName=Ops, always=false, about=, type=DEFAULT, value=[Rate of failed kerberos logins and latency (milliseconds)], valueName=Time)
field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName=Ops, always=false, about=, type=DEFAULT, value=[GetGroups], valueName=Time)
UgiMetrics, User and group related metrics
Kerberos krb5 configuration not found, setting default realm to empty
 Creating new Groups object
Trying to load the custom-built native-hadoop library...
Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
java.library.path=/Applications/NetBeans/NetBeans 8.0.2.app/Contents/Resources/NetBeans/webcommon/bin::/Users/michaeljones/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:.
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Falling back to shell based
Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
hadoop login
hadoop login commit
using local user:UnixPrincipal: michaeljones
Using user: "UnixPrincipal: michaeljones" with name michaeljones
User entry: "michaeljones"
UGI loginUser:michaeljones (auth:SIMPLE)
dfs.client.use.legacy.blockreader.local = false
dfs.client.read.shortcircuit = false
dfs.client.domain.socket.data.traffic = false
dfs.domain.socket.path = 
multipleLinearRandomRetry = null
rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWrapper, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@8dbfffb
getting client out of cache: org.apache.hadoop.ipc.Client@5674e1f2
Both short-circuit local reads and UNIX domain socket are disabled.
DataTransferProtocol not using SaslPropertiesResolver, no QOP found in configuration for dfs.data.transfer.protection
The ping interval is 60000 ms.
Connecting to localhost/127.0.0.1:9000
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones: starting, having connections 1
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones sending #0
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones got value #0
Call: getFileInfo took 131ms
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones sending #1
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones got value #1
Call: delete took 6ms
/user/michaeljones/hello.txt: masked=rw-r--r--
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones sending #2
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones got value #2
Call: create took 4ms
computePacketChunkSize: src=/user/michaeljones/hello.txt, chunkSize=516, chunksPerPacket=126, packetSize=65016
Lease renewer daemon for [DFSClient_NONMAPREDUCE_-1393294907_1] with renew id 1 started
DFSClient writeChunk allocating new packet seqno=0, src=/user/michaeljones/hello.txt, packetSize=65016, chunksPerPacket=126, bytesCurBlock=0
Queued packet 0
Queued packet 1
Allocating new block
Waiting for ack for: 1
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones sending #3
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones got value #3
Call: addBlock took 5ms
pipeline = DatanodeInfoWithStorage[127.0.0.1:50010,DS-b42c5705-9ba4-4b14-b00b-f9194bb036f0,DISK]
Connecting to datanode 127.0.0.1:50010
Send buf size 131072
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones sending #4
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones got value #4
Call: getServerDefaults took 2ms
SASL client skipping handshake in unsecured configuration for addr = /127.0.0.1, datanodeId = DatanodeInfoWithStorage[127.0.0.1:50010,DS-b42c5705-9ba4-4b14-b00b-f9194bb036f0,DISK]
DataStreamer block BP-1045030256-10.0.0.2-1433119149314:blk_1073742228_1405 sending packet packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 20
DFSClient seqno: 0 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
DataStreamer block BP-1045030256-10.0.0.2-1433119149314:blk_1073742228_1405 sending packet packet seqno: 1 offsetInBlock: 20 lastPacketInBlock: true lastByteOffsetInBlock: 20
DFSClient seqno: 1 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
Closing old block BP-1045030256-10.0.0.2-1433119149314:blk_1073742228_1405
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones sending #5
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones got value #5
Call: complete took 3ms
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones sending #6
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones got value #6
Call: getBlockLocations took 3ms
newInfo = LocatedBlocks{
  fileLength=20
  underConstruction=false
  blocks=[LocatedBlock{BP-1045030256-10.0.0.2-1433119149314:blk_1073742228_1405; getBlockSize()=20; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-b42c5705-9ba4-4b14-b00b-f9194bb036f0,DISK]]}]
  lastLocatedBlock=LocatedBlock{BP-1045030256-10.0.0.2-1433119149314:blk_1073742228_1405; getBlockSize()=20; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-b42c5705-9ba4-4b14-b00b-f9194bb036f0,DISK]]}
  isLastBlockComplete=true}
Connecting to datanode 127.0.0.1:50010
SASL client skipping handshake in unsecured configuration for addr = /127.0.0.1, datanodeId = DatanodeInfoWithStorage[127.0.0.1:50010,DS-b42c5705-9ba4-4b14-b00b-f9194bb036f0,DISK]
RunJobAsync
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones sending #7
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones got value #7
Call: getFileInfo took 3ms
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones sending #8
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones got value #8
Call: delete took 9ms
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.connect(Job.java:1256)
Trying ClientProtocolProvider : org.apache.hadoop.mapred.LocalClientProtocolProvider
session.id is deprecated. Instead, use dfs.metrics.session-id
Initializing JVM Metrics with processName=JobTracker, sessionId=
Picked org.apache.hadoop.mapred.LocalClientProtocolProvider as the ClientProtocolProvider
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Cluster.getFileSystem(Cluster.java:162)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.submit(Job.java:1287)
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones sending #9
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones got value #9
Call: getFileInfo took 2ms
Configuring job job_local1772068781_0001 with file:/tmp/hadoop-michaeljones/mapred/staging/michaeljones1772068781/.staging/job_local1772068781_0001 as the submit dir
adding the following namenodes' delegation tokens:[hdfs://localhost:9000]
Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
default FileSystem: file:///
No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
Creating splits at file:/tmp/hadoop-michaeljones/mapred/staging/michaeljones1772068781/.staging/job_local1772068781_0001
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones sending #10
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones got value #10
Call: getFileInfo took 1ms
Time taken to get FileStatuses: 8
Total input paths to process : 1
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones sending #11
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones got value #11
Call: getBlockLocations took 3ms
Total # of splits generated by getSplits: 1, TimeTaken: 33
number of splits:1
Handling deprecation for all properties in config...
Handling deprecation for mapreduce.jobtracker.address
Handling deprecation for yarn.resourcemanager.scheduler.monitor.policies
Handling deprecation for dfs.namenode.resource.check.interval
Handling deprecation for mapreduce.jobhistory.client.thread-count
Handling deprecation for yarn.app.mapreduce.am.containerlauncher.threadpool-initial-size
Handling deprecation for mapred.child.java.opts
Handling deprecation for mapreduce.jobtracker.retiredjobs.cache.size
Handling deprecation for dfs.client.https.need-auth
Handling deprecation for yarn.admin.acl
Handling deprecation for yarn.app.mapreduce.am.job.committer.cancel-timeout
Handling deprecation for mapreduce.job.emit-timeline-data
Handling deprecation for fs.ftp.host.port
Handling deprecation for dfs.namenode.avoid.read.stale.datanode
Handling deprecation for dfs.journalnode.rpc-address
Handling deprecation for mapreduce.job.end-notification.retry.attempts
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.ttl-interval-ms
Handling deprecation for yarn.resourcemanager.leveldb-state-store.path
Handling deprecation for mapred.mapper.new-api
Handling deprecation for yarn.ipc.rpc.class
Handling deprecation for ipc.client.connection.maxidletime
Handling deprecation for yarn.nodemanager.process-kill-wait.ms
Handling deprecation for mapreduce.cluster.acls.enabled
Handling deprecation for mapreduce.jobtracker.handler.count
Handling deprecation for io.map.index.interval
Handling deprecation for dfs.namenode.https-address
Handling deprecation for mapreduce.task.profile.reduces
Handling deprecation for fs.s3n.multipart.uploads.enabled
Handling deprecation for io.seqfile.sorter.recordlimit
Handling deprecation for mapreduce.job.ubertask.maxmaps
Handling deprecation for mapreduce.tasktracker.tasks.sleeptimebeforesigkill
Handling deprecation for hadoop.util.hash.type
Handling deprecation for dfs.namenode.replication.min
Handling deprecation for yarn.nodemanager.container-manager.thread-count
Handling deprecation for mapreduce.jobtracker.jobhistory.block.size
Handling deprecation for dfs.namenode.fs-limits.min-block-size
Handling deprecation for mapreduce.app-submission.cross-platform
Handling deprecation for fs.AbstractFileSystem.file.impl
Handling deprecation for net.topology.script.number.args
Handling deprecation for yarn.resourcemanager.container-tokens.master-key-rolling-interval-secs
Handling deprecation for mapreduce.map.output.compress.codec
Handling deprecation for mapreduce.job.reducer.preempt.delay.sec
Handling deprecation for s3native.bytes-per-checksum
Handling deprecation for dfs.namenode.path.based.cache.block.map.allocation.percent
Handling deprecation for yarn.nodemanager.windows-container.memory-limit.enabled
Handling deprecation for mapreduce.input.fileinputformat.split.minsize
Handling deprecation for hadoop.security.group.mapping
Handling deprecation for mapreduce.jobtracker.system.dir
Handling deprecation for mapreduce.job.end-notification.max.attempts
Handling deprecation for mapreduce.reduce.markreset.buffer.percent
Handling deprecation for dfs.datanode.cache.revocation.polling.ms
Handling deprecation for mapreduce.reduce.speculative
Handling deprecation for yarn.nodemanager.localizer.cache.cleanup.interval-ms
Handling deprecation for dfs.namenode.lazypersist.file.scrub.interval.sec
Handling deprecation for fs.s3a.threads.core
Handling deprecation for mapreduce.jobhistory.recovery.store.fs.uri
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.start-time-read-cache-size
Handling deprecation for hadoop.registry.zk.retry.interval.ms
Handling deprecation for yarn.nodemanager.keytab
Handling deprecation for dfs.namenode.replication.interval
Handling deprecation for yarn.resourcemanager.admin.address
Handling deprecation for mapreduce.job.maps
Handling deprecation for nfs.dump.dir
Handling deprecation for mapreduce.job.user.name
Handling deprecation for mapreduce.jobtracker.maxtasks.perjob
Handling deprecation for mapreduce.job.ubertask.enable
Handling deprecation for mapreduce.job.reduce.class
Handling deprecation for yarn.nodemanager.delete.debug-delay-sec
Handling deprecation for yarn.timeline-service.ttl-enable
Handling deprecation for yarn.resourcemanager.fs.state-store.retry-policy-spec
Handling deprecation for mapreduce.reduce.skip.maxgroups
Handling deprecation for dfs.client.use.datanode.hostname
Handling deprecation for fs.trash.interval
Handling deprecation for mapreduce.job.name
Handling deprecation for mapreduce.am.max-attempts
Handling deprecation for mapreduce.jobtracker.heartbeats.in.second
Handling deprecation for yarn.resourcemanager.zk-num-retries
Handling deprecation for s3.blocksize
Handling deprecation for dfs.datanode.data.dir
Handling deprecation for mapreduce.jobtracker.persist.jobstatus.active
Handling deprecation for mapreduce.reduce.shuffle.parallelcopies
Handling deprecation for fs.s3.buffer.dir
Handling deprecation for mapreduce.jobhistory.done-dir
Handling deprecation for hadoop.security.instrumentation.requires.admin
Handling deprecation for hadoop.registry.zk.retry.ceiling.ms
Handling deprecation for nfs.rtmax
Handling deprecation for dfs.datanode.data.dir.perm
Handling deprecation for yarn.resourcemanager.container.liveness-monitor.interval-ms
Handling deprecation for yarn.nodemanager.env-whitelist
Handling deprecation for dfs.namenode.backup.address
Handling deprecation for dfs.namenode.xattrs.enabled
Handling deprecation for dfs.datanode.readahead.bytes
Handling deprecation for mapreduce.jobhistory.cleaner.enable
Handling deprecation for dfs.client.block.write.retries
Handling deprecation for mapreduce.tasktracker.http.address
Handling deprecation for yarn.nodemanager.linux-container-executor.cgroups.hierarchy
Handling deprecation for ha.failover-controller.graceful-fence.connection.retries
Handling deprecation for yarn.resourcemanager.recovery.enabled
Handling deprecation for yarn.app.mapreduce.am.container.log.backups
Handling deprecation for dfs.namenode.safemode.threshold-pct
Handling deprecation for yarn.nodemanager.disk-health-checker.interval-ms
Handling deprecation for hadoop.security.java.secure.random.algorithm
Handling deprecation for dfs.namenode.list.cache.directives.num.responses
Handling deprecation for dfs.datanode.dns.nameserver
Handling deprecation for mapreduce.cluster.temp.dir
Handling deprecation for fs.s3a.max.total.tasks
Handling deprecation for mapreduce.reduce.maxattempts
Handling deprecation for mapreduce.client.submit.file.replication
Handling deprecation for mapreduce.shuffle.port
Handling deprecation for yarn.resourcemanager.resource-tracker.client.thread-count
Handling deprecation for dfs.namenode.replication.considerLoad
Handling deprecation for dfs.namenode.edits.journal-plugin.qjournal
Handling deprecation for dfs.client.write.exclude.nodes.cache.expiry.interval.millis
Handling deprecation for yarn.nodemanager.delete.thread-count
Handling deprecation for dfs.client.mmap.cache.timeout.ms
Handling deprecation for yarn.nodemanager.admin-env
Handling deprecation for io.skip.checksum.errors
Handling deprecation for yarn.timeline-service.hostname
Handling deprecation for yarn.resourcemanager.proxy-user-privileges.enabled
Handling deprecation for mapreduce.job.speculative.speculative-cap-total-tasks
Handling deprecation for yarn.acl.enable
Handling deprecation for fs.s3a.fast.upload
Handling deprecation for file.blocksize
Handling deprecation for mapreduce.job.speculative.slowtaskthreshold
Handling deprecation for ftp.replication
Handling deprecation for yarn.sharedcache.cleaner.initial-delay-mins
Handling deprecation for s3native.client-write-packet-size
Handling deprecation for hadoop.rpc.socket.factory.class.default
Handling deprecation for file.bytes-per-checksum
Handling deprecation for dfs.datanode.slow.io.warning.threshold.ms
Handling deprecation for io.seqfile.lazydecompress
Handling deprecation for mapreduce.task.skip.start.attempts
Handling deprecation for dfs.namenode.reject-unresolved-dn-topology-mapping
Handling deprecation for hadoop.common.configuration.version
Handling deprecation for yarn.resourcemanager.client.thread-count
Handling deprecation for dfs.datanode.drop.cache.behind.reads
Handling deprecation for yarn.sharedcache.admin.address
Handling deprecation for mapreduce.job.output.value.class
Handling deprecation for mapreduce.output.fileoutputformat.outputdir
Handling deprecation for mapreduce.jobtracker.taskcache.levels
Handling deprecation for yarn.nodemanager.linux-container-executor.nonsecure-mode.user-pattern
Handling deprecation for yarn.resourcemanager.zk-timeout-ms
Handling deprecation for yarn.resourcemanager.max-completed-applications
Handling deprecation for mapreduce.job.jvm.numtasks
Handling deprecation for yarn.sharedcache.cleaner.period-mins
Handling deprecation for mapreduce.jobtracker.tasktracker.maxblacklists
Handling deprecation for dfs.namenode.top.num.users
Handling deprecation for yarn.nodemanager.linux-container-executor.cgroups.mount
Handling deprecation for yarn.sharedcache.checksum.algo.impl
Handling deprecation for mapreduce.job.end-notification.max.retry.interval
Handling deprecation for mapreduce.job.acl-view-job
Handling deprecation for mapreduce.job.classloader
Handling deprecation for yarn.log-aggregation-enable
Handling deprecation for mapreduce.reduce.shuffle.fetch.retry.interval-ms
Handling deprecation for yarn.resourcemanager.nodemanager.minimum.version
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.size
Handling deprecation for yarn.app.mapreduce.am.job.task.listener.thread-count
Handling deprecation for yarn.app.mapreduce.am.resource.cpu-vcores
Handling deprecation for dfs.namenode.edit.log.autoroll.check.interval.ms
Handling deprecation for mapreduce.output.fileoutputformat.compress.type
Handling deprecation for hadoop.hdfs.configuration.version
Handling deprecation for hadoop.security.group.mapping.ldap.search.attr.member
Handling deprecation for yarn.nodemanager.log.retain-seconds
Handling deprecation for yarn.nodemanager.local-cache.max-files-per-directory
Handling deprecation for mapreduce.job.end-notification.retry.interval
Handling deprecation for hadoop.ssl.client.conf
Handling deprecation for yarn.sharedcache.root-dir
Handling deprecation for dfs.journalnode.https-address
Handling deprecation for mapreduce.reduce.shuffle.fetch.retry.timeout-ms
Handling deprecation for dfs.bytes-per-checksum
Handling deprecation for dfs.namenode.max.objects
Handling deprecation for mapreduce.tasktracker.instrumentation
Handling deprecation for dfs.datanode.max.transfer.threads
Handling deprecation for dfs.block.access.key.update.interval
Handling deprecation for mapreduce.jobtracker.jobhistory.task.numberprogresssplits
Handling deprecation for mapreduce.map.memory.mb
Handling deprecation for ha.failover-controller.new-active.rpc-timeout.ms
Handling deprecation for hadoop.ssl.hostname.verifier
Handling deprecation for dfs.client.read.shortcircuit
Handling deprecation for dfs.datanode.hdfs-blocks-metadata.enabled
Handling deprecation for mapreduce.tasktracker.healthchecker.interval
Handling deprecation for dfs.image.transfer.chunksize
Handling deprecation for mapreduce.tasktracker.taskmemorymanager.monitoringinterval
Handling deprecation for dfs.client.https.keystore.resource
Handling deprecation for yarn.resourcemanager.connect.retry-interval.ms
Handling deprecation for yarn.timeline-service.webapp.address
Handling deprecation for s3native.blocksize
Handling deprecation for yarn.scheduler.minimum-allocation-mb
Handling deprecation for yarn.sharedcache.cleaner.resource-sleep-ms
Handling deprecation for net.topology.impl
Handling deprecation for dfs.client.failover.sleep.base.millis
Handling deprecation for dfs.permissions.superusergroup
Handling deprecation for io.seqfile.compress.blocksize
Handling deprecation for hadoop.registry.zk.retry.times
Handling deprecation for fs.AbstractFileSystem.ftp.impl
Handling deprecation for dfs.namenode.checkpoint.edits.dir
Handling deprecation for mapreduce.job.running.reduce.limit
Handling deprecation for dfs.blockreport.initialDelay
Handling deprecation for dfs.namenode.heartbeat.recheck-interval
Handling deprecation for dfs.namenode.safemode.extension
Handling deprecation for yarn.scheduler.maximum-allocation-mb
Handling deprecation for mapreduce.job.reduce.shuffle.consumer.plugin.class
Handling deprecation for yarn.nodemanager.vmem-check-enabled
Handling deprecation for mapreduce.task.io.sort.factor
Handling deprecation for mapreduce.jobtracker.persist.jobstatus.dir
Handling deprecation for dfs.client.failover.sleep.max.millis
Handling deprecation for dfs.namenode.delegation.key.update-interval
Handling deprecation for hadoop.rpc.protection
Handling deprecation for fs.permissions.umask-mode
Handling deprecation for fs.s3.sleepTimeSeconds
Handling deprecation for ha.health-monitor.rpc-timeout.ms
Handling deprecation for hadoop.http.staticuser.user
Handling deprecation for fs.s3a.connection.maximum
Handling deprecation for yarn.nodemanager.linux-container-executor.nonsecure-mode.limit-users
Handling deprecation for fs.s3a.paging.maximum
Handling deprecation for fs.AbstractFileSystem.viewfs.impl
Handling deprecation for fs.ftp.host
Handling deprecation for yarn.nodemanager.linux-container-executor.nonsecure-mode.local-user
Handling deprecation for fs.s3a.impl
Handling deprecation for hadoop.http.authentication.kerberos.keytab
Handling deprecation for dfs.namenode.fs-limits.max-blocks-per-file
Handling deprecation for mapreduce.tasktracker.http.threads
Handling deprecation for mapreduce.tasktracker.dns.nameserver
Handling deprecation for yarn.resourcemanager.am-rm-tokens.master-key-rolling-interval-secs
Handling deprecation for dfs.client.block.write.replace-datanode-on-failure.enable
Handling deprecation for io.compression.codec.bzip2.library
Handling deprecation for mapreduce.map.skip.maxrecords
Handling deprecation for dfs.client.use.legacy.blockreader.local
Handling deprecation for dfs.namenode.checkpoint.dir
Handling deprecation for dfs.namenode.top.windows.minutes
Handling deprecation for mapreduce.job.maxtaskfailures.per.tracker
Handling deprecation for net.topology.node.switch.mapping.impl
Handling deprecation for mapreduce.shuffle.max.connections
Handling deprecation for mapreduce.jobhistory.loadedjobs.cache.size
Handling deprecation for dfs.storage.policy.enabled
Handling deprecation for yarn.client.application-client-protocol.poll-interval-ms
Handling deprecation for yarn.nodemanager.localizer.address
Handling deprecation for dfs.namenode.list.cache.pools.num.responses
Handling deprecation for nfs.server.port
Handling deprecation for mapreduce.client.output.filter
Handling deprecation for yarn.timeline-service.client.best-effort
Handling deprecation for ha.zookeeper.parent-znode
Handling deprecation for mapreduce.jobtracker.persist.jobstatus.hours
Handling deprecation for yarn.sharedcache.admin.thread-count
Handling deprecation for yarn.nodemanager.resource.cpu-vcores
Handling deprecation for dfs.datanode.block-pinning.enabled
Handling deprecation for mapreduce.jobhistory.http.policy
Handling deprecation for yarn.resourcemanager.webapp.delegation-token-auth-filter.enabled
Handling deprecation for mapreduce.job.speculative.retry-after-no-speculate
Handling deprecation for fs.s3a.attempts.maximum
Handling deprecation for s3native.stream-buffer-size
Handling deprecation for io.seqfile.local.dir
Handling deprecation for yarn.log-aggregation.retain-check-interval-seconds
Handling deprecation for fs.s3n.multipart.copy.block.size
Handling deprecation for dfs.encrypt.data.transfer.cipher.key.bitlength
Handling deprecation for dfs.datanode.sync.behind.writes
Handling deprecation for yarn.resourcemanager.zk-acl
Handling deprecation for hadoop.ssl.keystores.factory.class
Handling deprecation for mapreduce.job.split.metainfo.maxsize
Handling deprecation for fs.s3.maxRetries
Handling deprecation for hadoop.security.random.device.file.path
Handling deprecation for yarn.client.nodemanager-connect.max-wait-ms
Handling deprecation for dfs.namenode.stale.datanode.interval
Handling deprecation for mapreduce.task.io.sort.mb
Handling deprecation for yarn.resourcemanager.zk-state-store.parent-path
Handling deprecation for yarn.app.mapreduce.client-am.ipc.max-retries
Handling deprecation for fs.client.resolve.remote.symlinks
Handling deprecation for yarn.nodemanager.linux-container-executor.cgroups.strict-resource-usage
Handling deprecation for hadoop.ssl.enabled.protocols
Handling deprecation for mapreduce.reduce.cpu.vcores
Handling deprecation for yarn.client.failover-retries
Handling deprecation for mapreduce.jobhistory.address
Handling deprecation for hadoop.ssl.enabled
Handling deprecation for dfs.replication.max
Handling deprecation for dfs.namenode.name.dir
Handling deprecation for dfs.datanode.https.address
Handling deprecation for ipc.client.kill.max
Handling deprecation for mapreduce.job.committer.setup.cleanup.needed
Handling deprecation for dfs.client.domain.socket.data.traffic
Handling deprecation for yarn.nodemanager.localizer.cache.target-size-mb
Handling deprecation for yarn.resourcemanager.admin.client.thread-count
Handling deprecation for dfs.block.access.token.enable
Handling deprecation for mapreduce.job.speculative.retry-after-speculate
Handling deprecation for dfs.datanode.address
Handling deprecation for mapreduce.jobtracker.restart.recover
Handling deprecation for ipc.client.connect.max.retries
Handling deprecation for yarn.timeline-service.store-class
Handling deprecation for dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
Handling deprecation for hadoop.tmp.dir
Handling deprecation for dfs.datanode.handler.count
Handling deprecation for yarn.resourcemanager.ha.automatic-failover.embedded
Handling deprecation for yarn.timeline-service.ttl-ms
Handling deprecation for mapreduce.task.profile.map.params
Handling deprecation for yarn.resourcemanager.nodemanagers.heartbeat-interval-ms
Handling deprecation for mapreduce.map.speculative
Handling deprecation for yarn.timeline-service.recovery.enabled
Handling deprecation for mapreduce.job.map.class
Handling deprecation for dfs.namenode.resource.checked.volumes.minimum
Handling deprecation for yarn.nodemanager.recovery.dir
Handling deprecation for mapreduce.job.counters.max
Handling deprecation for yarn.resourcemanager.keytab
Handling deprecation for dfs.namenode.max.extra.edits.segments.retained
Handling deprecation for dfs.webhdfs.user.provider.user.pattern
Handling deprecation for dfs.client.mmap.enabled
Handling deprecation for mapreduce.map.log.level
Handling deprecation for dfs.client.file-block-storage-locations.timeout.millis
Handling deprecation for yarn.client.max-cached-nodemanagers-proxies
Handling deprecation for yarn.app.mapreduce.am.scheduler.heartbeat.interval-ms
Handling deprecation for hadoop.fuse.timer.period
Handling deprecation for fs.trash.checkpoint.interval
Handling deprecation for yarn.sharedcache.app-checker.class
Handling deprecation for dfs.journalnode.http-address
Handling deprecation for yarn.app.mapreduce.am.staging-dir
Handling deprecation for mapreduce.tasktracker.local.dir.minspacestart
Handling deprecation for yarn.nm.liveness-monitor.expiry-interval-ms
Handling deprecation for ha.health-monitor.check-interval.ms
Handling deprecation for mapreduce.reduce.shuffle.merge.percent
Handling deprecation for dfs.namenode.retrycache.heap.percent
Handling deprecation for yarn.nodemanager.docker-container-executor.exec-name
Handling deprecation for ipc.client.connect.timeout
Handling deprecation for yarn.resourcemanager.fs.state-store.retry-interval-ms
Handling deprecation for mapreduce.output.fileoutputformat.compress
Handling deprecation for yarn.nodemanager.local-dirs
Handling deprecation for yarn.nodemanager.recovery.enabled
Handling deprecation for io.native.lib.available
Handling deprecation for yarn.sharedcache.store.in-memory.staleness-period-mins
Handling deprecation for yarn.resourcemanager.am.max-attempts
Handling deprecation for s3.replication
Handling deprecation for mapreduce.input.fileinputformat.inputdir
Handling deprecation for fs.AbstractFileSystem.har.impl
Handling deprecation for dfs.image.compress
Handling deprecation for mapreduce.job.running.map.limit
Handling deprecation for mapreduce.reduce.input.buffer.percent
Handling deprecation for yarn.nodemanager.webapp.address
Handling deprecation for dfs.datanode.available-space-volume-choosing-policy.balanced-space-preference-fraction
Handling deprecation for dfs.namenode.edit.log.autoroll.multiplier.threshold
Handling deprecation for hadoop.security.group.mapping.ldap.ssl
Handling deprecation for dfs.namenode.checkpoint.check.period
Handling deprecation for fs.defaultFS
Handling deprecation for fs.s3a.multipart.size
Handling deprecation for dfs.client.slow.io.warning.threshold.ms
Handling deprecation for yarn.app.mapreduce.am.job.committer.commit-window
Handling deprecation for hadoop.security.group.mapping.ldap.search.attr.group.name
Handling deprecation for yarn.nodemanager.disk-health-checker.max-disk-utilization-per-disk-percentage
Handling deprecation for yarn.nodemanager.container-monitor.procfs-tree.smaps-based-rss.enabled
Handling deprecation for mapreduce.job.submithostname
Handling deprecation for mapreduce.map.sort.spill.percent
Handling deprecation for hadoop.security.crypto.codec.classes.aes.ctr.nopadding
Handling deprecation for dfs.namenode.http-address
Handling deprecation for hadoop.security.groups.negative-cache.secs
Handling deprecation for hadoop.ssl.server.conf
Handling deprecation for mapreduce.ifile.readahead
Handling deprecation for s3native.replication
Handling deprecation for yarn.client.nodemanager-client-async.thread-pool-max-size
Handling deprecation for mapreduce.jobtracker.staging.root.dir
Handling deprecation for mapreduce.jobhistory.admin.address
Handling deprecation for dfs.namenode.startup.delay.block.deletion.sec
Handling deprecation for yarn.nodemanager.health-checker.interval-ms
Handling deprecation for dfs.namenode.checkpoint.max-retries
Handling deprecation for s3.stream-buffer-size
Handling deprecation for ftp.client-write-packet-size
Handling deprecation for dfs.datanode.fsdatasetcache.max.threads.per.volume
Handling deprecation for mapreduce.output.fileoutputformat.compress.codec
Handling deprecation for yarn.timeline-service.keytab
Handling deprecation for yarn.sharedcache.store.in-memory.initial-delay-mins
Handling deprecation for mapreduce.jobhistory.webapp.address
Handling deprecation for mapreduce.task.userlog.limit.kb
Handling deprecation for mapreduce.reduce.shuffle.fetch.retry.enabled
Handling deprecation for yarn.app.mapreduce.task.container.log.backups
Handling deprecation for dfs.heartbeat.interval
Handling deprecation for ha.zookeeper.session-timeout.ms
Handling deprecation for fs.s3a.connection.ssl.enabled
Handling deprecation for yarn.sharedcache.webapp.address
Handling deprecation for hadoop.http.authentication.signature.secret.file
Handling deprecation for hadoop.fuse.connection.timeout
Handling deprecation for mapreduce.input.fileinputformat.numinputfiles
Handling deprecation for yarn.nodemanager.log-aggregation.compression-type
Handling deprecation for ipc.server.max.connections
Handling deprecation for yarn.resourcemanager.work-preserving-recovery.scheduling-wait-ms
Handling deprecation for yarn.nodemanager.log-dirs
Handling deprecation for yarn.app.mapreduce.am.resource.mb
Handling deprecation for hadoop.security.groups.cache.secs
Handling deprecation for mapreduce.job.speculative.minimum-allowed-tasks
Handling deprecation for yarn.nodemanager.container-monitor.interval-ms
Handling deprecation for dfs.datanode.cache.revocation.timeout.ms
Handling deprecation for mapreduce.jobhistory.recovery.store.class
Handling deprecation for mapreduce.task.combine.progress.records
Handling deprecation for s3.client-write-packet-size
Handling deprecation for mapreduce.jobtracker.instrumentation
Handling deprecation for dfs.replication
Handling deprecation for mapreduce.shuffle.transfer.buffer.size
Handling deprecation for hadoop.security.group.mapping.ldap.directory.search.timeout
Handling deprecation for dfs.datanode.available-space-volume-choosing-policy.balanced-space-threshold
Handling deprecation for hadoop.work.around.non.threadsafe.getpwuid
Handling deprecation for yarn.app.mapreduce.client-am.ipc.max-retries-on-timeouts
Handling deprecation for yarn.nodemanager.address
Handling deprecation for mapreduce.tasktracker.taskcontroller
Handling deprecation for mapreduce.tasktracker.indexcache.mb
Handling deprecation for yarn.scheduler.maximum-allocation-vcores
Handling deprecation for mapreduce.job.reduces
Handling deprecation for yarn.nodemanager.sleep-delay-before-sigkill.ms
Handling deprecation for yarn.timeline-service.address
Handling deprecation for yarn.resourcemanager.configuration.provider-class
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.expiry
Handling deprecation for yarn.sharedcache.enabled
Handling deprecation for tfile.io.chunk.size
Handling deprecation for mapreduce.job.acl-modify-job
Handling deprecation for hadoop.registry.zk.session.timeout.ms
Handling deprecation for fs.automatic.close
Handling deprecation for ha.health-monitor.sleep-after-disconnect.ms
Handling deprecation for mapreduce.tasktracker.reduce.tasks.maximum
Handling deprecation for mapreduce.input.fileinputformat.list-status.num-threads
Handling deprecation for dfs.datanode.directoryscan.threads
Handling deprecation for dfs.datanode.directoryscan.interval
Handling deprecation for dfs.namenode.acls.enabled
Handling deprecation for dfs.client.short.circuit.replica.stale.threshold.ms
Handling deprecation for hadoop.http.authentication.token.validity
Handling deprecation for fs.s3.block.size
Handling deprecation for ha.failover-controller.graceful-fence.rpc-timeout.ms
Handling deprecation for mapreduce.tasktracker.local.dir.minspacekill
Handling deprecation for dfs.namenode.resource.du.reserved
Handling deprecation for mapreduce.jobhistory.cleaner.interval-ms
Handling deprecation for dfs.namenode.datanode.registration.ip-hostname-check
Handling deprecation for mapreduce.jobhistory.intermediate-done-dir
Handling deprecation for mapreduce.jobtracker.http.address
Handling deprecation for dfs.namenode.backup.http-address
Handling deprecation for dfs.namenode.edits.noeditlogchannelflush
Handling deprecation for mapreduce.reduce.shuffle.input.buffer.percent
Handling deprecation for mapreduce.map.maxattempts
Handling deprecation for yarn.http.policy
Handling deprecation for dfs.namenode.audit.loggers
Handling deprecation for hadoop.security.groups.cache.warn.after.ms
Handling deprecation for io.serializations
Handling deprecation for mapreduce.tasktracker.outofband.heartbeat
Handling deprecation for mapreduce.reduce.shuffle.read.timeout
Handling deprecation for hadoop.security.crypto.buffer.size
Handling deprecation for mapreduce.reduce.skip.proc.count.autoincr
Handling deprecation for mapreduce.ifile.readahead.bytes
Handling deprecation for dfs.http.policy
Handling deprecation for hadoop.registry.secure
Handling deprecation for dfs.namenode.safemode.min.datanodes
Handling deprecation for dfs.client.file-block-storage-locations.num-threads
Handling deprecation for mapreduce.cluster.local.dir
Handling deprecation for mapreduce.tasktracker.report.address
Handling deprecation for dfs.namenode.secondary.https-address
Handling deprecation for hadoop.kerberos.kinit.command
Handling deprecation for yarn.timeline-service.http-authentication.type
Handling deprecation for dfs.block.access.token.lifetime
Handling deprecation for dfs.webhdfs.enabled
Handling deprecation for dfs.namenode.delegation.token.max-lifetime
Handling deprecation for dfs.namenode.avoid.write.stale.datanode
Handling deprecation for dfs.datanode.drop.cache.behind.writes
Handling deprecation for yarn.log-aggregation.retain-seconds
Handling deprecation for mapreduce.job.complete.cancel.delegation.tokens
Handling deprecation for mapreduce.local.clientfactory.class.name
Handling deprecation for mapreduce.shuffle.connection-keep-alive.timeout
Handling deprecation for dfs.namenode.num.extra.edits.retained
Handling deprecation for yarn.scheduler.minimum-allocation-vcores
Handling deprecation for ipc.client.connect.max.retries.on.timeouts
Handling deprecation for yarn.timeline-service.client.retry-interval-ms
Handling deprecation for yarn.timeline-service.client.max-retries
Handling deprecation for fs.s3n.block.size
Handling deprecation for mapreduce.job.map.output.collector.class
Handling deprecation for ha.health-monitor.connect-retry-interval.ms
Handling deprecation for mapreduce.shuffle.max.threads
Handling deprecation for nfs.exports.allowed.hosts
Handling deprecation for dfs.client.mmap.cache.size
Handling deprecation for mapreduce.tasktracker.map.tasks.maximum
Handling deprecation for io.file.buffer.size
Handling deprecation for dfs.client.datanode-restart.timeout
Handling deprecation for io.mapfile.bloom.size
Handling deprecation for hadoop.security.kms.client.authentication.retry-count
Handling deprecation for dfs.namenode.checkpoint.txns
Handling deprecation for ipc.client.connect.retry.interval
Handling deprecation for dfs.client-write-packet-size
Handling deprecation for mapreduce.reduce.shuffle.connect.timeout
Handling deprecation for yarn.resourcemanager.fs.state-store.uri
Handling deprecation for fs.swift.impl
Handling deprecation for hadoop.registry.zk.connection.timeout.ms
Handling deprecation for mapred.queue.default.acl-administer-jobs
Handling deprecation for mapreduce.job.submithostaddress
Handling deprecation for dfs.cachereport.intervalMsec
Handling deprecation for yarn.app.mapreduce.shuffle.log.backups
Handling deprecation for yarn.app.mapreduce.am.container.log.limit.kb
Handling deprecation for yarn.nodemanager.resourcemanager.minimum.version
Handling deprecation for ftp.blocksize
Handling deprecation for yarn.resourcemanager.address
Handling deprecation for file.stream-buffer-size
Handling deprecation for yarn.resourcemanager.scheduler.monitor.enable
Handling deprecation for mapreduce.job.ubertask.maxreduces
Handling deprecation for nfs.allow.insecure.ports
Handling deprecation for yarn.sharedcache.nm.uploader.thread-count
Handling deprecation for ipc.client.idlethreshold
Handling deprecation for ftp.stream-buffer-size
Handling deprecation for yarn.sharedcache.client-server.address
Handling deprecation for dfs.client.failover.connection.retries.on.timeouts
Handling deprecation for dfs.namenode.replication.work.multiplier.per.iteration
Handling deprecation for hadoop.http.authentication.simple.anonymous.allowed
Handling deprecation for hadoop.security.authorization
Handling deprecation for yarn.client.nodemanager-connect.retry-interval-ms
Handling deprecation for yarn.am.liveness-monitor.expiry-interval-ms
Handling deprecation for fs.har.impl.disable.cache
Handling deprecation for yarn.nodemanager.linux-container-executor.resources-handler.class
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.read-cache-size
Handling deprecation for hadoop.security.authentication
Handling deprecation for dfs.image.compression.codec
Handling deprecation for mapreduce.task.files.preserve.failedtasks
Handling deprecation for dfs.client.read.shortcircuit.streams.cache.size
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.path
Handling deprecation for mapreduce.job.reduce.slowstart.completedmaps
Handling deprecation for mapreduce.jobhistory.minicluster.fixed.ports
Handling deprecation for file.replication
Handling deprecation for yarn.resourcemanager.ha.automatic-failover.enabled
Handling deprecation for mapreduce.job.userlog.retain.hours
Handling deprecation for mapreduce.jobhistory.joblist.cache.size
Handling deprecation for dfs.namenode.accesstime.precision
Handling deprecation for yarn.resourcemanager.work-preserving-recovery.enabled
Handling deprecation for dfs.namenode.fs-limits.max-xattrs-per-inode
Handling deprecation for io.mapfile.bloom.error.rate
Handling deprecation for yarn.resourcemanager.store.class
Handling deprecation for dfs.image.transfer.timeout
Handling deprecation for yarn.timeline-service.leveldb-state-store.path
Handling deprecation for nfs.wtmax
Handling deprecation for mapreduce.job.combine.class
Handling deprecation for dfs.namenode.support.allow.format
Handling deprecation for fs.s3a.multipart.purge
Handling deprecation for dfs.secondary.namenode.kerberos.internal.spnego.principal
Handling deprecation for fs.s3a.connection.establish.timeout
Handling deprecation for dfs.stream-buffer-size
Handling deprecation for dfs.namenode.invalidate.work.pct.per.iteration
Handling deprecation for yarn.nodemanager.container-executor.class
Handling deprecation for fs.s3a.multipart.purge.age
Handling deprecation for yarn.resourcemanager.scheduler.client.thread-count
Handling deprecation for dfs.namenode.top.enabled
Handling deprecation for yarn.app.mapreduce.shuffle.log.separate
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.low-watermark
Handling deprecation for fs.s3a.fast.buffer.size
Handling deprecation for hadoop.user.group.static.mapping.overrides
Handling deprecation for tfile.fs.input.buffer.size
Handling deprecation for dfs.client.cached.conn.retry
Handling deprecation for hadoop.http.authentication.type
Handling deprecation for dfs.namenode.list.encryption.zones.num.responses
Handling deprecation for mapreduce.map.cpu.vcores
Handling deprecation for dfs.namenode.path.based.cache.refresh.interval.ms
Handling deprecation for dfs.namenode.decommission.interval
Handling deprecation for dfs.namenode.fs-limits.max-directory-items
Handling deprecation for yarn.resourcemanager.zk-retry-interval-ms
Handling deprecation for ftp.bytes-per-checksum
Handling deprecation for dfs.ha.log-roll.period
Handling deprecation for dfs.user.home.dir.prefix
Handling deprecation for ipc.client.fallback-to-simple-auth-allowed
Handling deprecation for yarn.nodemanager.pmem-check-enabled
Handling deprecation for yarn.nodemanager.remote-app-log-dir
Handling deprecation for dfs.namenode.inotify.max.events.per.rpc
Handling deprecation for mapreduce.task.profile.maps
Handling deprecation for mapreduce.shuffle.ssl.file.buffer.size
Handling deprecation for mapreduce.tasktracker.healthchecker.script.timeout
Handling deprecation for yarn.timeline-service.webapp.https.address
Handling deprecation for yarn.nodemanager.resource.percentage-physical-cpu-limit
Handling deprecation for yarn.app.mapreduce.am.command-opts
Handling deprecation for dfs.namenode.fs-limits.max-xattr-size
Handling deprecation for dfs.datanode.http.address
Handling deprecation for dfs.namenode.blocks.per.postponedblocks.rescan
Handling deprecation for yarn.sharedcache.nm.uploader.replication.factor
Handling deprecation for hadoop.registry.zk.root
Handling deprecation for hadoop.jetty.logs.serve.aliases
Handling deprecation for yarn.client.failover-proxy-provider
Handling deprecation for mapreduce.jobhistory.admin.acl
Handling deprecation for yarn.app.mapreduce.am.hard-kill-timeout-ms
Handling deprecation for yarn.nodemanager.remote-app-log-dir-suffix
Handling deprecation for mapreduce.jobhistory.principal
Handling deprecation for yarn.resourcemanager.webapp.address
Handling deprecation for mapreduce.jobhistory.recovery.enable
Handling deprecation for yarn.sharedcache.store.in-memory.check-period-mins
Handling deprecation for nfs.mountd.port
Handling deprecation for mapreduce.reduce.merge.inmem.threshold
Handling deprecation for fs.df.interval
Handling deprecation for yarn.timeline-service.enabled
Handling deprecation for mapreduce.jobtracker.jobhistory.lru.cache.size
Handling deprecation for mapreduce.task.profile
Handling deprecation for mapreduce.job.output.key.class
Handling deprecation for yarn.nodemanager.hostname
Handling deprecation for dfs.namenode.num.checkpoints.retained
Handling deprecation for mapreduce.job.queuename
Handling deprecation for mapreduce.jobhistory.max-age-ms
Handling deprecation for mapreduce.job.token.tracking.ids.enabled
Handling deprecation for yarn.nodemanager.localizer.client.thread-count
Handling deprecation for yarn.sharedcache.uploader.server.thread-count
Handling deprecation for dfs.client.mmap.retry.timeout.ms
Handling deprecation for mapreduce.jobhistory.move.thread-count
Handling deprecation for dfs.permissions.enabled
Handling deprecation for dfs.blockreport.split.threshold
Handling deprecation for fs.AbstractFileSystem.hdfs.impl
Handling deprecation for dfs.datanode.balance.bandwidthPerSec
Handling deprecation for dfs.block.scanner.volume.bytes.per.second
Handling deprecation for hadoop.http.filter.initializers
Handling deprecation for yarn.timeline-service.http-authentication.simple.anonymous.allowed
Handling deprecation for dfs.default.chunk.view.size
Handling deprecation for yarn.sharedcache.client-server.thread-count
Handling deprecation for yarn.resourcemanager.resource-tracker.address
Handling deprecation for mapreduce.job.working.dir
Handling deprecation for mapreduce.jobhistory.datestring.cache.size
Handling deprecation for mapreduce.task.profile.params
Handling deprecation for dfs.namenode.decommission.blocks.per.interval
Handling deprecation for dfs.namenode.handler.count
Handling deprecation for dfs.image.transfer.bandwidthPerSec
Handling deprecation for rpc.metrics.quantile.enable
Handling deprecation for mapreduce.jobtracker.expire.trackers.interval
Handling deprecation for mapreduce.task.timeout
Handling deprecation for yarn.app.mapreduce.client.max-retries
Handling deprecation for yarn.nodemanager.resource.memory-mb
Handling deprecation for yarn.nodemanager.disk-health-checker.min-healthy-disks
Handling deprecation for dfs.datanode.failed.volumes.tolerated
Handling deprecation for yarn.timeline-service.handler-thread-count
Handling deprecation for ipc.server.listen.queue.size
Handling deprecation for fs.s3a.threads.max
Handling deprecation for yarn.resourcemanager.connect.max-wait.ms
Handling deprecation for mapreduce.fileoutputcommitter.algorithm.version
Handling deprecation for mapreduce.framework.name
Handling deprecation for mapreduce.map.skip.proc.count.autoincr
Handling deprecation for mapreduce.job.max.split.locations
Handling deprecation for yarn.resourcemanager.scheduler.class
Handling deprecation for yarn.resourcemanager.system-metrics-publisher.enabled
Handling deprecation for dfs.blocksize
Handling deprecation for yarn.sharedcache.nested-level
Handling deprecation for mapreduce.shuffle.connection-keep-alive.enable
Handling deprecation for fs.s3a.threads.keepalivetime
Handling deprecation for fs.s3a.connection.timeout
Handling deprecation for file.client-write-packet-size
Handling deprecation for ha.failover-controller.cli-check.rpc-timeout.ms
Handling deprecation for ha.zookeeper.acl
Handling deprecation for dfs.namenode.write.stale.datanode.ratio
Handling deprecation for dfs.encrypt.data.transfer
Handling deprecation for dfs.datanode.shared.file.descriptor.paths
Handling deprecation for mapreduce.input.lineinputformat.linespermap
Handling deprecation for yarn.resourcemanager.delayed.delegation-token.removal-interval-ms
Handling deprecation for yarn.nodemanager.localizer.fetch.thread-count
Handling deprecation for dfs.client.failover.max.attempts
Handling deprecation for yarn.resourcemanager.scheduler.address
Handling deprecation for dfs.client.read.shortcircuit.streams.cache.expiry.ms
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.start-time-write-cache-size
Handling deprecation for yarn.nodemanager.health-checker.script.timeout-ms
Handling deprecation for yarn.resourcemanager.fs.state-store.num-retries
Handling deprecation for hadoop.ssl.require.client.cert
Handling deprecation for hadoop.security.uid.cache.secs
Handling deprecation for mapreduce.jobhistory.keytab
Handling deprecation for dfs.client.read.shortcircuit.skip.checksum
Handling deprecation for yarn.resourcemanager.ha.automatic-failover.zk-base-path
Handling deprecation for mapreduce.shuffle.ssl.enabled
Handling deprecation for mapreduce.reduce.log.level
Handling deprecation for hadoop.registry.rm.enabled
Handling deprecation for mapreduce.tasktracker.dns.interface
Handling deprecation for yarn.resourcemanager.system-metrics-publisher.dispatcher.pool-size
Handling deprecation for mapreduce.job.speculative.speculative-cap-running-tasks
Handling deprecation for dfs.datanode.block.id.layout.upgrade.threads
Handling deprecation for dfs.datanode.use.datanode.hostname
Handling deprecation for dfs.client.context
Handling deprecation for yarn.resourcemanager.ha.enabled
Handling deprecation for mapred.reducer.new-api
Handling deprecation for dfs.namenode.delegation.token.renew-interval
Handling deprecation for dfs.blockreport.intervalMsec
Handling deprecation for fs.s3a.multipart.threshold
Handling deprecation for mapreduce.reduce.shuffle.memory.limit.percent
Handling deprecation for dfs.https.server.keystore.resource
Handling deprecation for io.map.index.skip
Handling deprecation for mapreduce.job.hdfs-servers
Handling deprecation for mapreduce.jobtracker.taskscheduler
Handling deprecation for dfs.namenode.kerberos.internal.spnego.principal
Handling deprecation for yarn.resourcemanager.state-store.max-completed-applications
Handling deprecation for mapreduce.map.output.compress
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.num.refill.threads
Handling deprecation for fs.s3n.multipart.uploads.block.size
Handling deprecation for mapreduce.task.merge.progress.records
Handling deprecation for dfs.datanode.dns.interface
Handling deprecation for map.sort.class
Handling deprecation for yarn.nodemanager.aux-services.mapreduce_shuffle.class
Handling deprecation for tfile.fs.output.buffer.size
Handling deprecation for fs.du.interval
Handling deprecation for dfs.client.failover.connection.retries
Handling deprecation for dfs.namenode.top.window.num.buckets
Handling deprecation for mapreduce.job.dir
Handling deprecation for fs.s3a.buffer.dir
Handling deprecation for mapreduce.reduce.shuffle.retry-delay.max.ms
Handling deprecation for yarn.sharedcache.uploader.server.address
Handling deprecation for mapreduce.client.progressmonitor.pollinterval
Handling deprecation for yarn.app.mapreduce.shuffle.log.limit.kb
Handling deprecation for dfs.datanode.max.locked.memory
Handling deprecation for dfs.namenode.retrycache.expirytime.millis
Handling deprecation for dfs.datanode.scan.period.hours
Handling deprecation for dfs.client.block.write.replace-datanode-on-failure.best-effort
Handling deprecation for mapreduce.jobhistory.move.interval-ms
Handling deprecation for dfs.ha.fencing.ssh.connect-timeout
Handling deprecation for yarn.nodemanager.log-aggregation.roll-monitoring-interval-seconds
Handling deprecation for dfs.namenode.fs-limits.max-component-length
Handling deprecation for hadoop.registry.zk.quorum
Handling deprecation for dfs.namenode.enable.retrycache
Handling deprecation for dfs.datanode.du.reserved
Handling deprecation for yarn.timeline-service.state-store-class
Handling deprecation for dfs.datanode.ipc.address
Handling deprecation for hadoop.registry.system.acls
Handling deprecation for dfs.client.block.write.replace-datanode-on-failure.policy
Handling deprecation for dfs.namenode.path.based.cache.retry.interval.ms
Handling deprecation for hadoop.security.crypto.cipher.suite
Handling deprecation for dfs.ha.tail-edits.period
Handling deprecation for mapreduce.task.profile.reduce.params
Handling deprecation for hadoop.registry.jaas.context
Handling deprecation for yarn.resourcemanager.hostname
Handling deprecation for mapreduce.reduce.memory.mb
Handling deprecation for hadoop.security.group.mapping.ldap.search.filter.group
Handling deprecation for hadoop.http.authentication.kerberos.principal
Handling deprecation for hadoop.security.group.mapping.ldap.search.filter.user
Handling deprecation for yarn.nodemanager.disk-health-checker.min-free-space-per-disk-mb
Handling deprecation for dfs.namenode.edits.dir
Handling deprecation for yarn.client.failover-retries-on-socket-timeouts
Handling deprecation for dfs.namenode.decommission.max.concurrent.tracked.nodes
Handling deprecation for mapreduce.client.completion.pollinterval
Handling deprecation for dfs.namenode.name.dir.restore
Handling deprecation for dfs.namenode.secondary.http-address
Handling deprecation for mapreduce.jobhistory.recovery.store.leveldb.path
Handling deprecation for yarn.sharedcache.store.class
Handling deprecation for s3.bytes-per-checksum
Handling deprecation for yarn.nodemanager.windows-container.cpu-limit.enabled
Handling deprecation for yarn.resourcemanager.webapp.https.address
Handling deprecation for yarn.nodemanager.vmem-pmem-ratio
Handling deprecation for dfs.namenode.checkpoint.period
Handling deprecation for dfs.ha.automatic-failover.enabled
Submitting tokens for job: job_local1772068781_0001
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.fs.FileContext.getAbstractFileSystem(FileContext.java:331)
Handling deprecation for all properties in config...
Handling deprecation for mapreduce.jobtracker.address
Handling deprecation for yarn.resourcemanager.scheduler.monitor.policies
Handling deprecation for dfs.namenode.resource.check.interval
Handling deprecation for mapreduce.jobhistory.client.thread-count
Handling deprecation for yarn.app.mapreduce.am.containerlauncher.threadpool-initial-size
Handling deprecation for mapred.child.java.opts
Handling deprecation for mapreduce.jobtracker.retiredjobs.cache.size
Handling deprecation for dfs.client.https.need-auth
Handling deprecation for yarn.admin.acl
Handling deprecation for yarn.app.mapreduce.am.job.committer.cancel-timeout
Handling deprecation for mapreduce.job.emit-timeline-data
Handling deprecation for fs.ftp.host.port
Handling deprecation for dfs.namenode.avoid.read.stale.datanode
Handling deprecation for dfs.journalnode.rpc-address
Handling deprecation for mapreduce.job.end-notification.retry.attempts
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.ttl-interval-ms
Handling deprecation for yarn.resourcemanager.leveldb-state-store.path
Handling deprecation for mapred.mapper.new-api
Handling deprecation for yarn.ipc.rpc.class
Handling deprecation for ipc.client.connection.maxidletime
Handling deprecation for yarn.nodemanager.process-kill-wait.ms
Handling deprecation for mapreduce.cluster.acls.enabled
Handling deprecation for mapreduce.jobtracker.handler.count
Handling deprecation for io.map.index.interval
Handling deprecation for dfs.namenode.https-address
Handling deprecation for mapreduce.task.profile.reduces
Handling deprecation for fs.s3n.multipart.uploads.enabled
Handling deprecation for io.seqfile.sorter.recordlimit
Handling deprecation for mapreduce.job.ubertask.maxmaps
Handling deprecation for mapreduce.tasktracker.tasks.sleeptimebeforesigkill
Handling deprecation for hadoop.util.hash.type
Handling deprecation for dfs.namenode.replication.min
Handling deprecation for yarn.nodemanager.container-manager.thread-count
Handling deprecation for mapreduce.jobtracker.jobhistory.block.size
Handling deprecation for dfs.namenode.fs-limits.min-block-size
Handling deprecation for mapreduce.app-submission.cross-platform
Handling deprecation for fs.AbstractFileSystem.file.impl
Handling deprecation for net.topology.script.number.args
Handling deprecation for yarn.resourcemanager.container-tokens.master-key-rolling-interval-secs
Handling deprecation for mapreduce.map.output.compress.codec
Handling deprecation for mapreduce.job.reducer.preempt.delay.sec
Handling deprecation for s3native.bytes-per-checksum
Handling deprecation for dfs.namenode.path.based.cache.block.map.allocation.percent
Handling deprecation for yarn.nodemanager.windows-container.memory-limit.enabled
Handling deprecation for mapreduce.input.fileinputformat.split.minsize
Handling deprecation for hadoop.security.group.mapping
Handling deprecation for mapreduce.jobtracker.system.dir
Handling deprecation for mapreduce.job.end-notification.max.attempts
Handling deprecation for mapreduce.reduce.markreset.buffer.percent
Handling deprecation for dfs.datanode.cache.revocation.polling.ms
Handling deprecation for mapreduce.reduce.speculative
Handling deprecation for yarn.nodemanager.localizer.cache.cleanup.interval-ms
Handling deprecation for dfs.namenode.lazypersist.file.scrub.interval.sec
Handling deprecation for fs.s3a.threads.core
Handling deprecation for mapreduce.jobhistory.recovery.store.fs.uri
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.start-time-read-cache-size
Handling deprecation for hadoop.registry.zk.retry.interval.ms
Handling deprecation for yarn.nodemanager.keytab
Handling deprecation for dfs.namenode.replication.interval
Handling deprecation for yarn.resourcemanager.admin.address
Handling deprecation for mapreduce.job.maps
Handling deprecation for nfs.dump.dir
Handling deprecation for mapreduce.job.user.name
Handling deprecation for mapreduce.jobtracker.maxtasks.perjob
Handling deprecation for mapreduce.job.ubertask.enable
Handling deprecation for mapreduce.job.reduce.class
Handling deprecation for yarn.nodemanager.delete.debug-delay-sec
Handling deprecation for yarn.timeline-service.ttl-enable
Handling deprecation for yarn.resourcemanager.fs.state-store.retry-policy-spec
Handling deprecation for mapreduce.reduce.skip.maxgroups
Handling deprecation for dfs.client.use.datanode.hostname
Handling deprecation for fs.trash.interval
Handling deprecation for mapreduce.job.name
Handling deprecation for mapreduce.am.max-attempts
Handling deprecation for mapreduce.jobtracker.heartbeats.in.second
Handling deprecation for yarn.resourcemanager.zk-num-retries
Handling deprecation for s3.blocksize
Handling deprecation for dfs.datanode.data.dir
Handling deprecation for mapreduce.jobtracker.persist.jobstatus.active
Handling deprecation for mapreduce.reduce.shuffle.parallelcopies
Handling deprecation for fs.s3.buffer.dir
Handling deprecation for mapreduce.jobhistory.done-dir
Handling deprecation for hadoop.security.instrumentation.requires.admin
Handling deprecation for hadoop.registry.zk.retry.ceiling.ms
Handling deprecation for nfs.rtmax
Handling deprecation for dfs.datanode.data.dir.perm
Handling deprecation for yarn.resourcemanager.container.liveness-monitor.interval-ms
Handling deprecation for yarn.nodemanager.env-whitelist
Handling deprecation for dfs.namenode.backup.address
Handling deprecation for dfs.namenode.xattrs.enabled
Handling deprecation for dfs.datanode.readahead.bytes
Handling deprecation for mapreduce.jobhistory.cleaner.enable
Handling deprecation for dfs.client.block.write.retries
Handling deprecation for mapreduce.tasktracker.http.address
Handling deprecation for yarn.nodemanager.linux-container-executor.cgroups.hierarchy
Handling deprecation for ha.failover-controller.graceful-fence.connection.retries
Handling deprecation for yarn.resourcemanager.recovery.enabled
Handling deprecation for yarn.app.mapreduce.am.container.log.backups
Handling deprecation for dfs.namenode.safemode.threshold-pct
Handling deprecation for yarn.nodemanager.disk-health-checker.interval-ms
Handling deprecation for hadoop.security.java.secure.random.algorithm
Handling deprecation for dfs.namenode.list.cache.directives.num.responses
Handling deprecation for dfs.datanode.dns.nameserver
Handling deprecation for mapreduce.cluster.temp.dir
Handling deprecation for fs.s3a.max.total.tasks
Handling deprecation for mapreduce.reduce.maxattempts
Handling deprecation for mapreduce.client.submit.file.replication
Handling deprecation for mapreduce.shuffle.port
Handling deprecation for yarn.resourcemanager.resource-tracker.client.thread-count
Handling deprecation for dfs.namenode.replication.considerLoad
Handling deprecation for dfs.namenode.edits.journal-plugin.qjournal
Handling deprecation for dfs.client.write.exclude.nodes.cache.expiry.interval.millis
Handling deprecation for yarn.nodemanager.delete.thread-count
Handling deprecation for dfs.client.mmap.cache.timeout.ms
Handling deprecation for yarn.nodemanager.admin-env
Handling deprecation for io.skip.checksum.errors
Handling deprecation for yarn.timeline-service.hostname
Handling deprecation for yarn.resourcemanager.proxy-user-privileges.enabled
Handling deprecation for mapreduce.job.speculative.speculative-cap-total-tasks
Handling deprecation for yarn.acl.enable
Handling deprecation for fs.s3a.fast.upload
Handling deprecation for file.blocksize
Handling deprecation for mapreduce.job.speculative.slowtaskthreshold
Handling deprecation for ftp.replication
Handling deprecation for yarn.sharedcache.cleaner.initial-delay-mins
Handling deprecation for s3native.client-write-packet-size
Handling deprecation for hadoop.rpc.socket.factory.class.default
Handling deprecation for file.bytes-per-checksum
Handling deprecation for dfs.datanode.slow.io.warning.threshold.ms
Handling deprecation for io.seqfile.lazydecompress
Handling deprecation for mapreduce.task.skip.start.attempts
Handling deprecation for dfs.namenode.reject-unresolved-dn-topology-mapping
Handling deprecation for hadoop.common.configuration.version
Handling deprecation for yarn.resourcemanager.client.thread-count
Handling deprecation for dfs.datanode.drop.cache.behind.reads
Handling deprecation for yarn.sharedcache.admin.address
Handling deprecation for mapreduce.job.output.value.class
Handling deprecation for mapreduce.output.fileoutputformat.outputdir
Handling deprecation for mapreduce.jobtracker.taskcache.levels
Handling deprecation for yarn.nodemanager.linux-container-executor.nonsecure-mode.user-pattern
Handling deprecation for yarn.resourcemanager.zk-timeout-ms
Handling deprecation for yarn.resourcemanager.max-completed-applications
Handling deprecation for mapreduce.job.jvm.numtasks
Handling deprecation for yarn.sharedcache.cleaner.period-mins
Handling deprecation for mapreduce.jobtracker.tasktracker.maxblacklists
Handling deprecation for dfs.namenode.top.num.users
Handling deprecation for yarn.nodemanager.linux-container-executor.cgroups.mount
Handling deprecation for yarn.sharedcache.checksum.algo.impl
Handling deprecation for mapreduce.job.end-notification.max.retry.interval
Handling deprecation for mapreduce.job.acl-view-job
Handling deprecation for mapreduce.job.classloader
Handling deprecation for yarn.log-aggregation-enable
Handling deprecation for mapreduce.reduce.shuffle.fetch.retry.interval-ms
Handling deprecation for yarn.resourcemanager.nodemanager.minimum.version
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.size
Handling deprecation for yarn.app.mapreduce.am.job.task.listener.thread-count
Handling deprecation for yarn.app.mapreduce.am.resource.cpu-vcores
Handling deprecation for dfs.namenode.edit.log.autoroll.check.interval.ms
Handling deprecation for mapreduce.output.fileoutputformat.compress.type
Handling deprecation for hadoop.hdfs.configuration.version
Handling deprecation for hadoop.security.group.mapping.ldap.search.attr.member
Handling deprecation for yarn.nodemanager.log.retain-seconds
Handling deprecation for yarn.nodemanager.local-cache.max-files-per-directory
Handling deprecation for mapreduce.job.end-notification.retry.interval
Handling deprecation for hadoop.ssl.client.conf
Handling deprecation for yarn.sharedcache.root-dir
Handling deprecation for dfs.journalnode.https-address
Handling deprecation for mapreduce.reduce.shuffle.fetch.retry.timeout-ms
Handling deprecation for dfs.bytes-per-checksum
Handling deprecation for dfs.namenode.max.objects
Handling deprecation for mapreduce.tasktracker.instrumentation
Handling deprecation for dfs.datanode.max.transfer.threads
Handling deprecation for dfs.block.access.key.update.interval
Handling deprecation for mapreduce.jobtracker.jobhistory.task.numberprogresssplits
Handling deprecation for mapreduce.map.memory.mb
Handling deprecation for ha.failover-controller.new-active.rpc-timeout.ms
Handling deprecation for hadoop.ssl.hostname.verifier
Handling deprecation for dfs.client.read.shortcircuit
Handling deprecation for dfs.datanode.hdfs-blocks-metadata.enabled
Handling deprecation for mapreduce.tasktracker.healthchecker.interval
Handling deprecation for dfs.image.transfer.chunksize
Handling deprecation for mapreduce.tasktracker.taskmemorymanager.monitoringinterval
Handling deprecation for dfs.client.https.keystore.resource
Handling deprecation for yarn.resourcemanager.connect.retry-interval.ms
Handling deprecation for yarn.timeline-service.webapp.address
Handling deprecation for s3native.blocksize
Handling deprecation for yarn.scheduler.minimum-allocation-mb
Handling deprecation for yarn.sharedcache.cleaner.resource-sleep-ms
Handling deprecation for net.topology.impl
Handling deprecation for dfs.client.failover.sleep.base.millis
Handling deprecation for dfs.permissions.superusergroup
Handling deprecation for io.seqfile.compress.blocksize
Handling deprecation for hadoop.registry.zk.retry.times
Handling deprecation for fs.AbstractFileSystem.ftp.impl
Handling deprecation for dfs.namenode.checkpoint.edits.dir
Handling deprecation for mapreduce.job.running.reduce.limit
Handling deprecation for dfs.blockreport.initialDelay
Handling deprecation for dfs.namenode.heartbeat.recheck-interval
Handling deprecation for dfs.namenode.safemode.extension
Handling deprecation for yarn.scheduler.maximum-allocation-mb
Handling deprecation for mapreduce.job.reduce.shuffle.consumer.plugin.class
Handling deprecation for yarn.nodemanager.vmem-check-enabled
Handling deprecation for mapreduce.task.io.sort.factor
Handling deprecation for mapreduce.jobtracker.persist.jobstatus.dir
Handling deprecation for dfs.client.failover.sleep.max.millis
Handling deprecation for dfs.namenode.delegation.key.update-interval
Handling deprecation for hadoop.rpc.protection
Handling deprecation for fs.permissions.umask-mode
Handling deprecation for fs.s3.sleepTimeSeconds
Handling deprecation for ha.health-monitor.rpc-timeout.ms
Handling deprecation for hadoop.http.staticuser.user
Handling deprecation for fs.s3a.connection.maximum
Handling deprecation for yarn.nodemanager.linux-container-executor.nonsecure-mode.limit-users
Handling deprecation for fs.s3a.paging.maximum
Handling deprecation for fs.AbstractFileSystem.viewfs.impl
Handling deprecation for fs.ftp.host
Handling deprecation for yarn.nodemanager.linux-container-executor.nonsecure-mode.local-user
Handling deprecation for fs.s3a.impl
Handling deprecation for hadoop.http.authentication.kerberos.keytab
Handling deprecation for dfs.namenode.fs-limits.max-blocks-per-file
Handling deprecation for mapreduce.tasktracker.http.threads
Handling deprecation for mapreduce.tasktracker.dns.nameserver
Handling deprecation for yarn.resourcemanager.am-rm-tokens.master-key-rolling-interval-secs
Handling deprecation for dfs.client.block.write.replace-datanode-on-failure.enable
Handling deprecation for io.compression.codec.bzip2.library
Handling deprecation for mapreduce.map.skip.maxrecords
Handling deprecation for dfs.client.use.legacy.blockreader.local
Handling deprecation for dfs.namenode.checkpoint.dir
Handling deprecation for dfs.namenode.top.windows.minutes
Handling deprecation for mapreduce.job.maxtaskfailures.per.tracker
Handling deprecation for net.topology.node.switch.mapping.impl
Handling deprecation for mapreduce.shuffle.max.connections
Handling deprecation for mapreduce.jobhistory.loadedjobs.cache.size
Handling deprecation for dfs.storage.policy.enabled
Handling deprecation for yarn.client.application-client-protocol.poll-interval-ms
Handling deprecation for yarn.nodemanager.localizer.address
Handling deprecation for dfs.namenode.list.cache.pools.num.responses
Handling deprecation for nfs.server.port
Handling deprecation for mapreduce.client.output.filter
Handling deprecation for yarn.timeline-service.client.best-effort
Handling deprecation for ha.zookeeper.parent-znode
Handling deprecation for mapreduce.jobtracker.persist.jobstatus.hours
Handling deprecation for yarn.sharedcache.admin.thread-count
Handling deprecation for yarn.nodemanager.resource.cpu-vcores
Handling deprecation for dfs.datanode.block-pinning.enabled
Handling deprecation for mapreduce.jobhistory.http.policy
Handling deprecation for yarn.resourcemanager.webapp.delegation-token-auth-filter.enabled
Handling deprecation for mapreduce.job.speculative.retry-after-no-speculate
Handling deprecation for fs.s3a.attempts.maximum
Handling deprecation for s3native.stream-buffer-size
Handling deprecation for io.seqfile.local.dir
Handling deprecation for yarn.log-aggregation.retain-check-interval-seconds
Handling deprecation for fs.s3n.multipart.copy.block.size
Handling deprecation for dfs.encrypt.data.transfer.cipher.key.bitlength
Handling deprecation for dfs.datanode.sync.behind.writes
Handling deprecation for yarn.resourcemanager.zk-acl
Handling deprecation for hadoop.ssl.keystores.factory.class
Handling deprecation for mapreduce.job.split.metainfo.maxsize
Handling deprecation for fs.s3.maxRetries
Handling deprecation for hadoop.security.random.device.file.path
Handling deprecation for yarn.client.nodemanager-connect.max-wait-ms
Handling deprecation for dfs.namenode.stale.datanode.interval
Handling deprecation for mapreduce.task.io.sort.mb
Handling deprecation for yarn.resourcemanager.zk-state-store.parent-path
Handling deprecation for yarn.app.mapreduce.client-am.ipc.max-retries
Handling deprecation for fs.client.resolve.remote.symlinks
Handling deprecation for yarn.nodemanager.linux-container-executor.cgroups.strict-resource-usage
Handling deprecation for hadoop.ssl.enabled.protocols
Handling deprecation for mapreduce.reduce.cpu.vcores
Handling deprecation for yarn.client.failover-retries
Handling deprecation for mapreduce.jobhistory.address
Handling deprecation for hadoop.ssl.enabled
Handling deprecation for dfs.replication.max
Handling deprecation for dfs.namenode.name.dir
Handling deprecation for dfs.datanode.https.address
Handling deprecation for ipc.client.kill.max
Handling deprecation for mapreduce.job.committer.setup.cleanup.needed
Handling deprecation for dfs.client.domain.socket.data.traffic
Handling deprecation for yarn.nodemanager.localizer.cache.target-size-mb
Handling deprecation for yarn.resourcemanager.admin.client.thread-count
Handling deprecation for dfs.block.access.token.enable
Handling deprecation for mapreduce.job.speculative.retry-after-speculate
Handling deprecation for dfs.datanode.address
Handling deprecation for mapreduce.jobtracker.restart.recover
Handling deprecation for ipc.client.connect.max.retries
Handling deprecation for yarn.timeline-service.store-class
Handling deprecation for dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
Handling deprecation for hadoop.tmp.dir
Handling deprecation for dfs.datanode.handler.count
Handling deprecation for yarn.resourcemanager.ha.automatic-failover.embedded
Handling deprecation for yarn.timeline-service.ttl-ms
Handling deprecation for mapreduce.task.profile.map.params
Handling deprecation for yarn.resourcemanager.nodemanagers.heartbeat-interval-ms
Handling deprecation for mapreduce.map.speculative
Handling deprecation for yarn.timeline-service.recovery.enabled
Handling deprecation for mapreduce.job.map.class
Handling deprecation for dfs.namenode.resource.checked.volumes.minimum
Handling deprecation for yarn.nodemanager.recovery.dir
Handling deprecation for mapreduce.job.counters.max
Handling deprecation for yarn.resourcemanager.keytab
Handling deprecation for dfs.namenode.max.extra.edits.segments.retained
Handling deprecation for dfs.webhdfs.user.provider.user.pattern
Handling deprecation for dfs.client.mmap.enabled
Handling deprecation for mapreduce.map.log.level
Handling deprecation for dfs.client.file-block-storage-locations.timeout.millis
Handling deprecation for yarn.client.max-cached-nodemanagers-proxies
Handling deprecation for yarn.app.mapreduce.am.scheduler.heartbeat.interval-ms
Handling deprecation for hadoop.fuse.timer.period
Handling deprecation for fs.trash.checkpoint.interval
Handling deprecation for yarn.sharedcache.app-checker.class
Handling deprecation for dfs.journalnode.http-address
Handling deprecation for yarn.app.mapreduce.am.staging-dir
Handling deprecation for mapreduce.tasktracker.local.dir.minspacestart
Handling deprecation for yarn.nm.liveness-monitor.expiry-interval-ms
Handling deprecation for ha.health-monitor.check-interval.ms
Handling deprecation for mapreduce.reduce.shuffle.merge.percent
Handling deprecation for dfs.namenode.retrycache.heap.percent
Handling deprecation for yarn.nodemanager.docker-container-executor.exec-name
Handling deprecation for ipc.client.connect.timeout
Handling deprecation for yarn.resourcemanager.fs.state-store.retry-interval-ms
Handling deprecation for mapreduce.output.fileoutputformat.compress
Handling deprecation for yarn.nodemanager.local-dirs
Handling deprecation for yarn.nodemanager.recovery.enabled
Handling deprecation for io.native.lib.available
Handling deprecation for yarn.sharedcache.store.in-memory.staleness-period-mins
Handling deprecation for yarn.resourcemanager.am.max-attempts
Handling deprecation for s3.replication
Handling deprecation for mapreduce.input.fileinputformat.inputdir
Handling deprecation for fs.AbstractFileSystem.har.impl
Handling deprecation for dfs.image.compress
Handling deprecation for mapreduce.job.running.map.limit
Handling deprecation for mapreduce.reduce.input.buffer.percent
Handling deprecation for yarn.nodemanager.webapp.address
Handling deprecation for dfs.datanode.available-space-volume-choosing-policy.balanced-space-preference-fraction
Handling deprecation for dfs.namenode.edit.log.autoroll.multiplier.threshold
Handling deprecation for hadoop.security.group.mapping.ldap.ssl
Handling deprecation for dfs.namenode.checkpoint.check.period
Handling deprecation for fs.defaultFS
Handling deprecation for fs.s3a.multipart.size
Handling deprecation for dfs.client.slow.io.warning.threshold.ms
Handling deprecation for yarn.app.mapreduce.am.job.committer.commit-window
Handling deprecation for hadoop.security.group.mapping.ldap.search.attr.group.name
Handling deprecation for yarn.nodemanager.disk-health-checker.max-disk-utilization-per-disk-percentage
Handling deprecation for yarn.nodemanager.container-monitor.procfs-tree.smaps-based-rss.enabled
Handling deprecation for mapreduce.job.submithostname
Handling deprecation for mapreduce.map.sort.spill.percent
Handling deprecation for hadoop.security.crypto.codec.classes.aes.ctr.nopadding
Handling deprecation for dfs.namenode.http-address
Handling deprecation for hadoop.security.groups.negative-cache.secs
Handling deprecation for hadoop.ssl.server.conf
Handling deprecation for mapreduce.ifile.readahead
Handling deprecation for s3native.replication
Handling deprecation for yarn.client.nodemanager-client-async.thread-pool-max-size
Handling deprecation for mapreduce.jobtracker.staging.root.dir
Handling deprecation for mapreduce.jobhistory.admin.address
Handling deprecation for dfs.namenode.startup.delay.block.deletion.sec
Handling deprecation for yarn.nodemanager.health-checker.interval-ms
Handling deprecation for dfs.namenode.checkpoint.max-retries
Handling deprecation for s3.stream-buffer-size
Handling deprecation for ftp.client-write-packet-size
Handling deprecation for dfs.datanode.fsdatasetcache.max.threads.per.volume
Handling deprecation for mapreduce.output.fileoutputformat.compress.codec
Handling deprecation for yarn.timeline-service.keytab
Handling deprecation for yarn.sharedcache.store.in-memory.initial-delay-mins
Handling deprecation for mapreduce.jobhistory.webapp.address
Handling deprecation for mapreduce.task.userlog.limit.kb
Handling deprecation for mapreduce.reduce.shuffle.fetch.retry.enabled
Handling deprecation for yarn.app.mapreduce.task.container.log.backups
Handling deprecation for dfs.heartbeat.interval
Handling deprecation for ha.zookeeper.session-timeout.ms
Handling deprecation for fs.s3a.connection.ssl.enabled
Handling deprecation for yarn.sharedcache.webapp.address
Handling deprecation for hadoop.http.authentication.signature.secret.file
Handling deprecation for hadoop.fuse.connection.timeout
Handling deprecation for mapreduce.input.fileinputformat.numinputfiles
Handling deprecation for yarn.nodemanager.log-aggregation.compression-type
Handling deprecation for ipc.server.max.connections
Handling deprecation for yarn.resourcemanager.work-preserving-recovery.scheduling-wait-ms
Handling deprecation for yarn.nodemanager.log-dirs
Handling deprecation for yarn.app.mapreduce.am.resource.mb
Handling deprecation for hadoop.security.groups.cache.secs
Handling deprecation for mapreduce.job.speculative.minimum-allowed-tasks
Handling deprecation for yarn.nodemanager.container-monitor.interval-ms
Handling deprecation for dfs.datanode.cache.revocation.timeout.ms
Handling deprecation for mapreduce.jobhistory.recovery.store.class
Handling deprecation for mapreduce.task.combine.progress.records
Handling deprecation for s3.client-write-packet-size
Handling deprecation for mapreduce.jobtracker.instrumentation
Handling deprecation for dfs.replication
Handling deprecation for mapreduce.shuffle.transfer.buffer.size
Handling deprecation for hadoop.security.group.mapping.ldap.directory.search.timeout
Handling deprecation for dfs.datanode.available-space-volume-choosing-policy.balanced-space-threshold
Handling deprecation for hadoop.work.around.non.threadsafe.getpwuid
Handling deprecation for yarn.app.mapreduce.client-am.ipc.max-retries-on-timeouts
Handling deprecation for yarn.nodemanager.address
Handling deprecation for mapreduce.tasktracker.taskcontroller
Handling deprecation for mapreduce.tasktracker.indexcache.mb
Handling deprecation for yarn.scheduler.maximum-allocation-vcores
Handling deprecation for mapreduce.job.reduces
Handling deprecation for yarn.nodemanager.sleep-delay-before-sigkill.ms
Handling deprecation for yarn.timeline-service.address
Handling deprecation for yarn.resourcemanager.configuration.provider-class
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.expiry
Handling deprecation for yarn.sharedcache.enabled
Handling deprecation for tfile.io.chunk.size
Handling deprecation for mapreduce.job.acl-modify-job
Handling deprecation for hadoop.registry.zk.session.timeout.ms
Handling deprecation for fs.automatic.close
Handling deprecation for ha.health-monitor.sleep-after-disconnect.ms
Handling deprecation for mapreduce.tasktracker.reduce.tasks.maximum
Handling deprecation for mapreduce.input.fileinputformat.list-status.num-threads
Handling deprecation for dfs.datanode.directoryscan.threads
Handling deprecation for dfs.datanode.directoryscan.interval
Handling deprecation for dfs.namenode.acls.enabled
Handling deprecation for dfs.client.short.circuit.replica.stale.threshold.ms
Handling deprecation for hadoop.http.authentication.token.validity
Handling deprecation for fs.s3.block.size
Handling deprecation for ha.failover-controller.graceful-fence.rpc-timeout.ms
Handling deprecation for mapreduce.tasktracker.local.dir.minspacekill
Handling deprecation for dfs.namenode.resource.du.reserved
Handling deprecation for mapreduce.jobhistory.cleaner.interval-ms
Handling deprecation for dfs.namenode.datanode.registration.ip-hostname-check
Handling deprecation for mapreduce.jobhistory.intermediate-done-dir
Handling deprecation for mapreduce.jobtracker.http.address
Handling deprecation for dfs.namenode.backup.http-address
Handling deprecation for dfs.namenode.edits.noeditlogchannelflush
Handling deprecation for mapreduce.reduce.shuffle.input.buffer.percent
Handling deprecation for mapreduce.map.maxattempts
Handling deprecation for yarn.http.policy
Handling deprecation for dfs.namenode.audit.loggers
Handling deprecation for hadoop.security.groups.cache.warn.after.ms
Handling deprecation for io.serializations
Handling deprecation for mapreduce.tasktracker.outofband.heartbeat
Handling deprecation for mapreduce.reduce.shuffle.read.timeout
Handling deprecation for hadoop.security.crypto.buffer.size
Handling deprecation for mapreduce.reduce.skip.proc.count.autoincr
Handling deprecation for mapreduce.ifile.readahead.bytes
Handling deprecation for dfs.http.policy
Handling deprecation for hadoop.registry.secure
Handling deprecation for dfs.namenode.safemode.min.datanodes
Handling deprecation for dfs.client.file-block-storage-locations.num-threads
Handling deprecation for mapreduce.cluster.local.dir
Handling deprecation for mapreduce.tasktracker.report.address
Handling deprecation for dfs.namenode.secondary.https-address
Handling deprecation for hadoop.kerberos.kinit.command
Handling deprecation for yarn.timeline-service.http-authentication.type
Handling deprecation for dfs.block.access.token.lifetime
Handling deprecation for dfs.webhdfs.enabled
Handling deprecation for dfs.namenode.delegation.token.max-lifetime
Handling deprecation for dfs.namenode.avoid.write.stale.datanode
Handling deprecation for dfs.datanode.drop.cache.behind.writes
Handling deprecation for yarn.log-aggregation.retain-seconds
Handling deprecation for mapreduce.job.complete.cancel.delegation.tokens
Handling deprecation for mapreduce.local.clientfactory.class.name
Handling deprecation for mapreduce.shuffle.connection-keep-alive.timeout
Handling deprecation for dfs.namenode.num.extra.edits.retained
Handling deprecation for yarn.scheduler.minimum-allocation-vcores
Handling deprecation for ipc.client.connect.max.retries.on.timeouts
Handling deprecation for yarn.timeline-service.client.retry-interval-ms
Handling deprecation for yarn.timeline-service.client.max-retries
Handling deprecation for fs.s3n.block.size
Handling deprecation for mapreduce.job.map.output.collector.class
Handling deprecation for ha.health-monitor.connect-retry-interval.ms
Handling deprecation for mapreduce.shuffle.max.threads
Handling deprecation for nfs.exports.allowed.hosts
Handling deprecation for dfs.client.mmap.cache.size
Handling deprecation for mapreduce.tasktracker.map.tasks.maximum
Handling deprecation for io.file.buffer.size
Handling deprecation for dfs.client.datanode-restart.timeout
Handling deprecation for io.mapfile.bloom.size
Handling deprecation for hadoop.security.kms.client.authentication.retry-count
Handling deprecation for dfs.namenode.checkpoint.txns
Handling deprecation for ipc.client.connect.retry.interval
Handling deprecation for dfs.client-write-packet-size
Handling deprecation for mapreduce.reduce.shuffle.connect.timeout
Handling deprecation for yarn.resourcemanager.fs.state-store.uri
Handling deprecation for fs.swift.impl
Handling deprecation for hadoop.registry.zk.connection.timeout.ms
Handling deprecation for mapred.queue.default.acl-administer-jobs
Handling deprecation for mapreduce.job.submithostaddress
Handling deprecation for dfs.cachereport.intervalMsec
Handling deprecation for yarn.app.mapreduce.shuffle.log.backups
Handling deprecation for yarn.app.mapreduce.am.container.log.limit.kb
Handling deprecation for yarn.nodemanager.resourcemanager.minimum.version
Handling deprecation for ftp.blocksize
Handling deprecation for yarn.resourcemanager.address
Handling deprecation for file.stream-buffer-size
Handling deprecation for yarn.resourcemanager.scheduler.monitor.enable
Handling deprecation for mapreduce.job.ubertask.maxreduces
Handling deprecation for nfs.allow.insecure.ports
Handling deprecation for yarn.sharedcache.nm.uploader.thread-count
Handling deprecation for ipc.client.idlethreshold
Handling deprecation for ftp.stream-buffer-size
Handling deprecation for yarn.sharedcache.client-server.address
Handling deprecation for dfs.client.failover.connection.retries.on.timeouts
Handling deprecation for dfs.namenode.replication.work.multiplier.per.iteration
Handling deprecation for hadoop.http.authentication.simple.anonymous.allowed
Handling deprecation for hadoop.security.authorization
Handling deprecation for yarn.client.nodemanager-connect.retry-interval-ms
Handling deprecation for yarn.am.liveness-monitor.expiry-interval-ms
Handling deprecation for fs.har.impl.disable.cache
Handling deprecation for yarn.nodemanager.linux-container-executor.resources-handler.class
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.read-cache-size
Handling deprecation for hadoop.security.authentication
Handling deprecation for dfs.image.compression.codec
Handling deprecation for mapreduce.task.files.preserve.failedtasks
Handling deprecation for dfs.client.read.shortcircuit.streams.cache.size
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.path
Handling deprecation for mapreduce.job.reduce.slowstart.completedmaps
Handling deprecation for mapreduce.jobhistory.minicluster.fixed.ports
Handling deprecation for file.replication
Handling deprecation for yarn.resourcemanager.ha.automatic-failover.enabled
Handling deprecation for mapreduce.job.userlog.retain.hours
Handling deprecation for mapreduce.jobhistory.joblist.cache.size
Handling deprecation for dfs.namenode.accesstime.precision
Handling deprecation for yarn.resourcemanager.work-preserving-recovery.enabled
Handling deprecation for dfs.namenode.fs-limits.max-xattrs-per-inode
Handling deprecation for io.mapfile.bloom.error.rate
Handling deprecation for yarn.resourcemanager.store.class
Handling deprecation for dfs.image.transfer.timeout
Handling deprecation for yarn.timeline-service.leveldb-state-store.path
Handling deprecation for nfs.wtmax
Handling deprecation for mapreduce.job.combine.class
Handling deprecation for dfs.namenode.support.allow.format
Handling deprecation for fs.s3a.multipart.purge
Handling deprecation for dfs.secondary.namenode.kerberos.internal.spnego.principal
Handling deprecation for fs.s3a.connection.establish.timeout
Handling deprecation for dfs.stream-buffer-size
Handling deprecation for dfs.namenode.invalidate.work.pct.per.iteration
Handling deprecation for yarn.nodemanager.container-executor.class
Handling deprecation for fs.s3a.multipart.purge.age
Handling deprecation for yarn.resourcemanager.scheduler.client.thread-count
Handling deprecation for dfs.namenode.top.enabled
Handling deprecation for yarn.app.mapreduce.shuffle.log.separate
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.low-watermark
Handling deprecation for fs.s3a.fast.buffer.size
Handling deprecation for hadoop.user.group.static.mapping.overrides
Handling deprecation for tfile.fs.input.buffer.size
Handling deprecation for dfs.client.cached.conn.retry
Handling deprecation for hadoop.http.authentication.type
Handling deprecation for dfs.namenode.list.encryption.zones.num.responses
Handling deprecation for mapreduce.map.cpu.vcores
Handling deprecation for dfs.namenode.path.based.cache.refresh.interval.ms
Handling deprecation for dfs.namenode.decommission.interval
Handling deprecation for dfs.namenode.fs-limits.max-directory-items
Handling deprecation for yarn.resourcemanager.zk-retry-interval-ms
Handling deprecation for ftp.bytes-per-checksum
Handling deprecation for dfs.ha.log-roll.period
Handling deprecation for dfs.user.home.dir.prefix
Handling deprecation for ipc.client.fallback-to-simple-auth-allowed
Handling deprecation for yarn.nodemanager.pmem-check-enabled
Handling deprecation for yarn.nodemanager.remote-app-log-dir
Handling deprecation for dfs.namenode.inotify.max.events.per.rpc
Handling deprecation for mapreduce.task.profile.maps
Handling deprecation for mapreduce.shuffle.ssl.file.buffer.size
Handling deprecation for mapreduce.tasktracker.healthchecker.script.timeout
Handling deprecation for yarn.timeline-service.webapp.https.address
Handling deprecation for yarn.nodemanager.resource.percentage-physical-cpu-limit
Handling deprecation for yarn.app.mapreduce.am.command-opts
Handling deprecation for dfs.namenode.fs-limits.max-xattr-size
Handling deprecation for dfs.datanode.http.address
Handling deprecation for dfs.namenode.blocks.per.postponedblocks.rescan
Handling deprecation for yarn.sharedcache.nm.uploader.replication.factor
Handling deprecation for hadoop.registry.zk.root
Handling deprecation for hadoop.jetty.logs.serve.aliases
Handling deprecation for yarn.client.failover-proxy-provider
Handling deprecation for mapreduce.jobhistory.admin.acl
Handling deprecation for yarn.app.mapreduce.am.hard-kill-timeout-ms
Handling deprecation for yarn.nodemanager.remote-app-log-dir-suffix
Handling deprecation for mapreduce.jobhistory.principal
Handling deprecation for yarn.resourcemanager.webapp.address
Handling deprecation for mapreduce.jobhistory.recovery.enable
Handling deprecation for yarn.sharedcache.store.in-memory.check-period-mins
Handling deprecation for nfs.mountd.port
Handling deprecation for mapreduce.reduce.merge.inmem.threshold
Handling deprecation for fs.df.interval
Handling deprecation for yarn.timeline-service.enabled
Handling deprecation for mapreduce.jobtracker.jobhistory.lru.cache.size
Handling deprecation for mapreduce.task.profile
Handling deprecation for mapreduce.job.output.key.class
Handling deprecation for yarn.nodemanager.hostname
Handling deprecation for dfs.namenode.num.checkpoints.retained
Handling deprecation for mapreduce.job.queuename
Handling deprecation for mapreduce.jobhistory.max-age-ms
Handling deprecation for mapreduce.job.token.tracking.ids.enabled
Handling deprecation for yarn.nodemanager.localizer.client.thread-count
Handling deprecation for yarn.sharedcache.uploader.server.thread-count
Handling deprecation for dfs.client.mmap.retry.timeout.ms
Handling deprecation for mapreduce.jobhistory.move.thread-count
Handling deprecation for dfs.permissions.enabled
Handling deprecation for dfs.blockreport.split.threshold
Handling deprecation for fs.AbstractFileSystem.hdfs.impl
Handling deprecation for dfs.datanode.balance.bandwidthPerSec
Handling deprecation for dfs.block.scanner.volume.bytes.per.second
Handling deprecation for hadoop.http.filter.initializers
Handling deprecation for yarn.timeline-service.http-authentication.simple.anonymous.allowed
Handling deprecation for dfs.default.chunk.view.size
Handling deprecation for yarn.sharedcache.client-server.thread-count
Handling deprecation for yarn.resourcemanager.resource-tracker.address
Handling deprecation for mapreduce.job.working.dir
Handling deprecation for mapreduce.jobhistory.datestring.cache.size
Handling deprecation for mapreduce.task.profile.params
Handling deprecation for dfs.namenode.decommission.blocks.per.interval
Handling deprecation for dfs.namenode.handler.count
Handling deprecation for dfs.image.transfer.bandwidthPerSec
Handling deprecation for rpc.metrics.quantile.enable
Handling deprecation for mapreduce.jobtracker.expire.trackers.interval
Handling deprecation for mapreduce.task.timeout
Handling deprecation for yarn.app.mapreduce.client.max-retries
Handling deprecation for yarn.nodemanager.resource.memory-mb
Handling deprecation for yarn.nodemanager.disk-health-checker.min-healthy-disks
Handling deprecation for dfs.datanode.failed.volumes.tolerated
Handling deprecation for yarn.timeline-service.handler-thread-count
Handling deprecation for ipc.server.listen.queue.size
Handling deprecation for fs.s3a.threads.max
Handling deprecation for yarn.resourcemanager.connect.max-wait.ms
Handling deprecation for mapreduce.fileoutputcommitter.algorithm.version
Handling deprecation for mapreduce.framework.name
Handling deprecation for mapreduce.map.skip.proc.count.autoincr
Handling deprecation for mapreduce.job.max.split.locations
Handling deprecation for yarn.resourcemanager.scheduler.class
Handling deprecation for yarn.resourcemanager.system-metrics-publisher.enabled
Handling deprecation for dfs.blocksize
Handling deprecation for yarn.sharedcache.nested-level
Handling deprecation for mapreduce.shuffle.connection-keep-alive.enable
Handling deprecation for fs.s3a.threads.keepalivetime
Handling deprecation for fs.s3a.connection.timeout
Handling deprecation for file.client-write-packet-size
Handling deprecation for ha.failover-controller.cli-check.rpc-timeout.ms
Handling deprecation for ha.zookeeper.acl
Handling deprecation for dfs.namenode.write.stale.datanode.ratio
Handling deprecation for dfs.encrypt.data.transfer
Handling deprecation for dfs.datanode.shared.file.descriptor.paths
Handling deprecation for mapreduce.input.lineinputformat.linespermap
Handling deprecation for yarn.resourcemanager.delayed.delegation-token.removal-interval-ms
Handling deprecation for yarn.nodemanager.localizer.fetch.thread-count
Handling deprecation for dfs.client.failover.max.attempts
Handling deprecation for yarn.resourcemanager.scheduler.address
Handling deprecation for dfs.client.read.shortcircuit.streams.cache.expiry.ms
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.start-time-write-cache-size
Handling deprecation for yarn.nodemanager.health-checker.script.timeout-ms
Handling deprecation for yarn.resourcemanager.fs.state-store.num-retries
Handling deprecation for hadoop.ssl.require.client.cert
Handling deprecation for hadoop.security.uid.cache.secs
Handling deprecation for mapreduce.jobhistory.keytab
Handling deprecation for dfs.client.read.shortcircuit.skip.checksum
Handling deprecation for yarn.resourcemanager.ha.automatic-failover.zk-base-path
Handling deprecation for mapreduce.shuffle.ssl.enabled
Handling deprecation for mapreduce.reduce.log.level
Handling deprecation for hadoop.registry.rm.enabled
Handling deprecation for mapreduce.tasktracker.dns.interface
Handling deprecation for yarn.resourcemanager.system-metrics-publisher.dispatcher.pool-size
Handling deprecation for mapreduce.job.speculative.speculative-cap-running-tasks
Handling deprecation for dfs.datanode.block.id.layout.upgrade.threads
Handling deprecation for dfs.datanode.use.datanode.hostname
Handling deprecation for dfs.client.context
Handling deprecation for yarn.resourcemanager.ha.enabled
Handling deprecation for mapred.reducer.new-api
Handling deprecation for dfs.namenode.delegation.token.renew-interval
Handling deprecation for dfs.blockreport.intervalMsec
Handling deprecation for fs.s3a.multipart.threshold
Handling deprecation for mapreduce.reduce.shuffle.memory.limit.percent
Handling deprecation for dfs.https.server.keystore.resource
Handling deprecation for io.map.index.skip
Handling deprecation for mapreduce.job.hdfs-servers
Handling deprecation for mapreduce.jobtracker.taskscheduler
Handling deprecation for dfs.namenode.kerberos.internal.spnego.principal
Handling deprecation for yarn.resourcemanager.state-store.max-completed-applications
Handling deprecation for mapreduce.map.output.compress
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.num.refill.threads
Handling deprecation for fs.s3n.multipart.uploads.block.size
Handling deprecation for mapreduce.task.merge.progress.records
Handling deprecation for dfs.datanode.dns.interface
Handling deprecation for map.sort.class
Handling deprecation for yarn.nodemanager.aux-services.mapreduce_shuffle.class
Handling deprecation for tfile.fs.output.buffer.size
Handling deprecation for fs.du.interval
Handling deprecation for dfs.client.failover.connection.retries
Handling deprecation for dfs.namenode.top.window.num.buckets
Handling deprecation for mapreduce.job.dir
Handling deprecation for fs.s3a.buffer.dir
Handling deprecation for mapreduce.reduce.shuffle.retry-delay.max.ms
Handling deprecation for yarn.sharedcache.uploader.server.address
Handling deprecation for mapreduce.client.progressmonitor.pollinterval
Handling deprecation for yarn.app.mapreduce.shuffle.log.limit.kb
Handling deprecation for dfs.datanode.max.locked.memory
Handling deprecation for dfs.namenode.retrycache.expirytime.millis
Handling deprecation for dfs.datanode.scan.period.hours
Handling deprecation for dfs.client.block.write.replace-datanode-on-failure.best-effort
Handling deprecation for mapreduce.jobhistory.move.interval-ms
Handling deprecation for dfs.ha.fencing.ssh.connect-timeout
Handling deprecation for yarn.nodemanager.log-aggregation.roll-monitoring-interval-seconds
Handling deprecation for dfs.namenode.fs-limits.max-component-length
Handling deprecation for hadoop.registry.zk.quorum
Handling deprecation for dfs.namenode.enable.retrycache
Handling deprecation for dfs.datanode.du.reserved
Handling deprecation for yarn.timeline-service.state-store-class
Handling deprecation for dfs.datanode.ipc.address
Handling deprecation for hadoop.registry.system.acls
Handling deprecation for dfs.client.block.write.replace-datanode-on-failure.policy
Handling deprecation for dfs.namenode.path.based.cache.retry.interval.ms
Handling deprecation for hadoop.security.crypto.cipher.suite
Handling deprecation for dfs.ha.tail-edits.period
Handling deprecation for mapreduce.task.profile.reduce.params
Handling deprecation for hadoop.registry.jaas.context
Handling deprecation for yarn.resourcemanager.hostname
Handling deprecation for mapreduce.reduce.memory.mb
Handling deprecation for hadoop.security.group.mapping.ldap.search.filter.group
Handling deprecation for hadoop.http.authentication.kerberos.principal
Handling deprecation for hadoop.security.group.mapping.ldap.search.filter.user
Handling deprecation for yarn.nodemanager.disk-health-checker.min-free-space-per-disk-mb
Handling deprecation for dfs.namenode.edits.dir
Handling deprecation for yarn.client.failover-retries-on-socket-timeouts
Handling deprecation for dfs.namenode.decommission.max.concurrent.tracked.nodes
Handling deprecation for mapreduce.client.completion.pollinterval
Handling deprecation for dfs.namenode.name.dir.restore
Handling deprecation for dfs.namenode.secondary.http-address
Handling deprecation for mapreduce.jobhistory.recovery.store.leveldb.path
Handling deprecation for yarn.sharedcache.store.class
Handling deprecation for s3.bytes-per-checksum
Handling deprecation for yarn.nodemanager.windows-container.cpu-limit.enabled
Handling deprecation for yarn.resourcemanager.webapp.https.address
Handling deprecation for yarn.nodemanager.vmem-pmem-ratio
Handling deprecation for dfs.namenode.checkpoint.period
Handling deprecation for dfs.ha.automatic-failover.enabled
The url to track the job: http://localhost:8080/
Running job: job_local1772068781_0001
OutputCommitter set in config null
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
File Output Committer Algorithm version is 1
OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
/user/michaeljones/wcOutput/_temporary/0: masked=rwxr-xr-x
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones sending #12
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones got value #12
Call: mkdirs took 4ms
Starting mapper thread pool executor.
Max local threads: 1
Map tasks to process: 1
Waiting for map tasks
Starting task: attempt_local1772068781_0001_m_000000_0
currentIndex 0   0:0
mapreduce.cluster.local.dir for child : /tmp/hadoop-michaeljones/mapred/local/localRunner//michaeljones/jobcache/job_local1772068781_0001/attempt_local1772068781_0001_m_000000_0
using new api for output committer
File Output Committer Algorithm version is 1
ProcfsBasedProcessTree currently is supported only on Linux.
 Using ResourceCalculatorProcessTree : null
Processing split: hdfs://localhost:9000/user/michaeljones/wcInput:0+50
Trying map output collector class: org.apache.hadoop.mapred.MapTask$MapOutputBuffer
(EQUATOR) 0 kvi 26214396(104857584)
mapreduce.task.io.sort.mb: 100
soft limit at 83886080
bufstart = 0; bufvoid = 104857600
kvstart = 26214396; length = 6553600
Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones sending #13
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones got value #13
Call: getBlockLocations took 2ms
newInfo = LocatedBlocks{
  fileLength=50
  underConstruction=false
  blocks=[LocatedBlock{BP-1045030256-10.0.0.2-1433119149314:blk_1073741825_1002; getBlockSize()=50; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-b42c5705-9ba4-4b14-b00b-f9194bb036f0,DISK]]}]
  lastLocatedBlock=LocatedBlock{BP-1045030256-10.0.0.2-1433119149314:blk_1073741825_1002; getBlockSize()=50; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-b42c5705-9ba4-4b14-b00b-f9194bb036f0,DISK]]}
  isLastBlockComplete=true}
Connecting to datanode 127.0.0.1:50010

Starting flush of map output
Spilling map output
bufstart = 0; bufend = 82; bufvoid = 104857600
kvstart = 26214396(104857584); kvend = 26214368(104857472); length = 29/6553600
Finished spill 0
Task:attempt_local1772068781_0001_m_000000_0 is done. And is in the process of committing
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones sending #14
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones got value #14
Call: getFileInfo took 2ms
map
Task 'attempt_local1772068781_0001_m_000000_0' done.
Finishing task: attempt_local1772068781_0001_m_000000_0
map task executor complete.
Starting reduce thread pool executor.
Max local threads: 1
Reduce tasks to process: 1
Starting task: attempt_local1772068781_0001_r_000000_0
Waiting for reduce tasks
currentIndex 0   0:0
mapreduce.cluster.local.dir for child : /tmp/hadoop-michaeljones/mapred/local/localRunner//michaeljones/jobcache/job_local1772068781_0001/attempt_local1772068781_0001_r_000000_0
using new api for output committer
File Output Committer Algorithm version is 1
ProcfsBasedProcessTree currently is supported only on Linux.
 Using ResourceCalculatorProcessTree : null
Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@2c418b0e
MergerManager: memoryLimit=668309888, maxSingleShuffleLimit=167077472, mergeThreshold=441084544, ioSortFactor=10, memToMemMergeOutputsThreshold=10
attempt_local1772068781_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
Got 0 map completion events from 0
GetMapEventsThread about to sleep for 1000
LocalFetcher 1 going to fetch: attempt_local1772068781_0001_m_000000_0
attempt_local1772068781_0001_m_000000_0: Proceeding with shuffle since usedMemory (0) is lesser than memoryLimit (668309888).CommitMemory is (0)
localfetcher#1 about to shuffle output of map attempt_local1772068781_0001_m_000000_0 decomp: 63 len: 67 to MEMORY
Read 63 bytes from map-output for attempt_local1772068781_0001_m_000000_0
closeInMemoryFile -> map-output of size: 63, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->63
map attempt_local1772068781_0001_m_000000_0 done 1 / 1 copied.
EventFetcher is interrupted.. Returning
1 / 1 copied.
finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
Merging 1 sorted segments
Down to the last merge-pass, with 1 segments left of total size: 57 bytes
Merged 1 segments, 63 bytes to disk to satisfy reduce memory limit
Disk file: /tmp/hadoop-michaeljones/mapred/local/localRunner/michaeljones/jobcache/job_local1772068781_0001/attempt_local1772068781_0001_r_000000_0/output/map_0.out.merged Length is 67
Merging 1 files, 67 bytes from disk
Merging 0 segments, 0 bytes from memory into reduce
Merging 1 sorted segments
Down to the last merge-pass, with 1 segments left of total size: 57 bytes
1 / 1 copied.
/user/michaeljones/wcOutput/_temporary/0/_temporary/attempt_local1772068781_0001_r_000000_0/part-r-00000: masked=rw-r--r--
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones sending #15
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones got value #15
Call: create took 4ms
computePacketChunkSize: src=/user/michaeljones/wcOutput/_temporary/0/_temporary/attempt_local1772068781_0001_r_000000_0/part-r-00000, chunkSize=516, chunksPerPacket=126, packetSize=65016
mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
DFSClient writeChunk allocating new packet seqno=0, src=/user/michaeljones/wcOutput/_temporary/0/_temporary/attempt_local1772068781_0001_r_000000_0/part-r-00000, packetSize=65016, chunksPerPacket=126, bytesCurBlock=0
Queued packet 0
Allocating new block
Queued packet 1
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones sending #16
Waiting for ack for: 1
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones got value #16
Call: addBlock took 3ms
pipeline = DatanodeInfoWithStorage[127.0.0.1:50010,DS-b42c5705-9ba4-4b14-b00b-f9194bb036f0,DISK]
Connecting to datanode 127.0.0.1:50010
Send buf size 131072
SASL client skipping handshake in unsecured configuration for addr = /127.0.0.1, datanodeId = DatanodeInfoWithStorage[127.0.0.1:50010,DS-b42c5705-9ba4-4b14-b00b-f9194bb036f0,DISK]
DataStreamer block BP-1045030256-10.0.0.2-1433119149314:blk_1073742229_1406 sending packet packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 41
DFSClient seqno: 0 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
DataStreamer block BP-1045030256-10.0.0.2-1433119149314:blk_1073742229_1406 sending packet packet seqno: 1 offsetInBlock: 41 lastPacketInBlock: true lastByteOffsetInBlock: 41
DFSClient seqno: 1 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
Closing old block BP-1045030256-10.0.0.2-1433119149314:blk_1073742229_1406
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones sending #17
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones got value #17
Call: complete took 2ms
Task:attempt_local1772068781_0001_r_000000_0 is done. And is in the process of committing
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones sending #18
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones got value #18
Call: getFileInfo took 2ms
1 / 1 copied.
Task attempt_local1772068781_0001_r_000000_0 is allowed to commit now
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones sending #19
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones got value #19
Call: getFileInfo took 2ms
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones sending #20
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones got value #20
Call: getFileInfo took 2ms
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones sending #21
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones got value #21
Call: rename took 3ms
Saved output of task 'attempt_local1772068781_0001_r_000000_0' to hdfs://localhost:9000/user/michaeljones/wcOutput/_temporary/0/task_local1772068781_0001_r_000000
reduce > reduce
Task 'attempt_local1772068781_0001_r_000000_0' done.
Finishing task: attempt_local1772068781_0001_r_000000_0
reduce task executor complete.
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones sending #22
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones got value #22
Call: getListing took 2ms
Merging data from FileStatus{path=hdfs://localhost:9000/user/michaeljones/wcOutput/_temporary/0/task_local1772068781_0001_r_000000; isDirectory=true; modification_time=1434159016706; access_time=0; owner=michaeljones; group=supergroup; permission=rwxr-xr-x; isSymlink=false} to hdfs://localhost:9000/user/michaeljones/wcOutput
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones sending #23
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones got value #23
Call: getFileInfo took 1ms
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones sending #24
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones got value #24
Call: getListing took 2ms
Merging data from FileStatus{path=hdfs://localhost:9000/user/michaeljones/wcOutput/_temporary/0/task_local1772068781_0001_r_000000/part-r-00000; isDirectory=false; length=41; replication=1; blocksize=134217728; modification_time=1434159016739; access_time=1434159016706; owner=michaeljones; group=supergroup; permission=rw-r--r--; isSymlink=false} to hdfs://localhost:9000/user/michaeljones/wcOutput/part-r-00000
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones sending #25
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones got value #25
Call: getFileInfo took 2ms
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones sending #26
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones got value #26
Call: rename took 5ms
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones sending #27
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones got value #27
Call: delete took 2ms
/user/michaeljones/wcOutput/_SUCCESS: masked=rw-r--r--
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones sending #28
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones got value #28
Call: create took 4ms
computePacketChunkSize: src=/user/michaeljones/wcOutput/_SUCCESS, chunkSize=516, chunksPerPacket=126, packetSize=65016
Waiting for ack for: -1
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones sending #29
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones got value #29
Call: complete took 2ms
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.fs.FileContext.getAbstractFileSystem(FileContext.java:331)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
Job job_local1772068781_0001 running in uber mode : false
 map 100% reduce 100%
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.getTaskCompletionEvents(Job.java:670)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.getTaskCompletionEvents(Job.java:670)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
Job job_local1772068781_0001 completed successfully
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.getCounters(Job.java:758)
Counters: 35
	File System Counters
		FILE: Number of bytes read=520
		FILE: Number of bytes written=565627
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=140
		HDFS: Number of bytes written=81
		HDFS: Number of read operations=19
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=10
	Map-Reduce Framework
		Map input records=2
		Map output records=8
		Map output bytes=82
		Map output materialized bytes=67
		Input split bytes=112
		Combine input records=8
		Combine output records=5
		Reduce input groups=5
		Reduce shuffle bytes=67
		Reduce input records=5
		Reduce output records=5
		Spilled Records=10
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=514850816
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=50
	File Output Format Counters 
		Bytes Written=41
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
RunJobAnalysisAsync
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones sending #30
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones got value #30
Call: getFileInfo took 2ms
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones sending #31
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones got value #31
Call: delete took 5ms
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.connect(Job.java:1256)
Trying ClientProtocolProvider : org.apache.hadoop.mapred.LocalClientProtocolProvider
Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
Picked org.apache.hadoop.mapred.LocalClientProtocolProvider as the ClientProtocolProvider
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Cluster.getFileSystem(Cluster.java:162)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.submit(Job.java:1287)
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones sending #32
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones got value #32
Call: getFileInfo took 2ms
Configuring job job_local343739539_0002 with file:/tmp/hadoop-michaeljones/mapred/staging/michaeljones343739539/.staging/job_local343739539_0002 as the submit dir
adding the following namenodes' delegation tokens:[hdfs://localhost:9000]
Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
default FileSystem: file:///
No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
Creating splits at file:/tmp/hadoop-michaeljones/mapred/staging/michaeljones343739539/.staging/job_local343739539_0002
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones sending #33
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones got value #33
Call: getFileInfo took 1ms
Time taken to get FileStatuses: 2
Total input paths to process : 1
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones sending #34
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones got value #34
Call: getBlockLocations took 2ms
Total # of splits generated by getSplits: 1, TimeTaken: 5
number of splits:1
Handling deprecation for all properties in config...
Handling deprecation for mapreduce.jobtracker.address
Handling deprecation for yarn.resourcemanager.scheduler.monitor.policies
Handling deprecation for dfs.namenode.resource.check.interval
Handling deprecation for mapreduce.jobhistory.client.thread-count
Handling deprecation for yarn.app.mapreduce.am.containerlauncher.threadpool-initial-size
Handling deprecation for mapred.child.java.opts
Handling deprecation for mapreduce.jobtracker.retiredjobs.cache.size
Handling deprecation for dfs.client.https.need-auth
Handling deprecation for yarn.admin.acl
Handling deprecation for yarn.app.mapreduce.am.job.committer.cancel-timeout
Handling deprecation for mapreduce.job.emit-timeline-data
Handling deprecation for fs.ftp.host.port
Handling deprecation for dfs.namenode.avoid.read.stale.datanode
Handling deprecation for dfs.journalnode.rpc-address
Handling deprecation for mapreduce.job.end-notification.retry.attempts
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.ttl-interval-ms
Handling deprecation for yarn.resourcemanager.leveldb-state-store.path
Handling deprecation for mapred.mapper.new-api
Handling deprecation for yarn.ipc.rpc.class
Handling deprecation for ipc.client.connection.maxidletime
Handling deprecation for yarn.nodemanager.process-kill-wait.ms
Handling deprecation for mapreduce.cluster.acls.enabled
Handling deprecation for mapreduce.jobtracker.handler.count
Handling deprecation for io.map.index.interval
Handling deprecation for dfs.namenode.https-address
Handling deprecation for mapreduce.task.profile.reduces
Handling deprecation for fs.s3n.multipart.uploads.enabled
Handling deprecation for io.seqfile.sorter.recordlimit
Handling deprecation for mapreduce.job.ubertask.maxmaps
Handling deprecation for mapreduce.tasktracker.tasks.sleeptimebeforesigkill
Handling deprecation for hadoop.util.hash.type
Handling deprecation for dfs.namenode.replication.min
Handling deprecation for yarn.nodemanager.container-manager.thread-count
Handling deprecation for mapreduce.jobtracker.jobhistory.block.size
Handling deprecation for dfs.namenode.fs-limits.min-block-size
Handling deprecation for mapreduce.app-submission.cross-platform
Handling deprecation for fs.AbstractFileSystem.file.impl
Handling deprecation for net.topology.script.number.args
Handling deprecation for yarn.resourcemanager.container-tokens.master-key-rolling-interval-secs
Handling deprecation for mapreduce.map.output.compress.codec
Handling deprecation for mapreduce.job.reducer.preempt.delay.sec
Handling deprecation for s3native.bytes-per-checksum
Handling deprecation for dfs.namenode.path.based.cache.block.map.allocation.percent
Handling deprecation for yarn.nodemanager.windows-container.memory-limit.enabled
Handling deprecation for mapreduce.input.fileinputformat.split.minsize
Handling deprecation for hadoop.security.group.mapping
Handling deprecation for mapreduce.jobtracker.system.dir
Handling deprecation for mapreduce.job.end-notification.max.attempts
Handling deprecation for mapreduce.reduce.markreset.buffer.percent
Handling deprecation for dfs.datanode.cache.revocation.polling.ms
Handling deprecation for mapreduce.reduce.speculative
Handling deprecation for yarn.nodemanager.localizer.cache.cleanup.interval-ms
Handling deprecation for dfs.namenode.lazypersist.file.scrub.interval.sec
Handling deprecation for fs.s3a.threads.core
Handling deprecation for mapreduce.jobhistory.recovery.store.fs.uri
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.start-time-read-cache-size
Handling deprecation for hadoop.registry.zk.retry.interval.ms
Handling deprecation for yarn.nodemanager.keytab
Handling deprecation for dfs.namenode.replication.interval
Handling deprecation for yarn.resourcemanager.admin.address
Handling deprecation for mapreduce.job.maps
Handling deprecation for nfs.dump.dir
Handling deprecation for mapreduce.job.user.name
Handling deprecation for mapreduce.jobtracker.maxtasks.perjob
Handling deprecation for mapreduce.job.ubertask.enable
Handling deprecation for mapreduce.job.reduce.class
Handling deprecation for yarn.nodemanager.delete.debug-delay-sec
Handling deprecation for yarn.timeline-service.ttl-enable
Handling deprecation for yarn.resourcemanager.fs.state-store.retry-policy-spec
Handling deprecation for mapreduce.reduce.skip.maxgroups
Handling deprecation for dfs.client.use.datanode.hostname
Handling deprecation for fs.trash.interval
Handling deprecation for mapreduce.job.name
Handling deprecation for mapreduce.am.max-attempts
Handling deprecation for mapreduce.jobtracker.heartbeats.in.second
Handling deprecation for yarn.resourcemanager.zk-num-retries
Handling deprecation for s3.blocksize
Handling deprecation for dfs.datanode.data.dir
Handling deprecation for mapreduce.jobtracker.persist.jobstatus.active
Handling deprecation for mapreduce.reduce.shuffle.parallelcopies
Handling deprecation for fs.s3.buffer.dir
Handling deprecation for mapreduce.jobhistory.done-dir
Handling deprecation for hadoop.security.instrumentation.requires.admin
Handling deprecation for hadoop.registry.zk.retry.ceiling.ms
Handling deprecation for nfs.rtmax
Handling deprecation for dfs.datanode.data.dir.perm
Handling deprecation for yarn.resourcemanager.container.liveness-monitor.interval-ms
Handling deprecation for yarn.nodemanager.env-whitelist
Handling deprecation for dfs.namenode.backup.address
Handling deprecation for dfs.namenode.xattrs.enabled
Handling deprecation for dfs.datanode.readahead.bytes
Handling deprecation for mapreduce.jobhistory.cleaner.enable
Handling deprecation for dfs.client.block.write.retries
Handling deprecation for mapreduce.tasktracker.http.address
Handling deprecation for yarn.nodemanager.linux-container-executor.cgroups.hierarchy
Handling deprecation for ha.failover-controller.graceful-fence.connection.retries
Handling deprecation for yarn.resourcemanager.recovery.enabled
Handling deprecation for yarn.app.mapreduce.am.container.log.backups
Handling deprecation for dfs.namenode.safemode.threshold-pct
Handling deprecation for yarn.nodemanager.disk-health-checker.interval-ms
Handling deprecation for hadoop.security.java.secure.random.algorithm
Handling deprecation for dfs.namenode.list.cache.directives.num.responses
Handling deprecation for dfs.datanode.dns.nameserver
Handling deprecation for mapreduce.cluster.temp.dir
Handling deprecation for fs.s3a.max.total.tasks
Handling deprecation for mapreduce.reduce.maxattempts
Handling deprecation for mapreduce.client.submit.file.replication
Handling deprecation for mapreduce.shuffle.port
Handling deprecation for yarn.resourcemanager.resource-tracker.client.thread-count
Handling deprecation for dfs.namenode.replication.considerLoad
Handling deprecation for dfs.namenode.edits.journal-plugin.qjournal
Handling deprecation for dfs.client.write.exclude.nodes.cache.expiry.interval.millis
Handling deprecation for yarn.nodemanager.delete.thread-count
Handling deprecation for dfs.client.mmap.cache.timeout.ms
Handling deprecation for yarn.nodemanager.admin-env
Handling deprecation for io.skip.checksum.errors
Handling deprecation for yarn.timeline-service.hostname
Handling deprecation for yarn.resourcemanager.proxy-user-privileges.enabled
Handling deprecation for mapreduce.job.speculative.speculative-cap-total-tasks
Handling deprecation for yarn.acl.enable
Handling deprecation for fs.s3a.fast.upload
Handling deprecation for file.blocksize
Handling deprecation for mapreduce.job.speculative.slowtaskthreshold
Handling deprecation for ftp.replication
Handling deprecation for yarn.sharedcache.cleaner.initial-delay-mins
Handling deprecation for s3native.client-write-packet-size
Handling deprecation for hadoop.rpc.socket.factory.class.default
Handling deprecation for file.bytes-per-checksum
Handling deprecation for dfs.datanode.slow.io.warning.threshold.ms
Handling deprecation for io.seqfile.lazydecompress
Handling deprecation for mapreduce.task.skip.start.attempts
Handling deprecation for dfs.namenode.reject-unresolved-dn-topology-mapping
Handling deprecation for hadoop.common.configuration.version
Handling deprecation for yarn.resourcemanager.client.thread-count
Handling deprecation for dfs.datanode.drop.cache.behind.reads
Handling deprecation for yarn.sharedcache.admin.address
Handling deprecation for mapreduce.job.output.value.class
Handling deprecation for mapreduce.output.fileoutputformat.outputdir
Handling deprecation for mapreduce.jobtracker.taskcache.levels
Handling deprecation for yarn.nodemanager.linux-container-executor.nonsecure-mode.user-pattern
Handling deprecation for yarn.resourcemanager.zk-timeout-ms
Handling deprecation for yarn.resourcemanager.max-completed-applications
Handling deprecation for mapreduce.job.jvm.numtasks
Handling deprecation for yarn.sharedcache.cleaner.period-mins
Handling deprecation for mapreduce.jobtracker.tasktracker.maxblacklists
Handling deprecation for dfs.namenode.top.num.users
Handling deprecation for yarn.nodemanager.linux-container-executor.cgroups.mount
Handling deprecation for yarn.sharedcache.checksum.algo.impl
Handling deprecation for mapreduce.job.end-notification.max.retry.interval
Handling deprecation for mapreduce.job.acl-view-job
Handling deprecation for mapreduce.job.classloader
Handling deprecation for yarn.log-aggregation-enable
Handling deprecation for mapreduce.reduce.shuffle.fetch.retry.interval-ms
Handling deprecation for yarn.resourcemanager.nodemanager.minimum.version
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.size
Handling deprecation for yarn.app.mapreduce.am.job.task.listener.thread-count
Handling deprecation for yarn.app.mapreduce.am.resource.cpu-vcores
Handling deprecation for dfs.namenode.edit.log.autoroll.check.interval.ms
Handling deprecation for mapreduce.output.fileoutputformat.compress.type
Handling deprecation for hadoop.hdfs.configuration.version
Handling deprecation for hadoop.security.group.mapping.ldap.search.attr.member
Handling deprecation for yarn.nodemanager.log.retain-seconds
Handling deprecation for yarn.nodemanager.local-cache.max-files-per-directory
Handling deprecation for mapreduce.job.end-notification.retry.interval
Handling deprecation for hadoop.ssl.client.conf
Handling deprecation for yarn.sharedcache.root-dir
Handling deprecation for dfs.journalnode.https-address
Handling deprecation for mapreduce.reduce.shuffle.fetch.retry.timeout-ms
Handling deprecation for dfs.bytes-per-checksum
Handling deprecation for dfs.namenode.max.objects
Handling deprecation for mapreduce.tasktracker.instrumentation
Handling deprecation for dfs.datanode.max.transfer.threads
Handling deprecation for dfs.block.access.key.update.interval
Handling deprecation for mapreduce.jobtracker.jobhistory.task.numberprogresssplits
Handling deprecation for mapreduce.map.memory.mb
Handling deprecation for ha.failover-controller.new-active.rpc-timeout.ms
Handling deprecation for hadoop.ssl.hostname.verifier
Handling deprecation for dfs.client.read.shortcircuit
Handling deprecation for dfs.datanode.hdfs-blocks-metadata.enabled
Handling deprecation for mapreduce.tasktracker.healthchecker.interval
Handling deprecation for dfs.image.transfer.chunksize
Handling deprecation for mapreduce.tasktracker.taskmemorymanager.monitoringinterval
Handling deprecation for dfs.client.https.keystore.resource
Handling deprecation for yarn.resourcemanager.connect.retry-interval.ms
Handling deprecation for yarn.timeline-service.webapp.address
Handling deprecation for s3native.blocksize
Handling deprecation for yarn.scheduler.minimum-allocation-mb
Handling deprecation for yarn.sharedcache.cleaner.resource-sleep-ms
Handling deprecation for net.topology.impl
Handling deprecation for dfs.client.failover.sleep.base.millis
Handling deprecation for dfs.permissions.superusergroup
Handling deprecation for io.seqfile.compress.blocksize
Handling deprecation for hadoop.registry.zk.retry.times
Handling deprecation for fs.AbstractFileSystem.ftp.impl
Handling deprecation for dfs.namenode.checkpoint.edits.dir
Handling deprecation for mapreduce.job.running.reduce.limit
Handling deprecation for dfs.blockreport.initialDelay
Handling deprecation for dfs.namenode.heartbeat.recheck-interval
Handling deprecation for dfs.namenode.safemode.extension
Handling deprecation for yarn.scheduler.maximum-allocation-mb
Handling deprecation for mapreduce.job.reduce.shuffle.consumer.plugin.class
Handling deprecation for yarn.nodemanager.vmem-check-enabled
Handling deprecation for mapreduce.task.io.sort.factor
Handling deprecation for mapreduce.jobtracker.persist.jobstatus.dir
Handling deprecation for dfs.client.failover.sleep.max.millis
Handling deprecation for dfs.namenode.delegation.key.update-interval
Handling deprecation for hadoop.rpc.protection
Handling deprecation for fs.permissions.umask-mode
Handling deprecation for fs.s3.sleepTimeSeconds
Handling deprecation for ha.health-monitor.rpc-timeout.ms
Handling deprecation for hadoop.http.staticuser.user
Handling deprecation for fs.s3a.connection.maximum
Handling deprecation for yarn.nodemanager.linux-container-executor.nonsecure-mode.limit-users
Handling deprecation for fs.s3a.paging.maximum
Handling deprecation for fs.AbstractFileSystem.viewfs.impl
Handling deprecation for fs.ftp.host
Handling deprecation for yarn.nodemanager.linux-container-executor.nonsecure-mode.local-user
Handling deprecation for fs.s3a.impl
Handling deprecation for hadoop.http.authentication.kerberos.keytab
Handling deprecation for dfs.namenode.fs-limits.max-blocks-per-file
Handling deprecation for mapreduce.tasktracker.http.threads
Handling deprecation for mapreduce.tasktracker.dns.nameserver
Handling deprecation for yarn.resourcemanager.am-rm-tokens.master-key-rolling-interval-secs
Handling deprecation for dfs.client.block.write.replace-datanode-on-failure.enable
Handling deprecation for io.compression.codec.bzip2.library
Handling deprecation for mapreduce.map.skip.maxrecords
Handling deprecation for dfs.client.use.legacy.blockreader.local
Handling deprecation for dfs.namenode.checkpoint.dir
Handling deprecation for dfs.namenode.top.windows.minutes
Handling deprecation for mapreduce.job.maxtaskfailures.per.tracker
Handling deprecation for net.topology.node.switch.mapping.impl
Handling deprecation for mapreduce.shuffle.max.connections
Handling deprecation for mapreduce.jobhistory.loadedjobs.cache.size
Handling deprecation for dfs.storage.policy.enabled
Handling deprecation for yarn.client.application-client-protocol.poll-interval-ms
Handling deprecation for yarn.nodemanager.localizer.address
Handling deprecation for dfs.namenode.list.cache.pools.num.responses
Handling deprecation for nfs.server.port
Handling deprecation for mapreduce.client.output.filter
Handling deprecation for yarn.timeline-service.client.best-effort
Handling deprecation for ha.zookeeper.parent-znode
Handling deprecation for mapreduce.jobtracker.persist.jobstatus.hours
Handling deprecation for yarn.sharedcache.admin.thread-count
Handling deprecation for yarn.nodemanager.resource.cpu-vcores
Handling deprecation for dfs.datanode.block-pinning.enabled
Handling deprecation for mapreduce.jobhistory.http.policy
Handling deprecation for yarn.resourcemanager.webapp.delegation-token-auth-filter.enabled
Handling deprecation for mapreduce.job.speculative.retry-after-no-speculate
Handling deprecation for fs.s3a.attempts.maximum
Handling deprecation for s3native.stream-buffer-size
Handling deprecation for io.seqfile.local.dir
Handling deprecation for yarn.log-aggregation.retain-check-interval-seconds
Handling deprecation for fs.s3n.multipart.copy.block.size
Handling deprecation for dfs.encrypt.data.transfer.cipher.key.bitlength
Handling deprecation for dfs.datanode.sync.behind.writes
Handling deprecation for yarn.resourcemanager.zk-acl
Handling deprecation for hadoop.ssl.keystores.factory.class
Handling deprecation for mapreduce.job.split.metainfo.maxsize
Handling deprecation for fs.s3.maxRetries
Handling deprecation for hadoop.security.random.device.file.path
Handling deprecation for yarn.client.nodemanager-connect.max-wait-ms
Handling deprecation for dfs.namenode.stale.datanode.interval
Handling deprecation for mapreduce.task.io.sort.mb
Handling deprecation for yarn.resourcemanager.zk-state-store.parent-path
Handling deprecation for yarn.app.mapreduce.client-am.ipc.max-retries
Handling deprecation for fs.client.resolve.remote.symlinks
Handling deprecation for yarn.nodemanager.linux-container-executor.cgroups.strict-resource-usage
Handling deprecation for hadoop.ssl.enabled.protocols
Handling deprecation for mapreduce.reduce.cpu.vcores
Handling deprecation for yarn.client.failover-retries
Handling deprecation for mapreduce.jobhistory.address
Handling deprecation for hadoop.ssl.enabled
Handling deprecation for dfs.replication.max
Handling deprecation for dfs.namenode.name.dir
Handling deprecation for dfs.datanode.https.address
Handling deprecation for ipc.client.kill.max
Handling deprecation for mapreduce.job.committer.setup.cleanup.needed
Handling deprecation for dfs.client.domain.socket.data.traffic
Handling deprecation for yarn.nodemanager.localizer.cache.target-size-mb
Handling deprecation for yarn.resourcemanager.admin.client.thread-count
Handling deprecation for dfs.block.access.token.enable
Handling deprecation for mapreduce.job.speculative.retry-after-speculate
Handling deprecation for dfs.datanode.address
Handling deprecation for mapreduce.jobtracker.restart.recover
Handling deprecation for ipc.client.connect.max.retries
Handling deprecation for yarn.timeline-service.store-class
Handling deprecation for dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
Handling deprecation for hadoop.tmp.dir
Handling deprecation for dfs.datanode.handler.count
Handling deprecation for yarn.resourcemanager.ha.automatic-failover.embedded
Handling deprecation for yarn.timeline-service.ttl-ms
Handling deprecation for mapreduce.task.profile.map.params
Handling deprecation for yarn.resourcemanager.nodemanagers.heartbeat-interval-ms
Handling deprecation for mapreduce.map.speculative
Handling deprecation for yarn.timeline-service.recovery.enabled
Handling deprecation for mapreduce.job.map.class
Handling deprecation for dfs.namenode.resource.checked.volumes.minimum
Handling deprecation for yarn.nodemanager.recovery.dir
Handling deprecation for mapreduce.job.counters.max
Handling deprecation for yarn.resourcemanager.keytab
Handling deprecation for dfs.namenode.max.extra.edits.segments.retained
Handling deprecation for dfs.webhdfs.user.provider.user.pattern
Handling deprecation for dfs.client.mmap.enabled
Handling deprecation for mapreduce.map.log.level
Handling deprecation for dfs.client.file-block-storage-locations.timeout.millis
Handling deprecation for yarn.client.max-cached-nodemanagers-proxies
Handling deprecation for yarn.app.mapreduce.am.scheduler.heartbeat.interval-ms
Handling deprecation for hadoop.fuse.timer.period
Handling deprecation for fs.trash.checkpoint.interval
Handling deprecation for yarn.sharedcache.app-checker.class
Handling deprecation for dfs.journalnode.http-address
Handling deprecation for yarn.app.mapreduce.am.staging-dir
Handling deprecation for mapreduce.tasktracker.local.dir.minspacestart
Handling deprecation for yarn.nm.liveness-monitor.expiry-interval-ms
Handling deprecation for ha.health-monitor.check-interval.ms
Handling deprecation for mapreduce.reduce.shuffle.merge.percent
Handling deprecation for dfs.namenode.retrycache.heap.percent
Handling deprecation for yarn.nodemanager.docker-container-executor.exec-name
Handling deprecation for ipc.client.connect.timeout
Handling deprecation for yarn.resourcemanager.fs.state-store.retry-interval-ms
Handling deprecation for mapreduce.output.fileoutputformat.compress
Handling deprecation for yarn.nodemanager.local-dirs
Handling deprecation for yarn.nodemanager.recovery.enabled
Handling deprecation for io.native.lib.available
Handling deprecation for yarn.sharedcache.store.in-memory.staleness-period-mins
Handling deprecation for yarn.resourcemanager.am.max-attempts
Handling deprecation for s3.replication
Handling deprecation for mapreduce.input.fileinputformat.inputdir
Handling deprecation for fs.AbstractFileSystem.har.impl
Handling deprecation for dfs.image.compress
Handling deprecation for mapreduce.job.running.map.limit
Handling deprecation for mapreduce.reduce.input.buffer.percent
Handling deprecation for yarn.nodemanager.webapp.address
Handling deprecation for dfs.datanode.available-space-volume-choosing-policy.balanced-space-preference-fraction
Handling deprecation for dfs.namenode.edit.log.autoroll.multiplier.threshold
Handling deprecation for hadoop.security.group.mapping.ldap.ssl
Handling deprecation for dfs.namenode.checkpoint.check.period
Handling deprecation for fs.defaultFS
Handling deprecation for fs.s3a.multipart.size
Handling deprecation for dfs.client.slow.io.warning.threshold.ms
Handling deprecation for yarn.app.mapreduce.am.job.committer.commit-window
Handling deprecation for hadoop.security.group.mapping.ldap.search.attr.group.name
Handling deprecation for yarn.nodemanager.disk-health-checker.max-disk-utilization-per-disk-percentage
Handling deprecation for yarn.nodemanager.container-monitor.procfs-tree.smaps-based-rss.enabled
Handling deprecation for mapreduce.job.submithostname
Handling deprecation for mapreduce.map.sort.spill.percent
Handling deprecation for hadoop.security.crypto.codec.classes.aes.ctr.nopadding
Handling deprecation for dfs.namenode.http-address
Handling deprecation for hadoop.security.groups.negative-cache.secs
Handling deprecation for hadoop.ssl.server.conf
Handling deprecation for mapreduce.ifile.readahead
Handling deprecation for s3native.replication
Handling deprecation for yarn.client.nodemanager-client-async.thread-pool-max-size
Handling deprecation for mapreduce.jobtracker.staging.root.dir
Handling deprecation for mapreduce.jobhistory.admin.address
Handling deprecation for dfs.namenode.startup.delay.block.deletion.sec
Handling deprecation for yarn.nodemanager.health-checker.interval-ms
Handling deprecation for dfs.namenode.checkpoint.max-retries
Handling deprecation for s3.stream-buffer-size
Handling deprecation for ftp.client-write-packet-size
Handling deprecation for dfs.datanode.fsdatasetcache.max.threads.per.volume
Handling deprecation for mapreduce.output.fileoutputformat.compress.codec
Handling deprecation for yarn.timeline-service.keytab
Handling deprecation for yarn.sharedcache.store.in-memory.initial-delay-mins
Handling deprecation for mapreduce.jobhistory.webapp.address
Handling deprecation for mapreduce.task.userlog.limit.kb
Handling deprecation for mapreduce.reduce.shuffle.fetch.retry.enabled
Handling deprecation for yarn.app.mapreduce.task.container.log.backups
Handling deprecation for dfs.heartbeat.interval
Handling deprecation for ha.zookeeper.session-timeout.ms
Handling deprecation for fs.s3a.connection.ssl.enabled
Handling deprecation for yarn.sharedcache.webapp.address
Handling deprecation for hadoop.http.authentication.signature.secret.file
Handling deprecation for hadoop.fuse.connection.timeout
Handling deprecation for mapreduce.input.fileinputformat.numinputfiles
Handling deprecation for yarn.nodemanager.log-aggregation.compression-type
Handling deprecation for ipc.server.max.connections
Handling deprecation for yarn.resourcemanager.work-preserving-recovery.scheduling-wait-ms
Handling deprecation for yarn.nodemanager.log-dirs
Handling deprecation for yarn.app.mapreduce.am.resource.mb
Handling deprecation for hadoop.security.groups.cache.secs
Handling deprecation for mapreduce.job.speculative.minimum-allowed-tasks
Handling deprecation for yarn.nodemanager.container-monitor.interval-ms
Handling deprecation for dfs.datanode.cache.revocation.timeout.ms
Handling deprecation for mapreduce.jobhistory.recovery.store.class
Handling deprecation for mapreduce.task.combine.progress.records
Handling deprecation for s3.client-write-packet-size
Handling deprecation for mapreduce.jobtracker.instrumentation
Handling deprecation for dfs.replication
Handling deprecation for mapreduce.shuffle.transfer.buffer.size
Handling deprecation for hadoop.security.group.mapping.ldap.directory.search.timeout
Handling deprecation for dfs.datanode.available-space-volume-choosing-policy.balanced-space-threshold
Handling deprecation for hadoop.work.around.non.threadsafe.getpwuid
Handling deprecation for yarn.app.mapreduce.client-am.ipc.max-retries-on-timeouts
Handling deprecation for yarn.nodemanager.address
Handling deprecation for mapreduce.tasktracker.taskcontroller
Handling deprecation for mapreduce.tasktracker.indexcache.mb
Handling deprecation for yarn.scheduler.maximum-allocation-vcores
Handling deprecation for mapreduce.job.reduces
Handling deprecation for yarn.nodemanager.sleep-delay-before-sigkill.ms
Handling deprecation for yarn.timeline-service.address
Handling deprecation for yarn.resourcemanager.configuration.provider-class
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.expiry
Handling deprecation for yarn.sharedcache.enabled
Handling deprecation for tfile.io.chunk.size
Handling deprecation for mapreduce.job.acl-modify-job
Handling deprecation for hadoop.registry.zk.session.timeout.ms
Handling deprecation for fs.automatic.close
Handling deprecation for ha.health-monitor.sleep-after-disconnect.ms
Handling deprecation for mapreduce.tasktracker.reduce.tasks.maximum
Handling deprecation for mapreduce.input.fileinputformat.list-status.num-threads
Handling deprecation for dfs.datanode.directoryscan.threads
Handling deprecation for dfs.datanode.directoryscan.interval
Handling deprecation for dfs.namenode.acls.enabled
Handling deprecation for dfs.client.short.circuit.replica.stale.threshold.ms
Handling deprecation for hadoop.http.authentication.token.validity
Handling deprecation for fs.s3.block.size
Handling deprecation for ha.failover-controller.graceful-fence.rpc-timeout.ms
Handling deprecation for mapreduce.tasktracker.local.dir.minspacekill
Handling deprecation for dfs.namenode.resource.du.reserved
Handling deprecation for mapreduce.jobhistory.cleaner.interval-ms
Handling deprecation for dfs.namenode.datanode.registration.ip-hostname-check
Handling deprecation for mapreduce.jobhistory.intermediate-done-dir
Handling deprecation for mapreduce.jobtracker.http.address
Handling deprecation for dfs.namenode.backup.http-address
Handling deprecation for dfs.namenode.edits.noeditlogchannelflush
Handling deprecation for mapreduce.reduce.shuffle.input.buffer.percent
Handling deprecation for mapreduce.map.maxattempts
Handling deprecation for yarn.http.policy
Handling deprecation for dfs.namenode.audit.loggers
Handling deprecation for hadoop.security.groups.cache.warn.after.ms
Handling deprecation for io.serializations
Handling deprecation for mapreduce.tasktracker.outofband.heartbeat
Handling deprecation for mapreduce.reduce.shuffle.read.timeout
Handling deprecation for hadoop.security.crypto.buffer.size
Handling deprecation for mapreduce.reduce.skip.proc.count.autoincr
Handling deprecation for mapreduce.ifile.readahead.bytes
Handling deprecation for dfs.http.policy
Handling deprecation for hadoop.registry.secure
Handling deprecation for dfs.namenode.safemode.min.datanodes
Handling deprecation for dfs.client.file-block-storage-locations.num-threads
Handling deprecation for mapreduce.cluster.local.dir
Handling deprecation for mapreduce.tasktracker.report.address
Handling deprecation for dfs.namenode.secondary.https-address
Handling deprecation for hadoop.kerberos.kinit.command
Handling deprecation for yarn.timeline-service.http-authentication.type
Handling deprecation for dfs.block.access.token.lifetime
Handling deprecation for dfs.webhdfs.enabled
Handling deprecation for dfs.namenode.delegation.token.max-lifetime
Handling deprecation for dfs.namenode.avoid.write.stale.datanode
Handling deprecation for dfs.datanode.drop.cache.behind.writes
Handling deprecation for yarn.log-aggregation.retain-seconds
Handling deprecation for mapreduce.job.complete.cancel.delegation.tokens
Handling deprecation for mapreduce.local.clientfactory.class.name
Handling deprecation for mapreduce.shuffle.connection-keep-alive.timeout
Handling deprecation for dfs.namenode.num.extra.edits.retained
Handling deprecation for yarn.scheduler.minimum-allocation-vcores
Handling deprecation for ipc.client.connect.max.retries.on.timeouts
Handling deprecation for yarn.timeline-service.client.retry-interval-ms
Handling deprecation for yarn.timeline-service.client.max-retries
Handling deprecation for fs.s3n.block.size
Handling deprecation for mapreduce.job.map.output.collector.class
Handling deprecation for ha.health-monitor.connect-retry-interval.ms
Handling deprecation for mapreduce.shuffle.max.threads
Handling deprecation for nfs.exports.allowed.hosts
Handling deprecation for dfs.client.mmap.cache.size
Handling deprecation for mapreduce.tasktracker.map.tasks.maximum
Handling deprecation for io.file.buffer.size
Handling deprecation for dfs.client.datanode-restart.timeout
Handling deprecation for io.mapfile.bloom.size
Handling deprecation for hadoop.security.kms.client.authentication.retry-count
Handling deprecation for dfs.namenode.checkpoint.txns
Handling deprecation for ipc.client.connect.retry.interval
Handling deprecation for dfs.client-write-packet-size
Handling deprecation for mapreduce.reduce.shuffle.connect.timeout
Handling deprecation for yarn.resourcemanager.fs.state-store.uri
Handling deprecation for fs.swift.impl
Handling deprecation for hadoop.registry.zk.connection.timeout.ms
Handling deprecation for mapred.queue.default.acl-administer-jobs
Handling deprecation for mapreduce.job.submithostaddress
Handling deprecation for dfs.cachereport.intervalMsec
Handling deprecation for yarn.app.mapreduce.shuffle.log.backups
Handling deprecation for yarn.app.mapreduce.am.container.log.limit.kb
Handling deprecation for yarn.nodemanager.resourcemanager.minimum.version
Handling deprecation for ftp.blocksize
Handling deprecation for yarn.resourcemanager.address
Handling deprecation for file.stream-buffer-size
Handling deprecation for yarn.resourcemanager.scheduler.monitor.enable
Handling deprecation for mapreduce.job.ubertask.maxreduces
Handling deprecation for nfs.allow.insecure.ports
Handling deprecation for yarn.sharedcache.nm.uploader.thread-count
Handling deprecation for ipc.client.idlethreshold
Handling deprecation for ftp.stream-buffer-size
Handling deprecation for yarn.sharedcache.client-server.address
Handling deprecation for dfs.client.failover.connection.retries.on.timeouts
Handling deprecation for dfs.namenode.replication.work.multiplier.per.iteration
Handling deprecation for hadoop.http.authentication.simple.anonymous.allowed
Handling deprecation for hadoop.security.authorization
Handling deprecation for yarn.client.nodemanager-connect.retry-interval-ms
Handling deprecation for yarn.am.liveness-monitor.expiry-interval-ms
Handling deprecation for fs.har.impl.disable.cache
Handling deprecation for yarn.nodemanager.linux-container-executor.resources-handler.class
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.read-cache-size
Handling deprecation for hadoop.security.authentication
Handling deprecation for dfs.image.compression.codec
Handling deprecation for mapreduce.task.files.preserve.failedtasks
Handling deprecation for dfs.client.read.shortcircuit.streams.cache.size
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.path
Handling deprecation for mapreduce.job.reduce.slowstart.completedmaps
Handling deprecation for mapreduce.jobhistory.minicluster.fixed.ports
Handling deprecation for file.replication
Handling deprecation for yarn.resourcemanager.ha.automatic-failover.enabled
Handling deprecation for mapreduce.job.userlog.retain.hours
Handling deprecation for mapreduce.jobhistory.joblist.cache.size
Handling deprecation for dfs.namenode.accesstime.precision
Handling deprecation for yarn.resourcemanager.work-preserving-recovery.enabled
Handling deprecation for dfs.namenode.fs-limits.max-xattrs-per-inode
Handling deprecation for io.mapfile.bloom.error.rate
Handling deprecation for yarn.resourcemanager.store.class
Handling deprecation for dfs.image.transfer.timeout
Handling deprecation for yarn.timeline-service.leveldb-state-store.path
Handling deprecation for nfs.wtmax
Handling deprecation for mapreduce.job.combine.class
Handling deprecation for dfs.namenode.support.allow.format
Handling deprecation for fs.s3a.multipart.purge
Handling deprecation for dfs.secondary.namenode.kerberos.internal.spnego.principal
Handling deprecation for fs.s3a.connection.establish.timeout
Handling deprecation for dfs.stream-buffer-size
Handling deprecation for dfs.namenode.invalidate.work.pct.per.iteration
Handling deprecation for yarn.nodemanager.container-executor.class
Handling deprecation for fs.s3a.multipart.purge.age
Handling deprecation for yarn.resourcemanager.scheduler.client.thread-count
Handling deprecation for dfs.namenode.top.enabled
Handling deprecation for yarn.app.mapreduce.shuffle.log.separate
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.low-watermark
Handling deprecation for fs.s3a.fast.buffer.size
Handling deprecation for hadoop.user.group.static.mapping.overrides
Handling deprecation for tfile.fs.input.buffer.size
Handling deprecation for dfs.client.cached.conn.retry
Handling deprecation for hadoop.http.authentication.type
Handling deprecation for dfs.namenode.list.encryption.zones.num.responses
Handling deprecation for mapreduce.map.cpu.vcores
Handling deprecation for dfs.namenode.path.based.cache.refresh.interval.ms
Handling deprecation for dfs.namenode.decommission.interval
Handling deprecation for dfs.namenode.fs-limits.max-directory-items
Handling deprecation for yarn.resourcemanager.zk-retry-interval-ms
Handling deprecation for ftp.bytes-per-checksum
Handling deprecation for dfs.ha.log-roll.period
Handling deprecation for dfs.user.home.dir.prefix
Handling deprecation for ipc.client.fallback-to-simple-auth-allowed
Handling deprecation for yarn.nodemanager.pmem-check-enabled
Handling deprecation for yarn.nodemanager.remote-app-log-dir
Handling deprecation for dfs.namenode.inotify.max.events.per.rpc
Handling deprecation for mapreduce.task.profile.maps
Handling deprecation for mapreduce.shuffle.ssl.file.buffer.size
Handling deprecation for mapreduce.tasktracker.healthchecker.script.timeout
Handling deprecation for yarn.timeline-service.webapp.https.address
Handling deprecation for yarn.nodemanager.resource.percentage-physical-cpu-limit
Handling deprecation for yarn.app.mapreduce.am.command-opts
Handling deprecation for dfs.namenode.fs-limits.max-xattr-size
Handling deprecation for dfs.datanode.http.address
Handling deprecation for dfs.namenode.blocks.per.postponedblocks.rescan
Handling deprecation for yarn.sharedcache.nm.uploader.replication.factor
Handling deprecation for hadoop.registry.zk.root
Handling deprecation for hadoop.jetty.logs.serve.aliases
Handling deprecation for yarn.client.failover-proxy-provider
Handling deprecation for mapreduce.jobhistory.admin.acl
Handling deprecation for yarn.app.mapreduce.am.hard-kill-timeout-ms
Handling deprecation for yarn.nodemanager.remote-app-log-dir-suffix
Handling deprecation for mapreduce.jobhistory.principal
Handling deprecation for yarn.resourcemanager.webapp.address
Handling deprecation for mapreduce.jobhistory.recovery.enable
Handling deprecation for yarn.sharedcache.store.in-memory.check-period-mins
Handling deprecation for nfs.mountd.port
Handling deprecation for mapreduce.reduce.merge.inmem.threshold
Handling deprecation for fs.df.interval
Handling deprecation for yarn.timeline-service.enabled
Handling deprecation for mapreduce.jobtracker.jobhistory.lru.cache.size
Handling deprecation for mapreduce.task.profile
Handling deprecation for mapreduce.job.output.key.class
Handling deprecation for yarn.nodemanager.hostname
Handling deprecation for dfs.namenode.num.checkpoints.retained
Handling deprecation for mapreduce.job.queuename
Handling deprecation for mapreduce.jobhistory.max-age-ms
Handling deprecation for mapreduce.job.token.tracking.ids.enabled
Handling deprecation for yarn.nodemanager.localizer.client.thread-count
Handling deprecation for yarn.sharedcache.uploader.server.thread-count
Handling deprecation for dfs.client.mmap.retry.timeout.ms
Handling deprecation for mapreduce.jobhistory.move.thread-count
Handling deprecation for dfs.permissions.enabled
Handling deprecation for dfs.blockreport.split.threshold
Handling deprecation for fs.AbstractFileSystem.hdfs.impl
Handling deprecation for dfs.datanode.balance.bandwidthPerSec
Handling deprecation for dfs.block.scanner.volume.bytes.per.second
Handling deprecation for hadoop.http.filter.initializers
Handling deprecation for yarn.timeline-service.http-authentication.simple.anonymous.allowed
Handling deprecation for dfs.default.chunk.view.size
Handling deprecation for yarn.sharedcache.client-server.thread-count
Handling deprecation for yarn.resourcemanager.resource-tracker.address
Handling deprecation for mapreduce.job.working.dir
Handling deprecation for mapreduce.jobhistory.datestring.cache.size
Handling deprecation for mapreduce.task.profile.params
Handling deprecation for dfs.namenode.decommission.blocks.per.interval
Handling deprecation for dfs.namenode.handler.count
Handling deprecation for dfs.image.transfer.bandwidthPerSec
Handling deprecation for rpc.metrics.quantile.enable
Handling deprecation for mapreduce.jobtracker.expire.trackers.interval
Handling deprecation for mapreduce.task.timeout
Handling deprecation for yarn.app.mapreduce.client.max-retries
Handling deprecation for yarn.nodemanager.resource.memory-mb
Handling deprecation for yarn.nodemanager.disk-health-checker.min-healthy-disks
Handling deprecation for dfs.datanode.failed.volumes.tolerated
Handling deprecation for yarn.timeline-service.handler-thread-count
Handling deprecation for ipc.server.listen.queue.size
Handling deprecation for fs.s3a.threads.max
Handling deprecation for yarn.resourcemanager.connect.max-wait.ms
Handling deprecation for mapreduce.fileoutputcommitter.algorithm.version
Handling deprecation for mapreduce.framework.name
Handling deprecation for mapreduce.map.skip.proc.count.autoincr
Handling deprecation for mapreduce.job.max.split.locations
Handling deprecation for yarn.resourcemanager.scheduler.class
Handling deprecation for yarn.resourcemanager.system-metrics-publisher.enabled
Handling deprecation for dfs.blocksize
Handling deprecation for yarn.sharedcache.nested-level
Handling deprecation for mapreduce.shuffle.connection-keep-alive.enable
Handling deprecation for fs.s3a.threads.keepalivetime
Handling deprecation for fs.s3a.connection.timeout
Handling deprecation for file.client-write-packet-size
Handling deprecation for ha.failover-controller.cli-check.rpc-timeout.ms
Handling deprecation for ha.zookeeper.acl
Handling deprecation for dfs.namenode.write.stale.datanode.ratio
Handling deprecation for dfs.encrypt.data.transfer
Handling deprecation for dfs.datanode.shared.file.descriptor.paths
Handling deprecation for mapreduce.input.lineinputformat.linespermap
Handling deprecation for yarn.resourcemanager.delayed.delegation-token.removal-interval-ms
Handling deprecation for yarn.nodemanager.localizer.fetch.thread-count
Handling deprecation for dfs.client.failover.max.attempts
Handling deprecation for yarn.resourcemanager.scheduler.address
Handling deprecation for dfs.client.read.shortcircuit.streams.cache.expiry.ms
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.start-time-write-cache-size
Handling deprecation for yarn.nodemanager.health-checker.script.timeout-ms
Handling deprecation for yarn.resourcemanager.fs.state-store.num-retries
Handling deprecation for hadoop.ssl.require.client.cert
Handling deprecation for hadoop.security.uid.cache.secs
Handling deprecation for mapreduce.jobhistory.keytab
Handling deprecation for dfs.client.read.shortcircuit.skip.checksum
Handling deprecation for yarn.resourcemanager.ha.automatic-failover.zk-base-path
Handling deprecation for mapreduce.shuffle.ssl.enabled
Handling deprecation for mapreduce.reduce.log.level
Handling deprecation for hadoop.registry.rm.enabled
Handling deprecation for mapreduce.tasktracker.dns.interface
Handling deprecation for yarn.resourcemanager.system-metrics-publisher.dispatcher.pool-size
Handling deprecation for mapreduce.job.speculative.speculative-cap-running-tasks
Handling deprecation for dfs.datanode.block.id.layout.upgrade.threads
Handling deprecation for dfs.datanode.use.datanode.hostname
Handling deprecation for dfs.client.context
Handling deprecation for yarn.resourcemanager.ha.enabled
Handling deprecation for mapred.reducer.new-api
Handling deprecation for dfs.namenode.delegation.token.renew-interval
Handling deprecation for dfs.blockreport.intervalMsec
Handling deprecation for fs.s3a.multipart.threshold
Handling deprecation for mapreduce.reduce.shuffle.memory.limit.percent
Handling deprecation for dfs.https.server.keystore.resource
Handling deprecation for io.map.index.skip
Handling deprecation for mapreduce.job.hdfs-servers
Handling deprecation for mapreduce.jobtracker.taskscheduler
Handling deprecation for dfs.namenode.kerberos.internal.spnego.principal
Handling deprecation for yarn.resourcemanager.state-store.max-completed-applications
Handling deprecation for mapreduce.map.output.compress
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.num.refill.threads
Handling deprecation for fs.s3n.multipart.uploads.block.size
Handling deprecation for mapreduce.task.merge.progress.records
Handling deprecation for dfs.datanode.dns.interface
Handling deprecation for map.sort.class
Handling deprecation for yarn.nodemanager.aux-services.mapreduce_shuffle.class
Handling deprecation for tfile.fs.output.buffer.size
Handling deprecation for fs.du.interval
Handling deprecation for dfs.client.failover.connection.retries
Handling deprecation for dfs.namenode.top.window.num.buckets
Handling deprecation for mapreduce.job.dir
Handling deprecation for fs.s3a.buffer.dir
Handling deprecation for mapreduce.reduce.shuffle.retry-delay.max.ms
Handling deprecation for yarn.sharedcache.uploader.server.address
Handling deprecation for mapreduce.client.progressmonitor.pollinterval
Handling deprecation for yarn.app.mapreduce.shuffle.log.limit.kb
Handling deprecation for dfs.datanode.max.locked.memory
Handling deprecation for dfs.namenode.retrycache.expirytime.millis
Handling deprecation for dfs.datanode.scan.period.hours
Handling deprecation for dfs.client.block.write.replace-datanode-on-failure.best-effort
Handling deprecation for mapreduce.jobhistory.move.interval-ms
Handling deprecation for dfs.ha.fencing.ssh.connect-timeout
Handling deprecation for yarn.nodemanager.log-aggregation.roll-monitoring-interval-seconds
Handling deprecation for dfs.namenode.fs-limits.max-component-length
Handling deprecation for hadoop.registry.zk.quorum
Handling deprecation for dfs.namenode.enable.retrycache
Handling deprecation for dfs.datanode.du.reserved
Handling deprecation for yarn.timeline-service.state-store-class
Handling deprecation for dfs.datanode.ipc.address
Handling deprecation for hadoop.registry.system.acls
Handling deprecation for dfs.client.block.write.replace-datanode-on-failure.policy
Handling deprecation for dfs.namenode.path.based.cache.retry.interval.ms
Handling deprecation for hadoop.security.crypto.cipher.suite
Handling deprecation for dfs.ha.tail-edits.period
Handling deprecation for mapreduce.task.profile.reduce.params
Handling deprecation for hadoop.registry.jaas.context
Handling deprecation for yarn.resourcemanager.hostname
Handling deprecation for mapreduce.reduce.memory.mb
Handling deprecation for hadoop.security.group.mapping.ldap.search.filter.group
Handling deprecation for hadoop.http.authentication.kerberos.principal
Handling deprecation for hadoop.security.group.mapping.ldap.search.filter.user
Handling deprecation for yarn.nodemanager.disk-health-checker.min-free-space-per-disk-mb
Handling deprecation for dfs.namenode.edits.dir
Handling deprecation for yarn.client.failover-retries-on-socket-timeouts
Handling deprecation for dfs.namenode.decommission.max.concurrent.tracked.nodes
Handling deprecation for mapreduce.client.completion.pollinterval
Handling deprecation for dfs.namenode.name.dir.restore
Handling deprecation for dfs.namenode.secondary.http-address
Handling deprecation for mapreduce.jobhistory.recovery.store.leveldb.path
Handling deprecation for yarn.sharedcache.store.class
Handling deprecation for s3.bytes-per-checksum
Handling deprecation for yarn.nodemanager.windows-container.cpu-limit.enabled
Handling deprecation for yarn.resourcemanager.webapp.https.address
Handling deprecation for yarn.nodemanager.vmem-pmem-ratio
Handling deprecation for dfs.namenode.checkpoint.period
Handling deprecation for dfs.ha.automatic-failover.enabled
Submitting tokens for job: job_local343739539_0002
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.fs.FileContext.getAbstractFileSystem(FileContext.java:331)
Handling deprecation for all properties in config...
Handling deprecation for mapreduce.jobtracker.address
Handling deprecation for yarn.resourcemanager.scheduler.monitor.policies
Handling deprecation for dfs.namenode.resource.check.interval
Handling deprecation for mapreduce.jobhistory.client.thread-count
Handling deprecation for yarn.app.mapreduce.am.containerlauncher.threadpool-initial-size
Handling deprecation for mapred.child.java.opts
Handling deprecation for mapreduce.jobtracker.retiredjobs.cache.size
Handling deprecation for dfs.client.https.need-auth
Handling deprecation for yarn.admin.acl
Handling deprecation for yarn.app.mapreduce.am.job.committer.cancel-timeout
Handling deprecation for mapreduce.job.emit-timeline-data
Handling deprecation for fs.ftp.host.port
Handling deprecation for dfs.namenode.avoid.read.stale.datanode
Handling deprecation for dfs.journalnode.rpc-address
Handling deprecation for mapreduce.job.end-notification.retry.attempts
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.ttl-interval-ms
Handling deprecation for yarn.resourcemanager.leveldb-state-store.path
Handling deprecation for mapred.mapper.new-api
Handling deprecation for yarn.ipc.rpc.class
Handling deprecation for ipc.client.connection.maxidletime
Handling deprecation for yarn.nodemanager.process-kill-wait.ms
Handling deprecation for mapreduce.cluster.acls.enabled
Handling deprecation for mapreduce.jobtracker.handler.count
Handling deprecation for io.map.index.interval
Handling deprecation for dfs.namenode.https-address
Handling deprecation for mapreduce.task.profile.reduces
Handling deprecation for fs.s3n.multipart.uploads.enabled
Handling deprecation for io.seqfile.sorter.recordlimit
Handling deprecation for mapreduce.job.ubertask.maxmaps
Handling deprecation for mapreduce.tasktracker.tasks.sleeptimebeforesigkill
Handling deprecation for hadoop.util.hash.type
Handling deprecation for dfs.namenode.replication.min
Handling deprecation for yarn.nodemanager.container-manager.thread-count
Handling deprecation for mapreduce.jobtracker.jobhistory.block.size
Handling deprecation for dfs.namenode.fs-limits.min-block-size
Handling deprecation for mapreduce.app-submission.cross-platform
Handling deprecation for fs.AbstractFileSystem.file.impl
Handling deprecation for net.topology.script.number.args
Handling deprecation for yarn.resourcemanager.container-tokens.master-key-rolling-interval-secs
Handling deprecation for mapreduce.map.output.compress.codec
Handling deprecation for mapreduce.job.reducer.preempt.delay.sec
Handling deprecation for s3native.bytes-per-checksum
Handling deprecation for dfs.namenode.path.based.cache.block.map.allocation.percent
Handling deprecation for yarn.nodemanager.windows-container.memory-limit.enabled
Handling deprecation for mapreduce.input.fileinputformat.split.minsize
Handling deprecation for hadoop.security.group.mapping
Handling deprecation for mapreduce.jobtracker.system.dir
Handling deprecation for mapreduce.job.end-notification.max.attempts
Handling deprecation for mapreduce.reduce.markreset.buffer.percent
Handling deprecation for dfs.datanode.cache.revocation.polling.ms
Handling deprecation for mapreduce.reduce.speculative
Handling deprecation for yarn.nodemanager.localizer.cache.cleanup.interval-ms
Handling deprecation for dfs.namenode.lazypersist.file.scrub.interval.sec
Handling deprecation for fs.s3a.threads.core
Handling deprecation for mapreduce.jobhistory.recovery.store.fs.uri
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.start-time-read-cache-size
Handling deprecation for hadoop.registry.zk.retry.interval.ms
Handling deprecation for yarn.nodemanager.keytab
Handling deprecation for dfs.namenode.replication.interval
Handling deprecation for yarn.resourcemanager.admin.address
Handling deprecation for mapreduce.job.maps
Handling deprecation for nfs.dump.dir
Handling deprecation for mapreduce.job.user.name
Handling deprecation for mapreduce.jobtracker.maxtasks.perjob
Handling deprecation for mapreduce.job.ubertask.enable
Handling deprecation for mapreduce.job.reduce.class
Handling deprecation for yarn.nodemanager.delete.debug-delay-sec
Handling deprecation for yarn.timeline-service.ttl-enable
Handling deprecation for yarn.resourcemanager.fs.state-store.retry-policy-spec
Handling deprecation for mapreduce.reduce.skip.maxgroups
Handling deprecation for dfs.client.use.datanode.hostname
Handling deprecation for fs.trash.interval
Handling deprecation for mapreduce.job.name
Handling deprecation for mapreduce.am.max-attempts
Handling deprecation for mapreduce.jobtracker.heartbeats.in.second
Handling deprecation for yarn.resourcemanager.zk-num-retries
Handling deprecation for s3.blocksize
Handling deprecation for dfs.datanode.data.dir
Handling deprecation for mapreduce.jobtracker.persist.jobstatus.active
Handling deprecation for mapreduce.reduce.shuffle.parallelcopies
Handling deprecation for fs.s3.buffer.dir
Handling deprecation for mapreduce.jobhistory.done-dir
Handling deprecation for hadoop.security.instrumentation.requires.admin
Handling deprecation for hadoop.registry.zk.retry.ceiling.ms
Handling deprecation for nfs.rtmax
Handling deprecation for dfs.datanode.data.dir.perm
Handling deprecation for yarn.resourcemanager.container.liveness-monitor.interval-ms
Handling deprecation for yarn.nodemanager.env-whitelist
Handling deprecation for dfs.namenode.backup.address
Handling deprecation for dfs.namenode.xattrs.enabled
Handling deprecation for dfs.datanode.readahead.bytes
Handling deprecation for mapreduce.jobhistory.cleaner.enable
Handling deprecation for dfs.client.block.write.retries
Handling deprecation for mapreduce.tasktracker.http.address
Handling deprecation for yarn.nodemanager.linux-container-executor.cgroups.hierarchy
Handling deprecation for ha.failover-controller.graceful-fence.connection.retries
Handling deprecation for yarn.resourcemanager.recovery.enabled
Handling deprecation for yarn.app.mapreduce.am.container.log.backups
Handling deprecation for dfs.namenode.safemode.threshold-pct
Handling deprecation for yarn.nodemanager.disk-health-checker.interval-ms
Handling deprecation for hadoop.security.java.secure.random.algorithm
Handling deprecation for dfs.namenode.list.cache.directives.num.responses
Handling deprecation for dfs.datanode.dns.nameserver
Handling deprecation for mapreduce.cluster.temp.dir
Handling deprecation for fs.s3a.max.total.tasks
Handling deprecation for mapreduce.reduce.maxattempts
Handling deprecation for mapreduce.client.submit.file.replication
Handling deprecation for mapreduce.shuffle.port
Handling deprecation for yarn.resourcemanager.resource-tracker.client.thread-count
Handling deprecation for dfs.namenode.replication.considerLoad
Handling deprecation for dfs.namenode.edits.journal-plugin.qjournal
Handling deprecation for dfs.client.write.exclude.nodes.cache.expiry.interval.millis
Handling deprecation for yarn.nodemanager.delete.thread-count
Handling deprecation for dfs.client.mmap.cache.timeout.ms
Handling deprecation for yarn.nodemanager.admin-env
Handling deprecation for io.skip.checksum.errors
Handling deprecation for yarn.timeline-service.hostname
Handling deprecation for yarn.resourcemanager.proxy-user-privileges.enabled
Handling deprecation for mapreduce.job.speculative.speculative-cap-total-tasks
Handling deprecation for yarn.acl.enable
Handling deprecation for fs.s3a.fast.upload
Handling deprecation for file.blocksize
Handling deprecation for mapreduce.job.speculative.slowtaskthreshold
Handling deprecation for ftp.replication
Handling deprecation for yarn.sharedcache.cleaner.initial-delay-mins
Handling deprecation for s3native.client-write-packet-size
Handling deprecation for hadoop.rpc.socket.factory.class.default
Handling deprecation for file.bytes-per-checksum
Handling deprecation for dfs.datanode.slow.io.warning.threshold.ms
Handling deprecation for io.seqfile.lazydecompress
Handling deprecation for mapreduce.task.skip.start.attempts
Handling deprecation for dfs.namenode.reject-unresolved-dn-topology-mapping
Handling deprecation for hadoop.common.configuration.version
Handling deprecation for yarn.resourcemanager.client.thread-count
Handling deprecation for dfs.datanode.drop.cache.behind.reads
Handling deprecation for yarn.sharedcache.admin.address
Handling deprecation for mapreduce.job.output.value.class
Handling deprecation for mapreduce.output.fileoutputformat.outputdir
Handling deprecation for mapreduce.jobtracker.taskcache.levels
Handling deprecation for yarn.nodemanager.linux-container-executor.nonsecure-mode.user-pattern
Handling deprecation for yarn.resourcemanager.zk-timeout-ms
Handling deprecation for yarn.resourcemanager.max-completed-applications
Handling deprecation for mapreduce.job.jvm.numtasks
Handling deprecation for yarn.sharedcache.cleaner.period-mins
Handling deprecation for mapreduce.jobtracker.tasktracker.maxblacklists
Handling deprecation for dfs.namenode.top.num.users
Handling deprecation for yarn.nodemanager.linux-container-executor.cgroups.mount
Handling deprecation for yarn.sharedcache.checksum.algo.impl
Handling deprecation for mapreduce.job.end-notification.max.retry.interval
Handling deprecation for mapreduce.job.acl-view-job
Handling deprecation for mapreduce.job.classloader
Handling deprecation for yarn.log-aggregation-enable
Handling deprecation for mapreduce.reduce.shuffle.fetch.retry.interval-ms
Handling deprecation for yarn.resourcemanager.nodemanager.minimum.version
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.size
Handling deprecation for yarn.app.mapreduce.am.job.task.listener.thread-count
Handling deprecation for yarn.app.mapreduce.am.resource.cpu-vcores
Handling deprecation for dfs.namenode.edit.log.autoroll.check.interval.ms
Handling deprecation for mapreduce.output.fileoutputformat.compress.type
Handling deprecation for hadoop.hdfs.configuration.version
Handling deprecation for hadoop.security.group.mapping.ldap.search.attr.member
Handling deprecation for yarn.nodemanager.log.retain-seconds
Handling deprecation for yarn.nodemanager.local-cache.max-files-per-directory
Handling deprecation for mapreduce.job.end-notification.retry.interval
Handling deprecation for hadoop.ssl.client.conf
Handling deprecation for yarn.sharedcache.root-dir
Handling deprecation for dfs.journalnode.https-address
Handling deprecation for mapreduce.reduce.shuffle.fetch.retry.timeout-ms
Handling deprecation for dfs.bytes-per-checksum
Handling deprecation for dfs.namenode.max.objects
Handling deprecation for mapreduce.tasktracker.instrumentation
Handling deprecation for dfs.datanode.max.transfer.threads
Handling deprecation for dfs.block.access.key.update.interval
Handling deprecation for mapreduce.jobtracker.jobhistory.task.numberprogresssplits
Handling deprecation for mapreduce.map.memory.mb
Handling deprecation for ha.failover-controller.new-active.rpc-timeout.ms
Handling deprecation for hadoop.ssl.hostname.verifier
Handling deprecation for dfs.client.read.shortcircuit
Handling deprecation for dfs.datanode.hdfs-blocks-metadata.enabled
Handling deprecation for mapreduce.tasktracker.healthchecker.interval
Handling deprecation for dfs.image.transfer.chunksize
Handling deprecation for mapreduce.tasktracker.taskmemorymanager.monitoringinterval
Handling deprecation for dfs.client.https.keystore.resource
Handling deprecation for yarn.resourcemanager.connect.retry-interval.ms
Handling deprecation for yarn.timeline-service.webapp.address
Handling deprecation for s3native.blocksize
Handling deprecation for yarn.scheduler.minimum-allocation-mb
Handling deprecation for yarn.sharedcache.cleaner.resource-sleep-ms
Handling deprecation for net.topology.impl
Handling deprecation for dfs.client.failover.sleep.base.millis
Handling deprecation for dfs.permissions.superusergroup
Handling deprecation for io.seqfile.compress.blocksize
Handling deprecation for hadoop.registry.zk.retry.times
Handling deprecation for fs.AbstractFileSystem.ftp.impl
Handling deprecation for dfs.namenode.checkpoint.edits.dir
Handling deprecation for mapreduce.job.running.reduce.limit
Handling deprecation for dfs.blockreport.initialDelay
Handling deprecation for dfs.namenode.heartbeat.recheck-interval
Handling deprecation for dfs.namenode.safemode.extension
Handling deprecation for yarn.scheduler.maximum-allocation-mb
Handling deprecation for mapreduce.job.reduce.shuffle.consumer.plugin.class
Handling deprecation for yarn.nodemanager.vmem-check-enabled
Handling deprecation for mapreduce.task.io.sort.factor
Handling deprecation for mapreduce.jobtracker.persist.jobstatus.dir
Handling deprecation for dfs.client.failover.sleep.max.millis
Handling deprecation for dfs.namenode.delegation.key.update-interval
Handling deprecation for hadoop.rpc.protection
Handling deprecation for fs.permissions.umask-mode
Handling deprecation for fs.s3.sleepTimeSeconds
Handling deprecation for ha.health-monitor.rpc-timeout.ms
Handling deprecation for hadoop.http.staticuser.user
Handling deprecation for fs.s3a.connection.maximum
Handling deprecation for yarn.nodemanager.linux-container-executor.nonsecure-mode.limit-users
Handling deprecation for fs.s3a.paging.maximum
Handling deprecation for fs.AbstractFileSystem.viewfs.impl
Handling deprecation for fs.ftp.host
Handling deprecation for yarn.nodemanager.linux-container-executor.nonsecure-mode.local-user
Handling deprecation for fs.s3a.impl
Handling deprecation for hadoop.http.authentication.kerberos.keytab
Handling deprecation for dfs.namenode.fs-limits.max-blocks-per-file
Handling deprecation for mapreduce.tasktracker.http.threads
Handling deprecation for mapreduce.tasktracker.dns.nameserver
Handling deprecation for yarn.resourcemanager.am-rm-tokens.master-key-rolling-interval-secs
Handling deprecation for dfs.client.block.write.replace-datanode-on-failure.enable
Handling deprecation for io.compression.codec.bzip2.library
Handling deprecation for mapreduce.map.skip.maxrecords
Handling deprecation for dfs.client.use.legacy.blockreader.local
Handling deprecation for dfs.namenode.checkpoint.dir
Handling deprecation for dfs.namenode.top.windows.minutes
Handling deprecation for mapreduce.job.maxtaskfailures.per.tracker
Handling deprecation for net.topology.node.switch.mapping.impl
Handling deprecation for mapreduce.shuffle.max.connections
Handling deprecation for mapreduce.jobhistory.loadedjobs.cache.size
Handling deprecation for dfs.storage.policy.enabled
Handling deprecation for yarn.client.application-client-protocol.poll-interval-ms
Handling deprecation for yarn.nodemanager.localizer.address
Handling deprecation for dfs.namenode.list.cache.pools.num.responses
Handling deprecation for nfs.server.port
Handling deprecation for mapreduce.client.output.filter
Handling deprecation for yarn.timeline-service.client.best-effort
Handling deprecation for ha.zookeeper.parent-znode
Handling deprecation for mapreduce.jobtracker.persist.jobstatus.hours
Handling deprecation for yarn.sharedcache.admin.thread-count
Handling deprecation for yarn.nodemanager.resource.cpu-vcores
Handling deprecation for dfs.datanode.block-pinning.enabled
Handling deprecation for mapreduce.jobhistory.http.policy
Handling deprecation for yarn.resourcemanager.webapp.delegation-token-auth-filter.enabled
Handling deprecation for mapreduce.job.speculative.retry-after-no-speculate
Handling deprecation for fs.s3a.attempts.maximum
Handling deprecation for s3native.stream-buffer-size
Handling deprecation for io.seqfile.local.dir
Handling deprecation for yarn.log-aggregation.retain-check-interval-seconds
Handling deprecation for fs.s3n.multipart.copy.block.size
Handling deprecation for dfs.encrypt.data.transfer.cipher.key.bitlength
Handling deprecation for dfs.datanode.sync.behind.writes
Handling deprecation for yarn.resourcemanager.zk-acl
Handling deprecation for hadoop.ssl.keystores.factory.class
Handling deprecation for mapreduce.job.split.metainfo.maxsize
Handling deprecation for fs.s3.maxRetries
Handling deprecation for hadoop.security.random.device.file.path
Handling deprecation for yarn.client.nodemanager-connect.max-wait-ms
Handling deprecation for dfs.namenode.stale.datanode.interval
Handling deprecation for mapreduce.task.io.sort.mb
Handling deprecation for yarn.resourcemanager.zk-state-store.parent-path
Handling deprecation for yarn.app.mapreduce.client-am.ipc.max-retries
Handling deprecation for fs.client.resolve.remote.symlinks
Handling deprecation for yarn.nodemanager.linux-container-executor.cgroups.strict-resource-usage
Handling deprecation for hadoop.ssl.enabled.protocols
Handling deprecation for mapreduce.reduce.cpu.vcores
Handling deprecation for yarn.client.failover-retries
Handling deprecation for mapreduce.jobhistory.address
Handling deprecation for hadoop.ssl.enabled
Handling deprecation for dfs.replication.max
Handling deprecation for dfs.namenode.name.dir
Handling deprecation for dfs.datanode.https.address
Handling deprecation for ipc.client.kill.max
Handling deprecation for mapreduce.job.committer.setup.cleanup.needed
Handling deprecation for dfs.client.domain.socket.data.traffic
Handling deprecation for yarn.nodemanager.localizer.cache.target-size-mb
Handling deprecation for yarn.resourcemanager.admin.client.thread-count
Handling deprecation for dfs.block.access.token.enable
Handling deprecation for mapreduce.job.speculative.retry-after-speculate
Handling deprecation for dfs.datanode.address
Handling deprecation for mapreduce.jobtracker.restart.recover
Handling deprecation for ipc.client.connect.max.retries
Handling deprecation for yarn.timeline-service.store-class
Handling deprecation for dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
Handling deprecation for hadoop.tmp.dir
Handling deprecation for dfs.datanode.handler.count
Handling deprecation for yarn.resourcemanager.ha.automatic-failover.embedded
Handling deprecation for yarn.timeline-service.ttl-ms
Handling deprecation for mapreduce.task.profile.map.params
Handling deprecation for yarn.resourcemanager.nodemanagers.heartbeat-interval-ms
Handling deprecation for mapreduce.map.speculative
Handling deprecation for yarn.timeline-service.recovery.enabled
Handling deprecation for mapreduce.job.map.class
Handling deprecation for dfs.namenode.resource.checked.volumes.minimum
Handling deprecation for yarn.nodemanager.recovery.dir
Handling deprecation for mapreduce.job.counters.max
Handling deprecation for yarn.resourcemanager.keytab
Handling deprecation for dfs.namenode.max.extra.edits.segments.retained
Handling deprecation for dfs.webhdfs.user.provider.user.pattern
Handling deprecation for dfs.client.mmap.enabled
Handling deprecation for mapreduce.map.log.level
Handling deprecation for dfs.client.file-block-storage-locations.timeout.millis
Handling deprecation for yarn.client.max-cached-nodemanagers-proxies
Handling deprecation for yarn.app.mapreduce.am.scheduler.heartbeat.interval-ms
Handling deprecation for hadoop.fuse.timer.period
Handling deprecation for fs.trash.checkpoint.interval
Handling deprecation for yarn.sharedcache.app-checker.class
Handling deprecation for dfs.journalnode.http-address
Handling deprecation for yarn.app.mapreduce.am.staging-dir
Handling deprecation for mapreduce.tasktracker.local.dir.minspacestart
Handling deprecation for yarn.nm.liveness-monitor.expiry-interval-ms
Handling deprecation for ha.health-monitor.check-interval.ms
Handling deprecation for mapreduce.reduce.shuffle.merge.percent
Handling deprecation for dfs.namenode.retrycache.heap.percent
Handling deprecation for yarn.nodemanager.docker-container-executor.exec-name
Handling deprecation for ipc.client.connect.timeout
Handling deprecation for yarn.resourcemanager.fs.state-store.retry-interval-ms
Handling deprecation for mapreduce.output.fileoutputformat.compress
Handling deprecation for yarn.nodemanager.local-dirs
Handling deprecation for yarn.nodemanager.recovery.enabled
Handling deprecation for io.native.lib.available
Handling deprecation for yarn.sharedcache.store.in-memory.staleness-period-mins
Handling deprecation for yarn.resourcemanager.am.max-attempts
Handling deprecation for s3.replication
Handling deprecation for mapreduce.input.fileinputformat.inputdir
Handling deprecation for fs.AbstractFileSystem.har.impl
Handling deprecation for dfs.image.compress
Handling deprecation for mapreduce.job.running.map.limit
Handling deprecation for mapreduce.reduce.input.buffer.percent
Handling deprecation for yarn.nodemanager.webapp.address
Handling deprecation for dfs.datanode.available-space-volume-choosing-policy.balanced-space-preference-fraction
Handling deprecation for dfs.namenode.edit.log.autoroll.multiplier.threshold
Handling deprecation for hadoop.security.group.mapping.ldap.ssl
Handling deprecation for dfs.namenode.checkpoint.check.period
Handling deprecation for fs.defaultFS
Handling deprecation for fs.s3a.multipart.size
Handling deprecation for dfs.client.slow.io.warning.threshold.ms
Handling deprecation for yarn.app.mapreduce.am.job.committer.commit-window
Handling deprecation for hadoop.security.group.mapping.ldap.search.attr.group.name
Handling deprecation for yarn.nodemanager.disk-health-checker.max-disk-utilization-per-disk-percentage
Handling deprecation for yarn.nodemanager.container-monitor.procfs-tree.smaps-based-rss.enabled
Handling deprecation for mapreduce.job.submithostname
Handling deprecation for mapreduce.map.sort.spill.percent
Handling deprecation for hadoop.security.crypto.codec.classes.aes.ctr.nopadding
Handling deprecation for dfs.namenode.http-address
Handling deprecation for hadoop.security.groups.negative-cache.secs
Handling deprecation for hadoop.ssl.server.conf
Handling deprecation for mapreduce.ifile.readahead
Handling deprecation for s3native.replication
Handling deprecation for yarn.client.nodemanager-client-async.thread-pool-max-size
Handling deprecation for mapreduce.jobtracker.staging.root.dir
Handling deprecation for mapreduce.jobhistory.admin.address
Handling deprecation for dfs.namenode.startup.delay.block.deletion.sec
Handling deprecation for yarn.nodemanager.health-checker.interval-ms
Handling deprecation for dfs.namenode.checkpoint.max-retries
Handling deprecation for s3.stream-buffer-size
Handling deprecation for ftp.client-write-packet-size
Handling deprecation for dfs.datanode.fsdatasetcache.max.threads.per.volume
Handling deprecation for mapreduce.output.fileoutputformat.compress.codec
Handling deprecation for yarn.timeline-service.keytab
Handling deprecation for yarn.sharedcache.store.in-memory.initial-delay-mins
Handling deprecation for mapreduce.jobhistory.webapp.address
Handling deprecation for mapreduce.task.userlog.limit.kb
Handling deprecation for mapreduce.reduce.shuffle.fetch.retry.enabled
Handling deprecation for yarn.app.mapreduce.task.container.log.backups
Handling deprecation for dfs.heartbeat.interval
Handling deprecation for ha.zookeeper.session-timeout.ms
Handling deprecation for fs.s3a.connection.ssl.enabled
Handling deprecation for yarn.sharedcache.webapp.address
Handling deprecation for hadoop.http.authentication.signature.secret.file
Handling deprecation for hadoop.fuse.connection.timeout
Handling deprecation for mapreduce.input.fileinputformat.numinputfiles
Handling deprecation for yarn.nodemanager.log-aggregation.compression-type
Handling deprecation for ipc.server.max.connections
Handling deprecation for yarn.resourcemanager.work-preserving-recovery.scheduling-wait-ms
Handling deprecation for yarn.nodemanager.log-dirs
Handling deprecation for yarn.app.mapreduce.am.resource.mb
Handling deprecation for hadoop.security.groups.cache.secs
Handling deprecation for mapreduce.job.speculative.minimum-allowed-tasks
Handling deprecation for yarn.nodemanager.container-monitor.interval-ms
Handling deprecation for dfs.datanode.cache.revocation.timeout.ms
Handling deprecation for mapreduce.jobhistory.recovery.store.class
Handling deprecation for mapreduce.task.combine.progress.records
Handling deprecation for s3.client-write-packet-size
Handling deprecation for mapreduce.jobtracker.instrumentation
Handling deprecation for dfs.replication
Handling deprecation for mapreduce.shuffle.transfer.buffer.size
Handling deprecation for hadoop.security.group.mapping.ldap.directory.search.timeout
Handling deprecation for dfs.datanode.available-space-volume-choosing-policy.balanced-space-threshold
Handling deprecation for hadoop.work.around.non.threadsafe.getpwuid
Handling deprecation for yarn.app.mapreduce.client-am.ipc.max-retries-on-timeouts
Handling deprecation for yarn.nodemanager.address
Handling deprecation for mapreduce.tasktracker.taskcontroller
Handling deprecation for mapreduce.tasktracker.indexcache.mb
Handling deprecation for yarn.scheduler.maximum-allocation-vcores
Handling deprecation for mapreduce.job.reduces
Handling deprecation for yarn.nodemanager.sleep-delay-before-sigkill.ms
Handling deprecation for yarn.timeline-service.address
Handling deprecation for yarn.resourcemanager.configuration.provider-class
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.expiry
Handling deprecation for yarn.sharedcache.enabled
Handling deprecation for tfile.io.chunk.size
Handling deprecation for mapreduce.job.acl-modify-job
Handling deprecation for hadoop.registry.zk.session.timeout.ms
Handling deprecation for fs.automatic.close
Handling deprecation for ha.health-monitor.sleep-after-disconnect.ms
Handling deprecation for mapreduce.tasktracker.reduce.tasks.maximum
Handling deprecation for mapreduce.input.fileinputformat.list-status.num-threads
Handling deprecation for dfs.datanode.directoryscan.threads
Handling deprecation for dfs.datanode.directoryscan.interval
Handling deprecation for dfs.namenode.acls.enabled
Handling deprecation for dfs.client.short.circuit.replica.stale.threshold.ms
Handling deprecation for hadoop.http.authentication.token.validity
Handling deprecation for fs.s3.block.size
Handling deprecation for ha.failover-controller.graceful-fence.rpc-timeout.ms
Handling deprecation for mapreduce.tasktracker.local.dir.minspacekill
Handling deprecation for dfs.namenode.resource.du.reserved
Handling deprecation for mapreduce.jobhistory.cleaner.interval-ms
Handling deprecation for dfs.namenode.datanode.registration.ip-hostname-check
Handling deprecation for mapreduce.jobhistory.intermediate-done-dir
Handling deprecation for mapreduce.jobtracker.http.address
Handling deprecation for dfs.namenode.backup.http-address
Handling deprecation for dfs.namenode.edits.noeditlogchannelflush
Handling deprecation for mapreduce.reduce.shuffle.input.buffer.percent
Handling deprecation for mapreduce.map.maxattempts
Handling deprecation for yarn.http.policy
Handling deprecation for dfs.namenode.audit.loggers
Handling deprecation for hadoop.security.groups.cache.warn.after.ms
Handling deprecation for io.serializations
Handling deprecation for mapreduce.tasktracker.outofband.heartbeat
Handling deprecation for mapreduce.reduce.shuffle.read.timeout
Handling deprecation for hadoop.security.crypto.buffer.size
Handling deprecation for mapreduce.reduce.skip.proc.count.autoincr
Handling deprecation for mapreduce.ifile.readahead.bytes
Handling deprecation for dfs.http.policy
Handling deprecation for hadoop.registry.secure
Handling deprecation for dfs.namenode.safemode.min.datanodes
Handling deprecation for dfs.client.file-block-storage-locations.num-threads
Handling deprecation for mapreduce.cluster.local.dir
Handling deprecation for mapreduce.tasktracker.report.address
Handling deprecation for dfs.namenode.secondary.https-address
Handling deprecation for hadoop.kerberos.kinit.command
Handling deprecation for yarn.timeline-service.http-authentication.type
Handling deprecation for dfs.block.access.token.lifetime
Handling deprecation for dfs.webhdfs.enabled
Handling deprecation for dfs.namenode.delegation.token.max-lifetime
Handling deprecation for dfs.namenode.avoid.write.stale.datanode
Handling deprecation for dfs.datanode.drop.cache.behind.writes
Handling deprecation for yarn.log-aggregation.retain-seconds
Handling deprecation for mapreduce.job.complete.cancel.delegation.tokens
Handling deprecation for mapreduce.local.clientfactory.class.name
Handling deprecation for mapreduce.shuffle.connection-keep-alive.timeout
Handling deprecation for dfs.namenode.num.extra.edits.retained
Handling deprecation for yarn.scheduler.minimum-allocation-vcores
Handling deprecation for ipc.client.connect.max.retries.on.timeouts
Handling deprecation for yarn.timeline-service.client.retry-interval-ms
Handling deprecation for yarn.timeline-service.client.max-retries
Handling deprecation for fs.s3n.block.size
Handling deprecation for mapreduce.job.map.output.collector.class
Handling deprecation for ha.health-monitor.connect-retry-interval.ms
Handling deprecation for mapreduce.shuffle.max.threads
Handling deprecation for nfs.exports.allowed.hosts
Handling deprecation for dfs.client.mmap.cache.size
Handling deprecation for mapreduce.tasktracker.map.tasks.maximum
Handling deprecation for io.file.buffer.size
Handling deprecation for dfs.client.datanode-restart.timeout
Handling deprecation for io.mapfile.bloom.size
Handling deprecation for hadoop.security.kms.client.authentication.retry-count
Handling deprecation for dfs.namenode.checkpoint.txns
Handling deprecation for ipc.client.connect.retry.interval
Handling deprecation for dfs.client-write-packet-size
Handling deprecation for mapreduce.reduce.shuffle.connect.timeout
Handling deprecation for yarn.resourcemanager.fs.state-store.uri
Handling deprecation for fs.swift.impl
Handling deprecation for hadoop.registry.zk.connection.timeout.ms
Handling deprecation for mapred.queue.default.acl-administer-jobs
Handling deprecation for mapreduce.job.submithostaddress
Handling deprecation for dfs.cachereport.intervalMsec
Handling deprecation for yarn.app.mapreduce.shuffle.log.backups
Handling deprecation for yarn.app.mapreduce.am.container.log.limit.kb
Handling deprecation for yarn.nodemanager.resourcemanager.minimum.version
Handling deprecation for ftp.blocksize
Handling deprecation for yarn.resourcemanager.address
Handling deprecation for file.stream-buffer-size
Handling deprecation for yarn.resourcemanager.scheduler.monitor.enable
Handling deprecation for mapreduce.job.ubertask.maxreduces
Handling deprecation for nfs.allow.insecure.ports
Handling deprecation for yarn.sharedcache.nm.uploader.thread-count
Handling deprecation for ipc.client.idlethreshold
Handling deprecation for ftp.stream-buffer-size
Handling deprecation for yarn.sharedcache.client-server.address
Handling deprecation for dfs.client.failover.connection.retries.on.timeouts
Handling deprecation for dfs.namenode.replication.work.multiplier.per.iteration
Handling deprecation for hadoop.http.authentication.simple.anonymous.allowed
Handling deprecation for hadoop.security.authorization
Handling deprecation for yarn.client.nodemanager-connect.retry-interval-ms
Handling deprecation for yarn.am.liveness-monitor.expiry-interval-ms
Handling deprecation for fs.har.impl.disable.cache
Handling deprecation for yarn.nodemanager.linux-container-executor.resources-handler.class
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.read-cache-size
Handling deprecation for hadoop.security.authentication
Handling deprecation for dfs.image.compression.codec
Handling deprecation for mapreduce.task.files.preserve.failedtasks
Handling deprecation for dfs.client.read.shortcircuit.streams.cache.size
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.path
Handling deprecation for mapreduce.job.reduce.slowstart.completedmaps
Handling deprecation for mapreduce.jobhistory.minicluster.fixed.ports
Handling deprecation for file.replication
Handling deprecation for yarn.resourcemanager.ha.automatic-failover.enabled
Handling deprecation for mapreduce.job.userlog.retain.hours
Handling deprecation for mapreduce.jobhistory.joblist.cache.size
Handling deprecation for dfs.namenode.accesstime.precision
Handling deprecation for yarn.resourcemanager.work-preserving-recovery.enabled
Handling deprecation for dfs.namenode.fs-limits.max-xattrs-per-inode
Handling deprecation for io.mapfile.bloom.error.rate
Handling deprecation for yarn.resourcemanager.store.class
Handling deprecation for dfs.image.transfer.timeout
Handling deprecation for yarn.timeline-service.leveldb-state-store.path
Handling deprecation for nfs.wtmax
Handling deprecation for mapreduce.job.combine.class
Handling deprecation for dfs.namenode.support.allow.format
Handling deprecation for fs.s3a.multipart.purge
Handling deprecation for dfs.secondary.namenode.kerberos.internal.spnego.principal
Handling deprecation for fs.s3a.connection.establish.timeout
Handling deprecation for dfs.stream-buffer-size
Handling deprecation for dfs.namenode.invalidate.work.pct.per.iteration
Handling deprecation for yarn.nodemanager.container-executor.class
Handling deprecation for fs.s3a.multipart.purge.age
Handling deprecation for yarn.resourcemanager.scheduler.client.thread-count
Handling deprecation for dfs.namenode.top.enabled
Handling deprecation for yarn.app.mapreduce.shuffle.log.separate
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.low-watermark
Handling deprecation for fs.s3a.fast.buffer.size
Handling deprecation for hadoop.user.group.static.mapping.overrides
Handling deprecation for tfile.fs.input.buffer.size
Handling deprecation for dfs.client.cached.conn.retry
Handling deprecation for hadoop.http.authentication.type
Handling deprecation for dfs.namenode.list.encryption.zones.num.responses
Handling deprecation for mapreduce.map.cpu.vcores
Handling deprecation for dfs.namenode.path.based.cache.refresh.interval.ms
Handling deprecation for dfs.namenode.decommission.interval
Handling deprecation for dfs.namenode.fs-limits.max-directory-items
Handling deprecation for yarn.resourcemanager.zk-retry-interval-ms
Handling deprecation for ftp.bytes-per-checksum
Handling deprecation for dfs.ha.log-roll.period
Handling deprecation for dfs.user.home.dir.prefix
Handling deprecation for ipc.client.fallback-to-simple-auth-allowed
Handling deprecation for yarn.nodemanager.pmem-check-enabled
Handling deprecation for yarn.nodemanager.remote-app-log-dir
Handling deprecation for dfs.namenode.inotify.max.events.per.rpc
Handling deprecation for mapreduce.task.profile.maps
Handling deprecation for mapreduce.shuffle.ssl.file.buffer.size
Handling deprecation for mapreduce.tasktracker.healthchecker.script.timeout
Handling deprecation for yarn.timeline-service.webapp.https.address
Handling deprecation for yarn.nodemanager.resource.percentage-physical-cpu-limit
Handling deprecation for yarn.app.mapreduce.am.command-opts
Handling deprecation for dfs.namenode.fs-limits.max-xattr-size
Handling deprecation for dfs.datanode.http.address
Handling deprecation for dfs.namenode.blocks.per.postponedblocks.rescan
Handling deprecation for yarn.sharedcache.nm.uploader.replication.factor
Handling deprecation for hadoop.registry.zk.root
Handling deprecation for hadoop.jetty.logs.serve.aliases
Handling deprecation for yarn.client.failover-proxy-provider
Handling deprecation for mapreduce.jobhistory.admin.acl
Handling deprecation for yarn.app.mapreduce.am.hard-kill-timeout-ms
Handling deprecation for yarn.nodemanager.remote-app-log-dir-suffix
Handling deprecation for mapreduce.jobhistory.principal
Handling deprecation for yarn.resourcemanager.webapp.address
Handling deprecation for mapreduce.jobhistory.recovery.enable
Handling deprecation for yarn.sharedcache.store.in-memory.check-period-mins
Handling deprecation for nfs.mountd.port
Handling deprecation for mapreduce.reduce.merge.inmem.threshold
Handling deprecation for fs.df.interval
Handling deprecation for yarn.timeline-service.enabled
Handling deprecation for mapreduce.jobtracker.jobhistory.lru.cache.size
Handling deprecation for mapreduce.task.profile
Handling deprecation for mapreduce.job.output.key.class
Handling deprecation for yarn.nodemanager.hostname
Handling deprecation for dfs.namenode.num.checkpoints.retained
Handling deprecation for mapreduce.job.queuename
Handling deprecation for mapreduce.jobhistory.max-age-ms
Handling deprecation for mapreduce.job.token.tracking.ids.enabled
Handling deprecation for yarn.nodemanager.localizer.client.thread-count
Handling deprecation for yarn.sharedcache.uploader.server.thread-count
Handling deprecation for dfs.client.mmap.retry.timeout.ms
Handling deprecation for mapreduce.jobhistory.move.thread-count
Handling deprecation for dfs.permissions.enabled
Handling deprecation for dfs.blockreport.split.threshold
Handling deprecation for fs.AbstractFileSystem.hdfs.impl
Handling deprecation for dfs.datanode.balance.bandwidthPerSec
Handling deprecation for dfs.block.scanner.volume.bytes.per.second
Handling deprecation for hadoop.http.filter.initializers
Handling deprecation for yarn.timeline-service.http-authentication.simple.anonymous.allowed
Handling deprecation for dfs.default.chunk.view.size
Handling deprecation for yarn.sharedcache.client-server.thread-count
Handling deprecation for yarn.resourcemanager.resource-tracker.address
Handling deprecation for mapreduce.job.working.dir
Handling deprecation for mapreduce.jobhistory.datestring.cache.size
Handling deprecation for mapreduce.task.profile.params
Handling deprecation for dfs.namenode.decommission.blocks.per.interval
Handling deprecation for dfs.namenode.handler.count
Handling deprecation for dfs.image.transfer.bandwidthPerSec
Handling deprecation for rpc.metrics.quantile.enable
Handling deprecation for mapreduce.jobtracker.expire.trackers.interval
Handling deprecation for mapreduce.task.timeout
Handling deprecation for yarn.app.mapreduce.client.max-retries
Handling deprecation for yarn.nodemanager.resource.memory-mb
Handling deprecation for yarn.nodemanager.disk-health-checker.min-healthy-disks
Handling deprecation for dfs.datanode.failed.volumes.tolerated
Handling deprecation for yarn.timeline-service.handler-thread-count
Handling deprecation for ipc.server.listen.queue.size
Handling deprecation for fs.s3a.threads.max
Handling deprecation for yarn.resourcemanager.connect.max-wait.ms
Handling deprecation for mapreduce.fileoutputcommitter.algorithm.version
Handling deprecation for mapreduce.framework.name
Handling deprecation for mapreduce.map.skip.proc.count.autoincr
Handling deprecation for mapreduce.job.max.split.locations
Handling deprecation for yarn.resourcemanager.scheduler.class
Handling deprecation for yarn.resourcemanager.system-metrics-publisher.enabled
Handling deprecation for dfs.blocksize
Handling deprecation for yarn.sharedcache.nested-level
Handling deprecation for mapreduce.shuffle.connection-keep-alive.enable
Handling deprecation for fs.s3a.threads.keepalivetime
Handling deprecation for fs.s3a.connection.timeout
Handling deprecation for file.client-write-packet-size
Handling deprecation for ha.failover-controller.cli-check.rpc-timeout.ms
Handling deprecation for ha.zookeeper.acl
Handling deprecation for dfs.namenode.write.stale.datanode.ratio
Handling deprecation for dfs.encrypt.data.transfer
Handling deprecation for dfs.datanode.shared.file.descriptor.paths
Handling deprecation for mapreduce.input.lineinputformat.linespermap
Handling deprecation for yarn.resourcemanager.delayed.delegation-token.removal-interval-ms
Handling deprecation for yarn.nodemanager.localizer.fetch.thread-count
Handling deprecation for dfs.client.failover.max.attempts
Handling deprecation for yarn.resourcemanager.scheduler.address
Handling deprecation for dfs.client.read.shortcircuit.streams.cache.expiry.ms
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.start-time-write-cache-size
Handling deprecation for yarn.nodemanager.health-checker.script.timeout-ms
Handling deprecation for yarn.resourcemanager.fs.state-store.num-retries
Handling deprecation for hadoop.ssl.require.client.cert
Handling deprecation for hadoop.security.uid.cache.secs
Handling deprecation for mapreduce.jobhistory.keytab
Handling deprecation for dfs.client.read.shortcircuit.skip.checksum
Handling deprecation for yarn.resourcemanager.ha.automatic-failover.zk-base-path
Handling deprecation for mapreduce.shuffle.ssl.enabled
Handling deprecation for mapreduce.reduce.log.level
Handling deprecation for hadoop.registry.rm.enabled
Handling deprecation for mapreduce.tasktracker.dns.interface
Handling deprecation for yarn.resourcemanager.system-metrics-publisher.dispatcher.pool-size
Handling deprecation for mapreduce.job.speculative.speculative-cap-running-tasks
Handling deprecation for dfs.datanode.block.id.layout.upgrade.threads
Handling deprecation for dfs.datanode.use.datanode.hostname
Handling deprecation for dfs.client.context
Handling deprecation for yarn.resourcemanager.ha.enabled
Handling deprecation for mapred.reducer.new-api
Handling deprecation for dfs.namenode.delegation.token.renew-interval
Handling deprecation for dfs.blockreport.intervalMsec
Handling deprecation for fs.s3a.multipart.threshold
Handling deprecation for mapreduce.reduce.shuffle.memory.limit.percent
Handling deprecation for dfs.https.server.keystore.resource
Handling deprecation for io.map.index.skip
Handling deprecation for mapreduce.job.hdfs-servers
Handling deprecation for mapreduce.jobtracker.taskscheduler
Handling deprecation for dfs.namenode.kerberos.internal.spnego.principal
Handling deprecation for yarn.resourcemanager.state-store.max-completed-applications
Handling deprecation for mapreduce.map.output.compress
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.num.refill.threads
Handling deprecation for fs.s3n.multipart.uploads.block.size
Handling deprecation for mapreduce.task.merge.progress.records
Handling deprecation for dfs.datanode.dns.interface
Handling deprecation for map.sort.class
Handling deprecation for yarn.nodemanager.aux-services.mapreduce_shuffle.class
Handling deprecation for tfile.fs.output.buffer.size
Handling deprecation for fs.du.interval
Handling deprecation for dfs.client.failover.connection.retries
Handling deprecation for dfs.namenode.top.window.num.buckets
Handling deprecation for mapreduce.job.dir
Handling deprecation for fs.s3a.buffer.dir
Handling deprecation for mapreduce.reduce.shuffle.retry-delay.max.ms
Handling deprecation for yarn.sharedcache.uploader.server.address
Handling deprecation for mapreduce.client.progressmonitor.pollinterval
Handling deprecation for yarn.app.mapreduce.shuffle.log.limit.kb
Handling deprecation for dfs.datanode.max.locked.memory
Handling deprecation for dfs.namenode.retrycache.expirytime.millis
Handling deprecation for dfs.datanode.scan.period.hours
Handling deprecation for dfs.client.block.write.replace-datanode-on-failure.best-effort
Handling deprecation for mapreduce.jobhistory.move.interval-ms
Handling deprecation for dfs.ha.fencing.ssh.connect-timeout
Handling deprecation for yarn.nodemanager.log-aggregation.roll-monitoring-interval-seconds
Handling deprecation for dfs.namenode.fs-limits.max-component-length
Handling deprecation for hadoop.registry.zk.quorum
Handling deprecation for dfs.namenode.enable.retrycache
Handling deprecation for dfs.datanode.du.reserved
Handling deprecation for yarn.timeline-service.state-store-class
Handling deprecation for dfs.datanode.ipc.address
Handling deprecation for hadoop.registry.system.acls
Handling deprecation for dfs.client.block.write.replace-datanode-on-failure.policy
Handling deprecation for dfs.namenode.path.based.cache.retry.interval.ms
Handling deprecation for hadoop.security.crypto.cipher.suite
Handling deprecation for dfs.ha.tail-edits.period
Handling deprecation for mapreduce.task.profile.reduce.params
Handling deprecation for hadoop.registry.jaas.context
Handling deprecation for yarn.resourcemanager.hostname
Handling deprecation for mapreduce.reduce.memory.mb
Handling deprecation for hadoop.security.group.mapping.ldap.search.filter.group
Handling deprecation for hadoop.http.authentication.kerberos.principal
Handling deprecation for hadoop.security.group.mapping.ldap.search.filter.user
Handling deprecation for yarn.nodemanager.disk-health-checker.min-free-space-per-disk-mb
Handling deprecation for dfs.namenode.edits.dir
Handling deprecation for yarn.client.failover-retries-on-socket-timeouts
Handling deprecation for dfs.namenode.decommission.max.concurrent.tracked.nodes
Handling deprecation for mapreduce.client.completion.pollinterval
Handling deprecation for dfs.namenode.name.dir.restore
Handling deprecation for dfs.namenode.secondary.http-address
Handling deprecation for mapreduce.jobhistory.recovery.store.leveldb.path
Handling deprecation for yarn.sharedcache.store.class
Handling deprecation for s3.bytes-per-checksum
Handling deprecation for yarn.nodemanager.windows-container.cpu-limit.enabled
Handling deprecation for yarn.resourcemanager.webapp.https.address
Handling deprecation for yarn.nodemanager.vmem-pmem-ratio
Handling deprecation for dfs.namenode.checkpoint.period
Handling deprecation for dfs.ha.automatic-failover.enabled
The url to track the job: http://localhost:8080/
Running job: job_local343739539_0002
OutputCommitter set in config null
File Output Committer Algorithm version is 1
OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
/user/michaeljones/wcOutputAnalysis/_temporary/0: masked=rwxr-xr-x
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones sending #35
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones got value #35
Call: mkdirs took 3ms
Starting mapper thread pool executor.
Max local threads: 1
Map tasks to process: 1
Waiting for map tasks
Starting task: attempt_local343739539_0002_m_000000_0
currentIndex 0   0:0
mapreduce.cluster.local.dir for child : /tmp/hadoop-michaeljones/mapred/local/localRunner//michaeljones/jobcache/job_local343739539_0002/attempt_local343739539_0002_m_000000_0
using new api for output committer
File Output Committer Algorithm version is 1
ProcfsBasedProcessTree currently is supported only on Linux.
 Using ResourceCalculatorProcessTree : null
Processing split: hdfs://localhost:9000/user/michaeljones/wcInput:0+50
Trying map output collector class: org.apache.hadoop.mapred.MapTask$MapOutputBuffer
(EQUATOR) 0 kvi 26214396(104857584)
mapreduce.task.io.sort.mb: 100
soft limit at 83886080
bufstart = 0; bufvoid = 104857600
kvstart = 26214396; length = 6553600
Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones sending #36
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones got value #36
Call: getBlockLocations took 3ms
newInfo = LocatedBlocks{
  fileLength=50
  underConstruction=false
  blocks=[LocatedBlock{BP-1045030256-10.0.0.2-1433119149314:blk_1073741825_1002; getBlockSize()=50; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-b42c5705-9ba4-4b14-b00b-f9194bb036f0,DISK]]}]
  lastLocatedBlock=LocatedBlock{BP-1045030256-10.0.0.2-1433119149314:blk_1073741825_1002; getBlockSize()=50; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-b42c5705-9ba4-4b14-b00b-f9194bb036f0,DISK]]}
  isLastBlockComplete=true}
Connecting to datanode 127.0.0.1:50010

Starting flush of map output
Spilling map output
bufstart = 0; bufend = 82; bufvoid = 104857600
kvstart = 26214396(104857584); kvend = 26214368(104857472); length = 29/6553600
IntSumCombinerAnalyser-Bye[1]
IntSumCombinerAnalyser-Goodbye[1]
IntSumCombinerAnalyser-Hadoop[1,1]
IntSumCombinerAnalyser-Hello[1,1]
IntSumCombinerAnalyser-World[1,1]
Finished spill 0
Task:attempt_local343739539_0002_m_000000_0 is done. And is in the process of committing
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones sending #37
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones got value #37
Call: getFileInfo took 3ms
map
Task 'attempt_local343739539_0002_m_000000_0' done.
Finishing task: attempt_local343739539_0002_m_000000_0
map task executor complete.
Starting reduce thread pool executor.
Max local threads: 1
Reduce tasks to process: 1
Waiting for reduce tasks
Starting task: attempt_local343739539_0002_r_000000_0
currentIndex 0   0:0
mapreduce.cluster.local.dir for child : /tmp/hadoop-michaeljones/mapred/local/localRunner//michaeljones/jobcache/job_local343739539_0002/attempt_local343739539_0002_r_000000_0
using new api for output committer
File Output Committer Algorithm version is 1
ProcfsBasedProcessTree currently is supported only on Linux.
 Using ResourceCalculatorProcessTree : null
Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@fa9d56b
MergerManager: memoryLimit=668309888, maxSingleShuffleLimit=167077472, mergeThreshold=441084544, ioSortFactor=10, memToMemMergeOutputsThreshold=10
attempt_local343739539_0002_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
Got 0 map completion events from 0
GetMapEventsThread about to sleep for 1000
LocalFetcher 2 going to fetch: attempt_local343739539_0002_m_000000_0
attempt_local343739539_0002_m_000000_0: Proceeding with shuffle since usedMemory (0) is lesser than memoryLimit (668309888).CommitMemory is (0)
localfetcher#2 about to shuffle output of map attempt_local343739539_0002_m_000000_0 decomp: 63 len: 67 to MEMORY
Read 63 bytes from map-output for attempt_local343739539_0002_m_000000_0
closeInMemoryFile -> map-output of size: 63, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->63
map attempt_local343739539_0002_m_000000_0 done 1 / 1 copied.
EventFetcher is interrupted.. Returning
1 / 1 copied.
finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
Merging 1 sorted segments
Down to the last merge-pass, with 1 segments left of total size: 57 bytes
Merged 1 segments, 63 bytes to disk to satisfy reduce memory limit
Disk file: /tmp/hadoop-michaeljones/mapred/local/localRunner/michaeljones/jobcache/job_local343739539_0002/attempt_local343739539_0002_r_000000_0/output/map_0.out.merged Length is 67
Merging 1 files, 67 bytes from disk
Merging 0 segments, 0 bytes from memory into reduce
Merging 1 sorted segments
Down to the last merge-pass, with 1 segments left of total size: 57 bytes
1 / 1 copied.
/user/michaeljones/wcOutputAnalysis/_temporary/0/_temporary/attempt_local343739539_0002_r_000000_0/part-r-00000: masked=rw-r--r--
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones sending #38
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones got value #38
Call: create took 5ms
computePacketChunkSize: src=/user/michaeljones/wcOutputAnalysis/_temporary/0/_temporary/attempt_local343739539_0002_r_000000_0/part-r-00000, chunkSize=516, chunksPerPacket=126, packetSize=65016
IntSumReducerAnalyser-Bye[1]
IntSumReducerAnalyser-Goodbye[1]
IntSumReducerAnalyser-Hadoop[2]
IntSumReducerAnalyser-Hello[2]
IntSumReducerAnalyser-World[2]
DFSClient writeChunk allocating new packet seqno=0, src=/user/michaeljones/wcOutputAnalysis/_temporary/0/_temporary/attempt_local343739539_0002_r_000000_0/part-r-00000, packetSize=65016, chunksPerPacket=126, bytesCurBlock=0
Queued packet 0
Queued packet 1
Waiting for ack for: 1
Allocating new block
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones sending #39
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones got value #39
Call: addBlock took 3ms
pipeline = DatanodeInfoWithStorage[127.0.0.1:50010,DS-b42c5705-9ba4-4b14-b00b-f9194bb036f0,DISK]
Connecting to datanode 127.0.0.1:50010
Send buf size 131072
SASL client skipping handshake in unsecured configuration for addr = /127.0.0.1, datanodeId = DatanodeInfoWithStorage[127.0.0.1:50010,DS-b42c5705-9ba4-4b14-b00b-f9194bb036f0,DISK]
DataStreamer block BP-1045030256-10.0.0.2-1433119149314:blk_1073742230_1407 sending packet packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 41
DFSClient seqno: 0 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
DataStreamer block BP-1045030256-10.0.0.2-1433119149314:blk_1073742230_1407 sending packet packet seqno: 1 offsetInBlock: 41 lastPacketInBlock: true lastByteOffsetInBlock: 41
DFSClient seqno: 1 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
Closing old block BP-1045030256-10.0.0.2-1433119149314:blk_1073742230_1407
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones sending #40
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones got value #40
Call: complete took 4ms
Task:attempt_local343739539_0002_r_000000_0 is done. And is in the process of committing
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones sending #41
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones got value #41
Call: getFileInfo took 2ms
1 / 1 copied.
Task attempt_local343739539_0002_r_000000_0 is allowed to commit now
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones sending #42
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones got value #42
Call: getFileInfo took 2ms
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones sending #43
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones got value #43
Call: getFileInfo took 2ms
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones sending #44
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones got value #44
Call: rename took 5ms
Saved output of task 'attempt_local343739539_0002_r_000000_0' to hdfs://localhost:9000/user/michaeljones/wcOutputAnalysis/_temporary/0/task_local343739539_0002_r_000000
reduce > reduce
Task 'attempt_local343739539_0002_r_000000_0' done.
Finishing task: attempt_local343739539_0002_r_000000_0
reduce task executor complete.
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones sending #45
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones got value #45
Call: getListing took 2ms
Merging data from FileStatus{path=hdfs://localhost:9000/user/michaeljones/wcOutputAnalysis/_temporary/0/task_local343739539_0002_r_000000; isDirectory=true; modification_time=1434159017904; access_time=0; owner=michaeljones; group=supergroup; permission=rwxr-xr-x; isSymlink=false} to hdfs://localhost:9000/user/michaeljones/wcOutputAnalysis
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones sending #46
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones got value #46
Call: getFileInfo took 2ms
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones sending #47
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones got value #47
Call: getListing took 2ms
Merging data from FileStatus{path=hdfs://localhost:9000/user/michaeljones/wcOutputAnalysis/_temporary/0/task_local343739539_0002_r_000000/part-r-00000; isDirectory=false; length=41; replication=1; blocksize=134217728; modification_time=1434159017927; access_time=1434159017904; owner=michaeljones; group=supergroup; permission=rw-r--r--; isSymlink=false} to hdfs://localhost:9000/user/michaeljones/wcOutputAnalysis/part-r-00000
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones sending #48
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones got value #48
Call: getFileInfo took 1ms
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones sending #49
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones got value #49
Call: rename took 5ms
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones sending #50
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones got value #50
Call: delete took 2ms
/user/michaeljones/wcOutputAnalysis/_SUCCESS: masked=rw-r--r--
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones sending #51
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones got value #51
Call: create took 3ms
computePacketChunkSize: src=/user/michaeljones/wcOutputAnalysis/_SUCCESS, chunkSize=516, chunksPerPacket=126, packetSize=65016
Waiting for ack for: -1
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones sending #52
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones got value #52
Call: complete took 8ms
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.fs.FileContext.getAbstractFileSystem(FileContext.java:331)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
Job job_local343739539_0002 running in uber mode : false
 map 100% reduce 100%
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.getTaskCompletionEvents(Job.java:670)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.getTaskCompletionEvents(Job.java:670)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
Job job_local343739539_0002 completed successfully
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.getCounters(Job.java:758)
Counters: 35
	File System Counters
		FILE: Number of bytes read=1206
		FILE: Number of bytes written=1128497
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=240
		HDFS: Number of bytes written=163
		HDFS: Number of read operations=45
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=24
	Map-Reduce Framework
		Map input records=2
		Map output records=8
		Map output bytes=82
		Map output materialized bytes=67
		Input split bytes=112
		Combine input records=8
		Combine output records=5
		Reduce input groups=5
		Reduce shuffle bytes=67
		Reduce input records=5
		Reduce output records=5
		Spilled Records=10
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=762314752
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=50
	File Output Format Counters 
		Bytes Written=41
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
testMain
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones sending #53
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones got value #53
Call: getFileInfo took 3ms
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones sending #54
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones got value #54
Call: delete took 9ms
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.connect(Job.java:1256)
Trying ClientProtocolProvider : org.apache.hadoop.mapred.LocalClientProtocolProvider
Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
Picked org.apache.hadoop.mapred.LocalClientProtocolProvider as the ClientProtocolProvider
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Cluster.getFileSystem(Cluster.java:162)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.submit(Job.java:1287)
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones sending #55
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones got value #55
Call: getFileInfo took 2ms
Configuring job job_local633002303_0003 with file:/tmp/hadoop-michaeljones/mapred/staging/michaeljones633002303/.staging/job_local633002303_0003 as the submit dir
adding the following namenodes' delegation tokens:[hdfs://localhost:9000]
Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
default FileSystem: file:///
No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
Creating splits at file:/tmp/hadoop-michaeljones/mapred/staging/michaeljones633002303/.staging/job_local633002303_0003
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones sending #56
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones got value #56
Call: getFileInfo took 2ms
Time taken to get FileStatuses: 3
Total input paths to process : 1
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones sending #57
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones got value #57
Call: getBlockLocations took 2ms
Total # of splits generated by getSplits: 1, TimeTaken: 7
number of splits:1
Handling deprecation for all properties in config...
Handling deprecation for mapreduce.jobtracker.address
Handling deprecation for yarn.resourcemanager.scheduler.monitor.policies
Handling deprecation for dfs.namenode.resource.check.interval
Handling deprecation for mapreduce.jobhistory.client.thread-count
Handling deprecation for yarn.app.mapreduce.am.containerlauncher.threadpool-initial-size
Handling deprecation for mapred.child.java.opts
Handling deprecation for mapreduce.jobtracker.retiredjobs.cache.size
Handling deprecation for dfs.client.https.need-auth
Handling deprecation for yarn.admin.acl
Handling deprecation for yarn.app.mapreduce.am.job.committer.cancel-timeout
Handling deprecation for mapreduce.job.emit-timeline-data
Handling deprecation for fs.ftp.host.port
Handling deprecation for dfs.namenode.avoid.read.stale.datanode
Handling deprecation for dfs.journalnode.rpc-address
Handling deprecation for mapreduce.job.end-notification.retry.attempts
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.ttl-interval-ms
Handling deprecation for yarn.resourcemanager.leveldb-state-store.path
Handling deprecation for mapred.mapper.new-api
Handling deprecation for yarn.ipc.rpc.class
Handling deprecation for ipc.client.connection.maxidletime
Handling deprecation for yarn.nodemanager.process-kill-wait.ms
Handling deprecation for mapreduce.cluster.acls.enabled
Handling deprecation for mapreduce.jobtracker.handler.count
Handling deprecation for io.map.index.interval
Handling deprecation for dfs.namenode.https-address
Handling deprecation for mapreduce.task.profile.reduces
Handling deprecation for fs.s3n.multipart.uploads.enabled
Handling deprecation for io.seqfile.sorter.recordlimit
Handling deprecation for mapreduce.job.ubertask.maxmaps
Handling deprecation for mapreduce.tasktracker.tasks.sleeptimebeforesigkill
Handling deprecation for hadoop.util.hash.type
Handling deprecation for dfs.namenode.replication.min
Handling deprecation for yarn.nodemanager.container-manager.thread-count
Handling deprecation for mapreduce.jobtracker.jobhistory.block.size
Handling deprecation for dfs.namenode.fs-limits.min-block-size
Handling deprecation for mapreduce.app-submission.cross-platform
Handling deprecation for fs.AbstractFileSystem.file.impl
Handling deprecation for net.topology.script.number.args
Handling deprecation for yarn.resourcemanager.container-tokens.master-key-rolling-interval-secs
Handling deprecation for mapreduce.map.output.compress.codec
Handling deprecation for mapreduce.job.reducer.preempt.delay.sec
Handling deprecation for s3native.bytes-per-checksum
Handling deprecation for dfs.namenode.path.based.cache.block.map.allocation.percent
Handling deprecation for yarn.nodemanager.windows-container.memory-limit.enabled
Handling deprecation for mapreduce.input.fileinputformat.split.minsize
Handling deprecation for hadoop.security.group.mapping
Handling deprecation for mapreduce.jobtracker.system.dir
Handling deprecation for mapreduce.job.end-notification.max.attempts
Handling deprecation for mapreduce.reduce.markreset.buffer.percent
Handling deprecation for dfs.datanode.cache.revocation.polling.ms
Handling deprecation for mapreduce.reduce.speculative
Handling deprecation for yarn.nodemanager.localizer.cache.cleanup.interval-ms
Handling deprecation for dfs.namenode.lazypersist.file.scrub.interval.sec
Handling deprecation for fs.s3a.threads.core
Handling deprecation for mapreduce.jobhistory.recovery.store.fs.uri
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.start-time-read-cache-size
Handling deprecation for hadoop.registry.zk.retry.interval.ms
Handling deprecation for yarn.nodemanager.keytab
Handling deprecation for dfs.namenode.replication.interval
Handling deprecation for yarn.resourcemanager.admin.address
Handling deprecation for mapreduce.job.maps
Handling deprecation for nfs.dump.dir
Handling deprecation for mapreduce.job.user.name
Handling deprecation for mapreduce.jobtracker.maxtasks.perjob
Handling deprecation for mapreduce.job.ubertask.enable
Handling deprecation for mapreduce.job.reduce.class
Handling deprecation for yarn.nodemanager.delete.debug-delay-sec
Handling deprecation for yarn.timeline-service.ttl-enable
Handling deprecation for yarn.resourcemanager.fs.state-store.retry-policy-spec
Handling deprecation for mapreduce.reduce.skip.maxgroups
Handling deprecation for dfs.client.use.datanode.hostname
Handling deprecation for fs.trash.interval
Handling deprecation for mapreduce.job.name
Handling deprecation for mapreduce.am.max-attempts
Handling deprecation for mapreduce.jobtracker.heartbeats.in.second
Handling deprecation for yarn.resourcemanager.zk-num-retries
Handling deprecation for s3.blocksize
Handling deprecation for dfs.datanode.data.dir
Handling deprecation for mapreduce.jobtracker.persist.jobstatus.active
Handling deprecation for mapreduce.reduce.shuffle.parallelcopies
Handling deprecation for fs.s3.buffer.dir
Handling deprecation for mapreduce.jobhistory.done-dir
Handling deprecation for hadoop.security.instrumentation.requires.admin
Handling deprecation for hadoop.registry.zk.retry.ceiling.ms
Handling deprecation for nfs.rtmax
Handling deprecation for dfs.datanode.data.dir.perm
Handling deprecation for yarn.resourcemanager.container.liveness-monitor.interval-ms
Handling deprecation for yarn.nodemanager.env-whitelist
Handling deprecation for dfs.namenode.backup.address
Handling deprecation for dfs.namenode.xattrs.enabled
Handling deprecation for dfs.datanode.readahead.bytes
Handling deprecation for mapreduce.jobhistory.cleaner.enable
Handling deprecation for dfs.client.block.write.retries
Handling deprecation for mapreduce.tasktracker.http.address
Handling deprecation for yarn.nodemanager.linux-container-executor.cgroups.hierarchy
Handling deprecation for ha.failover-controller.graceful-fence.connection.retries
Handling deprecation for yarn.resourcemanager.recovery.enabled
Handling deprecation for yarn.app.mapreduce.am.container.log.backups
Handling deprecation for dfs.namenode.safemode.threshold-pct
Handling deprecation for yarn.nodemanager.disk-health-checker.interval-ms
Handling deprecation for hadoop.security.java.secure.random.algorithm
Handling deprecation for dfs.namenode.list.cache.directives.num.responses
Handling deprecation for dfs.datanode.dns.nameserver
Handling deprecation for mapreduce.cluster.temp.dir
Handling deprecation for fs.s3a.max.total.tasks
Handling deprecation for mapreduce.reduce.maxattempts
Handling deprecation for mapreduce.client.submit.file.replication
Handling deprecation for mapreduce.shuffle.port
Handling deprecation for yarn.resourcemanager.resource-tracker.client.thread-count
Handling deprecation for dfs.namenode.replication.considerLoad
Handling deprecation for dfs.namenode.edits.journal-plugin.qjournal
Handling deprecation for dfs.client.write.exclude.nodes.cache.expiry.interval.millis
Handling deprecation for yarn.nodemanager.delete.thread-count
Handling deprecation for dfs.client.mmap.cache.timeout.ms
Handling deprecation for yarn.nodemanager.admin-env
Handling deprecation for io.skip.checksum.errors
Handling deprecation for yarn.timeline-service.hostname
Handling deprecation for yarn.resourcemanager.proxy-user-privileges.enabled
Handling deprecation for mapreduce.job.speculative.speculative-cap-total-tasks
Handling deprecation for yarn.acl.enable
Handling deprecation for fs.s3a.fast.upload
Handling deprecation for file.blocksize
Handling deprecation for mapreduce.job.speculative.slowtaskthreshold
Handling deprecation for ftp.replication
Handling deprecation for yarn.sharedcache.cleaner.initial-delay-mins
Handling deprecation for s3native.client-write-packet-size
Handling deprecation for hadoop.rpc.socket.factory.class.default
Handling deprecation for file.bytes-per-checksum
Handling deprecation for dfs.datanode.slow.io.warning.threshold.ms
Handling deprecation for io.seqfile.lazydecompress
Handling deprecation for mapreduce.task.skip.start.attempts
Handling deprecation for dfs.namenode.reject-unresolved-dn-topology-mapping
Handling deprecation for hadoop.common.configuration.version
Handling deprecation for yarn.resourcemanager.client.thread-count
Handling deprecation for dfs.datanode.drop.cache.behind.reads
Handling deprecation for yarn.sharedcache.admin.address
Handling deprecation for mapreduce.job.output.value.class
Handling deprecation for mapreduce.output.fileoutputformat.outputdir
Handling deprecation for mapreduce.jobtracker.taskcache.levels
Handling deprecation for yarn.nodemanager.linux-container-executor.nonsecure-mode.user-pattern
Handling deprecation for yarn.resourcemanager.zk-timeout-ms
Handling deprecation for yarn.resourcemanager.max-completed-applications
Handling deprecation for mapreduce.job.jvm.numtasks
Handling deprecation for yarn.sharedcache.cleaner.period-mins
Handling deprecation for mapreduce.jobtracker.tasktracker.maxblacklists
Handling deprecation for dfs.namenode.top.num.users
Handling deprecation for yarn.nodemanager.linux-container-executor.cgroups.mount
Handling deprecation for yarn.sharedcache.checksum.algo.impl
Handling deprecation for mapreduce.job.end-notification.max.retry.interval
Handling deprecation for mapreduce.job.acl-view-job
Handling deprecation for mapreduce.job.classloader
Handling deprecation for yarn.log-aggregation-enable
Handling deprecation for mapreduce.reduce.shuffle.fetch.retry.interval-ms
Handling deprecation for yarn.resourcemanager.nodemanager.minimum.version
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.size
Handling deprecation for yarn.app.mapreduce.am.job.task.listener.thread-count
Handling deprecation for yarn.app.mapreduce.am.resource.cpu-vcores
Handling deprecation for dfs.namenode.edit.log.autoroll.check.interval.ms
Handling deprecation for mapreduce.output.fileoutputformat.compress.type
Handling deprecation for hadoop.hdfs.configuration.version
Handling deprecation for hadoop.security.group.mapping.ldap.search.attr.member
Handling deprecation for yarn.nodemanager.log.retain-seconds
Handling deprecation for yarn.nodemanager.local-cache.max-files-per-directory
Handling deprecation for mapreduce.job.end-notification.retry.interval
Handling deprecation for hadoop.ssl.client.conf
Handling deprecation for yarn.sharedcache.root-dir
Handling deprecation for dfs.journalnode.https-address
Handling deprecation for mapreduce.reduce.shuffle.fetch.retry.timeout-ms
Handling deprecation for dfs.bytes-per-checksum
Handling deprecation for dfs.namenode.max.objects
Handling deprecation for mapreduce.tasktracker.instrumentation
Handling deprecation for dfs.datanode.max.transfer.threads
Handling deprecation for dfs.block.access.key.update.interval
Handling deprecation for mapreduce.jobtracker.jobhistory.task.numberprogresssplits
Handling deprecation for mapreduce.map.memory.mb
Handling deprecation for ha.failover-controller.new-active.rpc-timeout.ms
Handling deprecation for hadoop.ssl.hostname.verifier
Handling deprecation for dfs.client.read.shortcircuit
Handling deprecation for dfs.datanode.hdfs-blocks-metadata.enabled
Handling deprecation for mapreduce.tasktracker.healthchecker.interval
Handling deprecation for dfs.image.transfer.chunksize
Handling deprecation for mapreduce.tasktracker.taskmemorymanager.monitoringinterval
Handling deprecation for dfs.client.https.keystore.resource
Handling deprecation for yarn.resourcemanager.connect.retry-interval.ms
Handling deprecation for yarn.timeline-service.webapp.address
Handling deprecation for s3native.blocksize
Handling deprecation for yarn.scheduler.minimum-allocation-mb
Handling deprecation for yarn.sharedcache.cleaner.resource-sleep-ms
Handling deprecation for net.topology.impl
Handling deprecation for dfs.client.failover.sleep.base.millis
Handling deprecation for dfs.permissions.superusergroup
Handling deprecation for io.seqfile.compress.blocksize
Handling deprecation for hadoop.registry.zk.retry.times
Handling deprecation for fs.AbstractFileSystem.ftp.impl
Handling deprecation for dfs.namenode.checkpoint.edits.dir
Handling deprecation for mapreduce.job.running.reduce.limit
Handling deprecation for dfs.blockreport.initialDelay
Handling deprecation for dfs.namenode.heartbeat.recheck-interval
Handling deprecation for dfs.namenode.safemode.extension
Handling deprecation for yarn.scheduler.maximum-allocation-mb
Handling deprecation for mapreduce.job.reduce.shuffle.consumer.plugin.class
Handling deprecation for yarn.nodemanager.vmem-check-enabled
Handling deprecation for mapreduce.task.io.sort.factor
Handling deprecation for mapreduce.jobtracker.persist.jobstatus.dir
Handling deprecation for dfs.client.failover.sleep.max.millis
Handling deprecation for dfs.namenode.delegation.key.update-interval
Handling deprecation for hadoop.rpc.protection
Handling deprecation for fs.permissions.umask-mode
Handling deprecation for fs.s3.sleepTimeSeconds
Handling deprecation for ha.health-monitor.rpc-timeout.ms
Handling deprecation for hadoop.http.staticuser.user
Handling deprecation for fs.s3a.connection.maximum
Handling deprecation for yarn.nodemanager.linux-container-executor.nonsecure-mode.limit-users
Handling deprecation for fs.s3a.paging.maximum
Handling deprecation for fs.AbstractFileSystem.viewfs.impl
Handling deprecation for fs.ftp.host
Handling deprecation for yarn.nodemanager.linux-container-executor.nonsecure-mode.local-user
Handling deprecation for fs.s3a.impl
Handling deprecation for hadoop.http.authentication.kerberos.keytab
Handling deprecation for dfs.namenode.fs-limits.max-blocks-per-file
Handling deprecation for mapreduce.tasktracker.http.threads
Handling deprecation for mapreduce.tasktracker.dns.nameserver
Handling deprecation for yarn.resourcemanager.am-rm-tokens.master-key-rolling-interval-secs
Handling deprecation for dfs.client.block.write.replace-datanode-on-failure.enable
Handling deprecation for io.compression.codec.bzip2.library
Handling deprecation for mapreduce.map.skip.maxrecords
Handling deprecation for dfs.client.use.legacy.blockreader.local
Handling deprecation for dfs.namenode.checkpoint.dir
Handling deprecation for dfs.namenode.top.windows.minutes
Handling deprecation for mapreduce.job.maxtaskfailures.per.tracker
Handling deprecation for net.topology.node.switch.mapping.impl
Handling deprecation for mapreduce.shuffle.max.connections
Handling deprecation for mapreduce.jobhistory.loadedjobs.cache.size
Handling deprecation for dfs.storage.policy.enabled
Handling deprecation for yarn.client.application-client-protocol.poll-interval-ms
Handling deprecation for yarn.nodemanager.localizer.address
Handling deprecation for dfs.namenode.list.cache.pools.num.responses
Handling deprecation for nfs.server.port
Handling deprecation for mapreduce.client.output.filter
Handling deprecation for yarn.timeline-service.client.best-effort
Handling deprecation for ha.zookeeper.parent-znode
Handling deprecation for mapreduce.jobtracker.persist.jobstatus.hours
Handling deprecation for yarn.sharedcache.admin.thread-count
Handling deprecation for yarn.nodemanager.resource.cpu-vcores
Handling deprecation for dfs.datanode.block-pinning.enabled
Handling deprecation for mapreduce.jobhistory.http.policy
Handling deprecation for yarn.resourcemanager.webapp.delegation-token-auth-filter.enabled
Handling deprecation for mapreduce.job.speculative.retry-after-no-speculate
Handling deprecation for fs.s3a.attempts.maximum
Handling deprecation for s3native.stream-buffer-size
Handling deprecation for io.seqfile.local.dir
Handling deprecation for yarn.log-aggregation.retain-check-interval-seconds
Handling deprecation for fs.s3n.multipart.copy.block.size
Handling deprecation for dfs.encrypt.data.transfer.cipher.key.bitlength
Handling deprecation for dfs.datanode.sync.behind.writes
Handling deprecation for yarn.resourcemanager.zk-acl
Handling deprecation for hadoop.ssl.keystores.factory.class
Handling deprecation for mapreduce.job.split.metainfo.maxsize
Handling deprecation for fs.s3.maxRetries
Handling deprecation for hadoop.security.random.device.file.path
Handling deprecation for yarn.client.nodemanager-connect.max-wait-ms
Handling deprecation for dfs.namenode.stale.datanode.interval
Handling deprecation for mapreduce.task.io.sort.mb
Handling deprecation for yarn.resourcemanager.zk-state-store.parent-path
Handling deprecation for yarn.app.mapreduce.client-am.ipc.max-retries
Handling deprecation for fs.client.resolve.remote.symlinks
Handling deprecation for yarn.nodemanager.linux-container-executor.cgroups.strict-resource-usage
Handling deprecation for hadoop.ssl.enabled.protocols
Handling deprecation for mapreduce.reduce.cpu.vcores
Handling deprecation for yarn.client.failover-retries
Handling deprecation for mapreduce.jobhistory.address
Handling deprecation for hadoop.ssl.enabled
Handling deprecation for dfs.replication.max
Handling deprecation for dfs.namenode.name.dir
Handling deprecation for dfs.datanode.https.address
Handling deprecation for ipc.client.kill.max
Handling deprecation for mapreduce.job.committer.setup.cleanup.needed
Handling deprecation for dfs.client.domain.socket.data.traffic
Handling deprecation for yarn.nodemanager.localizer.cache.target-size-mb
Handling deprecation for yarn.resourcemanager.admin.client.thread-count
Handling deprecation for dfs.block.access.token.enable
Handling deprecation for mapreduce.job.speculative.retry-after-speculate
Handling deprecation for dfs.datanode.address
Handling deprecation for mapreduce.jobtracker.restart.recover
Handling deprecation for ipc.client.connect.max.retries
Handling deprecation for yarn.timeline-service.store-class
Handling deprecation for dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
Handling deprecation for hadoop.tmp.dir
Handling deprecation for dfs.datanode.handler.count
Handling deprecation for yarn.resourcemanager.ha.automatic-failover.embedded
Handling deprecation for yarn.timeline-service.ttl-ms
Handling deprecation for mapreduce.task.profile.map.params
Handling deprecation for yarn.resourcemanager.nodemanagers.heartbeat-interval-ms
Handling deprecation for mapreduce.map.speculative
Handling deprecation for yarn.timeline-service.recovery.enabled
Handling deprecation for mapreduce.job.map.class
Handling deprecation for dfs.namenode.resource.checked.volumes.minimum
Handling deprecation for yarn.nodemanager.recovery.dir
Handling deprecation for mapreduce.job.counters.max
Handling deprecation for yarn.resourcemanager.keytab
Handling deprecation for dfs.namenode.max.extra.edits.segments.retained
Handling deprecation for dfs.webhdfs.user.provider.user.pattern
Handling deprecation for dfs.client.mmap.enabled
Handling deprecation for mapreduce.map.log.level
Handling deprecation for dfs.client.file-block-storage-locations.timeout.millis
Handling deprecation for yarn.client.max-cached-nodemanagers-proxies
Handling deprecation for yarn.app.mapreduce.am.scheduler.heartbeat.interval-ms
Handling deprecation for hadoop.fuse.timer.period
Handling deprecation for fs.trash.checkpoint.interval
Handling deprecation for yarn.sharedcache.app-checker.class
Handling deprecation for dfs.journalnode.http-address
Handling deprecation for yarn.app.mapreduce.am.staging-dir
Handling deprecation for mapreduce.tasktracker.local.dir.minspacestart
Handling deprecation for yarn.nm.liveness-monitor.expiry-interval-ms
Handling deprecation for ha.health-monitor.check-interval.ms
Handling deprecation for mapreduce.reduce.shuffle.merge.percent
Handling deprecation for dfs.namenode.retrycache.heap.percent
Handling deprecation for yarn.nodemanager.docker-container-executor.exec-name
Handling deprecation for ipc.client.connect.timeout
Handling deprecation for yarn.resourcemanager.fs.state-store.retry-interval-ms
Handling deprecation for mapreduce.output.fileoutputformat.compress
Handling deprecation for yarn.nodemanager.local-dirs
Handling deprecation for yarn.nodemanager.recovery.enabled
Handling deprecation for io.native.lib.available
Handling deprecation for yarn.sharedcache.store.in-memory.staleness-period-mins
Handling deprecation for yarn.resourcemanager.am.max-attempts
Handling deprecation for s3.replication
Handling deprecation for mapreduce.input.fileinputformat.inputdir
Handling deprecation for fs.AbstractFileSystem.har.impl
Handling deprecation for dfs.image.compress
Handling deprecation for mapreduce.job.running.map.limit
Handling deprecation for mapreduce.reduce.input.buffer.percent
Handling deprecation for yarn.nodemanager.webapp.address
Handling deprecation for dfs.datanode.available-space-volume-choosing-policy.balanced-space-preference-fraction
Handling deprecation for dfs.namenode.edit.log.autoroll.multiplier.threshold
Handling deprecation for hadoop.security.group.mapping.ldap.ssl
Handling deprecation for dfs.namenode.checkpoint.check.period
Handling deprecation for fs.defaultFS
Handling deprecation for fs.s3a.multipart.size
Handling deprecation for dfs.client.slow.io.warning.threshold.ms
Handling deprecation for yarn.app.mapreduce.am.job.committer.commit-window
Handling deprecation for hadoop.security.group.mapping.ldap.search.attr.group.name
Handling deprecation for yarn.nodemanager.disk-health-checker.max-disk-utilization-per-disk-percentage
Handling deprecation for yarn.nodemanager.container-monitor.procfs-tree.smaps-based-rss.enabled
Handling deprecation for mapreduce.job.submithostname
Handling deprecation for mapreduce.map.sort.spill.percent
Handling deprecation for hadoop.security.crypto.codec.classes.aes.ctr.nopadding
Handling deprecation for dfs.namenode.http-address
Handling deprecation for hadoop.security.groups.negative-cache.secs
Handling deprecation for hadoop.ssl.server.conf
Handling deprecation for mapreduce.ifile.readahead
Handling deprecation for s3native.replication
Handling deprecation for yarn.client.nodemanager-client-async.thread-pool-max-size
Handling deprecation for mapreduce.jobtracker.staging.root.dir
Handling deprecation for mapreduce.jobhistory.admin.address
Handling deprecation for dfs.namenode.startup.delay.block.deletion.sec
Handling deprecation for yarn.nodemanager.health-checker.interval-ms
Handling deprecation for dfs.namenode.checkpoint.max-retries
Handling deprecation for s3.stream-buffer-size
Handling deprecation for ftp.client-write-packet-size
Handling deprecation for dfs.datanode.fsdatasetcache.max.threads.per.volume
Handling deprecation for mapreduce.output.fileoutputformat.compress.codec
Handling deprecation for yarn.timeline-service.keytab
Handling deprecation for yarn.sharedcache.store.in-memory.initial-delay-mins
Handling deprecation for mapreduce.jobhistory.webapp.address
Handling deprecation for mapreduce.task.userlog.limit.kb
Handling deprecation for mapreduce.reduce.shuffle.fetch.retry.enabled
Handling deprecation for yarn.app.mapreduce.task.container.log.backups
Handling deprecation for dfs.heartbeat.interval
Handling deprecation for ha.zookeeper.session-timeout.ms
Handling deprecation for fs.s3a.connection.ssl.enabled
Handling deprecation for yarn.sharedcache.webapp.address
Handling deprecation for hadoop.http.authentication.signature.secret.file
Handling deprecation for hadoop.fuse.connection.timeout
Handling deprecation for mapreduce.input.fileinputformat.numinputfiles
Handling deprecation for yarn.nodemanager.log-aggregation.compression-type
Handling deprecation for ipc.server.max.connections
Handling deprecation for yarn.resourcemanager.work-preserving-recovery.scheduling-wait-ms
Handling deprecation for yarn.nodemanager.log-dirs
Handling deprecation for yarn.app.mapreduce.am.resource.mb
Handling deprecation for hadoop.security.groups.cache.secs
Handling deprecation for mapreduce.job.speculative.minimum-allowed-tasks
Handling deprecation for yarn.nodemanager.container-monitor.interval-ms
Handling deprecation for dfs.datanode.cache.revocation.timeout.ms
Handling deprecation for mapreduce.jobhistory.recovery.store.class
Handling deprecation for mapreduce.task.combine.progress.records
Handling deprecation for s3.client-write-packet-size
Handling deprecation for mapreduce.jobtracker.instrumentation
Handling deprecation for dfs.replication
Handling deprecation for mapreduce.shuffle.transfer.buffer.size
Handling deprecation for hadoop.security.group.mapping.ldap.directory.search.timeout
Handling deprecation for dfs.datanode.available-space-volume-choosing-policy.balanced-space-threshold
Handling deprecation for hadoop.work.around.non.threadsafe.getpwuid
Handling deprecation for yarn.app.mapreduce.client-am.ipc.max-retries-on-timeouts
Handling deprecation for yarn.nodemanager.address
Handling deprecation for mapreduce.tasktracker.taskcontroller
Handling deprecation for mapreduce.tasktracker.indexcache.mb
Handling deprecation for yarn.scheduler.maximum-allocation-vcores
Handling deprecation for mapreduce.job.reduces
Handling deprecation for yarn.nodemanager.sleep-delay-before-sigkill.ms
Handling deprecation for yarn.timeline-service.address
Handling deprecation for yarn.resourcemanager.configuration.provider-class
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.expiry
Handling deprecation for yarn.sharedcache.enabled
Handling deprecation for tfile.io.chunk.size
Handling deprecation for mapreduce.job.acl-modify-job
Handling deprecation for hadoop.registry.zk.session.timeout.ms
Handling deprecation for fs.automatic.close
Handling deprecation for ha.health-monitor.sleep-after-disconnect.ms
Handling deprecation for mapreduce.tasktracker.reduce.tasks.maximum
Handling deprecation for mapreduce.input.fileinputformat.list-status.num-threads
Handling deprecation for dfs.datanode.directoryscan.threads
Handling deprecation for dfs.datanode.directoryscan.interval
Handling deprecation for dfs.namenode.acls.enabled
Handling deprecation for dfs.client.short.circuit.replica.stale.threshold.ms
Handling deprecation for hadoop.http.authentication.token.validity
Handling deprecation for fs.s3.block.size
Handling deprecation for ha.failover-controller.graceful-fence.rpc-timeout.ms
Handling deprecation for mapreduce.tasktracker.local.dir.minspacekill
Handling deprecation for dfs.namenode.resource.du.reserved
Handling deprecation for mapreduce.jobhistory.cleaner.interval-ms
Handling deprecation for dfs.namenode.datanode.registration.ip-hostname-check
Handling deprecation for mapreduce.jobhistory.intermediate-done-dir
Handling deprecation for mapreduce.jobtracker.http.address
Handling deprecation for dfs.namenode.backup.http-address
Handling deprecation for dfs.namenode.edits.noeditlogchannelflush
Handling deprecation for mapreduce.reduce.shuffle.input.buffer.percent
Handling deprecation for mapreduce.map.maxattempts
Handling deprecation for yarn.http.policy
Handling deprecation for dfs.namenode.audit.loggers
Handling deprecation for hadoop.security.groups.cache.warn.after.ms
Handling deprecation for io.serializations
Handling deprecation for mapreduce.tasktracker.outofband.heartbeat
Handling deprecation for mapreduce.reduce.shuffle.read.timeout
Handling deprecation for hadoop.security.crypto.buffer.size
Handling deprecation for mapreduce.reduce.skip.proc.count.autoincr
Handling deprecation for mapreduce.ifile.readahead.bytes
Handling deprecation for dfs.http.policy
Handling deprecation for hadoop.registry.secure
Handling deprecation for dfs.namenode.safemode.min.datanodes
Handling deprecation for dfs.client.file-block-storage-locations.num-threads
Handling deprecation for mapreduce.cluster.local.dir
Handling deprecation for mapreduce.tasktracker.report.address
Handling deprecation for dfs.namenode.secondary.https-address
Handling deprecation for hadoop.kerberos.kinit.command
Handling deprecation for yarn.timeline-service.http-authentication.type
Handling deprecation for dfs.block.access.token.lifetime
Handling deprecation for dfs.webhdfs.enabled
Handling deprecation for dfs.namenode.delegation.token.max-lifetime
Handling deprecation for dfs.namenode.avoid.write.stale.datanode
Handling deprecation for dfs.datanode.drop.cache.behind.writes
Handling deprecation for yarn.log-aggregation.retain-seconds
Handling deprecation for mapreduce.job.complete.cancel.delegation.tokens
Handling deprecation for mapreduce.local.clientfactory.class.name
Handling deprecation for mapreduce.shuffle.connection-keep-alive.timeout
Handling deprecation for dfs.namenode.num.extra.edits.retained
Handling deprecation for yarn.scheduler.minimum-allocation-vcores
Handling deprecation for ipc.client.connect.max.retries.on.timeouts
Handling deprecation for yarn.timeline-service.client.retry-interval-ms
Handling deprecation for yarn.timeline-service.client.max-retries
Handling deprecation for fs.s3n.block.size
Handling deprecation for mapreduce.job.map.output.collector.class
Handling deprecation for ha.health-monitor.connect-retry-interval.ms
Handling deprecation for mapreduce.shuffle.max.threads
Handling deprecation for nfs.exports.allowed.hosts
Handling deprecation for dfs.client.mmap.cache.size
Handling deprecation for mapreduce.tasktracker.map.tasks.maximum
Handling deprecation for io.file.buffer.size
Handling deprecation for dfs.client.datanode-restart.timeout
Handling deprecation for io.mapfile.bloom.size
Handling deprecation for hadoop.security.kms.client.authentication.retry-count
Handling deprecation for dfs.namenode.checkpoint.txns
Handling deprecation for ipc.client.connect.retry.interval
Handling deprecation for dfs.client-write-packet-size
Handling deprecation for mapreduce.reduce.shuffle.connect.timeout
Handling deprecation for yarn.resourcemanager.fs.state-store.uri
Handling deprecation for fs.swift.impl
Handling deprecation for hadoop.registry.zk.connection.timeout.ms
Handling deprecation for mapred.queue.default.acl-administer-jobs
Handling deprecation for mapreduce.job.submithostaddress
Handling deprecation for dfs.cachereport.intervalMsec
Handling deprecation for yarn.app.mapreduce.shuffle.log.backups
Handling deprecation for yarn.app.mapreduce.am.container.log.limit.kb
Handling deprecation for yarn.nodemanager.resourcemanager.minimum.version
Handling deprecation for ftp.blocksize
Handling deprecation for yarn.resourcemanager.address
Handling deprecation for file.stream-buffer-size
Handling deprecation for yarn.resourcemanager.scheduler.monitor.enable
Handling deprecation for mapreduce.job.ubertask.maxreduces
Handling deprecation for nfs.allow.insecure.ports
Handling deprecation for yarn.sharedcache.nm.uploader.thread-count
Handling deprecation for ipc.client.idlethreshold
Handling deprecation for ftp.stream-buffer-size
Handling deprecation for yarn.sharedcache.client-server.address
Handling deprecation for dfs.client.failover.connection.retries.on.timeouts
Handling deprecation for dfs.namenode.replication.work.multiplier.per.iteration
Handling deprecation for hadoop.http.authentication.simple.anonymous.allowed
Handling deprecation for hadoop.security.authorization
Handling deprecation for yarn.client.nodemanager-connect.retry-interval-ms
Handling deprecation for yarn.am.liveness-monitor.expiry-interval-ms
Handling deprecation for fs.har.impl.disable.cache
Handling deprecation for yarn.nodemanager.linux-container-executor.resources-handler.class
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.read-cache-size
Handling deprecation for hadoop.security.authentication
Handling deprecation for dfs.image.compression.codec
Handling deprecation for mapreduce.task.files.preserve.failedtasks
Handling deprecation for dfs.client.read.shortcircuit.streams.cache.size
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.path
Handling deprecation for mapreduce.job.reduce.slowstart.completedmaps
Handling deprecation for mapreduce.jobhistory.minicluster.fixed.ports
Handling deprecation for file.replication
Handling deprecation for yarn.resourcemanager.ha.automatic-failover.enabled
Handling deprecation for mapreduce.job.userlog.retain.hours
Handling deprecation for mapreduce.jobhistory.joblist.cache.size
Handling deprecation for dfs.namenode.accesstime.precision
Handling deprecation for yarn.resourcemanager.work-preserving-recovery.enabled
Handling deprecation for dfs.namenode.fs-limits.max-xattrs-per-inode
Handling deprecation for io.mapfile.bloom.error.rate
Handling deprecation for yarn.resourcemanager.store.class
Handling deprecation for dfs.image.transfer.timeout
Handling deprecation for yarn.timeline-service.leveldb-state-store.path
Handling deprecation for nfs.wtmax
Handling deprecation for mapreduce.job.combine.class
Handling deprecation for dfs.namenode.support.allow.format
Handling deprecation for fs.s3a.multipart.purge
Handling deprecation for dfs.secondary.namenode.kerberos.internal.spnego.principal
Handling deprecation for fs.s3a.connection.establish.timeout
Handling deprecation for dfs.stream-buffer-size
Handling deprecation for dfs.namenode.invalidate.work.pct.per.iteration
Handling deprecation for yarn.nodemanager.container-executor.class
Handling deprecation for fs.s3a.multipart.purge.age
Handling deprecation for yarn.resourcemanager.scheduler.client.thread-count
Handling deprecation for dfs.namenode.top.enabled
Handling deprecation for yarn.app.mapreduce.shuffle.log.separate
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.low-watermark
Handling deprecation for fs.s3a.fast.buffer.size
Handling deprecation for hadoop.user.group.static.mapping.overrides
Handling deprecation for tfile.fs.input.buffer.size
Handling deprecation for dfs.client.cached.conn.retry
Handling deprecation for hadoop.http.authentication.type
Handling deprecation for dfs.namenode.list.encryption.zones.num.responses
Handling deprecation for mapreduce.map.cpu.vcores
Handling deprecation for dfs.namenode.path.based.cache.refresh.interval.ms
Handling deprecation for dfs.namenode.decommission.interval
Handling deprecation for dfs.namenode.fs-limits.max-directory-items
Handling deprecation for yarn.resourcemanager.zk-retry-interval-ms
Handling deprecation for ftp.bytes-per-checksum
Handling deprecation for dfs.ha.log-roll.period
Handling deprecation for dfs.user.home.dir.prefix
Handling deprecation for ipc.client.fallback-to-simple-auth-allowed
Handling deprecation for yarn.nodemanager.pmem-check-enabled
Handling deprecation for yarn.nodemanager.remote-app-log-dir
Handling deprecation for dfs.namenode.inotify.max.events.per.rpc
Handling deprecation for mapreduce.task.profile.maps
Handling deprecation for mapreduce.shuffle.ssl.file.buffer.size
Handling deprecation for mapreduce.tasktracker.healthchecker.script.timeout
Handling deprecation for yarn.timeline-service.webapp.https.address
Handling deprecation for yarn.nodemanager.resource.percentage-physical-cpu-limit
Handling deprecation for yarn.app.mapreduce.am.command-opts
Handling deprecation for dfs.namenode.fs-limits.max-xattr-size
Handling deprecation for dfs.datanode.http.address
Handling deprecation for dfs.namenode.blocks.per.postponedblocks.rescan
Handling deprecation for yarn.sharedcache.nm.uploader.replication.factor
Handling deprecation for hadoop.registry.zk.root
Handling deprecation for hadoop.jetty.logs.serve.aliases
Handling deprecation for yarn.client.failover-proxy-provider
Handling deprecation for mapreduce.jobhistory.admin.acl
Handling deprecation for yarn.app.mapreduce.am.hard-kill-timeout-ms
Handling deprecation for yarn.nodemanager.remote-app-log-dir-suffix
Handling deprecation for mapreduce.jobhistory.principal
Handling deprecation for yarn.resourcemanager.webapp.address
Handling deprecation for mapreduce.jobhistory.recovery.enable
Handling deprecation for yarn.sharedcache.store.in-memory.check-period-mins
Handling deprecation for nfs.mountd.port
Handling deprecation for mapreduce.reduce.merge.inmem.threshold
Handling deprecation for fs.df.interval
Handling deprecation for yarn.timeline-service.enabled
Handling deprecation for mapreduce.jobtracker.jobhistory.lru.cache.size
Handling deprecation for mapreduce.task.profile
Handling deprecation for mapreduce.job.output.key.class
Handling deprecation for yarn.nodemanager.hostname
Handling deprecation for dfs.namenode.num.checkpoints.retained
Handling deprecation for mapreduce.job.queuename
Handling deprecation for mapreduce.jobhistory.max-age-ms
Handling deprecation for mapreduce.job.token.tracking.ids.enabled
Handling deprecation for yarn.nodemanager.localizer.client.thread-count
Handling deprecation for yarn.sharedcache.uploader.server.thread-count
Handling deprecation for dfs.client.mmap.retry.timeout.ms
Handling deprecation for mapreduce.jobhistory.move.thread-count
Handling deprecation for dfs.permissions.enabled
Handling deprecation for dfs.blockreport.split.threshold
Handling deprecation for fs.AbstractFileSystem.hdfs.impl
Handling deprecation for dfs.datanode.balance.bandwidthPerSec
Handling deprecation for dfs.block.scanner.volume.bytes.per.second
Handling deprecation for hadoop.http.filter.initializers
Handling deprecation for yarn.timeline-service.http-authentication.simple.anonymous.allowed
Handling deprecation for dfs.default.chunk.view.size
Handling deprecation for yarn.sharedcache.client-server.thread-count
Handling deprecation for yarn.resourcemanager.resource-tracker.address
Handling deprecation for mapreduce.job.working.dir
Handling deprecation for mapreduce.jobhistory.datestring.cache.size
Handling deprecation for mapreduce.task.profile.params
Handling deprecation for dfs.namenode.decommission.blocks.per.interval
Handling deprecation for dfs.namenode.handler.count
Handling deprecation for dfs.image.transfer.bandwidthPerSec
Handling deprecation for rpc.metrics.quantile.enable
Handling deprecation for mapreduce.jobtracker.expire.trackers.interval
Handling deprecation for mapreduce.task.timeout
Handling deprecation for yarn.app.mapreduce.client.max-retries
Handling deprecation for yarn.nodemanager.resource.memory-mb
Handling deprecation for yarn.nodemanager.disk-health-checker.min-healthy-disks
Handling deprecation for dfs.datanode.failed.volumes.tolerated
Handling deprecation for yarn.timeline-service.handler-thread-count
Handling deprecation for ipc.server.listen.queue.size
Handling deprecation for fs.s3a.threads.max
Handling deprecation for yarn.resourcemanager.connect.max-wait.ms
Handling deprecation for mapreduce.fileoutputcommitter.algorithm.version
Handling deprecation for mapreduce.framework.name
Handling deprecation for mapreduce.map.skip.proc.count.autoincr
Handling deprecation for mapreduce.job.max.split.locations
Handling deprecation for yarn.resourcemanager.scheduler.class
Handling deprecation for yarn.resourcemanager.system-metrics-publisher.enabled
Handling deprecation for dfs.blocksize
Handling deprecation for yarn.sharedcache.nested-level
Handling deprecation for mapreduce.shuffle.connection-keep-alive.enable
Handling deprecation for fs.s3a.threads.keepalivetime
Handling deprecation for fs.s3a.connection.timeout
Handling deprecation for file.client-write-packet-size
Handling deprecation for ha.failover-controller.cli-check.rpc-timeout.ms
Handling deprecation for ha.zookeeper.acl
Handling deprecation for dfs.namenode.write.stale.datanode.ratio
Handling deprecation for dfs.encrypt.data.transfer
Handling deprecation for dfs.datanode.shared.file.descriptor.paths
Handling deprecation for mapreduce.input.lineinputformat.linespermap
Handling deprecation for yarn.resourcemanager.delayed.delegation-token.removal-interval-ms
Handling deprecation for yarn.nodemanager.localizer.fetch.thread-count
Handling deprecation for dfs.client.failover.max.attempts
Handling deprecation for yarn.resourcemanager.scheduler.address
Handling deprecation for dfs.client.read.shortcircuit.streams.cache.expiry.ms
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.start-time-write-cache-size
Handling deprecation for yarn.nodemanager.health-checker.script.timeout-ms
Handling deprecation for yarn.resourcemanager.fs.state-store.num-retries
Handling deprecation for hadoop.ssl.require.client.cert
Handling deprecation for hadoop.security.uid.cache.secs
Handling deprecation for mapreduce.jobhistory.keytab
Handling deprecation for dfs.client.read.shortcircuit.skip.checksum
Handling deprecation for yarn.resourcemanager.ha.automatic-failover.zk-base-path
Handling deprecation for mapreduce.shuffle.ssl.enabled
Handling deprecation for mapreduce.reduce.log.level
Handling deprecation for hadoop.registry.rm.enabled
Handling deprecation for mapreduce.tasktracker.dns.interface
Handling deprecation for yarn.resourcemanager.system-metrics-publisher.dispatcher.pool-size
Handling deprecation for mapreduce.job.speculative.speculative-cap-running-tasks
Handling deprecation for dfs.datanode.block.id.layout.upgrade.threads
Handling deprecation for dfs.datanode.use.datanode.hostname
Handling deprecation for dfs.client.context
Handling deprecation for yarn.resourcemanager.ha.enabled
Handling deprecation for mapred.reducer.new-api
Handling deprecation for dfs.namenode.delegation.token.renew-interval
Handling deprecation for dfs.blockreport.intervalMsec
Handling deprecation for fs.s3a.multipart.threshold
Handling deprecation for mapreduce.reduce.shuffle.memory.limit.percent
Handling deprecation for dfs.https.server.keystore.resource
Handling deprecation for io.map.index.skip
Handling deprecation for mapreduce.job.hdfs-servers
Handling deprecation for mapreduce.jobtracker.taskscheduler
Handling deprecation for dfs.namenode.kerberos.internal.spnego.principal
Handling deprecation for yarn.resourcemanager.state-store.max-completed-applications
Handling deprecation for mapreduce.map.output.compress
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.num.refill.threads
Handling deprecation for fs.s3n.multipart.uploads.block.size
Handling deprecation for mapreduce.task.merge.progress.records
Handling deprecation for dfs.datanode.dns.interface
Handling deprecation for map.sort.class
Handling deprecation for yarn.nodemanager.aux-services.mapreduce_shuffle.class
Handling deprecation for tfile.fs.output.buffer.size
Handling deprecation for fs.du.interval
Handling deprecation for dfs.client.failover.connection.retries
Handling deprecation for dfs.namenode.top.window.num.buckets
Handling deprecation for mapreduce.job.dir
Handling deprecation for fs.s3a.buffer.dir
Handling deprecation for mapreduce.reduce.shuffle.retry-delay.max.ms
Handling deprecation for yarn.sharedcache.uploader.server.address
Handling deprecation for mapreduce.client.progressmonitor.pollinterval
Handling deprecation for yarn.app.mapreduce.shuffle.log.limit.kb
Handling deprecation for dfs.datanode.max.locked.memory
Handling deprecation for dfs.namenode.retrycache.expirytime.millis
Handling deprecation for dfs.datanode.scan.period.hours
Handling deprecation for dfs.client.block.write.replace-datanode-on-failure.best-effort
Handling deprecation for mapreduce.jobhistory.move.interval-ms
Handling deprecation for dfs.ha.fencing.ssh.connect-timeout
Handling deprecation for yarn.nodemanager.log-aggregation.roll-monitoring-interval-seconds
Handling deprecation for dfs.namenode.fs-limits.max-component-length
Handling deprecation for hadoop.registry.zk.quorum
Handling deprecation for dfs.namenode.enable.retrycache
Handling deprecation for dfs.datanode.du.reserved
Handling deprecation for yarn.timeline-service.state-store-class
Handling deprecation for dfs.datanode.ipc.address
Handling deprecation for hadoop.registry.system.acls
Handling deprecation for dfs.client.block.write.replace-datanode-on-failure.policy
Handling deprecation for dfs.namenode.path.based.cache.retry.interval.ms
Handling deprecation for hadoop.security.crypto.cipher.suite
Handling deprecation for dfs.ha.tail-edits.period
Handling deprecation for mapreduce.task.profile.reduce.params
Handling deprecation for hadoop.registry.jaas.context
Handling deprecation for yarn.resourcemanager.hostname
Handling deprecation for mapreduce.reduce.memory.mb
Handling deprecation for hadoop.security.group.mapping.ldap.search.filter.group
Handling deprecation for hadoop.http.authentication.kerberos.principal
Handling deprecation for hadoop.security.group.mapping.ldap.search.filter.user
Handling deprecation for yarn.nodemanager.disk-health-checker.min-free-space-per-disk-mb
Handling deprecation for dfs.namenode.edits.dir
Handling deprecation for yarn.client.failover-retries-on-socket-timeouts
Handling deprecation for dfs.namenode.decommission.max.concurrent.tracked.nodes
Handling deprecation for mapreduce.client.completion.pollinterval
Handling deprecation for dfs.namenode.name.dir.restore
Handling deprecation for dfs.namenode.secondary.http-address
Handling deprecation for mapreduce.jobhistory.recovery.store.leveldb.path
Handling deprecation for yarn.sharedcache.store.class
Handling deprecation for s3.bytes-per-checksum
Handling deprecation for yarn.nodemanager.windows-container.cpu-limit.enabled
Handling deprecation for yarn.resourcemanager.webapp.https.address
Handling deprecation for yarn.nodemanager.vmem-pmem-ratio
Handling deprecation for dfs.namenode.checkpoint.period
Handling deprecation for dfs.ha.automatic-failover.enabled
Submitting tokens for job: job_local633002303_0003
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.fs.FileContext.getAbstractFileSystem(FileContext.java:331)
Handling deprecation for all properties in config...
Handling deprecation for mapreduce.jobtracker.address
Handling deprecation for yarn.resourcemanager.scheduler.monitor.policies
Handling deprecation for dfs.namenode.resource.check.interval
Handling deprecation for mapreduce.jobhistory.client.thread-count
Handling deprecation for yarn.app.mapreduce.am.containerlauncher.threadpool-initial-size
Handling deprecation for mapred.child.java.opts
Handling deprecation for mapreduce.jobtracker.retiredjobs.cache.size
Handling deprecation for dfs.client.https.need-auth
Handling deprecation for yarn.admin.acl
Handling deprecation for yarn.app.mapreduce.am.job.committer.cancel-timeout
Handling deprecation for mapreduce.job.emit-timeline-data
Handling deprecation for fs.ftp.host.port
Handling deprecation for dfs.namenode.avoid.read.stale.datanode
Handling deprecation for dfs.journalnode.rpc-address
Handling deprecation for mapreduce.job.end-notification.retry.attempts
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.ttl-interval-ms
Handling deprecation for yarn.resourcemanager.leveldb-state-store.path
Handling deprecation for mapred.mapper.new-api
Handling deprecation for yarn.ipc.rpc.class
Handling deprecation for ipc.client.connection.maxidletime
Handling deprecation for yarn.nodemanager.process-kill-wait.ms
Handling deprecation for mapreduce.cluster.acls.enabled
Handling deprecation for mapreduce.jobtracker.handler.count
Handling deprecation for io.map.index.interval
Handling deprecation for dfs.namenode.https-address
Handling deprecation for mapreduce.task.profile.reduces
Handling deprecation for fs.s3n.multipart.uploads.enabled
Handling deprecation for io.seqfile.sorter.recordlimit
Handling deprecation for mapreduce.job.ubertask.maxmaps
Handling deprecation for mapreduce.tasktracker.tasks.sleeptimebeforesigkill
Handling deprecation for hadoop.util.hash.type
Handling deprecation for dfs.namenode.replication.min
Handling deprecation for yarn.nodemanager.container-manager.thread-count
Handling deprecation for mapreduce.jobtracker.jobhistory.block.size
Handling deprecation for dfs.namenode.fs-limits.min-block-size
Handling deprecation for mapreduce.app-submission.cross-platform
Handling deprecation for fs.AbstractFileSystem.file.impl
Handling deprecation for net.topology.script.number.args
Handling deprecation for yarn.resourcemanager.container-tokens.master-key-rolling-interval-secs
Handling deprecation for mapreduce.map.output.compress.codec
Handling deprecation for mapreduce.job.reducer.preempt.delay.sec
Handling deprecation for s3native.bytes-per-checksum
Handling deprecation for dfs.namenode.path.based.cache.block.map.allocation.percent
Handling deprecation for yarn.nodemanager.windows-container.memory-limit.enabled
Handling deprecation for mapreduce.input.fileinputformat.split.minsize
Handling deprecation for hadoop.security.group.mapping
Handling deprecation for mapreduce.jobtracker.system.dir
Handling deprecation for mapreduce.job.end-notification.max.attempts
Handling deprecation for mapreduce.reduce.markreset.buffer.percent
Handling deprecation for dfs.datanode.cache.revocation.polling.ms
Handling deprecation for mapreduce.reduce.speculative
Handling deprecation for yarn.nodemanager.localizer.cache.cleanup.interval-ms
Handling deprecation for dfs.namenode.lazypersist.file.scrub.interval.sec
Handling deprecation for fs.s3a.threads.core
Handling deprecation for mapreduce.jobhistory.recovery.store.fs.uri
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.start-time-read-cache-size
Handling deprecation for hadoop.registry.zk.retry.interval.ms
Handling deprecation for yarn.nodemanager.keytab
Handling deprecation for dfs.namenode.replication.interval
Handling deprecation for yarn.resourcemanager.admin.address
Handling deprecation for mapreduce.job.maps
Handling deprecation for nfs.dump.dir
Handling deprecation for mapreduce.job.user.name
Handling deprecation for mapreduce.jobtracker.maxtasks.perjob
Handling deprecation for mapreduce.job.ubertask.enable
Handling deprecation for mapreduce.job.reduce.class
Handling deprecation for yarn.nodemanager.delete.debug-delay-sec
Handling deprecation for yarn.timeline-service.ttl-enable
Handling deprecation for yarn.resourcemanager.fs.state-store.retry-policy-spec
Handling deprecation for mapreduce.reduce.skip.maxgroups
Handling deprecation for dfs.client.use.datanode.hostname
Handling deprecation for fs.trash.interval
Handling deprecation for mapreduce.job.name
Handling deprecation for mapreduce.am.max-attempts
Handling deprecation for mapreduce.jobtracker.heartbeats.in.second
Handling deprecation for yarn.resourcemanager.zk-num-retries
Handling deprecation for s3.blocksize
Handling deprecation for dfs.datanode.data.dir
Handling deprecation for mapreduce.jobtracker.persist.jobstatus.active
Handling deprecation for mapreduce.reduce.shuffle.parallelcopies
Handling deprecation for fs.s3.buffer.dir
Handling deprecation for mapreduce.jobhistory.done-dir
Handling deprecation for hadoop.security.instrumentation.requires.admin
Handling deprecation for hadoop.registry.zk.retry.ceiling.ms
Handling deprecation for nfs.rtmax
Handling deprecation for dfs.datanode.data.dir.perm
Handling deprecation for yarn.resourcemanager.container.liveness-monitor.interval-ms
Handling deprecation for yarn.nodemanager.env-whitelist
Handling deprecation for dfs.namenode.backup.address
Handling deprecation for dfs.namenode.xattrs.enabled
Handling deprecation for dfs.datanode.readahead.bytes
Handling deprecation for mapreduce.jobhistory.cleaner.enable
Handling deprecation for dfs.client.block.write.retries
Handling deprecation for mapreduce.tasktracker.http.address
Handling deprecation for yarn.nodemanager.linux-container-executor.cgroups.hierarchy
Handling deprecation for ha.failover-controller.graceful-fence.connection.retries
Handling deprecation for yarn.resourcemanager.recovery.enabled
Handling deprecation for yarn.app.mapreduce.am.container.log.backups
Handling deprecation for dfs.namenode.safemode.threshold-pct
Handling deprecation for yarn.nodemanager.disk-health-checker.interval-ms
Handling deprecation for hadoop.security.java.secure.random.algorithm
Handling deprecation for dfs.namenode.list.cache.directives.num.responses
Handling deprecation for dfs.datanode.dns.nameserver
Handling deprecation for mapreduce.cluster.temp.dir
Handling deprecation for fs.s3a.max.total.tasks
Handling deprecation for mapreduce.reduce.maxattempts
Handling deprecation for mapreduce.client.submit.file.replication
Handling deprecation for mapreduce.shuffle.port
Handling deprecation for yarn.resourcemanager.resource-tracker.client.thread-count
Handling deprecation for dfs.namenode.replication.considerLoad
Handling deprecation for dfs.namenode.edits.journal-plugin.qjournal
Handling deprecation for dfs.client.write.exclude.nodes.cache.expiry.interval.millis
Handling deprecation for yarn.nodemanager.delete.thread-count
Handling deprecation for dfs.client.mmap.cache.timeout.ms
Handling deprecation for yarn.nodemanager.admin-env
Handling deprecation for io.skip.checksum.errors
Handling deprecation for yarn.timeline-service.hostname
Handling deprecation for yarn.resourcemanager.proxy-user-privileges.enabled
Handling deprecation for mapreduce.job.speculative.speculative-cap-total-tasks
Handling deprecation for yarn.acl.enable
Handling deprecation for fs.s3a.fast.upload
Handling deprecation for file.blocksize
Handling deprecation for mapreduce.job.speculative.slowtaskthreshold
Handling deprecation for ftp.replication
Handling deprecation for yarn.sharedcache.cleaner.initial-delay-mins
Handling deprecation for s3native.client-write-packet-size
Handling deprecation for hadoop.rpc.socket.factory.class.default
Handling deprecation for file.bytes-per-checksum
Handling deprecation for dfs.datanode.slow.io.warning.threshold.ms
Handling deprecation for io.seqfile.lazydecompress
Handling deprecation for mapreduce.task.skip.start.attempts
Handling deprecation for dfs.namenode.reject-unresolved-dn-topology-mapping
Handling deprecation for hadoop.common.configuration.version
Handling deprecation for yarn.resourcemanager.client.thread-count
Handling deprecation for dfs.datanode.drop.cache.behind.reads
Handling deprecation for yarn.sharedcache.admin.address
Handling deprecation for mapreduce.job.output.value.class
Handling deprecation for mapreduce.output.fileoutputformat.outputdir
Handling deprecation for mapreduce.jobtracker.taskcache.levels
Handling deprecation for yarn.nodemanager.linux-container-executor.nonsecure-mode.user-pattern
Handling deprecation for yarn.resourcemanager.zk-timeout-ms
Handling deprecation for yarn.resourcemanager.max-completed-applications
Handling deprecation for mapreduce.job.jvm.numtasks
Handling deprecation for yarn.sharedcache.cleaner.period-mins
Handling deprecation for mapreduce.jobtracker.tasktracker.maxblacklists
Handling deprecation for dfs.namenode.top.num.users
Handling deprecation for yarn.nodemanager.linux-container-executor.cgroups.mount
Handling deprecation for yarn.sharedcache.checksum.algo.impl
Handling deprecation for mapreduce.job.end-notification.max.retry.interval
Handling deprecation for mapreduce.job.acl-view-job
Handling deprecation for mapreduce.job.classloader
Handling deprecation for yarn.log-aggregation-enable
Handling deprecation for mapreduce.reduce.shuffle.fetch.retry.interval-ms
Handling deprecation for yarn.resourcemanager.nodemanager.minimum.version
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.size
Handling deprecation for yarn.app.mapreduce.am.job.task.listener.thread-count
Handling deprecation for yarn.app.mapreduce.am.resource.cpu-vcores
Handling deprecation for dfs.namenode.edit.log.autoroll.check.interval.ms
Handling deprecation for mapreduce.output.fileoutputformat.compress.type
Handling deprecation for hadoop.hdfs.configuration.version
Handling deprecation for hadoop.security.group.mapping.ldap.search.attr.member
Handling deprecation for yarn.nodemanager.log.retain-seconds
Handling deprecation for yarn.nodemanager.local-cache.max-files-per-directory
Handling deprecation for mapreduce.job.end-notification.retry.interval
Handling deprecation for hadoop.ssl.client.conf
Handling deprecation for yarn.sharedcache.root-dir
Handling deprecation for dfs.journalnode.https-address
Handling deprecation for mapreduce.reduce.shuffle.fetch.retry.timeout-ms
Handling deprecation for dfs.bytes-per-checksum
Handling deprecation for dfs.namenode.max.objects
Handling deprecation for mapreduce.tasktracker.instrumentation
Handling deprecation for dfs.datanode.max.transfer.threads
Handling deprecation for dfs.block.access.key.update.interval
Handling deprecation for mapreduce.jobtracker.jobhistory.task.numberprogresssplits
Handling deprecation for mapreduce.map.memory.mb
Handling deprecation for ha.failover-controller.new-active.rpc-timeout.ms
Handling deprecation for hadoop.ssl.hostname.verifier
Handling deprecation for dfs.client.read.shortcircuit
Handling deprecation for dfs.datanode.hdfs-blocks-metadata.enabled
Handling deprecation for mapreduce.tasktracker.healthchecker.interval
Handling deprecation for dfs.image.transfer.chunksize
Handling deprecation for mapreduce.tasktracker.taskmemorymanager.monitoringinterval
Handling deprecation for dfs.client.https.keystore.resource
Handling deprecation for yarn.resourcemanager.connect.retry-interval.ms
Handling deprecation for yarn.timeline-service.webapp.address
Handling deprecation for s3native.blocksize
Handling deprecation for yarn.scheduler.minimum-allocation-mb
Handling deprecation for yarn.sharedcache.cleaner.resource-sleep-ms
Handling deprecation for net.topology.impl
Handling deprecation for dfs.client.failover.sleep.base.millis
Handling deprecation for dfs.permissions.superusergroup
Handling deprecation for io.seqfile.compress.blocksize
Handling deprecation for hadoop.registry.zk.retry.times
Handling deprecation for fs.AbstractFileSystem.ftp.impl
Handling deprecation for dfs.namenode.checkpoint.edits.dir
Handling deprecation for mapreduce.job.running.reduce.limit
Handling deprecation for dfs.blockreport.initialDelay
Handling deprecation for dfs.namenode.heartbeat.recheck-interval
Handling deprecation for dfs.namenode.safemode.extension
Handling deprecation for yarn.scheduler.maximum-allocation-mb
Handling deprecation for mapreduce.job.reduce.shuffle.consumer.plugin.class
Handling deprecation for yarn.nodemanager.vmem-check-enabled
Handling deprecation for mapreduce.task.io.sort.factor
Handling deprecation for mapreduce.jobtracker.persist.jobstatus.dir
Handling deprecation for dfs.client.failover.sleep.max.millis
Handling deprecation for dfs.namenode.delegation.key.update-interval
Handling deprecation for hadoop.rpc.protection
Handling deprecation for fs.permissions.umask-mode
Handling deprecation for fs.s3.sleepTimeSeconds
Handling deprecation for ha.health-monitor.rpc-timeout.ms
Handling deprecation for hadoop.http.staticuser.user
Handling deprecation for fs.s3a.connection.maximum
Handling deprecation for yarn.nodemanager.linux-container-executor.nonsecure-mode.limit-users
Handling deprecation for fs.s3a.paging.maximum
Handling deprecation for fs.AbstractFileSystem.viewfs.impl
Handling deprecation for fs.ftp.host
Handling deprecation for yarn.nodemanager.linux-container-executor.nonsecure-mode.local-user
Handling deprecation for fs.s3a.impl
Handling deprecation for hadoop.http.authentication.kerberos.keytab
Handling deprecation for dfs.namenode.fs-limits.max-blocks-per-file
Handling deprecation for mapreduce.tasktracker.http.threads
Handling deprecation for mapreduce.tasktracker.dns.nameserver
Handling deprecation for yarn.resourcemanager.am-rm-tokens.master-key-rolling-interval-secs
Handling deprecation for dfs.client.block.write.replace-datanode-on-failure.enable
Handling deprecation for io.compression.codec.bzip2.library
Handling deprecation for mapreduce.map.skip.maxrecords
Handling deprecation for dfs.client.use.legacy.blockreader.local
Handling deprecation for dfs.namenode.checkpoint.dir
Handling deprecation for dfs.namenode.top.windows.minutes
Handling deprecation for mapreduce.job.maxtaskfailures.per.tracker
Handling deprecation for net.topology.node.switch.mapping.impl
Handling deprecation for mapreduce.shuffle.max.connections
Handling deprecation for mapreduce.jobhistory.loadedjobs.cache.size
Handling deprecation for dfs.storage.policy.enabled
Handling deprecation for yarn.client.application-client-protocol.poll-interval-ms
Handling deprecation for yarn.nodemanager.localizer.address
Handling deprecation for dfs.namenode.list.cache.pools.num.responses
Handling deprecation for nfs.server.port
Handling deprecation for mapreduce.client.output.filter
Handling deprecation for yarn.timeline-service.client.best-effort
Handling deprecation for ha.zookeeper.parent-znode
Handling deprecation for mapreduce.jobtracker.persist.jobstatus.hours
Handling deprecation for yarn.sharedcache.admin.thread-count
Handling deprecation for yarn.nodemanager.resource.cpu-vcores
Handling deprecation for dfs.datanode.block-pinning.enabled
Handling deprecation for mapreduce.jobhistory.http.policy
Handling deprecation for yarn.resourcemanager.webapp.delegation-token-auth-filter.enabled
Handling deprecation for mapreduce.job.speculative.retry-after-no-speculate
Handling deprecation for fs.s3a.attempts.maximum
Handling deprecation for s3native.stream-buffer-size
Handling deprecation for io.seqfile.local.dir
Handling deprecation for yarn.log-aggregation.retain-check-interval-seconds
Handling deprecation for fs.s3n.multipart.copy.block.size
Handling deprecation for dfs.encrypt.data.transfer.cipher.key.bitlength
Handling deprecation for dfs.datanode.sync.behind.writes
Handling deprecation for yarn.resourcemanager.zk-acl
Handling deprecation for hadoop.ssl.keystores.factory.class
Handling deprecation for mapreduce.job.split.metainfo.maxsize
Handling deprecation for fs.s3.maxRetries
Handling deprecation for hadoop.security.random.device.file.path
Handling deprecation for yarn.client.nodemanager-connect.max-wait-ms
Handling deprecation for dfs.namenode.stale.datanode.interval
Handling deprecation for mapreduce.task.io.sort.mb
Handling deprecation for yarn.resourcemanager.zk-state-store.parent-path
Handling deprecation for yarn.app.mapreduce.client-am.ipc.max-retries
Handling deprecation for fs.client.resolve.remote.symlinks
Handling deprecation for yarn.nodemanager.linux-container-executor.cgroups.strict-resource-usage
Handling deprecation for hadoop.ssl.enabled.protocols
Handling deprecation for mapreduce.reduce.cpu.vcores
Handling deprecation for yarn.client.failover-retries
Handling deprecation for mapreduce.jobhistory.address
Handling deprecation for hadoop.ssl.enabled
Handling deprecation for dfs.replication.max
Handling deprecation for dfs.namenode.name.dir
Handling deprecation for dfs.datanode.https.address
Handling deprecation for ipc.client.kill.max
Handling deprecation for mapreduce.job.committer.setup.cleanup.needed
Handling deprecation for dfs.client.domain.socket.data.traffic
Handling deprecation for yarn.nodemanager.localizer.cache.target-size-mb
Handling deprecation for yarn.resourcemanager.admin.client.thread-count
Handling deprecation for dfs.block.access.token.enable
Handling deprecation for mapreduce.job.speculative.retry-after-speculate
Handling deprecation for dfs.datanode.address
Handling deprecation for mapreduce.jobtracker.restart.recover
Handling deprecation for ipc.client.connect.max.retries
Handling deprecation for yarn.timeline-service.store-class
Handling deprecation for dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
Handling deprecation for hadoop.tmp.dir
Handling deprecation for dfs.datanode.handler.count
Handling deprecation for yarn.resourcemanager.ha.automatic-failover.embedded
Handling deprecation for yarn.timeline-service.ttl-ms
Handling deprecation for mapreduce.task.profile.map.params
Handling deprecation for yarn.resourcemanager.nodemanagers.heartbeat-interval-ms
Handling deprecation for mapreduce.map.speculative
Handling deprecation for yarn.timeline-service.recovery.enabled
Handling deprecation for mapreduce.job.map.class
Handling deprecation for dfs.namenode.resource.checked.volumes.minimum
Handling deprecation for yarn.nodemanager.recovery.dir
Handling deprecation for mapreduce.job.counters.max
Handling deprecation for yarn.resourcemanager.keytab
Handling deprecation for dfs.namenode.max.extra.edits.segments.retained
Handling deprecation for dfs.webhdfs.user.provider.user.pattern
Handling deprecation for dfs.client.mmap.enabled
Handling deprecation for mapreduce.map.log.level
Handling deprecation for dfs.client.file-block-storage-locations.timeout.millis
Handling deprecation for yarn.client.max-cached-nodemanagers-proxies
Handling deprecation for yarn.app.mapreduce.am.scheduler.heartbeat.interval-ms
Handling deprecation for hadoop.fuse.timer.period
Handling deprecation for fs.trash.checkpoint.interval
Handling deprecation for yarn.sharedcache.app-checker.class
Handling deprecation for dfs.journalnode.http-address
Handling deprecation for yarn.app.mapreduce.am.staging-dir
Handling deprecation for mapreduce.tasktracker.local.dir.minspacestart
Handling deprecation for yarn.nm.liveness-monitor.expiry-interval-ms
Handling deprecation for ha.health-monitor.check-interval.ms
Handling deprecation for mapreduce.reduce.shuffle.merge.percent
Handling deprecation for dfs.namenode.retrycache.heap.percent
Handling deprecation for yarn.nodemanager.docker-container-executor.exec-name
Handling deprecation for ipc.client.connect.timeout
Handling deprecation for yarn.resourcemanager.fs.state-store.retry-interval-ms
Handling deprecation for mapreduce.output.fileoutputformat.compress
Handling deprecation for yarn.nodemanager.local-dirs
Handling deprecation for yarn.nodemanager.recovery.enabled
Handling deprecation for io.native.lib.available
Handling deprecation for yarn.sharedcache.store.in-memory.staleness-period-mins
Handling deprecation for yarn.resourcemanager.am.max-attempts
Handling deprecation for s3.replication
Handling deprecation for mapreduce.input.fileinputformat.inputdir
Handling deprecation for fs.AbstractFileSystem.har.impl
Handling deprecation for dfs.image.compress
Handling deprecation for mapreduce.job.running.map.limit
Handling deprecation for mapreduce.reduce.input.buffer.percent
Handling deprecation for yarn.nodemanager.webapp.address
Handling deprecation for dfs.datanode.available-space-volume-choosing-policy.balanced-space-preference-fraction
Handling deprecation for dfs.namenode.edit.log.autoroll.multiplier.threshold
Handling deprecation for hadoop.security.group.mapping.ldap.ssl
Handling deprecation for dfs.namenode.checkpoint.check.period
Handling deprecation for fs.defaultFS
Handling deprecation for fs.s3a.multipart.size
Handling deprecation for dfs.client.slow.io.warning.threshold.ms
Handling deprecation for yarn.app.mapreduce.am.job.committer.commit-window
Handling deprecation for hadoop.security.group.mapping.ldap.search.attr.group.name
Handling deprecation for yarn.nodemanager.disk-health-checker.max-disk-utilization-per-disk-percentage
Handling deprecation for yarn.nodemanager.container-monitor.procfs-tree.smaps-based-rss.enabled
Handling deprecation for mapreduce.job.submithostname
Handling deprecation for mapreduce.map.sort.spill.percent
Handling deprecation for hadoop.security.crypto.codec.classes.aes.ctr.nopadding
Handling deprecation for dfs.namenode.http-address
Handling deprecation for hadoop.security.groups.negative-cache.secs
Handling deprecation for hadoop.ssl.server.conf
Handling deprecation for mapreduce.ifile.readahead
Handling deprecation for s3native.replication
Handling deprecation for yarn.client.nodemanager-client-async.thread-pool-max-size
Handling deprecation for mapreduce.jobtracker.staging.root.dir
Handling deprecation for mapreduce.jobhistory.admin.address
Handling deprecation for dfs.namenode.startup.delay.block.deletion.sec
Handling deprecation for yarn.nodemanager.health-checker.interval-ms
Handling deprecation for dfs.namenode.checkpoint.max-retries
Handling deprecation for s3.stream-buffer-size
Handling deprecation for ftp.client-write-packet-size
Handling deprecation for dfs.datanode.fsdatasetcache.max.threads.per.volume
Handling deprecation for mapreduce.output.fileoutputformat.compress.codec
Handling deprecation for yarn.timeline-service.keytab
Handling deprecation for yarn.sharedcache.store.in-memory.initial-delay-mins
Handling deprecation for mapreduce.jobhistory.webapp.address
Handling deprecation for mapreduce.task.userlog.limit.kb
Handling deprecation for mapreduce.reduce.shuffle.fetch.retry.enabled
Handling deprecation for yarn.app.mapreduce.task.container.log.backups
Handling deprecation for dfs.heartbeat.interval
Handling deprecation for ha.zookeeper.session-timeout.ms
Handling deprecation for fs.s3a.connection.ssl.enabled
Handling deprecation for yarn.sharedcache.webapp.address
Handling deprecation for hadoop.http.authentication.signature.secret.file
Handling deprecation for hadoop.fuse.connection.timeout
Handling deprecation for mapreduce.input.fileinputformat.numinputfiles
Handling deprecation for yarn.nodemanager.log-aggregation.compression-type
Handling deprecation for ipc.server.max.connections
Handling deprecation for yarn.resourcemanager.work-preserving-recovery.scheduling-wait-ms
Handling deprecation for yarn.nodemanager.log-dirs
Handling deprecation for yarn.app.mapreduce.am.resource.mb
Handling deprecation for hadoop.security.groups.cache.secs
Handling deprecation for mapreduce.job.speculative.minimum-allowed-tasks
Handling deprecation for yarn.nodemanager.container-monitor.interval-ms
Handling deprecation for dfs.datanode.cache.revocation.timeout.ms
Handling deprecation for mapreduce.jobhistory.recovery.store.class
Handling deprecation for mapreduce.task.combine.progress.records
Handling deprecation for s3.client-write-packet-size
Handling deprecation for mapreduce.jobtracker.instrumentation
Handling deprecation for dfs.replication
Handling deprecation for mapreduce.shuffle.transfer.buffer.size
Handling deprecation for hadoop.security.group.mapping.ldap.directory.search.timeout
Handling deprecation for dfs.datanode.available-space-volume-choosing-policy.balanced-space-threshold
Handling deprecation for hadoop.work.around.non.threadsafe.getpwuid
Handling deprecation for yarn.app.mapreduce.client-am.ipc.max-retries-on-timeouts
Handling deprecation for yarn.nodemanager.address
Handling deprecation for mapreduce.tasktracker.taskcontroller
Handling deprecation for mapreduce.tasktracker.indexcache.mb
Handling deprecation for yarn.scheduler.maximum-allocation-vcores
Handling deprecation for mapreduce.job.reduces
Handling deprecation for yarn.nodemanager.sleep-delay-before-sigkill.ms
Handling deprecation for yarn.timeline-service.address
Handling deprecation for yarn.resourcemanager.configuration.provider-class
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.expiry
Handling deprecation for yarn.sharedcache.enabled
Handling deprecation for tfile.io.chunk.size
Handling deprecation for mapreduce.job.acl-modify-job
Handling deprecation for hadoop.registry.zk.session.timeout.ms
Handling deprecation for fs.automatic.close
Handling deprecation for ha.health-monitor.sleep-after-disconnect.ms
Handling deprecation for mapreduce.tasktracker.reduce.tasks.maximum
Handling deprecation for mapreduce.input.fileinputformat.list-status.num-threads
Handling deprecation for dfs.datanode.directoryscan.threads
Handling deprecation for dfs.datanode.directoryscan.interval
Handling deprecation for dfs.namenode.acls.enabled
Handling deprecation for dfs.client.short.circuit.replica.stale.threshold.ms
Handling deprecation for hadoop.http.authentication.token.validity
Handling deprecation for fs.s3.block.size
Handling deprecation for ha.failover-controller.graceful-fence.rpc-timeout.ms
Handling deprecation for mapreduce.tasktracker.local.dir.minspacekill
Handling deprecation for dfs.namenode.resource.du.reserved
Handling deprecation for mapreduce.jobhistory.cleaner.interval-ms
Handling deprecation for dfs.namenode.datanode.registration.ip-hostname-check
Handling deprecation for mapreduce.jobhistory.intermediate-done-dir
Handling deprecation for mapreduce.jobtracker.http.address
Handling deprecation for dfs.namenode.backup.http-address
Handling deprecation for dfs.namenode.edits.noeditlogchannelflush
Handling deprecation for mapreduce.reduce.shuffle.input.buffer.percent
Handling deprecation for mapreduce.map.maxattempts
Handling deprecation for yarn.http.policy
Handling deprecation for dfs.namenode.audit.loggers
Handling deprecation for hadoop.security.groups.cache.warn.after.ms
Handling deprecation for io.serializations
Handling deprecation for mapreduce.tasktracker.outofband.heartbeat
Handling deprecation for mapreduce.reduce.shuffle.read.timeout
Handling deprecation for hadoop.security.crypto.buffer.size
Handling deprecation for mapreduce.reduce.skip.proc.count.autoincr
Handling deprecation for mapreduce.ifile.readahead.bytes
Handling deprecation for dfs.http.policy
Handling deprecation for hadoop.registry.secure
Handling deprecation for dfs.namenode.safemode.min.datanodes
Handling deprecation for dfs.client.file-block-storage-locations.num-threads
Handling deprecation for mapreduce.cluster.local.dir
Handling deprecation for mapreduce.tasktracker.report.address
Handling deprecation for dfs.namenode.secondary.https-address
Handling deprecation for hadoop.kerberos.kinit.command
Handling deprecation for yarn.timeline-service.http-authentication.type
Handling deprecation for dfs.block.access.token.lifetime
Handling deprecation for dfs.webhdfs.enabled
Handling deprecation for dfs.namenode.delegation.token.max-lifetime
Handling deprecation for dfs.namenode.avoid.write.stale.datanode
Handling deprecation for dfs.datanode.drop.cache.behind.writes
Handling deprecation for yarn.log-aggregation.retain-seconds
Handling deprecation for mapreduce.job.complete.cancel.delegation.tokens
Handling deprecation for mapreduce.local.clientfactory.class.name
Handling deprecation for mapreduce.shuffle.connection-keep-alive.timeout
Handling deprecation for dfs.namenode.num.extra.edits.retained
Handling deprecation for yarn.scheduler.minimum-allocation-vcores
Handling deprecation for ipc.client.connect.max.retries.on.timeouts
Handling deprecation for yarn.timeline-service.client.retry-interval-ms
Handling deprecation for yarn.timeline-service.client.max-retries
Handling deprecation for fs.s3n.block.size
Handling deprecation for mapreduce.job.map.output.collector.class
Handling deprecation for ha.health-monitor.connect-retry-interval.ms
Handling deprecation for mapreduce.shuffle.max.threads
Handling deprecation for nfs.exports.allowed.hosts
Handling deprecation for dfs.client.mmap.cache.size
Handling deprecation for mapreduce.tasktracker.map.tasks.maximum
Handling deprecation for io.file.buffer.size
Handling deprecation for dfs.client.datanode-restart.timeout
Handling deprecation for io.mapfile.bloom.size
Handling deprecation for hadoop.security.kms.client.authentication.retry-count
Handling deprecation for dfs.namenode.checkpoint.txns
Handling deprecation for ipc.client.connect.retry.interval
Handling deprecation for dfs.client-write-packet-size
Handling deprecation for mapreduce.reduce.shuffle.connect.timeout
Handling deprecation for yarn.resourcemanager.fs.state-store.uri
Handling deprecation for fs.swift.impl
Handling deprecation for hadoop.registry.zk.connection.timeout.ms
Handling deprecation for mapred.queue.default.acl-administer-jobs
Handling deprecation for mapreduce.job.submithostaddress
Handling deprecation for dfs.cachereport.intervalMsec
Handling deprecation for yarn.app.mapreduce.shuffle.log.backups
Handling deprecation for yarn.app.mapreduce.am.container.log.limit.kb
Handling deprecation for yarn.nodemanager.resourcemanager.minimum.version
Handling deprecation for ftp.blocksize
Handling deprecation for yarn.resourcemanager.address
Handling deprecation for file.stream-buffer-size
Handling deprecation for yarn.resourcemanager.scheduler.monitor.enable
Handling deprecation for mapreduce.job.ubertask.maxreduces
Handling deprecation for nfs.allow.insecure.ports
Handling deprecation for yarn.sharedcache.nm.uploader.thread-count
Handling deprecation for ipc.client.idlethreshold
Handling deprecation for ftp.stream-buffer-size
Handling deprecation for yarn.sharedcache.client-server.address
Handling deprecation for dfs.client.failover.connection.retries.on.timeouts
Handling deprecation for dfs.namenode.replication.work.multiplier.per.iteration
Handling deprecation for hadoop.http.authentication.simple.anonymous.allowed
Handling deprecation for hadoop.security.authorization
Handling deprecation for yarn.client.nodemanager-connect.retry-interval-ms
Handling deprecation for yarn.am.liveness-monitor.expiry-interval-ms
Handling deprecation for fs.har.impl.disable.cache
Handling deprecation for yarn.nodemanager.linux-container-executor.resources-handler.class
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.read-cache-size
Handling deprecation for hadoop.security.authentication
Handling deprecation for dfs.image.compression.codec
Handling deprecation for mapreduce.task.files.preserve.failedtasks
Handling deprecation for dfs.client.read.shortcircuit.streams.cache.size
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.path
Handling deprecation for mapreduce.job.reduce.slowstart.completedmaps
Handling deprecation for mapreduce.jobhistory.minicluster.fixed.ports
Handling deprecation for file.replication
Handling deprecation for yarn.resourcemanager.ha.automatic-failover.enabled
Handling deprecation for mapreduce.job.userlog.retain.hours
Handling deprecation for mapreduce.jobhistory.joblist.cache.size
Handling deprecation for dfs.namenode.accesstime.precision
Handling deprecation for yarn.resourcemanager.work-preserving-recovery.enabled
Handling deprecation for dfs.namenode.fs-limits.max-xattrs-per-inode
Handling deprecation for io.mapfile.bloom.error.rate
Handling deprecation for yarn.resourcemanager.store.class
Handling deprecation for dfs.image.transfer.timeout
Handling deprecation for yarn.timeline-service.leveldb-state-store.path
Handling deprecation for nfs.wtmax
Handling deprecation for mapreduce.job.combine.class
Handling deprecation for dfs.namenode.support.allow.format
Handling deprecation for fs.s3a.multipart.purge
Handling deprecation for dfs.secondary.namenode.kerberos.internal.spnego.principal
Handling deprecation for fs.s3a.connection.establish.timeout
Handling deprecation for dfs.stream-buffer-size
Handling deprecation for dfs.namenode.invalidate.work.pct.per.iteration
Handling deprecation for yarn.nodemanager.container-executor.class
Handling deprecation for fs.s3a.multipart.purge.age
Handling deprecation for yarn.resourcemanager.scheduler.client.thread-count
Handling deprecation for dfs.namenode.top.enabled
Handling deprecation for yarn.app.mapreduce.shuffle.log.separate
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.low-watermark
Handling deprecation for fs.s3a.fast.buffer.size
Handling deprecation for hadoop.user.group.static.mapping.overrides
Handling deprecation for tfile.fs.input.buffer.size
Handling deprecation for dfs.client.cached.conn.retry
Handling deprecation for hadoop.http.authentication.type
Handling deprecation for dfs.namenode.list.encryption.zones.num.responses
Handling deprecation for mapreduce.map.cpu.vcores
Handling deprecation for dfs.namenode.path.based.cache.refresh.interval.ms
Handling deprecation for dfs.namenode.decommission.interval
Handling deprecation for dfs.namenode.fs-limits.max-directory-items
Handling deprecation for yarn.resourcemanager.zk-retry-interval-ms
Handling deprecation for ftp.bytes-per-checksum
Handling deprecation for dfs.ha.log-roll.period
Handling deprecation for dfs.user.home.dir.prefix
Handling deprecation for ipc.client.fallback-to-simple-auth-allowed
Handling deprecation for yarn.nodemanager.pmem-check-enabled
Handling deprecation for yarn.nodemanager.remote-app-log-dir
Handling deprecation for dfs.namenode.inotify.max.events.per.rpc
Handling deprecation for mapreduce.task.profile.maps
Handling deprecation for mapreduce.shuffle.ssl.file.buffer.size
Handling deprecation for mapreduce.tasktracker.healthchecker.script.timeout
Handling deprecation for yarn.timeline-service.webapp.https.address
Handling deprecation for yarn.nodemanager.resource.percentage-physical-cpu-limit
Handling deprecation for yarn.app.mapreduce.am.command-opts
Handling deprecation for dfs.namenode.fs-limits.max-xattr-size
Handling deprecation for dfs.datanode.http.address
Handling deprecation for dfs.namenode.blocks.per.postponedblocks.rescan
Handling deprecation for yarn.sharedcache.nm.uploader.replication.factor
Handling deprecation for hadoop.registry.zk.root
Handling deprecation for hadoop.jetty.logs.serve.aliases
Handling deprecation for yarn.client.failover-proxy-provider
Handling deprecation for mapreduce.jobhistory.admin.acl
Handling deprecation for yarn.app.mapreduce.am.hard-kill-timeout-ms
Handling deprecation for yarn.nodemanager.remote-app-log-dir-suffix
Handling deprecation for mapreduce.jobhistory.principal
Handling deprecation for yarn.resourcemanager.webapp.address
Handling deprecation for mapreduce.jobhistory.recovery.enable
Handling deprecation for yarn.sharedcache.store.in-memory.check-period-mins
Handling deprecation for nfs.mountd.port
Handling deprecation for mapreduce.reduce.merge.inmem.threshold
Handling deprecation for fs.df.interval
Handling deprecation for yarn.timeline-service.enabled
Handling deprecation for mapreduce.jobtracker.jobhistory.lru.cache.size
Handling deprecation for mapreduce.task.profile
Handling deprecation for mapreduce.job.output.key.class
Handling deprecation for yarn.nodemanager.hostname
Handling deprecation for dfs.namenode.num.checkpoints.retained
Handling deprecation for mapreduce.job.queuename
Handling deprecation for mapreduce.jobhistory.max-age-ms
Handling deprecation for mapreduce.job.token.tracking.ids.enabled
Handling deprecation for yarn.nodemanager.localizer.client.thread-count
Handling deprecation for yarn.sharedcache.uploader.server.thread-count
Handling deprecation for dfs.client.mmap.retry.timeout.ms
Handling deprecation for mapreduce.jobhistory.move.thread-count
Handling deprecation for dfs.permissions.enabled
Handling deprecation for dfs.blockreport.split.threshold
Handling deprecation for fs.AbstractFileSystem.hdfs.impl
Handling deprecation for dfs.datanode.balance.bandwidthPerSec
Handling deprecation for dfs.block.scanner.volume.bytes.per.second
Handling deprecation for hadoop.http.filter.initializers
Handling deprecation for yarn.timeline-service.http-authentication.simple.anonymous.allowed
Handling deprecation for dfs.default.chunk.view.size
Handling deprecation for yarn.sharedcache.client-server.thread-count
Handling deprecation for yarn.resourcemanager.resource-tracker.address
Handling deprecation for mapreduce.job.working.dir
Handling deprecation for mapreduce.jobhistory.datestring.cache.size
Handling deprecation for mapreduce.task.profile.params
Handling deprecation for dfs.namenode.decommission.blocks.per.interval
Handling deprecation for dfs.namenode.handler.count
Handling deprecation for dfs.image.transfer.bandwidthPerSec
Handling deprecation for rpc.metrics.quantile.enable
Handling deprecation for mapreduce.jobtracker.expire.trackers.interval
Handling deprecation for mapreduce.task.timeout
Handling deprecation for yarn.app.mapreduce.client.max-retries
Handling deprecation for yarn.nodemanager.resource.memory-mb
Handling deprecation for yarn.nodemanager.disk-health-checker.min-healthy-disks
Handling deprecation for dfs.datanode.failed.volumes.tolerated
Handling deprecation for yarn.timeline-service.handler-thread-count
Handling deprecation for ipc.server.listen.queue.size
Handling deprecation for fs.s3a.threads.max
Handling deprecation for yarn.resourcemanager.connect.max-wait.ms
Handling deprecation for mapreduce.fileoutputcommitter.algorithm.version
Handling deprecation for mapreduce.framework.name
Handling deprecation for mapreduce.map.skip.proc.count.autoincr
Handling deprecation for mapreduce.job.max.split.locations
Handling deprecation for yarn.resourcemanager.scheduler.class
Handling deprecation for yarn.resourcemanager.system-metrics-publisher.enabled
Handling deprecation for dfs.blocksize
Handling deprecation for yarn.sharedcache.nested-level
Handling deprecation for mapreduce.shuffle.connection-keep-alive.enable
Handling deprecation for fs.s3a.threads.keepalivetime
Handling deprecation for fs.s3a.connection.timeout
Handling deprecation for file.client-write-packet-size
Handling deprecation for ha.failover-controller.cli-check.rpc-timeout.ms
Handling deprecation for ha.zookeeper.acl
Handling deprecation for dfs.namenode.write.stale.datanode.ratio
Handling deprecation for dfs.encrypt.data.transfer
Handling deprecation for dfs.datanode.shared.file.descriptor.paths
Handling deprecation for mapreduce.input.lineinputformat.linespermap
Handling deprecation for yarn.resourcemanager.delayed.delegation-token.removal-interval-ms
Handling deprecation for yarn.nodemanager.localizer.fetch.thread-count
Handling deprecation for dfs.client.failover.max.attempts
Handling deprecation for yarn.resourcemanager.scheduler.address
Handling deprecation for dfs.client.read.shortcircuit.streams.cache.expiry.ms
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.start-time-write-cache-size
Handling deprecation for yarn.nodemanager.health-checker.script.timeout-ms
Handling deprecation for yarn.resourcemanager.fs.state-store.num-retries
Handling deprecation for hadoop.ssl.require.client.cert
Handling deprecation for hadoop.security.uid.cache.secs
Handling deprecation for mapreduce.jobhistory.keytab
Handling deprecation for dfs.client.read.shortcircuit.skip.checksum
Handling deprecation for yarn.resourcemanager.ha.automatic-failover.zk-base-path
Handling deprecation for mapreduce.shuffle.ssl.enabled
Handling deprecation for mapreduce.reduce.log.level
Handling deprecation for hadoop.registry.rm.enabled
Handling deprecation for mapreduce.tasktracker.dns.interface
Handling deprecation for yarn.resourcemanager.system-metrics-publisher.dispatcher.pool-size
Handling deprecation for mapreduce.job.speculative.speculative-cap-running-tasks
Handling deprecation for dfs.datanode.block.id.layout.upgrade.threads
Handling deprecation for dfs.datanode.use.datanode.hostname
Handling deprecation for dfs.client.context
Handling deprecation for yarn.resourcemanager.ha.enabled
Handling deprecation for mapred.reducer.new-api
Handling deprecation for dfs.namenode.delegation.token.renew-interval
Handling deprecation for dfs.blockreport.intervalMsec
Handling deprecation for fs.s3a.multipart.threshold
Handling deprecation for mapreduce.reduce.shuffle.memory.limit.percent
Handling deprecation for dfs.https.server.keystore.resource
Handling deprecation for io.map.index.skip
Handling deprecation for mapreduce.job.hdfs-servers
Handling deprecation for mapreduce.jobtracker.taskscheduler
Handling deprecation for dfs.namenode.kerberos.internal.spnego.principal
Handling deprecation for yarn.resourcemanager.state-store.max-completed-applications
Handling deprecation for mapreduce.map.output.compress
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.num.refill.threads
Handling deprecation for fs.s3n.multipart.uploads.block.size
Handling deprecation for mapreduce.task.merge.progress.records
Handling deprecation for dfs.datanode.dns.interface
Handling deprecation for map.sort.class
Handling deprecation for yarn.nodemanager.aux-services.mapreduce_shuffle.class
Handling deprecation for tfile.fs.output.buffer.size
Handling deprecation for fs.du.interval
Handling deprecation for dfs.client.failover.connection.retries
Handling deprecation for dfs.namenode.top.window.num.buckets
Handling deprecation for mapreduce.job.dir
Handling deprecation for fs.s3a.buffer.dir
Handling deprecation for mapreduce.reduce.shuffle.retry-delay.max.ms
Handling deprecation for yarn.sharedcache.uploader.server.address
Handling deprecation for mapreduce.client.progressmonitor.pollinterval
Handling deprecation for yarn.app.mapreduce.shuffle.log.limit.kb
Handling deprecation for dfs.datanode.max.locked.memory
Handling deprecation for dfs.namenode.retrycache.expirytime.millis
Handling deprecation for dfs.datanode.scan.period.hours
Handling deprecation for dfs.client.block.write.replace-datanode-on-failure.best-effort
Handling deprecation for mapreduce.jobhistory.move.interval-ms
Handling deprecation for dfs.ha.fencing.ssh.connect-timeout
Handling deprecation for yarn.nodemanager.log-aggregation.roll-monitoring-interval-seconds
Handling deprecation for dfs.namenode.fs-limits.max-component-length
Handling deprecation for hadoop.registry.zk.quorum
Handling deprecation for dfs.namenode.enable.retrycache
Handling deprecation for dfs.datanode.du.reserved
Handling deprecation for yarn.timeline-service.state-store-class
Handling deprecation for dfs.datanode.ipc.address
Handling deprecation for hadoop.registry.system.acls
Handling deprecation for dfs.client.block.write.replace-datanode-on-failure.policy
Handling deprecation for dfs.namenode.path.based.cache.retry.interval.ms
Handling deprecation for hadoop.security.crypto.cipher.suite
Handling deprecation for dfs.ha.tail-edits.period
Handling deprecation for mapreduce.task.profile.reduce.params
Handling deprecation for hadoop.registry.jaas.context
Handling deprecation for yarn.resourcemanager.hostname
Handling deprecation for mapreduce.reduce.memory.mb
Handling deprecation for hadoop.security.group.mapping.ldap.search.filter.group
Handling deprecation for hadoop.http.authentication.kerberos.principal
Handling deprecation for hadoop.security.group.mapping.ldap.search.filter.user
Handling deprecation for yarn.nodemanager.disk-health-checker.min-free-space-per-disk-mb
Handling deprecation for dfs.namenode.edits.dir
Handling deprecation for yarn.client.failover-retries-on-socket-timeouts
Handling deprecation for dfs.namenode.decommission.max.concurrent.tracked.nodes
Handling deprecation for mapreduce.client.completion.pollinterval
Handling deprecation for dfs.namenode.name.dir.restore
Handling deprecation for dfs.namenode.secondary.http-address
Handling deprecation for mapreduce.jobhistory.recovery.store.leveldb.path
Handling deprecation for yarn.sharedcache.store.class
Handling deprecation for s3.bytes-per-checksum
Handling deprecation for yarn.nodemanager.windows-container.cpu-limit.enabled
Handling deprecation for yarn.resourcemanager.webapp.https.address
Handling deprecation for yarn.nodemanager.vmem-pmem-ratio
Handling deprecation for dfs.namenode.checkpoint.period
Handling deprecation for dfs.ha.automatic-failover.enabled
The url to track the job: http://localhost:8080/
Running job: job_local633002303_0003
OutputCommitter set in config null
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
File Output Committer Algorithm version is 1
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
/user/michaeljones/wcOutputMain/_temporary/0: masked=rwxr-xr-x
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones sending #58
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones got value #58
Call: mkdirs took 4ms
Starting mapper thread pool executor.
Max local threads: 1
Map tasks to process: 1
Waiting for map tasks
Starting task: attempt_local633002303_0003_m_000000_0
currentIndex 0   0:0
mapreduce.cluster.local.dir for child : /tmp/hadoop-michaeljones/mapred/local/localRunner//michaeljones/jobcache/job_local633002303_0003/attempt_local633002303_0003_m_000000_0
using new api for output committer
File Output Committer Algorithm version is 1
ProcfsBasedProcessTree currently is supported only on Linux.
 Using ResourceCalculatorProcessTree : null
Processing split: hdfs://localhost:9000/user/michaeljones/wcInput:0+50
Trying map output collector class: org.apache.hadoop.mapred.MapTask$MapOutputBuffer
(EQUATOR) 0 kvi 26214396(104857584)
mapreduce.task.io.sort.mb: 100
soft limit at 83886080
bufstart = 0; bufvoid = 104857600
kvstart = 26214396; length = 6553600
Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones sending #59
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones got value #59
Call: getBlockLocations took 10ms
newInfo = LocatedBlocks{
  fileLength=50
  underConstruction=false
  blocks=[LocatedBlock{BP-1045030256-10.0.0.2-1433119149314:blk_1073741825_1002; getBlockSize()=50; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-b42c5705-9ba4-4b14-b00b-f9194bb036f0,DISK]]}]
  lastLocatedBlock=LocatedBlock{BP-1045030256-10.0.0.2-1433119149314:blk_1073741825_1002; getBlockSize()=50; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-b42c5705-9ba4-4b14-b00b-f9194bb036f0,DISK]]}
  isLastBlockComplete=true}
Connecting to datanode 127.0.0.1:50010

Starting flush of map output
Spilling map output
bufstart = 0; bufend = 82; bufvoid = 104857600
kvstart = 26214396(104857584); kvend = 26214368(104857472); length = 29/6553600
Finished spill 0
Task:attempt_local633002303_0003_m_000000_0 is done. And is in the process of committing
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones sending #60
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones got value #60
Call: getFileInfo took 2ms
map
Task 'attempt_local633002303_0003_m_000000_0' done.
Finishing task: attempt_local633002303_0003_m_000000_0
map task executor complete.
Starting reduce thread pool executor.
Max local threads: 1
Reduce tasks to process: 1
Waiting for reduce tasks
Starting task: attempt_local633002303_0003_r_000000_0
currentIndex 0   0:0
mapreduce.cluster.local.dir for child : /tmp/hadoop-michaeljones/mapred/local/localRunner//michaeljones/jobcache/job_local633002303_0003/attempt_local633002303_0003_r_000000_0
using new api for output committer
File Output Committer Algorithm version is 1
ProcfsBasedProcessTree currently is supported only on Linux.
 Using ResourceCalculatorProcessTree : null
Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@5bb5f1aa
MergerManager: memoryLimit=668309888, maxSingleShuffleLimit=167077472, mergeThreshold=441084544, ioSortFactor=10, memToMemMergeOutputsThreshold=10
attempt_local633002303_0003_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
Got 0 map completion events from 0
GetMapEventsThread about to sleep for 1000
LocalFetcher 3 going to fetch: attempt_local633002303_0003_m_000000_0
attempt_local633002303_0003_m_000000_0: Proceeding with shuffle since usedMemory (0) is lesser than memoryLimit (668309888).CommitMemory is (0)
localfetcher#3 about to shuffle output of map attempt_local633002303_0003_m_000000_0 decomp: 63 len: 67 to MEMORY
Read 63 bytes from map-output for attempt_local633002303_0003_m_000000_0
closeInMemoryFile -> map-output of size: 63, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->63
map attempt_local633002303_0003_m_000000_0 done 1 / 1 copied.
EventFetcher is interrupted.. Returning
1 / 1 copied.
finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
Merging 1 sorted segments
Down to the last merge-pass, with 1 segments left of total size: 57 bytes
Merged 1 segments, 63 bytes to disk to satisfy reduce memory limit
Disk file: /tmp/hadoop-michaeljones/mapred/local/localRunner/michaeljones/jobcache/job_local633002303_0003/attempt_local633002303_0003_r_000000_0/output/map_0.out.merged Length is 67
Merging 1 files, 67 bytes from disk
Merging 0 segments, 0 bytes from memory into reduce
Merging 1 sorted segments
Down to the last merge-pass, with 1 segments left of total size: 57 bytes
1 / 1 copied.
/user/michaeljones/wcOutputMain/_temporary/0/_temporary/attempt_local633002303_0003_r_000000_0/part-r-00000: masked=rw-r--r--
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones sending #61
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones got value #61
Call: create took 4ms
computePacketChunkSize: src=/user/michaeljones/wcOutputMain/_temporary/0/_temporary/attempt_local633002303_0003_r_000000_0/part-r-00000, chunkSize=516, chunksPerPacket=126, packetSize=65016
DFSClient writeChunk allocating new packet seqno=0, src=/user/michaeljones/wcOutputMain/_temporary/0/_temporary/attempt_local633002303_0003_r_000000_0/part-r-00000, packetSize=65016, chunksPerPacket=126, bytesCurBlock=0
Queued packet 0
Queued packet 1
Waiting for ack for: 1
Allocating new block
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones sending #62
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones got value #62
Call: addBlock took 4ms
pipeline = DatanodeInfoWithStorage[127.0.0.1:50010,DS-b42c5705-9ba4-4b14-b00b-f9194bb036f0,DISK]
Connecting to datanode 127.0.0.1:50010
Send buf size 131072
SASL client skipping handshake in unsecured configuration for addr = /127.0.0.1, datanodeId = DatanodeInfoWithStorage[127.0.0.1:50010,DS-b42c5705-9ba4-4b14-b00b-f9194bb036f0,DISK]
DataStreamer block BP-1045030256-10.0.0.2-1433119149314:blk_1073742231_1408 sending packet packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 41
DFSClient seqno: 0 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
DataStreamer block BP-1045030256-10.0.0.2-1433119149314:blk_1073742231_1408 sending packet packet seqno: 1 offsetInBlock: 41 lastPacketInBlock: true lastByteOffsetInBlock: 41
DFSClient seqno: 1 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
Closing old block BP-1045030256-10.0.0.2-1433119149314:blk_1073742231_1408
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones sending #63
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones got value #63
Call: complete took 2ms
Task:attempt_local633002303_0003_r_000000_0 is done. And is in the process of committing
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones sending #64
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones got value #64
Call: getFileInfo took 2ms
1 / 1 copied.
Task attempt_local633002303_0003_r_000000_0 is allowed to commit now
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones sending #65
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones got value #65
Call: getFileInfo took 3ms
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones sending #66
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones got value #66
Call: getFileInfo took 1ms
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones sending #67
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones got value #67
Call: rename took 3ms
Saved output of task 'attempt_local633002303_0003_r_000000_0' to hdfs://localhost:9000/user/michaeljones/wcOutputMain/_temporary/0/task_local633002303_0003_r_000000
reduce > reduce
Task 'attempt_local633002303_0003_r_000000_0' done.
Finishing task: attempt_local633002303_0003_r_000000_0
reduce task executor complete.
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones sending #68
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones got value #68
Call: getListing took 3ms
Merging data from FileStatus{path=hdfs://localhost:9000/user/michaeljones/wcOutputMain/_temporary/0/task_local633002303_0003_r_000000; isDirectory=true; modification_time=1434159019612; access_time=0; owner=michaeljones; group=supergroup; permission=rwxr-xr-x; isSymlink=false} to hdfs://localhost:9000/user/michaeljones/wcOutputMain
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones sending #69
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones got value #69
Call: getFileInfo took 2ms
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones sending #70
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones got value #70
Call: getListing took 2ms
Merging data from FileStatus{path=hdfs://localhost:9000/user/michaeljones/wcOutputMain/_temporary/0/task_local633002303_0003_r_000000/part-r-00000; isDirectory=false; length=41; replication=1; blocksize=134217728; modification_time=1434159019635; access_time=1434159019612; owner=michaeljones; group=supergroup; permission=rw-r--r--; isSymlink=false} to hdfs://localhost:9000/user/michaeljones/wcOutputMain/part-r-00000
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones sending #71
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones got value #71
Call: getFileInfo took 2ms
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones sending #72
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones got value #72
Call: rename took 3ms
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones sending #73
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones got value #73
Call: delete took 4ms
/user/michaeljones/wcOutputMain/_SUCCESS: masked=rw-r--r--
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones sending #74
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones got value #74
Call: create took 5ms
computePacketChunkSize: src=/user/michaeljones/wcOutputMain/_SUCCESS, chunkSize=516, chunksPerPacket=126, packetSize=65016
Waiting for ack for: -1
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones sending #75
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones got value #75
Call: complete took 2ms
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.fs.FileContext.getAbstractFileSystem(FileContext.java:331)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
Job job_local633002303_0003 running in uber mode : false
 map 100% reduce 100%
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.getTaskCompletionEvents(Job.java:670)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.getTaskCompletionEvents(Job.java:670)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
Job job_local633002303_0003 completed successfully
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.getCounters(Job.java:758)
Counters: 35
	File System Counters
		FILE: Number of bytes read=1892
		FILE: Number of bytes written=1691283
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=340
		HDFS: Number of bytes written=245
		HDFS: Number of read operations=71
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=38
	Map-Reduce Framework
		Map input records=2
		Map output records=8
		Map output bytes=82
		Map output materialized bytes=67
		Input split bytes=112
		Combine input records=8
		Combine output records=5
		Reduce input groups=5
		Reduce shuffle bytes=67
		Reduce input records=5
		Reduce output records=5
		Spilled Records=10
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=972029952
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=50
	File Output Format Counters 
		Bytes Written=41
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 5][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://localhost:50070
Connecting to localhost/127.0.0.1:50070
Connection established 127.0.0.1:50365<->127.0.0.1:50070
Executing request GET /webhdfs/v1/user/michaeljones/?op=LISTSTATUS HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-5 >> GET /webhdfs/v1/user/michaeljones/?op=LISTSTATUS HTTP/1.1
http-outgoing-5 >> accept: application/json
http-outgoing-5 >> Host: localhost:50070
http-outgoing-5 >> Connection: Keep-Alive
http-outgoing-5 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-5 >> Accept-Encoding: gzip,deflate
http-outgoing-5 >> "GET /webhdfs/v1/user/michaeljones/?op=LISTSTATUS HTTP/1.1[\r][\n]"
http-outgoing-5 >> "accept: application/json[\r][\n]"
http-outgoing-5 >> "Host: localhost:50070[\r][\n]"
http-outgoing-5 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-5 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-5 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-5 >> "[\r][\n]"
http-outgoing-5 << "HTTP/1.1 200 OK[\r][\n]"
http-outgoing-5 << "Cache-Control: no-cache[\r][\n]"
http-outgoing-5 << "Expires: Sat, 13 Jun 2015 01:30:20 GMT[\r][\n]"
http-outgoing-5 << "Date: Sat, 13 Jun 2015 01:30:20 GMT[\r][\n]"
http-outgoing-5 << "Pragma: no-cache[\r][\n]"
http-outgoing-5 << "Expires: Sat, 13 Jun 2015 01:30:20 GMT[\r][\n]"
http-outgoing-5 << "Date: Sat, 13 Jun 2015 01:30:20 GMT[\r][\n]"
http-outgoing-5 << "Pragma: no-cache[\r][\n]"
http-outgoing-5 << "Content-Type: application/json[\r][\n]"
http-outgoing-5 << "Transfer-Encoding: chunked[\r][\n]"
http-outgoing-5 << "Server: Jetty(6.1.26)[\r][\n]"
http-outgoing-5 << "[\r][\n]"
http-outgoing-5 << "E9C[\r][\n]"
http-outgoing-5 << "{"FileStatuses":{"FileStatus":[[\n]"
http-outgoing-5 << "{"accessTime":1434159010777,"blockSize":134217728,"childrenNum":0,"fileId":18441,"group":"supergroup","length":10899,"modificationTime":1434159010812,"owner":"michaeljones","pathSuffix":"README.md","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-5 << "{"accessTime":1434151935882,"blockSize":134217728,"childrenNum":0,"fileId":18419,"group":"supergroup","length":0,"modificationTime":1434151935894,"owner":"michaeljones","pathSuffix":"apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-5 << "{"accessTime":1434158893981,"blockSize":134217728,"childrenNum":0,"fileId":18435,"group":"supergroup","length":0,"modificationTime":1434158893986,"owner":"michaeljones","pathSuffix":"empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-5 << "{"accessTime":1434159010225,"blockSize":134217728,"childrenNum":0,"fileId":18439,"group":"supergroup","length":0,"modificationTime":1434159010231,"owner":"michaeljones","pathSuffix":"hello-apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-5 << "{"accessTime":1434091626279,"blockSize":134217728,"childrenNum":0,"fileId":18298,"group":"supergroup","length":0,"modificationTime":1434091626286,"owner":"michaeljones","pathSuffix":"hello-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-5 << "{"accessTime":1434159010131,"blockSize":134217728,"childrenNum":0,"fileId":18438,"group":"supergroup","length":0,"modificationTime":1434159010139,"owner":"michaeljones","pathSuffix":"hello-jersey-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-5 << "{"accessTime":1434158894531,"blockSize":134217728,"childrenNum":0,"fileId":18437,"group":"supergroup","length":461138,"modificationTime":1434158894573,"owner":"michaeljones","pathSuffix":"hello.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-5 << "{"accessTime":1434159013887,"blockSize":134217728,"childrenNum":0,"fileId":18442,"group":"supergroup","length":20,"modificationTime":1434159014350,"owner":"michaeljones","pathSuffix":"hello.txt","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-5 << "{"accessTime":1434159010577,"blockSize":134217728,"childrenNum":0,"fileId":18440,"group":"supergroup","length":54643,"modificationTime":1434159010604,"owner":"michaeljones","pathSuffix":"hellohadoop.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-5 << "{"accessTime":1434151935993,"blockSize":134217728,"childrenNum":0,"fileId":18420,"group":"supergroup","length":2134,"modificationTime":1434151936019,"owner":"michaeljones","pathSuffix":"pom.xml","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-5 << "{"accessTime":1434159014921,"blockSize":134217728,"childrenNum":0,"fileId":16388,"group":"supergroup","length":50,"modificationTime":1433119638967,"owner":"michaeljones","pathSuffix":"wcInput","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-5 << "{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18443,"group":"supergroup","length":0,"modificationTime":1434159016805,"owner":"michaeljones","pathSuffix":"wcOutput","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},[\n]"
http-outgoing-5 << "{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18450,"group":"supergroup","length":0,"modificationTime":1434159017973,"owner":"michaeljones","pathSuffix":"wcOutputAnalysis","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},[\n]"
http-outgoing-5 << "{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18457,"group":"supergroup","length":0,"modificationTime":1434159019678,"owner":"michaeljones","pathSuffix":"wcOutputMain","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"}[\n]"
http-outgoing-5 << "]}}[\n]"
http-outgoing-5 << "[\r][\n]"
http-outgoing-5 << "0[\r][\n]"
http-outgoing-5 << "[\r][\n]"
http-outgoing-5 << HTTP/1.1 200 OK
http-outgoing-5 << Cache-Control: no-cache
http-outgoing-5 << Expires: Sat, 13 Jun 2015 01:30:20 GMT
http-outgoing-5 << Date: Sat, 13 Jun 2015 01:30:20 GMT
http-outgoing-5 << Pragma: no-cache
http-outgoing-5 << Expires: Sat, 13 Jun 2015 01:30:20 GMT
http-outgoing-5 << Date: Sat, 13 Jun 2015 01:30:20 GMT
http-outgoing-5 << Pragma: no-cache
http-outgoing-5 << Content-Type: application/json
http-outgoing-5 << Transfer-Encoding: chunked
http-outgoing-5 << Server: Jetty(6.1.26)
Connection can be kept alive indefinitely
Connection [id: 5][route: {}->http://localhost:50070] can be kept alive indefinitely
Connection released: [id: 5][route: {}->http://localhost:50070][total kept alive: 1; route allocated: 1 of 2; total allocated: 1 of 20]
Apache client testGetStringContent
{"FileStatuses":{"FileStatus":[
{"accessTime":1434159010777,"blockSize":134217728,"childrenNum":0,"fileId":18441,"group":"supergroup","length":10899,"modificationTime":1434159010812,"owner":"michaeljones","pathSuffix":"README.md","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434151935882,"blockSize":134217728,"childrenNum":0,"fileId":18419,"group":"supergroup","length":0,"modificationTime":1434151935894,"owner":"michaeljones","pathSuffix":"apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434158893981,"blockSize":134217728,"childrenNum":0,"fileId":18435,"group":"supergroup","length":0,"modificationTime":1434158893986,"owner":"michaeljones","pathSuffix":"empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434159010225,"blockSize":134217728,"childrenNum":0,"fileId":18439,"group":"supergroup","length":0,"modificationTime":1434159010231,"owner":"michaeljones","pathSuffix":"hello-apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434091626279,"blockSize":134217728,"childrenNum":0,"fileId":18298,"group":"supergroup","length":0,"modificationTime":1434091626286,"owner":"michaeljones","pathSuffix":"hello-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434159010131,"blockSize":134217728,"childrenNum":0,"fileId":18438,"group":"supergroup","length":0,"modificationTime":1434159010139,"owner":"michaeljones","pathSuffix":"hello-jersey-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434158894531,"blockSize":134217728,"childrenNum":0,"fileId":18437,"group":"supergroup","length":461138,"modificationTime":1434158894573,"owner":"michaeljones","pathSuffix":"hello.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434159013887,"blockSize":134217728,"childrenNum":0,"fileId":18442,"group":"supergroup","length":20,"modificationTime":1434159014350,"owner":"michaeljones","pathSuffix":"hello.txt","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434159010577,"blockSize":134217728,"childrenNum":0,"fileId":18440,"group":"supergroup","length":54643,"modificationTime":1434159010604,"owner":"michaeljones","pathSuffix":"hellohadoop.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434151935993,"blockSize":134217728,"childrenNum":0,"fileId":18420,"group":"supergroup","length":2134,"modificationTime":1434151936019,"owner":"michaeljones","pathSuffix":"pom.xml","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434159014921,"blockSize":134217728,"childrenNum":0,"fileId":16388,"group":"supergroup","length":50,"modificationTime":1433119638967,"owner":"michaeljones","pathSuffix":"wcInput","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18443,"group":"supergroup","length":0,"modificationTime":1434159016805,"owner":"michaeljones","pathSuffix":"wcOutput","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},
{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18450,"group":"supergroup","length":0,"modificationTime":1434159017973,"owner":"michaeljones","pathSuffix":"wcOutputAnalysis","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},
{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18457,"group":"supergroup","length":0,"modificationTime":1434159019678,"owner":"michaeljones","pathSuffix":"wcOutputMain","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"}
]}}

CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 6][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://localhost:50070
Connecting to localhost/127.0.0.1:50070
Connection established 127.0.0.1:50366<->127.0.0.1:50070
Executing request PUT /webhdfs/v1/user/michaeljones/apache-empty.txt?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-6 >> PUT /webhdfs/v1/user/michaeljones/apache-empty.txt?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1
http-outgoing-6 >> Content-Length: 0
http-outgoing-6 >> Host: localhost:50070
http-outgoing-6 >> Connection: Keep-Alive
http-outgoing-6 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-6 >> Accept-Encoding: gzip,deflate
http-outgoing-6 >> "PUT /webhdfs/v1/user/michaeljones/apache-empty.txt?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1[\r][\n]"
http-outgoing-6 >> "Content-Length: 0[\r][\n]"
http-outgoing-6 >> "Host: localhost:50070[\r][\n]"
http-outgoing-6 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-6 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-6 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-6 >> "[\r][\n]"
http-outgoing-6 << "HTTP/1.1 307 TEMPORARY_REDIRECT[\r][\n]"
http-outgoing-6 << "Cache-Control: no-cache[\r][\n]"
http-outgoing-6 << "Expires: Sat, 13 Jun 2015 01:30:20 GMT[\r][\n]"
http-outgoing-6 << "Date: Sat, 13 Jun 2015 01:30:20 GMT[\r][\n]"
http-outgoing-6 << "Pragma: no-cache[\r][\n]"
http-outgoing-6 << "Expires: Sat, 13 Jun 2015 01:30:20 GMT[\r][\n]"
http-outgoing-6 << "Date: Sat, 13 Jun 2015 01:30:20 GMT[\r][\n]"
http-outgoing-6 << "Pragma: no-cache[\r][\n]"
http-outgoing-6 << "Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434195020516&s=3bI5eqNHkuVmpK/3SquRsmN40wU="; Path=/; Expires=Sat, 13-Jun-2015 11:30:20 GMT; HttpOnly[\r][\n]"
http-outgoing-6 << "Location: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true[\r][\n]"
http-outgoing-6 << "Content-Type: application/octet-stream[\r][\n]"
http-outgoing-6 << "Content-Length: 0[\r][\n]"
http-outgoing-6 << "Server: Jetty(6.1.26)[\r][\n]"
http-outgoing-6 << "[\r][\n]"
http-outgoing-6 << HTTP/1.1 307 TEMPORARY_REDIRECT
http-outgoing-6 << Cache-Control: no-cache
http-outgoing-6 << Expires: Sat, 13 Jun 2015 01:30:20 GMT
http-outgoing-6 << Date: Sat, 13 Jun 2015 01:30:20 GMT
http-outgoing-6 << Pragma: no-cache
http-outgoing-6 << Expires: Sat, 13 Jun 2015 01:30:20 GMT
http-outgoing-6 << Date: Sat, 13 Jun 2015 01:30:20 GMT
http-outgoing-6 << Pragma: no-cache
http-outgoing-6 << Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434195020516&s=3bI5eqNHkuVmpK/3SquRsmN40wU="; Path=/; Expires=Sat, 13-Jun-2015 11:30:20 GMT; HttpOnly
http-outgoing-6 << Location: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
http-outgoing-6 << Content-Type: application/octet-stream
http-outgoing-6 << Content-Length: 0
http-outgoing-6 << Server: Jetty(6.1.26)
Connection can be kept alive indefinitely
Cookie accepted [hadoop.auth=""u=michaeljones&p=michaeljones&t=simple&e=1434195020516&s=3bI5eqNHkuVmpK/3SquRsmN40wU="", version:0, domain:localhost, path:/, expiry:Sat Jun 13 21:30:20 AEST 2015]
Redirect to: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
http-outgoing-6: Shutdown connection
Connection discarded
http-outgoing-6: Close connection
Connection released: [id: 6][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
PUT file redirect: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 7][route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://michaels-air.bigpond:50075
Connecting to Michaels-Air.BigPond/10.0.0.2:50075
Connection established 10.0.0.2:50367<->10.0.0.2:50075
Executing request PUT /webhdfs/v1/user/michaeljones/apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-7 >> PUT /webhdfs/v1/user/michaeljones/apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1
http-outgoing-7 >> Content-Length: 0
http-outgoing-7 >> Host: michaels-air.bigpond:50075
http-outgoing-7 >> Connection: Keep-Alive
http-outgoing-7 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-7 >> Accept-Encoding: gzip,deflate
http-outgoing-7 >> "PUT /webhdfs/v1/user/michaeljones/apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1[\r][\n]"
http-outgoing-7 >> "Content-Length: 0[\r][\n]"
http-outgoing-7 >> "Host: michaels-air.bigpond:50075[\r][\n]"
http-outgoing-7 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-7 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-7 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-7 >> "[\r][\n]"
http-outgoing-7 << "HTTP/1.1 100 Continue[\r][\n]"
http-outgoing-7 << "[\r][\n]"
http-outgoing-7 << HTTP/1.1 100 Continue
http-outgoing-7 << "HTTP/1.1 201 Created[\r][\n]"
http-outgoing-7 << "Location: hdfs://localhost:9000/user/michaeljones/apache-empty.txt[\r][\n]"
http-outgoing-7 << "Content-Length: 0[\r][\n]"
http-outgoing-7 << "Connection: close[\r][\n]"
http-outgoing-7 << "[\r][\n]"
http-outgoing-7 << HTTP/1.1 201 Created
http-outgoing-7 << Location: hdfs://localhost:9000/user/michaeljones/apache-empty.txt
http-outgoing-7 << Content-Length: 0
http-outgoing-7 << Connection: close
http-outgoing-7: Shutdown connection
Connection discarded
http-outgoing-7: Close connection
Connection released: [id: 7][route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 8][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://localhost:50070
Connecting to localhost/127.0.0.1:50070
Connection established 127.0.0.1:50369<->127.0.0.1:50070
Executing request PUT /webhdfs/v1/user/michaeljones/pom.xml?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-8 >> PUT /webhdfs/v1/user/michaeljones/pom.xml?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1
http-outgoing-8 >> Content-Length: 0
http-outgoing-8 >> Host: localhost:50070
http-outgoing-8 >> Connection: Keep-Alive
http-outgoing-8 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-8 >> Accept-Encoding: gzip,deflate
http-outgoing-8 >> "PUT /webhdfs/v1/user/michaeljones/pom.xml?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1[\r][\n]"
http-outgoing-8 >> "Content-Length: 0[\r][\n]"
http-outgoing-8 >> "Host: localhost:50070[\r][\n]"
http-outgoing-8 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-8 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-8 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-8 >> "[\r][\n]"
http-outgoing-8 << "HTTP/1.1 307 TEMPORARY_REDIRECT[\r][\n]"
http-outgoing-8 << "Cache-Control: no-cache[\r][\n]"
http-outgoing-8 << "Expires: Sat, 13 Jun 2015 01:30:20 GMT[\r][\n]"
http-outgoing-8 << "Date: Sat, 13 Jun 2015 01:30:20 GMT[\r][\n]"
http-outgoing-8 << "Pragma: no-cache[\r][\n]"
http-outgoing-8 << "Expires: Sat, 13 Jun 2015 01:30:20 GMT[\r][\n]"
http-outgoing-8 << "Date: Sat, 13 Jun 2015 01:30:20 GMT[\r][\n]"
http-outgoing-8 << "Pragma: no-cache[\r][\n]"
http-outgoing-8 << "Content-Type: application/octet-stream[\r][\n]"
http-outgoing-8 << "Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434195020567&s=O614M8dqBq1Ho3C4kQAJ0wbycM8="; Path=/; Expires=Sat, 13-Jun-2015 11:30:20 GMT; HttpOnly[\r][\n]"
http-outgoing-8 << "Location: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/pom.xml?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true[\r][\n]"
http-outgoing-8 << "Content-Length: 0[\r][\n]"
http-outgoing-8 << "Server: Jetty(6.1.26)[\r][\n]"
http-outgoing-8 << "[\r][\n]"
http-outgoing-8 << HTTP/1.1 307 TEMPORARY_REDIRECT
http-outgoing-8 << Cache-Control: no-cache
http-outgoing-8 << Expires: Sat, 13 Jun 2015 01:30:20 GMT
http-outgoing-8 << Date: Sat, 13 Jun 2015 01:30:20 GMT
http-outgoing-8 << Pragma: no-cache
http-outgoing-8 << Expires: Sat, 13 Jun 2015 01:30:20 GMT
http-outgoing-8 << Date: Sat, 13 Jun 2015 01:30:20 GMT
http-outgoing-8 << Pragma: no-cache
http-outgoing-8 << Content-Type: application/octet-stream
http-outgoing-8 << Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434195020567&s=O614M8dqBq1Ho3C4kQAJ0wbycM8="; Path=/; Expires=Sat, 13-Jun-2015 11:30:20 GMT; HttpOnly
http-outgoing-8 << Location: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/pom.xml?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
http-outgoing-8 << Content-Length: 0
http-outgoing-8 << Server: Jetty(6.1.26)
Connection can be kept alive indefinitely
Cookie accepted [hadoop.auth=""u=michaeljones&p=michaeljones&t=simple&e=1434195020567&s=O614M8dqBq1Ho3C4kQAJ0wbycM8="", version:0, domain:localhost, path:/, expiry:Sat Jun 13 21:30:20 AEST 2015]
Redirect to: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/pom.xml?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
http-outgoing-8: Shutdown connection
Connection discarded
http-outgoing-8: Close connection
Connection released: [id: 8][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
PUT file redirect: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/pom.xml?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 9][route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://michaels-air.bigpond:50075
Connecting to Michaels-Air.BigPond/10.0.0.2:50075
Connection established 10.0.0.2:50370<->10.0.0.2:50075
Executing request PUT /webhdfs/v1/user/michaeljones/pom.xml?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-9 >> PUT /webhdfs/v1/user/michaeljones/pom.xml?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1
http-outgoing-9 >> Transfer-Encoding: chunked
http-outgoing-9 >> Content-Type: application/octet-stream
http-outgoing-9 >> Host: michaels-air.bigpond:50075
http-outgoing-9 >> Connection: Keep-Alive
http-outgoing-9 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-9 >> Accept-Encoding: gzip,deflate
http-outgoing-9 >> "PUT /webhdfs/v1/user/michaeljones/pom.xml?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1[\r][\n]"
http-outgoing-9 >> "Transfer-Encoding: chunked[\r][\n]"
http-outgoing-9 >> "Content-Type: application/octet-stream[\r][\n]"
http-outgoing-9 >> "Host: michaels-air.bigpond:50075[\r][\n]"
http-outgoing-9 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-9 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-9 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-9 >> "[\r][\n]"
http-outgoing-9 >> "856[\r][\n]"
http-outgoing-9 >> "<?xml version="1.0" encoding="UTF-8"?>[\n]"
http-outgoing-9 >> "<project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">[\n]"
http-outgoing-9 >> "    <modelVersion>4.0.0</modelVersion>[\n]"
http-outgoing-9 >> "    <groupId>com.michaeljones</groupId>[\n]"
http-outgoing-9 >> "    <artifactId>HelloHadoopWorldMaven</artifactId>[\n]"
http-outgoing-9 >> "    <version>1.0-SNAPSHOT</version>[\n]"
http-outgoing-9 >> "    <packaging>jar</packaging>[\n]"
http-outgoing-9 >> "    <dependencies>[\n]"
http-outgoing-9 >> "        <!-- run bin/hadoop version to see the jar it was built with, which is this dependency -->[\n]"
http-outgoing-9 >> "        <dependency>[\n]"
http-outgoing-9 >> "            <groupId>org.apache.hadoop</groupId>[\n]"
http-outgoing-9 >> "            <artifactId>hadoop-common</artifactId>[\n]"
http-outgoing-9 >> "            <version>2.7.0</version>[\n]"
http-outgoing-9 >> "        </dependency>[\n]"
http-outgoing-9 >> "        <dependency>[\n]"
http-outgoing-9 >> "            <groupId>org.apache.hadoop</groupId>[\n]"
http-outgoing-9 >> "            <artifactId>hadoop-hdfs</artifactId>[\n]"
http-outgoing-9 >> "            <version>2.7.0</version>[\n]"
http-outgoing-9 >> "        </dependency>[\n]"
http-outgoing-9 >> "        <dependency>[\n]"
http-outgoing-9 >> "            <groupId>junit</groupId>[\n]"
http-outgoing-9 >> "            <artifactId>junit</artifactId>[\n]"
http-outgoing-9 >> "            <version>4.10</version>[\n]"
http-outgoing-9 >> "            <scope>test</scope>[\n]"
http-outgoing-9 >> "        </dependency>[\n]"
http-outgoing-9 >> "        <dependency>[\n]"
http-outgoing-9 >> "            <groupId>org.apache.hadoop</groupId>[\n]"
http-outgoing-9 >> "            <artifactId>hadoop-mapreduce-client-core</artifactId>[\n]"
http-outgoing-9 >> "            <version>2.7.0</version>[\n]"
http-outgoing-9 >> "        </dependency>[\n]"
http-outgoing-9 >> "        <dependency>[\n]"
http-outgoing-9 >> "            <groupId>org.apache.hadoop</groupId>[\n]"
http-outgoing-9 >> "            <artifactId>hadoop-mapreduce-client-common</artifactId>[\n]"
Connection manager is shutting down
http-outgoing-9 >> "            <version>2.7.0</version>[\n]"
Connection manager shut down
http-outgoing-9 >> "        </dependency>[\n]"
http-outgoing-9 >> "        <dependency>[\n]"
http-outgoing-9 >> "            <groupId>com.googlecode.json-simple</groupId>[\n]"
http-outgoing-9 >> "            <artifactId>json-simple</artifactId>[\n]"
Connection manager is shutting down
http-outgoing-9 >> "            <version>1.1.1</version>[\n]"
http-outgoing-9 >> "        </dependency>[\n]"
http-outgoing-9 >> "        <dependency>[\n]"
http-outgoing-5: Close connection
http-outgoing-9 >> "            <groupId>org.apache.httpcomponents</groupId>[\n]"
http-outgoing-9 >> "            <artifactId>httpclient</artifactId>[\n]"
http-outgoing-5: Close connection
Connection manager shut down
http-outgoing-9 >> "            <version>4.4-beta1</version>[\n]"
http-outgoing-9 >> "        </dependency>[\n]"
http-outgoing-9 >> "    </dependencies>[\n]"
http-outgoing-9 >> "    <properties>[\n]"
http-outgoing-9 >> "        <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>[\n]"
http-outgoing-9 >> "        <maven.compiler.source>1.7</maven.compiler.source>[\n]"
http-outgoing-9 >> "        <maven.compiler.target>1.7</maven.compiler.target>[\n]"
http-outgoing-9 >> "    </properties>[\n]"
http-outgoing-9 >> "</project>[\r][\n]"
http-outgoing-9 >> "0[\r][\n]"
http-outgoing-9 >> "[\r][\n]"
http-outgoing-9 << "HTTP/1.1 100 Continue[\r][\n]"
http-outgoing-9 << "[\r][\n]"
http-outgoing-9 << HTTP/1.1 100 Continue
http-outgoing-9 << "HTTP/1.1 201 Created[\r][\n]"
http-outgoing-9 << "Location: hdfs://localhost:9000/user/michaeljones/pom.xml[\r][\n]"
http-outgoing-9 << "Content-Length: 0[\r][\n]"
http-outgoing-9 << "Connection: close[\r][\n]"
http-outgoing-9 << "[\r][\n]"
http-outgoing-9 << HTTP/1.1 201 Created
http-outgoing-9 << Location: hdfs://localhost:9000/user/michaeljones/pom.xml
http-outgoing-9 << Content-Length: 0
http-outgoing-9 << Connection: close
http-outgoing-9: Shutdown connection
Connection discarded
http-outgoing-9: Close connection
Connection released: [id: 9][route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection manager is shutting down
Connection manager shut down
Jersey client testGetStringContent
{"FileStatuses":{"FileStatus":[
{"accessTime":1434159010777,"blockSize":134217728,"childrenNum":0,"fileId":18441,"group":"supergroup","length":10899,"modificationTime":1434159010812,"owner":"michaeljones","pathSuffix":"README.md","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434159020549,"blockSize":134217728,"childrenNum":0,"fileId":18464,"group":"supergroup","length":0,"modificationTime":1434159020554,"owner":"michaeljones","pathSuffix":"apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434158893981,"blockSize":134217728,"childrenNum":0,"fileId":18435,"group":"supergroup","length":0,"modificationTime":1434158893986,"owner":"michaeljones","pathSuffix":"empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434159010225,"blockSize":134217728,"childrenNum":0,"fileId":18439,"group":"supergroup","length":0,"modificationTime":1434159010231,"owner":"michaeljones","pathSuffix":"hello-apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434091626279,"blockSize":134217728,"childrenNum":0,"fileId":18298,"group":"supergroup","length":0,"modificationTime":1434091626286,"owner":"michaeljones","pathSuffix":"hello-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434159010131,"blockSize":134217728,"childrenNum":0,"fileId":18438,"group":"supergroup","length":0,"modificationTime":1434159010139,"owner":"michaeljones","pathSuffix":"hello-jersey-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434158894531,"blockSize":134217728,"childrenNum":0,"fileId":18437,"group":"supergroup","length":461138,"modificationTime":1434158894573,"owner":"michaeljones","pathSuffix":"hello.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434159013887,"blockSize":134217728,"childrenNum":0,"fileId":18442,"group":"supergroup","length":20,"modificationTime":1434159014350,"owner":"michaeljones","pathSuffix":"hello.txt","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434159010577,"blockSize":134217728,"childrenNum":0,"fileId":18440,"group":"supergroup","length":54643,"modificationTime":1434159010604,"owner":"michaeljones","pathSuffix":"hellohadoop.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434159020604,"blockSize":134217728,"childrenNum":0,"fileId":18465,"group":"supergroup","length":2134,"modificationTime":1434159020632,"owner":"michaeljones","pathSuffix":"pom.xml","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434159014921,"blockSize":134217728,"childrenNum":0,"fileId":16388,"group":"supergroup","length":50,"modificationTime":1433119638967,"owner":"michaeljones","pathSuffix":"wcInput","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18443,"group":"supergroup","length":0,"modificationTime":1434159016805,"owner":"michaeljones","pathSuffix":"wcOutput","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},
{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18450,"group":"supergroup","length":0,"modificationTime":1434159017973,"owner":"michaeljones","pathSuffix":"wcOutputAnalysis","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},
{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18457,"group":"supergroup","length":0,"modificationTime":1434159019678,"owner":"michaeljones","pathSuffix":"wcOutputMain","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"}
]}}

com.sun.jersey.client.property.chunkedEncodingSize: 1048576
stopping client from cache: org.apache.hadoop.ipc.Client@5674e1f2
removing client from cache: org.apache.hadoop.ipc.Client@5674e1f2
stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@5674e1f2
Stopping client
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones: closed
IPC Client (1558763625) connection to localhost/127.0.0.1:9000 from michaeljones: stopped, remaining connections 0
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 0][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://localhost:50070
Connecting to localhost/127.0.0.1:50070
Connection established 127.0.0.1:49370<->127.0.0.1:50070
Executing request GET /webhdfs/v1/user/michaeljones/?user.name=michaeljones&op=LISTSTATUS HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-0 >> GET /webhdfs/v1/user/michaeljones/?user.name=michaeljones&op=LISTSTATUS HTTP/1.1
http-outgoing-0 >> accept: application/json
http-outgoing-0 >> Host: localhost:50070
http-outgoing-0 >> Connection: Keep-Alive
http-outgoing-0 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-0 >> Accept-Encoding: gzip,deflate
http-outgoing-0 >> "GET /webhdfs/v1/user/michaeljones/?user.name=michaeljones&op=LISTSTATUS HTTP/1.1[\r][\n]"
http-outgoing-0 >> "accept: application/json[\r][\n]"
http-outgoing-0 >> "Host: localhost:50070[\r][\n]"
http-outgoing-0 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-0 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-0 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-0 >> "[\r][\n]"
http-outgoing-0 << "HTTP/1.1 200 OK[\r][\n]"
http-outgoing-0 << "Cache-Control: no-cache[\r][\n]"
http-outgoing-0 << "Expires: Sat, 13 Jun 2015 03:05:18 GMT[\r][\n]"
http-outgoing-0 << "Date: Sat, 13 Jun 2015 03:05:18 GMT[\r][\n]"
http-outgoing-0 << "Pragma: no-cache[\r][\n]"
http-outgoing-0 << "Expires: Sat, 13 Jun 2015 03:05:18 GMT[\r][\n]"
http-outgoing-0 << "Date: Sat, 13 Jun 2015 03:05:18 GMT[\r][\n]"
http-outgoing-0 << "Pragma: no-cache[\r][\n]"
http-outgoing-0 << "Content-Type: application/json[\r][\n]"
http-outgoing-0 << "Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434200718384&s=damkR4gk/eWuBO0bqtWgbxsc7Sw="; Path=/; Expires=Sat, 13-Jun-2015 13:05:18 GMT; HttpOnly[\r][\n]"
http-outgoing-0 << "Transfer-Encoding: chunked[\r][\n]"
http-outgoing-0 << "Server: Jetty(6.1.26)[\r][\n]"
http-outgoing-0 << "[\r][\n]"
http-outgoing-0 << "E9C[\r][\n]"
http-outgoing-0 << "{"FileStatuses":{"FileStatus":[[\n]"
http-outgoing-0 << "{"accessTime":1434159010777,"blockSize":134217728,"childrenNum":0,"fileId":18441,"group":"supergroup","length":10899,"modificationTime":1434159010812,"owner":"michaeljones","pathSuffix":"README.md","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434159020549,"blockSize":134217728,"childrenNum":0,"fileId":18464,"group":"supergroup","length":0,"modificationTime":1434159020554,"owner":"michaeljones","pathSuffix":"apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434159021414,"blockSize":134217728,"childrenNum":0,"fileId":18467,"group":"supergroup","length":0,"modificationTime":1434159021420,"owner":"michaeljones","pathSuffix":"empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434159010225,"blockSize":134217728,"childrenNum":0,"fileId":18439,"group":"supergroup","length":0,"modificationTime":1434159010231,"owner":"michaeljones","pathSuffix":"hello-apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434091626279,"blockSize":134217728,"childrenNum":0,"fileId":18298,"group":"supergroup","length":0,"modificationTime":1434091626286,"owner":"michaeljones","pathSuffix":"hello-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434159010131,"blockSize":134217728,"childrenNum":0,"fileId":18438,"group":"supergroup","length":0,"modificationTime":1434159010139,"owner":"michaeljones","pathSuffix":"hello-jersey-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434159021522,"blockSize":134217728,"childrenNum":0,"fileId":18468,"group":"supergroup","length":869081,"modificationTime":1434159021575,"owner":"michaeljones","pathSuffix":"hello.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434159013887,"blockSize":134217728,"childrenNum":0,"fileId":18442,"group":"supergroup","length":20,"modificationTime":1434159014350,"owner":"michaeljones","pathSuffix":"hello.txt","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434159010577,"blockSize":134217728,"childrenNum":0,"fileId":18440,"group":"supergroup","length":54643,"modificationTime":1434159010604,"owner":"michaeljones","pathSuffix":"hellohadoop.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434159020604,"blockSize":134217728,"childrenNum":0,"fileId":18465,"group":"supergroup","length":2134,"modificationTime":1434159020632,"owner":"michaeljones","pathSuffix":"pom.xml","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434159014921,"blockSize":134217728,"childrenNum":0,"fileId":16388,"group":"supergroup","length":50,"modificationTime":1433119638967,"owner":"michaeljones","pathSuffix":"wcInput","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18443,"group":"supergroup","length":0,"modificationTime":1434159016805,"owner":"michaeljones","pathSuffix":"wcOutput","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},[\n]"
http-outgoing-0 << "{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18450,"group":"supergroup","length":0,"modificationTime":1434159017973,"owner":"michaeljones","pathSuffix":"wcOutputAnalysis","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},[\n]"
http-outgoing-0 << "{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18457,"group":"supergroup","length":0,"modificationTime":1434159019678,"owner":"michaeljones","pathSuffix":"wcOutputMain","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"}[\n]"
http-outgoing-0 << "]}}[\n]"
http-outgoing-0 << "[\r][\n]"
http-outgoing-0 << HTTP/1.1 200 OK
http-outgoing-0 << Cache-Control: no-cache
http-outgoing-0 << Expires: Sat, 13 Jun 2015 03:05:18 GMT
http-outgoing-0 << Date: Sat, 13 Jun 2015 03:05:18 GMT
http-outgoing-0 << Pragma: no-cache
http-outgoing-0 << Expires: Sat, 13 Jun 2015 03:05:18 GMT
http-outgoing-0 << Date: Sat, 13 Jun 2015 03:05:18 GMT
http-outgoing-0 << Pragma: no-cache
http-outgoing-0 << Content-Type: application/json
http-outgoing-0 << Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434200718384&s=damkR4gk/eWuBO0bqtWgbxsc7Sw="; Path=/; Expires=Sat, 13-Jun-2015 13:05:18 GMT; HttpOnly
http-outgoing-0 << Transfer-Encoding: chunked
http-outgoing-0 << Server: Jetty(6.1.26)
Connection can be kept alive indefinitely
Cookie accepted [hadoop.auth=""u=michaeljones&p=michaeljones&t=simple&e=1434200718384&s=damkR4gk/eWuBO0bqtWgbxsc7Sw="", version:0, domain:localhost, path:/, expiry:Sat Jun 13 23:05:18 AEST 2015]
http-outgoing-0 << "0[\r][\n]"
http-outgoing-0 << "[\r][\n]"
Connection [id: 0][route: {}->http://localhost:50070] can be kept alive indefinitely
Connection released: [id: 0][route: {}->http://localhost:50070][total kept alive: 1; route allocated: 1 of 2; total allocated: 1 of 20]
Connection manager is shutting down
http-outgoing-0: Close connection
http-outgoing-0: Close connection
Connection manager shut down
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 1][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://localhost:50070
Connecting to localhost/127.0.0.1:50070
Connection established 127.0.0.1:49373<->127.0.0.1:50070
Executing request PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-1 >> PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1
http-outgoing-1 >> Content-Length: 0
http-outgoing-1 >> Host: localhost:50070
http-outgoing-1 >> Connection: Keep-Alive
http-outgoing-1 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-1 >> Accept-Encoding: gzip,deflate
http-outgoing-1 >> "PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1[\r][\n]"
http-outgoing-1 >> "Content-Length: 0[\r][\n]"
http-outgoing-1 >> "Host: localhost:50070[\r][\n]"
http-outgoing-1 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-1 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-1 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-1 >> "[\r][\n]"
http-outgoing-1 << "HTTP/1.1 307 TEMPORARY_REDIRECT[\r][\n]"
http-outgoing-1 << "Cache-Control: no-cache[\r][\n]"
http-outgoing-1 << "Expires: Sat, 13 Jun 2015 03:05:19 GMT[\r][\n]"
http-outgoing-1 << "Date: Sat, 13 Jun 2015 03:05:19 GMT[\r][\n]"
http-outgoing-1 << "Pragma: no-cache[\r][\n]"
http-outgoing-1 << "Expires: Sat, 13 Jun 2015 03:05:19 GMT[\r][\n]"
http-outgoing-1 << "Date: Sat, 13 Jun 2015 03:05:19 GMT[\r][\n]"
http-outgoing-1 << "Pragma: no-cache[\r][\n]"
http-outgoing-1 << "Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434200719797&s=ewvGJigoiJQot+lATAcfV9JWjxk="; Path=/; Expires=Sat, 13-Jun-2015 13:05:19 GMT; HttpOnly[\r][\n]"
http-outgoing-1 << "Location: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true[\r][\n]"
http-outgoing-1 << "Content-Type: application/octet-stream[\r][\n]"
http-outgoing-1 << "Content-Length: 0[\r][\n]"
http-outgoing-1 << "Server: Jetty(6.1.26)[\r][\n]"
http-outgoing-1 << "[\r][\n]"
http-outgoing-1 << HTTP/1.1 307 TEMPORARY_REDIRECT
http-outgoing-1 << Cache-Control: no-cache
http-outgoing-1 << Expires: Sat, 13 Jun 2015 03:05:19 GMT
http-outgoing-1 << Date: Sat, 13 Jun 2015 03:05:19 GMT
http-outgoing-1 << Pragma: no-cache
http-outgoing-1 << Expires: Sat, 13 Jun 2015 03:05:19 GMT
http-outgoing-1 << Date: Sat, 13 Jun 2015 03:05:19 GMT
http-outgoing-1 << Pragma: no-cache
http-outgoing-1 << Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434200719797&s=ewvGJigoiJQot+lATAcfV9JWjxk="; Path=/; Expires=Sat, 13-Jun-2015 13:05:19 GMT; HttpOnly
http-outgoing-1 << Location: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
http-outgoing-1 << Content-Type: application/octet-stream
http-outgoing-1 << Content-Length: 0
http-outgoing-1 << Server: Jetty(6.1.26)
Connection can be kept alive indefinitely
Cookie accepted [hadoop.auth=""u=michaeljones&p=michaeljones&t=simple&e=1434200719797&s=ewvGJigoiJQot+lATAcfV9JWjxk="", version:0, domain:localhost, path:/, expiry:Sat Jun 13 23:05:19 AEST 2015]
Redirect to: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
http-outgoing-1: Shutdown connection
Connection discarded
http-outgoing-1: Close connection
Connection released: [id: 1][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 2][route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://michaels-air.bigpond:50075
Connecting to michaels-air.bigpond/10.0.0.2:50075
Connection established 10.0.0.2:49374<->10.0.0.2:50075
Executing request PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-2 >> PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1
http-outgoing-2 >> Content-Length: 0
http-outgoing-2 >> Host: michaels-air.bigpond:50075
http-outgoing-2 >> Connection: Keep-Alive
http-outgoing-2 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-2 >> Accept-Encoding: gzip,deflate
http-outgoing-2 >> "PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1[\r][\n]"
http-outgoing-2 >> "Content-Length: 0[\r][\n]"
http-outgoing-2 >> "Host: michaels-air.bigpond:50075[\r][\n]"
http-outgoing-2 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-2 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-2 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-2 >> "[\r][\n]"
http-outgoing-2 << "HTTP/1.1 100 Continue[\r][\n]"
http-outgoing-2 << "[\r][\n]"
http-outgoing-2 << HTTP/1.1 100 Continue
http-outgoing-2 << "HTTP/1.1 201 Created[\r][\n]"
http-outgoing-2 << "Location: hdfs://localhost:9000/user/michaeljones/hello-apache-empty.txt[\r][\n]"
http-outgoing-2 << "Content-Length: 0[\r][\n]"
http-outgoing-2 << "Connection: close[\r][\n]"
http-outgoing-2 << "[\r][\n]"
http-outgoing-2 << HTTP/1.1 201 Created
http-outgoing-2 << Location: hdfs://localhost:9000/user/michaeljones/hello-apache-empty.txt
http-outgoing-2 << Content-Length: 0
http-outgoing-2 << Connection: close
http-outgoing-2: Shutdown connection
Connection discarded
http-outgoing-2: Close connection
Connection released: [id: 2][route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection manager is shutting down
Connection manager shut down
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 3][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://localhost:50070
Connecting to localhost/127.0.0.1:50070
Connection established 127.0.0.1:49380<->127.0.0.1:50070
Executing request PUT /webhdfs/v1/user/michaeljones/README.md?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-3 >> PUT /webhdfs/v1/user/michaeljones/README.md?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1
http-outgoing-3 >> Transfer-Encoding: chunked
http-outgoing-3 >> Content-Type: application/octet-stream
http-outgoing-3 >> Host: localhost:50070
http-outgoing-3 >> Connection: Keep-Alive
http-outgoing-3 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-3 >> Accept-Encoding: gzip,deflate
http-outgoing-3 >> "PUT /webhdfs/v1/user/michaeljones/README.md?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1[\r][\n]"
http-outgoing-3 >> "Transfer-Encoding: chunked[\r][\n]"
http-outgoing-3 >> "Content-Type: application/octet-stream[\r][\n]"
http-outgoing-3 >> "Host: localhost:50070[\r][\n]"
http-outgoing-3 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-3 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-3 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-3 >> "[\r][\n]"
http-outgoing-3 >> "1000[\r][\n]"
http-outgoing-3 >> "# Hello-Hadoop-netbeans-OS-X[\n]"
http-outgoing-3 >> "Java Maven project for playing with the HDFS API without any 3rd party hadoop plugins.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## Aim of project[\n]"
http-outgoing-3 >> "Hello world/tutorial level for programmatically operating with a pseudo distributed hadoop configuration on OS X. Hadoop 2.7 on Yosemite.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## What this project demonstrates[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "This is work in progress and so far the following functionality is demonstrated:[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "1. Direct programmatic control of the HDFS and running map reduce jobs - all unit tests run from the IDE with hadoop configuration built into this project and under git control.[\n]"
http-outgoing-3 >> "2. Uploading of files to the HDFS by implementing a Web REST API client.[\n]"
http-outgoing-3 >> "3. Layered application code for maximum re-use and ease of test driven development. The client I wrote uses an interface which has allowed me to provide both a Jersey HTTP client implementation and an Apache HTTP client implementation for comparison between the two toolkits.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "The initial difficulty was working out how to run the program in the IDE and talk to the local pseudo distributed setup without using a 3rd party Hadoop plugin. Apparently there used to be a plugin for netbeans, but it has been discontinued. I am a newbie with this technology.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "The Apache Hadoop instructions for building and running java programs are via their command line build/run utility only. Getting the yahoo hadoop HDFS tutorial program to build in the IDE wasn't too hard. However, by default it will ignore the local Hadoop configuration and only operate with the local file system in local debug mode.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## Wading through the configuration[\n]"
http-outgoing-3 >> "Hadoop is designed to work with a number of different topologies, directory locations, levels of replication, simulated environments etc. so as we would expect nothing works unless the configuration is right.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "First Hadoop needs to be installed and configured in pseudo distributed mode such that it builds and runs test programs on the command line. The hadoop documentation has instructions for doing this. Documentation is online and also included in the installation: share/doc/hadoop/index.html. However this is not enough to get it to work in the IDE.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## The netbeans project settings that are needed to run with the HDFS from the IDE:[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "1. Get log4j configured to work in the IDE. Absence of log4j configuration won't stop hadoop from running, but we won't get to see useful error messages from hadoop without it.[\n]"
http-outgoing-3 >> "2. HADOOP_HOME environment variable project run (and test) property.[\n]"
http-outgoing-3 >> "3. Duplicate hadoop configuration in the classpath. The above environment variable does not pick up the hadoop configuration from its usual place. Yahoo's only suggestion is to run from the command line via the hadoop script. The Apache HDFS API documention says that configuration is looked for in the classpath, so I took the approach of duplicating the configuration (just 2 files) instead of figuring out how to get it to look in the installation path.[\n]"
http-outgoing-3 >> "4. The correct Maven dependencies. If not all the jar depenencies are there the program may build and run, but it won't talk to the HDFS if it doesn't load the HDFS jars.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "I think that the setup of this project would probably work on Linux too.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## Working through trouble shooting the HDFS project settings[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "Issue 1 above shows up as:[\n]"
http-outgoing-3 >> "<pre><code>[\n]"
http-outgoing-3 >> "log4j:WARN No appenders could be found for logger (org.apache.hadoop.util.Shell).[\n]"
http-outgoing-3 >> "log4j:WARN Please initialize the log4j system properly.[\n]"
http-outgoing-3 >> "log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.[\n]"
http-outgoing-3 >> "</pre></code>[\n]"
http-outgoing-3 >> "This is solved by putting a log4j.properties configuration file in the classpath. For a Maven build getting files into the classpath can be achieved by putting them in src/main/resources. I don't think this is in the classpath, but the build will then copy the file into ./target/classes/ which is in the classpath.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "Issue 2 above shows up as:[\n]"
http-outgoing-3 >> "<pre><code>[\n]"
http-outgoing-3 >> "Failed to detect a valid hadoop home directory[\n]"
http-outgoing-3 >> "java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.[\n]"
http-outgoing-3 >> "</code></pre>[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "This is fixed by going into the project properties => Build => Actions => Run Project and adding the environmen[\r][\n]"
http-outgoing-3 >> "1000[\r][\n]"
http-outgoing-3 >> "t variable for HADOOP_HOME. This will result in an entry in the Maven POM. Repeat for "Test Project", "Debug Project" etc.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "Issue 3. shows up as running, but creating a file on the local file system instead of the HDFS. This was fixed       looking at the HDFS API documentation for org.apache.hadoop.conf.Configuration. This documentation is under the chapter: C API libhdfs HDFS which has a link to the HDFS API under "The APIs" (I strangely cannot find this in the main index). On my installation the HDFS API documentation link is file:///opt/local/hadoop-2.7.0/share/doc/hadoop/api/org/apache/hadoop/fs/FileSystem.html.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "This documentation told me that hadoop loads core-site.xml and core-default.xml in the classpath. Classpath for a Maven build can be reached by placing these files in the directory src/main/resources (see logging configuration above). I added hdfs-site instead of core-default (which doesn't exist on my 2.7 install) into the src/main/resources project directory.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "Issue 3 shows up as:[\n]"
http-outgoing-3 >> "<pre><code>[\n]"
http-outgoing-3 >> "java.io.IOException: "hadoop No FileSystem for scheme: hdfs".[\n]"
http-outgoing-3 >> "</code></pre>[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "This is part of the build dependency problem. The various threads on stackoverflow etc. suggested that a minimum dependency was the jar for hadoop-core. However, there is no such jar on 2.7. I ran the hadoop command to dump version and got this:[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "<pre><code>[\n]"
http-outgoing-3 >> "bin/hadoop version[\n]"
http-outgoing-3 >> "Hadoop 2.7.0[\n]"
http-outgoing-3 >> "Subversion https://git-wip-us.apache.org/repos/asf/hadoop.git -r d4c8d4d4d203c934e8074b31289a28724c0842cf[\n]"
http-outgoing-3 >> "Compiled by jenkins on 2015-04-10T18:40Z[\n]"
http-outgoing-3 >> "Compiled with protoc 2.5.0[\n]"
http-outgoing-3 >> "From source with checksum a9e90912c37a35c3195d23951fd18f[\n]"
http-outgoing-3 >> "This command was run using /opt/local/hadoop-2.7.0/share/hadoop/common/hadoop-common-2.7.0.jar[\n]"
http-outgoing-3 >> "</code></pre>[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "I noted the jar name at the end and added it as a dependency to the POM. This can either be hand coded in or right click pom.xml => Insert Code => Add Dependency => Search => query hadoop-common and select version which was 2.7.0 [jar] - central. Maven will then add dependencies to other hadoop jars in the "Dependencies" group in the project explorer. Netbeans will then download these dependencies before the next build. They go into ~/.m2/repository should they ever need to be cleaned out (Netbeans doesn't seem to have an IDE remove dependency option).[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "After doing the above project built, but showed up the "no filesystem error". I noticed that Maven had not pulled in any hdfs jars matching the jars in my share/hadoop/hdfs installation directory. So I took a guess that it needed only the top level hadoop-hdfs-2.7.0.jar and added this as a dependency to the POM and all was good :)[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## Working through trouble shooting the Map Reduce project settings[\n]"
http-outgoing-3 >> "After getting the HDFS API working in the IDE it was time to move on to getting the famous Word Count map-reduce tutorial running.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "So coded it, set the main program to the word count main as the one to run. From the IDE: project Properties => Run => Main Class. Provide input and output arguments for the word count program. I noted that the netbeans properties pop-up window does not persist these settings next time it pops up. However this setting is persistant and ends up in nbactions.xml.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "However, running the word count map reduce program resulted in an ioException:[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "<pre><code>[\n]"
http-outgoing-3 >> "Please check your configuration for mapreduce.framework.name and the correspond server addresses.[\n]"
http-outgoing-3 >> "</pre></code>[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "Because the resources directory only contains 2 configuration files from my hadoop installation I thought maybe I was missing a map reduce one. So the first thing I did was go into the configuration directory of my installation and grep all files to see if there was a configuration file with mapreduce framework property. There was not. I checked my programatic configuration dump from my test program. This property was not mentioned either. The only map reduce configuration was to do with some environment variables for heap size in one of the shell scripts. Note to self: this may be relevant and I can consider setting this in the IDE. However, that didn't look like the problem.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "I then chec[\r][\n]"
http-outgoing-3 >> "a93[\r][\n]"
http-outgoing-3 >> "ked my dependencies and noted there were no map reduce jars pulled in by Maven. So I added hadoop-mapreduce-client-core. Still not running. Checked the web and a thread on stackoverflow mentioned a number of other jars: hadoop-mapreduce-client-common and hadoop-mapreduce-client shuffle. I added just the hadoop-mapreduce-client-common and it runs :) I have a feeling that I might need some of the other jars for other API calls and that there must be a better way of working out dependencies than this trial and error. As mentioned I am a newbie with this, so if anyone has any comments feel free to email me.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## Logging from application code[\n]"
http-outgoing-3 >> "Although the hadoop libraries log correctly with a properly located log4.properties file, application code calling the log4j logger seems to ignore this file. Using the log4j logger as per instructions in the log4j manual and many online tutorials did not result in getting any logging redirected to file configured in the properties file. Instead console output only is obtained. A clue to this mystery was that a most basic of hello world netbeans maven projects which did not import any hadoop stuff also failed to log to a file and did not even give the "No appenders" warning. Then I noticed that there were org.sl4j depencies in the hadoop build, so using sl4j instead solved the problem. Once my hello world project used sl4j's LoggerFactory and had sl4j-api and sl4j-12 as a dependencies it started to use the properties file. See http://www.slf4j.org/manual.html[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## Upload a file from local storage to the HDFS via the REST API[\n]"
http-outgoing-3 >> "The WebHDFS REST API documentation which came with the installation specifies that file creation is a two stage operation where an initial PUT to the namenode is sent. This responds with a redirect to the datanode and another PUT should be made to this redirection which can contain the chunked data stream. This does not sound REST to me as it relies on holding redirection state (a fully distributed configuration could presumably return a redirection to any one of the datanodes). Hadoop say this is because of a bug in some HTTP client implementations - incorrect implementation of [0xe2][0x80][0x9c]Expect: 100-continue[0xe2][0x80][0x9d].[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "However, the 2 stage PUT not being REST seems to be a moot point, at least with the Jersey client. I do not get a redirection and a file creates/uploads all in one go.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "Since writing the above paragraph I have implemented the Apache Client back end option to my HDFS Web client interface and this client behaves differently. It does indeed cause a redirect as per Hadoop documentation. The follow up PUT to the redirected location with the chunked file stream works as per documentation.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "To be continued ...[\n]"
http-outgoing-3 >> "[\r][\n]"
http-outgoing-3 >> "0[\r][\n]"
http-outgoing-3 >> "[\r][\n]"
http-outgoing-3 << "HTTP/1.1 307 TEMPORARY_REDIRECT[\r][\n]"
http-outgoing-3 << "Cache-Control: no-cache[\r][\n]"
http-outgoing-3 << "Expires: Sat, 13 Jun 2015 03:05:20 GMT[\r][\n]"
http-outgoing-3 << "Date: Sat, 13 Jun 2015 03:05:20 GMT[\r][\n]"
http-outgoing-3 << "Pragma: no-cache[\r][\n]"
http-outgoing-3 << "Expires: Sat, 13 Jun 2015 03:05:20 GMT[\r][\n]"
http-outgoing-3 << "Date: Sat, 13 Jun 2015 03:05:20 GMT[\r][\n]"
http-outgoing-3 << "Pragma: no-cache[\r][\n]"
http-outgoing-3 << "Content-Type: application/octet-stream[\r][\n]"
http-outgoing-3 << "Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434200720744&s=zDmThBZ+h2AwgaGU81iLfZ0fObc="; Path=/; Expires=Sat, 13-Jun-2015 13:05:20 GMT; HttpOnly[\r][\n]"
http-outgoing-3 << "Location: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/README.md?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true[\r][\n]"
http-outgoing-3 << "Content-Length: 0[\r][\n]"
http-outgoing-3 << "Server: Jetty(6.1.26)[\r][\n]"
http-outgoing-3 << "[\r][\n]"
http-outgoing-3 << HTTP/1.1 307 TEMPORARY_REDIRECT
http-outgoing-3 << Cache-Control: no-cache
http-outgoing-3 << Expires: Sat, 13 Jun 2015 03:05:20 GMT
http-outgoing-3 << Date: Sat, 13 Jun 2015 03:05:20 GMT
http-outgoing-3 << Pragma: no-cache
http-outgoing-3 << Expires: Sat, 13 Jun 2015 03:05:20 GMT
http-outgoing-3 << Date: Sat, 13 Jun 2015 03:05:20 GMT
http-outgoing-3 << Pragma: no-cache
http-outgoing-3 << Content-Type: application/octet-stream
http-outgoing-3 << Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434200720744&s=zDmThBZ+h2AwgaGU81iLfZ0fObc="; Path=/; Expires=Sat, 13-Jun-2015 13:05:20 GMT; HttpOnly
http-outgoing-3 << Location: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/README.md?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
http-outgoing-3 << Content-Length: 0
http-outgoing-3 << Server: Jetty(6.1.26)
Connection can be kept alive indefinitely
Cookie accepted [hadoop.auth=""u=michaeljones&p=michaeljones&t=simple&e=1434200720744&s=zDmThBZ+h2AwgaGU81iLfZ0fObc="", version:0, domain:localhost, path:/, expiry:Sat Jun 13 23:05:20 AEST 2015]
Redirect to: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/README.md?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
http-outgoing-3: Shutdown connection
Connection discarded
http-outgoing-3: Close connection
Connection released: [id: 3][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 4][route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://michaels-air.bigpond:50075
Connecting to michaels-air.bigpond/10.0.0.2:50075
Connection established 10.0.0.2:49381<->10.0.0.2:50075
Executing request PUT /webhdfs/v1/user/michaeljones/README.md?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-4 >> PUT /webhdfs/v1/user/michaeljones/README.md?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1
http-outgoing-4 >> Transfer-Encoding: chunked
http-outgoing-4 >> Content-Type: application/octet-stream
http-outgoing-4 >> Host: michaels-air.bigpond:50075
http-outgoing-4 >> Connection: Keep-Alive
http-outgoing-4 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-4 >> Accept-Encoding: gzip,deflate
http-outgoing-4 >> "PUT /webhdfs/v1/user/michaeljones/README.md?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1[\r][\n]"
http-outgoing-4 >> "Transfer-Encoding: chunked[\r][\n]"
http-outgoing-4 >> "Content-Type: application/octet-stream[\r][\n]"
http-outgoing-4 >> "Host: michaels-air.bigpond:50075[\r][\n]"
http-outgoing-4 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-4 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-4 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-4 >> "[\r][\n]"
http-outgoing-4 >> "1000[\r][\n]"
http-outgoing-4 >> "# Hello-Hadoop-netbeans-OS-X[\n]"
http-outgoing-4 >> "Java Maven project for playing with the HDFS API without any 3rd party hadoop plugins.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## Aim of project[\n]"
http-outgoing-4 >> "Hello world/tutorial level for programmatically operating with a pseudo distributed hadoop configuration on OS X. Hadoop 2.7 on Yosemite.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## What this project demonstrates[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "This is work in progress and so far the following functionality is demonstrated:[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "1. Direct programmatic control of the HDFS and running map reduce jobs - all unit tests run from the IDE with hadoop configuration built into this project and under git control.[\n]"
http-outgoing-4 >> "2. Uploading of files to the HDFS by implementing a Web REST API client.[\n]"
http-outgoing-4 >> "3. Layered application code for maximum re-use and ease of test driven development. The client I wrote uses an interface which has allowed me to provide both a Jersey HTTP client implementation and an Apache HTTP client implementation for comparison between the two toolkits.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "The initial difficulty was working out how to run the program in the IDE and talk to the local pseudo distributed setup without using a 3rd party Hadoop plugin. Apparently there used to be a plugin for netbeans, but it has been discontinued. I am a newbie with this technology.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "The Apache Hadoop instructions for building and running java programs are via their command line build/run utility only. Getting the yahoo hadoop HDFS tutorial program to build in the IDE wasn't too hard. However, by default it will ignore the local Hadoop configuration and only operate with the local file system in local debug mode.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## Wading through the configuration[\n]"
http-outgoing-4 >> "Hadoop is designed to work with a number of different topologies, directory locations, levels of replication, simulated environments etc. so as we would expect nothing works unless the configuration is right.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "First Hadoop needs to be installed and configured in pseudo distributed mode such that it builds and runs test programs on the command line. The hadoop documentation has instructions for doing this. Documentation is online and also included in the installation: share/doc/hadoop/index.html. However this is not enough to get it to work in the IDE.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## The netbeans project settings that are needed to run with the HDFS from the IDE:[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "1. Get log4j configured to work in the IDE. Absence of log4j configuration won't stop hadoop from running, but we won't get to see useful error messages from hadoop without it.[\n]"
http-outgoing-4 >> "2. HADOOP_HOME environment variable project run (and test) property.[\n]"
http-outgoing-4 >> "3. Duplicate hadoop configuration in the classpath. The above environment variable does not pick up the hadoop configuration from its usual place. Yahoo's only suggestion is to run from the command line via the hadoop script. The Apache HDFS API documention says that configuration is looked for in the classpath, so I took the approach of duplicating the configuration (just 2 files) instead of figuring out how to get it to look in the installation path.[\n]"
http-outgoing-4 >> "4. The correct Maven dependencies. If not all the jar depenencies are there the program may build and run, but it won't talk to the HDFS if it doesn't load the HDFS jars.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "I think that the setup of this project would probably work on Linux too.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## Working through trouble shooting the HDFS project settings[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "Issue 1 above shows up as:[\n]"
http-outgoing-4 >> "<pre><code>[\n]"
http-outgoing-4 >> "log4j:WARN No appenders could be found for logger (org.apache.hadoop.util.Shell).[\n]"
http-outgoing-4 >> "log4j:WARN Please initialize the log4j system properly.[\n]"
http-outgoing-4 >> "log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.[\n]"
http-outgoing-4 >> "</pre></code>[\n]"
http-outgoing-4 >> "This is solved by putting a log4j.properties configuration file in the classpath. For a Maven build getting files into the classpath can be achieved by putting them in src/main/resources. I don't think this is in the classpath, but the build will then copy the file into ./target/classes/ which is in the classpath.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "Issue 2 above shows up as:[\n]"
http-outgoing-4 >> "<pre><code>[\n]"
http-outgoing-4 >> "Failed to detect a valid hadoop home directory[\n]"
http-outgoing-4 >> "java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.[\n]"
http-outgoing-4 >> "</code></pre>[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "This is fixed by going into the project properties => Build => Actions => Run Project and adding the environmen[\r][\n]"
http-outgoing-4 >> "1000[\r][\n]"
http-outgoing-4 >> "t variable for HADOOP_HOME. This will result in an entry in the Maven POM. Repeat for "Test Project", "Debug Project" etc.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "Issue 3. shows up as running, but creating a file on the local file system instead of the HDFS. This was fixed       looking at the HDFS API documentation for org.apache.hadoop.conf.Configuration. This documentation is under the chapter: C API libhdfs HDFS which has a link to the HDFS API under "The APIs" (I strangely cannot find this in the main index). On my installation the HDFS API documentation link is file:///opt/local/hadoop-2.7.0/share/doc/hadoop/api/org/apache/hadoop/fs/FileSystem.html.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "This documentation told me that hadoop loads core-site.xml and core-default.xml in the classpath. Classpath for a Maven build can be reached by placing these files in the directory src/main/resources (see logging configuration above). I added hdfs-site instead of core-default (which doesn't exist on my 2.7 install) into the src/main/resources project directory.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "Issue 3 shows up as:[\n]"
http-outgoing-4 >> "<pre><code>[\n]"
http-outgoing-4 >> "java.io.IOException: "hadoop No FileSystem for scheme: hdfs".[\n]"
http-outgoing-4 >> "</code></pre>[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "This is part of the build dependency problem. The various threads on stackoverflow etc. suggested that a minimum dependency was the jar for hadoop-core. However, there is no such jar on 2.7. I ran the hadoop command to dump version and got this:[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "<pre><code>[\n]"
http-outgoing-4 >> "bin/hadoop version[\n]"
http-outgoing-4 >> "Hadoop 2.7.0[\n]"
http-outgoing-4 >> "Subversion https://git-wip-us.apache.org/repos/asf/hadoop.git -r d4c8d4d4d203c934e8074b31289a28724c0842cf[\n]"
http-outgoing-4 >> "Compiled by jenkins on 2015-04-10T18:40Z[\n]"
http-outgoing-4 >> "Compiled with protoc 2.5.0[\n]"
http-outgoing-4 >> "From source with checksum a9e90912c37a35c3195d23951fd18f[\n]"
http-outgoing-4 >> "This command was run using /opt/local/hadoop-2.7.0/share/hadoop/common/hadoop-common-2.7.0.jar[\n]"
http-outgoing-4 >> "</code></pre>[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "I noted the jar name at the end and added it as a dependency to the POM. This can either be hand coded in or right click pom.xml => Insert Code => Add Dependency => Search => query hadoop-common and select version which was 2.7.0 [jar] - central. Maven will then add dependencies to other hadoop jars in the "Dependencies" group in the project explorer. Netbeans will then download these dependencies before the next build. They go into ~/.m2/repository should they ever need to be cleaned out (Netbeans doesn't seem to have an IDE remove dependency option).[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "After doing the above project built, but showed up the "no filesystem error". I noticed that Maven had not pulled in any hdfs jars matching the jars in my share/hadoop/hdfs installation directory. So I took a guess that it needed only the top level hadoop-hdfs-2.7.0.jar and added this as a dependency to the POM and all was good :)[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## Working through trouble shooting the Map Reduce project settings[\n]"
http-outgoing-4 >> "After getting the HDFS API working in the IDE it was time to move on to getting the famous Word Count map-reduce tutorial running.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "So coded it, set the main program to the word count main as the one to run. From the IDE: project Properties => Run => Main Class. Provide input and output arguments for the word count program. I noted that the netbeans properties pop-up window does not persist these settings next time it pops up. However this setting is persistant and ends up in nbactions.xml.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "However, running the word count map reduce program resulted in an ioException:[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "<pre><code>[\n]"
http-outgoing-4 >> "Please check your configuration for mapreduce.framework.name and the correspond server addresses.[\n]"
http-outgoing-4 >> "</pre></code>[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "Because the resources directory only contains 2 configuration files from my hadoop installation I thought maybe I was missing a map reduce one. So the first thing I did was go into the configuration directory of my installation and grep all files to see if there was a configuration file with mapreduce framework property. There was not. I checked my programatic configuration dump from my test program. This property was not mentioned either. The only map reduce configuration was to do with some environment variables for heap size in one of the shell scripts. Note to self: this may be relevant and I can consider setting this in the IDE. However, that didn't look like the problem.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "I then chec[\r][\n]"
http-outgoing-4 >> "a93[\r][\n]"
http-outgoing-4 >> "ked my dependencies and noted there were no map reduce jars pulled in by Maven. So I added hadoop-mapreduce-client-core. Still not running. Checked the web and a thread on stackoverflow mentioned a number of other jars: hadoop-mapreduce-client-common and hadoop-mapreduce-client shuffle. I added just the hadoop-mapreduce-client-common and it runs :) I have a feeling that I might need some of the other jars for other API calls and that there must be a better way of working out dependencies than this trial and error. As mentioned I am a newbie with this, so if anyone has any comments feel free to email me.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## Logging from application code[\n]"
http-outgoing-4 >> "Although the hadoop libraries log correctly with a properly located log4.properties file, application code calling the log4j logger seems to ignore this file. Using the log4j logger as per instructions in the log4j manual and many online tutorials did not result in getting any logging redirected to file configured in the properties file. Instead console output only is obtained. A clue to this mystery was that a most basic of hello world netbeans maven projects which did not import any hadoop stuff also failed to log to a file and did not even give the "No appenders" warning. Then I noticed that there were org.sl4j depencies in the hadoop build, so using sl4j instead solved the problem. Once my hello world project used sl4j's LoggerFactory and had sl4j-api and sl4j-12 as a dependencies it started to use the properties file. See http://www.slf4j.org/manual.html[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## Upload a file from local storage to the HDFS via the REST API[\n]"
http-outgoing-4 >> "The WebHDFS REST API documentation which came with the installation specifies that file creation is a two stage operation where an initial PUT to the namenode is sent. This responds with a redirect to the datanode and another PUT should be made to this redirection which can contain the chunked data stream. This does not sound REST to me as it relies on holding redirection state (a fully distributed configuration could presumably return a redirection to any one of the datanodes). Hadoop say this is because of a bug in some HTTP client implementations - incorrect implementation of [0xe2][0x80][0x9c]Expect: 100-continue[0xe2][0x80][0x9d].[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "However, the 2 stage PUT not being REST seems to be a moot point, at least with the Jersey client. I do not get a redirection and a file creates/uploads all in one go.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "Since writing the above paragraph I have implemented the Apache Client back end option to my HDFS Web client interface and this client behaves differently. It does indeed cause a redirect as per Hadoop documentation. The follow up PUT to the redirected location with the chunked file stream works as per documentation.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "To be continued ...[\n]"
http-outgoing-4 >> "[\r][\n]"
http-outgoing-4 >> "0[\r][\n]"
http-outgoing-4 >> "[\r][\n]"
http-outgoing-4 << "HTTP/1.1 100 Continue[\r][\n]"
http-outgoing-4 << "[\r][\n]"
http-outgoing-4 << HTTP/1.1 100 Continue
http-outgoing-4 << "HTTP/1.1 201 Created[\r][\n]"
http-outgoing-4 << "Location: hdfs://localhost:9000/user/michaeljones/README.md[\r][\n]"
http-outgoing-4 << "Content-Length: 0[\r][\n]"
http-outgoing-4 << "Connection: close[\r][\n]"
http-outgoing-4 << "[\r][\n]"
http-outgoing-4 << HTTP/1.1 201 Created
http-outgoing-4 << Location: hdfs://localhost:9000/user/michaeljones/README.md
http-outgoing-4 << Content-Length: 0
http-outgoing-4 << Connection: close
http-outgoing-4: Shutdown connection
Connection discarded
http-outgoing-4: Close connection
Connection released: [id: 4][route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection manager is shutting down
Connection manager shut down
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 0][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://localhost:50070
Connecting to localhost/127.0.0.1:50070
Connection established 127.0.0.1:49404<->127.0.0.1:50070
Executing request GET /webhdfs/v1/user/michaeljones/?user.name=michaeljones&op=LISTSTATUS HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-0 >> GET /webhdfs/v1/user/michaeljones/?user.name=michaeljones&op=LISTSTATUS HTTP/1.1
http-outgoing-0 >> accept: application/json
http-outgoing-0 >> Host: localhost:50070
http-outgoing-0 >> Connection: Keep-Alive
http-outgoing-0 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-0 >> Accept-Encoding: gzip,deflate
http-outgoing-0 >> "GET /webhdfs/v1/user/michaeljones/?user.name=michaeljones&op=LISTSTATUS HTTP/1.1[\r][\n]"
http-outgoing-0 >> "accept: application/json[\r][\n]"
http-outgoing-0 >> "Host: localhost:50070[\r][\n]"
http-outgoing-0 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-0 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-0 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-0 >> "[\r][\n]"
http-outgoing-0 << "HTTP/1.1 200 OK[\r][\n]"
http-outgoing-0 << "Cache-Control: no-cache[\r][\n]"
http-outgoing-0 << "Expires: Sat, 13 Jun 2015 03:08:35 GMT[\r][\n]"
http-outgoing-0 << "Date: Sat, 13 Jun 2015 03:08:35 GMT[\r][\n]"
http-outgoing-0 << "Pragma: no-cache[\r][\n]"
http-outgoing-0 << "Expires: Sat, 13 Jun 2015 03:08:35 GMT[\r][\n]"
http-outgoing-0 << "Date: Sat, 13 Jun 2015 03:08:35 GMT[\r][\n]"
http-outgoing-0 << "Pragma: no-cache[\r][\n]"
http-outgoing-0 << "Content-Type: application/json[\r][\n]"
http-outgoing-0 << "Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434200915689&s=wG+D+j2nBrQG9CfHUcHx1yqTPgQ="; Path=/; Expires=Sat, 13-Jun-2015 13:08:35 GMT; HttpOnly[\r][\n]"
http-outgoing-0 << "Transfer-Encoding: chunked[\r][\n]"
http-outgoing-0 << "Server: Jetty(6.1.26)[\r][\n]"
http-outgoing-0 << "[\r][\n]"
http-outgoing-0 << "E9C[\r][\n]"
http-outgoing-0 << "{"FileStatuses":{"FileStatus":[[\n]"
http-outgoing-0 << "{"accessTime":1434164720788,"blockSize":134217728,"childrenNum":0,"fileId":18472,"group":"supergroup","length":10899,"modificationTime":1434164720848,"owner":"michaeljones","pathSuffix":"README.md","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434159020549,"blockSize":134217728,"childrenNum":0,"fileId":18464,"group":"supergroup","length":0,"modificationTime":1434159020554,"owner":"michaeljones","pathSuffix":"apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434159021414,"blockSize":134217728,"childrenNum":0,"fileId":18467,"group":"supergroup","length":0,"modificationTime":1434159021420,"owner":"michaeljones","pathSuffix":"empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434164719826,"blockSize":134217728,"childrenNum":0,"fileId":18470,"group":"supergroup","length":0,"modificationTime":1434164719836,"owner":"michaeljones","pathSuffix":"hello-apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434091626279,"blockSize":134217728,"childrenNum":0,"fileId":18298,"group":"supergroup","length":0,"modificationTime":1434091626286,"owner":"michaeljones","pathSuffix":"hello-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434164719677,"blockSize":134217728,"childrenNum":0,"fileId":18469,"group":"supergroup","length":0,"modificationTime":1434164719764,"owner":"michaeljones","pathSuffix":"hello-jersey-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434159021522,"blockSize":134217728,"childrenNum":0,"fileId":18468,"group":"supergroup","length":869081,"modificationTime":1434159021575,"owner":"michaeljones","pathSuffix":"hello.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434159013887,"blockSize":134217728,"childrenNum":0,"fileId":18442,"group":"supergroup","length":20,"modificationTime":1434159014350,"owner":"michaeljones","pathSuffix":"hello.txt","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434164720026,"blockSize":134217728,"childrenNum":0,"fileId":18471,"group":"supergroup","length":62912,"modificationTime":1434164720697,"owner":"michaeljones","pathSuffix":"hellohadoop.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434159020604,"blockSize":134217728,"childrenNum":0,"fileId":18465,"group":"supergroup","length":2134,"modificationTime":1434159020632,"owner":"michaeljones","pathSuffix":"pom.xml","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434159014921,"blockSize":134217728,"childrenNum":0,"fileId":16388,"group":"supergroup","length":50,"modificationTime":1433119638967,"owner":"michaeljones","pathSuffix":"wcInput","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18443,"group":"supergroup","length":0,"modificationTime":1434159016805,"owner":"michaeljones","pathSuffix":"wcOutput","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},[\n]"
http-outgoing-0 << "{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18450,"group":"supergroup","length":0,"modificationTime":1434159017973,"owner":"michaeljones","pathSuffix":"wcOutputAnalysis","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},[\n]"
http-outgoing-0 << "{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18457,"group":"supergroup","length":0,"modificationTime":1434159019678,"owner":"michaeljones","pathSuffix":"wcOutputMain","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"}[\n]"
http-outgoing-0 << "]}}[\n]"
http-outgoing-0 << "[\r][\n]"
http-outgoing-0 << "0[\r][\n]"
http-outgoing-0 << "[\r][\n]"
http-outgoing-0 << HTTP/1.1 200 OK
http-outgoing-0 << Cache-Control: no-cache
http-outgoing-0 << Expires: Sat, 13 Jun 2015 03:08:35 GMT
http-outgoing-0 << Date: Sat, 13 Jun 2015 03:08:35 GMT
http-outgoing-0 << Pragma: no-cache
http-outgoing-0 << Expires: Sat, 13 Jun 2015 03:08:35 GMT
http-outgoing-0 << Date: Sat, 13 Jun 2015 03:08:35 GMT
http-outgoing-0 << Pragma: no-cache
http-outgoing-0 << Content-Type: application/json
http-outgoing-0 << Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434200915689&s=wG+D+j2nBrQG9CfHUcHx1yqTPgQ="; Path=/; Expires=Sat, 13-Jun-2015 13:08:35 GMT; HttpOnly
http-outgoing-0 << Transfer-Encoding: chunked
http-outgoing-0 << Server: Jetty(6.1.26)
Connection can be kept alive indefinitely
Cookie accepted [hadoop.auth=""u=michaeljones&p=michaeljones&t=simple&e=1434200915689&s=wG+D+j2nBrQG9CfHUcHx1yqTPgQ="", version:0, domain:localhost, path:/, expiry:Sat Jun 13 23:08:35 AEST 2015]
Connection [id: 0][route: {}->http://localhost:50070] can be kept alive indefinitely
Connection released: [id: 0][route: {}->http://localhost:50070][total kept alive: 1; route allocated: 1 of 2; total allocated: 1 of 20]
Connection manager is shutting down
http-outgoing-0: Close connection
http-outgoing-0: Close connection
Connection manager shut down
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 1][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://localhost:50070
Connecting to localhost/127.0.0.1:50070
Connection established 127.0.0.1:49407<->127.0.0.1:50070
Executing request PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-1 >> PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1
http-outgoing-1 >> Content-Length: 0
http-outgoing-1 >> Host: localhost:50070
http-outgoing-1 >> Connection: Keep-Alive
http-outgoing-1 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-1 >> Accept-Encoding: gzip,deflate
http-outgoing-1 >> "PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1[\r][\n]"
http-outgoing-1 >> "Content-Length: 0[\r][\n]"
http-outgoing-1 >> "Host: localhost:50070[\r][\n]"
http-outgoing-1 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-1 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-1 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-1 >> "[\r][\n]"
http-outgoing-1 << "HTTP/1.1 307 TEMPORARY_REDIRECT[\r][\n]"
http-outgoing-1 << "Cache-Control: no-cache[\r][\n]"
http-outgoing-1 << "Expires: Sat, 13 Jun 2015 03:08:36 GMT[\r][\n]"
http-outgoing-1 << "Date: Sat, 13 Jun 2015 03:08:36 GMT[\r][\n]"
http-outgoing-1 << "Pragma: no-cache[\r][\n]"
http-outgoing-1 << "Expires: Sat, 13 Jun 2015 03:08:36 GMT[\r][\n]"
http-outgoing-1 << "Date: Sat, 13 Jun 2015 03:08:36 GMT[\r][\n]"
http-outgoing-1 << "Pragma: no-cache[\r][\n]"
http-outgoing-1 << "Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434200916204&s=OUN48JrzZUNsw1qTBkJh1NrFaWQ="; Path=/; Expires=Sat, 13-Jun-2015 13:08:36 GMT; HttpOnly[\r][\n]"
http-outgoing-1 << "Location: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true[\r][\n]"
http-outgoing-1 << "Content-Type: application/octet-stream[\r][\n]"
http-outgoing-1 << "Content-Length: 0[\r][\n]"
http-outgoing-1 << "Server: Jetty(6.1.26)[\r][\n]"
http-outgoing-1 << "[\r][\n]"
http-outgoing-1 << HTTP/1.1 307 TEMPORARY_REDIRECT
http-outgoing-1 << Cache-Control: no-cache
http-outgoing-1 << Expires: Sat, 13 Jun 2015 03:08:36 GMT
http-outgoing-1 << Date: Sat, 13 Jun 2015 03:08:36 GMT
http-outgoing-1 << Pragma: no-cache
http-outgoing-1 << Expires: Sat, 13 Jun 2015 03:08:36 GMT
http-outgoing-1 << Date: Sat, 13 Jun 2015 03:08:36 GMT
http-outgoing-1 << Pragma: no-cache
http-outgoing-1 << Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434200916204&s=OUN48JrzZUNsw1qTBkJh1NrFaWQ="; Path=/; Expires=Sat, 13-Jun-2015 13:08:36 GMT; HttpOnly
http-outgoing-1 << Location: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
http-outgoing-1 << Content-Type: application/octet-stream
http-outgoing-1 << Content-Length: 0
http-outgoing-1 << Server: Jetty(6.1.26)
Connection can be kept alive indefinitely
Cookie accepted [hadoop.auth=""u=michaeljones&p=michaeljones&t=simple&e=1434200916204&s=OUN48JrzZUNsw1qTBkJh1NrFaWQ="", version:0, domain:localhost, path:/, expiry:Sat Jun 13 23:08:36 AEST 2015]
Redirect to: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
http-outgoing-1: Shutdown connection
Connection discarded
http-outgoing-1: Close connection
Connection released: [id: 1][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 2][route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://michaels-air.bigpond:50075
Connecting to michaels-air.bigpond/10.0.0.2:50075
Connection established 10.0.0.2:49408<->10.0.0.2:50075
Executing request PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-2 >> PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1
http-outgoing-2 >> Content-Length: 0
http-outgoing-2 >> Host: michaels-air.bigpond:50075
http-outgoing-2 >> Connection: Keep-Alive
http-outgoing-2 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-2 >> Accept-Encoding: gzip,deflate
http-outgoing-2 >> "PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1[\r][\n]"
http-outgoing-2 >> "Content-Length: 0[\r][\n]"
http-outgoing-2 >> "Host: michaels-air.bigpond:50075[\r][\n]"
http-outgoing-2 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-2 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-2 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-2 >> "[\r][\n]"
http-outgoing-2 << "HTTP/1.1 100 Continue[\r][\n]"
http-outgoing-2 << "[\r][\n]"
http-outgoing-2 << HTTP/1.1 100 Continue
http-outgoing-2 << "HTTP/1.1 201 Created[\r][\n]"
http-outgoing-2 << "Location: hdfs://localhost:9000/user/michaeljones/hello-apache-empty.txt[\r][\n]"
http-outgoing-2 << "Content-Length: 0[\r][\n]"
http-outgoing-2 << "Connection: close[\r][\n]"
http-outgoing-2 << "[\r][\n]"
http-outgoing-2 << HTTP/1.1 201 Created
http-outgoing-2 << Location: hdfs://localhost:9000/user/michaeljones/hello-apache-empty.txt
http-outgoing-2 << Content-Length: 0
http-outgoing-2 << Connection: close
http-outgoing-2: Shutdown connection
Connection discarded
http-outgoing-2: Close connection
Connection released: [id: 2][route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection manager is shutting down
Connection manager shut down
com.sun.jersey.client.property.chunkedEncodingSize: 1048576
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 0][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://localhost:50070
Connecting to localhost/127.0.0.1:50070
Connection established 127.0.0.1:49484<->127.0.0.1:50070
Executing request GET /webhdfs/v1/user/michaeljones/?user.name=michaeljones&op=LISTSTATUS HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-0 >> GET /webhdfs/v1/user/michaeljones/?user.name=michaeljones&op=LISTSTATUS HTTP/1.1
http-outgoing-0 >> accept: application/json
http-outgoing-0 >> Host: localhost:50070
http-outgoing-0 >> Connection: Keep-Alive
http-outgoing-0 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-0 >> Accept-Encoding: gzip,deflate
http-outgoing-0 >> "GET /webhdfs/v1/user/michaeljones/?user.name=michaeljones&op=LISTSTATUS HTTP/1.1[\r][\n]"
http-outgoing-0 >> "accept: application/json[\r][\n]"
http-outgoing-0 >> "Host: localhost:50070[\r][\n]"
http-outgoing-0 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-0 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-0 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-0 >> "[\r][\n]"
http-outgoing-0 << "HTTP/1.1 200 OK[\r][\n]"
http-outgoing-0 << "Cache-Control: no-cache[\r][\n]"
http-outgoing-0 << "Expires: Sat, 13 Jun 2015 03:17:54 GMT[\r][\n]"
http-outgoing-0 << "Date: Sat, 13 Jun 2015 03:17:54 GMT[\r][\n]"
http-outgoing-0 << "Pragma: no-cache[\r][\n]"
http-outgoing-0 << "Expires: Sat, 13 Jun 2015 03:17:54 GMT[\r][\n]"
http-outgoing-0 << "Date: Sat, 13 Jun 2015 03:17:54 GMT[\r][\n]"
http-outgoing-0 << "Pragma: no-cache[\r][\n]"
http-outgoing-0 << "Content-Type: application/json[\r][\n]"
http-outgoing-0 << "Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434201474566&s=SFivall28yPViGBio2KcHauGlfk="; Path=/; Expires=Sat, 13-Jun-2015 13:17:54 GMT; HttpOnly[\r][\n]"
http-outgoing-0 << "Transfer-Encoding: chunked[\r][\n]"
http-outgoing-0 << "Server: Jetty(6.1.26)[\r][\n]"
http-outgoing-0 << "[\r][\n]"
http-outgoing-0 << "E9C[\r][\n]"
http-outgoing-0 << "{"FileStatuses":{"FileStatus":[[\n]"
http-outgoing-0 << "{"accessTime":1434164720788,"blockSize":134217728,"childrenNum":0,"fileId":18472,"group":"supergroup","length":10899,"modificationTime":1434164720848,"owner":"michaeljones","pathSuffix":"README.md","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434159020549,"blockSize":134217728,"childrenNum":0,"fileId":18464,"group":"supergroup","length":0,"modificationTime":1434159020554,"owner":"michaeljones","pathSuffix":"apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434159021414,"blockSize":134217728,"childrenNum":0,"fileId":18467,"group":"supergroup","length":0,"modificationTime":1434159021420,"owner":"michaeljones","pathSuffix":"empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434164916247,"blockSize":134217728,"childrenNum":0,"fileId":18474,"group":"supergroup","length":0,"modificationTime":1434164916255,"owner":"michaeljones","pathSuffix":"hello-apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434091626279,"blockSize":134217728,"childrenNum":0,"fileId":18298,"group":"supergroup","length":0,"modificationTime":1434091626286,"owner":"michaeljones","pathSuffix":"hello-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434164916150,"blockSize":134217728,"childrenNum":0,"fileId":18473,"group":"supergroup","length":0,"modificationTime":1434164916158,"owner":"michaeljones","pathSuffix":"hello-jersey-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434159021522,"blockSize":134217728,"childrenNum":0,"fileId":18468,"group":"supergroup","length":869081,"modificationTime":1434159021575,"owner":"michaeljones","pathSuffix":"hello.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434159013887,"blockSize":134217728,"childrenNum":0,"fileId":18442,"group":"supergroup","length":20,"modificationTime":1434159014350,"owner":"michaeljones","pathSuffix":"hello.txt","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434164916518,"blockSize":134217728,"childrenNum":0,"fileId":18475,"group":"supergroup","length":62912,"modificationTime":1434164916548,"owner":"michaeljones","pathSuffix":"hellohadoop.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434159020604,"blockSize":134217728,"childrenNum":0,"fileId":18465,"group":"supergroup","length":2134,"modificationTime":1434159020632,"owner":"michaeljones","pathSuffix":"pom.xml","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434159014921,"blockSize":134217728,"childrenNum":0,"fileId":16388,"group":"supergroup","length":50,"modificationTime":1433119638967,"owner":"michaeljones","pathSuffix":"wcInput","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18443,"group":"supergroup","length":0,"modificationTime":1434159016805,"owner":"michaeljones","pathSuffix":"wcOutput","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},[\n]"
http-outgoing-0 << "{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18450,"group":"supergroup","length":0,"modificationTime":1434159017973,"owner":"michaeljones","pathSuffix":"wcOutputAnalysis","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},[\n]"
http-outgoing-0 << "{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18457,"group":"supergroup","length":0,"modificationTime":1434159019678,"owner":"michaeljones","pathSuffix":"wcOutputMain","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"}[\n]"
http-outgoing-0 << "]}}[\n]"
http-outgoing-0 << "[\r][\n]"
http-outgoing-0 << HTTP/1.1 200 OK
http-outgoing-0 << Cache-Control: no-cache
http-outgoing-0 << Expires: Sat, 13 Jun 2015 03:17:54 GMT
http-outgoing-0 << Date: Sat, 13 Jun 2015 03:17:54 GMT
http-outgoing-0 << Pragma: no-cache
http-outgoing-0 << Expires: Sat, 13 Jun 2015 03:17:54 GMT
http-outgoing-0 << Date: Sat, 13 Jun 2015 03:17:54 GMT
http-outgoing-0 << Pragma: no-cache
http-outgoing-0 << Content-Type: application/json
http-outgoing-0 << Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434201474566&s=SFivall28yPViGBio2KcHauGlfk="; Path=/; Expires=Sat, 13-Jun-2015 13:17:54 GMT; HttpOnly
http-outgoing-0 << Transfer-Encoding: chunked
http-outgoing-0 << Server: Jetty(6.1.26)
Connection can be kept alive indefinitely
Cookie accepted [hadoop.auth=""u=michaeljones&p=michaeljones&t=simple&e=1434201474566&s=SFivall28yPViGBio2KcHauGlfk="", version:0, domain:localhost, path:/, expiry:Sat Jun 13 23:17:54 AEST 2015]
http-outgoing-0 << "0[\r][\n]"
http-outgoing-0 << "[\r][\n]"
Connection [id: 0][route: {}->http://localhost:50070] can be kept alive indefinitely
Connection released: [id: 0][route: {}->http://localhost:50070][total kept alive: 1; route allocated: 1 of 2; total allocated: 1 of 20]
Connection manager is shutting down
http-outgoing-0: Close connection
http-outgoing-0: Close connection
Connection manager shut down
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 1][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://localhost:50070
Connecting to localhost/127.0.0.1:50070
Connection established 127.0.0.1:49487<->127.0.0.1:50070
Executing request PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-1 >> PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1
http-outgoing-1 >> Content-Length: 0
http-outgoing-1 >> Host: localhost:50070
http-outgoing-1 >> Connection: Keep-Alive
http-outgoing-1 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-1 >> Accept-Encoding: gzip,deflate
http-outgoing-1 >> "PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1[\r][\n]"
http-outgoing-1 >> "Content-Length: 0[\r][\n]"
http-outgoing-1 >> "Host: localhost:50070[\r][\n]"
http-outgoing-1 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-1 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-1 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-1 >> "[\r][\n]"
http-outgoing-1 << "HTTP/1.1 307 TEMPORARY_REDIRECT[\r][\n]"
http-outgoing-1 << "Cache-Control: no-cache[\r][\n]"
http-outgoing-1 << "Expires: Sat, 13 Jun 2015 03:17:55 GMT[\r][\n]"
http-outgoing-1 << "Date: Sat, 13 Jun 2015 03:17:55 GMT[\r][\n]"
http-outgoing-1 << "Pragma: no-cache[\r][\n]"
http-outgoing-1 << "Expires: Sat, 13 Jun 2015 03:17:55 GMT[\r][\n]"
http-outgoing-1 << "Date: Sat, 13 Jun 2015 03:17:55 GMT[\r][\n]"
http-outgoing-1 << "Pragma: no-cache[\r][\n]"
http-outgoing-1 << "Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434201475002&s=kW3ZYLgUzJP5tLTvPIjgWBe0PI4="; Path=/; Expires=Sat, 13-Jun-2015 13:17:55 GMT; HttpOnly[\r][\n]"
http-outgoing-1 << "Location: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true[\r][\n]"
http-outgoing-1 << "Content-Type: application/octet-stream[\r][\n]"
http-outgoing-1 << "Content-Length: 0[\r][\n]"
http-outgoing-1 << "Server: Jetty(6.1.26)[\r][\n]"
http-outgoing-1 << "[\r][\n]"
http-outgoing-1 << HTTP/1.1 307 TEMPORARY_REDIRECT
http-outgoing-1 << Cache-Control: no-cache
http-outgoing-1 << Expires: Sat, 13 Jun 2015 03:17:55 GMT
http-outgoing-1 << Date: Sat, 13 Jun 2015 03:17:55 GMT
http-outgoing-1 << Pragma: no-cache
http-outgoing-1 << Expires: Sat, 13 Jun 2015 03:17:55 GMT
http-outgoing-1 << Date: Sat, 13 Jun 2015 03:17:55 GMT
http-outgoing-1 << Pragma: no-cache
http-outgoing-1 << Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434201475002&s=kW3ZYLgUzJP5tLTvPIjgWBe0PI4="; Path=/; Expires=Sat, 13-Jun-2015 13:17:55 GMT; HttpOnly
http-outgoing-1 << Location: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
http-outgoing-1 << Content-Type: application/octet-stream
http-outgoing-1 << Content-Length: 0
http-outgoing-1 << Server: Jetty(6.1.26)
Connection can be kept alive indefinitely
Cookie accepted [hadoop.auth=""u=michaeljones&p=michaeljones&t=simple&e=1434201475002&s=kW3ZYLgUzJP5tLTvPIjgWBe0PI4="", version:0, domain:localhost, path:/, expiry:Sat Jun 13 23:17:55 AEST 2015]
Redirect to: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
http-outgoing-1: Shutdown connection
Connection discarded
http-outgoing-1: Close connection
Connection released: [id: 1][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 2][route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://michaels-air.bigpond:50075
Connecting to michaels-air.bigpond/10.0.0.2:50075
Connection established 10.0.0.2:49488<->10.0.0.2:50075
Executing request PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-2 >> PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1
http-outgoing-2 >> Content-Length: 0
http-outgoing-2 >> Host: michaels-air.bigpond:50075
http-outgoing-2 >> Connection: Keep-Alive
http-outgoing-2 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-2 >> Accept-Encoding: gzip,deflate
http-outgoing-2 >> "PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1[\r][\n]"
http-outgoing-2 >> "Content-Length: 0[\r][\n]"
http-outgoing-2 >> "Host: michaels-air.bigpond:50075[\r][\n]"
http-outgoing-2 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-2 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-2 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-2 >> "[\r][\n]"
http-outgoing-2 << "HTTP/1.1 100 Continue[\r][\n]"
http-outgoing-2 << "[\r][\n]"
http-outgoing-2 << HTTP/1.1 100 Continue
http-outgoing-2 << "HTTP/1.1 201 Created[\r][\n]"
http-outgoing-2 << "Location: hdfs://localhost:9000/user/michaeljones/hello-apache-empty.txt[\r][\n]"
http-outgoing-2 << "Content-Length: 0[\r][\n]"
http-outgoing-2 << "Connection: close[\r][\n]"
http-outgoing-2 << "[\r][\n]"
http-outgoing-2 << HTTP/1.1 201 Created
http-outgoing-2 << Location: hdfs://localhost:9000/user/michaeljones/hello-apache-empty.txt
http-outgoing-2 << Content-Length: 0
http-outgoing-2 << Connection: close
http-outgoing-2: Shutdown connection
Connection discarded
http-outgoing-2: Close connection
Connection released: [id: 2][route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection manager is shutting down
Connection manager shut down
Jersey client Redirect to: hdfs://localhost:9000/user/michaeljones/hellohadoop.log
com.sun.jersey.client.property.chunkedEncodingSize: 1048576
Jersey client Redirect to: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/hello.log.2015-06-12?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 0][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://localhost:50070
Connecting to localhost/127.0.0.1:50070
Connection established 127.0.0.1:49502<->127.0.0.1:50070
Executing request GET /webhdfs/v1/user/michaeljones/?user.name=michaeljones&op=LISTSTATUS HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-0 >> GET /webhdfs/v1/user/michaeljones/?user.name=michaeljones&op=LISTSTATUS HTTP/1.1
http-outgoing-0 >> accept: application/json
http-outgoing-0 >> Host: localhost:50070
http-outgoing-0 >> Connection: Keep-Alive
http-outgoing-0 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-0 >> Accept-Encoding: gzip,deflate
http-outgoing-0 >> "GET /webhdfs/v1/user/michaeljones/?user.name=michaeljones&op=LISTSTATUS HTTP/1.1[\r][\n]"
http-outgoing-0 >> "accept: application/json[\r][\n]"
http-outgoing-0 >> "Host: localhost:50070[\r][\n]"
http-outgoing-0 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-0 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-0 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-0 >> "[\r][\n]"
http-outgoing-0 << "HTTP/1.1 200 OK[\r][\n]"
http-outgoing-0 << "Cache-Control: no-cache[\r][\n]"
http-outgoing-0 << "Expires: Sat, 13 Jun 2015 03:20:34 GMT[\r][\n]"
http-outgoing-0 << "Date: Sat, 13 Jun 2015 03:20:34 GMT[\r][\n]"
http-outgoing-0 << "Pragma: no-cache[\r][\n]"
http-outgoing-0 << "Expires: Sat, 13 Jun 2015 03:20:34 GMT[\r][\n]"
http-outgoing-0 << "Date: Sat, 13 Jun 2015 03:20:34 GMT[\r][\n]"
http-outgoing-0 << "Pragma: no-cache[\r][\n]"
http-outgoing-0 << "Content-Type: application/json[\r][\n]"
http-outgoing-0 << "Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434201634365&s=KNF01+7QU66YIsTJcru1AdZPAE0="; Path=/; Expires=Sat, 13-Jun-2015 13:20:34 GMT; HttpOnly[\r][\n]"
http-outgoing-0 << "Transfer-Encoding: chunked[\r][\n]"
http-outgoing-0 << "Server: Jetty(6.1.26)[\r][\n]"
http-outgoing-0 << "[\r][\n]"
http-outgoing-0 << "E9C[\r][\n]"
http-outgoing-0 << "{"FileStatuses":{"FileStatus":[[\n]"
http-outgoing-0 << "{"accessTime":1434164720788,"blockSize":134217728,"childrenNum":0,"fileId":18472,"group":"supergroup","length":10899,"modificationTime":1434164720848,"owner":"michaeljones","pathSuffix":"README.md","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434159020549,"blockSize":134217728,"childrenNum":0,"fileId":18464,"group":"supergroup","length":0,"modificationTime":1434159020554,"owner":"michaeljones","pathSuffix":"apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434159021414,"blockSize":134217728,"childrenNum":0,"fileId":18467,"group":"supergroup","length":0,"modificationTime":1434159021420,"owner":"michaeljones","pathSuffix":"empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434165475039,"blockSize":134217728,"childrenNum":0,"fileId":18477,"group":"supergroup","length":0,"modificationTime":1434165475046,"owner":"michaeljones","pathSuffix":"hello-apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434091626279,"blockSize":134217728,"childrenNum":0,"fileId":18298,"group":"supergroup","length":0,"modificationTime":1434091626286,"owner":"michaeljones","pathSuffix":"hello-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434165474968,"blockSize":134217728,"childrenNum":0,"fileId":18476,"group":"supergroup","length":0,"modificationTime":1434165474977,"owner":"michaeljones","pathSuffix":"hello-jersey-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434159021522,"blockSize":134217728,"childrenNum":0,"fileId":18468,"group":"supergroup","length":869081,"modificationTime":1434159021575,"owner":"michaeljones","pathSuffix":"hello.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434159013887,"blockSize":134217728,"childrenNum":0,"fileId":18442,"group":"supergroup","length":20,"modificationTime":1434159014350,"owner":"michaeljones","pathSuffix":"hello.txt","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434165475314,"blockSize":134217728,"childrenNum":0,"fileId":18478,"group":"supergroup","length":62912,"modificationTime":1434165475348,"owner":"michaeljones","pathSuffix":"hellohadoop.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434159020604,"blockSize":134217728,"childrenNum":0,"fileId":18465,"group":"supergroup","length":2134,"modificationTime":1434159020632,"owner":"michaeljones","pathSuffix":"pom.xml","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434159014921,"blockSize":134217728,"childrenNum":0,"fileId":16388,"group":"supergroup","length":50,"modificationTime":1433119638967,"owner":"michaeljones","pathSuffix":"wcInput","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18443,"group":"supergroup","length":0,"modificationTime":1434159016805,"owner":"michaeljones","pathSuffix":"wcOutput","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},[\n]"
http-outgoing-0 << "{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18450,"group":"supergroup","length":0,"modificationTime":1434159017973,"owner":"michaeljones","pathSuffix":"wcOutputAnalysis","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},[\n]"
http-outgoing-0 << "{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18457,"group":"supergroup","length":0,"modificationTime":1434159019678,"owner":"michaeljones","pathSuffix":"wcOutputMain","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"}[\n]"
http-outgoing-0 << "]}}[\n]"
http-outgoing-0 << "[\r][\n]"
http-outgoing-0 << "0[\r][\n]"
http-outgoing-0 << "[\r][\n]"
http-outgoing-0 << HTTP/1.1 200 OK
http-outgoing-0 << Cache-Control: no-cache
http-outgoing-0 << Expires: Sat, 13 Jun 2015 03:20:34 GMT
http-outgoing-0 << Date: Sat, 13 Jun 2015 03:20:34 GMT
http-outgoing-0 << Pragma: no-cache
http-outgoing-0 << Expires: Sat, 13 Jun 2015 03:20:34 GMT
http-outgoing-0 << Date: Sat, 13 Jun 2015 03:20:34 GMT
http-outgoing-0 << Pragma: no-cache
http-outgoing-0 << Content-Type: application/json
http-outgoing-0 << Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434201634365&s=KNF01+7QU66YIsTJcru1AdZPAE0="; Path=/; Expires=Sat, 13-Jun-2015 13:20:34 GMT; HttpOnly
http-outgoing-0 << Transfer-Encoding: chunked
http-outgoing-0 << Server: Jetty(6.1.26)
Connection can be kept alive indefinitely
Cookie accepted [hadoop.auth=""u=michaeljones&p=michaeljones&t=simple&e=1434201634365&s=KNF01+7QU66YIsTJcru1AdZPAE0="", version:0, domain:localhost, path:/, expiry:Sat Jun 13 23:20:34 AEST 2015]
Connection [id: 0][route: {}->http://localhost:50070] can be kept alive indefinitely
Connection released: [id: 0][route: {}->http://localhost:50070][total kept alive: 1; route allocated: 1 of 2; total allocated: 1 of 20]
Connection manager is shutting down
http-outgoing-0: Close connection
http-outgoing-0: Close connection
Connection manager shut down
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 1][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://localhost:50070
Connecting to localhost/127.0.0.1:50070
Connection established 127.0.0.1:49505<->127.0.0.1:50070
Executing request PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-1 >> PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1
http-outgoing-1 >> Content-Length: 0
http-outgoing-1 >> Host: localhost:50070
http-outgoing-1 >> Connection: Keep-Alive
http-outgoing-1 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-1 >> Accept-Encoding: gzip,deflate
http-outgoing-1 >> "PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1[\r][\n]"
http-outgoing-1 >> "Content-Length: 0[\r][\n]"
http-outgoing-1 >> "Host: localhost:50070[\r][\n]"
http-outgoing-1 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-1 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-1 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-1 >> "[\r][\n]"
http-outgoing-1 << "HTTP/1.1 307 TEMPORARY_REDIRECT[\r][\n]"
http-outgoing-1 << "Cache-Control: no-cache[\r][\n]"
http-outgoing-1 << "Expires: Sat, 13 Jun 2015 03:20:34 GMT[\r][\n]"
http-outgoing-1 << "Date: Sat, 13 Jun 2015 03:20:34 GMT[\r][\n]"
http-outgoing-1 << "Pragma: no-cache[\r][\n]"
http-outgoing-1 << "Expires: Sat, 13 Jun 2015 03:20:34 GMT[\r][\n]"
http-outgoing-1 << "Date: Sat, 13 Jun 2015 03:20:34 GMT[\r][\n]"
http-outgoing-1 << "Pragma: no-cache[\r][\n]"
http-outgoing-1 << "Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434201634908&s=9W/mQUL/IdbU9WjIIzCwTYges/Q="; Path=/; Expires=Sat, 13-Jun-2015 13:20:34 GMT; HttpOnly[\r][\n]"
http-outgoing-1 << "Location: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true[\r][\n]"
http-outgoing-1 << "Content-Type: application/octet-stream[\r][\n]"
http-outgoing-1 << "Content-Length: 0[\r][\n]"
http-outgoing-1 << "Server: Jetty(6.1.26)[\r][\n]"
http-outgoing-1 << "[\r][\n]"
http-outgoing-1 << HTTP/1.1 307 TEMPORARY_REDIRECT
http-outgoing-1 << Cache-Control: no-cache
http-outgoing-1 << Expires: Sat, 13 Jun 2015 03:20:34 GMT
http-outgoing-1 << Date: Sat, 13 Jun 2015 03:20:34 GMT
http-outgoing-1 << Pragma: no-cache
http-outgoing-1 << Expires: Sat, 13 Jun 2015 03:20:34 GMT
http-outgoing-1 << Date: Sat, 13 Jun 2015 03:20:34 GMT
http-outgoing-1 << Pragma: no-cache
http-outgoing-1 << Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434201634908&s=9W/mQUL/IdbU9WjIIzCwTYges/Q="; Path=/; Expires=Sat, 13-Jun-2015 13:20:34 GMT; HttpOnly
http-outgoing-1 << Location: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
http-outgoing-1 << Content-Type: application/octet-stream
http-outgoing-1 << Content-Length: 0
http-outgoing-1 << Server: Jetty(6.1.26)
Connection can be kept alive indefinitely
Cookie accepted [hadoop.auth=""u=michaeljones&p=michaeljones&t=simple&e=1434201634908&s=9W/mQUL/IdbU9WjIIzCwTYges/Q="", version:0, domain:localhost, path:/, expiry:Sat Jun 13 23:20:34 AEST 2015]
Redirect to: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
http-outgoing-1: Shutdown connection
Connection discarded
http-outgoing-1: Close connection
Connection released: [id: 1][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 2][route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://michaels-air.bigpond:50075
Connecting to michaels-air.bigpond/10.0.0.2:50075
Connection established 10.0.0.2:49506<->10.0.0.2:50075
Executing request PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-2 >> PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1
http-outgoing-2 >> Content-Length: 0
http-outgoing-2 >> Host: michaels-air.bigpond:50075
http-outgoing-2 >> Connection: Keep-Alive
http-outgoing-2 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-2 >> Accept-Encoding: gzip,deflate
http-outgoing-2 >> "PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1[\r][\n]"
http-outgoing-2 >> "Content-Length: 0[\r][\n]"
http-outgoing-2 >> "Host: michaels-air.bigpond:50075[\r][\n]"
http-outgoing-2 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-2 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-2 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-2 >> "[\r][\n]"
http-outgoing-2 << "HTTP/1.1 100 Continue[\r][\n]"
http-outgoing-2 << "[\r][\n]"
http-outgoing-2 << HTTP/1.1 100 Continue
http-outgoing-2 << "HTTP/1.1 201 Created[\r][\n]"
http-outgoing-2 << "Location: hdfs://localhost:9000/user/michaeljones/hello-apache-empty.txt[\r][\n]"
http-outgoing-2 << "Content-Length: 0[\r][\n]"
http-outgoing-2 << "Connection: close[\r][\n]"
http-outgoing-2 << "[\r][\n]"
http-outgoing-2 << HTTP/1.1 201 Created
http-outgoing-2 << Location: hdfs://localhost:9000/user/michaeljones/hello-apache-empty.txt
http-outgoing-2 << Content-Length: 0
http-outgoing-2 << Connection: close
http-outgoing-2: Shutdown connection
Connection discarded
http-outgoing-2: Close connection
Connection released: [id: 2][route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection manager is shutting down
Connection manager shut down
Jersey client Redirect to: hdfs://localhost:9000/user/michaeljones/hellohadoop.log
com.sun.jersey.client.property.chunkedEncodingSize: 1048576
Jersey client Redirect to: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/hello.log.2015-06-12?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 0][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://localhost:50070
Connecting to localhost/127.0.0.1:50070
Connection established 127.0.0.1:49528<->127.0.0.1:50070
Executing request GET /webhdfs/v1/user/michaeljones/?user.name=michaeljones&op=LISTSTATUS HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-0 >> GET /webhdfs/v1/user/michaeljones/?user.name=michaeljones&op=LISTSTATUS HTTP/1.1
http-outgoing-0 >> accept: application/json
http-outgoing-0 >> Host: localhost:50070
http-outgoing-0 >> Connection: Keep-Alive
http-outgoing-0 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-0 >> Accept-Encoding: gzip,deflate
http-outgoing-0 >> "GET /webhdfs/v1/user/michaeljones/?user.name=michaeljones&op=LISTSTATUS HTTP/1.1[\r][\n]"
http-outgoing-0 >> "accept: application/json[\r][\n]"
http-outgoing-0 >> "Host: localhost:50070[\r][\n]"
http-outgoing-0 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-0 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-0 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-0 >> "[\r][\n]"
http-outgoing-0 << "HTTP/1.1 200 OK[\r][\n]"
http-outgoing-0 << "Cache-Control: no-cache[\r][\n]"
http-outgoing-0 << "Expires: Sat, 13 Jun 2015 03:23:04 GMT[\r][\n]"
http-outgoing-0 << "Date: Sat, 13 Jun 2015 03:23:04 GMT[\r][\n]"
http-outgoing-0 << "Pragma: no-cache[\r][\n]"
http-outgoing-0 << "Expires: Sat, 13 Jun 2015 03:23:04 GMT[\r][\n]"
http-outgoing-0 << "Date: Sat, 13 Jun 2015 03:23:04 GMT[\r][\n]"
http-outgoing-0 << "Pragma: no-cache[\r][\n]"
http-outgoing-0 << "Content-Type: application/json[\r][\n]"
http-outgoing-0 << "Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434201784519&s=BPujocSMO+gZ1/Ao0kFPBQhkwkY="; Path=/; Expires=Sat, 13-Jun-2015 13:23:04 GMT; HttpOnly[\r][\n]"
http-outgoing-0 << "Transfer-Encoding: chunked[\r][\n]"
http-outgoing-0 << "Server: Jetty(6.1.26)[\r][\n]"
http-outgoing-0 << "[\r][\n]"
http-outgoing-0 << "E9C[\r][\n]"
http-outgoing-0 << "{"FileStatuses":{"FileStatus":[[\n]"
http-outgoing-0 << "{"accessTime":1434164720788,"blockSize":134217728,"childrenNum":0,"fileId":18472,"group":"supergroup","length":10899,"modificationTime":1434164720848,"owner":"michaeljones","pathSuffix":"README.md","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434159020549,"blockSize":134217728,"childrenNum":0,"fileId":18464,"group":"supergroup","length":0,"modificationTime":1434159020554,"owner":"michaeljones","pathSuffix":"apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434159021414,"blockSize":134217728,"childrenNum":0,"fileId":18467,"group":"supergroup","length":0,"modificationTime":1434159021420,"owner":"michaeljones","pathSuffix":"empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434165634957,"blockSize":134217728,"childrenNum":0,"fileId":18480,"group":"supergroup","length":0,"modificationTime":1434165634967,"owner":"michaeljones","pathSuffix":"hello-apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434091626279,"blockSize":134217728,"childrenNum":0,"fileId":18298,"group":"supergroup","length":0,"modificationTime":1434091626286,"owner":"michaeljones","pathSuffix":"hello-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434165634859,"blockSize":134217728,"childrenNum":0,"fileId":18479,"group":"supergroup","length":0,"modificationTime":1434165634867,"owner":"michaeljones","pathSuffix":"hello-jersey-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434159021522,"blockSize":134217728,"childrenNum":0,"fileId":18468,"group":"supergroup","length":869081,"modificationTime":1434159021575,"owner":"michaeljones","pathSuffix":"hello.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434159013887,"blockSize":134217728,"childrenNum":0,"fileId":18442,"group":"supergroup","length":20,"modificationTime":1434159014350,"owner":"michaeljones","pathSuffix":"hello.txt","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434165635216,"blockSize":134217728,"childrenNum":0,"fileId":18481,"group":"supergroup","length":62912,"modificationTime":1434165635249,"owner":"michaeljones","pathSuffix":"hellohadoop.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434159020604,"blockSize":134217728,"childrenNum":0,"fileId":18465,"group":"supergroup","length":2134,"modificationTime":1434159020632,"owner":"michaeljones","pathSuffix":"pom.xml","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434159014921,"blockSize":134217728,"childrenNum":0,"fileId":16388,"group":"supergroup","length":50,"modificationTime":1433119638967,"owner":"michaeljones","pathSuffix":"wcInput","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18443,"group":"supergroup","length":0,"modificationTime":1434159016805,"owner":"michaeljones","pathSuffix":"wcOutput","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},[\n]"
http-outgoing-0 << "{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18450,"group":"supergroup","length":0,"modificationTime":1434159017973,"owner":"michaeljones","pathSuffix":"wcOutputAnalysis","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},[\n]"
http-outgoing-0 << "{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18457,"group":"supergroup","length":0,"modificationTime":1434159019678,"owner":"michaeljones","pathSuffix":"wcOutputMain","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"}[\n]"
http-outgoing-0 << "]}}[\n]"
http-outgoing-0 << "[\r][\n]"
http-outgoing-0 << HTTP/1.1 200 OK
http-outgoing-0 << Cache-Control: no-cache
http-outgoing-0 << Expires: Sat, 13 Jun 2015 03:23:04 GMT
http-outgoing-0 << Date: Sat, 13 Jun 2015 03:23:04 GMT
http-outgoing-0 << Pragma: no-cache
http-outgoing-0 << Expires: Sat, 13 Jun 2015 03:23:04 GMT
http-outgoing-0 << Date: Sat, 13 Jun 2015 03:23:04 GMT
http-outgoing-0 << Pragma: no-cache
http-outgoing-0 << Content-Type: application/json
http-outgoing-0 << Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434201784519&s=BPujocSMO+gZ1/Ao0kFPBQhkwkY="; Path=/; Expires=Sat, 13-Jun-2015 13:23:04 GMT; HttpOnly
http-outgoing-0 << Transfer-Encoding: chunked
http-outgoing-0 << Server: Jetty(6.1.26)
Connection can be kept alive indefinitely
Cookie accepted [hadoop.auth=""u=michaeljones&p=michaeljones&t=simple&e=1434201784519&s=BPujocSMO+gZ1/Ao0kFPBQhkwkY="", version:0, domain:localhost, path:/, expiry:Sat Jun 13 23:23:04 AEST 2015]
http-outgoing-0 << "0[\r][\n]"
http-outgoing-0 << "[\r][\n]"
Connection [id: 0][route: {}->http://localhost:50070] can be kept alive indefinitely
Connection released: [id: 0][route: {}->http://localhost:50070][total kept alive: 1; route allocated: 1 of 2; total allocated: 1 of 20]
Connection manager is shutting down
http-outgoing-0: Close connection
http-outgoing-0: Close connection
Connection manager shut down
Jersey client Redirect to: hdfs://localhost:9000/user/michaeljones/hellohadoop.log
com.sun.jersey.client.property.chunkedEncodingSize: 1048576
Jersey client Redirect to: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/hello.log.2015-06-12?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 1][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://localhost:50070
Connecting to localhost/127.0.0.1:50070
Connection established 127.0.0.1:49536<->127.0.0.1:50070
Executing request PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-1 >> PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1
http-outgoing-1 >> Content-Length: 0
http-outgoing-1 >> Host: localhost:50070
http-outgoing-1 >> Connection: Keep-Alive
http-outgoing-1 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-1 >> Accept-Encoding: gzip,deflate
http-outgoing-1 >> "PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1[\r][\n]"
http-outgoing-1 >> "Content-Length: 0[\r][\n]"
http-outgoing-1 >> "Host: localhost:50070[\r][\n]"
http-outgoing-1 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-1 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-1 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-1 >> "[\r][\n]"
http-outgoing-1 << "HTTP/1.1 307 TEMPORARY_REDIRECT[\r][\n]"
http-outgoing-1 << "Cache-Control: no-cache[\r][\n]"
http-outgoing-1 << "Expires: Sat, 13 Jun 2015 03:23:05 GMT[\r][\n]"
http-outgoing-1 << "Date: Sat, 13 Jun 2015 03:23:05 GMT[\r][\n]"
http-outgoing-1 << "Pragma: no-cache[\r][\n]"
http-outgoing-1 << "Expires: Sat, 13 Jun 2015 03:23:05 GMT[\r][\n]"
http-outgoing-1 << "Date: Sat, 13 Jun 2015 03:23:05 GMT[\r][\n]"
http-outgoing-1 << "Pragma: no-cache[\r][\n]"
http-outgoing-1 << "Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434201785343&s=u/9vX9Stqen8Zt6rEkuYekWKjS0="; Path=/; Expires=Sat, 13-Jun-2015 13:23:05 GMT; HttpOnly[\r][\n]"
http-outgoing-1 << "Location: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true[\r][\n]"
http-outgoing-1 << "Content-Type: application/octet-stream[\r][\n]"
http-outgoing-1 << "Content-Length: 0[\r][\n]"
http-outgoing-1 << "Server: Jetty(6.1.26)[\r][\n]"
http-outgoing-1 << "[\r][\n]"
http-outgoing-1 << HTTP/1.1 307 TEMPORARY_REDIRECT
http-outgoing-1 << Cache-Control: no-cache
http-outgoing-1 << Expires: Sat, 13 Jun 2015 03:23:05 GMT
http-outgoing-1 << Date: Sat, 13 Jun 2015 03:23:05 GMT
http-outgoing-1 << Pragma: no-cache
http-outgoing-1 << Expires: Sat, 13 Jun 2015 03:23:05 GMT
http-outgoing-1 << Date: Sat, 13 Jun 2015 03:23:05 GMT
http-outgoing-1 << Pragma: no-cache
http-outgoing-1 << Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434201785343&s=u/9vX9Stqen8Zt6rEkuYekWKjS0="; Path=/; Expires=Sat, 13-Jun-2015 13:23:05 GMT; HttpOnly
http-outgoing-1 << Location: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
http-outgoing-1 << Content-Type: application/octet-stream
http-outgoing-1 << Content-Length: 0
http-outgoing-1 << Server: Jetty(6.1.26)
Connection can be kept alive indefinitely
Cookie accepted [hadoop.auth=""u=michaeljones&p=michaeljones&t=simple&e=1434201785343&s=u/9vX9Stqen8Zt6rEkuYekWKjS0="", version:0, domain:localhost, path:/, expiry:Sat Jun 13 23:23:05 AEST 2015]
Redirect to: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
http-outgoing-1: Shutdown connection
Connection discarded
http-outgoing-1: Close connection
Connection released: [id: 1][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 2][route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://michaels-air.bigpond:50075
Connecting to michaels-air.bigpond/10.0.0.2:50075
Connection established 10.0.0.2:49537<->10.0.0.2:50075
Executing request PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-2 >> PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1
http-outgoing-2 >> Content-Length: 0
http-outgoing-2 >> Host: michaels-air.bigpond:50075
http-outgoing-2 >> Connection: Keep-Alive
http-outgoing-2 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-2 >> Accept-Encoding: gzip,deflate
http-outgoing-2 >> "PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1[\r][\n]"
Connection manager is shutting down
Connection manager shut down
http-outgoing-2 >> "Content-Length: 0[\r][\n]"
http-outgoing-2 >> "Host: michaels-air.bigpond:50075[\r][\n]"
http-outgoing-2 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-2 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-2 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-2 >> "[\r][\n]"
http-outgoing-2 << "HTTP/1.1 100 Continue[\r][\n]"
http-outgoing-2 << "[\r][\n]"
http-outgoing-2 << HTTP/1.1 100 Continue
http-outgoing-2 << "HTTP/1.1 201 Created[\r][\n]"
http-outgoing-2 << "Location: hdfs://localhost:9000/user/michaeljones/hello-apache-empty.txt[\r][\n]"
http-outgoing-2 << "Content-Length: 0[\r][\n]"
http-outgoing-2 << "Connection: close[\r][\n]"
http-outgoing-2 << "[\r][\n]"
http-outgoing-2 << HTTP/1.1 201 Created
http-outgoing-2 << Location: hdfs://localhost:9000/user/michaeljones/hello-apache-empty.txt
http-outgoing-2 << Content-Length: 0
http-outgoing-2 << Connection: close
http-outgoing-2: Shutdown connection
Connection discarded
http-outgoing-2: Close connection
Connection released: [id: 2][route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection manager is shutting down
Connection manager shut down
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 0][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://localhost:50070
Connecting to localhost/127.0.0.1:50070
Connection established 127.0.0.1:49542<->127.0.0.1:50070
Executing request GET /webhdfs/v1/user/michaeljones/?user.name=michaeljones&op=LISTSTATUS HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-0 >> GET /webhdfs/v1/user/michaeljones/?user.name=michaeljones&op=LISTSTATUS HTTP/1.1
http-outgoing-0 >> accept: application/json
http-outgoing-0 >> Host: localhost:50070
http-outgoing-0 >> Connection: Keep-Alive
http-outgoing-0 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-0 >> Accept-Encoding: gzip,deflate
http-outgoing-0 >> "GET /webhdfs/v1/user/michaeljones/?user.name=michaeljones&op=LISTSTATUS HTTP/1.1[\r][\n]"
http-outgoing-0 >> "accept: application/json[\r][\n]"
http-outgoing-0 >> "Host: localhost:50070[\r][\n]"
http-outgoing-0 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-0 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-0 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-0 >> "[\r][\n]"
http-outgoing-0 << "HTTP/1.1 200 OK[\r][\n]"
http-outgoing-0 << "Cache-Control: no-cache[\r][\n]"
http-outgoing-0 << "Expires: Sat, 13 Jun 2015 03:23:21 GMT[\r][\n]"
http-outgoing-0 << "Date: Sat, 13 Jun 2015 03:23:21 GMT[\r][\n]"
http-outgoing-0 << "Pragma: no-cache[\r][\n]"
http-outgoing-0 << "Expires: Sat, 13 Jun 2015 03:23:21 GMT[\r][\n]"
http-outgoing-0 << "Date: Sat, 13 Jun 2015 03:23:21 GMT[\r][\n]"
http-outgoing-0 << "Pragma: no-cache[\r][\n]"
http-outgoing-0 << "Content-Type: application/json[\r][\n]"
http-outgoing-0 << "Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434201801147&s=kRdOOlFE1wt35X9NOhWSlFxQvzM="; Path=/; Expires=Sat, 13-Jun-2015 13:23:21 GMT; HttpOnly[\r][\n]"
http-outgoing-0 << "Transfer-Encoding: chunked[\r][\n]"
http-outgoing-0 << "Server: Jetty(6.1.26)[\r][\n]"
http-outgoing-0 << "[\r][\n]"
http-outgoing-0 << "E9C[\r][\n]"
http-outgoing-0 << "{"FileStatuses":{"FileStatus":[[\n]"
http-outgoing-0 << "{"accessTime":1434164720788,"blockSize":134217728,"childrenNum":0,"fileId":18472,"group":"supergroup","length":10899,"modificationTime":1434164720848,"owner":"michaeljones","pathSuffix":"README.md","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434159020549,"blockSize":134217728,"childrenNum":0,"fileId":18464,"group":"supergroup","length":0,"modificationTime":1434159020554,"owner":"michaeljones","pathSuffix":"apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434159021414,"blockSize":134217728,"childrenNum":0,"fileId":18467,"group":"supergroup","length":0,"modificationTime":1434159021420,"owner":"michaeljones","pathSuffix":"empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434165785508,"blockSize":134217728,"childrenNum":0,"fileId":18484,"group":"supergroup","length":0,"modificationTime":1434165785514,"owner":"michaeljones","pathSuffix":"hello-apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434091626279,"blockSize":134217728,"childrenNum":0,"fileId":18298,"group":"supergroup","length":0,"modificationTime":1434091626286,"owner":"michaeljones","pathSuffix":"hello-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434165785309,"blockSize":134217728,"childrenNum":0,"fileId":18483,"group":"supergroup","length":0,"modificationTime":1434165785318,"owner":"michaeljones","pathSuffix":"hello-jersey-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434159021522,"blockSize":134217728,"childrenNum":0,"fileId":18468,"group":"supergroup","length":869081,"modificationTime":1434159021575,"owner":"michaeljones","pathSuffix":"hello.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434159013887,"blockSize":134217728,"childrenNum":0,"fileId":18442,"group":"supergroup","length":20,"modificationTime":1434159014350,"owner":"michaeljones","pathSuffix":"hello.txt","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434165784970,"blockSize":134217728,"childrenNum":0,"fileId":18482,"group":"supergroup","length":62912,"modificationTime":1434165784998,"owner":"michaeljones","pathSuffix":"hellohadoop.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434159020604,"blockSize":134217728,"childrenNum":0,"fileId":18465,"group":"supergroup","length":2134,"modificationTime":1434159020632,"owner":"michaeljones","pathSuffix":"pom.xml","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434159014921,"blockSize":134217728,"childrenNum":0,"fileId":16388,"group":"supergroup","length":50,"modificationTime":1433119638967,"owner":"michaeljones","pathSuffix":"wcInput","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18443,"group":"supergroup","length":0,"modificationTime":1434159016805,"owner":"michaeljones","pathSuffix":"wcOutput","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},[\n]"
http-outgoing-0 << "{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18450,"group":"supergroup","length":0,"modificationTime":1434159017973,"owner":"michaeljones","pathSuffix":"wcOutputAnalysis","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},[\n]"
http-outgoing-0 << "{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18457,"group":"supergroup","length":0,"modificationTime":1434159019678,"owner":"michaeljones","pathSuffix":"wcOutputMain","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"}[\n]"
http-outgoing-0 << "]}}[\n]"
http-outgoing-0 << "[\r][\n]"
http-outgoing-0 << HTTP/1.1 200 OK
http-outgoing-0 << Cache-Control: no-cache
http-outgoing-0 << Expires: Sat, 13 Jun 2015 03:23:21 GMT
http-outgoing-0 << Date: Sat, 13 Jun 2015 03:23:21 GMT
http-outgoing-0 << Pragma: no-cache
http-outgoing-0 << Expires: Sat, 13 Jun 2015 03:23:21 GMT
http-outgoing-0 << Date: Sat, 13 Jun 2015 03:23:21 GMT
http-outgoing-0 << Pragma: no-cache
http-outgoing-0 << Content-Type: application/json
http-outgoing-0 << Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434201801147&s=kRdOOlFE1wt35X9NOhWSlFxQvzM="; Path=/; Expires=Sat, 13-Jun-2015 13:23:21 GMT; HttpOnly
http-outgoing-0 << Transfer-Encoding: chunked
http-outgoing-0 << Server: Jetty(6.1.26)
Connection can be kept alive indefinitely
Cookie accepted [hadoop.auth=""u=michaeljones&p=michaeljones&t=simple&e=1434201801147&s=kRdOOlFE1wt35X9NOhWSlFxQvzM="", version:0, domain:localhost, path:/, expiry:Sat Jun 13 23:23:21 AEST 2015]
http-outgoing-0 << "0[\r][\n]"
http-outgoing-0 << "[\r][\n]"
Connection [id: 0][route: {}->http://localhost:50070] can be kept alive indefinitely
Connection released: [id: 0][route: {}->http://localhost:50070][total kept alive: 1; route allocated: 1 of 2; total allocated: 1 of 20]
Connection manager is shutting down
http-outgoing-0: Close connection
http-outgoing-0: Close connection
Connection manager shut down
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 1][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://localhost:50070
Connecting to localhost/127.0.0.1:50070
Connection established 127.0.0.1:49545<->127.0.0.1:50070
Executing request PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-1 >> PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1
http-outgoing-1 >> Content-Length: 0
http-outgoing-1 >> Host: localhost:50070
http-outgoing-1 >> Connection: Keep-Alive
http-outgoing-1 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-1 >> Accept-Encoding: gzip,deflate
http-outgoing-1 >> "PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1[\r][\n]"
http-outgoing-1 >> "Content-Length: 0[\r][\n]"
http-outgoing-1 >> "Host: localhost:50070[\r][\n]"
http-outgoing-1 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-1 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-1 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-1 >> "[\r][\n]"
http-outgoing-1 << "HTTP/1.1 307 TEMPORARY_REDIRECT[\r][\n]"
http-outgoing-1 << "Cache-Control: no-cache[\r][\n]"
http-outgoing-1 << "Expires: Sat, 13 Jun 2015 03:23:21 GMT[\r][\n]"
http-outgoing-1 << "Date: Sat, 13 Jun 2015 03:23:21 GMT[\r][\n]"
http-outgoing-1 << "Pragma: no-cache[\r][\n]"
http-outgoing-1 << "Expires: Sat, 13 Jun 2015 03:23:21 GMT[\r][\n]"
http-outgoing-1 << "Date: Sat, 13 Jun 2015 03:23:21 GMT[\r][\n]"
http-outgoing-1 << "Pragma: no-cache[\r][\n]"
http-outgoing-1 << "Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434201801622&s=SpNPkdIpU2YPruI7Z4hhysBB4NU="; Path=/; Expires=Sat, 13-Jun-2015 13:23:21 GMT; HttpOnly[\r][\n]"
http-outgoing-1 << "Location: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true[\r][\n]"
http-outgoing-1 << "Content-Type: application/octet-stream[\r][\n]"
http-outgoing-1 << "Content-Length: 0[\r][\n]"
http-outgoing-1 << "Server: Jetty(6.1.26)[\r][\n]"
http-outgoing-1 << "[\r][\n]"
http-outgoing-1 << HTTP/1.1 307 TEMPORARY_REDIRECT
http-outgoing-1 << Cache-Control: no-cache
http-outgoing-1 << Expires: Sat, 13 Jun 2015 03:23:21 GMT
http-outgoing-1 << Date: Sat, 13 Jun 2015 03:23:21 GMT
http-outgoing-1 << Pragma: no-cache
http-outgoing-1 << Expires: Sat, 13 Jun 2015 03:23:21 GMT
http-outgoing-1 << Date: Sat, 13 Jun 2015 03:23:21 GMT
http-outgoing-1 << Pragma: no-cache
http-outgoing-1 << Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434201801622&s=SpNPkdIpU2YPruI7Z4hhysBB4NU="; Path=/; Expires=Sat, 13-Jun-2015 13:23:21 GMT; HttpOnly
http-outgoing-1 << Location: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
http-outgoing-1 << Content-Type: application/octet-stream
http-outgoing-1 << Content-Length: 0
http-outgoing-1 << Server: Jetty(6.1.26)
Connection can be kept alive indefinitely
Cookie accepted [hadoop.auth=""u=michaeljones&p=michaeljones&t=simple&e=1434201801622&s=SpNPkdIpU2YPruI7Z4hhysBB4NU="", version:0, domain:localhost, path:/, expiry:Sat Jun 13 23:23:21 AEST 2015]
Redirect to: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
http-outgoing-1: Shutdown connection
Connection discarded
http-outgoing-1: Close connection
Connection released: [id: 1][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 2][route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://michaels-air.bigpond:50075
Connecting to michaels-air.bigpond/10.0.0.2:50075
Connection established 10.0.0.2:49546<->10.0.0.2:50075
Executing request PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-2 >> PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1
http-outgoing-2 >> Content-Length: 0
http-outgoing-2 >> Host: michaels-air.bigpond:50075
http-outgoing-2 >> Connection: Keep-Alive
http-outgoing-2 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-2 >> Accept-Encoding: gzip,deflate
http-outgoing-2 >> "PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1[\r][\n]"
http-outgoing-2 >> "Content-Length: 0[\r][\n]"
http-outgoing-2 >> "Host: michaels-air.bigpond:50075[\r][\n]"
http-outgoing-2 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-2 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-2 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-2 >> "[\r][\n]"
http-outgoing-2 << "HTTP/1.1 100 Continue[\r][\n]"
http-outgoing-2 << "[\r][\n]"
http-outgoing-2 << HTTP/1.1 100 Continue
http-outgoing-2 << "HTTP/1.1 201 Created[\r][\n]"
http-outgoing-2 << "Location: hdfs://localhost:9000/user/michaeljones/hello-apache-empty.txt[\r][\n]"
http-outgoing-2 << "Content-Length: 0[\r][\n]"
http-outgoing-2 << "Connection: close[\r][\n]"
http-outgoing-2 << "[\r][\n]"
http-outgoing-2 << HTTP/1.1 201 Created
http-outgoing-2 << Location: hdfs://localhost:9000/user/michaeljones/hello-apache-empty.txt
http-outgoing-2 << Content-Length: 0
http-outgoing-2 << Connection: close
http-outgoing-2: Shutdown connection
Connection discarded
http-outgoing-2: Close connection
Connection released: [id: 2][route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection manager is shutting down
Connection manager shut down
Jersey client Redirect to: hdfs://localhost:9000/user/michaeljones/hellohadoop.log
com.sun.jersey.client.property.chunkedEncodingSize: 1048576
Jersey client Redirect to: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/hello.log.2015-06-12?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 0][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://localhost:50070
Connecting to localhost/127.0.0.1:50070
Connection established 127.0.0.1:49567<->127.0.0.1:50070
Executing request GET /webhdfs/v1/user/michaeljones/?user.name=michaeljones&op=LISTSTATUS HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-0 >> GET /webhdfs/v1/user/michaeljones/?user.name=michaeljones&op=LISTSTATUS HTTP/1.1
http-outgoing-0 >> accept: application/json
http-outgoing-0 >> Host: localhost:50070
http-outgoing-0 >> Connection: Keep-Alive
http-outgoing-0 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-0 >> Accept-Encoding: gzip,deflate
http-outgoing-0 >> "GET /webhdfs/v1/user/michaeljones/?user.name=michaeljones&op=LISTSTATUS HTTP/1.1[\r][\n]"
http-outgoing-0 >> "accept: application/json[\r][\n]"
http-outgoing-0 >> "Host: localhost:50070[\r][\n]"
http-outgoing-0 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-0 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-0 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-0 >> "[\r][\n]"
http-outgoing-0 << "HTTP/1.1 200 OK[\r][\n]"
http-outgoing-0 << "Cache-Control: no-cache[\r][\n]"
http-outgoing-0 << "Expires: Sat, 13 Jun 2015 03:25:43 GMT[\r][\n]"
http-outgoing-0 << "Date: Sat, 13 Jun 2015 03:25:43 GMT[\r][\n]"
http-outgoing-0 << "Pragma: no-cache[\r][\n]"
http-outgoing-0 << "Expires: Sat, 13 Jun 2015 03:25:43 GMT[\r][\n]"
http-outgoing-0 << "Date: Sat, 13 Jun 2015 03:25:43 GMT[\r][\n]"
http-outgoing-0 << "Pragma: no-cache[\r][\n]"
http-outgoing-0 << "Content-Type: application/json[\r][\n]"
http-outgoing-0 << "Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434201943658&s=ajMRPDFAnTfS+SRjWB9VpgfGHG4="; Path=/; Expires=Sat, 13-Jun-2015 13:25:43 GMT; HttpOnly[\r][\n]"
http-outgoing-0 << "Transfer-Encoding: chunked[\r][\n]"
http-outgoing-0 << "Server: Jetty(6.1.26)[\r][\n]"
http-outgoing-0 << "[\r][\n]"
http-outgoing-0 << "E9C[\r][\n]"
http-outgoing-0 << "{"FileStatuses":{"FileStatus":[[\n]"
http-outgoing-0 << "{"accessTime":1434164720788,"blockSize":134217728,"childrenNum":0,"fileId":18472,"group":"supergroup","length":10899,"modificationTime":1434164720848,"owner":"michaeljones","pathSuffix":"README.md","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434159020549,"blockSize":134217728,"childrenNum":0,"fileId":18464,"group":"supergroup","length":0,"modificationTime":1434159020554,"owner":"michaeljones","pathSuffix":"apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434159021414,"blockSize":134217728,"childrenNum":0,"fileId":18467,"group":"supergroup","length":0,"modificationTime":1434159021420,"owner":"michaeljones","pathSuffix":"empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434165801652,"blockSize":134217728,"childrenNum":0,"fileId":18486,"group":"supergroup","length":0,"modificationTime":1434165801656,"owner":"michaeljones","pathSuffix":"hello-apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434091626279,"blockSize":134217728,"childrenNum":0,"fileId":18298,"group":"supergroup","length":0,"modificationTime":1434091626286,"owner":"michaeljones","pathSuffix":"hello-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434165801582,"blockSize":134217728,"childrenNum":0,"fileId":18485,"group":"supergroup","length":0,"modificationTime":1434165801588,"owner":"michaeljones","pathSuffix":"hello-jersey-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434159021522,"blockSize":134217728,"childrenNum":0,"fileId":18468,"group":"supergroup","length":869081,"modificationTime":1434159021575,"owner":"michaeljones","pathSuffix":"hello.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434159013887,"blockSize":134217728,"childrenNum":0,"fileId":18442,"group":"supergroup","length":20,"modificationTime":1434159014350,"owner":"michaeljones","pathSuffix":"hello.txt","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434165801913,"blockSize":134217728,"childrenNum":0,"fileId":18487,"group":"supergroup","length":62912,"modificationTime":1434165801942,"owner":"michaeljones","pathSuffix":"hellohadoop.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434159020604,"blockSize":134217728,"childrenNum":0,"fileId":18465,"group":"supergroup","length":2134,"modificationTime":1434159020632,"owner":"michaeljones","pathSuffix":"pom.xml","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434159014921,"blockSize":134217728,"childrenNum":0,"fileId":16388,"group":"supergroup","length":50,"modificationTime":1433119638967,"owner":"michaeljones","pathSuffix":"wcInput","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18443,"group":"supergroup","length":0,"modificationTime":1434159016805,"owner":"michaeljones","pathSuffix":"wcOutput","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},[\n]"
http-outgoing-0 << "{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18450,"group":"supergroup","length":0,"modificationTime":1434159017973,"owner":"michaeljones","pathSuffix":"wcOutputAnalysis","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},[\n]"
http-outgoing-0 << "{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18457,"group":"supergroup","length":0,"modificationTime":1434159019678,"owner":"michaeljones","pathSuffix":"wcOutputMain","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"}[\n]"
http-outgoing-0 << "]}}[\n]"
http-outgoing-0 << "[\r][\n]"
http-outgoing-0 << "0[\r][\n]"
http-outgoing-0 << "[\r][\n]"
http-outgoing-0 << HTTP/1.1 200 OK
http-outgoing-0 << Cache-Control: no-cache
http-outgoing-0 << Expires: Sat, 13 Jun 2015 03:25:43 GMT
http-outgoing-0 << Date: Sat, 13 Jun 2015 03:25:43 GMT
http-outgoing-0 << Pragma: no-cache
http-outgoing-0 << Expires: Sat, 13 Jun 2015 03:25:43 GMT
http-outgoing-0 << Date: Sat, 13 Jun 2015 03:25:43 GMT
http-outgoing-0 << Pragma: no-cache
http-outgoing-0 << Content-Type: application/json
http-outgoing-0 << Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434201943658&s=ajMRPDFAnTfS+SRjWB9VpgfGHG4="; Path=/; Expires=Sat, 13-Jun-2015 13:25:43 GMT; HttpOnly
http-outgoing-0 << Transfer-Encoding: chunked
http-outgoing-0 << Server: Jetty(6.1.26)
Connection can be kept alive indefinitely
Cookie accepted [hadoop.auth=""u=michaeljones&p=michaeljones&t=simple&e=1434201943658&s=ajMRPDFAnTfS+SRjWB9VpgfGHG4="", version:0, domain:localhost, path:/, expiry:Sat Jun 13 23:25:43 AEST 2015]
Connection [id: 0][route: {}->http://localhost:50070] can be kept alive indefinitely
Connection released: [id: 0][route: {}->http://localhost:50070][total kept alive: 1; route allocated: 1 of 2; total allocated: 1 of 20]
Connection manager is shutting down
http-outgoing-0: Close connection
http-outgoing-0: Close connection
Connection manager shut down
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 1][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://localhost:50070
Connecting to localhost/127.0.0.1:50070
Connection established 127.0.0.1:49570<->127.0.0.1:50070
Executing request PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-1 >> PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1
http-outgoing-1 >> Content-Length: 0
http-outgoing-1 >> Host: localhost:50070
http-outgoing-1 >> Connection: Keep-Alive
http-outgoing-1 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-1 >> Accept-Encoding: gzip,deflate
http-outgoing-1 >> "PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1[\r][\n]"
http-outgoing-1 >> "Content-Length: 0[\r][\n]"
http-outgoing-1 >> "Host: localhost:50070[\r][\n]"
http-outgoing-1 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-1 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-1 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-1 >> "[\r][\n]"
http-outgoing-1 << "HTTP/1.1 307 TEMPORARY_REDIRECT[\r][\n]"
http-outgoing-1 << "Cache-Control: no-cache[\r][\n]"
http-outgoing-1 << "Expires: Sat, 13 Jun 2015 03:25:44 GMT[\r][\n]"
http-outgoing-1 << "Date: Sat, 13 Jun 2015 03:25:44 GMT[\r][\n]"
http-outgoing-1 << "Pragma: no-cache[\r][\n]"
http-outgoing-1 << "Expires: Sat, 13 Jun 2015 03:25:44 GMT[\r][\n]"
http-outgoing-1 << "Date: Sat, 13 Jun 2015 03:25:44 GMT[\r][\n]"
http-outgoing-1 << "Pragma: no-cache[\r][\n]"
http-outgoing-1 << "Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434201944194&s=Fhyvl+xZG7YwHTB/kp1fJjOTQuI="; Path=/; Expires=Sat, 13-Jun-2015 13:25:44 GMT; HttpOnly[\r][\n]"
http-outgoing-1 << "Location: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true[\r][\n]"
http-outgoing-1 << "Content-Type: application/octet-stream[\r][\n]"
http-outgoing-1 << "Content-Length: 0[\r][\n]"
http-outgoing-1 << "Server: Jetty(6.1.26)[\r][\n]"
http-outgoing-1 << "[\r][\n]"
http-outgoing-1 << HTTP/1.1 307 TEMPORARY_REDIRECT
http-outgoing-1 << Cache-Control: no-cache
http-outgoing-1 << Expires: Sat, 13 Jun 2015 03:25:44 GMT
http-outgoing-1 << Date: Sat, 13 Jun 2015 03:25:44 GMT
http-outgoing-1 << Pragma: no-cache
http-outgoing-1 << Expires: Sat, 13 Jun 2015 03:25:44 GMT
http-outgoing-1 << Date: Sat, 13 Jun 2015 03:25:44 GMT
http-outgoing-1 << Pragma: no-cache
http-outgoing-1 << Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434201944194&s=Fhyvl+xZG7YwHTB/kp1fJjOTQuI="; Path=/; Expires=Sat, 13-Jun-2015 13:25:44 GMT; HttpOnly
http-outgoing-1 << Location: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
http-outgoing-1 << Content-Type: application/octet-stream
http-outgoing-1 << Content-Length: 0
http-outgoing-1 << Server: Jetty(6.1.26)
Connection can be kept alive indefinitely
Cookie accepted [hadoop.auth=""u=michaeljones&p=michaeljones&t=simple&e=1434201944194&s=Fhyvl+xZG7YwHTB/kp1fJjOTQuI="", version:0, domain:localhost, path:/, expiry:Sat Jun 13 23:25:44 AEST 2015]
Redirect to: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
http-outgoing-1: Shutdown connection
Connection discarded
http-outgoing-1: Close connection
Connection released: [id: 1][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 2][route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://michaels-air.bigpond:50075
Connecting to michaels-air.bigpond/10.0.0.2:50075
Connection established 10.0.0.2:49571<->10.0.0.2:50075
Executing request PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-2 >> PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1
http-outgoing-2 >> Content-Length: 0
http-outgoing-2 >> Host: michaels-air.bigpond:50075
http-outgoing-2 >> Connection: Keep-Alive
http-outgoing-2 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-2 >> Accept-Encoding: gzip,deflate
http-outgoing-2 >> "PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1[\r][\n]"
http-outgoing-2 >> "Content-Length: 0[\r][\n]"
http-outgoing-2 >> "Host: michaels-air.bigpond:50075[\r][\n]"
http-outgoing-2 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-2 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-2 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-2 >> "[\r][\n]"
http-outgoing-2 << "HTTP/1.1 100 Continue[\r][\n]"
http-outgoing-2 << "[\r][\n]"
http-outgoing-2 << HTTP/1.1 100 Continue
http-outgoing-2 << "HTTP/1.1 201 Created[\r][\n]"
http-outgoing-2 << "Location: hdfs://localhost:9000/user/michaeljones/hello-apache-empty.txt[\r][\n]"
http-outgoing-2 << "Content-Length: 0[\r][\n]"
http-outgoing-2 << "Connection: close[\r][\n]"
http-outgoing-2 << "[\r][\n]"
http-outgoing-2 << HTTP/1.1 201 Created
http-outgoing-2 << Location: hdfs://localhost:9000/user/michaeljones/hello-apache-empty.txt
http-outgoing-2 << Content-Length: 0
http-outgoing-2 << Connection: close
http-outgoing-2: Shutdown connection
Connection discarded
http-outgoing-2: Close connection
Connection released: [id: 2][route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection manager is shutting down
Connection manager shut down
Jersey client Redirect to: hdfs://localhost:9000/user/michaeljones/hellohadoop.log
com.sun.jersey.client.property.chunkedEncodingSize: 1048576
Jersey client Redirect to: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/hello.log.2015-06-12?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 0][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://localhost:50070
Connecting to localhost/127.0.0.1:50070
Connection established 127.0.0.1:49684<->127.0.0.1:50070
Executing request GET /webhdfs/v1/user/michaeljones/?user.name=michaeljones&op=LISTSTATUS HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-0 >> GET /webhdfs/v1/user/michaeljones/?user.name=michaeljones&op=LISTSTATUS HTTP/1.1
http-outgoing-0 >> accept: application/json
http-outgoing-0 >> Host: localhost:50070
http-outgoing-0 >> Connection: Keep-Alive
http-outgoing-0 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-0 >> Accept-Encoding: gzip,deflate
http-outgoing-0 >> "GET /webhdfs/v1/user/michaeljones/?user.name=michaeljones&op=LISTSTATUS HTTP/1.1[\r][\n]"
http-outgoing-0 >> "accept: application/json[\r][\n]"
http-outgoing-0 >> "Host: localhost:50070[\r][\n]"
http-outgoing-0 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-0 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-0 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-0 >> "[\r][\n]"
http-outgoing-0 << "HTTP/1.1 200 OK[\r][\n]"
http-outgoing-0 << "Cache-Control: no-cache[\r][\n]"
http-outgoing-0 << "Expires: Sat, 13 Jun 2015 03:37:48 GMT[\r][\n]"
http-outgoing-0 << "Date: Sat, 13 Jun 2015 03:37:48 GMT[\r][\n]"
http-outgoing-0 << "Pragma: no-cache[\r][\n]"
http-outgoing-0 << "Expires: Sat, 13 Jun 2015 03:37:48 GMT[\r][\n]"
http-outgoing-0 << "Date: Sat, 13 Jun 2015 03:37:48 GMT[\r][\n]"
http-outgoing-0 << "Pragma: no-cache[\r][\n]"
http-outgoing-0 << "Content-Type: application/json[\r][\n]"
http-outgoing-0 << "Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434202668578&s=9URBpMABUwmf2A/FFPq/ezC4Ers="; Path=/; Expires=Sat, 13-Jun-2015 13:37:48 GMT; HttpOnly[\r][\n]"
http-outgoing-0 << "Transfer-Encoding: chunked[\r][\n]"
http-outgoing-0 << "Server: Jetty(6.1.26)[\r][\n]"
http-outgoing-0 << "[\r][\n]"
http-outgoing-0 << "E9C[\r][\n]"
http-outgoing-0 << "{"FileStatuses":{"FileStatus":[[\n]"
http-outgoing-0 << "{"accessTime":1434164720788,"blockSize":134217728,"childrenNum":0,"fileId":18472,"group":"supergroup","length":10899,"modificationTime":1434164720848,"owner":"michaeljones","pathSuffix":"README.md","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434159020549,"blockSize":134217728,"childrenNum":0,"fileId":18464,"group":"supergroup","length":0,"modificationTime":1434159020554,"owner":"michaeljones","pathSuffix":"apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434159021414,"blockSize":134217728,"childrenNum":0,"fileId":18467,"group":"supergroup","length":0,"modificationTime":1434159021420,"owner":"michaeljones","pathSuffix":"empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434165944243,"blockSize":134217728,"childrenNum":0,"fileId":18489,"group":"supergroup","length":0,"modificationTime":1434165944250,"owner":"michaeljones","pathSuffix":"hello-apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434091626279,"blockSize":134217728,"childrenNum":0,"fileId":18298,"group":"supergroup","length":0,"modificationTime":1434091626286,"owner":"michaeljones","pathSuffix":"hello-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434165944123,"blockSize":134217728,"childrenNum":0,"fileId":18488,"group":"supergroup","length":0,"modificationTime":1434165944132,"owner":"michaeljones","pathSuffix":"hello-jersey-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434159021522,"blockSize":134217728,"childrenNum":0,"fileId":18468,"group":"supergroup","length":869081,"modificationTime":1434159021575,"owner":"michaeljones","pathSuffix":"hello.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434159013887,"blockSize":134217728,"childrenNum":0,"fileId":18442,"group":"supergroup","length":20,"modificationTime":1434159014350,"owner":"michaeljones","pathSuffix":"hello.txt","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434165944774,"blockSize":134217728,"childrenNum":0,"fileId":18490,"group":"supergroup","length":62912,"modificationTime":1434165944802,"owner":"michaeljones","pathSuffix":"hellohadoop.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434159020604,"blockSize":134217728,"childrenNum":0,"fileId":18465,"group":"supergroup","length":2134,"modificationTime":1434159020632,"owner":"michaeljones","pathSuffix":"pom.xml","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434159014921,"blockSize":134217728,"childrenNum":0,"fileId":16388,"group":"supergroup","length":50,"modificationTime":1433119638967,"owner":"michaeljones","pathSuffix":"wcInput","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18443,"group":"supergroup","length":0,"modificationTime":1434159016805,"owner":"michaeljones","pathSuffix":"wcOutput","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},[\n]"
http-outgoing-0 << "{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18450,"group":"supergroup","length":0,"modificationTime":1434159017973,"owner":"michaeljones","pathSuffix":"wcOutputAnalysis","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},[\n]"
http-outgoing-0 << "{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18457,"group":"supergroup","length":0,"modificationTime":1434159019678,"owner":"michaeljones","pathSuffix":"wcOutputMain","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"}[\n]"
http-outgoing-0 << "]}}[\n]"
http-outgoing-0 << "[\r][\n]"
http-outgoing-0 << "0[\r][\n]"
http-outgoing-0 << "[\r][\n]"
http-outgoing-0 << HTTP/1.1 200 OK
http-outgoing-0 << Cache-Control: no-cache
http-outgoing-0 << Expires: Sat, 13 Jun 2015 03:37:48 GMT
http-outgoing-0 << Date: Sat, 13 Jun 2015 03:37:48 GMT
http-outgoing-0 << Pragma: no-cache
http-outgoing-0 << Expires: Sat, 13 Jun 2015 03:37:48 GMT
http-outgoing-0 << Date: Sat, 13 Jun 2015 03:37:48 GMT
http-outgoing-0 << Pragma: no-cache
http-outgoing-0 << Content-Type: application/json
http-outgoing-0 << Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434202668578&s=9URBpMABUwmf2A/FFPq/ezC4Ers="; Path=/; Expires=Sat, 13-Jun-2015 13:37:48 GMT; HttpOnly
http-outgoing-0 << Transfer-Encoding: chunked
http-outgoing-0 << Server: Jetty(6.1.26)
Connection can be kept alive indefinitely
Cookie accepted [hadoop.auth=""u=michaeljones&p=michaeljones&t=simple&e=1434202668578&s=9URBpMABUwmf2A/FFPq/ezC4Ers="", version:0, domain:localhost, path:/, expiry:Sat Jun 13 23:37:48 AEST 2015]
Connection [id: 0][route: {}->http://localhost:50070] can be kept alive indefinitely
Connection released: [id: 0][route: {}->http://localhost:50070][total kept alive: 1; route allocated: 1 of 2; total allocated: 1 of 20]
Connection manager is shutting down
http-outgoing-0: Close connection
http-outgoing-0: Close connection
Connection manager shut down
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 1][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://localhost:50070
Connecting to localhost/127.0.0.1:50070
Connection established 127.0.0.1:49687<->127.0.0.1:50070
Executing request PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-1 >> PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1
http-outgoing-1 >> Content-Length: 0
http-outgoing-1 >> Host: localhost:50070
http-outgoing-1 >> Connection: Keep-Alive
http-outgoing-1 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-1 >> Accept-Encoding: gzip,deflate
http-outgoing-1 >> "PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1[\r][\n]"
http-outgoing-1 >> "Content-Length: 0[\r][\n]"
http-outgoing-1 >> "Host: localhost:50070[\r][\n]"
http-outgoing-1 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-1 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-1 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-1 >> "[\r][\n]"
http-outgoing-1 << "HTTP/1.1 307 TEMPORARY_REDIRECT[\r][\n]"
http-outgoing-1 << "Cache-Control: no-cache[\r][\n]"
http-outgoing-1 << "Expires: Sat, 13 Jun 2015 03:37:49 GMT[\r][\n]"
http-outgoing-1 << "Date: Sat, 13 Jun 2015 03:37:49 GMT[\r][\n]"
http-outgoing-1 << "Pragma: no-cache[\r][\n]"
http-outgoing-1 << "Expires: Sat, 13 Jun 2015 03:37:49 GMT[\r][\n]"
http-outgoing-1 << "Date: Sat, 13 Jun 2015 03:37:49 GMT[\r][\n]"
http-outgoing-1 << "Pragma: no-cache[\r][\n]"
http-outgoing-1 << "Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434202669037&s=GWKzEhiO3jE7Dz52U2h+dKe99Po="; Path=/; Expires=Sat, 13-Jun-2015 13:37:49 GMT; HttpOnly[\r][\n]"
http-outgoing-1 << "Location: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true[\r][\n]"
http-outgoing-1 << "Content-Type: application/octet-stream[\r][\n]"
http-outgoing-1 << "Content-Length: 0[\r][\n]"
http-outgoing-1 << "Server: Jetty(6.1.26)[\r][\n]"
http-outgoing-1 << "[\r][\n]"
http-outgoing-1 << HTTP/1.1 307 TEMPORARY_REDIRECT
http-outgoing-1 << Cache-Control: no-cache
http-outgoing-1 << Expires: Sat, 13 Jun 2015 03:37:49 GMT
http-outgoing-1 << Date: Sat, 13 Jun 2015 03:37:49 GMT
http-outgoing-1 << Pragma: no-cache
http-outgoing-1 << Expires: Sat, 13 Jun 2015 03:37:49 GMT
http-outgoing-1 << Date: Sat, 13 Jun 2015 03:37:49 GMT
http-outgoing-1 << Pragma: no-cache
http-outgoing-1 << Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434202669037&s=GWKzEhiO3jE7Dz52U2h+dKe99Po="; Path=/; Expires=Sat, 13-Jun-2015 13:37:49 GMT; HttpOnly
http-outgoing-1 << Location: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
http-outgoing-1 << Content-Type: application/octet-stream
http-outgoing-1 << Content-Length: 0
http-outgoing-1 << Server: Jetty(6.1.26)
Connection can be kept alive indefinitely
Cookie accepted [hadoop.auth=""u=michaeljones&p=michaeljones&t=simple&e=1434202669037&s=GWKzEhiO3jE7Dz52U2h+dKe99Po="", version:0, domain:localhost, path:/, expiry:Sat Jun 13 23:37:49 AEST 2015]
Redirect to: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
http-outgoing-1: Shutdown connection
Connection discarded
http-outgoing-1: Close connection
Connection released: [id: 1][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 2][route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://michaels-air.bigpond:50075
Connecting to michaels-air.bigpond/10.0.0.2:50075
Connection established 10.0.0.2:49688<->10.0.0.2:50075
Executing request PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-2 >> PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1
http-outgoing-2 >> Content-Length: 0
http-outgoing-2 >> Host: michaels-air.bigpond:50075
http-outgoing-2 >> Connection: Keep-Alive
http-outgoing-2 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-2 >> Accept-Encoding: gzip,deflate
http-outgoing-2 >> "PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1[\r][\n]"
http-outgoing-2 >> "Content-Length: 0[\r][\n]"
http-outgoing-2 >> "Host: michaels-air.bigpond:50075[\r][\n]"
http-outgoing-2 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-2 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-2 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-2 >> "[\r][\n]"
http-outgoing-2 << "HTTP/1.1 100 Continue[\r][\n]"
http-outgoing-2 << "[\r][\n]"
http-outgoing-2 << HTTP/1.1 100 Continue
http-outgoing-2 << "HTTP/1.1 201 Created[\r][\n]"
http-outgoing-2 << "Location: hdfs://localhost:9000/user/michaeljones/hello-apache-empty.txt[\r][\n]"
http-outgoing-2 << "Content-Length: 0[\r][\n]"
http-outgoing-2 << "Connection: close[\r][\n]"
http-outgoing-2 << "[\r][\n]"
http-outgoing-2 << HTTP/1.1 201 Created
http-outgoing-2 << Location: hdfs://localhost:9000/user/michaeljones/hello-apache-empty.txt
http-outgoing-2 << Content-Length: 0
http-outgoing-2 << Connection: close
http-outgoing-2: Shutdown connection
Connection discarded
http-outgoing-2: Close connection
Connection released: [id: 2][route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection manager is shutting down
Connection manager shut down
Jersey client Redirect to: hdfs://localhost:9000/user/michaeljones/hellohadoop.log
com.sun.jersey.client.property.chunkedEncodingSize: 1048576
Jersey client Redirect to: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/hello.log.2015-06-12?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 0][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://localhost:50070
Connecting to localhost/127.0.0.1:50070
Connection established 127.0.0.1:49712<->127.0.0.1:50070
Executing request GET /webhdfs/v1/user/michaeljones/?user.name=michaeljones&op=LISTSTATUS HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-0 >> GET /webhdfs/v1/user/michaeljones/?user.name=michaeljones&op=LISTSTATUS HTTP/1.1
http-outgoing-0 >> accept: application/json
http-outgoing-0 >> Host: localhost:50070
http-outgoing-0 >> Connection: Keep-Alive
http-outgoing-0 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-0 >> Accept-Encoding: gzip,deflate
http-outgoing-0 >> "GET /webhdfs/v1/user/michaeljones/?user.name=michaeljones&op=LISTSTATUS HTTP/1.1[\r][\n]"
http-outgoing-0 >> "accept: application/json[\r][\n]"
http-outgoing-0 >> "Host: localhost:50070[\r][\n]"
http-outgoing-0 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-0 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-0 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-0 >> "[\r][\n]"
http-outgoing-0 << "HTTP/1.1 200 OK[\r][\n]"
http-outgoing-0 << "Cache-Control: no-cache[\r][\n]"
http-outgoing-0 << "Expires: Sat, 13 Jun 2015 03:40:33 GMT[\r][\n]"
http-outgoing-0 << "Date: Sat, 13 Jun 2015 03:40:33 GMT[\r][\n]"
http-outgoing-0 << "Pragma: no-cache[\r][\n]"
http-outgoing-0 << "Expires: Sat, 13 Jun 2015 03:40:33 GMT[\r][\n]"
http-outgoing-0 << "Date: Sat, 13 Jun 2015 03:40:33 GMT[\r][\n]"
http-outgoing-0 << "Pragma: no-cache[\r][\n]"
http-outgoing-0 << "Content-Type: application/json[\r][\n]"
http-outgoing-0 << "Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434202833295&s=siwttfqX+yLUZewgomIxqofr2M8="; Path=/; Expires=Sat, 13-Jun-2015 13:40:33 GMT; HttpOnly[\r][\n]"
http-outgoing-0 << "Transfer-Encoding: chunked[\r][\n]"
http-outgoing-0 << "Server: Jetty(6.1.26)[\r][\n]"
http-outgoing-0 << "[\r][\n]"
http-outgoing-0 << "E9C[\r][\n]"
http-outgoing-0 << "{"FileStatuses":{"FileStatus":[[\n]"
http-outgoing-0 << "{"accessTime":1434164720788,"blockSize":134217728,"childrenNum":0,"fileId":18472,"group":"supergroup","length":10899,"modificationTime":1434164720848,"owner":"michaeljones","pathSuffix":"README.md","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434159020549,"blockSize":134217728,"childrenNum":0,"fileId":18464,"group":"supergroup","length":0,"modificationTime":1434159020554,"owner":"michaeljones","pathSuffix":"apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434159021414,"blockSize":134217728,"childrenNum":0,"fileId":18467,"group":"supergroup","length":0,"modificationTime":1434159021420,"owner":"michaeljones","pathSuffix":"empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434166669066,"blockSize":134217728,"childrenNum":0,"fileId":18492,"group":"supergroup","length":0,"modificationTime":1434166669073,"owner":"michaeljones","pathSuffix":"hello-apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434091626279,"blockSize":134217728,"childrenNum":0,"fileId":18298,"group":"supergroup","length":0,"modificationTime":1434091626286,"owner":"michaeljones","pathSuffix":"hello-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434166669010,"blockSize":134217728,"childrenNum":0,"fileId":18491,"group":"supergroup","length":0,"modificationTime":1434166669016,"owner":"michaeljones","pathSuffix":"hello-jersey-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434159021522,"blockSize":134217728,"childrenNum":0,"fileId":18468,"group":"supergroup","length":869081,"modificationTime":1434159021575,"owner":"michaeljones","pathSuffix":"hello.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434159013887,"blockSize":134217728,"childrenNum":0,"fileId":18442,"group":"supergroup","length":20,"modificationTime":1434159014350,"owner":"michaeljones","pathSuffix":"hello.txt","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434166669406,"blockSize":134217728,"childrenNum":0,"fileId":18493,"group":"supergroup","length":62912,"modificationTime":1434166669427,"owner":"michaeljones","pathSuffix":"hellohadoop.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434159020604,"blockSize":134217728,"childrenNum":0,"fileId":18465,"group":"supergroup","length":2134,"modificationTime":1434159020632,"owner":"michaeljones","pathSuffix":"pom.xml","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434159014921,"blockSize":134217728,"childrenNum":0,"fileId":16388,"group":"supergroup","length":50,"modificationTime":1433119638967,"owner":"michaeljones","pathSuffix":"wcInput","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18443,"group":"supergroup","length":0,"modificationTime":1434159016805,"owner":"michaeljones","pathSuffix":"wcOutput","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},[\n]"
http-outgoing-0 << "{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18450,"group":"supergroup","length":0,"modificationTime":1434159017973,"owner":"michaeljones","pathSuffix":"wcOutputAnalysis","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},[\n]"
http-outgoing-0 << "{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18457,"group":"supergroup","length":0,"modificationTime":1434159019678,"owner":"michaeljones","pathSuffix":"wcOutputMain","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"}[\n]"
http-outgoing-0 << "]}}[\n]"
http-outgoing-0 << "[\r][\n]"
http-outgoing-0 << "0[\r][\n]"
http-outgoing-0 << "[\r][\n]"
http-outgoing-0 << HTTP/1.1 200 OK
http-outgoing-0 << Cache-Control: no-cache
http-outgoing-0 << Expires: Sat, 13 Jun 2015 03:40:33 GMT
http-outgoing-0 << Date: Sat, 13 Jun 2015 03:40:33 GMT
http-outgoing-0 << Pragma: no-cache
http-outgoing-0 << Expires: Sat, 13 Jun 2015 03:40:33 GMT
http-outgoing-0 << Date: Sat, 13 Jun 2015 03:40:33 GMT
http-outgoing-0 << Pragma: no-cache
http-outgoing-0 << Content-Type: application/json
http-outgoing-0 << Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434202833295&s=siwttfqX+yLUZewgomIxqofr2M8="; Path=/; Expires=Sat, 13-Jun-2015 13:40:33 GMT; HttpOnly
http-outgoing-0 << Transfer-Encoding: chunked
http-outgoing-0 << Server: Jetty(6.1.26)
Connection can be kept alive indefinitely
Cookie accepted [hadoop.auth=""u=michaeljones&p=michaeljones&t=simple&e=1434202833295&s=siwttfqX+yLUZewgomIxqofr2M8="", version:0, domain:localhost, path:/, expiry:Sat Jun 13 23:40:33 AEST 2015]
Connection [id: 0][route: {}->http://localhost:50070] can be kept alive indefinitely
Connection released: [id: 0][route: {}->http://localhost:50070][total kept alive: 1; route allocated: 1 of 2; total allocated: 1 of 20]
Connection manager is shutting down
http-outgoing-0: Close connection
http-outgoing-0: Close connection
Connection manager shut down
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 1][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://localhost:50070
Connecting to localhost/127.0.0.1:50070
Connection established 127.0.0.1:49715<->127.0.0.1:50070
Executing request PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-1 >> PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1
http-outgoing-1 >> Content-Length: 0
http-outgoing-1 >> Host: localhost:50070
http-outgoing-1 >> Connection: Keep-Alive
http-outgoing-1 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-1 >> Accept-Encoding: gzip,deflate
http-outgoing-1 >> "PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1[\r][\n]"
http-outgoing-1 >> "Content-Length: 0[\r][\n]"
http-outgoing-1 >> "Host: localhost:50070[\r][\n]"
http-outgoing-1 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-1 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-1 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-1 >> "[\r][\n]"
http-outgoing-1 << "HTTP/1.1 307 TEMPORARY_REDIRECT[\r][\n]"
http-outgoing-1 << "Cache-Control: no-cache[\r][\n]"
http-outgoing-1 << "Expires: Sat, 13 Jun 2015 03:40:33 GMT[\r][\n]"
http-outgoing-1 << "Date: Sat, 13 Jun 2015 03:40:33 GMT[\r][\n]"
http-outgoing-1 << "Pragma: no-cache[\r][\n]"
http-outgoing-1 << "Expires: Sat, 13 Jun 2015 03:40:33 GMT[\r][\n]"
http-outgoing-1 << "Date: Sat, 13 Jun 2015 03:40:33 GMT[\r][\n]"
http-outgoing-1 << "Pragma: no-cache[\r][\n]"
http-outgoing-1 << "Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434202833940&s=37Gnhm6SHf09GOGRBgCWN8x2cNI="; Path=/; Expires=Sat, 13-Jun-2015 13:40:33 GMT; HttpOnly[\r][\n]"
http-outgoing-1 << "Location: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true[\r][\n]"
http-outgoing-1 << "Content-Type: application/octet-stream[\r][\n]"
http-outgoing-1 << "Content-Length: 0[\r][\n]"
http-outgoing-1 << "Server: Jetty(6.1.26)[\r][\n]"
http-outgoing-1 << "[\r][\n]"
http-outgoing-1 << HTTP/1.1 307 TEMPORARY_REDIRECT
http-outgoing-1 << Cache-Control: no-cache
http-outgoing-1 << Expires: Sat, 13 Jun 2015 03:40:33 GMT
http-outgoing-1 << Date: Sat, 13 Jun 2015 03:40:33 GMT
http-outgoing-1 << Pragma: no-cache
http-outgoing-1 << Expires: Sat, 13 Jun 2015 03:40:33 GMT
http-outgoing-1 << Date: Sat, 13 Jun 2015 03:40:33 GMT
http-outgoing-1 << Pragma: no-cache
http-outgoing-1 << Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434202833940&s=37Gnhm6SHf09GOGRBgCWN8x2cNI="; Path=/; Expires=Sat, 13-Jun-2015 13:40:33 GMT; HttpOnly
http-outgoing-1 << Location: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
http-outgoing-1 << Content-Type: application/octet-stream
http-outgoing-1 << Content-Length: 0
http-outgoing-1 << Server: Jetty(6.1.26)
Connection can be kept alive indefinitely
Cookie accepted [hadoop.auth=""u=michaeljones&p=michaeljones&t=simple&e=1434202833940&s=37Gnhm6SHf09GOGRBgCWN8x2cNI="", version:0, domain:localhost, path:/, expiry:Sat Jun 13 23:40:33 AEST 2015]
Redirect to: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
http-outgoing-1: Shutdown connection
Connection discarded
http-outgoing-1: Close connection
Connection released: [id: 1][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 2][route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://michaels-air.bigpond:50075
Connecting to michaels-air.bigpond/10.0.0.2:50075
Connection established 10.0.0.2:49716<->10.0.0.2:50075
Executing request PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-2 >> PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1
http-outgoing-2 >> Content-Length: 0
http-outgoing-2 >> Host: michaels-air.bigpond:50075
http-outgoing-2 >> Connection: Keep-Alive
http-outgoing-2 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-2 >> Accept-Encoding: gzip,deflate
http-outgoing-2 >> "PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1[\r][\n]"
http-outgoing-2 >> "Content-Length: 0[\r][\n]"
http-outgoing-2 >> "Host: michaels-air.bigpond:50075[\r][\n]"
http-outgoing-2 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-2 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-2 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-2 >> "[\r][\n]"
http-outgoing-2 << "HTTP/1.1 100 Continue[\r][\n]"
http-outgoing-2 << "[\r][\n]"
http-outgoing-2 << HTTP/1.1 100 Continue
http-outgoing-2 << "HTTP/1.1 201 Created[\r][\n]"
http-outgoing-2 << "Location: hdfs://localhost:9000/user/michaeljones/hello-apache-empty.txt[\r][\n]"
http-outgoing-2 << "Content-Length: 0[\r][\n]"
http-outgoing-2 << "Connection: close[\r][\n]"
http-outgoing-2 << "[\r][\n]"
http-outgoing-2 << HTTP/1.1 201 Created
http-outgoing-2 << Location: hdfs://localhost:9000/user/michaeljones/hello-apache-empty.txt
http-outgoing-2 << Content-Length: 0
http-outgoing-2 << Connection: close
http-outgoing-2: Shutdown connection
Connection discarded
http-outgoing-2: Close connection
Connection released: [id: 2][route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection manager is shutting down
Connection manager shut down
Jersey client Redirect to: hdfs://localhost:9000/user/michaeljones/hellohadoop.log
com.sun.jersey.client.property.chunkedEncodingSize: 1048576
Jersey client Redirect to: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/hello.log.2015-06-12?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 0][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://localhost:50070
Connecting to localhost/127.0.0.1:50070
Connection established 127.0.0.1:49766<->127.0.0.1:50070
Executing request GET /webhdfs/v1/user/michaeljones/?user.name=michaeljones&op=LISTSTATUS HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-0 >> GET /webhdfs/v1/user/michaeljones/?user.name=michaeljones&op=LISTSTATUS HTTP/1.1
http-outgoing-0 >> accept: application/json
http-outgoing-0 >> Host: localhost:50070
http-outgoing-0 >> Connection: Keep-Alive
http-outgoing-0 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-0 >> Accept-Encoding: gzip,deflate
http-outgoing-0 >> "GET /webhdfs/v1/user/michaeljones/?user.name=michaeljones&op=LISTSTATUS HTTP/1.1[\r][\n]"
http-outgoing-0 >> "accept: application/json[\r][\n]"
http-outgoing-0 >> "Host: localhost:50070[\r][\n]"
http-outgoing-0 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-0 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-0 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-0 >> "[\r][\n]"
http-outgoing-0 << "HTTP/1.1 200 OK[\r][\n]"
http-outgoing-0 << "Cache-Control: no-cache[\r][\n]"
http-outgoing-0 << "Expires: Sat, 13 Jun 2015 03:45:34 GMT[\r][\n]"
http-outgoing-0 << "Date: Sat, 13 Jun 2015 03:45:34 GMT[\r][\n]"
http-outgoing-0 << "Pragma: no-cache[\r][\n]"
http-outgoing-0 << "Expires: Sat, 13 Jun 2015 03:45:34 GMT[\r][\n]"
http-outgoing-0 << "Date: Sat, 13 Jun 2015 03:45:34 GMT[\r][\n]"
http-outgoing-0 << "Pragma: no-cache[\r][\n]"
http-outgoing-0 << "Content-Type: application/json[\r][\n]"
http-outgoing-0 << "Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434203134054&s=YCYV978U324MBPIKl+ZsqQt3rfk="; Path=/; Expires=Sat, 13-Jun-2015 13:45:34 GMT; HttpOnly[\r][\n]"
http-outgoing-0 << "Transfer-Encoding: chunked[\r][\n]"
http-outgoing-0 << "Server: Jetty(6.1.26)[\r][\n]"
http-outgoing-0 << "[\r][\n]"
http-outgoing-0 << "E9C[\r][\n]"
http-outgoing-0 << "{"FileStatuses":{"FileStatus":[[\n]"
http-outgoing-0 << "{"accessTime":1434164720788,"blockSize":134217728,"childrenNum":0,"fileId":18472,"group":"supergroup","length":10899,"modificationTime":1434164720848,"owner":"michaeljones","pathSuffix":"README.md","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434159020549,"blockSize":134217728,"childrenNum":0,"fileId":18464,"group":"supergroup","length":0,"modificationTime":1434159020554,"owner":"michaeljones","pathSuffix":"apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434159021414,"blockSize":134217728,"childrenNum":0,"fileId":18467,"group":"supergroup","length":0,"modificationTime":1434159021420,"owner":"michaeljones","pathSuffix":"empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434166833976,"blockSize":134217728,"childrenNum":0,"fileId":18495,"group":"supergroup","length":0,"modificationTime":1434166833983,"owner":"michaeljones","pathSuffix":"hello-apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434091626279,"blockSize":134217728,"childrenNum":0,"fileId":18298,"group":"supergroup","length":0,"modificationTime":1434091626286,"owner":"michaeljones","pathSuffix":"hello-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434166833897,"blockSize":134217728,"childrenNum":0,"fileId":18494,"group":"supergroup","length":0,"modificationTime":1434166833904,"owner":"michaeljones","pathSuffix":"hello-jersey-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434159021522,"blockSize":134217728,"childrenNum":0,"fileId":18468,"group":"supergroup","length":869081,"modificationTime":1434159021575,"owner":"michaeljones","pathSuffix":"hello.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434159013887,"blockSize":134217728,"childrenNum":0,"fileId":18442,"group":"supergroup","length":20,"modificationTime":1434159014350,"owner":"michaeljones","pathSuffix":"hello.txt","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434166838149,"blockSize":134217728,"childrenNum":0,"fileId":18496,"group":"supergroup","length":62912,"modificationTime":1434166838233,"owner":"michaeljones","pathSuffix":"hellohadoop.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434159020604,"blockSize":134217728,"childrenNum":0,"fileId":18465,"group":"supergroup","length":2134,"modificationTime":1434159020632,"owner":"michaeljones","pathSuffix":"pom.xml","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434159014921,"blockSize":134217728,"childrenNum":0,"fileId":16388,"group":"supergroup","length":50,"modificationTime":1433119638967,"owner":"michaeljones","pathSuffix":"wcInput","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18443,"group":"supergroup","length":0,"modificationTime":1434159016805,"owner":"michaeljones","pathSuffix":"wcOutput","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},[\n]"
http-outgoing-0 << "{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18450,"group":"supergroup","length":0,"modificationTime":1434159017973,"owner":"michaeljones","pathSuffix":"wcOutputAnalysis","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},[\n]"
http-outgoing-0 << "{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18457,"group":"supergroup","length":0,"modificationTime":1434159019678,"owner":"michaeljones","pathSuffix":"wcOutputMain","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"}[\n]"
http-outgoing-0 << "]}}[\n]"
http-outgoing-0 << "[\r][\n]"
http-outgoing-0 << HTTP/1.1 200 OK
http-outgoing-0 << Cache-Control: no-cache
http-outgoing-0 << Expires: Sat, 13 Jun 2015 03:45:34 GMT
http-outgoing-0 << Date: Sat, 13 Jun 2015 03:45:34 GMT
http-outgoing-0 << Pragma: no-cache
http-outgoing-0 << Expires: Sat, 13 Jun 2015 03:45:34 GMT
http-outgoing-0 << Date: Sat, 13 Jun 2015 03:45:34 GMT
http-outgoing-0 << Pragma: no-cache
http-outgoing-0 << Content-Type: application/json
http-outgoing-0 << Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434203134054&s=YCYV978U324MBPIKl+ZsqQt3rfk="; Path=/; Expires=Sat, 13-Jun-2015 13:45:34 GMT; HttpOnly
http-outgoing-0 << Transfer-Encoding: chunked
http-outgoing-0 << Server: Jetty(6.1.26)
Connection can be kept alive indefinitely
Cookie accepted [hadoop.auth=""u=michaeljones&p=michaeljones&t=simple&e=1434203134054&s=YCYV978U324MBPIKl+ZsqQt3rfk="", version:0, domain:localhost, path:/, expiry:Sat Jun 13 23:45:34 AEST 2015]
http-outgoing-0 << "0[\r][\n]"
http-outgoing-0 << "[\r][\n]"
Connection [id: 0][route: {}->http://localhost:50070] can be kept alive indefinitely
Connection released: [id: 0][route: {}->http://localhost:50070][total kept alive: 1; route allocated: 1 of 2; total allocated: 1 of 20]
Connection manager is shutting down
http-outgoing-0: Close connection
http-outgoing-0: Close connection
Connection manager shut down
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 1][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://localhost:50070
Connecting to localhost/127.0.0.1:50070
Connection established 127.0.0.1:49769<->127.0.0.1:50070
Executing request PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-1 >> PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1
http-outgoing-1 >> Content-Length: 0
http-outgoing-1 >> Host: localhost:50070
http-outgoing-1 >> Connection: Keep-Alive
http-outgoing-1 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-1 >> Accept-Encoding: gzip,deflate
http-outgoing-1 >> "PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1[\r][\n]"
http-outgoing-1 >> "Content-Length: 0[\r][\n]"
http-outgoing-1 >> "Host: localhost:50070[\r][\n]"
http-outgoing-1 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-1 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-1 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-1 >> "[\r][\n]"
http-outgoing-1 << "HTTP/1.1 307 TEMPORARY_REDIRECT[\r][\n]"
http-outgoing-1 << "Cache-Control: no-cache[\r][\n]"
http-outgoing-1 << "Expires: Sat, 13 Jun 2015 03:45:34 GMT[\r][\n]"
http-outgoing-1 << "Date: Sat, 13 Jun 2015 03:45:34 GMT[\r][\n]"
http-outgoing-1 << "Pragma: no-cache[\r][\n]"
http-outgoing-1 << "Expires: Sat, 13 Jun 2015 03:45:34 GMT[\r][\n]"
http-outgoing-1 << "Date: Sat, 13 Jun 2015 03:45:34 GMT[\r][\n]"
http-outgoing-1 << "Pragma: no-cache[\r][\n]"
http-outgoing-1 << "Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434203134579&s=YCKhnuuKO9GG/NkKpfjbDCZPmLk="; Path=/; Expires=Sat, 13-Jun-2015 13:45:34 GMT; HttpOnly[\r][\n]"
http-outgoing-1 << "Location: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true[\r][\n]"
http-outgoing-1 << "Content-Type: application/octet-stream[\r][\n]"
http-outgoing-1 << "Content-Length: 0[\r][\n]"
http-outgoing-1 << "Server: Jetty(6.1.26)[\r][\n]"
http-outgoing-1 << "[\r][\n]"
http-outgoing-1 << HTTP/1.1 307 TEMPORARY_REDIRECT
http-outgoing-1 << Cache-Control: no-cache
http-outgoing-1 << Expires: Sat, 13 Jun 2015 03:45:34 GMT
http-outgoing-1 << Date: Sat, 13 Jun 2015 03:45:34 GMT
http-outgoing-1 << Pragma: no-cache
http-outgoing-1 << Expires: Sat, 13 Jun 2015 03:45:34 GMT
http-outgoing-1 << Date: Sat, 13 Jun 2015 03:45:34 GMT
http-outgoing-1 << Pragma: no-cache
http-outgoing-1 << Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434203134579&s=YCKhnuuKO9GG/NkKpfjbDCZPmLk="; Path=/; Expires=Sat, 13-Jun-2015 13:45:34 GMT; HttpOnly
http-outgoing-1 << Location: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
http-outgoing-1 << Content-Type: application/octet-stream
http-outgoing-1 << Content-Length: 0
http-outgoing-1 << Server: Jetty(6.1.26)
Connection can be kept alive indefinitely
Cookie accepted [hadoop.auth=""u=michaeljones&p=michaeljones&t=simple&e=1434203134579&s=YCKhnuuKO9GG/NkKpfjbDCZPmLk="", version:0, domain:localhost, path:/, expiry:Sat Jun 13 23:45:34 AEST 2015]
Redirect to: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
http-outgoing-1: Shutdown connection
Connection discarded
http-outgoing-1: Close connection
Connection released: [id: 1][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 2][route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://michaels-air.bigpond:50075
Connecting to michaels-air.bigpond/10.0.0.2:50075
Connection established 10.0.0.2:49770<->10.0.0.2:50075
Executing request PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-2 >> PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1
http-outgoing-2 >> Content-Length: 0
http-outgoing-2 >> Host: michaels-air.bigpond:50075
http-outgoing-2 >> Connection: Keep-Alive
http-outgoing-2 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-2 >> Accept-Encoding: gzip,deflate
http-outgoing-2 >> "PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1[\r][\n]"
http-outgoing-2 >> "Content-Length: 0[\r][\n]"
http-outgoing-2 >> "Host: michaels-air.bigpond:50075[\r][\n]"
http-outgoing-2 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-2 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-2 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-2 >> "[\r][\n]"
http-outgoing-2 << "HTTP/1.1 100 Continue[\r][\n]"
http-outgoing-2 << "[\r][\n]"
http-outgoing-2 << HTTP/1.1 100 Continue
http-outgoing-2 << "HTTP/1.1 201 Created[\r][\n]"
http-outgoing-2 << "Location: hdfs://localhost:9000/user/michaeljones/hello-apache-empty.txt[\r][\n]"
http-outgoing-2 << "Content-Length: 0[\r][\n]"
http-outgoing-2 << "Connection: close[\r][\n]"
http-outgoing-2 << "[\r][\n]"
http-outgoing-2 << HTTP/1.1 201 Created
http-outgoing-2 << Location: hdfs://localhost:9000/user/michaeljones/hello-apache-empty.txt
http-outgoing-2 << Content-Length: 0
http-outgoing-2 << Connection: close
http-outgoing-2: Shutdown connection
Connection discarded
http-outgoing-2: Close connection
Connection released: [id: 2][route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection manager is shutting down
Connection manager shut down
Jersey client Redirect to: hdfs://localhost:9000/user/michaeljones/hellohadoop.log
com.sun.jersey.client.property.chunkedEncodingSize: 1048576
Jersey client Redirect to: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/hello.log.2015-06-12?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 3][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://localhost:50070
Connecting to localhost/127.0.0.1:50070
Connection established 127.0.0.1:49780<->127.0.0.1:50070
Executing request PUT /webhdfs/v1/user/michaeljones/README.md?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-3 >> PUT /webhdfs/v1/user/michaeljones/README.md?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1
http-outgoing-3 >> Transfer-Encoding: chunked
http-outgoing-3 >> Content-Type: application/octet-stream
http-outgoing-3 >> Host: localhost:50070
http-outgoing-3 >> Connection: Keep-Alive
http-outgoing-3 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-3 >> Accept-Encoding: gzip,deflate
http-outgoing-3 >> "PUT /webhdfs/v1/user/michaeljones/README.md?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1[\r][\n]"
http-outgoing-3 >> "Transfer-Encoding: chunked[\r][\n]"
http-outgoing-3 >> "Content-Type: application/octet-stream[\r][\n]"
http-outgoing-3 >> "Host: localhost:50070[\r][\n]"
http-outgoing-3 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-3 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-3 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-3 >> "[\r][\n]"
http-outgoing-3 >> "1000[\r][\n]"
http-outgoing-3 >> "# Hello-Hadoop-netbeans-OS-X[\n]"
http-outgoing-3 >> "Java Maven project for playing with the HDFS API without any 3rd party hadoop plugins.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## Aim of project[\n]"
http-outgoing-3 >> "Hello world/tutorial level for programmatically operating with a pseudo distributed hadoop configuration on OS X. Hadoop 2.7 on Yosemite.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## What this project demonstrates[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "This is work in progress and so far the following functionality is demonstrated:[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "1. Direct programmatic control of the HDFS and running map reduce jobs - all unit tests run from the IDE with hadoop configuration built into this project and under git control.[\n]"
http-outgoing-3 >> "2. Uploading of files to the HDFS by implementing a Web REST API client.[\n]"
http-outgoing-3 >> "3. Layered application code for maximum re-use and ease of test driven development. The client I wrote uses an interface which has allowed me to provide both a Jersey HTTP client implementation and an Apache HTTP client implementation for comparison between the two toolkits.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "The initial difficulty was working out how to run the program in the IDE and talk to the local pseudo distributed setup without using a 3rd party Hadoop plugin. Apparently there used to be a plugin for netbeans, but it has been discontinued. I am a newbie with this technology.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "The Apache Hadoop instructions for building and running java programs are via their command line build/run utility only. Getting the yahoo hadoop HDFS tutorial program to build in the IDE wasn't too hard. However, by default it will ignore the local Hadoop configuration and only operate with the local file system in local debug mode.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## Wading through the configuration[\n]"
http-outgoing-3 >> "Hadoop is designed to work with a number of different topologies, directory locations, levels of replication, simulated environments etc. so as we would expect nothing works unless the configuration is right.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "First Hadoop needs to be installed and configured in pseudo distributed mode such that it builds and runs test programs on the command line. The hadoop documentation has instructions for doing this. Documentation is online and also included in the installation: share/doc/hadoop/index.html. However this is not enough to get it to work in the IDE.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## The netbeans project settings that are needed to run with the HDFS from the IDE:[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "1. Get log4j configured to work in the IDE. Absence of log4j configuration won't stop hadoop from running, but we won't get to see useful error messages from hadoop without it.[\n]"
http-outgoing-3 >> "2. HADOOP_HOME environment variable project run (and test) property.[\n]"
http-outgoing-3 >> "3. Duplicate hadoop configuration in the classpath. The above environment variable does not pick up the hadoop configuration from its usual place. Yahoo's only suggestion is to run from the command line via the hadoop script. The Apache HDFS API documention says that configuration is looked for in the classpath, so I took the approach of duplicating the configuration (just 2 files) instead of figuring out how to get it to look in the installation path.[\n]"
http-outgoing-3 >> "4. The correct Maven dependencies. If not all the jar depenencies are there the program may build and run, but it won't talk to the HDFS if it doesn't load the HDFS jars.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "I think that the setup of this project would probably work on Linux too.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## Working through trouble shooting the HDFS project settings[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "Issue 1 above shows up as:[\n]"
http-outgoing-3 >> "<pre><code>[\n]"
http-outgoing-3 >> "log4j:WARN No appenders could be found for logger (org.apache.hadoop.util.Shell).[\n]"
http-outgoing-3 >> "log4j:WARN Please initialize the log4j system properly.[\n]"
http-outgoing-3 >> "log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.[\n]"
http-outgoing-3 >> "</pre></code>[\n]"
http-outgoing-3 >> "This is solved by putting a log4j.properties configuration file in the classpath. For a Maven build getting files into the classpath can be achieved by putting them in src/main/resources. I don't think this is in the classpath, but the build will then copy the file into ./target/classes/ which is in the classpath.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "Issue 2 above shows up as:[\n]"
http-outgoing-3 >> "<pre><code>[\n]"
http-outgoing-3 >> "Failed to detect a valid hadoop home directory[\n]"
http-outgoing-3 >> "java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.[\n]"
http-outgoing-3 >> "</code></pre>[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "This is fixed by going into the project properties => Build => Actions => Run Project and adding the environmen[\r][\n]"
http-outgoing-3 >> "1000[\r][\n]"
http-outgoing-3 >> "t variable for HADOOP_HOME. This will result in an entry in the Maven POM. Repeat for "Test Project", "Debug Project" etc.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "Issue 3. shows up as running, but creating a file on the local file system instead of the HDFS. This was fixed       looking at the HDFS API documentation for org.apache.hadoop.conf.Configuration. This documentation is under the chapter: C API libhdfs HDFS which has a link to the HDFS API under "The APIs" (I strangely cannot find this in the main index). On my installation the HDFS API documentation link is file:///opt/local/hadoop-2.7.0/share/doc/hadoop/api/org/apache/hadoop/fs/FileSystem.html.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "This documentation told me that hadoop loads core-site.xml and core-default.xml in the classpath. Classpath for a Maven build can be reached by placing these files in the directory src/main/resources (see logging configuration above). I added hdfs-site instead of core-default (which doesn't exist on my 2.7 install) into the src/main/resources project directory.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "Issue 3 shows up as:[\n]"
http-outgoing-3 >> "<pre><code>[\n]"
http-outgoing-3 >> "java.io.IOException: "hadoop No FileSystem for scheme: hdfs".[\n]"
http-outgoing-3 >> "</code></pre>[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "This is part of the build dependency problem. The various threads on stackoverflow etc. suggested that a minimum dependency was the jar for hadoop-core. However, there is no such jar on 2.7. I ran the hadoop command to dump version and got this:[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "<pre><code>[\n]"
http-outgoing-3 >> "bin/hadoop version[\n]"
http-outgoing-3 >> "Hadoop 2.7.0[\n]"
http-outgoing-3 >> "Subversion https://git-wip-us.apache.org/repos/asf/hadoop.git -r d4c8d4d4d203c934e8074b31289a28724c0842cf[\n]"
http-outgoing-3 >> "Compiled by jenkins on 2015-04-10T18:40Z[\n]"
http-outgoing-3 >> "Compiled with protoc 2.5.0[\n]"
http-outgoing-3 >> "From source with checksum a9e90912c37a35c3195d23951fd18f[\n]"
http-outgoing-3 >> "This command was run using /opt/local/hadoop-2.7.0/share/hadoop/common/hadoop-common-2.7.0.jar[\n]"
http-outgoing-3 >> "</code></pre>[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "I noted the jar name at the end and added it as a dependency to the POM. This can either be hand coded in or right click pom.xml => Insert Code => Add Dependency => Search => query hadoop-common and select version which was 2.7.0 [jar] - central. Maven will then add dependencies to other hadoop jars in the "Dependencies" group in the project explorer. Netbeans will then download these dependencies before the next build. They go into ~/.m2/repository should they ever need to be cleaned out (Netbeans doesn't seem to have an IDE remove dependency option).[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "After doing the above project built, but showed up the "no filesystem error". I noticed that Maven had not pulled in any hdfs jars matching the jars in my share/hadoop/hdfs installation directory. So I took a guess that it needed only the top level hadoop-hdfs-2.7.0.jar and added this as a dependency to the POM and all was good :)[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## Working through trouble shooting the Map Reduce project settings[\n]"
http-outgoing-3 >> "After getting the HDFS API working in the IDE it was time to move on to getting the famous Word Count map-reduce tutorial running.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "So coded it, set the main program to the word count main as the one to run. From the IDE: project Properties => Run => Main Class. Provide input and output arguments for the word count program. I noted that the netbeans properties pop-up window does not persist these settings next time it pops up. However this setting is persistant and ends up in nbactions.xml.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "However, running the word count map reduce program resulted in an ioException:[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "<pre><code>[\n]"
http-outgoing-3 >> "Please check your configuration for mapreduce.framework.name and the correspond server addresses.[\n]"
http-outgoing-3 >> "</pre></code>[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "Because the resources directory only contains 2 configuration files from my hadoop installation I thought maybe I was missing a map reduce one. So the first thing I did was go into the configuration directory of my installation and grep all files to see if there was a configuration file with mapreduce framework property. There was not. I checked my programatic configuration dump from my test program. This property was not mentioned either. The only map reduce configuration was to do with some environment variables for heap size in one of the shell scripts. Note to self: this may be relevant and I can consider setting this in the IDE. However, that didn't look like the problem.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "I then chec[\r][\n]"
http-outgoing-3 >> "a93[\r][\n]"
http-outgoing-3 >> "ked my dependencies and noted there were no map reduce jars pulled in by Maven. So I added hadoop-mapreduce-client-core. Still not running. Checked the web and a thread on stackoverflow mentioned a number of other jars: hadoop-mapreduce-client-common and hadoop-mapreduce-client shuffle. I added just the hadoop-mapreduce-client-common and it runs :) I have a feeling that I might need some of the other jars for other API calls and that there must be a better way of working out dependencies than this trial and error. As mentioned I am a newbie with this, so if anyone has any comments feel free to email me.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## Logging from application code[\n]"
http-outgoing-3 >> "Although the hadoop libraries log correctly with a properly located log4.properties file, application code calling the log4j logger seems to ignore this file. Using the log4j logger as per instructions in the log4j manual and many online tutorials did not result in getting any logging redirected to file configured in the properties file. Instead console output only is obtained. A clue to this mystery was that a most basic of hello world netbeans maven projects which did not import any hadoop stuff also failed to log to a file and did not even give the "No appenders" warning. Then I noticed that there were org.sl4j depencies in the hadoop build, so using sl4j instead solved the problem. Once my hello world project used sl4j's LoggerFactory and had sl4j-api and sl4j-12 as a dependencies it started to use the properties file. See http://www.slf4j.org/manual.html[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## Upload a file from local storage to the HDFS via the REST API[\n]"
http-outgoing-3 >> "The WebHDFS REST API documentation which came with the installation specifies that file creation is a two stage operation where an initial PUT to the namenode is sent. This responds with a redirect to the datanode and another PUT should be made to this redirection which can contain the chunked data stream. This does not sound REST to me as it relies on holding redirection state (a fully distributed configuration could presumably return a redirection to any one of the datanodes). Hadoop say this is because of a bug in some HTTP client implementations - incorrect implementation of [0xe2][0x80][0x9c]Expect: 100-continue[0xe2][0x80][0x9d].[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "However, the 2 stage PUT not being REST seems to be a moot point, at least with the Jersey client. I do not get a redirection and a file creates/uploads all in one go.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "Since writing the above paragraph I have implemented the Apache Client back end option to my HDFS Web client interface and this client behaves differently. It does indeed cause a redirect as per Hadoop documentation. The follow up PUT to the redirected location with the chunked file stream works as per documentation.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "To be continued ...[\n]"
http-outgoing-3 >> "[\r][\n]"
http-outgoing-3 >> "0[\r][\n]"
http-outgoing-3 >> "[\r][\n]"
http-outgoing-3 << "HTTP/1.1 307 TEMPORARY_REDIRECT[\r][\n]"
http-outgoing-3 << "Cache-Control: no-cache[\r][\n]"
http-outgoing-3 << "Expires: Sat, 13 Jun 2015 03:45:35 GMT[\r][\n]"
http-outgoing-3 << "Date: Sat, 13 Jun 2015 03:45:35 GMT[\r][\n]"
http-outgoing-3 << "Pragma: no-cache[\r][\n]"
http-outgoing-3 << "Expires: Sat, 13 Jun 2015 03:45:35 GMT[\r][\n]"
http-outgoing-3 << "Date: Sat, 13 Jun 2015 03:45:35 GMT[\r][\n]"
http-outgoing-3 << "Pragma: no-cache[\r][\n]"
http-outgoing-3 << "Content-Type: application/octet-stream[\r][\n]"
http-outgoing-3 << "Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434203135168&s=/hpR9x1b7T90vAC718EXz4F7qn0="; Path=/; Expires=Sat, 13-Jun-2015 13:45:35 GMT; HttpOnly[\r][\n]"
http-outgoing-3 << "Location: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/README.md?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true[\r][\n]"
http-outgoing-3 << "Content-Length: 0[\r][\n]"
http-outgoing-3 << "Server: Jetty(6.1.26)[\r][\n]"
http-outgoing-3 << "[\r][\n]"
http-outgoing-3 << HTTP/1.1 307 TEMPORARY_REDIRECT
http-outgoing-3 << Cache-Control: no-cache
http-outgoing-3 << Expires: Sat, 13 Jun 2015 03:45:35 GMT
http-outgoing-3 << Date: Sat, 13 Jun 2015 03:45:35 GMT
http-outgoing-3 << Pragma: no-cache
http-outgoing-3 << Expires: Sat, 13 Jun 2015 03:45:35 GMT
http-outgoing-3 << Date: Sat, 13 Jun 2015 03:45:35 GMT
http-outgoing-3 << Pragma: no-cache
http-outgoing-3 << Content-Type: application/octet-stream
http-outgoing-3 << Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434203135168&s=/hpR9x1b7T90vAC718EXz4F7qn0="; Path=/; Expires=Sat, 13-Jun-2015 13:45:35 GMT; HttpOnly
http-outgoing-3 << Location: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/README.md?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
http-outgoing-3 << Content-Length: 0
http-outgoing-3 << Server: Jetty(6.1.26)
Connection can be kept alive indefinitely
Cookie accepted [hadoop.auth=""u=michaeljones&p=michaeljones&t=simple&e=1434203135168&s=/hpR9x1b7T90vAC718EXz4F7qn0="", version:0, domain:localhost, path:/, expiry:Sat Jun 13 23:45:35 AEST 2015]
Redirect to: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/README.md?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
http-outgoing-3: Shutdown connection
Connection discarded
http-outgoing-3: Close connection
Connection released: [id: 3][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 4][route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://michaels-air.bigpond:50075
Connecting to michaels-air.bigpond/10.0.0.2:50075
Connection established 10.0.0.2:49781<->10.0.0.2:50075
Executing request PUT /webhdfs/v1/user/michaeljones/README.md?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-4 >> PUT /webhdfs/v1/user/michaeljones/README.md?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1
http-outgoing-4 >> Transfer-Encoding: chunked
http-outgoing-4 >> Content-Type: application/octet-stream
http-outgoing-4 >> Host: michaels-air.bigpond:50075
http-outgoing-4 >> Connection: Keep-Alive
http-outgoing-4 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-4 >> Accept-Encoding: gzip,deflate
http-outgoing-4 >> "PUT /webhdfs/v1/user/michaeljones/README.md?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1[\r][\n]"
http-outgoing-4 >> "Transfer-Encoding: chunked[\r][\n]"
http-outgoing-4 >> "Content-Type: application/octet-stream[\r][\n]"
http-outgoing-4 >> "Host: michaels-air.bigpond:50075[\r][\n]"
http-outgoing-4 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-4 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-4 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-4 >> "[\r][\n]"
http-outgoing-4 >> "1000[\r][\n]"
http-outgoing-4 >> "# Hello-Hadoop-netbeans-OS-X[\n]"
http-outgoing-4 >> "Java Maven project for playing with the HDFS API without any 3rd party hadoop plugins.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## Aim of project[\n]"
http-outgoing-4 >> "Hello world/tutorial level for programmatically operating with a pseudo distributed hadoop configuration on OS X. Hadoop 2.7 on Yosemite.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## What this project demonstrates[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "This is work in progress and so far the following functionality is demonstrated:[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "1. Direct programmatic control of the HDFS and running map reduce jobs - all unit tests run from the IDE with hadoop configuration built into this project and under git control.[\n]"
http-outgoing-4 >> "2. Uploading of files to the HDFS by implementing a Web REST API client.[\n]"
http-outgoing-4 >> "3. Layered application code for maximum re-use and ease of test driven development. The client I wrote uses an interface which has allowed me to provide both a Jersey HTTP client implementation and an Apache HTTP client implementation for comparison between the two toolkits.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "The initial difficulty was working out how to run the program in the IDE and talk to the local pseudo distributed setup without using a 3rd party Hadoop plugin. Apparently there used to be a plugin for netbeans, but it has been discontinued. I am a newbie with this technology.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "The Apache Hadoop instructions for building and running java programs are via their command line build/run utility only. Getting the yahoo hadoop HDFS tutorial program to build in the IDE wasn't too hard. However, by default it will ignore the local Hadoop configuration and only operate with the local file system in local debug mode.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## Wading through the configuration[\n]"
http-outgoing-4 >> "Hadoop is designed to work with a number of different topologies, directory locations, levels of replication, simulated environments etc. so as we would expect nothing works unless the configuration is right.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "First Hadoop needs to be installed and configured in pseudo distributed mode such that it builds and runs test programs on the command line. The hadoop documentation has instructions for doing this. Documentation is online and also included in the installation: share/doc/hadoop/index.html. However this is not enough to get it to work in the IDE.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## The netbeans project settings that are needed to run with the HDFS from the IDE:[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "1. Get log4j configured to work in the IDE. Absence of log4j configuration won't stop hadoop from running, but we won't get to see useful error messages from hadoop without it.[\n]"
http-outgoing-4 >> "2. HADOOP_HOME environment variable project run (and test) property.[\n]"
http-outgoing-4 >> "3. Duplicate hadoop configuration in the classpath. The above environment variable does not pick up the hadoop configuration from its usual place. Yahoo's only suggestion is to run from the command line via the hadoop script. The Apache HDFS API documention says that configuration is looked for in the classpath, so I took the approach of duplicating the configuration (just 2 files) instead of figuring out how to get it to look in the installation path.[\n]"
http-outgoing-4 >> "4. The correct Maven dependencies. If not all the jar depenencies are there the program may build and run, but it won't talk to the HDFS if it doesn't load the HDFS jars.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "I think that the setup of this project would probably work on Linux too.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## Working through trouble shooting the HDFS project settings[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "Issue 1 above shows up as:[\n]"
http-outgoing-4 >> "<pre><code>[\n]"
http-outgoing-4 >> "log4j:WARN No appenders could be found for logger (org.apache.hadoop.util.Shell).[\n]"
http-outgoing-4 >> "log4j:WARN Please initialize the log4j system properly.[\n]"
http-outgoing-4 >> "log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.[\n]"
http-outgoing-4 >> "</pre></code>[\n]"
http-outgoing-4 >> "This is solved by putting a log4j.properties configuration file in the classpath. For a Maven build getting files into the classpath can be achieved by putting them in src/main/resources. I don't think this is in the classpath, but the build will then copy the file into ./target/classes/ which is in the classpath.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "Issue 2 above shows up as:[\n]"
http-outgoing-4 >> "<pre><code>[\n]"
http-outgoing-4 >> "Failed to detect a valid hadoop home directory[\n]"
http-outgoing-4 >> "java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.[\n]"
http-outgoing-4 >> "</code></pre>[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "This is fixed by going into the project properties => Build => Actions => Run Project and adding the environmen[\r][\n]"
http-outgoing-4 >> "1000[\r][\n]"
http-outgoing-4 >> "t variable for HADOOP_HOME. This will result in an entry in the Maven POM. Repeat for "Test Project", "Debug Project" etc.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "Issue 3. shows up as running, but creating a file on the local file system instead of the HDFS. This was fixed       looking at the HDFS API documentation for org.apache.hadoop.conf.Configuration. This documentation is under the chapter: C API libhdfs HDFS which has a link to the HDFS API under "The APIs" (I strangely cannot find this in the main index). On my installation the HDFS API documentation link is file:///opt/local/hadoop-2.7.0/share/doc/hadoop/api/org/apache/hadoop/fs/FileSystem.html.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "This documentation told me that hadoop loads core-site.xml and core-default.xml in the classpath. Classpath for a Maven build can be reached by placing these files in the directory src/main/resources (see logging configuration above). I added hdfs-site instead of core-default (which doesn't exist on my 2.7 install) into the src/main/resources project directory.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "Issue 3 shows up as:[\n]"
http-outgoing-4 >> "<pre><code>[\n]"
http-outgoing-4 >> "java.io.IOException: "hadoop No FileSystem for scheme: hdfs".[\n]"
http-outgoing-4 >> "</code></pre>[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "This is part of the build dependency problem. The various threads on stackoverflow etc. suggested that a minimum dependency was the jar for hadoop-core. However, there is no such jar on 2.7. I ran the hadoop command to dump version and got this:[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "<pre><code>[\n]"
http-outgoing-4 >> "bin/hadoop version[\n]"
http-outgoing-4 >> "Hadoop 2.7.0[\n]"
http-outgoing-4 >> "Subversion https://git-wip-us.apache.org/repos/asf/hadoop.git -r d4c8d4d4d203c934e8074b31289a28724c0842cf[\n]"
http-outgoing-4 >> "Compiled by jenkins on 2015-04-10T18:40Z[\n]"
http-outgoing-4 >> "Compiled with protoc 2.5.0[\n]"
http-outgoing-4 >> "From source with checksum a9e90912c37a35c3195d23951fd18f[\n]"
http-outgoing-4 >> "This command was run using /opt/local/hadoop-2.7.0/share/hadoop/common/hadoop-common-2.7.0.jar[\n]"
http-outgoing-4 >> "</code></pre>[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "I noted the jar name at the end and added it as a dependency to the POM. This can either be hand coded in or right click pom.xml => Insert Code => Add Dependency => Search => query hadoop-common and select version which was 2.7.0 [jar] - central. Maven will then add dependencies to other hadoop jars in the "Dependencies" group in the project explorer. Netbeans will then download these dependencies before the next build. They go into ~/.m2/repository should they ever need to be cleaned out (Netbeans doesn't seem to have an IDE remove dependency option).[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "After doing the above project built, but showed up the "no filesystem error". I noticed that Maven had not pulled in any hdfs jars matching the jars in my share/hadoop/hdfs installation directory. So I took a guess that it needed only the top level hadoop-hdfs-2.7.0.jar and added this as a dependency to the POM and all was good :)[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## Working through trouble shooting the Map Reduce project settings[\n]"
http-outgoing-4 >> "After getting the HDFS API working in the IDE it was time to move on to getting the famous Word Count map-reduce tutorial running.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "So coded it, set the main program to the word count main as the one to run. From the IDE: project Properties => Run => Main Class. Provide input and output arguments for the word count program. I noted that the netbeans properties pop-up window does not persist these settings next time it pops up. However this setting is persistant and ends up in nbactions.xml.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "However, running the word count map reduce program resulted in an ioException:[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "<pre><code>[\n]"
http-outgoing-4 >> "Please check your configuration for mapreduce.framework.name and the correspond server addresses.[\n]"
http-outgoing-4 >> "</pre></code>[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "Because the resources directory only contains 2 configuration files from my hadoop installation I thought maybe I was missing a map reduce one. So the first thing I did was go into the configuration directory of my installation and grep all files to see if there was a configuration file with mapreduce framework property. There was not. I checked my programatic configuration dump from my test program. This property was not mentioned either. The only map reduce configuration was to do with some environment variables for heap size in one of the shell scripts. Note to self: this may be relevant and I can consider setting this in the IDE. However, that didn't look like the problem.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "I then chec[\r][\n]"
http-outgoing-4 >> "a93[\r][\n]"
http-outgoing-4 >> "ked my dependencies and noted there were no map reduce jars pulled in by Maven. So I added hadoop-mapreduce-client-core. Still not running. Checked the web and a thread on stackoverflow mentioned a number of other jars: hadoop-mapreduce-client-common and hadoop-mapreduce-client shuffle. I added just the hadoop-mapreduce-client-common and it runs :) I have a feeling that I might need some of the other jars for other API calls and that there must be a better way of working out dependencies than this trial and error. As mentioned I am a newbie with this, so if anyone has any comments feel free to email me.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## Logging from application code[\n]"
http-outgoing-4 >> "Although the hadoop libraries log correctly with a properly located log4.properties file, application code calling the log4j logger seems to ignore this file. Using the log4j logger as per instructions in the log4j manual and many online tutorials did not result in getting any logging redirected to file configured in the properties file. Instead console output only is obtained. A clue to this mystery was that a most basic of hello world netbeans maven projects which did not import any hadoop stuff also failed to log to a file and did not even give the "No appenders" warning. Then I noticed that there were org.sl4j depencies in the hadoop build, so using sl4j instead solved the problem. Once my hello world project used sl4j's LoggerFactory and had sl4j-api and sl4j-12 as a dependencies it started to use the properties file. See http://www.slf4j.org/manual.html[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## Upload a file from local storage to the HDFS via the REST API[\n]"
http-outgoing-4 >> "The WebHDFS REST API documentation which came with the installation specifies that file creation is a two stage operation where an initial PUT to the namenode is sent. This responds with a redirect to the datanode and another PUT should be made to this redirection which can contain the chunked data stream. This does not sound REST to me as it relies on holding redirection state (a fully distributed configuration could presumably return a redirection to any one of the datanodes). Hadoop say this is because of a bug in some HTTP client implementations - incorrect implementation of [0xe2][0x80][0x9c]Expect: 100-continue[0xe2][0x80][0x9d].[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "However, the 2 stage PUT not being REST seems to be a moot point, at least with the Jersey client. I do not get a redirection and a file creates/uploads all in one go.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "Since writing the above paragraph I have implemented the Apache Client back end option to my HDFS Web client interface and this client behaves differently. It does indeed cause a redirect as per Hadoop documentation. The follow up PUT to the redirected location with the chunked file stream works as per documentation.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "To be continued ...[\n]"
http-outgoing-4 >> "[\r][\n]"
http-outgoing-4 >> "0[\r][\n]"
http-outgoing-4 >> "[\r][\n]"
http-outgoing-4 << "HTTP/1.1 100 Continue[\r][\n]"
http-outgoing-4 << "[\r][\n]"
http-outgoing-4 << HTTP/1.1 100 Continue
http-outgoing-4 << "HTTP/1.1 201 Created[\r][\n]"
http-outgoing-4 << "Location: hdfs://localhost:9000/user/michaeljones/README.md[\r][\n]"
http-outgoing-4 << "Content-Length: 0[\r][\n]"
http-outgoing-4 << "Connection: close[\r][\n]"
http-outgoing-4 << "[\r][\n]"
http-outgoing-4 << HTTP/1.1 201 Created
http-outgoing-4 << Location: hdfs://localhost:9000/user/michaeljones/README.md
http-outgoing-4 << Content-Length: 0
http-outgoing-4 << Connection: close
http-outgoing-4: Shutdown connection
Connection discarded
http-outgoing-4: Close connection
Connection released: [id: 4][route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection manager is shutting down
Connection manager shut down
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 0][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://localhost:50070
Connecting to localhost/127.0.0.1:50070
Connection established 127.0.0.1:49793<->127.0.0.1:50070
Executing request GET /webhdfs/v1/user/michaeljones/?user.name=michaeljones&op=LISTSTATUS HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-0 >> GET /webhdfs/v1/user/michaeljones/?user.name=michaeljones&op=LISTSTATUS HTTP/1.1
http-outgoing-0 >> accept: application/json
http-outgoing-0 >> Host: localhost:50070
http-outgoing-0 >> Connection: Keep-Alive
http-outgoing-0 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-0 >> Accept-Encoding: gzip,deflate
http-outgoing-0 >> "GET /webhdfs/v1/user/michaeljones/?user.name=michaeljones&op=LISTSTATUS HTTP/1.1[\r][\n]"
http-outgoing-0 >> "accept: application/json[\r][\n]"
http-outgoing-0 >> "Host: localhost:50070[\r][\n]"
http-outgoing-0 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-0 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-0 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-0 >> "[\r][\n]"
http-outgoing-0 << "HTTP/1.1 200 OK[\r][\n]"
http-outgoing-0 << "Cache-Control: no-cache[\r][\n]"
http-outgoing-0 << "Expires: Sat, 13 Jun 2015 03:47:13 GMT[\r][\n]"
http-outgoing-0 << "Date: Sat, 13 Jun 2015 03:47:13 GMT[\r][\n]"
http-outgoing-0 << "Pragma: no-cache[\r][\n]"
http-outgoing-0 << "Expires: Sat, 13 Jun 2015 03:47:13 GMT[\r][\n]"
http-outgoing-0 << "Date: Sat, 13 Jun 2015 03:47:13 GMT[\r][\n]"
http-outgoing-0 << "Pragma: no-cache[\r][\n]"
http-outgoing-0 << "Content-Type: application/json[\r][\n]"
http-outgoing-0 << "Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434203233342&s=zqtLl5jsI7hVxxl4Zuc77b43s+Y="; Path=/; Expires=Sat, 13-Jun-2015 13:47:13 GMT; HttpOnly[\r][\n]"
http-outgoing-0 << "Transfer-Encoding: chunked[\r][\n]"
http-outgoing-0 << "Server: Jetty(6.1.26)[\r][\n]"
http-outgoing-0 << "[\r][\n]"
http-outgoing-0 << "FB4[\r][\n]"
http-outgoing-0 << "{"FileStatuses":{"FileStatus":[[\n]"
http-outgoing-0 << "{"accessTime":1434167135219,"blockSize":134217728,"childrenNum":0,"fileId":18501,"group":"supergroup","length":10899,"modificationTime":1434167135244,"owner":"michaeljones","pathSuffix":"README.md","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434159020549,"blockSize":134217728,"childrenNum":0,"fileId":18464,"group":"supergroup","length":0,"modificationTime":1434159020554,"owner":"michaeljones","pathSuffix":"apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434159021414,"blockSize":134217728,"childrenNum":0,"fileId":18467,"group":"supergroup","length":0,"modificationTime":1434159021420,"owner":"michaeljones","pathSuffix":"empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434167134617,"blockSize":134217728,"childrenNum":0,"fileId":18498,"group":"supergroup","length":0,"modificationTime":1434167134624,"owner":"michaeljones","pathSuffix":"hello-apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434091626279,"blockSize":134217728,"childrenNum":0,"fileId":18298,"group":"supergroup","length":0,"modificationTime":1434091626286,"owner":"michaeljones","pathSuffix":"hello-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434167134541,"blockSize":134217728,"childrenNum":0,"fileId":18497,"group":"supergroup","length":0,"modificationTime":1434167134547,"owner":"michaeljones","pathSuffix":"hello-jersey-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434159021522,"blockSize":134217728,"childrenNum":0,"fileId":18468,"group":"supergroup","length":869081,"modificationTime":1434159021575,"owner":"michaeljones","pathSuffix":"hello.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434167134954,"blockSize":134217728,"childrenNum":0,"fileId":18500,"group":"supergroup","length":3678856,"modificationTime":1434167135117,"owner":"michaeljones","pathSuffix":"hello.log.2015-06-12","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434159013887,"blockSize":134217728,"childrenNum":0,"fileId":18442,"group":"supergroup","length":20,"modificationTime":1434159014350,"owner":"michaeljones","pathSuffix":"hello.txt","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434167134837,"blockSize":134217728,"childrenNum":0,"fileId":18499,"group":"supergroup","length":62912,"modificationTime":1434167134868,"owner":"michaeljones","pathSuffix":"hellohadoop.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434159020604,"blockSize":134217728,"childrenNum":0,"fileId":18465,"group":"supergroup","length":2134,"modificationTime":1434159020632,"owner":"michaeljones","pathSuffix":"pom.xml","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434159014921,"blockSize":134217728,"childrenNum":0,"fileId":16388,"group":"supergroup","length":50,"modificationTime":1433119638967,"owner":"michaeljones","pathSuffix":"wcInput","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18443,"group":"supergroup","length":0,"modificationTime":1434159016805,"owner":"michaeljones","pathSuffix":"wcOutput","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},[\n]"
http-outgoing-0 << "{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18450,"group":"supergroup","length":0,"modificationTime":1434159017973,"owner":"michaeljones","pathSuffix":"wcOutputAnalysis","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},[\n]"
http-outgoing-0 << "{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18457,"group":"supergroup","length":0,"modificationTime":1434159019678,"owner":"michaeljones","pathSuffix":"wcOutputMain","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"}[\n]"
http-outgoing-0 << "]}}[\n]"
http-outgoing-0 << "[\r][\n]"
http-outgoing-0 << "0[\r][\n]"
http-outgoing-0 << "[\r][\n]"
http-outgoing-0 << HTTP/1.1 200 OK
http-outgoing-0 << Cache-Control: no-cache
http-outgoing-0 << Expires: Sat, 13 Jun 2015 03:47:13 GMT
http-outgoing-0 << Date: Sat, 13 Jun 2015 03:47:13 GMT
http-outgoing-0 << Pragma: no-cache
http-outgoing-0 << Expires: Sat, 13 Jun 2015 03:47:13 GMT
http-outgoing-0 << Date: Sat, 13 Jun 2015 03:47:13 GMT
http-outgoing-0 << Pragma: no-cache
http-outgoing-0 << Content-Type: application/json
http-outgoing-0 << Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434203233342&s=zqtLl5jsI7hVxxl4Zuc77b43s+Y="; Path=/; Expires=Sat, 13-Jun-2015 13:47:13 GMT; HttpOnly
http-outgoing-0 << Transfer-Encoding: chunked
http-outgoing-0 << Server: Jetty(6.1.26)
Connection can be kept alive indefinitely
Cookie accepted [hadoop.auth=""u=michaeljones&p=michaeljones&t=simple&e=1434203233342&s=zqtLl5jsI7hVxxl4Zuc77b43s+Y="", version:0, domain:localhost, path:/, expiry:Sat Jun 13 23:47:13 AEST 2015]
Connection [id: 0][route: {}->http://localhost:50070] can be kept alive indefinitely
Connection released: [id: 0][route: {}->http://localhost:50070][total kept alive: 1; route allocated: 1 of 2; total allocated: 1 of 20]
Connection manager is shutting down
http-outgoing-0: Close connection
http-outgoing-0: Close connection
Connection manager shut down
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 1][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://localhost:50070
Connecting to localhost/127.0.0.1:50070
Connection established 127.0.0.1:49796<->127.0.0.1:50070
Executing request PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-1 >> PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1
http-outgoing-1 >> Content-Length: 0
http-outgoing-1 >> Host: localhost:50070
http-outgoing-1 >> Connection: Keep-Alive
http-outgoing-1 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-1 >> Accept-Encoding: gzip,deflate
http-outgoing-1 >> "PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1[\r][\n]"
http-outgoing-1 >> "Content-Length: 0[\r][\n]"
http-outgoing-1 >> "Host: localhost:50070[\r][\n]"
http-outgoing-1 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-1 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-1 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-1 >> "[\r][\n]"
http-outgoing-1 << "HTTP/1.1 307 TEMPORARY_REDIRECT[\r][\n]"
http-outgoing-1 << "Cache-Control: no-cache[\r][\n]"
http-outgoing-1 << "Expires: Sat, 13 Jun 2015 03:47:13 GMT[\r][\n]"
http-outgoing-1 << "Date: Sat, 13 Jun 2015 03:47:13 GMT[\r][\n]"
http-outgoing-1 << "Pragma: no-cache[\r][\n]"
http-outgoing-1 << "Expires: Sat, 13 Jun 2015 03:47:13 GMT[\r][\n]"
http-outgoing-1 << "Date: Sat, 13 Jun 2015 03:47:13 GMT[\r][\n]"
http-outgoing-1 << "Pragma: no-cache[\r][\n]"
http-outgoing-1 << "Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434203233747&s=rTREWmNkmuf1Qb/wutDteo1fACA="; Path=/; Expires=Sat, 13-Jun-2015 13:47:13 GMT; HttpOnly[\r][\n]"
http-outgoing-1 << "Location: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true[\r][\n]"
http-outgoing-1 << "Content-Type: application/octet-stream[\r][\n]"
http-outgoing-1 << "Content-Length: 0[\r][\n]"
http-outgoing-1 << "Server: Jetty(6.1.26)[\r][\n]"
http-outgoing-1 << "[\r][\n]"
http-outgoing-1 << HTTP/1.1 307 TEMPORARY_REDIRECT
http-outgoing-1 << Cache-Control: no-cache
http-outgoing-1 << Expires: Sat, 13 Jun 2015 03:47:13 GMT
http-outgoing-1 << Date: Sat, 13 Jun 2015 03:47:13 GMT
http-outgoing-1 << Pragma: no-cache
http-outgoing-1 << Expires: Sat, 13 Jun 2015 03:47:13 GMT
http-outgoing-1 << Date: Sat, 13 Jun 2015 03:47:13 GMT
http-outgoing-1 << Pragma: no-cache
http-outgoing-1 << Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434203233747&s=rTREWmNkmuf1Qb/wutDteo1fACA="; Path=/; Expires=Sat, 13-Jun-2015 13:47:13 GMT; HttpOnly
http-outgoing-1 << Location: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
http-outgoing-1 << Content-Type: application/octet-stream
http-outgoing-1 << Content-Length: 0
http-outgoing-1 << Server: Jetty(6.1.26)
Connection can be kept alive indefinitely
Cookie accepted [hadoop.auth=""u=michaeljones&p=michaeljones&t=simple&e=1434203233747&s=rTREWmNkmuf1Qb/wutDteo1fACA="", version:0, domain:localhost, path:/, expiry:Sat Jun 13 23:47:13 AEST 2015]
Redirect to: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
http-outgoing-1: Shutdown connection
Connection discarded
http-outgoing-1: Close connection
Connection released: [id: 1][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 2][route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://michaels-air.bigpond:50075
Connecting to michaels-air.bigpond/10.0.0.2:50075
Connection established 10.0.0.2:49797<->10.0.0.2:50075
Executing request PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-2 >> PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1
http-outgoing-2 >> Content-Length: 0
http-outgoing-2 >> Host: michaels-air.bigpond:50075
http-outgoing-2 >> Connection: Keep-Alive
http-outgoing-2 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-2 >> Accept-Encoding: gzip,deflate
http-outgoing-2 >> "PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1[\r][\n]"
http-outgoing-2 >> "Content-Length: 0[\r][\n]"
http-outgoing-2 >> "Host: michaels-air.bigpond:50075[\r][\n]"
http-outgoing-2 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-2 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-2 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-2 >> "[\r][\n]"
http-outgoing-2 << "HTTP/1.1 100 Continue[\r][\n]"
http-outgoing-2 << "[\r][\n]"
http-outgoing-2 << HTTP/1.1 100 Continue
http-outgoing-2 << "HTTP/1.1 201 Created[\r][\n]"
http-outgoing-2 << "Location: hdfs://localhost:9000/user/michaeljones/hello-apache-empty.txt[\r][\n]"
http-outgoing-2 << "Content-Length: 0[\r][\n]"
http-outgoing-2 << "Connection: close[\r][\n]"
http-outgoing-2 << "[\r][\n]"
http-outgoing-2 << HTTP/1.1 201 Created
http-outgoing-2 << Location: hdfs://localhost:9000/user/michaeljones/hello-apache-empty.txt
http-outgoing-2 << Content-Length: 0
http-outgoing-2 << Connection: close
http-outgoing-2: Shutdown connection
Connection discarded
http-outgoing-2: Close connection
Connection released: [id: 2][route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection manager is shutting down
Connection manager shut down
Jersey client Redirect to: hdfs://localhost:9000/user/michaeljones/hellohadoop.log
com.sun.jersey.client.property.chunkedEncodingSize: 1048576
Jersey client Redirect to: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/hello.log.2015-06-12?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 3][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://localhost:50070
Connecting to localhost/127.0.0.1:50070
Connection established 127.0.0.1:49807<->127.0.0.1:50070
Executing request PUT /webhdfs/v1/user/michaeljones/README.md?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-3 >> PUT /webhdfs/v1/user/michaeljones/README.md?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1
http-outgoing-3 >> Transfer-Encoding: chunked
http-outgoing-3 >> Content-Type: application/octet-stream
http-outgoing-3 >> Host: localhost:50070
http-outgoing-3 >> Connection: Keep-Alive
http-outgoing-3 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-3 >> Accept-Encoding: gzip,deflate
http-outgoing-3 >> "PUT /webhdfs/v1/user/michaeljones/README.md?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1[\r][\n]"
http-outgoing-3 >> "Transfer-Encoding: chunked[\r][\n]"
http-outgoing-3 >> "Content-Type: application/octet-stream[\r][\n]"
http-outgoing-3 >> "Host: localhost:50070[\r][\n]"
http-outgoing-3 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-3 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-3 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-3 >> "[\r][\n]"
http-outgoing-3 >> "1000[\r][\n]"
http-outgoing-3 >> "# Hello-Hadoop-netbeans-OS-X[\n]"
http-outgoing-3 >> "Java Maven project for playing with the HDFS API without any 3rd party hadoop plugins.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## Aim of project[\n]"
http-outgoing-3 >> "Hello world/tutorial level for programmatically operating with a pseudo distributed hadoop configuration on OS X. Hadoop 2.7 on Yosemite.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## What this project demonstrates[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "This is work in progress and so far the following functionality is demonstrated:[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "1. Direct programmatic control of the HDFS and running map reduce jobs - all unit tests run from the IDE with hadoop configuration built into this project and under git control.[\n]"
http-outgoing-3 >> "2. Uploading of files to the HDFS by implementing a Web REST API client.[\n]"
http-outgoing-3 >> "3. Layered application code for maximum re-use and ease of test driven development. The client I wrote uses an interface which has allowed me to provide both a Jersey HTTP client implementation and an Apache HTTP client implementation for comparison between the two toolkits.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "The initial difficulty was working out how to run the program in the IDE and talk to the local pseudo distributed setup without using a 3rd party Hadoop plugin. Apparently there used to be a plugin for netbeans, but it has been discontinued. I am a newbie with this technology.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "The Apache Hadoop instructions for building and running java programs are via their command line build/run utility only. Getting the yahoo hadoop HDFS tutorial program to build in the IDE wasn't too hard. However, by default it will ignore the local Hadoop configuration and only operate with the local file system in local debug mode.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## Wading through the configuration[\n]"
http-outgoing-3 >> "Hadoop is designed to work with a number of different topologies, directory locations, levels of replication, simulated environments etc. so as we would expect nothing works unless the configuration is right.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "First Hadoop needs to be installed and configured in pseudo distributed mode such that it builds and runs test programs on the command line. The hadoop documentation has instructions for doing this. Documentation is online and also included in the installation: share/doc/hadoop/index.html. However this is not enough to get it to work in the IDE.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## The netbeans project settings that are needed to run with the HDFS from the IDE:[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "1. Get log4j configured to work in the IDE. Absence of log4j configuration won't stop hadoop from running, but we won't get to see useful error messages from hadoop without it.[\n]"
http-outgoing-3 >> "2. HADOOP_HOME environment variable project run (and test) property.[\n]"
http-outgoing-3 >> "3. Duplicate hadoop configuration in the classpath. The above environment variable does not pick up the hadoop configuration from its usual place. Yahoo's only suggestion is to run from the command line via the hadoop script. The Apache HDFS API documention says that configuration is looked for in the classpath, so I took the approach of duplicating the configuration (just 2 files) instead of figuring out how to get it to look in the installation path.[\n]"
http-outgoing-3 >> "4. The correct Maven dependencies. If not all the jar depenencies are there the program may build and run, but it won't talk to the HDFS if it doesn't load the HDFS jars.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "I think that the setup of this project would probably work on Linux too.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## Working through trouble shooting the HDFS project settings[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "Issue 1 above shows up as:[\n]"
http-outgoing-3 >> "<pre><code>[\n]"
http-outgoing-3 >> "log4j:WARN No appenders could be found for logger (org.apache.hadoop.util.Shell).[\n]"
http-outgoing-3 >> "log4j:WARN Please initialize the log4j system properly.[\n]"
http-outgoing-3 >> "log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.[\n]"
http-outgoing-3 >> "</pre></code>[\n]"
http-outgoing-3 >> "This is solved by putting a log4j.properties configuration file in the classpath. For a Maven build getting files into the classpath can be achieved by putting them in src/main/resources. I don't think this is in the classpath, but the build will then copy the file into ./target/classes/ which is in the classpath.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "Issue 2 above shows up as:[\n]"
http-outgoing-3 >> "<pre><code>[\n]"
http-outgoing-3 >> "Failed to detect a valid hadoop home directory[\n]"
http-outgoing-3 >> "java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.[\n]"
http-outgoing-3 >> "</code></pre>[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "This is fixed by going into the project properties => Build => Actions => Run Project and adding the environmen[\r][\n]"
http-outgoing-3 >> "1000[\r][\n]"
http-outgoing-3 >> "t variable for HADOOP_HOME. This will result in an entry in the Maven POM. Repeat for "Test Project", "Debug Project" etc.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "Issue 3. shows up as running, but creating a file on the local file system instead of the HDFS. This was fixed       looking at the HDFS API documentation for org.apache.hadoop.conf.Configuration. This documentation is under the chapter: C API libhdfs HDFS which has a link to the HDFS API under "The APIs" (I strangely cannot find this in the main index). On my installation the HDFS API documentation link is file:///opt/local/hadoop-2.7.0/share/doc/hadoop/api/org/apache/hadoop/fs/FileSystem.html.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "This documentation told me that hadoop loads core-site.xml and core-default.xml in the classpath. Classpath for a Maven build can be reached by placing these files in the directory src/main/resources (see logging configuration above). I added hdfs-site instead of core-default (which doesn't exist on my 2.7 install) into the src/main/resources project directory.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "Issue 3 shows up as:[\n]"
http-outgoing-3 >> "<pre><code>[\n]"
http-outgoing-3 >> "java.io.IOException: "hadoop No FileSystem for scheme: hdfs".[\n]"
http-outgoing-3 >> "</code></pre>[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "This is part of the build dependency problem. The various threads on stackoverflow etc. suggested that a minimum dependency was the jar for hadoop-core. However, there is no such jar on 2.7. I ran the hadoop command to dump version and got this:[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "<pre><code>[\n]"
http-outgoing-3 >> "bin/hadoop version[\n]"
http-outgoing-3 >> "Hadoop 2.7.0[\n]"
http-outgoing-3 >> "Subversion https://git-wip-us.apache.org/repos/asf/hadoop.git -r d4c8d4d4d203c934e8074b31289a28724c0842cf[\n]"
http-outgoing-3 >> "Compiled by jenkins on 2015-04-10T18:40Z[\n]"
http-outgoing-3 >> "Compiled with protoc 2.5.0[\n]"
http-outgoing-3 >> "From source with checksum a9e90912c37a35c3195d23951fd18f[\n]"
http-outgoing-3 >> "This command was run using /opt/local/hadoop-2.7.0/share/hadoop/common/hadoop-common-2.7.0.jar[\n]"
http-outgoing-3 >> "</code></pre>[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "I noted the jar name at the end and added it as a dependency to the POM. This can either be hand coded in or right click pom.xml => Insert Code => Add Dependency => Search => query hadoop-common and select version which was 2.7.0 [jar] - central. Maven will then add dependencies to other hadoop jars in the "Dependencies" group in the project explorer. Netbeans will then download these dependencies before the next build. They go into ~/.m2/repository should they ever need to be cleaned out (Netbeans doesn't seem to have an IDE remove dependency option).[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "After doing the above project built, but showed up the "no filesystem error". I noticed that Maven had not pulled in any hdfs jars matching the jars in my share/hadoop/hdfs installation directory. So I took a guess that it needed only the top level hadoop-hdfs-2.7.0.jar and added this as a dependency to the POM and all was good :)[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## Working through trouble shooting the Map Reduce project settings[\n]"
http-outgoing-3 >> "After getting the HDFS API working in the IDE it was time to move on to getting the famous Word Count map-reduce tutorial running.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "So coded it, set the main program to the word count main as the one to run. From the IDE: project Properties => Run => Main Class. Provide input and output arguments for the word count program. I noted that the netbeans properties pop-up window does not persist these settings next time it pops up. However this setting is persistant and ends up in nbactions.xml.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "However, running the word count map reduce program resulted in an ioException:[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "<pre><code>[\n]"
http-outgoing-3 >> "Please check your configuration for mapreduce.framework.name and the correspond server addresses.[\n]"
http-outgoing-3 >> "</pre></code>[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "Because the resources directory only contains 2 configuration files from my hadoop installation I thought maybe I was missing a map reduce one. So the first thing I did was go into the configuration directory of my installation and grep all files to see if there was a configuration file with mapreduce framework property. There was not. I checked my programatic configuration dump from my test program. This property was not mentioned either. The only map reduce configuration was to do with some environment variables for heap size in one of the shell scripts. Note to self: this may be relevant and I can consider setting this in the IDE. However, that didn't look like the problem.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "I then chec[\r][\n]"
http-outgoing-3 >> "a93[\r][\n]"
http-outgoing-3 >> "ked my dependencies and noted there were no map reduce jars pulled in by Maven. So I added hadoop-mapreduce-client-core. Still not running. Checked the web and a thread on stackoverflow mentioned a number of other jars: hadoop-mapreduce-client-common and hadoop-mapreduce-client shuffle. I added just the hadoop-mapreduce-client-common and it runs :) I have a feeling that I might need some of the other jars for other API calls and that there must be a better way of working out dependencies than this trial and error. As mentioned I am a newbie with this, so if anyone has any comments feel free to email me.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## Logging from application code[\n]"
http-outgoing-3 >> "Although the hadoop libraries log correctly with a properly located log4.properties file, application code calling the log4j logger seems to ignore this file. Using the log4j logger as per instructions in the log4j manual and many online tutorials did not result in getting any logging redirected to file configured in the properties file. Instead console output only is obtained. A clue to this mystery was that a most basic of hello world netbeans maven projects which did not import any hadoop stuff also failed to log to a file and did not even give the "No appenders" warning. Then I noticed that there were org.sl4j depencies in the hadoop build, so using sl4j instead solved the problem. Once my hello world project used sl4j's LoggerFactory and had sl4j-api and sl4j-12 as a dependencies it started to use the properties file. See http://www.slf4j.org/manual.html[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## Upload a file from local storage to the HDFS via the REST API[\n]"
http-outgoing-3 >> "The WebHDFS REST API documentation which came with the installation specifies that file creation is a two stage operation where an initial PUT to the namenode is sent. This responds with a redirect to the datanode and another PUT should be made to this redirection which can contain the chunked data stream. This does not sound REST to me as it relies on holding redirection state (a fully distributed configuration could presumably return a redirection to any one of the datanodes). Hadoop say this is because of a bug in some HTTP client implementations - incorrect implementation of [0xe2][0x80][0x9c]Expect: 100-continue[0xe2][0x80][0x9d].[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "However, the 2 stage PUT not being REST seems to be a moot point, at least with the Jersey client. I do not get a redirection and a file creates/uploads all in one go.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "Since writing the above paragraph I have implemented the Apache Client back end option to my HDFS Web client interface and this client behaves differently. It does indeed cause a redirect as per Hadoop documentation. The follow up PUT to the redirected location with the chunked file stream works as per documentation.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "To be continued ...[\n]"
http-outgoing-3 >> "[\r][\n]"
http-outgoing-3 >> "0[\r][\n]"
http-outgoing-3 >> "[\r][\n]"
http-outgoing-3 << "HTTP/1.1 307 TEMPORARY_REDIRECT[\r][\n]"
http-outgoing-3 << "Cache-Control: no-cache[\r][\n]"
http-outgoing-3 << "Expires: Sat, 13 Jun 2015 03:47:14 GMT[\r][\n]"
http-outgoing-3 << "Date: Sat, 13 Jun 2015 03:47:14 GMT[\r][\n]"
http-outgoing-3 << "Pragma: no-cache[\r][\n]"
http-outgoing-3 << "Expires: Sat, 13 Jun 2015 03:47:14 GMT[\r][\n]"
http-outgoing-3 << "Date: Sat, 13 Jun 2015 03:47:14 GMT[\r][\n]"
http-outgoing-3 << "Pragma: no-cache[\r][\n]"
http-outgoing-3 << "Content-Type: application/octet-stream[\r][\n]"
http-outgoing-3 << "Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434203234282&s=21dl/D1xiP7oc4KSkKohoEqwZcM="; Path=/; Expires=Sat, 13-Jun-2015 13:47:14 GMT; HttpOnly[\r][\n]"
http-outgoing-3 << "Location: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/README.md?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true[\r][\n]"
http-outgoing-3 << "Content-Length: 0[\r][\n]"
http-outgoing-3 << "Server: Jetty(6.1.26)[\r][\n]"
http-outgoing-3 << "[\r][\n]"
http-outgoing-3 << HTTP/1.1 307 TEMPORARY_REDIRECT
http-outgoing-3 << Cache-Control: no-cache
http-outgoing-3 << Expires: Sat, 13 Jun 2015 03:47:14 GMT
http-outgoing-3 << Date: Sat, 13 Jun 2015 03:47:14 GMT
http-outgoing-3 << Pragma: no-cache
http-outgoing-3 << Expires: Sat, 13 Jun 2015 03:47:14 GMT
http-outgoing-3 << Date: Sat, 13 Jun 2015 03:47:14 GMT
http-outgoing-3 << Pragma: no-cache
http-outgoing-3 << Content-Type: application/octet-stream
http-outgoing-3 << Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434203234282&s=21dl/D1xiP7oc4KSkKohoEqwZcM="; Path=/; Expires=Sat, 13-Jun-2015 13:47:14 GMT; HttpOnly
http-outgoing-3 << Location: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/README.md?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
http-outgoing-3 << Content-Length: 0
http-outgoing-3 << Server: Jetty(6.1.26)
Connection can be kept alive indefinitely
Cookie accepted [hadoop.auth=""u=michaeljones&p=michaeljones&t=simple&e=1434203234282&s=21dl/D1xiP7oc4KSkKohoEqwZcM="", version:0, domain:localhost, path:/, expiry:Sat Jun 13 23:47:14 AEST 2015]
Redirect to: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/README.md?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
http-outgoing-3: Shutdown connection
Connection discarded
http-outgoing-3: Close connection
Connection released: [id: 3][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 4][route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://michaels-air.bigpond:50075
Connecting to michaels-air.bigpond/10.0.0.2:50075
Connection established 10.0.0.2:49808<->10.0.0.2:50075
Executing request PUT /webhdfs/v1/user/michaeljones/README.md?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-4 >> PUT /webhdfs/v1/user/michaeljones/README.md?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1
http-outgoing-4 >> Transfer-Encoding: chunked
http-outgoing-4 >> Content-Type: application/octet-stream
http-outgoing-4 >> Host: michaels-air.bigpond:50075
http-outgoing-4 >> Connection: Keep-Alive
http-outgoing-4 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-4 >> Accept-Encoding: gzip,deflate
http-outgoing-4 >> "PUT /webhdfs/v1/user/michaeljones/README.md?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1[\r][\n]"
http-outgoing-4 >> "Transfer-Encoding: chunked[\r][\n]"
http-outgoing-4 >> "Content-Type: application/octet-stream[\r][\n]"
http-outgoing-4 >> "Host: michaels-air.bigpond:50075[\r][\n]"
http-outgoing-4 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-4 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-4 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-4 >> "[\r][\n]"
http-outgoing-4 >> "1000[\r][\n]"
http-outgoing-4 >> "# Hello-Hadoop-netbeans-OS-X[\n]"
http-outgoing-4 >> "Java Maven project for playing with the HDFS API without any 3rd party hadoop plugins.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## Aim of project[\n]"
http-outgoing-4 >> "Hello world/tutorial level for programmatically operating with a pseudo distributed hadoop configuration on OS X. Hadoop 2.7 on Yosemite.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## What this project demonstrates[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "This is work in progress and so far the following functionality is demonstrated:[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "1. Direct programmatic control of the HDFS and running map reduce jobs - all unit tests run from the IDE with hadoop configuration built into this project and under git control.[\n]"
http-outgoing-4 >> "2. Uploading of files to the HDFS by implementing a Web REST API client.[\n]"
http-outgoing-4 >> "3. Layered application code for maximum re-use and ease of test driven development. The client I wrote uses an interface which has allowed me to provide both a Jersey HTTP client implementation and an Apache HTTP client implementation for comparison between the two toolkits.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "The initial difficulty was working out how to run the program in the IDE and talk to the local pseudo distributed setup without using a 3rd party Hadoop plugin. Apparently there used to be a plugin for netbeans, but it has been discontinued. I am a newbie with this technology.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "The Apache Hadoop instructions for building and running java programs are via their command line build/run utility only. Getting the yahoo hadoop HDFS tutorial program to build in the IDE wasn't too hard. However, by default it will ignore the local Hadoop configuration and only operate with the local file system in local debug mode.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## Wading through the configuration[\n]"
http-outgoing-4 >> "Hadoop is designed to work with a number of different topologies, directory locations, levels of replication, simulated environments etc. so as we would expect nothing works unless the configuration is right.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "First Hadoop needs to be installed and configured in pseudo distributed mode such that it builds and runs test programs on the command line. The hadoop documentation has instructions for doing this. Documentation is online and also included in the installation: share/doc/hadoop/index.html. However this is not enough to get it to work in the IDE.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## The netbeans project settings that are needed to run with the HDFS from the IDE:[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "1. Get log4j configured to work in the IDE. Absence of log4j configuration won't stop hadoop from running, but we won't get to see useful error messages from hadoop without it.[\n]"
http-outgoing-4 >> "2. HADOOP_HOME environment variable project run (and test) property.[\n]"
http-outgoing-4 >> "3. Duplicate hadoop configuration in the classpath. The above environment variable does not pick up the hadoop configuration from its usual place. Yahoo's only suggestion is to run from the command line via the hadoop script. The Apache HDFS API documention says that configuration is looked for in the classpath, so I took the approach of duplicating the configuration (just 2 files) instead of figuring out how to get it to look in the installation path.[\n]"
http-outgoing-4 >> "4. The correct Maven dependencies. If not all the jar depenencies are there the program may build and run, but it won't talk to the HDFS if it doesn't load the HDFS jars.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "I think that the setup of this project would probably work on Linux too.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## Working through trouble shooting the HDFS project settings[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "Issue 1 above shows up as:[\n]"
http-outgoing-4 >> "<pre><code>[\n]"
http-outgoing-4 >> "log4j:WARN No appenders could be found for logger (org.apache.hadoop.util.Shell).[\n]"
http-outgoing-4 >> "log4j:WARN Please initialize the log4j system properly.[\n]"
http-outgoing-4 >> "log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.[\n]"
http-outgoing-4 >> "</pre></code>[\n]"
http-outgoing-4 >> "This is solved by putting a log4j.properties configuration file in the classpath. For a Maven build getting files into the classpath can be achieved by putting them in src/main/resources. I don't think this is in the classpath, but the build will then copy the file into ./target/classes/ which is in the classpath.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "Issue 2 above shows up as:[\n]"
http-outgoing-4 >> "<pre><code>[\n]"
http-outgoing-4 >> "Failed to detect a valid hadoop home directory[\n]"
http-outgoing-4 >> "java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.[\n]"
http-outgoing-4 >> "</code></pre>[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "This is fixed by going into the project properties => Build => Actions => Run Project and adding the environmen[\r][\n]"
http-outgoing-4 >> "1000[\r][\n]"
http-outgoing-4 >> "t variable for HADOOP_HOME. This will result in an entry in the Maven POM. Repeat for "Test Project", "Debug Project" etc.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "Issue 3. shows up as running, but creating a file on the local file system instead of the HDFS. This was fixed       looking at the HDFS API documentation for org.apache.hadoop.conf.Configuration. This documentation is under the chapter: C API libhdfs HDFS which has a link to the HDFS API under "The APIs" (I strangely cannot find this in the main index). On my installation the HDFS API documentation link is file:///opt/local/hadoop-2.7.0/share/doc/hadoop/api/org/apache/hadoop/fs/FileSystem.html.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "This documentation told me that hadoop loads core-site.xml and core-default.xml in the classpath. Classpath for a Maven build can be reached by placing these files in the directory src/main/resources (see logging configuration above). I added hdfs-site instead of core-default (which doesn't exist on my 2.7 install) into the src/main/resources project directory.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "Issue 3 shows up as:[\n]"
http-outgoing-4 >> "<pre><code>[\n]"
http-outgoing-4 >> "java.io.IOException: "hadoop No FileSystem for scheme: hdfs".[\n]"
http-outgoing-4 >> "</code></pre>[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "This is part of the build dependency problem. The various threads on stackoverflow etc. suggested that a minimum dependency was the jar for hadoop-core. However, there is no such jar on 2.7. I ran the hadoop command to dump version and got this:[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "<pre><code>[\n]"
http-outgoing-4 >> "bin/hadoop version[\n]"
http-outgoing-4 >> "Hadoop 2.7.0[\n]"
http-outgoing-4 >> "Subversion https://git-wip-us.apache.org/repos/asf/hadoop.git -r d4c8d4d4d203c934e8074b31289a28724c0842cf[\n]"
http-outgoing-4 >> "Compiled by jenkins on 2015-04-10T18:40Z[\n]"
http-outgoing-4 >> "Compiled with protoc 2.5.0[\n]"
http-outgoing-4 >> "From source with checksum a9e90912c37a35c3195d23951fd18f[\n]"
http-outgoing-4 >> "This command was run using /opt/local/hadoop-2.7.0/share/hadoop/common/hadoop-common-2.7.0.jar[\n]"
http-outgoing-4 >> "</code></pre>[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "I noted the jar name at the end and added it as a dependency to the POM. This can either be hand coded in or right click pom.xml => Insert Code => Add Dependency => Search => query hadoop-common and select version which was 2.7.0 [jar] - central. Maven will then add dependencies to other hadoop jars in the "Dependencies" group in the project explorer. Netbeans will then download these dependencies before the next build. They go into ~/.m2/repository should they ever need to be cleaned out (Netbeans doesn't seem to have an IDE remove dependency option).[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "After doing the above project built, but showed up the "no filesystem error". I noticed that Maven had not pulled in any hdfs jars matching the jars in my share/hadoop/hdfs installation directory. So I took a guess that it needed only the top level hadoop-hdfs-2.7.0.jar and added this as a dependency to the POM and all was good :)[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## Working through trouble shooting the Map Reduce project settings[\n]"
http-outgoing-4 >> "After getting the HDFS API working in the IDE it was time to move on to getting the famous Word Count map-reduce tutorial running.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "So coded it, set the main program to the word count main as the one to run. From the IDE: project Properties => Run => Main Class. Provide input and output arguments for the word count program. I noted that the netbeans properties pop-up window does not persist these settings next time it pops up. However this setting is persistant and ends up in nbactions.xml.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "However, running the word count map reduce program resulted in an ioException:[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "<pre><code>[\n]"
http-outgoing-4 >> "Please check your configuration for mapreduce.framework.name and the correspond server addresses.[\n]"
http-outgoing-4 >> "</pre></code>[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "Because the resources directory only contains 2 configuration files from my hadoop installation I thought maybe I was missing a map reduce one. So the first thing I did was go into the configuration directory of my installation and grep all files to see if there was a configuration file with mapreduce framework property. There was not. I checked my programatic configuration dump from my test program. This property was not mentioned either. The only map reduce configuration was to do with some environment variables for heap size in one of the shell scripts. Note to self: this may be relevant and I can consider setting this in the IDE. However, that didn't look like the problem.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "I then chec[\r][\n]"
http-outgoing-4 >> "a93[\r][\n]"
http-outgoing-4 >> "ked my dependencies and noted there were no map reduce jars pulled in by Maven. So I added hadoop-mapreduce-client-core. Still not running. Checked the web and a thread on stackoverflow mentioned a number of other jars: hadoop-mapreduce-client-common and hadoop-mapreduce-client shuffle. I added just the hadoop-mapreduce-client-common and it runs :) I have a feeling that I might need some of the other jars for other API calls and that there must be a better way of working out dependencies than this trial and error. As mentioned I am a newbie with this, so if anyone has any comments feel free to email me.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## Logging from application code[\n]"
http-outgoing-4 >> "Although the hadoop libraries log correctly with a properly located log4.properties file, application code calling the log4j logger seems to ignore this file. Using the log4j logger as per instructions in the log4j manual and many online tutorials did not result in getting any logging redirected to file configured in the properties file. Instead console output only is obtained. A clue to this mystery was that a most basic of hello world netbeans maven projects which did not import any hadoop stuff also failed to log to a file and did not even give the "No appenders" warning. Then I noticed that there were org.sl4j depencies in the hadoop build, so using sl4j instead solved the problem. Once my hello world project used sl4j's LoggerFactory and had sl4j-api and sl4j-12 as a dependencies it started to use the properties file. See http://www.slf4j.org/manual.html[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## Upload a file from local storage to the HDFS via the REST API[\n]"
http-outgoing-4 >> "The WebHDFS REST API documentation which came with the installation specifies that file creation is a two stage operation where an initial PUT to the namenode is sent. This responds with a redirect to the datanode and another PUT should be made to this redirection which can contain the chunked data stream. This does not sound REST to me as it relies on holding redirection state (a fully distributed configuration could presumably return a redirection to any one of the datanodes). Hadoop say this is because of a bug in some HTTP client implementations - incorrect implementation of [0xe2][0x80][0x9c]Expect: 100-continue[0xe2][0x80][0x9d].[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "However, the 2 stage PUT not being REST seems to be a moot point, at least with the Jersey client. I do not get a redirection and a file creates/uploads all in one go.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "Since writing the above paragraph I have implemented the Apache Client back end option to my HDFS Web client interface and this client behaves differently. It does indeed cause a redirect as per Hadoop documentation. The follow up PUT to the redirected location with the chunked file stream works as per documentation.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "To be continued ...[\n]"
http-outgoing-4 >> "[\r][\n]"
http-outgoing-4 >> "0[\r][\n]"
http-outgoing-4 >> "[\r][\n]"
http-outgoing-4 << "HTTP/1.1 100 Continue[\r][\n]"
http-outgoing-4 << "[\r][\n]"
http-outgoing-4 << HTTP/1.1 100 Continue
http-outgoing-4 << "HTTP/1.1 201 Created[\r][\n]"
http-outgoing-4 << "Location: hdfs://localhost:9000/user/michaeljones/README.md[\r][\n]"
http-outgoing-4 << "Content-Length: 0[\r][\n]"
http-outgoing-4 << "Connection: close[\r][\n]"
http-outgoing-4 << "[\r][\n]"
http-outgoing-4 << HTTP/1.1 201 Created
http-outgoing-4 << Location: hdfs://localhost:9000/user/michaeljones/README.md
http-outgoing-4 << Content-Length: 0
http-outgoing-4 << Connection: close
http-outgoing-4: Shutdown connection
Connection discarded
http-outgoing-4: Close connection
Connection released: [id: 4][route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection manager is shutting down
Connection manager shut down
setsid is not available on this machine. So not using it.
setsid exited with exit code 0
field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName=Ops, always=false, about=, type=DEFAULT, value=[Rate of successful kerberos logins and latency (milliseconds)], valueName=Time)
field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName=Ops, always=false, about=, type=DEFAULT, value=[Rate of failed kerberos logins and latency (milliseconds)], valueName=Time)
field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName=Ops, always=false, about=, type=DEFAULT, value=[GetGroups], valueName=Time)
UgiMetrics, User and group related metrics
Kerberos krb5 configuration not found, setting default realm to empty
 Creating new Groups object
Trying to load the custom-built native-hadoop library...
Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
java.library.path=/Applications/NetBeans/NetBeans 8.0.2.app/Contents/Resources/NetBeans/webcommon/bin::/Users/michaeljones/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:.
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Falling back to shell based
Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
hadoop login
hadoop login commit
using local user:UnixPrincipal: michaeljones
Using user: "UnixPrincipal: michaeljones" with name michaeljones
User entry: "michaeljones"
UGI loginUser:michaeljones (auth:SIMPLE)
dfs.client.use.legacy.blockreader.local = false
dfs.client.read.shortcircuit = false
dfs.client.domain.socket.data.traffic = false
dfs.domain.socket.path = 
multipleLinearRandomRetry = null
Connection manager is shutting down
Connection manager shut down
rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWrapper, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@1a6c1270
getting client out of cache: org.apache.hadoop.ipc.Client@22d7b4f8
Both short-circuit local reads and UNIX domain socket are disabled.
DataTransferProtocol not using SaslPropertiesResolver, no QOP found in configuration for dfs.data.transfer.protection
The ping interval is 60000 ms.
Connecting to localhost/127.0.0.1:9000
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones: starting, having connections 1
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #0
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #0
Call: getFileInfo took 121ms
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #1
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #1
Call: delete took 17ms
/user/michaeljones/hello.txt: masked=rw-r--r--
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #2
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #2
Call: create took 4ms
computePacketChunkSize: src=/user/michaeljones/hello.txt, chunkSize=516, chunksPerPacket=126, packetSize=65016
Lease renewer daemon for [DFSClient_NONMAPREDUCE_-203859550_1] with renew id 1 started
DFSClient writeChunk allocating new packet seqno=0, src=/user/michaeljones/hello.txt, packetSize=65016, chunksPerPacket=126, bytesCurBlock=0
Queued packet 0
Queued packet 1
Allocating new block
Waiting for ack for: 1
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #3
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #3
Call: addBlock took 4ms
pipeline = DatanodeInfoWithStorage[127.0.0.1:50010,DS-b42c5705-9ba4-4b14-b00b-f9194bb036f0,DISK]
Connecting to datanode 127.0.0.1:50010
Send buf size 131072
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #4
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #4
Call: getServerDefaults took 1ms
SASL client skipping handshake in unsecured configuration for addr = /127.0.0.1, datanodeId = DatanodeInfoWithStorage[127.0.0.1:50010,DS-b42c5705-9ba4-4b14-b00b-f9194bb036f0,DISK]
DataStreamer block BP-1045030256-10.0.0.2-1433119149314:blk_1073742251_1428 sending packet packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 20
DFSClient seqno: 0 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
DataStreamer block BP-1045030256-10.0.0.2-1433119149314:blk_1073742251_1428 sending packet packet seqno: 1 offsetInBlock: 20 lastPacketInBlock: true lastByteOffsetInBlock: 20
DFSClient seqno: 1 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
Closing old block BP-1045030256-10.0.0.2-1433119149314:blk_1073742251_1428
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #5
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #5
Call: complete took 4ms
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #6
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #6
Call: getBlockLocations took 27ms
newInfo = LocatedBlocks{
  fileLength=20
  underConstruction=false
  blocks=[LocatedBlock{BP-1045030256-10.0.0.2-1433119149314:blk_1073742251_1428; getBlockSize()=20; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-b42c5705-9ba4-4b14-b00b-f9194bb036f0,DISK]]}]
  lastLocatedBlock=LocatedBlock{BP-1045030256-10.0.0.2-1433119149314:blk_1073742251_1428; getBlockSize()=20; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-b42c5705-9ba4-4b14-b00b-f9194bb036f0,DISK]]}
  isLastBlockComplete=true}
Connecting to datanode 127.0.0.1:50010
SASL client skipping handshake in unsecured configuration for addr = /127.0.0.1, datanodeId = DatanodeInfoWithStorage[127.0.0.1:50010,DS-b42c5705-9ba4-4b14-b00b-f9194bb036f0,DISK]
testMain
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #7
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #7
Call: getFileInfo took 2ms
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #8
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #8
Call: delete took 7ms
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.connect(Job.java:1256)
Trying ClientProtocolProvider : org.apache.hadoop.mapred.LocalClientProtocolProvider
session.id is deprecated. Instead, use dfs.metrics.session-id
Initializing JVM Metrics with processName=JobTracker, sessionId=
Picked org.apache.hadoop.mapred.LocalClientProtocolProvider as the ClientProtocolProvider
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Cluster.getFileSystem(Cluster.java:162)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.submit(Job.java:1287)
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #9
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #9
Call: getFileInfo took 3ms
Configuring job job_local1429907472_0001 with file:/tmp/hadoop-michaeljones/mapred/staging/michaeljones1429907472/.staging/job_local1429907472_0001 as the submit dir
adding the following namenodes' delegation tokens:[hdfs://localhost:9000]
Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
default FileSystem: file:///
No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
Creating splits at file:/tmp/hadoop-michaeljones/mapred/staging/michaeljones1429907472/.staging/job_local1429907472_0001
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #10
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #10
Call: getFileInfo took 5ms
Time taken to get FileStatuses: 32
Total input paths to process : 1
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #11
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #11
Call: getBlockLocations took 7ms
Total # of splits generated by getSplits: 1, TimeTaken: 86
number of splits:1
Handling deprecation for all properties in config...
Handling deprecation for mapreduce.jobtracker.address
Handling deprecation for yarn.resourcemanager.scheduler.monitor.policies
Handling deprecation for dfs.namenode.resource.check.interval
Handling deprecation for mapreduce.jobhistory.client.thread-count
Handling deprecation for yarn.app.mapreduce.am.containerlauncher.threadpool-initial-size
Handling deprecation for mapred.child.java.opts
Handling deprecation for mapreduce.jobtracker.retiredjobs.cache.size
Handling deprecation for dfs.client.https.need-auth
Handling deprecation for yarn.admin.acl
Handling deprecation for yarn.app.mapreduce.am.job.committer.cancel-timeout
Handling deprecation for mapreduce.job.emit-timeline-data
Handling deprecation for fs.ftp.host.port
Handling deprecation for dfs.namenode.avoid.read.stale.datanode
Handling deprecation for dfs.journalnode.rpc-address
Handling deprecation for mapreduce.job.end-notification.retry.attempts
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.ttl-interval-ms
Handling deprecation for yarn.resourcemanager.leveldb-state-store.path
Handling deprecation for mapred.mapper.new-api
Handling deprecation for yarn.ipc.rpc.class
Handling deprecation for ipc.client.connection.maxidletime
Handling deprecation for yarn.nodemanager.process-kill-wait.ms
Handling deprecation for mapreduce.cluster.acls.enabled
Handling deprecation for mapreduce.jobtracker.handler.count
Handling deprecation for io.map.index.interval
Handling deprecation for dfs.namenode.https-address
Handling deprecation for mapreduce.task.profile.reduces
Handling deprecation for fs.s3n.multipart.uploads.enabled
Handling deprecation for io.seqfile.sorter.recordlimit
Handling deprecation for mapreduce.job.ubertask.maxmaps
Handling deprecation for mapreduce.tasktracker.tasks.sleeptimebeforesigkill
Handling deprecation for hadoop.util.hash.type
Handling deprecation for dfs.namenode.replication.min
Handling deprecation for yarn.nodemanager.container-manager.thread-count
Handling deprecation for mapreduce.jobtracker.jobhistory.block.size
Handling deprecation for dfs.namenode.fs-limits.min-block-size
Handling deprecation for mapreduce.app-submission.cross-platform
Handling deprecation for fs.AbstractFileSystem.file.impl
Handling deprecation for net.topology.script.number.args
Handling deprecation for yarn.resourcemanager.container-tokens.master-key-rolling-interval-secs
Handling deprecation for mapreduce.map.output.compress.codec
Handling deprecation for mapreduce.job.reducer.preempt.delay.sec
Handling deprecation for s3native.bytes-per-checksum
Handling deprecation for dfs.namenode.path.based.cache.block.map.allocation.percent
Handling deprecation for yarn.nodemanager.windows-container.memory-limit.enabled
Handling deprecation for mapreduce.input.fileinputformat.split.minsize
Handling deprecation for hadoop.security.group.mapping
Handling deprecation for mapreduce.jobtracker.system.dir
Handling deprecation for mapreduce.job.end-notification.max.attempts
Handling deprecation for mapreduce.reduce.markreset.buffer.percent
Handling deprecation for dfs.datanode.cache.revocation.polling.ms
Handling deprecation for mapreduce.reduce.speculative
Handling deprecation for yarn.nodemanager.localizer.cache.cleanup.interval-ms
Handling deprecation for dfs.namenode.lazypersist.file.scrub.interval.sec
Handling deprecation for fs.s3a.threads.core
Handling deprecation for mapreduce.jobhistory.recovery.store.fs.uri
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.start-time-read-cache-size
Handling deprecation for hadoop.registry.zk.retry.interval.ms
Handling deprecation for yarn.nodemanager.keytab
Handling deprecation for dfs.namenode.replication.interval
Handling deprecation for yarn.resourcemanager.admin.address
Handling deprecation for mapreduce.job.maps
Handling deprecation for nfs.dump.dir
Handling deprecation for mapreduce.job.user.name
Handling deprecation for mapreduce.jobtracker.maxtasks.perjob
Handling deprecation for mapreduce.job.ubertask.enable
Handling deprecation for mapreduce.job.reduce.class
Handling deprecation for yarn.nodemanager.delete.debug-delay-sec
Handling deprecation for yarn.timeline-service.ttl-enable
Handling deprecation for yarn.resourcemanager.fs.state-store.retry-policy-spec
Handling deprecation for mapreduce.reduce.skip.maxgroups
Handling deprecation for dfs.client.use.datanode.hostname
Handling deprecation for fs.trash.interval
Handling deprecation for mapreduce.job.name
Handling deprecation for mapreduce.am.max-attempts
Handling deprecation for mapreduce.jobtracker.heartbeats.in.second
Handling deprecation for yarn.resourcemanager.zk-num-retries
Handling deprecation for s3.blocksize
Handling deprecation for dfs.datanode.data.dir
Handling deprecation for mapreduce.jobtracker.persist.jobstatus.active
Handling deprecation for mapreduce.reduce.shuffle.parallelcopies
Handling deprecation for fs.s3.buffer.dir
Handling deprecation for mapreduce.jobhistory.done-dir
Handling deprecation for hadoop.security.instrumentation.requires.admin
Handling deprecation for hadoop.registry.zk.retry.ceiling.ms
Handling deprecation for nfs.rtmax
Handling deprecation for dfs.datanode.data.dir.perm
Handling deprecation for yarn.resourcemanager.container.liveness-monitor.interval-ms
Handling deprecation for yarn.nodemanager.env-whitelist
Handling deprecation for dfs.namenode.backup.address
Handling deprecation for dfs.namenode.xattrs.enabled
Handling deprecation for dfs.datanode.readahead.bytes
Handling deprecation for mapreduce.jobhistory.cleaner.enable
Handling deprecation for dfs.client.block.write.retries
Handling deprecation for mapreduce.tasktracker.http.address
Handling deprecation for yarn.nodemanager.linux-container-executor.cgroups.hierarchy
Handling deprecation for ha.failover-controller.graceful-fence.connection.retries
Handling deprecation for yarn.resourcemanager.recovery.enabled
Handling deprecation for yarn.app.mapreduce.am.container.log.backups
Handling deprecation for dfs.namenode.safemode.threshold-pct
Handling deprecation for yarn.nodemanager.disk-health-checker.interval-ms
Handling deprecation for hadoop.security.java.secure.random.algorithm
Handling deprecation for dfs.namenode.list.cache.directives.num.responses
Handling deprecation for dfs.datanode.dns.nameserver
Handling deprecation for mapreduce.cluster.temp.dir
Handling deprecation for fs.s3a.max.total.tasks
Handling deprecation for mapreduce.reduce.maxattempts
Handling deprecation for mapreduce.client.submit.file.replication
Handling deprecation for mapreduce.shuffle.port
Handling deprecation for yarn.resourcemanager.resource-tracker.client.thread-count
Handling deprecation for dfs.namenode.replication.considerLoad
Handling deprecation for dfs.namenode.edits.journal-plugin.qjournal
Handling deprecation for dfs.client.write.exclude.nodes.cache.expiry.interval.millis
Handling deprecation for yarn.nodemanager.delete.thread-count
Handling deprecation for dfs.client.mmap.cache.timeout.ms
Handling deprecation for yarn.nodemanager.admin-env
Handling deprecation for io.skip.checksum.errors
Handling deprecation for yarn.timeline-service.hostname
Handling deprecation for yarn.resourcemanager.proxy-user-privileges.enabled
Handling deprecation for mapreduce.job.speculative.speculative-cap-total-tasks
Handling deprecation for yarn.acl.enable
Handling deprecation for fs.s3a.fast.upload
Handling deprecation for file.blocksize
Handling deprecation for mapreduce.job.speculative.slowtaskthreshold
Handling deprecation for ftp.replication
Handling deprecation for yarn.sharedcache.cleaner.initial-delay-mins
Handling deprecation for s3native.client-write-packet-size
Handling deprecation for hadoop.rpc.socket.factory.class.default
Handling deprecation for file.bytes-per-checksum
Handling deprecation for dfs.datanode.slow.io.warning.threshold.ms
Handling deprecation for io.seqfile.lazydecompress
Handling deprecation for mapreduce.task.skip.start.attempts
Handling deprecation for dfs.namenode.reject-unresolved-dn-topology-mapping
Handling deprecation for hadoop.common.configuration.version
Handling deprecation for yarn.resourcemanager.client.thread-count
Handling deprecation for dfs.datanode.drop.cache.behind.reads
Handling deprecation for yarn.sharedcache.admin.address
Handling deprecation for mapreduce.job.output.value.class
Handling deprecation for mapreduce.output.fileoutputformat.outputdir
Handling deprecation for mapreduce.jobtracker.taskcache.levels
Handling deprecation for yarn.nodemanager.linux-container-executor.nonsecure-mode.user-pattern
Handling deprecation for yarn.resourcemanager.zk-timeout-ms
Handling deprecation for yarn.resourcemanager.max-completed-applications
Handling deprecation for mapreduce.job.jvm.numtasks
Handling deprecation for yarn.sharedcache.cleaner.period-mins
Handling deprecation for mapreduce.jobtracker.tasktracker.maxblacklists
Handling deprecation for dfs.namenode.top.num.users
Handling deprecation for yarn.nodemanager.linux-container-executor.cgroups.mount
Handling deprecation for yarn.sharedcache.checksum.algo.impl
Handling deprecation for mapreduce.job.end-notification.max.retry.interval
Handling deprecation for mapreduce.job.acl-view-job
Handling deprecation for mapreduce.job.classloader
Handling deprecation for yarn.log-aggregation-enable
Handling deprecation for mapreduce.reduce.shuffle.fetch.retry.interval-ms
Handling deprecation for yarn.resourcemanager.nodemanager.minimum.version
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.size
Handling deprecation for yarn.app.mapreduce.am.job.task.listener.thread-count
Handling deprecation for yarn.app.mapreduce.am.resource.cpu-vcores
Handling deprecation for dfs.namenode.edit.log.autoroll.check.interval.ms
Handling deprecation for mapreduce.output.fileoutputformat.compress.type
Handling deprecation for hadoop.hdfs.configuration.version
Handling deprecation for hadoop.security.group.mapping.ldap.search.attr.member
Handling deprecation for yarn.nodemanager.log.retain-seconds
Handling deprecation for yarn.nodemanager.local-cache.max-files-per-directory
Handling deprecation for mapreduce.job.end-notification.retry.interval
Handling deprecation for hadoop.ssl.client.conf
Handling deprecation for yarn.sharedcache.root-dir
Handling deprecation for dfs.journalnode.https-address
Handling deprecation for mapreduce.reduce.shuffle.fetch.retry.timeout-ms
Handling deprecation for dfs.bytes-per-checksum
Handling deprecation for dfs.namenode.max.objects
Handling deprecation for mapreduce.tasktracker.instrumentation
Handling deprecation for dfs.datanode.max.transfer.threads
Handling deprecation for dfs.block.access.key.update.interval
Handling deprecation for mapreduce.jobtracker.jobhistory.task.numberprogresssplits
Handling deprecation for mapreduce.map.memory.mb
Handling deprecation for ha.failover-controller.new-active.rpc-timeout.ms
Handling deprecation for hadoop.ssl.hostname.verifier
Handling deprecation for dfs.client.read.shortcircuit
Handling deprecation for dfs.datanode.hdfs-blocks-metadata.enabled
Handling deprecation for mapreduce.tasktracker.healthchecker.interval
Handling deprecation for dfs.image.transfer.chunksize
Handling deprecation for mapreduce.tasktracker.taskmemorymanager.monitoringinterval
Handling deprecation for dfs.client.https.keystore.resource
Handling deprecation for yarn.resourcemanager.connect.retry-interval.ms
Handling deprecation for yarn.timeline-service.webapp.address
Handling deprecation for s3native.blocksize
Handling deprecation for yarn.scheduler.minimum-allocation-mb
Handling deprecation for yarn.sharedcache.cleaner.resource-sleep-ms
Handling deprecation for net.topology.impl
Handling deprecation for dfs.client.failover.sleep.base.millis
Handling deprecation for dfs.permissions.superusergroup
Handling deprecation for io.seqfile.compress.blocksize
Handling deprecation for hadoop.registry.zk.retry.times
Handling deprecation for fs.AbstractFileSystem.ftp.impl
Handling deprecation for dfs.namenode.checkpoint.edits.dir
Handling deprecation for mapreduce.job.running.reduce.limit
Handling deprecation for dfs.blockreport.initialDelay
Handling deprecation for dfs.namenode.heartbeat.recheck-interval
Handling deprecation for dfs.namenode.safemode.extension
Handling deprecation for yarn.scheduler.maximum-allocation-mb
Handling deprecation for mapreduce.job.reduce.shuffle.consumer.plugin.class
Handling deprecation for yarn.nodemanager.vmem-check-enabled
Handling deprecation for mapreduce.task.io.sort.factor
Handling deprecation for mapreduce.jobtracker.persist.jobstatus.dir
Handling deprecation for dfs.client.failover.sleep.max.millis
Handling deprecation for dfs.namenode.delegation.key.update-interval
Handling deprecation for hadoop.rpc.protection
Handling deprecation for fs.permissions.umask-mode
Handling deprecation for fs.s3.sleepTimeSeconds
Handling deprecation for ha.health-monitor.rpc-timeout.ms
Handling deprecation for hadoop.http.staticuser.user
Handling deprecation for fs.s3a.connection.maximum
Handling deprecation for yarn.nodemanager.linux-container-executor.nonsecure-mode.limit-users
Handling deprecation for fs.s3a.paging.maximum
Handling deprecation for fs.AbstractFileSystem.viewfs.impl
Handling deprecation for fs.ftp.host
Handling deprecation for yarn.nodemanager.linux-container-executor.nonsecure-mode.local-user
Handling deprecation for fs.s3a.impl
Handling deprecation for hadoop.http.authentication.kerberos.keytab
Handling deprecation for dfs.namenode.fs-limits.max-blocks-per-file
Handling deprecation for mapreduce.tasktracker.http.threads
Handling deprecation for mapreduce.tasktracker.dns.nameserver
Handling deprecation for yarn.resourcemanager.am-rm-tokens.master-key-rolling-interval-secs
Handling deprecation for dfs.client.block.write.replace-datanode-on-failure.enable
Handling deprecation for io.compression.codec.bzip2.library
Handling deprecation for mapreduce.map.skip.maxrecords
Handling deprecation for dfs.client.use.legacy.blockreader.local
Handling deprecation for dfs.namenode.checkpoint.dir
Handling deprecation for dfs.namenode.top.windows.minutes
Handling deprecation for mapreduce.job.maxtaskfailures.per.tracker
Handling deprecation for net.topology.node.switch.mapping.impl
Handling deprecation for mapreduce.shuffle.max.connections
Handling deprecation for mapreduce.jobhistory.loadedjobs.cache.size
Handling deprecation for dfs.storage.policy.enabled
Handling deprecation for yarn.client.application-client-protocol.poll-interval-ms
Handling deprecation for yarn.nodemanager.localizer.address
Handling deprecation for dfs.namenode.list.cache.pools.num.responses
Handling deprecation for nfs.server.port
Handling deprecation for mapreduce.client.output.filter
Handling deprecation for yarn.timeline-service.client.best-effort
Handling deprecation for ha.zookeeper.parent-znode
Handling deprecation for mapreduce.jobtracker.persist.jobstatus.hours
Handling deprecation for yarn.sharedcache.admin.thread-count
Handling deprecation for yarn.nodemanager.resource.cpu-vcores
Handling deprecation for dfs.datanode.block-pinning.enabled
Handling deprecation for mapreduce.jobhistory.http.policy
Handling deprecation for yarn.resourcemanager.webapp.delegation-token-auth-filter.enabled
Handling deprecation for mapreduce.job.speculative.retry-after-no-speculate
Handling deprecation for fs.s3a.attempts.maximum
Handling deprecation for s3native.stream-buffer-size
Handling deprecation for io.seqfile.local.dir
Handling deprecation for yarn.log-aggregation.retain-check-interval-seconds
Handling deprecation for fs.s3n.multipart.copy.block.size
Handling deprecation for dfs.encrypt.data.transfer.cipher.key.bitlength
Handling deprecation for dfs.datanode.sync.behind.writes
Handling deprecation for yarn.resourcemanager.zk-acl
Handling deprecation for hadoop.ssl.keystores.factory.class
Handling deprecation for mapreduce.job.split.metainfo.maxsize
Handling deprecation for fs.s3.maxRetries
Handling deprecation for hadoop.security.random.device.file.path
Handling deprecation for yarn.client.nodemanager-connect.max-wait-ms
Handling deprecation for dfs.namenode.stale.datanode.interval
Handling deprecation for mapreduce.task.io.sort.mb
Handling deprecation for yarn.resourcemanager.zk-state-store.parent-path
Handling deprecation for yarn.app.mapreduce.client-am.ipc.max-retries
Handling deprecation for fs.client.resolve.remote.symlinks
Handling deprecation for yarn.nodemanager.linux-container-executor.cgroups.strict-resource-usage
Handling deprecation for hadoop.ssl.enabled.protocols
Handling deprecation for mapreduce.reduce.cpu.vcores
Handling deprecation for yarn.client.failover-retries
Handling deprecation for mapreduce.jobhistory.address
Handling deprecation for hadoop.ssl.enabled
Handling deprecation for dfs.replication.max
Handling deprecation for dfs.namenode.name.dir
Handling deprecation for dfs.datanode.https.address
Handling deprecation for ipc.client.kill.max
Handling deprecation for mapreduce.job.committer.setup.cleanup.needed
Handling deprecation for dfs.client.domain.socket.data.traffic
Handling deprecation for yarn.nodemanager.localizer.cache.target-size-mb
Handling deprecation for yarn.resourcemanager.admin.client.thread-count
Handling deprecation for dfs.block.access.token.enable
Handling deprecation for mapreduce.job.speculative.retry-after-speculate
Handling deprecation for dfs.datanode.address
Handling deprecation for mapreduce.jobtracker.restart.recover
Handling deprecation for ipc.client.connect.max.retries
Handling deprecation for yarn.timeline-service.store-class
Handling deprecation for dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
Handling deprecation for hadoop.tmp.dir
Handling deprecation for dfs.datanode.handler.count
Handling deprecation for yarn.resourcemanager.ha.automatic-failover.embedded
Handling deprecation for yarn.timeline-service.ttl-ms
Handling deprecation for mapreduce.task.profile.map.params
Handling deprecation for yarn.resourcemanager.nodemanagers.heartbeat-interval-ms
Handling deprecation for mapreduce.map.speculative
Handling deprecation for yarn.timeline-service.recovery.enabled
Handling deprecation for mapreduce.job.map.class
Handling deprecation for dfs.namenode.resource.checked.volumes.minimum
Handling deprecation for yarn.nodemanager.recovery.dir
Handling deprecation for mapreduce.job.counters.max
Handling deprecation for yarn.resourcemanager.keytab
Handling deprecation for dfs.namenode.max.extra.edits.segments.retained
Handling deprecation for dfs.webhdfs.user.provider.user.pattern
Handling deprecation for dfs.client.mmap.enabled
Handling deprecation for mapreduce.map.log.level
Handling deprecation for dfs.client.file-block-storage-locations.timeout.millis
Handling deprecation for yarn.client.max-cached-nodemanagers-proxies
Handling deprecation for yarn.app.mapreduce.am.scheduler.heartbeat.interval-ms
Handling deprecation for hadoop.fuse.timer.period
Handling deprecation for fs.trash.checkpoint.interval
Handling deprecation for yarn.sharedcache.app-checker.class
Handling deprecation for dfs.journalnode.http-address
Handling deprecation for yarn.app.mapreduce.am.staging-dir
Handling deprecation for mapreduce.tasktracker.local.dir.minspacestart
Handling deprecation for yarn.nm.liveness-monitor.expiry-interval-ms
Handling deprecation for ha.health-monitor.check-interval.ms
Handling deprecation for mapreduce.reduce.shuffle.merge.percent
Handling deprecation for dfs.namenode.retrycache.heap.percent
Handling deprecation for yarn.nodemanager.docker-container-executor.exec-name
Handling deprecation for ipc.client.connect.timeout
Handling deprecation for yarn.resourcemanager.fs.state-store.retry-interval-ms
Handling deprecation for mapreduce.output.fileoutputformat.compress
Handling deprecation for yarn.nodemanager.local-dirs
Handling deprecation for yarn.nodemanager.recovery.enabled
Handling deprecation for io.native.lib.available
Handling deprecation for yarn.sharedcache.store.in-memory.staleness-period-mins
Handling deprecation for yarn.resourcemanager.am.max-attempts
Handling deprecation for s3.replication
Handling deprecation for mapreduce.input.fileinputformat.inputdir
Handling deprecation for fs.AbstractFileSystem.har.impl
Handling deprecation for dfs.image.compress
Handling deprecation for mapreduce.job.running.map.limit
Handling deprecation for mapreduce.reduce.input.buffer.percent
Handling deprecation for yarn.nodemanager.webapp.address
Handling deprecation for dfs.datanode.available-space-volume-choosing-policy.balanced-space-preference-fraction
Handling deprecation for dfs.namenode.edit.log.autoroll.multiplier.threshold
Handling deprecation for hadoop.security.group.mapping.ldap.ssl
Handling deprecation for dfs.namenode.checkpoint.check.period
Handling deprecation for fs.defaultFS
Handling deprecation for fs.s3a.multipart.size
Handling deprecation for dfs.client.slow.io.warning.threshold.ms
Handling deprecation for yarn.app.mapreduce.am.job.committer.commit-window
Handling deprecation for hadoop.security.group.mapping.ldap.search.attr.group.name
Handling deprecation for yarn.nodemanager.disk-health-checker.max-disk-utilization-per-disk-percentage
Handling deprecation for yarn.nodemanager.container-monitor.procfs-tree.smaps-based-rss.enabled
Handling deprecation for mapreduce.job.submithostname
Handling deprecation for mapreduce.map.sort.spill.percent
Handling deprecation for hadoop.security.crypto.codec.classes.aes.ctr.nopadding
Handling deprecation for dfs.namenode.http-address
Handling deprecation for hadoop.security.groups.negative-cache.secs
Handling deprecation for hadoop.ssl.server.conf
Handling deprecation for mapreduce.ifile.readahead
Handling deprecation for s3native.replication
Handling deprecation for yarn.client.nodemanager-client-async.thread-pool-max-size
Handling deprecation for mapreduce.jobtracker.staging.root.dir
Handling deprecation for mapreduce.jobhistory.admin.address
Handling deprecation for dfs.namenode.startup.delay.block.deletion.sec
Handling deprecation for yarn.nodemanager.health-checker.interval-ms
Handling deprecation for dfs.namenode.checkpoint.max-retries
Handling deprecation for s3.stream-buffer-size
Handling deprecation for ftp.client-write-packet-size
Handling deprecation for dfs.datanode.fsdatasetcache.max.threads.per.volume
Handling deprecation for mapreduce.output.fileoutputformat.compress.codec
Handling deprecation for yarn.timeline-service.keytab
Handling deprecation for yarn.sharedcache.store.in-memory.initial-delay-mins
Handling deprecation for mapreduce.jobhistory.webapp.address
Handling deprecation for mapreduce.task.userlog.limit.kb
Handling deprecation for mapreduce.reduce.shuffle.fetch.retry.enabled
Handling deprecation for yarn.app.mapreduce.task.container.log.backups
Handling deprecation for dfs.heartbeat.interval
Handling deprecation for ha.zookeeper.session-timeout.ms
Handling deprecation for fs.s3a.connection.ssl.enabled
Handling deprecation for yarn.sharedcache.webapp.address
Handling deprecation for hadoop.http.authentication.signature.secret.file
Handling deprecation for hadoop.fuse.connection.timeout
Handling deprecation for mapreduce.input.fileinputformat.numinputfiles
Handling deprecation for yarn.nodemanager.log-aggregation.compression-type
Handling deprecation for ipc.server.max.connections
Handling deprecation for yarn.resourcemanager.work-preserving-recovery.scheduling-wait-ms
Handling deprecation for yarn.nodemanager.log-dirs
Handling deprecation for yarn.app.mapreduce.am.resource.mb
Handling deprecation for hadoop.security.groups.cache.secs
Handling deprecation for mapreduce.job.speculative.minimum-allowed-tasks
Handling deprecation for yarn.nodemanager.container-monitor.interval-ms
Handling deprecation for dfs.datanode.cache.revocation.timeout.ms
Handling deprecation for mapreduce.jobhistory.recovery.store.class
Handling deprecation for mapreduce.task.combine.progress.records
Handling deprecation for s3.client-write-packet-size
Handling deprecation for mapreduce.jobtracker.instrumentation
Handling deprecation for dfs.replication
Handling deprecation for mapreduce.shuffle.transfer.buffer.size
Handling deprecation for hadoop.security.group.mapping.ldap.directory.search.timeout
Handling deprecation for dfs.datanode.available-space-volume-choosing-policy.balanced-space-threshold
Handling deprecation for hadoop.work.around.non.threadsafe.getpwuid
Handling deprecation for yarn.app.mapreduce.client-am.ipc.max-retries-on-timeouts
Handling deprecation for yarn.nodemanager.address
Handling deprecation for mapreduce.tasktracker.taskcontroller
Handling deprecation for mapreduce.tasktracker.indexcache.mb
Handling deprecation for yarn.scheduler.maximum-allocation-vcores
Handling deprecation for mapreduce.job.reduces
Handling deprecation for yarn.nodemanager.sleep-delay-before-sigkill.ms
Handling deprecation for yarn.timeline-service.address
Handling deprecation for yarn.resourcemanager.configuration.provider-class
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.expiry
Handling deprecation for yarn.sharedcache.enabled
Handling deprecation for tfile.io.chunk.size
Handling deprecation for mapreduce.job.acl-modify-job
Handling deprecation for hadoop.registry.zk.session.timeout.ms
Handling deprecation for fs.automatic.close
Handling deprecation for ha.health-monitor.sleep-after-disconnect.ms
Handling deprecation for mapreduce.tasktracker.reduce.tasks.maximum
Handling deprecation for mapreduce.input.fileinputformat.list-status.num-threads
Handling deprecation for dfs.datanode.directoryscan.threads
Handling deprecation for dfs.datanode.directoryscan.interval
Handling deprecation for dfs.namenode.acls.enabled
Handling deprecation for dfs.client.short.circuit.replica.stale.threshold.ms
Handling deprecation for hadoop.http.authentication.token.validity
Handling deprecation for fs.s3.block.size
Handling deprecation for ha.failover-controller.graceful-fence.rpc-timeout.ms
Handling deprecation for mapreduce.tasktracker.local.dir.minspacekill
Handling deprecation for dfs.namenode.resource.du.reserved
Handling deprecation for mapreduce.jobhistory.cleaner.interval-ms
Handling deprecation for dfs.namenode.datanode.registration.ip-hostname-check
Handling deprecation for mapreduce.jobhistory.intermediate-done-dir
Handling deprecation for mapreduce.jobtracker.http.address
Handling deprecation for dfs.namenode.backup.http-address
Handling deprecation for dfs.namenode.edits.noeditlogchannelflush
Handling deprecation for mapreduce.reduce.shuffle.input.buffer.percent
Handling deprecation for mapreduce.map.maxattempts
Handling deprecation for yarn.http.policy
Handling deprecation for dfs.namenode.audit.loggers
Handling deprecation for hadoop.security.groups.cache.warn.after.ms
Handling deprecation for io.serializations
Handling deprecation for mapreduce.tasktracker.outofband.heartbeat
Handling deprecation for mapreduce.reduce.shuffle.read.timeout
Handling deprecation for hadoop.security.crypto.buffer.size
Handling deprecation for mapreduce.reduce.skip.proc.count.autoincr
Handling deprecation for mapreduce.ifile.readahead.bytes
Handling deprecation for dfs.http.policy
Handling deprecation for hadoop.registry.secure
Handling deprecation for dfs.namenode.safemode.min.datanodes
Handling deprecation for dfs.client.file-block-storage-locations.num-threads
Handling deprecation for mapreduce.cluster.local.dir
Handling deprecation for mapreduce.tasktracker.report.address
Handling deprecation for dfs.namenode.secondary.https-address
Handling deprecation for hadoop.kerberos.kinit.command
Handling deprecation for yarn.timeline-service.http-authentication.type
Handling deprecation for dfs.block.access.token.lifetime
Handling deprecation for dfs.webhdfs.enabled
Handling deprecation for dfs.namenode.delegation.token.max-lifetime
Handling deprecation for dfs.namenode.avoid.write.stale.datanode
Handling deprecation for dfs.datanode.drop.cache.behind.writes
Handling deprecation for yarn.log-aggregation.retain-seconds
Handling deprecation for mapreduce.job.complete.cancel.delegation.tokens
Handling deprecation for mapreduce.local.clientfactory.class.name
Handling deprecation for mapreduce.shuffle.connection-keep-alive.timeout
Handling deprecation for dfs.namenode.num.extra.edits.retained
Handling deprecation for yarn.scheduler.minimum-allocation-vcores
Handling deprecation for ipc.client.connect.max.retries.on.timeouts
Handling deprecation for yarn.timeline-service.client.retry-interval-ms
Handling deprecation for yarn.timeline-service.client.max-retries
Handling deprecation for fs.s3n.block.size
Handling deprecation for mapreduce.job.map.output.collector.class
Handling deprecation for ha.health-monitor.connect-retry-interval.ms
Handling deprecation for mapreduce.shuffle.max.threads
Handling deprecation for nfs.exports.allowed.hosts
Handling deprecation for dfs.client.mmap.cache.size
Handling deprecation for mapreduce.tasktracker.map.tasks.maximum
Handling deprecation for io.file.buffer.size
Handling deprecation for dfs.client.datanode-restart.timeout
Handling deprecation for io.mapfile.bloom.size
Handling deprecation for hadoop.security.kms.client.authentication.retry-count
Handling deprecation for dfs.namenode.checkpoint.txns
Handling deprecation for ipc.client.connect.retry.interval
Handling deprecation for dfs.client-write-packet-size
Handling deprecation for mapreduce.reduce.shuffle.connect.timeout
Handling deprecation for yarn.resourcemanager.fs.state-store.uri
Handling deprecation for fs.swift.impl
Handling deprecation for hadoop.registry.zk.connection.timeout.ms
Handling deprecation for mapred.queue.default.acl-administer-jobs
Handling deprecation for mapreduce.job.submithostaddress
Handling deprecation for dfs.cachereport.intervalMsec
Handling deprecation for yarn.app.mapreduce.shuffle.log.backups
Handling deprecation for yarn.app.mapreduce.am.container.log.limit.kb
Handling deprecation for yarn.nodemanager.resourcemanager.minimum.version
Handling deprecation for ftp.blocksize
Handling deprecation for yarn.resourcemanager.address
Handling deprecation for file.stream-buffer-size
Handling deprecation for yarn.resourcemanager.scheduler.monitor.enable
Handling deprecation for mapreduce.job.ubertask.maxreduces
Handling deprecation for nfs.allow.insecure.ports
Handling deprecation for yarn.sharedcache.nm.uploader.thread-count
Handling deprecation for ipc.client.idlethreshold
Handling deprecation for ftp.stream-buffer-size
Handling deprecation for yarn.sharedcache.client-server.address
Handling deprecation for dfs.client.failover.connection.retries.on.timeouts
Handling deprecation for dfs.namenode.replication.work.multiplier.per.iteration
Handling deprecation for hadoop.http.authentication.simple.anonymous.allowed
Handling deprecation for hadoop.security.authorization
Handling deprecation for yarn.client.nodemanager-connect.retry-interval-ms
Handling deprecation for yarn.am.liveness-monitor.expiry-interval-ms
Handling deprecation for fs.har.impl.disable.cache
Handling deprecation for yarn.nodemanager.linux-container-executor.resources-handler.class
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.read-cache-size
Handling deprecation for hadoop.security.authentication
Handling deprecation for dfs.image.compression.codec
Handling deprecation for mapreduce.task.files.preserve.failedtasks
Handling deprecation for dfs.client.read.shortcircuit.streams.cache.size
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.path
Handling deprecation for mapreduce.job.reduce.slowstart.completedmaps
Handling deprecation for mapreduce.jobhistory.minicluster.fixed.ports
Handling deprecation for file.replication
Handling deprecation for yarn.resourcemanager.ha.automatic-failover.enabled
Handling deprecation for mapreduce.job.userlog.retain.hours
Handling deprecation for mapreduce.jobhistory.joblist.cache.size
Handling deprecation for dfs.namenode.accesstime.precision
Handling deprecation for yarn.resourcemanager.work-preserving-recovery.enabled
Handling deprecation for dfs.namenode.fs-limits.max-xattrs-per-inode
Handling deprecation for io.mapfile.bloom.error.rate
Handling deprecation for yarn.resourcemanager.store.class
Handling deprecation for dfs.image.transfer.timeout
Handling deprecation for yarn.timeline-service.leveldb-state-store.path
Handling deprecation for nfs.wtmax
Handling deprecation for mapreduce.job.combine.class
Handling deprecation for dfs.namenode.support.allow.format
Handling deprecation for fs.s3a.multipart.purge
Handling deprecation for dfs.secondary.namenode.kerberos.internal.spnego.principal
Handling deprecation for fs.s3a.connection.establish.timeout
Handling deprecation for dfs.stream-buffer-size
Handling deprecation for dfs.namenode.invalidate.work.pct.per.iteration
Handling deprecation for yarn.nodemanager.container-executor.class
Handling deprecation for fs.s3a.multipart.purge.age
Handling deprecation for yarn.resourcemanager.scheduler.client.thread-count
Handling deprecation for dfs.namenode.top.enabled
Handling deprecation for yarn.app.mapreduce.shuffle.log.separate
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.low-watermark
Handling deprecation for fs.s3a.fast.buffer.size
Handling deprecation for hadoop.user.group.static.mapping.overrides
Handling deprecation for tfile.fs.input.buffer.size
Handling deprecation for dfs.client.cached.conn.retry
Handling deprecation for hadoop.http.authentication.type
Handling deprecation for dfs.namenode.list.encryption.zones.num.responses
Handling deprecation for mapreduce.map.cpu.vcores
Handling deprecation for dfs.namenode.path.based.cache.refresh.interval.ms
Handling deprecation for dfs.namenode.decommission.interval
Handling deprecation for dfs.namenode.fs-limits.max-directory-items
Handling deprecation for yarn.resourcemanager.zk-retry-interval-ms
Handling deprecation for ftp.bytes-per-checksum
Handling deprecation for dfs.ha.log-roll.period
Handling deprecation for dfs.user.home.dir.prefix
Handling deprecation for ipc.client.fallback-to-simple-auth-allowed
Handling deprecation for yarn.nodemanager.pmem-check-enabled
Handling deprecation for yarn.nodemanager.remote-app-log-dir
Handling deprecation for dfs.namenode.inotify.max.events.per.rpc
Handling deprecation for mapreduce.task.profile.maps
Handling deprecation for mapreduce.shuffle.ssl.file.buffer.size
Handling deprecation for mapreduce.tasktracker.healthchecker.script.timeout
Handling deprecation for yarn.timeline-service.webapp.https.address
Handling deprecation for yarn.nodemanager.resource.percentage-physical-cpu-limit
Handling deprecation for yarn.app.mapreduce.am.command-opts
Handling deprecation for dfs.namenode.fs-limits.max-xattr-size
Handling deprecation for dfs.datanode.http.address
Handling deprecation for dfs.namenode.blocks.per.postponedblocks.rescan
Handling deprecation for yarn.sharedcache.nm.uploader.replication.factor
Handling deprecation for hadoop.registry.zk.root
Handling deprecation for hadoop.jetty.logs.serve.aliases
Handling deprecation for yarn.client.failover-proxy-provider
Handling deprecation for mapreduce.jobhistory.admin.acl
Handling deprecation for yarn.app.mapreduce.am.hard-kill-timeout-ms
Handling deprecation for yarn.nodemanager.remote-app-log-dir-suffix
Handling deprecation for mapreduce.jobhistory.principal
Handling deprecation for yarn.resourcemanager.webapp.address
Handling deprecation for mapreduce.jobhistory.recovery.enable
Handling deprecation for yarn.sharedcache.store.in-memory.check-period-mins
Handling deprecation for nfs.mountd.port
Handling deprecation for mapreduce.reduce.merge.inmem.threshold
Handling deprecation for fs.df.interval
Handling deprecation for yarn.timeline-service.enabled
Handling deprecation for mapreduce.jobtracker.jobhistory.lru.cache.size
Handling deprecation for mapreduce.task.profile
Handling deprecation for mapreduce.job.output.key.class
Handling deprecation for yarn.nodemanager.hostname
Handling deprecation for dfs.namenode.num.checkpoints.retained
Handling deprecation for mapreduce.job.queuename
Handling deprecation for mapreduce.jobhistory.max-age-ms
Handling deprecation for mapreduce.job.token.tracking.ids.enabled
Handling deprecation for yarn.nodemanager.localizer.client.thread-count
Handling deprecation for yarn.sharedcache.uploader.server.thread-count
Handling deprecation for dfs.client.mmap.retry.timeout.ms
Handling deprecation for mapreduce.jobhistory.move.thread-count
Handling deprecation for dfs.permissions.enabled
Handling deprecation for dfs.blockreport.split.threshold
Handling deprecation for fs.AbstractFileSystem.hdfs.impl
Handling deprecation for dfs.datanode.balance.bandwidthPerSec
Handling deprecation for dfs.block.scanner.volume.bytes.per.second
Handling deprecation for hadoop.http.filter.initializers
Handling deprecation for yarn.timeline-service.http-authentication.simple.anonymous.allowed
Handling deprecation for dfs.default.chunk.view.size
Handling deprecation for yarn.sharedcache.client-server.thread-count
Handling deprecation for yarn.resourcemanager.resource-tracker.address
Handling deprecation for mapreduce.job.working.dir
Handling deprecation for mapreduce.jobhistory.datestring.cache.size
Handling deprecation for mapreduce.task.profile.params
Handling deprecation for dfs.namenode.decommission.blocks.per.interval
Handling deprecation for dfs.namenode.handler.count
Handling deprecation for dfs.image.transfer.bandwidthPerSec
Handling deprecation for rpc.metrics.quantile.enable
Handling deprecation for mapreduce.jobtracker.expire.trackers.interval
Handling deprecation for mapreduce.task.timeout
Handling deprecation for yarn.app.mapreduce.client.max-retries
Handling deprecation for yarn.nodemanager.resource.memory-mb
Handling deprecation for yarn.nodemanager.disk-health-checker.min-healthy-disks
Handling deprecation for dfs.datanode.failed.volumes.tolerated
Handling deprecation for yarn.timeline-service.handler-thread-count
Handling deprecation for ipc.server.listen.queue.size
Handling deprecation for fs.s3a.threads.max
Handling deprecation for yarn.resourcemanager.connect.max-wait.ms
Handling deprecation for mapreduce.fileoutputcommitter.algorithm.version
Handling deprecation for mapreduce.framework.name
Handling deprecation for mapreduce.map.skip.proc.count.autoincr
Handling deprecation for mapreduce.job.max.split.locations
Handling deprecation for yarn.resourcemanager.scheduler.class
Handling deprecation for yarn.resourcemanager.system-metrics-publisher.enabled
Handling deprecation for dfs.blocksize
Handling deprecation for yarn.sharedcache.nested-level
Handling deprecation for mapreduce.shuffle.connection-keep-alive.enable
Handling deprecation for fs.s3a.threads.keepalivetime
Handling deprecation for fs.s3a.connection.timeout
Handling deprecation for file.client-write-packet-size
Handling deprecation for ha.failover-controller.cli-check.rpc-timeout.ms
Handling deprecation for ha.zookeeper.acl
Handling deprecation for dfs.namenode.write.stale.datanode.ratio
Handling deprecation for dfs.encrypt.data.transfer
Handling deprecation for dfs.datanode.shared.file.descriptor.paths
Handling deprecation for mapreduce.input.lineinputformat.linespermap
Handling deprecation for yarn.resourcemanager.delayed.delegation-token.removal-interval-ms
Handling deprecation for yarn.nodemanager.localizer.fetch.thread-count
Handling deprecation for dfs.client.failover.max.attempts
Handling deprecation for yarn.resourcemanager.scheduler.address
Handling deprecation for dfs.client.read.shortcircuit.streams.cache.expiry.ms
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.start-time-write-cache-size
Handling deprecation for yarn.nodemanager.health-checker.script.timeout-ms
Handling deprecation for yarn.resourcemanager.fs.state-store.num-retries
Handling deprecation for hadoop.ssl.require.client.cert
Handling deprecation for hadoop.security.uid.cache.secs
Handling deprecation for mapreduce.jobhistory.keytab
Handling deprecation for dfs.client.read.shortcircuit.skip.checksum
Handling deprecation for yarn.resourcemanager.ha.automatic-failover.zk-base-path
Handling deprecation for mapreduce.shuffle.ssl.enabled
Handling deprecation for mapreduce.reduce.log.level
Handling deprecation for hadoop.registry.rm.enabled
Handling deprecation for mapreduce.tasktracker.dns.interface
Handling deprecation for yarn.resourcemanager.system-metrics-publisher.dispatcher.pool-size
Handling deprecation for mapreduce.job.speculative.speculative-cap-running-tasks
Handling deprecation for dfs.datanode.block.id.layout.upgrade.threads
Handling deprecation for dfs.datanode.use.datanode.hostname
Handling deprecation for dfs.client.context
Handling deprecation for yarn.resourcemanager.ha.enabled
Handling deprecation for mapred.reducer.new-api
Handling deprecation for dfs.namenode.delegation.token.renew-interval
Handling deprecation for dfs.blockreport.intervalMsec
Handling deprecation for fs.s3a.multipart.threshold
Handling deprecation for mapreduce.reduce.shuffle.memory.limit.percent
Handling deprecation for dfs.https.server.keystore.resource
Handling deprecation for io.map.index.skip
Handling deprecation for mapreduce.job.hdfs-servers
Handling deprecation for mapreduce.jobtracker.taskscheduler
Handling deprecation for dfs.namenode.kerberos.internal.spnego.principal
Handling deprecation for yarn.resourcemanager.state-store.max-completed-applications
Handling deprecation for mapreduce.map.output.compress
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.num.refill.threads
Handling deprecation for fs.s3n.multipart.uploads.block.size
Handling deprecation for mapreduce.task.merge.progress.records
Handling deprecation for dfs.datanode.dns.interface
Handling deprecation for map.sort.class
Handling deprecation for yarn.nodemanager.aux-services.mapreduce_shuffle.class
Handling deprecation for tfile.fs.output.buffer.size
Handling deprecation for fs.du.interval
Handling deprecation for dfs.client.failover.connection.retries
Handling deprecation for dfs.namenode.top.window.num.buckets
Handling deprecation for mapreduce.job.dir
Handling deprecation for fs.s3a.buffer.dir
Handling deprecation for mapreduce.reduce.shuffle.retry-delay.max.ms
Handling deprecation for yarn.sharedcache.uploader.server.address
Handling deprecation for mapreduce.client.progressmonitor.pollinterval
Handling deprecation for yarn.app.mapreduce.shuffle.log.limit.kb
Handling deprecation for dfs.datanode.max.locked.memory
Handling deprecation for dfs.namenode.retrycache.expirytime.millis
Handling deprecation for dfs.datanode.scan.period.hours
Handling deprecation for dfs.client.block.write.replace-datanode-on-failure.best-effort
Handling deprecation for mapreduce.jobhistory.move.interval-ms
Handling deprecation for dfs.ha.fencing.ssh.connect-timeout
Handling deprecation for yarn.nodemanager.log-aggregation.roll-monitoring-interval-seconds
Handling deprecation for dfs.namenode.fs-limits.max-component-length
Handling deprecation for hadoop.registry.zk.quorum
Handling deprecation for dfs.namenode.enable.retrycache
Handling deprecation for dfs.datanode.du.reserved
Handling deprecation for yarn.timeline-service.state-store-class
Handling deprecation for dfs.datanode.ipc.address
Handling deprecation for hadoop.registry.system.acls
Handling deprecation for dfs.client.block.write.replace-datanode-on-failure.policy
Handling deprecation for dfs.namenode.path.based.cache.retry.interval.ms
Handling deprecation for hadoop.security.crypto.cipher.suite
Handling deprecation for dfs.ha.tail-edits.period
Handling deprecation for mapreduce.task.profile.reduce.params
Handling deprecation for hadoop.registry.jaas.context
Handling deprecation for yarn.resourcemanager.hostname
Handling deprecation for mapreduce.reduce.memory.mb
Handling deprecation for hadoop.security.group.mapping.ldap.search.filter.group
Handling deprecation for hadoop.http.authentication.kerberos.principal
Handling deprecation for hadoop.security.group.mapping.ldap.search.filter.user
Handling deprecation for yarn.nodemanager.disk-health-checker.min-free-space-per-disk-mb
Handling deprecation for dfs.namenode.edits.dir
Handling deprecation for yarn.client.failover-retries-on-socket-timeouts
Handling deprecation for dfs.namenode.decommission.max.concurrent.tracked.nodes
Handling deprecation for mapreduce.client.completion.pollinterval
Handling deprecation for dfs.namenode.name.dir.restore
Handling deprecation for dfs.namenode.secondary.http-address
Handling deprecation for mapreduce.jobhistory.recovery.store.leveldb.path
Handling deprecation for yarn.sharedcache.store.class
Handling deprecation for s3.bytes-per-checksum
Handling deprecation for yarn.nodemanager.windows-container.cpu-limit.enabled
Handling deprecation for yarn.resourcemanager.webapp.https.address
Handling deprecation for yarn.nodemanager.vmem-pmem-ratio
Handling deprecation for dfs.namenode.checkpoint.period
Handling deprecation for dfs.ha.automatic-failover.enabled
Submitting tokens for job: job_local1429907472_0001
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.fs.FileContext.getAbstractFileSystem(FileContext.java:331)
Handling deprecation for all properties in config...
Handling deprecation for mapreduce.jobtracker.address
Handling deprecation for yarn.resourcemanager.scheduler.monitor.policies
Handling deprecation for dfs.namenode.resource.check.interval
Handling deprecation for mapreduce.jobhistory.client.thread-count
Handling deprecation for yarn.app.mapreduce.am.containerlauncher.threadpool-initial-size
Handling deprecation for mapred.child.java.opts
Handling deprecation for mapreduce.jobtracker.retiredjobs.cache.size
Handling deprecation for dfs.client.https.need-auth
Handling deprecation for yarn.admin.acl
Handling deprecation for yarn.app.mapreduce.am.job.committer.cancel-timeout
Handling deprecation for mapreduce.job.emit-timeline-data
Handling deprecation for fs.ftp.host.port
Handling deprecation for dfs.namenode.avoid.read.stale.datanode
Handling deprecation for dfs.journalnode.rpc-address
Handling deprecation for mapreduce.job.end-notification.retry.attempts
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.ttl-interval-ms
Handling deprecation for yarn.resourcemanager.leveldb-state-store.path
Handling deprecation for mapred.mapper.new-api
Handling deprecation for yarn.ipc.rpc.class
Handling deprecation for ipc.client.connection.maxidletime
Handling deprecation for yarn.nodemanager.process-kill-wait.ms
Handling deprecation for mapreduce.cluster.acls.enabled
Handling deprecation for mapreduce.jobtracker.handler.count
Handling deprecation for io.map.index.interval
Handling deprecation for dfs.namenode.https-address
Handling deprecation for mapreduce.task.profile.reduces
Handling deprecation for fs.s3n.multipart.uploads.enabled
Handling deprecation for io.seqfile.sorter.recordlimit
Handling deprecation for mapreduce.job.ubertask.maxmaps
Handling deprecation for mapreduce.tasktracker.tasks.sleeptimebeforesigkill
Handling deprecation for hadoop.util.hash.type
Handling deprecation for dfs.namenode.replication.min
Handling deprecation for yarn.nodemanager.container-manager.thread-count
Handling deprecation for mapreduce.jobtracker.jobhistory.block.size
Handling deprecation for dfs.namenode.fs-limits.min-block-size
Handling deprecation for mapreduce.app-submission.cross-platform
Handling deprecation for fs.AbstractFileSystem.file.impl
Handling deprecation for net.topology.script.number.args
Handling deprecation for yarn.resourcemanager.container-tokens.master-key-rolling-interval-secs
Handling deprecation for mapreduce.map.output.compress.codec
Handling deprecation for mapreduce.job.reducer.preempt.delay.sec
Handling deprecation for s3native.bytes-per-checksum
Handling deprecation for dfs.namenode.path.based.cache.block.map.allocation.percent
Handling deprecation for yarn.nodemanager.windows-container.memory-limit.enabled
Handling deprecation for mapreduce.input.fileinputformat.split.minsize
Handling deprecation for hadoop.security.group.mapping
Handling deprecation for mapreduce.jobtracker.system.dir
Handling deprecation for mapreduce.job.end-notification.max.attempts
Handling deprecation for mapreduce.reduce.markreset.buffer.percent
Handling deprecation for dfs.datanode.cache.revocation.polling.ms
Handling deprecation for mapreduce.reduce.speculative
Handling deprecation for yarn.nodemanager.localizer.cache.cleanup.interval-ms
Handling deprecation for dfs.namenode.lazypersist.file.scrub.interval.sec
Handling deprecation for fs.s3a.threads.core
Handling deprecation for mapreduce.jobhistory.recovery.store.fs.uri
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.start-time-read-cache-size
Handling deprecation for hadoop.registry.zk.retry.interval.ms
Handling deprecation for yarn.nodemanager.keytab
Handling deprecation for dfs.namenode.replication.interval
Handling deprecation for yarn.resourcemanager.admin.address
Handling deprecation for mapreduce.job.maps
Handling deprecation for nfs.dump.dir
Handling deprecation for mapreduce.job.user.name
Handling deprecation for mapreduce.jobtracker.maxtasks.perjob
Handling deprecation for mapreduce.job.ubertask.enable
Handling deprecation for mapreduce.job.reduce.class
Handling deprecation for yarn.nodemanager.delete.debug-delay-sec
Handling deprecation for yarn.timeline-service.ttl-enable
Handling deprecation for yarn.resourcemanager.fs.state-store.retry-policy-spec
Handling deprecation for mapreduce.reduce.skip.maxgroups
Handling deprecation for dfs.client.use.datanode.hostname
Handling deprecation for fs.trash.interval
Handling deprecation for mapreduce.job.name
Handling deprecation for mapreduce.am.max-attempts
Handling deprecation for mapreduce.jobtracker.heartbeats.in.second
Handling deprecation for yarn.resourcemanager.zk-num-retries
Handling deprecation for s3.blocksize
Handling deprecation for dfs.datanode.data.dir
Handling deprecation for mapreduce.jobtracker.persist.jobstatus.active
Handling deprecation for mapreduce.reduce.shuffle.parallelcopies
Handling deprecation for fs.s3.buffer.dir
Handling deprecation for mapreduce.jobhistory.done-dir
Handling deprecation for hadoop.security.instrumentation.requires.admin
Handling deprecation for hadoop.registry.zk.retry.ceiling.ms
Handling deprecation for nfs.rtmax
Handling deprecation for dfs.datanode.data.dir.perm
Handling deprecation for yarn.resourcemanager.container.liveness-monitor.interval-ms
Handling deprecation for yarn.nodemanager.env-whitelist
Handling deprecation for dfs.namenode.backup.address
Handling deprecation for dfs.namenode.xattrs.enabled
Handling deprecation for dfs.datanode.readahead.bytes
Handling deprecation for mapreduce.jobhistory.cleaner.enable
Handling deprecation for dfs.client.block.write.retries
Handling deprecation for mapreduce.tasktracker.http.address
Handling deprecation for yarn.nodemanager.linux-container-executor.cgroups.hierarchy
Handling deprecation for ha.failover-controller.graceful-fence.connection.retries
Handling deprecation for yarn.resourcemanager.recovery.enabled
Handling deprecation for yarn.app.mapreduce.am.container.log.backups
Handling deprecation for dfs.namenode.safemode.threshold-pct
Handling deprecation for yarn.nodemanager.disk-health-checker.interval-ms
Handling deprecation for hadoop.security.java.secure.random.algorithm
Handling deprecation for dfs.namenode.list.cache.directives.num.responses
Handling deprecation for dfs.datanode.dns.nameserver
Handling deprecation for mapreduce.cluster.temp.dir
Handling deprecation for fs.s3a.max.total.tasks
Handling deprecation for mapreduce.reduce.maxattempts
Handling deprecation for mapreduce.client.submit.file.replication
Handling deprecation for mapreduce.shuffle.port
Handling deprecation for yarn.resourcemanager.resource-tracker.client.thread-count
Handling deprecation for dfs.namenode.replication.considerLoad
Handling deprecation for dfs.namenode.edits.journal-plugin.qjournal
Handling deprecation for dfs.client.write.exclude.nodes.cache.expiry.interval.millis
Handling deprecation for yarn.nodemanager.delete.thread-count
Handling deprecation for dfs.client.mmap.cache.timeout.ms
Handling deprecation for yarn.nodemanager.admin-env
Handling deprecation for io.skip.checksum.errors
Handling deprecation for yarn.timeline-service.hostname
Handling deprecation for yarn.resourcemanager.proxy-user-privileges.enabled
Handling deprecation for mapreduce.job.speculative.speculative-cap-total-tasks
Handling deprecation for yarn.acl.enable
Handling deprecation for fs.s3a.fast.upload
Handling deprecation for file.blocksize
Handling deprecation for mapreduce.job.speculative.slowtaskthreshold
Handling deprecation for ftp.replication
Handling deprecation for yarn.sharedcache.cleaner.initial-delay-mins
Handling deprecation for s3native.client-write-packet-size
Handling deprecation for hadoop.rpc.socket.factory.class.default
Handling deprecation for file.bytes-per-checksum
Handling deprecation for dfs.datanode.slow.io.warning.threshold.ms
Handling deprecation for io.seqfile.lazydecompress
Handling deprecation for mapreduce.task.skip.start.attempts
Handling deprecation for dfs.namenode.reject-unresolved-dn-topology-mapping
Handling deprecation for hadoop.common.configuration.version
Handling deprecation for yarn.resourcemanager.client.thread-count
Handling deprecation for dfs.datanode.drop.cache.behind.reads
Handling deprecation for yarn.sharedcache.admin.address
Handling deprecation for mapreduce.job.output.value.class
Handling deprecation for mapreduce.output.fileoutputformat.outputdir
Handling deprecation for mapreduce.jobtracker.taskcache.levels
Handling deprecation for yarn.nodemanager.linux-container-executor.nonsecure-mode.user-pattern
Handling deprecation for yarn.resourcemanager.zk-timeout-ms
Handling deprecation for yarn.resourcemanager.max-completed-applications
Handling deprecation for mapreduce.job.jvm.numtasks
Handling deprecation for yarn.sharedcache.cleaner.period-mins
Handling deprecation for mapreduce.jobtracker.tasktracker.maxblacklists
Handling deprecation for dfs.namenode.top.num.users
Handling deprecation for yarn.nodemanager.linux-container-executor.cgroups.mount
Handling deprecation for yarn.sharedcache.checksum.algo.impl
Handling deprecation for mapreduce.job.end-notification.max.retry.interval
Handling deprecation for mapreduce.job.acl-view-job
Handling deprecation for mapreduce.job.classloader
Handling deprecation for yarn.log-aggregation-enable
Handling deprecation for mapreduce.reduce.shuffle.fetch.retry.interval-ms
Handling deprecation for yarn.resourcemanager.nodemanager.minimum.version
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.size
Handling deprecation for yarn.app.mapreduce.am.job.task.listener.thread-count
Handling deprecation for yarn.app.mapreduce.am.resource.cpu-vcores
Handling deprecation for dfs.namenode.edit.log.autoroll.check.interval.ms
Handling deprecation for mapreduce.output.fileoutputformat.compress.type
Handling deprecation for hadoop.hdfs.configuration.version
Handling deprecation for hadoop.security.group.mapping.ldap.search.attr.member
Handling deprecation for yarn.nodemanager.log.retain-seconds
Handling deprecation for yarn.nodemanager.local-cache.max-files-per-directory
Handling deprecation for mapreduce.job.end-notification.retry.interval
Handling deprecation for hadoop.ssl.client.conf
Handling deprecation for yarn.sharedcache.root-dir
Handling deprecation for dfs.journalnode.https-address
Handling deprecation for mapreduce.reduce.shuffle.fetch.retry.timeout-ms
Handling deprecation for dfs.bytes-per-checksum
Handling deprecation for dfs.namenode.max.objects
Handling deprecation for mapreduce.tasktracker.instrumentation
Handling deprecation for dfs.datanode.max.transfer.threads
Handling deprecation for dfs.block.access.key.update.interval
Handling deprecation for mapreduce.jobtracker.jobhistory.task.numberprogresssplits
Handling deprecation for mapreduce.map.memory.mb
Handling deprecation for ha.failover-controller.new-active.rpc-timeout.ms
Handling deprecation for hadoop.ssl.hostname.verifier
Handling deprecation for dfs.client.read.shortcircuit
Handling deprecation for dfs.datanode.hdfs-blocks-metadata.enabled
Handling deprecation for mapreduce.tasktracker.healthchecker.interval
Handling deprecation for dfs.image.transfer.chunksize
Handling deprecation for mapreduce.tasktracker.taskmemorymanager.monitoringinterval
Handling deprecation for dfs.client.https.keystore.resource
Handling deprecation for yarn.resourcemanager.connect.retry-interval.ms
Handling deprecation for yarn.timeline-service.webapp.address
Handling deprecation for s3native.blocksize
Handling deprecation for yarn.scheduler.minimum-allocation-mb
Handling deprecation for yarn.sharedcache.cleaner.resource-sleep-ms
Handling deprecation for net.topology.impl
Handling deprecation for dfs.client.failover.sleep.base.millis
Handling deprecation for dfs.permissions.superusergroup
Handling deprecation for io.seqfile.compress.blocksize
Handling deprecation for hadoop.registry.zk.retry.times
Handling deprecation for fs.AbstractFileSystem.ftp.impl
Handling deprecation for dfs.namenode.checkpoint.edits.dir
Handling deprecation for mapreduce.job.running.reduce.limit
Handling deprecation for dfs.blockreport.initialDelay
Handling deprecation for dfs.namenode.heartbeat.recheck-interval
Handling deprecation for dfs.namenode.safemode.extension
Handling deprecation for yarn.scheduler.maximum-allocation-mb
Handling deprecation for mapreduce.job.reduce.shuffle.consumer.plugin.class
Handling deprecation for yarn.nodemanager.vmem-check-enabled
Handling deprecation for mapreduce.task.io.sort.factor
Handling deprecation for mapreduce.jobtracker.persist.jobstatus.dir
Handling deprecation for dfs.client.failover.sleep.max.millis
Handling deprecation for dfs.namenode.delegation.key.update-interval
Handling deprecation for hadoop.rpc.protection
Handling deprecation for fs.permissions.umask-mode
Handling deprecation for fs.s3.sleepTimeSeconds
Handling deprecation for ha.health-monitor.rpc-timeout.ms
Handling deprecation for hadoop.http.staticuser.user
Handling deprecation for fs.s3a.connection.maximum
Handling deprecation for yarn.nodemanager.linux-container-executor.nonsecure-mode.limit-users
Handling deprecation for fs.s3a.paging.maximum
Handling deprecation for fs.AbstractFileSystem.viewfs.impl
Handling deprecation for fs.ftp.host
Handling deprecation for yarn.nodemanager.linux-container-executor.nonsecure-mode.local-user
Handling deprecation for fs.s3a.impl
Handling deprecation for hadoop.http.authentication.kerberos.keytab
Handling deprecation for dfs.namenode.fs-limits.max-blocks-per-file
Handling deprecation for mapreduce.tasktracker.http.threads
Handling deprecation for mapreduce.tasktracker.dns.nameserver
Handling deprecation for yarn.resourcemanager.am-rm-tokens.master-key-rolling-interval-secs
Handling deprecation for dfs.client.block.write.replace-datanode-on-failure.enable
Handling deprecation for io.compression.codec.bzip2.library
Handling deprecation for mapreduce.map.skip.maxrecords
Handling deprecation for dfs.client.use.legacy.blockreader.local
Handling deprecation for dfs.namenode.checkpoint.dir
Handling deprecation for dfs.namenode.top.windows.minutes
Handling deprecation for mapreduce.job.maxtaskfailures.per.tracker
Handling deprecation for net.topology.node.switch.mapping.impl
Handling deprecation for mapreduce.shuffle.max.connections
Handling deprecation for mapreduce.jobhistory.loadedjobs.cache.size
Handling deprecation for dfs.storage.policy.enabled
Handling deprecation for yarn.client.application-client-protocol.poll-interval-ms
Handling deprecation for yarn.nodemanager.localizer.address
Handling deprecation for dfs.namenode.list.cache.pools.num.responses
Handling deprecation for nfs.server.port
Handling deprecation for mapreduce.client.output.filter
Handling deprecation for yarn.timeline-service.client.best-effort
Handling deprecation for ha.zookeeper.parent-znode
Handling deprecation for mapreduce.jobtracker.persist.jobstatus.hours
Handling deprecation for yarn.sharedcache.admin.thread-count
Handling deprecation for yarn.nodemanager.resource.cpu-vcores
Handling deprecation for dfs.datanode.block-pinning.enabled
Handling deprecation for mapreduce.jobhistory.http.policy
Handling deprecation for yarn.resourcemanager.webapp.delegation-token-auth-filter.enabled
Handling deprecation for mapreduce.job.speculative.retry-after-no-speculate
Handling deprecation for fs.s3a.attempts.maximum
Handling deprecation for s3native.stream-buffer-size
Handling deprecation for io.seqfile.local.dir
Handling deprecation for yarn.log-aggregation.retain-check-interval-seconds
Handling deprecation for fs.s3n.multipart.copy.block.size
Handling deprecation for dfs.encrypt.data.transfer.cipher.key.bitlength
Handling deprecation for dfs.datanode.sync.behind.writes
Handling deprecation for yarn.resourcemanager.zk-acl
Handling deprecation for hadoop.ssl.keystores.factory.class
Handling deprecation for mapreduce.job.split.metainfo.maxsize
Handling deprecation for fs.s3.maxRetries
Handling deprecation for hadoop.security.random.device.file.path
Handling deprecation for yarn.client.nodemanager-connect.max-wait-ms
Handling deprecation for dfs.namenode.stale.datanode.interval
Handling deprecation for mapreduce.task.io.sort.mb
Handling deprecation for yarn.resourcemanager.zk-state-store.parent-path
Handling deprecation for yarn.app.mapreduce.client-am.ipc.max-retries
Handling deprecation for fs.client.resolve.remote.symlinks
Handling deprecation for yarn.nodemanager.linux-container-executor.cgroups.strict-resource-usage
Handling deprecation for hadoop.ssl.enabled.protocols
Handling deprecation for mapreduce.reduce.cpu.vcores
Handling deprecation for yarn.client.failover-retries
Handling deprecation for mapreduce.jobhistory.address
Handling deprecation for hadoop.ssl.enabled
Handling deprecation for dfs.replication.max
Handling deprecation for dfs.namenode.name.dir
Handling deprecation for dfs.datanode.https.address
Handling deprecation for ipc.client.kill.max
Handling deprecation for mapreduce.job.committer.setup.cleanup.needed
Handling deprecation for dfs.client.domain.socket.data.traffic
Handling deprecation for yarn.nodemanager.localizer.cache.target-size-mb
Handling deprecation for yarn.resourcemanager.admin.client.thread-count
Handling deprecation for dfs.block.access.token.enable
Handling deprecation for mapreduce.job.speculative.retry-after-speculate
Handling deprecation for dfs.datanode.address
Handling deprecation for mapreduce.jobtracker.restart.recover
Handling deprecation for ipc.client.connect.max.retries
Handling deprecation for yarn.timeline-service.store-class
Handling deprecation for dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
Handling deprecation for hadoop.tmp.dir
Handling deprecation for dfs.datanode.handler.count
Handling deprecation for yarn.resourcemanager.ha.automatic-failover.embedded
Handling deprecation for yarn.timeline-service.ttl-ms
Handling deprecation for mapreduce.task.profile.map.params
Handling deprecation for yarn.resourcemanager.nodemanagers.heartbeat-interval-ms
Handling deprecation for mapreduce.map.speculative
Handling deprecation for yarn.timeline-service.recovery.enabled
Handling deprecation for mapreduce.job.map.class
Handling deprecation for dfs.namenode.resource.checked.volumes.minimum
Handling deprecation for yarn.nodemanager.recovery.dir
Handling deprecation for mapreduce.job.counters.max
Handling deprecation for yarn.resourcemanager.keytab
Handling deprecation for dfs.namenode.max.extra.edits.segments.retained
Handling deprecation for dfs.webhdfs.user.provider.user.pattern
Handling deprecation for dfs.client.mmap.enabled
Handling deprecation for mapreduce.map.log.level
Handling deprecation for dfs.client.file-block-storage-locations.timeout.millis
Handling deprecation for yarn.client.max-cached-nodemanagers-proxies
Handling deprecation for yarn.app.mapreduce.am.scheduler.heartbeat.interval-ms
Handling deprecation for hadoop.fuse.timer.period
Handling deprecation for fs.trash.checkpoint.interval
Handling deprecation for yarn.sharedcache.app-checker.class
Handling deprecation for dfs.journalnode.http-address
Handling deprecation for yarn.app.mapreduce.am.staging-dir
Handling deprecation for mapreduce.tasktracker.local.dir.minspacestart
Handling deprecation for yarn.nm.liveness-monitor.expiry-interval-ms
Handling deprecation for ha.health-monitor.check-interval.ms
Handling deprecation for mapreduce.reduce.shuffle.merge.percent
Handling deprecation for dfs.namenode.retrycache.heap.percent
Handling deprecation for yarn.nodemanager.docker-container-executor.exec-name
Handling deprecation for ipc.client.connect.timeout
Handling deprecation for yarn.resourcemanager.fs.state-store.retry-interval-ms
Handling deprecation for mapreduce.output.fileoutputformat.compress
Handling deprecation for yarn.nodemanager.local-dirs
Handling deprecation for yarn.nodemanager.recovery.enabled
Handling deprecation for io.native.lib.available
Handling deprecation for yarn.sharedcache.store.in-memory.staleness-period-mins
Handling deprecation for yarn.resourcemanager.am.max-attempts
Handling deprecation for s3.replication
Handling deprecation for mapreduce.input.fileinputformat.inputdir
Handling deprecation for fs.AbstractFileSystem.har.impl
Handling deprecation for dfs.image.compress
Handling deprecation for mapreduce.job.running.map.limit
Handling deprecation for mapreduce.reduce.input.buffer.percent
Handling deprecation for yarn.nodemanager.webapp.address
Handling deprecation for dfs.datanode.available-space-volume-choosing-policy.balanced-space-preference-fraction
Handling deprecation for dfs.namenode.edit.log.autoroll.multiplier.threshold
Handling deprecation for hadoop.security.group.mapping.ldap.ssl
Handling deprecation for dfs.namenode.checkpoint.check.period
Handling deprecation for fs.defaultFS
Handling deprecation for fs.s3a.multipart.size
Handling deprecation for dfs.client.slow.io.warning.threshold.ms
Handling deprecation for yarn.app.mapreduce.am.job.committer.commit-window
Handling deprecation for hadoop.security.group.mapping.ldap.search.attr.group.name
Handling deprecation for yarn.nodemanager.disk-health-checker.max-disk-utilization-per-disk-percentage
Handling deprecation for yarn.nodemanager.container-monitor.procfs-tree.smaps-based-rss.enabled
Handling deprecation for mapreduce.job.submithostname
Handling deprecation for mapreduce.map.sort.spill.percent
Handling deprecation for hadoop.security.crypto.codec.classes.aes.ctr.nopadding
Handling deprecation for dfs.namenode.http-address
Handling deprecation for hadoop.security.groups.negative-cache.secs
Handling deprecation for hadoop.ssl.server.conf
Handling deprecation for mapreduce.ifile.readahead
Handling deprecation for s3native.replication
Handling deprecation for yarn.client.nodemanager-client-async.thread-pool-max-size
Handling deprecation for mapreduce.jobtracker.staging.root.dir
Handling deprecation for mapreduce.jobhistory.admin.address
Handling deprecation for dfs.namenode.startup.delay.block.deletion.sec
Handling deprecation for yarn.nodemanager.health-checker.interval-ms
Handling deprecation for dfs.namenode.checkpoint.max-retries
Handling deprecation for s3.stream-buffer-size
Handling deprecation for ftp.client-write-packet-size
Handling deprecation for dfs.datanode.fsdatasetcache.max.threads.per.volume
Handling deprecation for mapreduce.output.fileoutputformat.compress.codec
Handling deprecation for yarn.timeline-service.keytab
Handling deprecation for yarn.sharedcache.store.in-memory.initial-delay-mins
Handling deprecation for mapreduce.jobhistory.webapp.address
Handling deprecation for mapreduce.task.userlog.limit.kb
Handling deprecation for mapreduce.reduce.shuffle.fetch.retry.enabled
Handling deprecation for yarn.app.mapreduce.task.container.log.backups
Handling deprecation for dfs.heartbeat.interval
Handling deprecation for ha.zookeeper.session-timeout.ms
Handling deprecation for fs.s3a.connection.ssl.enabled
Handling deprecation for yarn.sharedcache.webapp.address
Handling deprecation for hadoop.http.authentication.signature.secret.file
Handling deprecation for hadoop.fuse.connection.timeout
Handling deprecation for mapreduce.input.fileinputformat.numinputfiles
Handling deprecation for yarn.nodemanager.log-aggregation.compression-type
Handling deprecation for ipc.server.max.connections
Handling deprecation for yarn.resourcemanager.work-preserving-recovery.scheduling-wait-ms
Handling deprecation for yarn.nodemanager.log-dirs
Handling deprecation for yarn.app.mapreduce.am.resource.mb
Handling deprecation for hadoop.security.groups.cache.secs
Handling deprecation for mapreduce.job.speculative.minimum-allowed-tasks
Handling deprecation for yarn.nodemanager.container-monitor.interval-ms
Handling deprecation for dfs.datanode.cache.revocation.timeout.ms
Handling deprecation for mapreduce.jobhistory.recovery.store.class
Handling deprecation for mapreduce.task.combine.progress.records
Handling deprecation for s3.client-write-packet-size
Handling deprecation for mapreduce.jobtracker.instrumentation
Handling deprecation for dfs.replication
Handling deprecation for mapreduce.shuffle.transfer.buffer.size
Handling deprecation for hadoop.security.group.mapping.ldap.directory.search.timeout
Handling deprecation for dfs.datanode.available-space-volume-choosing-policy.balanced-space-threshold
Handling deprecation for hadoop.work.around.non.threadsafe.getpwuid
Handling deprecation for yarn.app.mapreduce.client-am.ipc.max-retries-on-timeouts
Handling deprecation for yarn.nodemanager.address
Handling deprecation for mapreduce.tasktracker.taskcontroller
Handling deprecation for mapreduce.tasktracker.indexcache.mb
Handling deprecation for yarn.scheduler.maximum-allocation-vcores
Handling deprecation for mapreduce.job.reduces
Handling deprecation for yarn.nodemanager.sleep-delay-before-sigkill.ms
Handling deprecation for yarn.timeline-service.address
Handling deprecation for yarn.resourcemanager.configuration.provider-class
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.expiry
Handling deprecation for yarn.sharedcache.enabled
Handling deprecation for tfile.io.chunk.size
Handling deprecation for mapreduce.job.acl-modify-job
Handling deprecation for hadoop.registry.zk.session.timeout.ms
Handling deprecation for fs.automatic.close
Handling deprecation for ha.health-monitor.sleep-after-disconnect.ms
Handling deprecation for mapreduce.tasktracker.reduce.tasks.maximum
Handling deprecation for mapreduce.input.fileinputformat.list-status.num-threads
Handling deprecation for dfs.datanode.directoryscan.threads
Handling deprecation for dfs.datanode.directoryscan.interval
Handling deprecation for dfs.namenode.acls.enabled
Handling deprecation for dfs.client.short.circuit.replica.stale.threshold.ms
Handling deprecation for hadoop.http.authentication.token.validity
Handling deprecation for fs.s3.block.size
Handling deprecation for ha.failover-controller.graceful-fence.rpc-timeout.ms
Handling deprecation for mapreduce.tasktracker.local.dir.minspacekill
Handling deprecation for dfs.namenode.resource.du.reserved
Handling deprecation for mapreduce.jobhistory.cleaner.interval-ms
Handling deprecation for dfs.namenode.datanode.registration.ip-hostname-check
Handling deprecation for mapreduce.jobhistory.intermediate-done-dir
Handling deprecation for mapreduce.jobtracker.http.address
Handling deprecation for dfs.namenode.backup.http-address
Handling deprecation for dfs.namenode.edits.noeditlogchannelflush
Handling deprecation for mapreduce.reduce.shuffle.input.buffer.percent
Handling deprecation for mapreduce.map.maxattempts
Handling deprecation for yarn.http.policy
Handling deprecation for dfs.namenode.audit.loggers
Handling deprecation for hadoop.security.groups.cache.warn.after.ms
Handling deprecation for io.serializations
Handling deprecation for mapreduce.tasktracker.outofband.heartbeat
Handling deprecation for mapreduce.reduce.shuffle.read.timeout
Handling deprecation for hadoop.security.crypto.buffer.size
Handling deprecation for mapreduce.reduce.skip.proc.count.autoincr
Handling deprecation for mapreduce.ifile.readahead.bytes
Handling deprecation for dfs.http.policy
Handling deprecation for hadoop.registry.secure
Handling deprecation for dfs.namenode.safemode.min.datanodes
Handling deprecation for dfs.client.file-block-storage-locations.num-threads
Handling deprecation for mapreduce.cluster.local.dir
Handling deprecation for mapreduce.tasktracker.report.address
Handling deprecation for dfs.namenode.secondary.https-address
Handling deprecation for hadoop.kerberos.kinit.command
Handling deprecation for yarn.timeline-service.http-authentication.type
Handling deprecation for dfs.block.access.token.lifetime
Handling deprecation for dfs.webhdfs.enabled
Handling deprecation for dfs.namenode.delegation.token.max-lifetime
Handling deprecation for dfs.namenode.avoid.write.stale.datanode
Handling deprecation for dfs.datanode.drop.cache.behind.writes
Handling deprecation for yarn.log-aggregation.retain-seconds
Handling deprecation for mapreduce.job.complete.cancel.delegation.tokens
Handling deprecation for mapreduce.local.clientfactory.class.name
Handling deprecation for mapreduce.shuffle.connection-keep-alive.timeout
Handling deprecation for dfs.namenode.num.extra.edits.retained
Handling deprecation for yarn.scheduler.minimum-allocation-vcores
Handling deprecation for ipc.client.connect.max.retries.on.timeouts
Handling deprecation for yarn.timeline-service.client.retry-interval-ms
Handling deprecation for yarn.timeline-service.client.max-retries
Handling deprecation for fs.s3n.block.size
Handling deprecation for mapreduce.job.map.output.collector.class
Handling deprecation for ha.health-monitor.connect-retry-interval.ms
Handling deprecation for mapreduce.shuffle.max.threads
Handling deprecation for nfs.exports.allowed.hosts
Handling deprecation for dfs.client.mmap.cache.size
Handling deprecation for mapreduce.tasktracker.map.tasks.maximum
Handling deprecation for io.file.buffer.size
Handling deprecation for dfs.client.datanode-restart.timeout
Handling deprecation for io.mapfile.bloom.size
Handling deprecation for hadoop.security.kms.client.authentication.retry-count
Handling deprecation for dfs.namenode.checkpoint.txns
Handling deprecation for ipc.client.connect.retry.interval
Handling deprecation for dfs.client-write-packet-size
Handling deprecation for mapreduce.reduce.shuffle.connect.timeout
Handling deprecation for yarn.resourcemanager.fs.state-store.uri
Handling deprecation for fs.swift.impl
Handling deprecation for hadoop.registry.zk.connection.timeout.ms
Handling deprecation for mapred.queue.default.acl-administer-jobs
Handling deprecation for mapreduce.job.submithostaddress
Handling deprecation for dfs.cachereport.intervalMsec
Handling deprecation for yarn.app.mapreduce.shuffle.log.backups
Handling deprecation for yarn.app.mapreduce.am.container.log.limit.kb
Handling deprecation for yarn.nodemanager.resourcemanager.minimum.version
Handling deprecation for ftp.blocksize
Handling deprecation for yarn.resourcemanager.address
Handling deprecation for file.stream-buffer-size
Handling deprecation for yarn.resourcemanager.scheduler.monitor.enable
Handling deprecation for mapreduce.job.ubertask.maxreduces
Handling deprecation for nfs.allow.insecure.ports
Handling deprecation for yarn.sharedcache.nm.uploader.thread-count
Handling deprecation for ipc.client.idlethreshold
Handling deprecation for ftp.stream-buffer-size
Handling deprecation for yarn.sharedcache.client-server.address
Handling deprecation for dfs.client.failover.connection.retries.on.timeouts
Handling deprecation for dfs.namenode.replication.work.multiplier.per.iteration
Handling deprecation for hadoop.http.authentication.simple.anonymous.allowed
Handling deprecation for hadoop.security.authorization
Handling deprecation for yarn.client.nodemanager-connect.retry-interval-ms
Handling deprecation for yarn.am.liveness-monitor.expiry-interval-ms
Handling deprecation for fs.har.impl.disable.cache
Handling deprecation for yarn.nodemanager.linux-container-executor.resources-handler.class
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.read-cache-size
Handling deprecation for hadoop.security.authentication
Handling deprecation for dfs.image.compression.codec
Handling deprecation for mapreduce.task.files.preserve.failedtasks
Handling deprecation for dfs.client.read.shortcircuit.streams.cache.size
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.path
Handling deprecation for mapreduce.job.reduce.slowstart.completedmaps
Handling deprecation for mapreduce.jobhistory.minicluster.fixed.ports
Handling deprecation for file.replication
Handling deprecation for yarn.resourcemanager.ha.automatic-failover.enabled
Handling deprecation for mapreduce.job.userlog.retain.hours
Handling deprecation for mapreduce.jobhistory.joblist.cache.size
Handling deprecation for dfs.namenode.accesstime.precision
Handling deprecation for yarn.resourcemanager.work-preserving-recovery.enabled
Handling deprecation for dfs.namenode.fs-limits.max-xattrs-per-inode
Handling deprecation for io.mapfile.bloom.error.rate
Handling deprecation for yarn.resourcemanager.store.class
Handling deprecation for dfs.image.transfer.timeout
Handling deprecation for yarn.timeline-service.leveldb-state-store.path
Handling deprecation for nfs.wtmax
Handling deprecation for mapreduce.job.combine.class
Handling deprecation for dfs.namenode.support.allow.format
Handling deprecation for fs.s3a.multipart.purge
Handling deprecation for dfs.secondary.namenode.kerberos.internal.spnego.principal
Handling deprecation for fs.s3a.connection.establish.timeout
Handling deprecation for dfs.stream-buffer-size
Handling deprecation for dfs.namenode.invalidate.work.pct.per.iteration
Handling deprecation for yarn.nodemanager.container-executor.class
Handling deprecation for fs.s3a.multipart.purge.age
Handling deprecation for yarn.resourcemanager.scheduler.client.thread-count
Handling deprecation for dfs.namenode.top.enabled
Handling deprecation for yarn.app.mapreduce.shuffle.log.separate
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.low-watermark
Handling deprecation for fs.s3a.fast.buffer.size
Handling deprecation for hadoop.user.group.static.mapping.overrides
Handling deprecation for tfile.fs.input.buffer.size
Handling deprecation for dfs.client.cached.conn.retry
Handling deprecation for hadoop.http.authentication.type
Handling deprecation for dfs.namenode.list.encryption.zones.num.responses
Handling deprecation for mapreduce.map.cpu.vcores
Handling deprecation for dfs.namenode.path.based.cache.refresh.interval.ms
Handling deprecation for dfs.namenode.decommission.interval
Handling deprecation for dfs.namenode.fs-limits.max-directory-items
Handling deprecation for yarn.resourcemanager.zk-retry-interval-ms
Handling deprecation for ftp.bytes-per-checksum
Handling deprecation for dfs.ha.log-roll.period
Handling deprecation for dfs.user.home.dir.prefix
Handling deprecation for ipc.client.fallback-to-simple-auth-allowed
Handling deprecation for yarn.nodemanager.pmem-check-enabled
Handling deprecation for yarn.nodemanager.remote-app-log-dir
Handling deprecation for dfs.namenode.inotify.max.events.per.rpc
Handling deprecation for mapreduce.task.profile.maps
Handling deprecation for mapreduce.shuffle.ssl.file.buffer.size
Handling deprecation for mapreduce.tasktracker.healthchecker.script.timeout
Handling deprecation for yarn.timeline-service.webapp.https.address
Handling deprecation for yarn.nodemanager.resource.percentage-physical-cpu-limit
Handling deprecation for yarn.app.mapreduce.am.command-opts
Handling deprecation for dfs.namenode.fs-limits.max-xattr-size
Handling deprecation for dfs.datanode.http.address
Handling deprecation for dfs.namenode.blocks.per.postponedblocks.rescan
Handling deprecation for yarn.sharedcache.nm.uploader.replication.factor
Handling deprecation for hadoop.registry.zk.root
Handling deprecation for hadoop.jetty.logs.serve.aliases
Handling deprecation for yarn.client.failover-proxy-provider
Handling deprecation for mapreduce.jobhistory.admin.acl
Handling deprecation for yarn.app.mapreduce.am.hard-kill-timeout-ms
Handling deprecation for yarn.nodemanager.remote-app-log-dir-suffix
Handling deprecation for mapreduce.jobhistory.principal
Handling deprecation for yarn.resourcemanager.webapp.address
Handling deprecation for mapreduce.jobhistory.recovery.enable
Handling deprecation for yarn.sharedcache.store.in-memory.check-period-mins
Handling deprecation for nfs.mountd.port
Handling deprecation for mapreduce.reduce.merge.inmem.threshold
Handling deprecation for fs.df.interval
Handling deprecation for yarn.timeline-service.enabled
Handling deprecation for mapreduce.jobtracker.jobhistory.lru.cache.size
Handling deprecation for mapreduce.task.profile
Handling deprecation for mapreduce.job.output.key.class
Handling deprecation for yarn.nodemanager.hostname
Handling deprecation for dfs.namenode.num.checkpoints.retained
Handling deprecation for mapreduce.job.queuename
Handling deprecation for mapreduce.jobhistory.max-age-ms
Handling deprecation for mapreduce.job.token.tracking.ids.enabled
Handling deprecation for yarn.nodemanager.localizer.client.thread-count
Handling deprecation for yarn.sharedcache.uploader.server.thread-count
Handling deprecation for dfs.client.mmap.retry.timeout.ms
Handling deprecation for mapreduce.jobhistory.move.thread-count
Handling deprecation for dfs.permissions.enabled
Handling deprecation for dfs.blockreport.split.threshold
Handling deprecation for fs.AbstractFileSystem.hdfs.impl
Handling deprecation for dfs.datanode.balance.bandwidthPerSec
Handling deprecation for dfs.block.scanner.volume.bytes.per.second
Handling deprecation for hadoop.http.filter.initializers
Handling deprecation for yarn.timeline-service.http-authentication.simple.anonymous.allowed
Handling deprecation for dfs.default.chunk.view.size
Handling deprecation for yarn.sharedcache.client-server.thread-count
Handling deprecation for yarn.resourcemanager.resource-tracker.address
Handling deprecation for mapreduce.job.working.dir
Handling deprecation for mapreduce.jobhistory.datestring.cache.size
Handling deprecation for mapreduce.task.profile.params
Handling deprecation for dfs.namenode.decommission.blocks.per.interval
Handling deprecation for dfs.namenode.handler.count
Handling deprecation for dfs.image.transfer.bandwidthPerSec
Handling deprecation for rpc.metrics.quantile.enable
Handling deprecation for mapreduce.jobtracker.expire.trackers.interval
Handling deprecation for mapreduce.task.timeout
Handling deprecation for yarn.app.mapreduce.client.max-retries
Handling deprecation for yarn.nodemanager.resource.memory-mb
Handling deprecation for yarn.nodemanager.disk-health-checker.min-healthy-disks
Handling deprecation for dfs.datanode.failed.volumes.tolerated
Handling deprecation for yarn.timeline-service.handler-thread-count
Handling deprecation for ipc.server.listen.queue.size
Handling deprecation for fs.s3a.threads.max
Handling deprecation for yarn.resourcemanager.connect.max-wait.ms
Handling deprecation for mapreduce.fileoutputcommitter.algorithm.version
Handling deprecation for mapreduce.framework.name
Handling deprecation for mapreduce.map.skip.proc.count.autoincr
Handling deprecation for mapreduce.job.max.split.locations
Handling deprecation for yarn.resourcemanager.scheduler.class
Handling deprecation for yarn.resourcemanager.system-metrics-publisher.enabled
Handling deprecation for dfs.blocksize
Handling deprecation for yarn.sharedcache.nested-level
Handling deprecation for mapreduce.shuffle.connection-keep-alive.enable
Handling deprecation for fs.s3a.threads.keepalivetime
Handling deprecation for fs.s3a.connection.timeout
Handling deprecation for file.client-write-packet-size
Handling deprecation for ha.failover-controller.cli-check.rpc-timeout.ms
Handling deprecation for ha.zookeeper.acl
Handling deprecation for dfs.namenode.write.stale.datanode.ratio
Handling deprecation for dfs.encrypt.data.transfer
Handling deprecation for dfs.datanode.shared.file.descriptor.paths
Handling deprecation for mapreduce.input.lineinputformat.linespermap
Handling deprecation for yarn.resourcemanager.delayed.delegation-token.removal-interval-ms
Handling deprecation for yarn.nodemanager.localizer.fetch.thread-count
Handling deprecation for dfs.client.failover.max.attempts
Handling deprecation for yarn.resourcemanager.scheduler.address
Handling deprecation for dfs.client.read.shortcircuit.streams.cache.expiry.ms
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.start-time-write-cache-size
Handling deprecation for yarn.nodemanager.health-checker.script.timeout-ms
Handling deprecation for yarn.resourcemanager.fs.state-store.num-retries
Handling deprecation for hadoop.ssl.require.client.cert
Handling deprecation for hadoop.security.uid.cache.secs
Handling deprecation for mapreduce.jobhistory.keytab
Handling deprecation for dfs.client.read.shortcircuit.skip.checksum
Handling deprecation for yarn.resourcemanager.ha.automatic-failover.zk-base-path
Handling deprecation for mapreduce.shuffle.ssl.enabled
Handling deprecation for mapreduce.reduce.log.level
Handling deprecation for hadoop.registry.rm.enabled
Handling deprecation for mapreduce.tasktracker.dns.interface
Handling deprecation for yarn.resourcemanager.system-metrics-publisher.dispatcher.pool-size
Handling deprecation for mapreduce.job.speculative.speculative-cap-running-tasks
Handling deprecation for dfs.datanode.block.id.layout.upgrade.threads
Handling deprecation for dfs.datanode.use.datanode.hostname
Handling deprecation for dfs.client.context
Handling deprecation for yarn.resourcemanager.ha.enabled
Handling deprecation for mapred.reducer.new-api
Handling deprecation for dfs.namenode.delegation.token.renew-interval
Handling deprecation for dfs.blockreport.intervalMsec
Handling deprecation for fs.s3a.multipart.threshold
Handling deprecation for mapreduce.reduce.shuffle.memory.limit.percent
Handling deprecation for dfs.https.server.keystore.resource
Handling deprecation for io.map.index.skip
Handling deprecation for mapreduce.job.hdfs-servers
Handling deprecation for mapreduce.jobtracker.taskscheduler
Handling deprecation for dfs.namenode.kerberos.internal.spnego.principal
Handling deprecation for yarn.resourcemanager.state-store.max-completed-applications
Handling deprecation for mapreduce.map.output.compress
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.num.refill.threads
Handling deprecation for fs.s3n.multipart.uploads.block.size
Handling deprecation for mapreduce.task.merge.progress.records
Handling deprecation for dfs.datanode.dns.interface
Handling deprecation for map.sort.class
Handling deprecation for yarn.nodemanager.aux-services.mapreduce_shuffle.class
Handling deprecation for tfile.fs.output.buffer.size
Handling deprecation for fs.du.interval
Handling deprecation for dfs.client.failover.connection.retries
Handling deprecation for dfs.namenode.top.window.num.buckets
Handling deprecation for mapreduce.job.dir
Handling deprecation for fs.s3a.buffer.dir
Handling deprecation for mapreduce.reduce.shuffle.retry-delay.max.ms
Handling deprecation for yarn.sharedcache.uploader.server.address
Handling deprecation for mapreduce.client.progressmonitor.pollinterval
Handling deprecation for yarn.app.mapreduce.shuffle.log.limit.kb
Handling deprecation for dfs.datanode.max.locked.memory
Handling deprecation for dfs.namenode.retrycache.expirytime.millis
Handling deprecation for dfs.datanode.scan.period.hours
Handling deprecation for dfs.client.block.write.replace-datanode-on-failure.best-effort
Handling deprecation for mapreduce.jobhistory.move.interval-ms
Handling deprecation for dfs.ha.fencing.ssh.connect-timeout
Handling deprecation for yarn.nodemanager.log-aggregation.roll-monitoring-interval-seconds
Handling deprecation for dfs.namenode.fs-limits.max-component-length
Handling deprecation for hadoop.registry.zk.quorum
Handling deprecation for dfs.namenode.enable.retrycache
Handling deprecation for dfs.datanode.du.reserved
Handling deprecation for yarn.timeline-service.state-store-class
Handling deprecation for dfs.datanode.ipc.address
Handling deprecation for hadoop.registry.system.acls
Handling deprecation for dfs.client.block.write.replace-datanode-on-failure.policy
Handling deprecation for dfs.namenode.path.based.cache.retry.interval.ms
Handling deprecation for hadoop.security.crypto.cipher.suite
Handling deprecation for dfs.ha.tail-edits.period
Handling deprecation for mapreduce.task.profile.reduce.params
Handling deprecation for hadoop.registry.jaas.context
Handling deprecation for yarn.resourcemanager.hostname
Handling deprecation for mapreduce.reduce.memory.mb
Handling deprecation for hadoop.security.group.mapping.ldap.search.filter.group
Handling deprecation for hadoop.http.authentication.kerberos.principal
Handling deprecation for hadoop.security.group.mapping.ldap.search.filter.user
Handling deprecation for yarn.nodemanager.disk-health-checker.min-free-space-per-disk-mb
Handling deprecation for dfs.namenode.edits.dir
Handling deprecation for yarn.client.failover-retries-on-socket-timeouts
Handling deprecation for dfs.namenode.decommission.max.concurrent.tracked.nodes
Handling deprecation for mapreduce.client.completion.pollinterval
Handling deprecation for dfs.namenode.name.dir.restore
Handling deprecation for dfs.namenode.secondary.http-address
Handling deprecation for mapreduce.jobhistory.recovery.store.leveldb.path
Handling deprecation for yarn.sharedcache.store.class
Handling deprecation for s3.bytes-per-checksum
Handling deprecation for yarn.nodemanager.windows-container.cpu-limit.enabled
Handling deprecation for yarn.resourcemanager.webapp.https.address
Handling deprecation for yarn.nodemanager.vmem-pmem-ratio
Handling deprecation for dfs.namenode.checkpoint.period
Handling deprecation for dfs.ha.automatic-failover.enabled
The url to track the job: http://localhost:8080/
Running job: job_local1429907472_0001
OutputCommitter set in config null
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
File Output Committer Algorithm version is 1
OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
/user/michaeljones/wcOutputMain/_temporary/0: masked=rwxr-xr-x
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #12
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #12
Call: mkdirs took 23ms
Starting mapper thread pool executor.
Max local threads: 1
Map tasks to process: 1
Waiting for map tasks
Starting task: attempt_local1429907472_0001_m_000000_0
currentIndex 0   0:0
mapreduce.cluster.local.dir for child : /tmp/hadoop-michaeljones/mapred/local/localRunner//michaeljones/jobcache/job_local1429907472_0001/attempt_local1429907472_0001_m_000000_0
using new api for output committer
File Output Committer Algorithm version is 1
ProcfsBasedProcessTree currently is supported only on Linux.
 Using ResourceCalculatorProcessTree : null
Processing split: hdfs://localhost:9000/user/michaeljones/wcInput:0+50
Trying map output collector class: org.apache.hadoop.mapred.MapTask$MapOutputBuffer
(EQUATOR) 0 kvi 26214396(104857584)
mapreduce.task.io.sort.mb: 100
soft limit at 83886080
bufstart = 0; bufvoid = 104857600
kvstart = 26214396; length = 6553600
Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #13
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #13
Call: getBlockLocations took 6ms
newInfo = LocatedBlocks{
  fileLength=50
  underConstruction=false
  blocks=[LocatedBlock{BP-1045030256-10.0.0.2-1433119149314:blk_1073741825_1002; getBlockSize()=50; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-b42c5705-9ba4-4b14-b00b-f9194bb036f0,DISK]]}]
  lastLocatedBlock=LocatedBlock{BP-1045030256-10.0.0.2-1433119149314:blk_1073741825_1002; getBlockSize()=50; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-b42c5705-9ba4-4b14-b00b-f9194bb036f0,DISK]]}
  isLastBlockComplete=true}
Connecting to datanode 127.0.0.1:50010

Starting flush of map output
Spilling map output
bufstart = 0; bufend = 82; bufvoid = 104857600
kvstart = 26214396(104857584); kvend = 26214368(104857472); length = 29/6553600
Finished spill 0
Task:attempt_local1429907472_0001_m_000000_0 is done. And is in the process of committing
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #14
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #14
Call: getFileInfo took 2ms
map
Task 'attempt_local1429907472_0001_m_000000_0' done.
Finishing task: attempt_local1429907472_0001_m_000000_0
map task executor complete.
Starting reduce thread pool executor.
Max local threads: 1
Reduce tasks to process: 1
Waiting for reduce tasks
Starting task: attempt_local1429907472_0001_r_000000_0
currentIndex 0   0:0
mapreduce.cluster.local.dir for child : /tmp/hadoop-michaeljones/mapred/local/localRunner//michaeljones/jobcache/job_local1429907472_0001/attempt_local1429907472_0001_r_000000_0
using new api for output committer
File Output Committer Algorithm version is 1
ProcfsBasedProcessTree currently is supported only on Linux.
 Using ResourceCalculatorProcessTree : null
Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@51edc86f
MergerManager: memoryLimit=668309888, maxSingleShuffleLimit=167077472, mergeThreshold=441084544, ioSortFactor=10, memToMemMergeOutputsThreshold=10
attempt_local1429907472_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
Got 0 map completion events from 0
GetMapEventsThread about to sleep for 1000
LocalFetcher 1 going to fetch: attempt_local1429907472_0001_m_000000_0
attempt_local1429907472_0001_m_000000_0: Proceeding with shuffle since usedMemory (0) is lesser than memoryLimit (668309888).CommitMemory is (0)
localfetcher#1 about to shuffle output of map attempt_local1429907472_0001_m_000000_0 decomp: 63 len: 67 to MEMORY
Read 63 bytes from map-output for attempt_local1429907472_0001_m_000000_0
closeInMemoryFile -> map-output of size: 63, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->63
map attempt_local1429907472_0001_m_000000_0 done 1 / 1 copied.
EventFetcher is interrupted.. Returning
1 / 1 copied.
finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
Merging 1 sorted segments
Down to the last merge-pass, with 1 segments left of total size: 57 bytes
Merged 1 segments, 63 bytes to disk to satisfy reduce memory limit
Disk file: /tmp/hadoop-michaeljones/mapred/local/localRunner/michaeljones/jobcache/job_local1429907472_0001/attempt_local1429907472_0001_r_000000_0/output/map_0.out.merged Length is 67
Merging 1 files, 67 bytes from disk
Merging 0 segments, 0 bytes from memory into reduce
Merging 1 sorted segments
Down to the last merge-pass, with 1 segments left of total size: 57 bytes
1 / 1 copied.
/user/michaeljones/wcOutputMain/_temporary/0/_temporary/attempt_local1429907472_0001_r_000000_0/part-r-00000: masked=rw-r--r--
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #15
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #15
Call: create took 5ms
computePacketChunkSize: src=/user/michaeljones/wcOutputMain/_temporary/0/_temporary/attempt_local1429907472_0001_r_000000_0/part-r-00000, chunkSize=516, chunksPerPacket=126, packetSize=65016
mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
DFSClient writeChunk allocating new packet seqno=0, src=/user/michaeljones/wcOutputMain/_temporary/0/_temporary/attempt_local1429907472_0001_r_000000_0/part-r-00000, packetSize=65016, chunksPerPacket=126, bytesCurBlock=0
Queued packet 0
Allocating new block
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #16
Queued packet 1
Waiting for ack for: 1
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #16
Call: addBlock took 5ms
pipeline = DatanodeInfoWithStorage[127.0.0.1:50010,DS-b42c5705-9ba4-4b14-b00b-f9194bb036f0,DISK]
Connecting to datanode 127.0.0.1:50010
Send buf size 131072
SASL client skipping handshake in unsecured configuration for addr = /127.0.0.1, datanodeId = DatanodeInfoWithStorage[127.0.0.1:50010,DS-b42c5705-9ba4-4b14-b00b-f9194bb036f0,DISK]
DataStreamer block BP-1045030256-10.0.0.2-1433119149314:blk_1073742252_1429 sending packet packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 41
DFSClient seqno: 0 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
DataStreamer block BP-1045030256-10.0.0.2-1433119149314:blk_1073742252_1429 sending packet packet seqno: 1 offsetInBlock: 41 lastPacketInBlock: true lastByteOffsetInBlock: 41
DFSClient seqno: 1 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
Closing old block BP-1045030256-10.0.0.2-1433119149314:blk_1073742252_1429
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #17
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #17
Call: complete took 3ms
Task:attempt_local1429907472_0001_r_000000_0 is done. And is in the process of committing
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #18
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #18
Call: getFileInfo took 3ms
1 / 1 copied.
Task attempt_local1429907472_0001_r_000000_0 is allowed to commit now
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #19
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #19
Call: getFileInfo took 3ms
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #20
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #20
Call: getFileInfo took 2ms
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #21
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #21
Call: rename took 28ms
Saved output of task 'attempt_local1429907472_0001_r_000000_0' to hdfs://localhost:9000/user/michaeljones/wcOutputMain/_temporary/0/task_local1429907472_0001_r_000000
reduce > reduce
Task 'attempt_local1429907472_0001_r_000000_0' done.
Finishing task: attempt_local1429907472_0001_r_000000_0
reduce task executor complete.
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #22
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #22
Call: getListing took 3ms
Merging data from FileStatus{path=hdfs://localhost:9000/user/michaeljones/wcOutputMain/_temporary/0/task_local1429907472_0001_r_000000; isDirectory=true; modification_time=1434167240644; access_time=0; owner=michaeljones; group=supergroup; permission=rwxr-xr-x; isSymlink=false} to hdfs://localhost:9000/user/michaeljones/wcOutputMain
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #23
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #23
Call: getFileInfo took 3ms
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #24
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #24
Call: getListing took 2ms
Merging data from FileStatus{path=hdfs://localhost:9000/user/michaeljones/wcOutputMain/_temporary/0/task_local1429907472_0001_r_000000/part-r-00000; isDirectory=false; length=41; replication=1; blocksize=134217728; modification_time=1434167240676; access_time=1434167240644; owner=michaeljones; group=supergroup; permission=rw-r--r--; isSymlink=false} to hdfs://localhost:9000/user/michaeljones/wcOutputMain/part-r-00000
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #25
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #25
Call: getFileInfo took 2ms
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #26
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #26
Call: rename took 5ms
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #27
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #27
Call: delete took 5ms
/user/michaeljones/wcOutputMain/_SUCCESS: masked=rw-r--r--
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #28
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #28
Call: create took 3ms
computePacketChunkSize: src=/user/michaeljones/wcOutputMain/_SUCCESS, chunkSize=516, chunksPerPacket=126, packetSize=65016
Waiting for ack for: -1
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #29
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #29
Call: complete took 4ms
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.fs.FileContext.getAbstractFileSystem(FileContext.java:331)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
Job job_local1429907472_0001 running in uber mode : false
 map 100% reduce 100%
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.getTaskCompletionEvents(Job.java:670)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.getTaskCompletionEvents(Job.java:670)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
Job job_local1429907472_0001 completed successfully
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.getCounters(Job.java:758)
Counters: 35
	File System Counters
		FILE: Number of bytes read=520
		FILE: Number of bytes written=565643
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=140
		HDFS: Number of bytes written=81
		HDFS: Number of read operations=19
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=10
	Map-Reduce Framework
		Map input records=2
		Map output records=8
		Map output bytes=82
		Map output materialized bytes=67
		Input split bytes=112
		Combine input records=8
		Combine output records=5
		Reduce input groups=5
		Reduce shuffle bytes=67
		Reduce input records=5
		Reduce output records=5
		Spilled Records=10
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=562036736
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=50
	File Output Format Counters 
		Bytes Written=41
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
RunJobAsync
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #30
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #30
Call: getFileInfo took 3ms
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #31
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #31
Call: delete took 3ms
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.connect(Job.java:1256)
Trying ClientProtocolProvider : org.apache.hadoop.mapred.LocalClientProtocolProvider
Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
Picked org.apache.hadoop.mapred.LocalClientProtocolProvider as the ClientProtocolProvider
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Cluster.getFileSystem(Cluster.java:162)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.submit(Job.java:1287)
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #32
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #32
Call: getFileInfo took 3ms
Configuring job job_local737491137_0002 with file:/tmp/hadoop-michaeljones/mapred/staging/michaeljones737491137/.staging/job_local737491137_0002 as the submit dir
adding the following namenodes' delegation tokens:[hdfs://localhost:9000]
Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
default FileSystem: file:///
No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
Creating splits at file:/tmp/hadoop-michaeljones/mapred/staging/michaeljones737491137/.staging/job_local737491137_0002
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #33
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #33
Call: getFileInfo took 3ms
Time taken to get FileStatuses: 4
Total input paths to process : 1
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #34
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #34
Call: getBlockLocations took 3ms
Total # of splits generated by getSplits: 1, TimeTaken: 9
number of splits:1
Handling deprecation for all properties in config...
Handling deprecation for mapreduce.jobtracker.address
Handling deprecation for yarn.resourcemanager.scheduler.monitor.policies
Handling deprecation for dfs.namenode.resource.check.interval
Handling deprecation for mapreduce.jobhistory.client.thread-count
Handling deprecation for yarn.app.mapreduce.am.containerlauncher.threadpool-initial-size
Handling deprecation for mapred.child.java.opts
Handling deprecation for mapreduce.jobtracker.retiredjobs.cache.size
Handling deprecation for dfs.client.https.need-auth
Handling deprecation for yarn.admin.acl
Handling deprecation for yarn.app.mapreduce.am.job.committer.cancel-timeout
Handling deprecation for mapreduce.job.emit-timeline-data
Handling deprecation for fs.ftp.host.port
Handling deprecation for dfs.namenode.avoid.read.stale.datanode
Handling deprecation for dfs.journalnode.rpc-address
Handling deprecation for mapreduce.job.end-notification.retry.attempts
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.ttl-interval-ms
Handling deprecation for yarn.resourcemanager.leveldb-state-store.path
Handling deprecation for mapred.mapper.new-api
Handling deprecation for yarn.ipc.rpc.class
Handling deprecation for ipc.client.connection.maxidletime
Handling deprecation for yarn.nodemanager.process-kill-wait.ms
Handling deprecation for mapreduce.cluster.acls.enabled
Handling deprecation for mapreduce.jobtracker.handler.count
Handling deprecation for io.map.index.interval
Handling deprecation for dfs.namenode.https-address
Handling deprecation for mapreduce.task.profile.reduces
Handling deprecation for fs.s3n.multipart.uploads.enabled
Handling deprecation for io.seqfile.sorter.recordlimit
Handling deprecation for mapreduce.job.ubertask.maxmaps
Handling deprecation for mapreduce.tasktracker.tasks.sleeptimebeforesigkill
Handling deprecation for hadoop.util.hash.type
Handling deprecation for dfs.namenode.replication.min
Handling deprecation for yarn.nodemanager.container-manager.thread-count
Handling deprecation for mapreduce.jobtracker.jobhistory.block.size
Handling deprecation for dfs.namenode.fs-limits.min-block-size
Handling deprecation for mapreduce.app-submission.cross-platform
Handling deprecation for fs.AbstractFileSystem.file.impl
Handling deprecation for net.topology.script.number.args
Handling deprecation for yarn.resourcemanager.container-tokens.master-key-rolling-interval-secs
Handling deprecation for mapreduce.map.output.compress.codec
Handling deprecation for mapreduce.job.reducer.preempt.delay.sec
Handling deprecation for s3native.bytes-per-checksum
Handling deprecation for dfs.namenode.path.based.cache.block.map.allocation.percent
Handling deprecation for yarn.nodemanager.windows-container.memory-limit.enabled
Handling deprecation for mapreduce.input.fileinputformat.split.minsize
Handling deprecation for hadoop.security.group.mapping
Handling deprecation for mapreduce.jobtracker.system.dir
Handling deprecation for mapreduce.job.end-notification.max.attempts
Handling deprecation for mapreduce.reduce.markreset.buffer.percent
Handling deprecation for dfs.datanode.cache.revocation.polling.ms
Handling deprecation for mapreduce.reduce.speculative
Handling deprecation for yarn.nodemanager.localizer.cache.cleanup.interval-ms
Handling deprecation for dfs.namenode.lazypersist.file.scrub.interval.sec
Handling deprecation for fs.s3a.threads.core
Handling deprecation for mapreduce.jobhistory.recovery.store.fs.uri
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.start-time-read-cache-size
Handling deprecation for hadoop.registry.zk.retry.interval.ms
Handling deprecation for yarn.nodemanager.keytab
Handling deprecation for dfs.namenode.replication.interval
Handling deprecation for yarn.resourcemanager.admin.address
Handling deprecation for mapreduce.job.maps
Handling deprecation for nfs.dump.dir
Handling deprecation for mapreduce.job.user.name
Handling deprecation for mapreduce.jobtracker.maxtasks.perjob
Handling deprecation for mapreduce.job.ubertask.enable
Handling deprecation for mapreduce.job.reduce.class
Handling deprecation for yarn.nodemanager.delete.debug-delay-sec
Handling deprecation for yarn.timeline-service.ttl-enable
Handling deprecation for yarn.resourcemanager.fs.state-store.retry-policy-spec
Handling deprecation for mapreduce.reduce.skip.maxgroups
Handling deprecation for dfs.client.use.datanode.hostname
Handling deprecation for fs.trash.interval
Handling deprecation for mapreduce.job.name
Handling deprecation for mapreduce.am.max-attempts
Handling deprecation for mapreduce.jobtracker.heartbeats.in.second
Handling deprecation for yarn.resourcemanager.zk-num-retries
Handling deprecation for s3.blocksize
Handling deprecation for dfs.datanode.data.dir
Handling deprecation for mapreduce.jobtracker.persist.jobstatus.active
Handling deprecation for mapreduce.reduce.shuffle.parallelcopies
Handling deprecation for fs.s3.buffer.dir
Handling deprecation for mapreduce.jobhistory.done-dir
Handling deprecation for hadoop.security.instrumentation.requires.admin
Handling deprecation for hadoop.registry.zk.retry.ceiling.ms
Handling deprecation for nfs.rtmax
Handling deprecation for dfs.datanode.data.dir.perm
Handling deprecation for yarn.resourcemanager.container.liveness-monitor.interval-ms
Handling deprecation for yarn.nodemanager.env-whitelist
Handling deprecation for dfs.namenode.backup.address
Handling deprecation for dfs.namenode.xattrs.enabled
Handling deprecation for dfs.datanode.readahead.bytes
Handling deprecation for mapreduce.jobhistory.cleaner.enable
Handling deprecation for dfs.client.block.write.retries
Handling deprecation for mapreduce.tasktracker.http.address
Handling deprecation for yarn.nodemanager.linux-container-executor.cgroups.hierarchy
Handling deprecation for ha.failover-controller.graceful-fence.connection.retries
Handling deprecation for yarn.resourcemanager.recovery.enabled
Handling deprecation for yarn.app.mapreduce.am.container.log.backups
Handling deprecation for dfs.namenode.safemode.threshold-pct
Handling deprecation for yarn.nodemanager.disk-health-checker.interval-ms
Handling deprecation for hadoop.security.java.secure.random.algorithm
Handling deprecation for dfs.namenode.list.cache.directives.num.responses
Handling deprecation for dfs.datanode.dns.nameserver
Handling deprecation for mapreduce.cluster.temp.dir
Handling deprecation for fs.s3a.max.total.tasks
Handling deprecation for mapreduce.reduce.maxattempts
Handling deprecation for mapreduce.client.submit.file.replication
Handling deprecation for mapreduce.shuffle.port
Handling deprecation for yarn.resourcemanager.resource-tracker.client.thread-count
Handling deprecation for dfs.namenode.replication.considerLoad
Handling deprecation for dfs.namenode.edits.journal-plugin.qjournal
Handling deprecation for dfs.client.write.exclude.nodes.cache.expiry.interval.millis
Handling deprecation for yarn.nodemanager.delete.thread-count
Handling deprecation for dfs.client.mmap.cache.timeout.ms
Handling deprecation for yarn.nodemanager.admin-env
Handling deprecation for io.skip.checksum.errors
Handling deprecation for yarn.timeline-service.hostname
Handling deprecation for yarn.resourcemanager.proxy-user-privileges.enabled
Handling deprecation for mapreduce.job.speculative.speculative-cap-total-tasks
Handling deprecation for yarn.acl.enable
Handling deprecation for fs.s3a.fast.upload
Handling deprecation for file.blocksize
Handling deprecation for mapreduce.job.speculative.slowtaskthreshold
Handling deprecation for ftp.replication
Handling deprecation for yarn.sharedcache.cleaner.initial-delay-mins
Handling deprecation for s3native.client-write-packet-size
Handling deprecation for hadoop.rpc.socket.factory.class.default
Handling deprecation for file.bytes-per-checksum
Handling deprecation for dfs.datanode.slow.io.warning.threshold.ms
Handling deprecation for io.seqfile.lazydecompress
Handling deprecation for mapreduce.task.skip.start.attempts
Handling deprecation for dfs.namenode.reject-unresolved-dn-topology-mapping
Handling deprecation for hadoop.common.configuration.version
Handling deprecation for yarn.resourcemanager.client.thread-count
Handling deprecation for dfs.datanode.drop.cache.behind.reads
Handling deprecation for yarn.sharedcache.admin.address
Handling deprecation for mapreduce.job.output.value.class
Handling deprecation for mapreduce.output.fileoutputformat.outputdir
Handling deprecation for mapreduce.jobtracker.taskcache.levels
Handling deprecation for yarn.nodemanager.linux-container-executor.nonsecure-mode.user-pattern
Handling deprecation for yarn.resourcemanager.zk-timeout-ms
Handling deprecation for yarn.resourcemanager.max-completed-applications
Handling deprecation for mapreduce.job.jvm.numtasks
Handling deprecation for yarn.sharedcache.cleaner.period-mins
Handling deprecation for mapreduce.jobtracker.tasktracker.maxblacklists
Handling deprecation for dfs.namenode.top.num.users
Handling deprecation for yarn.nodemanager.linux-container-executor.cgroups.mount
Handling deprecation for yarn.sharedcache.checksum.algo.impl
Handling deprecation for mapreduce.job.end-notification.max.retry.interval
Handling deprecation for mapreduce.job.acl-view-job
Handling deprecation for mapreduce.job.classloader
Handling deprecation for yarn.log-aggregation-enable
Handling deprecation for mapreduce.reduce.shuffle.fetch.retry.interval-ms
Handling deprecation for yarn.resourcemanager.nodemanager.minimum.version
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.size
Handling deprecation for yarn.app.mapreduce.am.job.task.listener.thread-count
Handling deprecation for yarn.app.mapreduce.am.resource.cpu-vcores
Handling deprecation for dfs.namenode.edit.log.autoroll.check.interval.ms
Handling deprecation for mapreduce.output.fileoutputformat.compress.type
Handling deprecation for hadoop.hdfs.configuration.version
Handling deprecation for hadoop.security.group.mapping.ldap.search.attr.member
Handling deprecation for yarn.nodemanager.log.retain-seconds
Handling deprecation for yarn.nodemanager.local-cache.max-files-per-directory
Handling deprecation for mapreduce.job.end-notification.retry.interval
Handling deprecation for hadoop.ssl.client.conf
Handling deprecation for yarn.sharedcache.root-dir
Handling deprecation for dfs.journalnode.https-address
Handling deprecation for mapreduce.reduce.shuffle.fetch.retry.timeout-ms
Handling deprecation for dfs.bytes-per-checksum
Handling deprecation for dfs.namenode.max.objects
Handling deprecation for mapreduce.tasktracker.instrumentation
Handling deprecation for dfs.datanode.max.transfer.threads
Handling deprecation for dfs.block.access.key.update.interval
Handling deprecation for mapreduce.jobtracker.jobhistory.task.numberprogresssplits
Handling deprecation for mapreduce.map.memory.mb
Handling deprecation for ha.failover-controller.new-active.rpc-timeout.ms
Handling deprecation for hadoop.ssl.hostname.verifier
Handling deprecation for dfs.client.read.shortcircuit
Handling deprecation for dfs.datanode.hdfs-blocks-metadata.enabled
Handling deprecation for mapreduce.tasktracker.healthchecker.interval
Handling deprecation for dfs.image.transfer.chunksize
Handling deprecation for mapreduce.tasktracker.taskmemorymanager.monitoringinterval
Handling deprecation for dfs.client.https.keystore.resource
Handling deprecation for yarn.resourcemanager.connect.retry-interval.ms
Handling deprecation for yarn.timeline-service.webapp.address
Handling deprecation for s3native.blocksize
Handling deprecation for yarn.scheduler.minimum-allocation-mb
Handling deprecation for yarn.sharedcache.cleaner.resource-sleep-ms
Handling deprecation for net.topology.impl
Handling deprecation for dfs.client.failover.sleep.base.millis
Handling deprecation for dfs.permissions.superusergroup
Handling deprecation for io.seqfile.compress.blocksize
Handling deprecation for hadoop.registry.zk.retry.times
Handling deprecation for fs.AbstractFileSystem.ftp.impl
Handling deprecation for dfs.namenode.checkpoint.edits.dir
Handling deprecation for mapreduce.job.running.reduce.limit
Handling deprecation for dfs.blockreport.initialDelay
Handling deprecation for dfs.namenode.heartbeat.recheck-interval
Handling deprecation for dfs.namenode.safemode.extension
Handling deprecation for yarn.scheduler.maximum-allocation-mb
Handling deprecation for mapreduce.job.reduce.shuffle.consumer.plugin.class
Handling deprecation for yarn.nodemanager.vmem-check-enabled
Handling deprecation for mapreduce.task.io.sort.factor
Handling deprecation for mapreduce.jobtracker.persist.jobstatus.dir
Handling deprecation for dfs.client.failover.sleep.max.millis
Handling deprecation for dfs.namenode.delegation.key.update-interval
Handling deprecation for hadoop.rpc.protection
Handling deprecation for fs.permissions.umask-mode
Handling deprecation for fs.s3.sleepTimeSeconds
Handling deprecation for ha.health-monitor.rpc-timeout.ms
Handling deprecation for hadoop.http.staticuser.user
Handling deprecation for fs.s3a.connection.maximum
Handling deprecation for yarn.nodemanager.linux-container-executor.nonsecure-mode.limit-users
Handling deprecation for fs.s3a.paging.maximum
Handling deprecation for fs.AbstractFileSystem.viewfs.impl
Handling deprecation for fs.ftp.host
Handling deprecation for yarn.nodemanager.linux-container-executor.nonsecure-mode.local-user
Handling deprecation for fs.s3a.impl
Handling deprecation for hadoop.http.authentication.kerberos.keytab
Handling deprecation for dfs.namenode.fs-limits.max-blocks-per-file
Handling deprecation for mapreduce.tasktracker.http.threads
Handling deprecation for mapreduce.tasktracker.dns.nameserver
Handling deprecation for yarn.resourcemanager.am-rm-tokens.master-key-rolling-interval-secs
Handling deprecation for dfs.client.block.write.replace-datanode-on-failure.enable
Handling deprecation for io.compression.codec.bzip2.library
Handling deprecation for mapreduce.map.skip.maxrecords
Handling deprecation for dfs.client.use.legacy.blockreader.local
Handling deprecation for dfs.namenode.checkpoint.dir
Handling deprecation for dfs.namenode.top.windows.minutes
Handling deprecation for mapreduce.job.maxtaskfailures.per.tracker
Handling deprecation for net.topology.node.switch.mapping.impl
Handling deprecation for mapreduce.shuffle.max.connections
Handling deprecation for mapreduce.jobhistory.loadedjobs.cache.size
Handling deprecation for dfs.storage.policy.enabled
Handling deprecation for yarn.client.application-client-protocol.poll-interval-ms
Handling deprecation for yarn.nodemanager.localizer.address
Handling deprecation for dfs.namenode.list.cache.pools.num.responses
Handling deprecation for nfs.server.port
Handling deprecation for mapreduce.client.output.filter
Handling deprecation for yarn.timeline-service.client.best-effort
Handling deprecation for ha.zookeeper.parent-znode
Handling deprecation for mapreduce.jobtracker.persist.jobstatus.hours
Handling deprecation for yarn.sharedcache.admin.thread-count
Handling deprecation for yarn.nodemanager.resource.cpu-vcores
Handling deprecation for dfs.datanode.block-pinning.enabled
Handling deprecation for mapreduce.jobhistory.http.policy
Handling deprecation for yarn.resourcemanager.webapp.delegation-token-auth-filter.enabled
Handling deprecation for mapreduce.job.speculative.retry-after-no-speculate
Handling deprecation for fs.s3a.attempts.maximum
Handling deprecation for s3native.stream-buffer-size
Handling deprecation for io.seqfile.local.dir
Handling deprecation for yarn.log-aggregation.retain-check-interval-seconds
Handling deprecation for fs.s3n.multipart.copy.block.size
Handling deprecation for dfs.encrypt.data.transfer.cipher.key.bitlength
Handling deprecation for dfs.datanode.sync.behind.writes
Handling deprecation for yarn.resourcemanager.zk-acl
Handling deprecation for hadoop.ssl.keystores.factory.class
Handling deprecation for mapreduce.job.split.metainfo.maxsize
Handling deprecation for fs.s3.maxRetries
Handling deprecation for hadoop.security.random.device.file.path
Handling deprecation for yarn.client.nodemanager-connect.max-wait-ms
Handling deprecation for dfs.namenode.stale.datanode.interval
Handling deprecation for mapreduce.task.io.sort.mb
Handling deprecation for yarn.resourcemanager.zk-state-store.parent-path
Handling deprecation for yarn.app.mapreduce.client-am.ipc.max-retries
Handling deprecation for fs.client.resolve.remote.symlinks
Handling deprecation for yarn.nodemanager.linux-container-executor.cgroups.strict-resource-usage
Handling deprecation for hadoop.ssl.enabled.protocols
Handling deprecation for mapreduce.reduce.cpu.vcores
Handling deprecation for yarn.client.failover-retries
Handling deprecation for mapreduce.jobhistory.address
Handling deprecation for hadoop.ssl.enabled
Handling deprecation for dfs.replication.max
Handling deprecation for dfs.namenode.name.dir
Handling deprecation for dfs.datanode.https.address
Handling deprecation for ipc.client.kill.max
Handling deprecation for mapreduce.job.committer.setup.cleanup.needed
Handling deprecation for dfs.client.domain.socket.data.traffic
Handling deprecation for yarn.nodemanager.localizer.cache.target-size-mb
Handling deprecation for yarn.resourcemanager.admin.client.thread-count
Handling deprecation for dfs.block.access.token.enable
Handling deprecation for mapreduce.job.speculative.retry-after-speculate
Handling deprecation for dfs.datanode.address
Handling deprecation for mapreduce.jobtracker.restart.recover
Handling deprecation for ipc.client.connect.max.retries
Handling deprecation for yarn.timeline-service.store-class
Handling deprecation for dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
Handling deprecation for hadoop.tmp.dir
Handling deprecation for dfs.datanode.handler.count
Handling deprecation for yarn.resourcemanager.ha.automatic-failover.embedded
Handling deprecation for yarn.timeline-service.ttl-ms
Handling deprecation for mapreduce.task.profile.map.params
Handling deprecation for yarn.resourcemanager.nodemanagers.heartbeat-interval-ms
Handling deprecation for mapreduce.map.speculative
Handling deprecation for yarn.timeline-service.recovery.enabled
Handling deprecation for mapreduce.job.map.class
Handling deprecation for dfs.namenode.resource.checked.volumes.minimum
Handling deprecation for yarn.nodemanager.recovery.dir
Handling deprecation for mapreduce.job.counters.max
Handling deprecation for yarn.resourcemanager.keytab
Handling deprecation for dfs.namenode.max.extra.edits.segments.retained
Handling deprecation for dfs.webhdfs.user.provider.user.pattern
Handling deprecation for dfs.client.mmap.enabled
Handling deprecation for mapreduce.map.log.level
Handling deprecation for dfs.client.file-block-storage-locations.timeout.millis
Handling deprecation for yarn.client.max-cached-nodemanagers-proxies
Handling deprecation for yarn.app.mapreduce.am.scheduler.heartbeat.interval-ms
Handling deprecation for hadoop.fuse.timer.period
Handling deprecation for fs.trash.checkpoint.interval
Handling deprecation for yarn.sharedcache.app-checker.class
Handling deprecation for dfs.journalnode.http-address
Handling deprecation for yarn.app.mapreduce.am.staging-dir
Handling deprecation for mapreduce.tasktracker.local.dir.minspacestart
Handling deprecation for yarn.nm.liveness-monitor.expiry-interval-ms
Handling deprecation for ha.health-monitor.check-interval.ms
Handling deprecation for mapreduce.reduce.shuffle.merge.percent
Handling deprecation for dfs.namenode.retrycache.heap.percent
Handling deprecation for yarn.nodemanager.docker-container-executor.exec-name
Handling deprecation for ipc.client.connect.timeout
Handling deprecation for yarn.resourcemanager.fs.state-store.retry-interval-ms
Handling deprecation for mapreduce.output.fileoutputformat.compress
Handling deprecation for yarn.nodemanager.local-dirs
Handling deprecation for yarn.nodemanager.recovery.enabled
Handling deprecation for io.native.lib.available
Handling deprecation for yarn.sharedcache.store.in-memory.staleness-period-mins
Handling deprecation for yarn.resourcemanager.am.max-attempts
Handling deprecation for s3.replication
Handling deprecation for mapreduce.input.fileinputformat.inputdir
Handling deprecation for fs.AbstractFileSystem.har.impl
Handling deprecation for dfs.image.compress
Handling deprecation for mapreduce.job.running.map.limit
Handling deprecation for mapreduce.reduce.input.buffer.percent
Handling deprecation for yarn.nodemanager.webapp.address
Handling deprecation for dfs.datanode.available-space-volume-choosing-policy.balanced-space-preference-fraction
Handling deprecation for dfs.namenode.edit.log.autoroll.multiplier.threshold
Handling deprecation for hadoop.security.group.mapping.ldap.ssl
Handling deprecation for dfs.namenode.checkpoint.check.period
Handling deprecation for fs.defaultFS
Handling deprecation for fs.s3a.multipart.size
Handling deprecation for dfs.client.slow.io.warning.threshold.ms
Handling deprecation for yarn.app.mapreduce.am.job.committer.commit-window
Handling deprecation for hadoop.security.group.mapping.ldap.search.attr.group.name
Handling deprecation for yarn.nodemanager.disk-health-checker.max-disk-utilization-per-disk-percentage
Handling deprecation for yarn.nodemanager.container-monitor.procfs-tree.smaps-based-rss.enabled
Handling deprecation for mapreduce.job.submithostname
Handling deprecation for mapreduce.map.sort.spill.percent
Handling deprecation for hadoop.security.crypto.codec.classes.aes.ctr.nopadding
Handling deprecation for dfs.namenode.http-address
Handling deprecation for hadoop.security.groups.negative-cache.secs
Handling deprecation for hadoop.ssl.server.conf
Handling deprecation for mapreduce.ifile.readahead
Handling deprecation for s3native.replication
Handling deprecation for yarn.client.nodemanager-client-async.thread-pool-max-size
Handling deprecation for mapreduce.jobtracker.staging.root.dir
Handling deprecation for mapreduce.jobhistory.admin.address
Handling deprecation for dfs.namenode.startup.delay.block.deletion.sec
Handling deprecation for yarn.nodemanager.health-checker.interval-ms
Handling deprecation for dfs.namenode.checkpoint.max-retries
Handling deprecation for s3.stream-buffer-size
Handling deprecation for ftp.client-write-packet-size
Handling deprecation for dfs.datanode.fsdatasetcache.max.threads.per.volume
Handling deprecation for mapreduce.output.fileoutputformat.compress.codec
Handling deprecation for yarn.timeline-service.keytab
Handling deprecation for yarn.sharedcache.store.in-memory.initial-delay-mins
Handling deprecation for mapreduce.jobhistory.webapp.address
Handling deprecation for mapreduce.task.userlog.limit.kb
Handling deprecation for mapreduce.reduce.shuffle.fetch.retry.enabled
Handling deprecation for yarn.app.mapreduce.task.container.log.backups
Handling deprecation for dfs.heartbeat.interval
Handling deprecation for ha.zookeeper.session-timeout.ms
Handling deprecation for fs.s3a.connection.ssl.enabled
Handling deprecation for yarn.sharedcache.webapp.address
Handling deprecation for hadoop.http.authentication.signature.secret.file
Handling deprecation for hadoop.fuse.connection.timeout
Handling deprecation for mapreduce.input.fileinputformat.numinputfiles
Handling deprecation for yarn.nodemanager.log-aggregation.compression-type
Handling deprecation for ipc.server.max.connections
Handling deprecation for yarn.resourcemanager.work-preserving-recovery.scheduling-wait-ms
Handling deprecation for yarn.nodemanager.log-dirs
Handling deprecation for yarn.app.mapreduce.am.resource.mb
Handling deprecation for hadoop.security.groups.cache.secs
Handling deprecation for mapreduce.job.speculative.minimum-allowed-tasks
Handling deprecation for yarn.nodemanager.container-monitor.interval-ms
Handling deprecation for dfs.datanode.cache.revocation.timeout.ms
Handling deprecation for mapreduce.jobhistory.recovery.store.class
Handling deprecation for mapreduce.task.combine.progress.records
Handling deprecation for s3.client-write-packet-size
Handling deprecation for mapreduce.jobtracker.instrumentation
Handling deprecation for dfs.replication
Handling deprecation for mapreduce.shuffle.transfer.buffer.size
Handling deprecation for hadoop.security.group.mapping.ldap.directory.search.timeout
Handling deprecation for dfs.datanode.available-space-volume-choosing-policy.balanced-space-threshold
Handling deprecation for hadoop.work.around.non.threadsafe.getpwuid
Handling deprecation for yarn.app.mapreduce.client-am.ipc.max-retries-on-timeouts
Handling deprecation for yarn.nodemanager.address
Handling deprecation for mapreduce.tasktracker.taskcontroller
Handling deprecation for mapreduce.tasktracker.indexcache.mb
Handling deprecation for yarn.scheduler.maximum-allocation-vcores
Handling deprecation for mapreduce.job.reduces
Handling deprecation for yarn.nodemanager.sleep-delay-before-sigkill.ms
Handling deprecation for yarn.timeline-service.address
Handling deprecation for yarn.resourcemanager.configuration.provider-class
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.expiry
Handling deprecation for yarn.sharedcache.enabled
Handling deprecation for tfile.io.chunk.size
Handling deprecation for mapreduce.job.acl-modify-job
Handling deprecation for hadoop.registry.zk.session.timeout.ms
Handling deprecation for fs.automatic.close
Handling deprecation for ha.health-monitor.sleep-after-disconnect.ms
Handling deprecation for mapreduce.tasktracker.reduce.tasks.maximum
Handling deprecation for mapreduce.input.fileinputformat.list-status.num-threads
Handling deprecation for dfs.datanode.directoryscan.threads
Handling deprecation for dfs.datanode.directoryscan.interval
Handling deprecation for dfs.namenode.acls.enabled
Handling deprecation for dfs.client.short.circuit.replica.stale.threshold.ms
Handling deprecation for hadoop.http.authentication.token.validity
Handling deprecation for fs.s3.block.size
Handling deprecation for ha.failover-controller.graceful-fence.rpc-timeout.ms
Handling deprecation for mapreduce.tasktracker.local.dir.minspacekill
Handling deprecation for dfs.namenode.resource.du.reserved
Handling deprecation for mapreduce.jobhistory.cleaner.interval-ms
Handling deprecation for dfs.namenode.datanode.registration.ip-hostname-check
Handling deprecation for mapreduce.jobhistory.intermediate-done-dir
Handling deprecation for mapreduce.jobtracker.http.address
Handling deprecation for dfs.namenode.backup.http-address
Handling deprecation for dfs.namenode.edits.noeditlogchannelflush
Handling deprecation for mapreduce.reduce.shuffle.input.buffer.percent
Handling deprecation for mapreduce.map.maxattempts
Handling deprecation for yarn.http.policy
Handling deprecation for dfs.namenode.audit.loggers
Handling deprecation for hadoop.security.groups.cache.warn.after.ms
Handling deprecation for io.serializations
Handling deprecation for mapreduce.tasktracker.outofband.heartbeat
Handling deprecation for mapreduce.reduce.shuffle.read.timeout
Handling deprecation for hadoop.security.crypto.buffer.size
Handling deprecation for mapreduce.reduce.skip.proc.count.autoincr
Handling deprecation for mapreduce.ifile.readahead.bytes
Handling deprecation for dfs.http.policy
Handling deprecation for hadoop.registry.secure
Handling deprecation for dfs.namenode.safemode.min.datanodes
Handling deprecation for dfs.client.file-block-storage-locations.num-threads
Handling deprecation for mapreduce.cluster.local.dir
Handling deprecation for mapreduce.tasktracker.report.address
Handling deprecation for dfs.namenode.secondary.https-address
Handling deprecation for hadoop.kerberos.kinit.command
Handling deprecation for yarn.timeline-service.http-authentication.type
Handling deprecation for dfs.block.access.token.lifetime
Handling deprecation for dfs.webhdfs.enabled
Handling deprecation for dfs.namenode.delegation.token.max-lifetime
Handling deprecation for dfs.namenode.avoid.write.stale.datanode
Handling deprecation for dfs.datanode.drop.cache.behind.writes
Handling deprecation for yarn.log-aggregation.retain-seconds
Handling deprecation for mapreduce.job.complete.cancel.delegation.tokens
Handling deprecation for mapreduce.local.clientfactory.class.name
Handling deprecation for mapreduce.shuffle.connection-keep-alive.timeout
Handling deprecation for dfs.namenode.num.extra.edits.retained
Handling deprecation for yarn.scheduler.minimum-allocation-vcores
Handling deprecation for ipc.client.connect.max.retries.on.timeouts
Handling deprecation for yarn.timeline-service.client.retry-interval-ms
Handling deprecation for yarn.timeline-service.client.max-retries
Handling deprecation for fs.s3n.block.size
Handling deprecation for mapreduce.job.map.output.collector.class
Handling deprecation for ha.health-monitor.connect-retry-interval.ms
Handling deprecation for mapreduce.shuffle.max.threads
Handling deprecation for nfs.exports.allowed.hosts
Handling deprecation for dfs.client.mmap.cache.size
Handling deprecation for mapreduce.tasktracker.map.tasks.maximum
Handling deprecation for io.file.buffer.size
Handling deprecation for dfs.client.datanode-restart.timeout
Handling deprecation for io.mapfile.bloom.size
Handling deprecation for hadoop.security.kms.client.authentication.retry-count
Handling deprecation for dfs.namenode.checkpoint.txns
Handling deprecation for ipc.client.connect.retry.interval
Handling deprecation for dfs.client-write-packet-size
Handling deprecation for mapreduce.reduce.shuffle.connect.timeout
Handling deprecation for yarn.resourcemanager.fs.state-store.uri
Handling deprecation for fs.swift.impl
Handling deprecation for hadoop.registry.zk.connection.timeout.ms
Handling deprecation for mapred.queue.default.acl-administer-jobs
Handling deprecation for mapreduce.job.submithostaddress
Handling deprecation for dfs.cachereport.intervalMsec
Handling deprecation for yarn.app.mapreduce.shuffle.log.backups
Handling deprecation for yarn.app.mapreduce.am.container.log.limit.kb
Handling deprecation for yarn.nodemanager.resourcemanager.minimum.version
Handling deprecation for ftp.blocksize
Handling deprecation for yarn.resourcemanager.address
Handling deprecation for file.stream-buffer-size
Handling deprecation for yarn.resourcemanager.scheduler.monitor.enable
Handling deprecation for mapreduce.job.ubertask.maxreduces
Handling deprecation for nfs.allow.insecure.ports
Handling deprecation for yarn.sharedcache.nm.uploader.thread-count
Handling deprecation for ipc.client.idlethreshold
Handling deprecation for ftp.stream-buffer-size
Handling deprecation for yarn.sharedcache.client-server.address
Handling deprecation for dfs.client.failover.connection.retries.on.timeouts
Handling deprecation for dfs.namenode.replication.work.multiplier.per.iteration
Handling deprecation for hadoop.http.authentication.simple.anonymous.allowed
Handling deprecation for hadoop.security.authorization
Handling deprecation for yarn.client.nodemanager-connect.retry-interval-ms
Handling deprecation for yarn.am.liveness-monitor.expiry-interval-ms
Handling deprecation for fs.har.impl.disable.cache
Handling deprecation for yarn.nodemanager.linux-container-executor.resources-handler.class
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.read-cache-size
Handling deprecation for hadoop.security.authentication
Handling deprecation for dfs.image.compression.codec
Handling deprecation for mapreduce.task.files.preserve.failedtasks
Handling deprecation for dfs.client.read.shortcircuit.streams.cache.size
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.path
Handling deprecation for mapreduce.job.reduce.slowstart.completedmaps
Handling deprecation for mapreduce.jobhistory.minicluster.fixed.ports
Handling deprecation for file.replication
Handling deprecation for yarn.resourcemanager.ha.automatic-failover.enabled
Handling deprecation for mapreduce.job.userlog.retain.hours
Handling deprecation for mapreduce.jobhistory.joblist.cache.size
Handling deprecation for dfs.namenode.accesstime.precision
Handling deprecation for yarn.resourcemanager.work-preserving-recovery.enabled
Handling deprecation for dfs.namenode.fs-limits.max-xattrs-per-inode
Handling deprecation for io.mapfile.bloom.error.rate
Handling deprecation for yarn.resourcemanager.store.class
Handling deprecation for dfs.image.transfer.timeout
Handling deprecation for yarn.timeline-service.leveldb-state-store.path
Handling deprecation for nfs.wtmax
Handling deprecation for mapreduce.job.combine.class
Handling deprecation for dfs.namenode.support.allow.format
Handling deprecation for fs.s3a.multipart.purge
Handling deprecation for dfs.secondary.namenode.kerberos.internal.spnego.principal
Handling deprecation for fs.s3a.connection.establish.timeout
Handling deprecation for dfs.stream-buffer-size
Handling deprecation for dfs.namenode.invalidate.work.pct.per.iteration
Handling deprecation for yarn.nodemanager.container-executor.class
Handling deprecation for fs.s3a.multipart.purge.age
Handling deprecation for yarn.resourcemanager.scheduler.client.thread-count
Handling deprecation for dfs.namenode.top.enabled
Handling deprecation for yarn.app.mapreduce.shuffle.log.separate
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.low-watermark
Handling deprecation for fs.s3a.fast.buffer.size
Handling deprecation for hadoop.user.group.static.mapping.overrides
Handling deprecation for tfile.fs.input.buffer.size
Handling deprecation for dfs.client.cached.conn.retry
Handling deprecation for hadoop.http.authentication.type
Handling deprecation for dfs.namenode.list.encryption.zones.num.responses
Handling deprecation for mapreduce.map.cpu.vcores
Handling deprecation for dfs.namenode.path.based.cache.refresh.interval.ms
Handling deprecation for dfs.namenode.decommission.interval
Handling deprecation for dfs.namenode.fs-limits.max-directory-items
Handling deprecation for yarn.resourcemanager.zk-retry-interval-ms
Handling deprecation for ftp.bytes-per-checksum
Handling deprecation for dfs.ha.log-roll.period
Handling deprecation for dfs.user.home.dir.prefix
Handling deprecation for ipc.client.fallback-to-simple-auth-allowed
Handling deprecation for yarn.nodemanager.pmem-check-enabled
Handling deprecation for yarn.nodemanager.remote-app-log-dir
Handling deprecation for dfs.namenode.inotify.max.events.per.rpc
Handling deprecation for mapreduce.task.profile.maps
Handling deprecation for mapreduce.shuffle.ssl.file.buffer.size
Handling deprecation for mapreduce.tasktracker.healthchecker.script.timeout
Handling deprecation for yarn.timeline-service.webapp.https.address
Handling deprecation for yarn.nodemanager.resource.percentage-physical-cpu-limit
Handling deprecation for yarn.app.mapreduce.am.command-opts
Handling deprecation for dfs.namenode.fs-limits.max-xattr-size
Handling deprecation for dfs.datanode.http.address
Handling deprecation for dfs.namenode.blocks.per.postponedblocks.rescan
Handling deprecation for yarn.sharedcache.nm.uploader.replication.factor
Handling deprecation for hadoop.registry.zk.root
Handling deprecation for hadoop.jetty.logs.serve.aliases
Handling deprecation for yarn.client.failover-proxy-provider
Handling deprecation for mapreduce.jobhistory.admin.acl
Handling deprecation for yarn.app.mapreduce.am.hard-kill-timeout-ms
Handling deprecation for yarn.nodemanager.remote-app-log-dir-suffix
Handling deprecation for mapreduce.jobhistory.principal
Handling deprecation for yarn.resourcemanager.webapp.address
Handling deprecation for mapreduce.jobhistory.recovery.enable
Handling deprecation for yarn.sharedcache.store.in-memory.check-period-mins
Handling deprecation for nfs.mountd.port
Handling deprecation for mapreduce.reduce.merge.inmem.threshold
Handling deprecation for fs.df.interval
Handling deprecation for yarn.timeline-service.enabled
Handling deprecation for mapreduce.jobtracker.jobhistory.lru.cache.size
Handling deprecation for mapreduce.task.profile
Handling deprecation for mapreduce.job.output.key.class
Handling deprecation for yarn.nodemanager.hostname
Handling deprecation for dfs.namenode.num.checkpoints.retained
Handling deprecation for mapreduce.job.queuename
Handling deprecation for mapreduce.jobhistory.max-age-ms
Handling deprecation for mapreduce.job.token.tracking.ids.enabled
Handling deprecation for yarn.nodemanager.localizer.client.thread-count
Handling deprecation for yarn.sharedcache.uploader.server.thread-count
Handling deprecation for dfs.client.mmap.retry.timeout.ms
Handling deprecation for mapreduce.jobhistory.move.thread-count
Handling deprecation for dfs.permissions.enabled
Handling deprecation for dfs.blockreport.split.threshold
Handling deprecation for fs.AbstractFileSystem.hdfs.impl
Handling deprecation for dfs.datanode.balance.bandwidthPerSec
Handling deprecation for dfs.block.scanner.volume.bytes.per.second
Handling deprecation for hadoop.http.filter.initializers
Handling deprecation for yarn.timeline-service.http-authentication.simple.anonymous.allowed
Handling deprecation for dfs.default.chunk.view.size
Handling deprecation for yarn.sharedcache.client-server.thread-count
Handling deprecation for yarn.resourcemanager.resource-tracker.address
Handling deprecation for mapreduce.job.working.dir
Handling deprecation for mapreduce.jobhistory.datestring.cache.size
Handling deprecation for mapreduce.task.profile.params
Handling deprecation for dfs.namenode.decommission.blocks.per.interval
Handling deprecation for dfs.namenode.handler.count
Handling deprecation for dfs.image.transfer.bandwidthPerSec
Handling deprecation for rpc.metrics.quantile.enable
Handling deprecation for mapreduce.jobtracker.expire.trackers.interval
Handling deprecation for mapreduce.task.timeout
Handling deprecation for yarn.app.mapreduce.client.max-retries
Handling deprecation for yarn.nodemanager.resource.memory-mb
Handling deprecation for yarn.nodemanager.disk-health-checker.min-healthy-disks
Handling deprecation for dfs.datanode.failed.volumes.tolerated
Handling deprecation for yarn.timeline-service.handler-thread-count
Handling deprecation for ipc.server.listen.queue.size
Handling deprecation for fs.s3a.threads.max
Handling deprecation for yarn.resourcemanager.connect.max-wait.ms
Handling deprecation for mapreduce.fileoutputcommitter.algorithm.version
Handling deprecation for mapreduce.framework.name
Handling deprecation for mapreduce.map.skip.proc.count.autoincr
Handling deprecation for mapreduce.job.max.split.locations
Handling deprecation for yarn.resourcemanager.scheduler.class
Handling deprecation for yarn.resourcemanager.system-metrics-publisher.enabled
Handling deprecation for dfs.blocksize
Handling deprecation for yarn.sharedcache.nested-level
Handling deprecation for mapreduce.shuffle.connection-keep-alive.enable
Handling deprecation for fs.s3a.threads.keepalivetime
Handling deprecation for fs.s3a.connection.timeout
Handling deprecation for file.client-write-packet-size
Handling deprecation for ha.failover-controller.cli-check.rpc-timeout.ms
Handling deprecation for ha.zookeeper.acl
Handling deprecation for dfs.namenode.write.stale.datanode.ratio
Handling deprecation for dfs.encrypt.data.transfer
Handling deprecation for dfs.datanode.shared.file.descriptor.paths
Handling deprecation for mapreduce.input.lineinputformat.linespermap
Handling deprecation for yarn.resourcemanager.delayed.delegation-token.removal-interval-ms
Handling deprecation for yarn.nodemanager.localizer.fetch.thread-count
Handling deprecation for dfs.client.failover.max.attempts
Handling deprecation for yarn.resourcemanager.scheduler.address
Handling deprecation for dfs.client.read.shortcircuit.streams.cache.expiry.ms
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.start-time-write-cache-size
Handling deprecation for yarn.nodemanager.health-checker.script.timeout-ms
Handling deprecation for yarn.resourcemanager.fs.state-store.num-retries
Handling deprecation for hadoop.ssl.require.client.cert
Handling deprecation for hadoop.security.uid.cache.secs
Handling deprecation for mapreduce.jobhistory.keytab
Handling deprecation for dfs.client.read.shortcircuit.skip.checksum
Handling deprecation for yarn.resourcemanager.ha.automatic-failover.zk-base-path
Handling deprecation for mapreduce.shuffle.ssl.enabled
Handling deprecation for mapreduce.reduce.log.level
Handling deprecation for hadoop.registry.rm.enabled
Handling deprecation for mapreduce.tasktracker.dns.interface
Handling deprecation for yarn.resourcemanager.system-metrics-publisher.dispatcher.pool-size
Handling deprecation for mapreduce.job.speculative.speculative-cap-running-tasks
Handling deprecation for dfs.datanode.block.id.layout.upgrade.threads
Handling deprecation for dfs.datanode.use.datanode.hostname
Handling deprecation for dfs.client.context
Handling deprecation for yarn.resourcemanager.ha.enabled
Handling deprecation for mapred.reducer.new-api
Handling deprecation for dfs.namenode.delegation.token.renew-interval
Handling deprecation for dfs.blockreport.intervalMsec
Handling deprecation for fs.s3a.multipart.threshold
Handling deprecation for mapreduce.reduce.shuffle.memory.limit.percent
Handling deprecation for dfs.https.server.keystore.resource
Handling deprecation for io.map.index.skip
Handling deprecation for mapreduce.job.hdfs-servers
Handling deprecation for mapreduce.jobtracker.taskscheduler
Handling deprecation for dfs.namenode.kerberos.internal.spnego.principal
Handling deprecation for yarn.resourcemanager.state-store.max-completed-applications
Handling deprecation for mapreduce.map.output.compress
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.num.refill.threads
Handling deprecation for fs.s3n.multipart.uploads.block.size
Handling deprecation for mapreduce.task.merge.progress.records
Handling deprecation for dfs.datanode.dns.interface
Handling deprecation for map.sort.class
Handling deprecation for yarn.nodemanager.aux-services.mapreduce_shuffle.class
Handling deprecation for tfile.fs.output.buffer.size
Handling deprecation for fs.du.interval
Handling deprecation for dfs.client.failover.connection.retries
Handling deprecation for dfs.namenode.top.window.num.buckets
Handling deprecation for mapreduce.job.dir
Handling deprecation for fs.s3a.buffer.dir
Handling deprecation for mapreduce.reduce.shuffle.retry-delay.max.ms
Handling deprecation for yarn.sharedcache.uploader.server.address
Handling deprecation for mapreduce.client.progressmonitor.pollinterval
Handling deprecation for yarn.app.mapreduce.shuffle.log.limit.kb
Handling deprecation for dfs.datanode.max.locked.memory
Handling deprecation for dfs.namenode.retrycache.expirytime.millis
Handling deprecation for dfs.datanode.scan.period.hours
Handling deprecation for dfs.client.block.write.replace-datanode-on-failure.best-effort
Handling deprecation for mapreduce.jobhistory.move.interval-ms
Handling deprecation for dfs.ha.fencing.ssh.connect-timeout
Handling deprecation for yarn.nodemanager.log-aggregation.roll-monitoring-interval-seconds
Handling deprecation for dfs.namenode.fs-limits.max-component-length
Handling deprecation for hadoop.registry.zk.quorum
Handling deprecation for dfs.namenode.enable.retrycache
Handling deprecation for dfs.datanode.du.reserved
Handling deprecation for yarn.timeline-service.state-store-class
Handling deprecation for dfs.datanode.ipc.address
Handling deprecation for hadoop.registry.system.acls
Handling deprecation for dfs.client.block.write.replace-datanode-on-failure.policy
Handling deprecation for dfs.namenode.path.based.cache.retry.interval.ms
Handling deprecation for hadoop.security.crypto.cipher.suite
Handling deprecation for dfs.ha.tail-edits.period
Handling deprecation for mapreduce.task.profile.reduce.params
Handling deprecation for hadoop.registry.jaas.context
Handling deprecation for yarn.resourcemanager.hostname
Handling deprecation for mapreduce.reduce.memory.mb
Handling deprecation for hadoop.security.group.mapping.ldap.search.filter.group
Handling deprecation for hadoop.http.authentication.kerberos.principal
Handling deprecation for hadoop.security.group.mapping.ldap.search.filter.user
Handling deprecation for yarn.nodemanager.disk-health-checker.min-free-space-per-disk-mb
Handling deprecation for dfs.namenode.edits.dir
Handling deprecation for yarn.client.failover-retries-on-socket-timeouts
Handling deprecation for dfs.namenode.decommission.max.concurrent.tracked.nodes
Handling deprecation for mapreduce.client.completion.pollinterval
Handling deprecation for dfs.namenode.name.dir.restore
Handling deprecation for dfs.namenode.secondary.http-address
Handling deprecation for mapreduce.jobhistory.recovery.store.leveldb.path
Handling deprecation for yarn.sharedcache.store.class
Handling deprecation for s3.bytes-per-checksum
Handling deprecation for yarn.nodemanager.windows-container.cpu-limit.enabled
Handling deprecation for yarn.resourcemanager.webapp.https.address
Handling deprecation for yarn.nodemanager.vmem-pmem-ratio
Handling deprecation for dfs.namenode.checkpoint.period
Handling deprecation for dfs.ha.automatic-failover.enabled
Submitting tokens for job: job_local737491137_0002
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.fs.FileContext.getAbstractFileSystem(FileContext.java:331)
Handling deprecation for all properties in config...
Handling deprecation for mapreduce.jobtracker.address
Handling deprecation for yarn.resourcemanager.scheduler.monitor.policies
Handling deprecation for dfs.namenode.resource.check.interval
Handling deprecation for mapreduce.jobhistory.client.thread-count
Handling deprecation for yarn.app.mapreduce.am.containerlauncher.threadpool-initial-size
Handling deprecation for mapred.child.java.opts
Handling deprecation for mapreduce.jobtracker.retiredjobs.cache.size
Handling deprecation for dfs.client.https.need-auth
Handling deprecation for yarn.admin.acl
Handling deprecation for yarn.app.mapreduce.am.job.committer.cancel-timeout
Handling deprecation for mapreduce.job.emit-timeline-data
Handling deprecation for fs.ftp.host.port
Handling deprecation for dfs.namenode.avoid.read.stale.datanode
Handling deprecation for dfs.journalnode.rpc-address
Handling deprecation for mapreduce.job.end-notification.retry.attempts
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.ttl-interval-ms
Handling deprecation for yarn.resourcemanager.leveldb-state-store.path
Handling deprecation for mapred.mapper.new-api
Handling deprecation for yarn.ipc.rpc.class
Handling deprecation for ipc.client.connection.maxidletime
Handling deprecation for yarn.nodemanager.process-kill-wait.ms
Handling deprecation for mapreduce.cluster.acls.enabled
Handling deprecation for mapreduce.jobtracker.handler.count
Handling deprecation for io.map.index.interval
Handling deprecation for dfs.namenode.https-address
Handling deprecation for mapreduce.task.profile.reduces
Handling deprecation for fs.s3n.multipart.uploads.enabled
Handling deprecation for io.seqfile.sorter.recordlimit
Handling deprecation for mapreduce.job.ubertask.maxmaps
Handling deprecation for mapreduce.tasktracker.tasks.sleeptimebeforesigkill
Handling deprecation for hadoop.util.hash.type
Handling deprecation for dfs.namenode.replication.min
Handling deprecation for yarn.nodemanager.container-manager.thread-count
Handling deprecation for mapreduce.jobtracker.jobhistory.block.size
Handling deprecation for dfs.namenode.fs-limits.min-block-size
Handling deprecation for mapreduce.app-submission.cross-platform
Handling deprecation for fs.AbstractFileSystem.file.impl
Handling deprecation for net.topology.script.number.args
Handling deprecation for yarn.resourcemanager.container-tokens.master-key-rolling-interval-secs
Handling deprecation for mapreduce.map.output.compress.codec
Handling deprecation for mapreduce.job.reducer.preempt.delay.sec
Handling deprecation for s3native.bytes-per-checksum
Handling deprecation for dfs.namenode.path.based.cache.block.map.allocation.percent
Handling deprecation for yarn.nodemanager.windows-container.memory-limit.enabled
Handling deprecation for mapreduce.input.fileinputformat.split.minsize
Handling deprecation for hadoop.security.group.mapping
Handling deprecation for mapreduce.jobtracker.system.dir
Handling deprecation for mapreduce.job.end-notification.max.attempts
Handling deprecation for mapreduce.reduce.markreset.buffer.percent
Handling deprecation for dfs.datanode.cache.revocation.polling.ms
Handling deprecation for mapreduce.reduce.speculative
Handling deprecation for yarn.nodemanager.localizer.cache.cleanup.interval-ms
Handling deprecation for dfs.namenode.lazypersist.file.scrub.interval.sec
Handling deprecation for fs.s3a.threads.core
Handling deprecation for mapreduce.jobhistory.recovery.store.fs.uri
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.start-time-read-cache-size
Handling deprecation for hadoop.registry.zk.retry.interval.ms
Handling deprecation for yarn.nodemanager.keytab
Handling deprecation for dfs.namenode.replication.interval
Handling deprecation for yarn.resourcemanager.admin.address
Handling deprecation for mapreduce.job.maps
Handling deprecation for nfs.dump.dir
Handling deprecation for mapreduce.job.user.name
Handling deprecation for mapreduce.jobtracker.maxtasks.perjob
Handling deprecation for mapreduce.job.ubertask.enable
Handling deprecation for mapreduce.job.reduce.class
Handling deprecation for yarn.nodemanager.delete.debug-delay-sec
Handling deprecation for yarn.timeline-service.ttl-enable
Handling deprecation for yarn.resourcemanager.fs.state-store.retry-policy-spec
Handling deprecation for mapreduce.reduce.skip.maxgroups
Handling deprecation for dfs.client.use.datanode.hostname
Handling deprecation for fs.trash.interval
Handling deprecation for mapreduce.job.name
Handling deprecation for mapreduce.am.max-attempts
Handling deprecation for mapreduce.jobtracker.heartbeats.in.second
Handling deprecation for yarn.resourcemanager.zk-num-retries
Handling deprecation for s3.blocksize
Handling deprecation for dfs.datanode.data.dir
Handling deprecation for mapreduce.jobtracker.persist.jobstatus.active
Handling deprecation for mapreduce.reduce.shuffle.parallelcopies
Handling deprecation for fs.s3.buffer.dir
Handling deprecation for mapreduce.jobhistory.done-dir
Handling deprecation for hadoop.security.instrumentation.requires.admin
Handling deprecation for hadoop.registry.zk.retry.ceiling.ms
Handling deprecation for nfs.rtmax
Handling deprecation for dfs.datanode.data.dir.perm
Handling deprecation for yarn.resourcemanager.container.liveness-monitor.interval-ms
Handling deprecation for yarn.nodemanager.env-whitelist
Handling deprecation for dfs.namenode.backup.address
Handling deprecation for dfs.namenode.xattrs.enabled
Handling deprecation for dfs.datanode.readahead.bytes
Handling deprecation for mapreduce.jobhistory.cleaner.enable
Handling deprecation for dfs.client.block.write.retries
Handling deprecation for mapreduce.tasktracker.http.address
Handling deprecation for yarn.nodemanager.linux-container-executor.cgroups.hierarchy
Handling deprecation for ha.failover-controller.graceful-fence.connection.retries
Handling deprecation for yarn.resourcemanager.recovery.enabled
Handling deprecation for yarn.app.mapreduce.am.container.log.backups
Handling deprecation for dfs.namenode.safemode.threshold-pct
Handling deprecation for yarn.nodemanager.disk-health-checker.interval-ms
Handling deprecation for hadoop.security.java.secure.random.algorithm
Handling deprecation for dfs.namenode.list.cache.directives.num.responses
Handling deprecation for dfs.datanode.dns.nameserver
Handling deprecation for mapreduce.cluster.temp.dir
Handling deprecation for fs.s3a.max.total.tasks
Handling deprecation for mapreduce.reduce.maxattempts
Handling deprecation for mapreduce.client.submit.file.replication
Handling deprecation for mapreduce.shuffle.port
Handling deprecation for yarn.resourcemanager.resource-tracker.client.thread-count
Handling deprecation for dfs.namenode.replication.considerLoad
Handling deprecation for dfs.namenode.edits.journal-plugin.qjournal
Handling deprecation for dfs.client.write.exclude.nodes.cache.expiry.interval.millis
Handling deprecation for yarn.nodemanager.delete.thread-count
Handling deprecation for dfs.client.mmap.cache.timeout.ms
Handling deprecation for yarn.nodemanager.admin-env
Handling deprecation for io.skip.checksum.errors
Handling deprecation for yarn.timeline-service.hostname
Handling deprecation for yarn.resourcemanager.proxy-user-privileges.enabled
Handling deprecation for mapreduce.job.speculative.speculative-cap-total-tasks
Handling deprecation for yarn.acl.enable
Handling deprecation for fs.s3a.fast.upload
Handling deprecation for file.blocksize
Handling deprecation for mapreduce.job.speculative.slowtaskthreshold
Handling deprecation for ftp.replication
Handling deprecation for yarn.sharedcache.cleaner.initial-delay-mins
Handling deprecation for s3native.client-write-packet-size
Handling deprecation for hadoop.rpc.socket.factory.class.default
Handling deprecation for file.bytes-per-checksum
Handling deprecation for dfs.datanode.slow.io.warning.threshold.ms
Handling deprecation for io.seqfile.lazydecompress
Handling deprecation for mapreduce.task.skip.start.attempts
Handling deprecation for dfs.namenode.reject-unresolved-dn-topology-mapping
Handling deprecation for hadoop.common.configuration.version
Handling deprecation for yarn.resourcemanager.client.thread-count
Handling deprecation for dfs.datanode.drop.cache.behind.reads
Handling deprecation for yarn.sharedcache.admin.address
Handling deprecation for mapreduce.job.output.value.class
Handling deprecation for mapreduce.output.fileoutputformat.outputdir
Handling deprecation for mapreduce.jobtracker.taskcache.levels
Handling deprecation for yarn.nodemanager.linux-container-executor.nonsecure-mode.user-pattern
Handling deprecation for yarn.resourcemanager.zk-timeout-ms
Handling deprecation for yarn.resourcemanager.max-completed-applications
Handling deprecation for mapreduce.job.jvm.numtasks
Handling deprecation for yarn.sharedcache.cleaner.period-mins
Handling deprecation for mapreduce.jobtracker.tasktracker.maxblacklists
Handling deprecation for dfs.namenode.top.num.users
Handling deprecation for yarn.nodemanager.linux-container-executor.cgroups.mount
Handling deprecation for yarn.sharedcache.checksum.algo.impl
Handling deprecation for mapreduce.job.end-notification.max.retry.interval
Handling deprecation for mapreduce.job.acl-view-job
Handling deprecation for mapreduce.job.classloader
Handling deprecation for yarn.log-aggregation-enable
Handling deprecation for mapreduce.reduce.shuffle.fetch.retry.interval-ms
Handling deprecation for yarn.resourcemanager.nodemanager.minimum.version
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.size
Handling deprecation for yarn.app.mapreduce.am.job.task.listener.thread-count
Handling deprecation for yarn.app.mapreduce.am.resource.cpu-vcores
Handling deprecation for dfs.namenode.edit.log.autoroll.check.interval.ms
Handling deprecation for mapreduce.output.fileoutputformat.compress.type
Handling deprecation for hadoop.hdfs.configuration.version
Handling deprecation for hadoop.security.group.mapping.ldap.search.attr.member
Handling deprecation for yarn.nodemanager.log.retain-seconds
Handling deprecation for yarn.nodemanager.local-cache.max-files-per-directory
Handling deprecation for mapreduce.job.end-notification.retry.interval
Handling deprecation for hadoop.ssl.client.conf
Handling deprecation for yarn.sharedcache.root-dir
Handling deprecation for dfs.journalnode.https-address
Handling deprecation for mapreduce.reduce.shuffle.fetch.retry.timeout-ms
Handling deprecation for dfs.bytes-per-checksum
Handling deprecation for dfs.namenode.max.objects
Handling deprecation for mapreduce.tasktracker.instrumentation
Handling deprecation for dfs.datanode.max.transfer.threads
Handling deprecation for dfs.block.access.key.update.interval
Handling deprecation for mapreduce.jobtracker.jobhistory.task.numberprogresssplits
Handling deprecation for mapreduce.map.memory.mb
Handling deprecation for ha.failover-controller.new-active.rpc-timeout.ms
Handling deprecation for hadoop.ssl.hostname.verifier
Handling deprecation for dfs.client.read.shortcircuit
Handling deprecation for dfs.datanode.hdfs-blocks-metadata.enabled
Handling deprecation for mapreduce.tasktracker.healthchecker.interval
Handling deprecation for dfs.image.transfer.chunksize
Handling deprecation for mapreduce.tasktracker.taskmemorymanager.monitoringinterval
Handling deprecation for dfs.client.https.keystore.resource
Handling deprecation for yarn.resourcemanager.connect.retry-interval.ms
Handling deprecation for yarn.timeline-service.webapp.address
Handling deprecation for s3native.blocksize
Handling deprecation for yarn.scheduler.minimum-allocation-mb
Handling deprecation for yarn.sharedcache.cleaner.resource-sleep-ms
Handling deprecation for net.topology.impl
Handling deprecation for dfs.client.failover.sleep.base.millis
Handling deprecation for dfs.permissions.superusergroup
Handling deprecation for io.seqfile.compress.blocksize
Handling deprecation for hadoop.registry.zk.retry.times
Handling deprecation for fs.AbstractFileSystem.ftp.impl
Handling deprecation for dfs.namenode.checkpoint.edits.dir
Handling deprecation for mapreduce.job.running.reduce.limit
Handling deprecation for dfs.blockreport.initialDelay
Handling deprecation for dfs.namenode.heartbeat.recheck-interval
Handling deprecation for dfs.namenode.safemode.extension
Handling deprecation for yarn.scheduler.maximum-allocation-mb
Handling deprecation for mapreduce.job.reduce.shuffle.consumer.plugin.class
Handling deprecation for yarn.nodemanager.vmem-check-enabled
Handling deprecation for mapreduce.task.io.sort.factor
Handling deprecation for mapreduce.jobtracker.persist.jobstatus.dir
Handling deprecation for dfs.client.failover.sleep.max.millis
Handling deprecation for dfs.namenode.delegation.key.update-interval
Handling deprecation for hadoop.rpc.protection
Handling deprecation for fs.permissions.umask-mode
Handling deprecation for fs.s3.sleepTimeSeconds
Handling deprecation for ha.health-monitor.rpc-timeout.ms
Handling deprecation for hadoop.http.staticuser.user
Handling deprecation for fs.s3a.connection.maximum
Handling deprecation for yarn.nodemanager.linux-container-executor.nonsecure-mode.limit-users
Handling deprecation for fs.s3a.paging.maximum
Handling deprecation for fs.AbstractFileSystem.viewfs.impl
Handling deprecation for fs.ftp.host
Handling deprecation for yarn.nodemanager.linux-container-executor.nonsecure-mode.local-user
Handling deprecation for fs.s3a.impl
Handling deprecation for hadoop.http.authentication.kerberos.keytab
Handling deprecation for dfs.namenode.fs-limits.max-blocks-per-file
Handling deprecation for mapreduce.tasktracker.http.threads
Handling deprecation for mapreduce.tasktracker.dns.nameserver
Handling deprecation for yarn.resourcemanager.am-rm-tokens.master-key-rolling-interval-secs
Handling deprecation for dfs.client.block.write.replace-datanode-on-failure.enable
Handling deprecation for io.compression.codec.bzip2.library
Handling deprecation for mapreduce.map.skip.maxrecords
Handling deprecation for dfs.client.use.legacy.blockreader.local
Handling deprecation for dfs.namenode.checkpoint.dir
Handling deprecation for dfs.namenode.top.windows.minutes
Handling deprecation for mapreduce.job.maxtaskfailures.per.tracker
Handling deprecation for net.topology.node.switch.mapping.impl
Handling deprecation for mapreduce.shuffle.max.connections
Handling deprecation for mapreduce.jobhistory.loadedjobs.cache.size
Handling deprecation for dfs.storage.policy.enabled
Handling deprecation for yarn.client.application-client-protocol.poll-interval-ms
Handling deprecation for yarn.nodemanager.localizer.address
Handling deprecation for dfs.namenode.list.cache.pools.num.responses
Handling deprecation for nfs.server.port
Handling deprecation for mapreduce.client.output.filter
Handling deprecation for yarn.timeline-service.client.best-effort
Handling deprecation for ha.zookeeper.parent-znode
Handling deprecation for mapreduce.jobtracker.persist.jobstatus.hours
Handling deprecation for yarn.sharedcache.admin.thread-count
Handling deprecation for yarn.nodemanager.resource.cpu-vcores
Handling deprecation for dfs.datanode.block-pinning.enabled
Handling deprecation for mapreduce.jobhistory.http.policy
Handling deprecation for yarn.resourcemanager.webapp.delegation-token-auth-filter.enabled
Handling deprecation for mapreduce.job.speculative.retry-after-no-speculate
Handling deprecation for fs.s3a.attempts.maximum
Handling deprecation for s3native.stream-buffer-size
Handling deprecation for io.seqfile.local.dir
Handling deprecation for yarn.log-aggregation.retain-check-interval-seconds
Handling deprecation for fs.s3n.multipart.copy.block.size
Handling deprecation for dfs.encrypt.data.transfer.cipher.key.bitlength
Handling deprecation for dfs.datanode.sync.behind.writes
Handling deprecation for yarn.resourcemanager.zk-acl
Handling deprecation for hadoop.ssl.keystores.factory.class
Handling deprecation for mapreduce.job.split.metainfo.maxsize
Handling deprecation for fs.s3.maxRetries
Handling deprecation for hadoop.security.random.device.file.path
Handling deprecation for yarn.client.nodemanager-connect.max-wait-ms
Handling deprecation for dfs.namenode.stale.datanode.interval
Handling deprecation for mapreduce.task.io.sort.mb
Handling deprecation for yarn.resourcemanager.zk-state-store.parent-path
Handling deprecation for yarn.app.mapreduce.client-am.ipc.max-retries
Handling deprecation for fs.client.resolve.remote.symlinks
Handling deprecation for yarn.nodemanager.linux-container-executor.cgroups.strict-resource-usage
Handling deprecation for hadoop.ssl.enabled.protocols
Handling deprecation for mapreduce.reduce.cpu.vcores
Handling deprecation for yarn.client.failover-retries
Handling deprecation for mapreduce.jobhistory.address
Handling deprecation for hadoop.ssl.enabled
Handling deprecation for dfs.replication.max
Handling deprecation for dfs.namenode.name.dir
Handling deprecation for dfs.datanode.https.address
Handling deprecation for ipc.client.kill.max
Handling deprecation for mapreduce.job.committer.setup.cleanup.needed
Handling deprecation for dfs.client.domain.socket.data.traffic
Handling deprecation for yarn.nodemanager.localizer.cache.target-size-mb
Handling deprecation for yarn.resourcemanager.admin.client.thread-count
Handling deprecation for dfs.block.access.token.enable
Handling deprecation for mapreduce.job.speculative.retry-after-speculate
Handling deprecation for dfs.datanode.address
Handling deprecation for mapreduce.jobtracker.restart.recover
Handling deprecation for ipc.client.connect.max.retries
Handling deprecation for yarn.timeline-service.store-class
Handling deprecation for dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
Handling deprecation for hadoop.tmp.dir
Handling deprecation for dfs.datanode.handler.count
Handling deprecation for yarn.resourcemanager.ha.automatic-failover.embedded
Handling deprecation for yarn.timeline-service.ttl-ms
Handling deprecation for mapreduce.task.profile.map.params
Handling deprecation for yarn.resourcemanager.nodemanagers.heartbeat-interval-ms
Handling deprecation for mapreduce.map.speculative
Handling deprecation for yarn.timeline-service.recovery.enabled
Handling deprecation for mapreduce.job.map.class
Handling deprecation for dfs.namenode.resource.checked.volumes.minimum
Handling deprecation for yarn.nodemanager.recovery.dir
Handling deprecation for mapreduce.job.counters.max
Handling deprecation for yarn.resourcemanager.keytab
Handling deprecation for dfs.namenode.max.extra.edits.segments.retained
Handling deprecation for dfs.webhdfs.user.provider.user.pattern
Handling deprecation for dfs.client.mmap.enabled
Handling deprecation for mapreduce.map.log.level
Handling deprecation for dfs.client.file-block-storage-locations.timeout.millis
Handling deprecation for yarn.client.max-cached-nodemanagers-proxies
Handling deprecation for yarn.app.mapreduce.am.scheduler.heartbeat.interval-ms
Handling deprecation for hadoop.fuse.timer.period
Handling deprecation for fs.trash.checkpoint.interval
Handling deprecation for yarn.sharedcache.app-checker.class
Handling deprecation for dfs.journalnode.http-address
Handling deprecation for yarn.app.mapreduce.am.staging-dir
Handling deprecation for mapreduce.tasktracker.local.dir.minspacestart
Handling deprecation for yarn.nm.liveness-monitor.expiry-interval-ms
Handling deprecation for ha.health-monitor.check-interval.ms
Handling deprecation for mapreduce.reduce.shuffle.merge.percent
Handling deprecation for dfs.namenode.retrycache.heap.percent
Handling deprecation for yarn.nodemanager.docker-container-executor.exec-name
Handling deprecation for ipc.client.connect.timeout
Handling deprecation for yarn.resourcemanager.fs.state-store.retry-interval-ms
Handling deprecation for mapreduce.output.fileoutputformat.compress
Handling deprecation for yarn.nodemanager.local-dirs
Handling deprecation for yarn.nodemanager.recovery.enabled
Handling deprecation for io.native.lib.available
Handling deprecation for yarn.sharedcache.store.in-memory.staleness-period-mins
Handling deprecation for yarn.resourcemanager.am.max-attempts
Handling deprecation for s3.replication
Handling deprecation for mapreduce.input.fileinputformat.inputdir
Handling deprecation for fs.AbstractFileSystem.har.impl
Handling deprecation for dfs.image.compress
Handling deprecation for mapreduce.job.running.map.limit
Handling deprecation for mapreduce.reduce.input.buffer.percent
Handling deprecation for yarn.nodemanager.webapp.address
Handling deprecation for dfs.datanode.available-space-volume-choosing-policy.balanced-space-preference-fraction
Handling deprecation for dfs.namenode.edit.log.autoroll.multiplier.threshold
Handling deprecation for hadoop.security.group.mapping.ldap.ssl
Handling deprecation for dfs.namenode.checkpoint.check.period
Handling deprecation for fs.defaultFS
Handling deprecation for fs.s3a.multipart.size
Handling deprecation for dfs.client.slow.io.warning.threshold.ms
Handling deprecation for yarn.app.mapreduce.am.job.committer.commit-window
Handling deprecation for hadoop.security.group.mapping.ldap.search.attr.group.name
Handling deprecation for yarn.nodemanager.disk-health-checker.max-disk-utilization-per-disk-percentage
Handling deprecation for yarn.nodemanager.container-monitor.procfs-tree.smaps-based-rss.enabled
Handling deprecation for mapreduce.job.submithostname
Handling deprecation for mapreduce.map.sort.spill.percent
Handling deprecation for hadoop.security.crypto.codec.classes.aes.ctr.nopadding
Handling deprecation for dfs.namenode.http-address
Handling deprecation for hadoop.security.groups.negative-cache.secs
Handling deprecation for hadoop.ssl.server.conf
Handling deprecation for mapreduce.ifile.readahead
Handling deprecation for s3native.replication
Handling deprecation for yarn.client.nodemanager-client-async.thread-pool-max-size
Handling deprecation for mapreduce.jobtracker.staging.root.dir
Handling deprecation for mapreduce.jobhistory.admin.address
Handling deprecation for dfs.namenode.startup.delay.block.deletion.sec
Handling deprecation for yarn.nodemanager.health-checker.interval-ms
Handling deprecation for dfs.namenode.checkpoint.max-retries
Handling deprecation for s3.stream-buffer-size
Handling deprecation for ftp.client-write-packet-size
Handling deprecation for dfs.datanode.fsdatasetcache.max.threads.per.volume
Handling deprecation for mapreduce.output.fileoutputformat.compress.codec
Handling deprecation for yarn.timeline-service.keytab
Handling deprecation for yarn.sharedcache.store.in-memory.initial-delay-mins
Handling deprecation for mapreduce.jobhistory.webapp.address
Handling deprecation for mapreduce.task.userlog.limit.kb
Handling deprecation for mapreduce.reduce.shuffle.fetch.retry.enabled
Handling deprecation for yarn.app.mapreduce.task.container.log.backups
Handling deprecation for dfs.heartbeat.interval
Handling deprecation for ha.zookeeper.session-timeout.ms
Handling deprecation for fs.s3a.connection.ssl.enabled
Handling deprecation for yarn.sharedcache.webapp.address
Handling deprecation for hadoop.http.authentication.signature.secret.file
Handling deprecation for hadoop.fuse.connection.timeout
Handling deprecation for mapreduce.input.fileinputformat.numinputfiles
Handling deprecation for yarn.nodemanager.log-aggregation.compression-type
Handling deprecation for ipc.server.max.connections
Handling deprecation for yarn.resourcemanager.work-preserving-recovery.scheduling-wait-ms
Handling deprecation for yarn.nodemanager.log-dirs
Handling deprecation for yarn.app.mapreduce.am.resource.mb
Handling deprecation for hadoop.security.groups.cache.secs
Handling deprecation for mapreduce.job.speculative.minimum-allowed-tasks
Handling deprecation for yarn.nodemanager.container-monitor.interval-ms
Handling deprecation for dfs.datanode.cache.revocation.timeout.ms
Handling deprecation for mapreduce.jobhistory.recovery.store.class
Handling deprecation for mapreduce.task.combine.progress.records
Handling deprecation for s3.client-write-packet-size
Handling deprecation for mapreduce.jobtracker.instrumentation
Handling deprecation for dfs.replication
Handling deprecation for mapreduce.shuffle.transfer.buffer.size
Handling deprecation for hadoop.security.group.mapping.ldap.directory.search.timeout
Handling deprecation for dfs.datanode.available-space-volume-choosing-policy.balanced-space-threshold
Handling deprecation for hadoop.work.around.non.threadsafe.getpwuid
Handling deprecation for yarn.app.mapreduce.client-am.ipc.max-retries-on-timeouts
Handling deprecation for yarn.nodemanager.address
Handling deprecation for mapreduce.tasktracker.taskcontroller
Handling deprecation for mapreduce.tasktracker.indexcache.mb
Handling deprecation for yarn.scheduler.maximum-allocation-vcores
Handling deprecation for mapreduce.job.reduces
Handling deprecation for yarn.nodemanager.sleep-delay-before-sigkill.ms
Handling deprecation for yarn.timeline-service.address
Handling deprecation for yarn.resourcemanager.configuration.provider-class
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.expiry
Handling deprecation for yarn.sharedcache.enabled
Handling deprecation for tfile.io.chunk.size
Handling deprecation for mapreduce.job.acl-modify-job
Handling deprecation for hadoop.registry.zk.session.timeout.ms
Handling deprecation for fs.automatic.close
Handling deprecation for ha.health-monitor.sleep-after-disconnect.ms
Handling deprecation for mapreduce.tasktracker.reduce.tasks.maximum
Handling deprecation for mapreduce.input.fileinputformat.list-status.num-threads
Handling deprecation for dfs.datanode.directoryscan.threads
Handling deprecation for dfs.datanode.directoryscan.interval
Handling deprecation for dfs.namenode.acls.enabled
Handling deprecation for dfs.client.short.circuit.replica.stale.threshold.ms
Handling deprecation for hadoop.http.authentication.token.validity
Handling deprecation for fs.s3.block.size
Handling deprecation for ha.failover-controller.graceful-fence.rpc-timeout.ms
Handling deprecation for mapreduce.tasktracker.local.dir.minspacekill
Handling deprecation for dfs.namenode.resource.du.reserved
Handling deprecation for mapreduce.jobhistory.cleaner.interval-ms
Handling deprecation for dfs.namenode.datanode.registration.ip-hostname-check
Handling deprecation for mapreduce.jobhistory.intermediate-done-dir
Handling deprecation for mapreduce.jobtracker.http.address
Handling deprecation for dfs.namenode.backup.http-address
Handling deprecation for dfs.namenode.edits.noeditlogchannelflush
Handling deprecation for mapreduce.reduce.shuffle.input.buffer.percent
Handling deprecation for mapreduce.map.maxattempts
Handling deprecation for yarn.http.policy
Handling deprecation for dfs.namenode.audit.loggers
Handling deprecation for hadoop.security.groups.cache.warn.after.ms
Handling deprecation for io.serializations
Handling deprecation for mapreduce.tasktracker.outofband.heartbeat
Handling deprecation for mapreduce.reduce.shuffle.read.timeout
Handling deprecation for hadoop.security.crypto.buffer.size
Handling deprecation for mapreduce.reduce.skip.proc.count.autoincr
Handling deprecation for mapreduce.ifile.readahead.bytes
Handling deprecation for dfs.http.policy
Handling deprecation for hadoop.registry.secure
Handling deprecation for dfs.namenode.safemode.min.datanodes
Handling deprecation for dfs.client.file-block-storage-locations.num-threads
Handling deprecation for mapreduce.cluster.local.dir
Handling deprecation for mapreduce.tasktracker.report.address
Handling deprecation for dfs.namenode.secondary.https-address
Handling deprecation for hadoop.kerberos.kinit.command
Handling deprecation for yarn.timeline-service.http-authentication.type
Handling deprecation for dfs.block.access.token.lifetime
Handling deprecation for dfs.webhdfs.enabled
Handling deprecation for dfs.namenode.delegation.token.max-lifetime
Handling deprecation for dfs.namenode.avoid.write.stale.datanode
Handling deprecation for dfs.datanode.drop.cache.behind.writes
Handling deprecation for yarn.log-aggregation.retain-seconds
Handling deprecation for mapreduce.job.complete.cancel.delegation.tokens
Handling deprecation for mapreduce.local.clientfactory.class.name
Handling deprecation for mapreduce.shuffle.connection-keep-alive.timeout
Handling deprecation for dfs.namenode.num.extra.edits.retained
Handling deprecation for yarn.scheduler.minimum-allocation-vcores
Handling deprecation for ipc.client.connect.max.retries.on.timeouts
Handling deprecation for yarn.timeline-service.client.retry-interval-ms
Handling deprecation for yarn.timeline-service.client.max-retries
Handling deprecation for fs.s3n.block.size
Handling deprecation for mapreduce.job.map.output.collector.class
Handling deprecation for ha.health-monitor.connect-retry-interval.ms
Handling deprecation for mapreduce.shuffle.max.threads
Handling deprecation for nfs.exports.allowed.hosts
Handling deprecation for dfs.client.mmap.cache.size
Handling deprecation for mapreduce.tasktracker.map.tasks.maximum
Handling deprecation for io.file.buffer.size
Handling deprecation for dfs.client.datanode-restart.timeout
Handling deprecation for io.mapfile.bloom.size
Handling deprecation for hadoop.security.kms.client.authentication.retry-count
Handling deprecation for dfs.namenode.checkpoint.txns
Handling deprecation for ipc.client.connect.retry.interval
Handling deprecation for dfs.client-write-packet-size
Handling deprecation for mapreduce.reduce.shuffle.connect.timeout
Handling deprecation for yarn.resourcemanager.fs.state-store.uri
Handling deprecation for fs.swift.impl
Handling deprecation for hadoop.registry.zk.connection.timeout.ms
Handling deprecation for mapred.queue.default.acl-administer-jobs
Handling deprecation for mapreduce.job.submithostaddress
Handling deprecation for dfs.cachereport.intervalMsec
Handling deprecation for yarn.app.mapreduce.shuffle.log.backups
Handling deprecation for yarn.app.mapreduce.am.container.log.limit.kb
Handling deprecation for yarn.nodemanager.resourcemanager.minimum.version
Handling deprecation for ftp.blocksize
Handling deprecation for yarn.resourcemanager.address
Handling deprecation for file.stream-buffer-size
Handling deprecation for yarn.resourcemanager.scheduler.monitor.enable
Handling deprecation for mapreduce.job.ubertask.maxreduces
Handling deprecation for nfs.allow.insecure.ports
Handling deprecation for yarn.sharedcache.nm.uploader.thread-count
Handling deprecation for ipc.client.idlethreshold
Handling deprecation for ftp.stream-buffer-size
Handling deprecation for yarn.sharedcache.client-server.address
Handling deprecation for dfs.client.failover.connection.retries.on.timeouts
Handling deprecation for dfs.namenode.replication.work.multiplier.per.iteration
Handling deprecation for hadoop.http.authentication.simple.anonymous.allowed
Handling deprecation for hadoop.security.authorization
Handling deprecation for yarn.client.nodemanager-connect.retry-interval-ms
Handling deprecation for yarn.am.liveness-monitor.expiry-interval-ms
Handling deprecation for fs.har.impl.disable.cache
Handling deprecation for yarn.nodemanager.linux-container-executor.resources-handler.class
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.read-cache-size
Handling deprecation for hadoop.security.authentication
Handling deprecation for dfs.image.compression.codec
Handling deprecation for mapreduce.task.files.preserve.failedtasks
Handling deprecation for dfs.client.read.shortcircuit.streams.cache.size
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.path
Handling deprecation for mapreduce.job.reduce.slowstart.completedmaps
Handling deprecation for mapreduce.jobhistory.minicluster.fixed.ports
Handling deprecation for file.replication
Handling deprecation for yarn.resourcemanager.ha.automatic-failover.enabled
Handling deprecation for mapreduce.job.userlog.retain.hours
Handling deprecation for mapreduce.jobhistory.joblist.cache.size
Handling deprecation for dfs.namenode.accesstime.precision
Handling deprecation for yarn.resourcemanager.work-preserving-recovery.enabled
Handling deprecation for dfs.namenode.fs-limits.max-xattrs-per-inode
Handling deprecation for io.mapfile.bloom.error.rate
Handling deprecation for yarn.resourcemanager.store.class
Handling deprecation for dfs.image.transfer.timeout
Handling deprecation for yarn.timeline-service.leveldb-state-store.path
Handling deprecation for nfs.wtmax
Handling deprecation for mapreduce.job.combine.class
Handling deprecation for dfs.namenode.support.allow.format
Handling deprecation for fs.s3a.multipart.purge
Handling deprecation for dfs.secondary.namenode.kerberos.internal.spnego.principal
Handling deprecation for fs.s3a.connection.establish.timeout
Handling deprecation for dfs.stream-buffer-size
Handling deprecation for dfs.namenode.invalidate.work.pct.per.iteration
Handling deprecation for yarn.nodemanager.container-executor.class
Handling deprecation for fs.s3a.multipart.purge.age
Handling deprecation for yarn.resourcemanager.scheduler.client.thread-count
Handling deprecation for dfs.namenode.top.enabled
Handling deprecation for yarn.app.mapreduce.shuffle.log.separate
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.low-watermark
Handling deprecation for fs.s3a.fast.buffer.size
Handling deprecation for hadoop.user.group.static.mapping.overrides
Handling deprecation for tfile.fs.input.buffer.size
Handling deprecation for dfs.client.cached.conn.retry
Handling deprecation for hadoop.http.authentication.type
Handling deprecation for dfs.namenode.list.encryption.zones.num.responses
Handling deprecation for mapreduce.map.cpu.vcores
Handling deprecation for dfs.namenode.path.based.cache.refresh.interval.ms
Handling deprecation for dfs.namenode.decommission.interval
Handling deprecation for dfs.namenode.fs-limits.max-directory-items
Handling deprecation for yarn.resourcemanager.zk-retry-interval-ms
Handling deprecation for ftp.bytes-per-checksum
Handling deprecation for dfs.ha.log-roll.period
Handling deprecation for dfs.user.home.dir.prefix
Handling deprecation for ipc.client.fallback-to-simple-auth-allowed
Handling deprecation for yarn.nodemanager.pmem-check-enabled
Handling deprecation for yarn.nodemanager.remote-app-log-dir
Handling deprecation for dfs.namenode.inotify.max.events.per.rpc
Handling deprecation for mapreduce.task.profile.maps
Handling deprecation for mapreduce.shuffle.ssl.file.buffer.size
Handling deprecation for mapreduce.tasktracker.healthchecker.script.timeout
Handling deprecation for yarn.timeline-service.webapp.https.address
Handling deprecation for yarn.nodemanager.resource.percentage-physical-cpu-limit
Handling deprecation for yarn.app.mapreduce.am.command-opts
Handling deprecation for dfs.namenode.fs-limits.max-xattr-size
Handling deprecation for dfs.datanode.http.address
Handling deprecation for dfs.namenode.blocks.per.postponedblocks.rescan
Handling deprecation for yarn.sharedcache.nm.uploader.replication.factor
Handling deprecation for hadoop.registry.zk.root
Handling deprecation for hadoop.jetty.logs.serve.aliases
Handling deprecation for yarn.client.failover-proxy-provider
Handling deprecation for mapreduce.jobhistory.admin.acl
Handling deprecation for yarn.app.mapreduce.am.hard-kill-timeout-ms
Handling deprecation for yarn.nodemanager.remote-app-log-dir-suffix
Handling deprecation for mapreduce.jobhistory.principal
Handling deprecation for yarn.resourcemanager.webapp.address
Handling deprecation for mapreduce.jobhistory.recovery.enable
Handling deprecation for yarn.sharedcache.store.in-memory.check-period-mins
Handling deprecation for nfs.mountd.port
Handling deprecation for mapreduce.reduce.merge.inmem.threshold
Handling deprecation for fs.df.interval
Handling deprecation for yarn.timeline-service.enabled
Handling deprecation for mapreduce.jobtracker.jobhistory.lru.cache.size
Handling deprecation for mapreduce.task.profile
Handling deprecation for mapreduce.job.output.key.class
Handling deprecation for yarn.nodemanager.hostname
Handling deprecation for dfs.namenode.num.checkpoints.retained
Handling deprecation for mapreduce.job.queuename
Handling deprecation for mapreduce.jobhistory.max-age-ms
Handling deprecation for mapreduce.job.token.tracking.ids.enabled
Handling deprecation for yarn.nodemanager.localizer.client.thread-count
Handling deprecation for yarn.sharedcache.uploader.server.thread-count
Handling deprecation for dfs.client.mmap.retry.timeout.ms
Handling deprecation for mapreduce.jobhistory.move.thread-count
Handling deprecation for dfs.permissions.enabled
Handling deprecation for dfs.blockreport.split.threshold
Handling deprecation for fs.AbstractFileSystem.hdfs.impl
Handling deprecation for dfs.datanode.balance.bandwidthPerSec
Handling deprecation for dfs.block.scanner.volume.bytes.per.second
Handling deprecation for hadoop.http.filter.initializers
Handling deprecation for yarn.timeline-service.http-authentication.simple.anonymous.allowed
Handling deprecation for dfs.default.chunk.view.size
Handling deprecation for yarn.sharedcache.client-server.thread-count
Handling deprecation for yarn.resourcemanager.resource-tracker.address
Handling deprecation for mapreduce.job.working.dir
Handling deprecation for mapreduce.jobhistory.datestring.cache.size
Handling deprecation for mapreduce.task.profile.params
Handling deprecation for dfs.namenode.decommission.blocks.per.interval
Handling deprecation for dfs.namenode.handler.count
Handling deprecation for dfs.image.transfer.bandwidthPerSec
Handling deprecation for rpc.metrics.quantile.enable
Handling deprecation for mapreduce.jobtracker.expire.trackers.interval
Handling deprecation for mapreduce.task.timeout
Handling deprecation for yarn.app.mapreduce.client.max-retries
Handling deprecation for yarn.nodemanager.resource.memory-mb
Handling deprecation for yarn.nodemanager.disk-health-checker.min-healthy-disks
Handling deprecation for dfs.datanode.failed.volumes.tolerated
Handling deprecation for yarn.timeline-service.handler-thread-count
Handling deprecation for ipc.server.listen.queue.size
Handling deprecation for fs.s3a.threads.max
Handling deprecation for yarn.resourcemanager.connect.max-wait.ms
Handling deprecation for mapreduce.fileoutputcommitter.algorithm.version
Handling deprecation for mapreduce.framework.name
Handling deprecation for mapreduce.map.skip.proc.count.autoincr
Handling deprecation for mapreduce.job.max.split.locations
Handling deprecation for yarn.resourcemanager.scheduler.class
Handling deprecation for yarn.resourcemanager.system-metrics-publisher.enabled
Handling deprecation for dfs.blocksize
Handling deprecation for yarn.sharedcache.nested-level
Handling deprecation for mapreduce.shuffle.connection-keep-alive.enable
Handling deprecation for fs.s3a.threads.keepalivetime
Handling deprecation for fs.s3a.connection.timeout
Handling deprecation for file.client-write-packet-size
Handling deprecation for ha.failover-controller.cli-check.rpc-timeout.ms
Handling deprecation for ha.zookeeper.acl
Handling deprecation for dfs.namenode.write.stale.datanode.ratio
Handling deprecation for dfs.encrypt.data.transfer
Handling deprecation for dfs.datanode.shared.file.descriptor.paths
Handling deprecation for mapreduce.input.lineinputformat.linespermap
Handling deprecation for yarn.resourcemanager.delayed.delegation-token.removal-interval-ms
Handling deprecation for yarn.nodemanager.localizer.fetch.thread-count
Handling deprecation for dfs.client.failover.max.attempts
Handling deprecation for yarn.resourcemanager.scheduler.address
Handling deprecation for dfs.client.read.shortcircuit.streams.cache.expiry.ms
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.start-time-write-cache-size
Handling deprecation for yarn.nodemanager.health-checker.script.timeout-ms
Handling deprecation for yarn.resourcemanager.fs.state-store.num-retries
Handling deprecation for hadoop.ssl.require.client.cert
Handling deprecation for hadoop.security.uid.cache.secs
Handling deprecation for mapreduce.jobhistory.keytab
Handling deprecation for dfs.client.read.shortcircuit.skip.checksum
Handling deprecation for yarn.resourcemanager.ha.automatic-failover.zk-base-path
Handling deprecation for mapreduce.shuffle.ssl.enabled
Handling deprecation for mapreduce.reduce.log.level
Handling deprecation for hadoop.registry.rm.enabled
Handling deprecation for mapreduce.tasktracker.dns.interface
Handling deprecation for yarn.resourcemanager.system-metrics-publisher.dispatcher.pool-size
Handling deprecation for mapreduce.job.speculative.speculative-cap-running-tasks
Handling deprecation for dfs.datanode.block.id.layout.upgrade.threads
Handling deprecation for dfs.datanode.use.datanode.hostname
Handling deprecation for dfs.client.context
Handling deprecation for yarn.resourcemanager.ha.enabled
Handling deprecation for mapred.reducer.new-api
Handling deprecation for dfs.namenode.delegation.token.renew-interval
Handling deprecation for dfs.blockreport.intervalMsec
Handling deprecation for fs.s3a.multipart.threshold
Handling deprecation for mapreduce.reduce.shuffle.memory.limit.percent
Handling deprecation for dfs.https.server.keystore.resource
Handling deprecation for io.map.index.skip
Handling deprecation for mapreduce.job.hdfs-servers
Handling deprecation for mapreduce.jobtracker.taskscheduler
Handling deprecation for dfs.namenode.kerberos.internal.spnego.principal
Handling deprecation for yarn.resourcemanager.state-store.max-completed-applications
Handling deprecation for mapreduce.map.output.compress
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.num.refill.threads
Handling deprecation for fs.s3n.multipart.uploads.block.size
Handling deprecation for mapreduce.task.merge.progress.records
Handling deprecation for dfs.datanode.dns.interface
Handling deprecation for map.sort.class
Handling deprecation for yarn.nodemanager.aux-services.mapreduce_shuffle.class
Handling deprecation for tfile.fs.output.buffer.size
Handling deprecation for fs.du.interval
Handling deprecation for dfs.client.failover.connection.retries
Handling deprecation for dfs.namenode.top.window.num.buckets
Handling deprecation for mapreduce.job.dir
Handling deprecation for fs.s3a.buffer.dir
Handling deprecation for mapreduce.reduce.shuffle.retry-delay.max.ms
Handling deprecation for yarn.sharedcache.uploader.server.address
Handling deprecation for mapreduce.client.progressmonitor.pollinterval
Handling deprecation for yarn.app.mapreduce.shuffle.log.limit.kb
Handling deprecation for dfs.datanode.max.locked.memory
Handling deprecation for dfs.namenode.retrycache.expirytime.millis
Handling deprecation for dfs.datanode.scan.period.hours
Handling deprecation for dfs.client.block.write.replace-datanode-on-failure.best-effort
Handling deprecation for mapreduce.jobhistory.move.interval-ms
Handling deprecation for dfs.ha.fencing.ssh.connect-timeout
Handling deprecation for yarn.nodemanager.log-aggregation.roll-monitoring-interval-seconds
Handling deprecation for dfs.namenode.fs-limits.max-component-length
Handling deprecation for hadoop.registry.zk.quorum
Handling deprecation for dfs.namenode.enable.retrycache
Handling deprecation for dfs.datanode.du.reserved
Handling deprecation for yarn.timeline-service.state-store-class
Handling deprecation for dfs.datanode.ipc.address
Handling deprecation for hadoop.registry.system.acls
Handling deprecation for dfs.client.block.write.replace-datanode-on-failure.policy
Handling deprecation for dfs.namenode.path.based.cache.retry.interval.ms
Handling deprecation for hadoop.security.crypto.cipher.suite
Handling deprecation for dfs.ha.tail-edits.period
Handling deprecation for mapreduce.task.profile.reduce.params
Handling deprecation for hadoop.registry.jaas.context
Handling deprecation for yarn.resourcemanager.hostname
Handling deprecation for mapreduce.reduce.memory.mb
Handling deprecation for hadoop.security.group.mapping.ldap.search.filter.group
Handling deprecation for hadoop.http.authentication.kerberos.principal
Handling deprecation for hadoop.security.group.mapping.ldap.search.filter.user
Handling deprecation for yarn.nodemanager.disk-health-checker.min-free-space-per-disk-mb
Handling deprecation for dfs.namenode.edits.dir
Handling deprecation for yarn.client.failover-retries-on-socket-timeouts
Handling deprecation for dfs.namenode.decommission.max.concurrent.tracked.nodes
Handling deprecation for mapreduce.client.completion.pollinterval
Handling deprecation for dfs.namenode.name.dir.restore
Handling deprecation for dfs.namenode.secondary.http-address
Handling deprecation for mapreduce.jobhistory.recovery.store.leveldb.path
Handling deprecation for yarn.sharedcache.store.class
Handling deprecation for s3.bytes-per-checksum
Handling deprecation for yarn.nodemanager.windows-container.cpu-limit.enabled
Handling deprecation for yarn.resourcemanager.webapp.https.address
Handling deprecation for yarn.nodemanager.vmem-pmem-ratio
Handling deprecation for dfs.namenode.checkpoint.period
Handling deprecation for dfs.ha.automatic-failover.enabled
The url to track the job: http://localhost:8080/
OutputCommitter set in config null
File Output Committer Algorithm version is 1
OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
/user/michaeljones/wcOutput/_temporary/0: masked=rwxr-xr-x
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #35
Running job: job_local737491137_0002
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #35
Call: mkdirs took 14ms
Starting mapper thread pool executor.
Max local threads: 1
Map tasks to process: 1
Waiting for map tasks
Starting task: attempt_local737491137_0002_m_000000_0
currentIndex 0   0:0
mapreduce.cluster.local.dir for child : /tmp/hadoop-michaeljones/mapred/local/localRunner//michaeljones/jobcache/job_local737491137_0002/attempt_local737491137_0002_m_000000_0
using new api for output committer
File Output Committer Algorithm version is 1
ProcfsBasedProcessTree currently is supported only on Linux.
 Using ResourceCalculatorProcessTree : null
Processing split: hdfs://localhost:9000/user/michaeljones/wcInput:0+50
Trying map output collector class: org.apache.hadoop.mapred.MapTask$MapOutputBuffer
(EQUATOR) 0 kvi 26214396(104857584)
mapreduce.task.io.sort.mb: 100
soft limit at 83886080
bufstart = 0; bufvoid = 104857600
kvstart = 26214396; length = 6553600
Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #36
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #36
Call: getBlockLocations took 2ms
newInfo = LocatedBlocks{
  fileLength=50
  underConstruction=false
  blocks=[LocatedBlock{BP-1045030256-10.0.0.2-1433119149314:blk_1073741825_1002; getBlockSize()=50; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-b42c5705-9ba4-4b14-b00b-f9194bb036f0,DISK]]}]
  lastLocatedBlock=LocatedBlock{BP-1045030256-10.0.0.2-1433119149314:blk_1073741825_1002; getBlockSize()=50; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-b42c5705-9ba4-4b14-b00b-f9194bb036f0,DISK]]}
  isLastBlockComplete=true}
Connecting to datanode 127.0.0.1:50010

Starting flush of map output
Spilling map output
bufstart = 0; bufend = 82; bufvoid = 104857600
kvstart = 26214396(104857584); kvend = 26214368(104857472); length = 29/6553600
Finished spill 0
Task:attempt_local737491137_0002_m_000000_0 is done. And is in the process of committing
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #37
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #37
Call: getFileInfo took 2ms
map
Task 'attempt_local737491137_0002_m_000000_0' done.
Finishing task: attempt_local737491137_0002_m_000000_0
map task executor complete.
Starting reduce thread pool executor.
Max local threads: 1
Reduce tasks to process: 1
Waiting for reduce tasks
Starting task: attempt_local737491137_0002_r_000000_0
currentIndex 0   0:0
mapreduce.cluster.local.dir for child : /tmp/hadoop-michaeljones/mapred/local/localRunner//michaeljones/jobcache/job_local737491137_0002/attempt_local737491137_0002_r_000000_0
using new api for output committer
File Output Committer Algorithm version is 1
ProcfsBasedProcessTree currently is supported only on Linux.
 Using ResourceCalculatorProcessTree : null
Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@69d2a83b
MergerManager: memoryLimit=668309888, maxSingleShuffleLimit=167077472, mergeThreshold=441084544, ioSortFactor=10, memToMemMergeOutputsThreshold=10
attempt_local737491137_0002_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
Got 0 map completion events from 0
GetMapEventsThread about to sleep for 1000
LocalFetcher 2 going to fetch: attempt_local737491137_0002_m_000000_0
attempt_local737491137_0002_m_000000_0: Proceeding with shuffle since usedMemory (0) is lesser than memoryLimit (668309888).CommitMemory is (0)
localfetcher#2 about to shuffle output of map attempt_local737491137_0002_m_000000_0 decomp: 63 len: 67 to MEMORY
Read 63 bytes from map-output for attempt_local737491137_0002_m_000000_0
closeInMemoryFile -> map-output of size: 63, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->63
map attempt_local737491137_0002_m_000000_0 done 1 / 1 copied.
EventFetcher is interrupted.. Returning
1 / 1 copied.
finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
Merging 1 sorted segments
Down to the last merge-pass, with 1 segments left of total size: 57 bytes
Merged 1 segments, 63 bytes to disk to satisfy reduce memory limit
Disk file: /tmp/hadoop-michaeljones/mapred/local/localRunner/michaeljones/jobcache/job_local737491137_0002/attempt_local737491137_0002_r_000000_0/output/map_0.out.merged Length is 67
Merging 1 files, 67 bytes from disk
Merging 0 segments, 0 bytes from memory into reduce
Merging 1 sorted segments
Down to the last merge-pass, with 1 segments left of total size: 57 bytes
1 / 1 copied.
/user/michaeljones/wcOutput/_temporary/0/_temporary/attempt_local737491137_0002_r_000000_0/part-r-00000: masked=rw-r--r--
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #38
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #38
Call: create took 4ms
computePacketChunkSize: src=/user/michaeljones/wcOutput/_temporary/0/_temporary/attempt_local737491137_0002_r_000000_0/part-r-00000, chunkSize=516, chunksPerPacket=126, packetSize=65016
DFSClient writeChunk allocating new packet seqno=0, src=/user/michaeljones/wcOutput/_temporary/0/_temporary/attempt_local737491137_0002_r_000000_0/part-r-00000, packetSize=65016, chunksPerPacket=126, bytesCurBlock=0
Queued packet 0
Queued packet 1
Waiting for ack for: 1
Allocating new block
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #39
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #39
Call: addBlock took 8ms
pipeline = DatanodeInfoWithStorage[127.0.0.1:50010,DS-b42c5705-9ba4-4b14-b00b-f9194bb036f0,DISK]
Connecting to datanode 127.0.0.1:50010
Send buf size 131072
SASL client skipping handshake in unsecured configuration for addr = /127.0.0.1, datanodeId = DatanodeInfoWithStorage[127.0.0.1:50010,DS-b42c5705-9ba4-4b14-b00b-f9194bb036f0,DISK]
DataStreamer block BP-1045030256-10.0.0.2-1433119149314:blk_1073742253_1430 sending packet packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 41
DFSClient seqno: 0 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
DataStreamer block BP-1045030256-10.0.0.2-1433119149314:blk_1073742253_1430 sending packet packet seqno: 1 offsetInBlock: 41 lastPacketInBlock: true lastByteOffsetInBlock: 41
DFSClient seqno: 1 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
Closing old block BP-1045030256-10.0.0.2-1433119149314:blk_1073742253_1430
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #40
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #40
Call: complete took 4ms
Task:attempt_local737491137_0002_r_000000_0 is done. And is in the process of committing
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #41
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #41
Call: getFileInfo took 2ms
1 / 1 copied.
Task attempt_local737491137_0002_r_000000_0 is allowed to commit now
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #42
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #42
Call: getFileInfo took 3ms
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #43
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #43
Call: getFileInfo took 2ms
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #44
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #44
Call: rename took 5ms
Saved output of task 'attempt_local737491137_0002_r_000000_0' to hdfs://localhost:9000/user/michaeljones/wcOutput/_temporary/0/task_local737491137_0002_r_000000
reduce > reduce
Task 'attempt_local737491137_0002_r_000000_0' done.
Finishing task: attempt_local737491137_0002_r_000000_0
reduce task executor complete.
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #45
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #45
Call: getListing took 2ms
Merging data from FileStatus{path=hdfs://localhost:9000/user/michaeljones/wcOutput/_temporary/0/task_local737491137_0002_r_000000; isDirectory=true; modification_time=1434167242114; access_time=0; owner=michaeljones; group=supergroup; permission=rwxr-xr-x; isSymlink=false} to hdfs://localhost:9000/user/michaeljones/wcOutput
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #46
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #46
Call: getFileInfo took 2ms
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #47
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #47
Call: getListing took 2ms
Merging data from FileStatus{path=hdfs://localhost:9000/user/michaeljones/wcOutput/_temporary/0/task_local737491137_0002_r_000000/part-r-00000; isDirectory=false; length=41; replication=1; blocksize=134217728; modification_time=1434167242143; access_time=1434167242114; owner=michaeljones; group=supergroup; permission=rw-r--r--; isSymlink=false} to hdfs://localhost:9000/user/michaeljones/wcOutput/part-r-00000
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #48
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #48
Call: getFileInfo took 1ms
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #49
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #49
Call: rename took 10ms
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #50
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #50
Call: delete took 2ms
/user/michaeljones/wcOutput/_SUCCESS: masked=rw-r--r--
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #51
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #51
Call: create took 5ms
computePacketChunkSize: src=/user/michaeljones/wcOutput/_SUCCESS, chunkSize=516, chunksPerPacket=126, packetSize=65016
Waiting for ack for: -1
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #52
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #52
Call: complete took 4ms
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.fs.FileContext.getAbstractFileSystem(FileContext.java:331)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
Job job_local737491137_0002 running in uber mode : false
 map 100% reduce 100%
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.getTaskCompletionEvents(Job.java:670)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.getTaskCompletionEvents(Job.java:670)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
Job job_local737491137_0002 completed successfully
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.getCounters(Job.java:758)
Counters: 35
	File System Counters
		FILE: Number of bytes read=1206
		FILE: Number of bytes written=1128413
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=240
		HDFS: Number of bytes written=163
		HDFS: Number of read operations=45
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=24
	Map-Reduce Framework
		Map input records=2
		Map output records=8
		Map output bytes=82
		Map output materialized bytes=67
		Input split bytes=112
		Combine input records=8
		Combine output records=5
		Reduce input groups=5
		Reduce shuffle bytes=67
		Reduce input records=5
		Reduce output records=5
		Spilled Records=10
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=867172352
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=50
	File Output Format Counters 
		Bytes Written=41
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
RunJobAnalysisAsync
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #53
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #53
Call: getFileInfo took 2ms
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #54
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #54
Call: delete took 6ms
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.connect(Job.java:1256)
Trying ClientProtocolProvider : org.apache.hadoop.mapred.LocalClientProtocolProvider
Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
Picked org.apache.hadoop.mapred.LocalClientProtocolProvider as the ClientProtocolProvider
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Cluster.getFileSystem(Cluster.java:162)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.submit(Job.java:1287)
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #55
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #55
Call: getFileInfo took 3ms
Configuring job job_local1326756033_0003 with file:/tmp/hadoop-michaeljones/mapred/staging/michaeljones1326756033/.staging/job_local1326756033_0003 as the submit dir
adding the following namenodes' delegation tokens:[hdfs://localhost:9000]
Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
default FileSystem: file:///
No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
Creating splits at file:/tmp/hadoop-michaeljones/mapred/staging/michaeljones1326756033/.staging/job_local1326756033_0003
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #56
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #56
Call: getFileInfo took 2ms
Time taken to get FileStatuses: 3
Total input paths to process : 1
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #57
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #57
Call: getBlockLocations took 3ms
Total # of splits generated by getSplits: 1, TimeTaken: 8
number of splits:1
Handling deprecation for all properties in config...
Handling deprecation for mapreduce.jobtracker.address
Handling deprecation for yarn.resourcemanager.scheduler.monitor.policies
Handling deprecation for dfs.namenode.resource.check.interval
Handling deprecation for mapreduce.jobhistory.client.thread-count
Handling deprecation for yarn.app.mapreduce.am.containerlauncher.threadpool-initial-size
Handling deprecation for mapred.child.java.opts
Handling deprecation for mapreduce.jobtracker.retiredjobs.cache.size
Handling deprecation for dfs.client.https.need-auth
Handling deprecation for yarn.admin.acl
Handling deprecation for yarn.app.mapreduce.am.job.committer.cancel-timeout
Handling deprecation for mapreduce.job.emit-timeline-data
Handling deprecation for fs.ftp.host.port
Handling deprecation for dfs.namenode.avoid.read.stale.datanode
Handling deprecation for dfs.journalnode.rpc-address
Handling deprecation for mapreduce.job.end-notification.retry.attempts
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.ttl-interval-ms
Handling deprecation for yarn.resourcemanager.leveldb-state-store.path
Handling deprecation for mapred.mapper.new-api
Handling deprecation for yarn.ipc.rpc.class
Handling deprecation for ipc.client.connection.maxidletime
Handling deprecation for yarn.nodemanager.process-kill-wait.ms
Handling deprecation for mapreduce.cluster.acls.enabled
Handling deprecation for mapreduce.jobtracker.handler.count
Handling deprecation for io.map.index.interval
Handling deprecation for dfs.namenode.https-address
Handling deprecation for mapreduce.task.profile.reduces
Handling deprecation for fs.s3n.multipart.uploads.enabled
Handling deprecation for io.seqfile.sorter.recordlimit
Handling deprecation for mapreduce.job.ubertask.maxmaps
Handling deprecation for mapreduce.tasktracker.tasks.sleeptimebeforesigkill
Handling deprecation for hadoop.util.hash.type
Handling deprecation for dfs.namenode.replication.min
Handling deprecation for yarn.nodemanager.container-manager.thread-count
Handling deprecation for mapreduce.jobtracker.jobhistory.block.size
Handling deprecation for dfs.namenode.fs-limits.min-block-size
Handling deprecation for mapreduce.app-submission.cross-platform
Handling deprecation for fs.AbstractFileSystem.file.impl
Handling deprecation for net.topology.script.number.args
Handling deprecation for yarn.resourcemanager.container-tokens.master-key-rolling-interval-secs
Handling deprecation for mapreduce.map.output.compress.codec
Handling deprecation for mapreduce.job.reducer.preempt.delay.sec
Handling deprecation for s3native.bytes-per-checksum
Handling deprecation for dfs.namenode.path.based.cache.block.map.allocation.percent
Handling deprecation for yarn.nodemanager.windows-container.memory-limit.enabled
Handling deprecation for mapreduce.input.fileinputformat.split.minsize
Handling deprecation for hadoop.security.group.mapping
Handling deprecation for mapreduce.jobtracker.system.dir
Handling deprecation for mapreduce.job.end-notification.max.attempts
Handling deprecation for mapreduce.reduce.markreset.buffer.percent
Handling deprecation for dfs.datanode.cache.revocation.polling.ms
Handling deprecation for mapreduce.reduce.speculative
Handling deprecation for yarn.nodemanager.localizer.cache.cleanup.interval-ms
Handling deprecation for dfs.namenode.lazypersist.file.scrub.interval.sec
Handling deprecation for fs.s3a.threads.core
Handling deprecation for mapreduce.jobhistory.recovery.store.fs.uri
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.start-time-read-cache-size
Handling deprecation for hadoop.registry.zk.retry.interval.ms
Handling deprecation for yarn.nodemanager.keytab
Handling deprecation for dfs.namenode.replication.interval
Handling deprecation for yarn.resourcemanager.admin.address
Handling deprecation for mapreduce.job.maps
Handling deprecation for nfs.dump.dir
Handling deprecation for mapreduce.job.user.name
Handling deprecation for mapreduce.jobtracker.maxtasks.perjob
Handling deprecation for mapreduce.job.ubertask.enable
Handling deprecation for mapreduce.job.reduce.class
Handling deprecation for yarn.nodemanager.delete.debug-delay-sec
Handling deprecation for yarn.timeline-service.ttl-enable
Handling deprecation for yarn.resourcemanager.fs.state-store.retry-policy-spec
Handling deprecation for mapreduce.reduce.skip.maxgroups
Handling deprecation for dfs.client.use.datanode.hostname
Handling deprecation for fs.trash.interval
Handling deprecation for mapreduce.job.name
Handling deprecation for mapreduce.am.max-attempts
Handling deprecation for mapreduce.jobtracker.heartbeats.in.second
Handling deprecation for yarn.resourcemanager.zk-num-retries
Handling deprecation for s3.blocksize
Handling deprecation for dfs.datanode.data.dir
Handling deprecation for mapreduce.jobtracker.persist.jobstatus.active
Handling deprecation for mapreduce.reduce.shuffle.parallelcopies
Handling deprecation for fs.s3.buffer.dir
Handling deprecation for mapreduce.jobhistory.done-dir
Handling deprecation for hadoop.security.instrumentation.requires.admin
Handling deprecation for hadoop.registry.zk.retry.ceiling.ms
Handling deprecation for nfs.rtmax
Handling deprecation for dfs.datanode.data.dir.perm
Handling deprecation for yarn.resourcemanager.container.liveness-monitor.interval-ms
Handling deprecation for yarn.nodemanager.env-whitelist
Handling deprecation for dfs.namenode.backup.address
Handling deprecation for dfs.namenode.xattrs.enabled
Handling deprecation for dfs.datanode.readahead.bytes
Handling deprecation for mapreduce.jobhistory.cleaner.enable
Handling deprecation for dfs.client.block.write.retries
Handling deprecation for mapreduce.tasktracker.http.address
Handling deprecation for yarn.nodemanager.linux-container-executor.cgroups.hierarchy
Handling deprecation for ha.failover-controller.graceful-fence.connection.retries
Handling deprecation for yarn.resourcemanager.recovery.enabled
Handling deprecation for yarn.app.mapreduce.am.container.log.backups
Handling deprecation for dfs.namenode.safemode.threshold-pct
Handling deprecation for yarn.nodemanager.disk-health-checker.interval-ms
Handling deprecation for hadoop.security.java.secure.random.algorithm
Handling deprecation for dfs.namenode.list.cache.directives.num.responses
Handling deprecation for dfs.datanode.dns.nameserver
Handling deprecation for mapreduce.cluster.temp.dir
Handling deprecation for fs.s3a.max.total.tasks
Handling deprecation for mapreduce.reduce.maxattempts
Handling deprecation for mapreduce.client.submit.file.replication
Handling deprecation for mapreduce.shuffle.port
Handling deprecation for yarn.resourcemanager.resource-tracker.client.thread-count
Handling deprecation for dfs.namenode.replication.considerLoad
Handling deprecation for dfs.namenode.edits.journal-plugin.qjournal
Handling deprecation for dfs.client.write.exclude.nodes.cache.expiry.interval.millis
Handling deprecation for yarn.nodemanager.delete.thread-count
Handling deprecation for dfs.client.mmap.cache.timeout.ms
Handling deprecation for yarn.nodemanager.admin-env
Handling deprecation for io.skip.checksum.errors
Handling deprecation for yarn.timeline-service.hostname
Handling deprecation for yarn.resourcemanager.proxy-user-privileges.enabled
Handling deprecation for mapreduce.job.speculative.speculative-cap-total-tasks
Handling deprecation for yarn.acl.enable
Handling deprecation for fs.s3a.fast.upload
Handling deprecation for file.blocksize
Handling deprecation for mapreduce.job.speculative.slowtaskthreshold
Handling deprecation for ftp.replication
Handling deprecation for yarn.sharedcache.cleaner.initial-delay-mins
Handling deprecation for s3native.client-write-packet-size
Handling deprecation for hadoop.rpc.socket.factory.class.default
Handling deprecation for file.bytes-per-checksum
Handling deprecation for dfs.datanode.slow.io.warning.threshold.ms
Handling deprecation for io.seqfile.lazydecompress
Handling deprecation for mapreduce.task.skip.start.attempts
Handling deprecation for dfs.namenode.reject-unresolved-dn-topology-mapping
Handling deprecation for hadoop.common.configuration.version
Handling deprecation for yarn.resourcemanager.client.thread-count
Handling deprecation for dfs.datanode.drop.cache.behind.reads
Handling deprecation for yarn.sharedcache.admin.address
Handling deprecation for mapreduce.job.output.value.class
Handling deprecation for mapreduce.output.fileoutputformat.outputdir
Handling deprecation for mapreduce.jobtracker.taskcache.levels
Handling deprecation for yarn.nodemanager.linux-container-executor.nonsecure-mode.user-pattern
Handling deprecation for yarn.resourcemanager.zk-timeout-ms
Handling deprecation for yarn.resourcemanager.max-completed-applications
Handling deprecation for mapreduce.job.jvm.numtasks
Handling deprecation for yarn.sharedcache.cleaner.period-mins
Handling deprecation for mapreduce.jobtracker.tasktracker.maxblacklists
Handling deprecation for dfs.namenode.top.num.users
Handling deprecation for yarn.nodemanager.linux-container-executor.cgroups.mount
Handling deprecation for yarn.sharedcache.checksum.algo.impl
Handling deprecation for mapreduce.job.end-notification.max.retry.interval
Handling deprecation for mapreduce.job.acl-view-job
Handling deprecation for mapreduce.job.classloader
Handling deprecation for yarn.log-aggregation-enable
Handling deprecation for mapreduce.reduce.shuffle.fetch.retry.interval-ms
Handling deprecation for yarn.resourcemanager.nodemanager.minimum.version
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.size
Handling deprecation for yarn.app.mapreduce.am.job.task.listener.thread-count
Handling deprecation for yarn.app.mapreduce.am.resource.cpu-vcores
Handling deprecation for dfs.namenode.edit.log.autoroll.check.interval.ms
Handling deprecation for mapreduce.output.fileoutputformat.compress.type
Handling deprecation for hadoop.hdfs.configuration.version
Handling deprecation for hadoop.security.group.mapping.ldap.search.attr.member
Handling deprecation for yarn.nodemanager.log.retain-seconds
Handling deprecation for yarn.nodemanager.local-cache.max-files-per-directory
Handling deprecation for mapreduce.job.end-notification.retry.interval
Handling deprecation for hadoop.ssl.client.conf
Handling deprecation for yarn.sharedcache.root-dir
Handling deprecation for dfs.journalnode.https-address
Handling deprecation for mapreduce.reduce.shuffle.fetch.retry.timeout-ms
Handling deprecation for dfs.bytes-per-checksum
Handling deprecation for dfs.namenode.max.objects
Handling deprecation for mapreduce.tasktracker.instrumentation
Handling deprecation for dfs.datanode.max.transfer.threads
Handling deprecation for dfs.block.access.key.update.interval
Handling deprecation for mapreduce.jobtracker.jobhistory.task.numberprogresssplits
Handling deprecation for mapreduce.map.memory.mb
Handling deprecation for ha.failover-controller.new-active.rpc-timeout.ms
Handling deprecation for hadoop.ssl.hostname.verifier
Handling deprecation for dfs.client.read.shortcircuit
Handling deprecation for dfs.datanode.hdfs-blocks-metadata.enabled
Handling deprecation for mapreduce.tasktracker.healthchecker.interval
Handling deprecation for dfs.image.transfer.chunksize
Handling deprecation for mapreduce.tasktracker.taskmemorymanager.monitoringinterval
Handling deprecation for dfs.client.https.keystore.resource
Handling deprecation for yarn.resourcemanager.connect.retry-interval.ms
Handling deprecation for yarn.timeline-service.webapp.address
Handling deprecation for s3native.blocksize
Handling deprecation for yarn.scheduler.minimum-allocation-mb
Handling deprecation for yarn.sharedcache.cleaner.resource-sleep-ms
Handling deprecation for net.topology.impl
Handling deprecation for dfs.client.failover.sleep.base.millis
Handling deprecation for dfs.permissions.superusergroup
Handling deprecation for io.seqfile.compress.blocksize
Handling deprecation for hadoop.registry.zk.retry.times
Handling deprecation for fs.AbstractFileSystem.ftp.impl
Handling deprecation for dfs.namenode.checkpoint.edits.dir
Handling deprecation for mapreduce.job.running.reduce.limit
Handling deprecation for dfs.blockreport.initialDelay
Handling deprecation for dfs.namenode.heartbeat.recheck-interval
Handling deprecation for dfs.namenode.safemode.extension
Handling deprecation for yarn.scheduler.maximum-allocation-mb
Handling deprecation for mapreduce.job.reduce.shuffle.consumer.plugin.class
Handling deprecation for yarn.nodemanager.vmem-check-enabled
Handling deprecation for mapreduce.task.io.sort.factor
Handling deprecation for mapreduce.jobtracker.persist.jobstatus.dir
Handling deprecation for dfs.client.failover.sleep.max.millis
Handling deprecation for dfs.namenode.delegation.key.update-interval
Handling deprecation for hadoop.rpc.protection
Handling deprecation for fs.permissions.umask-mode
Handling deprecation for fs.s3.sleepTimeSeconds
Handling deprecation for ha.health-monitor.rpc-timeout.ms
Handling deprecation for hadoop.http.staticuser.user
Handling deprecation for fs.s3a.connection.maximum
Handling deprecation for yarn.nodemanager.linux-container-executor.nonsecure-mode.limit-users
Handling deprecation for fs.s3a.paging.maximum
Handling deprecation for fs.AbstractFileSystem.viewfs.impl
Handling deprecation for fs.ftp.host
Handling deprecation for yarn.nodemanager.linux-container-executor.nonsecure-mode.local-user
Handling deprecation for fs.s3a.impl
Handling deprecation for hadoop.http.authentication.kerberos.keytab
Handling deprecation for dfs.namenode.fs-limits.max-blocks-per-file
Handling deprecation for mapreduce.tasktracker.http.threads
Handling deprecation for mapreduce.tasktracker.dns.nameserver
Handling deprecation for yarn.resourcemanager.am-rm-tokens.master-key-rolling-interval-secs
Handling deprecation for dfs.client.block.write.replace-datanode-on-failure.enable
Handling deprecation for io.compression.codec.bzip2.library
Handling deprecation for mapreduce.map.skip.maxrecords
Handling deprecation for dfs.client.use.legacy.blockreader.local
Handling deprecation for dfs.namenode.checkpoint.dir
Handling deprecation for dfs.namenode.top.windows.minutes
Handling deprecation for mapreduce.job.maxtaskfailures.per.tracker
Handling deprecation for net.topology.node.switch.mapping.impl
Handling deprecation for mapreduce.shuffle.max.connections
Handling deprecation for mapreduce.jobhistory.loadedjobs.cache.size
Handling deprecation for dfs.storage.policy.enabled
Handling deprecation for yarn.client.application-client-protocol.poll-interval-ms
Handling deprecation for yarn.nodemanager.localizer.address
Handling deprecation for dfs.namenode.list.cache.pools.num.responses
Handling deprecation for nfs.server.port
Handling deprecation for mapreduce.client.output.filter
Handling deprecation for yarn.timeline-service.client.best-effort
Handling deprecation for ha.zookeeper.parent-znode
Handling deprecation for mapreduce.jobtracker.persist.jobstatus.hours
Handling deprecation for yarn.sharedcache.admin.thread-count
Handling deprecation for yarn.nodemanager.resource.cpu-vcores
Handling deprecation for dfs.datanode.block-pinning.enabled
Handling deprecation for mapreduce.jobhistory.http.policy
Handling deprecation for yarn.resourcemanager.webapp.delegation-token-auth-filter.enabled
Handling deprecation for mapreduce.job.speculative.retry-after-no-speculate
Handling deprecation for fs.s3a.attempts.maximum
Handling deprecation for s3native.stream-buffer-size
Handling deprecation for io.seqfile.local.dir
Handling deprecation for yarn.log-aggregation.retain-check-interval-seconds
Handling deprecation for fs.s3n.multipart.copy.block.size
Handling deprecation for dfs.encrypt.data.transfer.cipher.key.bitlength
Handling deprecation for dfs.datanode.sync.behind.writes
Handling deprecation for yarn.resourcemanager.zk-acl
Handling deprecation for hadoop.ssl.keystores.factory.class
Handling deprecation for mapreduce.job.split.metainfo.maxsize
Handling deprecation for fs.s3.maxRetries
Handling deprecation for hadoop.security.random.device.file.path
Handling deprecation for yarn.client.nodemanager-connect.max-wait-ms
Handling deprecation for dfs.namenode.stale.datanode.interval
Handling deprecation for mapreduce.task.io.sort.mb
Handling deprecation for yarn.resourcemanager.zk-state-store.parent-path
Handling deprecation for yarn.app.mapreduce.client-am.ipc.max-retries
Handling deprecation for fs.client.resolve.remote.symlinks
Handling deprecation for yarn.nodemanager.linux-container-executor.cgroups.strict-resource-usage
Handling deprecation for hadoop.ssl.enabled.protocols
Handling deprecation for mapreduce.reduce.cpu.vcores
Handling deprecation for yarn.client.failover-retries
Handling deprecation for mapreduce.jobhistory.address
Handling deprecation for hadoop.ssl.enabled
Handling deprecation for dfs.replication.max
Handling deprecation for dfs.namenode.name.dir
Handling deprecation for dfs.datanode.https.address
Handling deprecation for ipc.client.kill.max
Handling deprecation for mapreduce.job.committer.setup.cleanup.needed
Handling deprecation for dfs.client.domain.socket.data.traffic
Handling deprecation for yarn.nodemanager.localizer.cache.target-size-mb
Handling deprecation for yarn.resourcemanager.admin.client.thread-count
Handling deprecation for dfs.block.access.token.enable
Handling deprecation for mapreduce.job.speculative.retry-after-speculate
Handling deprecation for dfs.datanode.address
Handling deprecation for mapreduce.jobtracker.restart.recover
Handling deprecation for ipc.client.connect.max.retries
Handling deprecation for yarn.timeline-service.store-class
Handling deprecation for dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
Handling deprecation for hadoop.tmp.dir
Handling deprecation for dfs.datanode.handler.count
Handling deprecation for yarn.resourcemanager.ha.automatic-failover.embedded
Handling deprecation for yarn.timeline-service.ttl-ms
Handling deprecation for mapreduce.task.profile.map.params
Handling deprecation for yarn.resourcemanager.nodemanagers.heartbeat-interval-ms
Handling deprecation for mapreduce.map.speculative
Handling deprecation for yarn.timeline-service.recovery.enabled
Handling deprecation for mapreduce.job.map.class
Handling deprecation for dfs.namenode.resource.checked.volumes.minimum
Handling deprecation for yarn.nodemanager.recovery.dir
Handling deprecation for mapreduce.job.counters.max
Handling deprecation for yarn.resourcemanager.keytab
Handling deprecation for dfs.namenode.max.extra.edits.segments.retained
Handling deprecation for dfs.webhdfs.user.provider.user.pattern
Handling deprecation for dfs.client.mmap.enabled
Handling deprecation for mapreduce.map.log.level
Handling deprecation for dfs.client.file-block-storage-locations.timeout.millis
Handling deprecation for yarn.client.max-cached-nodemanagers-proxies
Handling deprecation for yarn.app.mapreduce.am.scheduler.heartbeat.interval-ms
Handling deprecation for hadoop.fuse.timer.period
Handling deprecation for fs.trash.checkpoint.interval
Handling deprecation for yarn.sharedcache.app-checker.class
Handling deprecation for dfs.journalnode.http-address
Handling deprecation for yarn.app.mapreduce.am.staging-dir
Handling deprecation for mapreduce.tasktracker.local.dir.minspacestart
Handling deprecation for yarn.nm.liveness-monitor.expiry-interval-ms
Handling deprecation for ha.health-monitor.check-interval.ms
Handling deprecation for mapreduce.reduce.shuffle.merge.percent
Handling deprecation for dfs.namenode.retrycache.heap.percent
Handling deprecation for yarn.nodemanager.docker-container-executor.exec-name
Handling deprecation for ipc.client.connect.timeout
Handling deprecation for yarn.resourcemanager.fs.state-store.retry-interval-ms
Handling deprecation for mapreduce.output.fileoutputformat.compress
Handling deprecation for yarn.nodemanager.local-dirs
Handling deprecation for yarn.nodemanager.recovery.enabled
Handling deprecation for io.native.lib.available
Handling deprecation for yarn.sharedcache.store.in-memory.staleness-period-mins
Handling deprecation for yarn.resourcemanager.am.max-attempts
Handling deprecation for s3.replication
Handling deprecation for mapreduce.input.fileinputformat.inputdir
Handling deprecation for fs.AbstractFileSystem.har.impl
Handling deprecation for dfs.image.compress
Handling deprecation for mapreduce.job.running.map.limit
Handling deprecation for mapreduce.reduce.input.buffer.percent
Handling deprecation for yarn.nodemanager.webapp.address
Handling deprecation for dfs.datanode.available-space-volume-choosing-policy.balanced-space-preference-fraction
Handling deprecation for dfs.namenode.edit.log.autoroll.multiplier.threshold
Handling deprecation for hadoop.security.group.mapping.ldap.ssl
Handling deprecation for dfs.namenode.checkpoint.check.period
Handling deprecation for fs.defaultFS
Handling deprecation for fs.s3a.multipart.size
Handling deprecation for dfs.client.slow.io.warning.threshold.ms
Handling deprecation for yarn.app.mapreduce.am.job.committer.commit-window
Handling deprecation for hadoop.security.group.mapping.ldap.search.attr.group.name
Handling deprecation for yarn.nodemanager.disk-health-checker.max-disk-utilization-per-disk-percentage
Handling deprecation for yarn.nodemanager.container-monitor.procfs-tree.smaps-based-rss.enabled
Handling deprecation for mapreduce.job.submithostname
Handling deprecation for mapreduce.map.sort.spill.percent
Handling deprecation for hadoop.security.crypto.codec.classes.aes.ctr.nopadding
Handling deprecation for dfs.namenode.http-address
Handling deprecation for hadoop.security.groups.negative-cache.secs
Handling deprecation for hadoop.ssl.server.conf
Handling deprecation for mapreduce.ifile.readahead
Handling deprecation for s3native.replication
Handling deprecation for yarn.client.nodemanager-client-async.thread-pool-max-size
Handling deprecation for mapreduce.jobtracker.staging.root.dir
Handling deprecation for mapreduce.jobhistory.admin.address
Handling deprecation for dfs.namenode.startup.delay.block.deletion.sec
Handling deprecation for yarn.nodemanager.health-checker.interval-ms
Handling deprecation for dfs.namenode.checkpoint.max-retries
Handling deprecation for s3.stream-buffer-size
Handling deprecation for ftp.client-write-packet-size
Handling deprecation for dfs.datanode.fsdatasetcache.max.threads.per.volume
Handling deprecation for mapreduce.output.fileoutputformat.compress.codec
Handling deprecation for yarn.timeline-service.keytab
Handling deprecation for yarn.sharedcache.store.in-memory.initial-delay-mins
Handling deprecation for mapreduce.jobhistory.webapp.address
Handling deprecation for mapreduce.task.userlog.limit.kb
Handling deprecation for mapreduce.reduce.shuffle.fetch.retry.enabled
Handling deprecation for yarn.app.mapreduce.task.container.log.backups
Handling deprecation for dfs.heartbeat.interval
Handling deprecation for ha.zookeeper.session-timeout.ms
Handling deprecation for fs.s3a.connection.ssl.enabled
Handling deprecation for yarn.sharedcache.webapp.address
Handling deprecation for hadoop.http.authentication.signature.secret.file
Handling deprecation for hadoop.fuse.connection.timeout
Handling deprecation for mapreduce.input.fileinputformat.numinputfiles
Handling deprecation for yarn.nodemanager.log-aggregation.compression-type
Handling deprecation for ipc.server.max.connections
Handling deprecation for yarn.resourcemanager.work-preserving-recovery.scheduling-wait-ms
Handling deprecation for yarn.nodemanager.log-dirs
Handling deprecation for yarn.app.mapreduce.am.resource.mb
Handling deprecation for hadoop.security.groups.cache.secs
Handling deprecation for mapreduce.job.speculative.minimum-allowed-tasks
Handling deprecation for yarn.nodemanager.container-monitor.interval-ms
Handling deprecation for dfs.datanode.cache.revocation.timeout.ms
Handling deprecation for mapreduce.jobhistory.recovery.store.class
Handling deprecation for mapreduce.task.combine.progress.records
Handling deprecation for s3.client-write-packet-size
Handling deprecation for mapreduce.jobtracker.instrumentation
Handling deprecation for dfs.replication
Handling deprecation for mapreduce.shuffle.transfer.buffer.size
Handling deprecation for hadoop.security.group.mapping.ldap.directory.search.timeout
Handling deprecation for dfs.datanode.available-space-volume-choosing-policy.balanced-space-threshold
Handling deprecation for hadoop.work.around.non.threadsafe.getpwuid
Handling deprecation for yarn.app.mapreduce.client-am.ipc.max-retries-on-timeouts
Handling deprecation for yarn.nodemanager.address
Handling deprecation for mapreduce.tasktracker.taskcontroller
Handling deprecation for mapreduce.tasktracker.indexcache.mb
Handling deprecation for yarn.scheduler.maximum-allocation-vcores
Handling deprecation for mapreduce.job.reduces
Handling deprecation for yarn.nodemanager.sleep-delay-before-sigkill.ms
Handling deprecation for yarn.timeline-service.address
Handling deprecation for yarn.resourcemanager.configuration.provider-class
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.expiry
Handling deprecation for yarn.sharedcache.enabled
Handling deprecation for tfile.io.chunk.size
Handling deprecation for mapreduce.job.acl-modify-job
Handling deprecation for hadoop.registry.zk.session.timeout.ms
Handling deprecation for fs.automatic.close
Handling deprecation for ha.health-monitor.sleep-after-disconnect.ms
Handling deprecation for mapreduce.tasktracker.reduce.tasks.maximum
Handling deprecation for mapreduce.input.fileinputformat.list-status.num-threads
Handling deprecation for dfs.datanode.directoryscan.threads
Handling deprecation for dfs.datanode.directoryscan.interval
Handling deprecation for dfs.namenode.acls.enabled
Handling deprecation for dfs.client.short.circuit.replica.stale.threshold.ms
Handling deprecation for hadoop.http.authentication.token.validity
Handling deprecation for fs.s3.block.size
Handling deprecation for ha.failover-controller.graceful-fence.rpc-timeout.ms
Handling deprecation for mapreduce.tasktracker.local.dir.minspacekill
Handling deprecation for dfs.namenode.resource.du.reserved
Handling deprecation for mapreduce.jobhistory.cleaner.interval-ms
Handling deprecation for dfs.namenode.datanode.registration.ip-hostname-check
Handling deprecation for mapreduce.jobhistory.intermediate-done-dir
Handling deprecation for mapreduce.jobtracker.http.address
Handling deprecation for dfs.namenode.backup.http-address
Handling deprecation for dfs.namenode.edits.noeditlogchannelflush
Handling deprecation for mapreduce.reduce.shuffle.input.buffer.percent
Handling deprecation for mapreduce.map.maxattempts
Handling deprecation for yarn.http.policy
Handling deprecation for dfs.namenode.audit.loggers
Handling deprecation for hadoop.security.groups.cache.warn.after.ms
Handling deprecation for io.serializations
Handling deprecation for mapreduce.tasktracker.outofband.heartbeat
Handling deprecation for mapreduce.reduce.shuffle.read.timeout
Handling deprecation for hadoop.security.crypto.buffer.size
Handling deprecation for mapreduce.reduce.skip.proc.count.autoincr
Handling deprecation for mapreduce.ifile.readahead.bytes
Handling deprecation for dfs.http.policy
Handling deprecation for hadoop.registry.secure
Handling deprecation for dfs.namenode.safemode.min.datanodes
Handling deprecation for dfs.client.file-block-storage-locations.num-threads
Handling deprecation for mapreduce.cluster.local.dir
Handling deprecation for mapreduce.tasktracker.report.address
Handling deprecation for dfs.namenode.secondary.https-address
Handling deprecation for hadoop.kerberos.kinit.command
Handling deprecation for yarn.timeline-service.http-authentication.type
Handling deprecation for dfs.block.access.token.lifetime
Handling deprecation for dfs.webhdfs.enabled
Handling deprecation for dfs.namenode.delegation.token.max-lifetime
Handling deprecation for dfs.namenode.avoid.write.stale.datanode
Handling deprecation for dfs.datanode.drop.cache.behind.writes
Handling deprecation for yarn.log-aggregation.retain-seconds
Handling deprecation for mapreduce.job.complete.cancel.delegation.tokens
Handling deprecation for mapreduce.local.clientfactory.class.name
Handling deprecation for mapreduce.shuffle.connection-keep-alive.timeout
Handling deprecation for dfs.namenode.num.extra.edits.retained
Handling deprecation for yarn.scheduler.minimum-allocation-vcores
Handling deprecation for ipc.client.connect.max.retries.on.timeouts
Handling deprecation for yarn.timeline-service.client.retry-interval-ms
Handling deprecation for yarn.timeline-service.client.max-retries
Handling deprecation for fs.s3n.block.size
Handling deprecation for mapreduce.job.map.output.collector.class
Handling deprecation for ha.health-monitor.connect-retry-interval.ms
Handling deprecation for mapreduce.shuffle.max.threads
Handling deprecation for nfs.exports.allowed.hosts
Handling deprecation for dfs.client.mmap.cache.size
Handling deprecation for mapreduce.tasktracker.map.tasks.maximum
Handling deprecation for io.file.buffer.size
Handling deprecation for dfs.client.datanode-restart.timeout
Handling deprecation for io.mapfile.bloom.size
Handling deprecation for hadoop.security.kms.client.authentication.retry-count
Handling deprecation for dfs.namenode.checkpoint.txns
Handling deprecation for ipc.client.connect.retry.interval
Handling deprecation for dfs.client-write-packet-size
Handling deprecation for mapreduce.reduce.shuffle.connect.timeout
Handling deprecation for yarn.resourcemanager.fs.state-store.uri
Handling deprecation for fs.swift.impl
Handling deprecation for hadoop.registry.zk.connection.timeout.ms
Handling deprecation for mapred.queue.default.acl-administer-jobs
Handling deprecation for mapreduce.job.submithostaddress
Handling deprecation for dfs.cachereport.intervalMsec
Handling deprecation for yarn.app.mapreduce.shuffle.log.backups
Handling deprecation for yarn.app.mapreduce.am.container.log.limit.kb
Handling deprecation for yarn.nodemanager.resourcemanager.minimum.version
Handling deprecation for ftp.blocksize
Handling deprecation for yarn.resourcemanager.address
Handling deprecation for file.stream-buffer-size
Handling deprecation for yarn.resourcemanager.scheduler.monitor.enable
Handling deprecation for mapreduce.job.ubertask.maxreduces
Handling deprecation for nfs.allow.insecure.ports
Handling deprecation for yarn.sharedcache.nm.uploader.thread-count
Handling deprecation for ipc.client.idlethreshold
Handling deprecation for ftp.stream-buffer-size
Handling deprecation for yarn.sharedcache.client-server.address
Handling deprecation for dfs.client.failover.connection.retries.on.timeouts
Handling deprecation for dfs.namenode.replication.work.multiplier.per.iteration
Handling deprecation for hadoop.http.authentication.simple.anonymous.allowed
Handling deprecation for hadoop.security.authorization
Handling deprecation for yarn.client.nodemanager-connect.retry-interval-ms
Handling deprecation for yarn.am.liveness-monitor.expiry-interval-ms
Handling deprecation for fs.har.impl.disable.cache
Handling deprecation for yarn.nodemanager.linux-container-executor.resources-handler.class
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.read-cache-size
Handling deprecation for hadoop.security.authentication
Handling deprecation for dfs.image.compression.codec
Handling deprecation for mapreduce.task.files.preserve.failedtasks
Handling deprecation for dfs.client.read.shortcircuit.streams.cache.size
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.path
Handling deprecation for mapreduce.job.reduce.slowstart.completedmaps
Handling deprecation for mapreduce.jobhistory.minicluster.fixed.ports
Handling deprecation for file.replication
Handling deprecation for yarn.resourcemanager.ha.automatic-failover.enabled
Handling deprecation for mapreduce.job.userlog.retain.hours
Handling deprecation for mapreduce.jobhistory.joblist.cache.size
Handling deprecation for dfs.namenode.accesstime.precision
Handling deprecation for yarn.resourcemanager.work-preserving-recovery.enabled
Handling deprecation for dfs.namenode.fs-limits.max-xattrs-per-inode
Handling deprecation for io.mapfile.bloom.error.rate
Handling deprecation for yarn.resourcemanager.store.class
Handling deprecation for dfs.image.transfer.timeout
Handling deprecation for yarn.timeline-service.leveldb-state-store.path
Handling deprecation for nfs.wtmax
Handling deprecation for mapreduce.job.combine.class
Handling deprecation for dfs.namenode.support.allow.format
Handling deprecation for fs.s3a.multipart.purge
Handling deprecation for dfs.secondary.namenode.kerberos.internal.spnego.principal
Handling deprecation for fs.s3a.connection.establish.timeout
Handling deprecation for dfs.stream-buffer-size
Handling deprecation for dfs.namenode.invalidate.work.pct.per.iteration
Handling deprecation for yarn.nodemanager.container-executor.class
Handling deprecation for fs.s3a.multipart.purge.age
Handling deprecation for yarn.resourcemanager.scheduler.client.thread-count
Handling deprecation for dfs.namenode.top.enabled
Handling deprecation for yarn.app.mapreduce.shuffle.log.separate
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.low-watermark
Handling deprecation for fs.s3a.fast.buffer.size
Handling deprecation for hadoop.user.group.static.mapping.overrides
Handling deprecation for tfile.fs.input.buffer.size
Handling deprecation for dfs.client.cached.conn.retry
Handling deprecation for hadoop.http.authentication.type
Handling deprecation for dfs.namenode.list.encryption.zones.num.responses
Handling deprecation for mapreduce.map.cpu.vcores
Handling deprecation for dfs.namenode.path.based.cache.refresh.interval.ms
Handling deprecation for dfs.namenode.decommission.interval
Handling deprecation for dfs.namenode.fs-limits.max-directory-items
Handling deprecation for yarn.resourcemanager.zk-retry-interval-ms
Handling deprecation for ftp.bytes-per-checksum
Handling deprecation for dfs.ha.log-roll.period
Handling deprecation for dfs.user.home.dir.prefix
Handling deprecation for ipc.client.fallback-to-simple-auth-allowed
Handling deprecation for yarn.nodemanager.pmem-check-enabled
Handling deprecation for yarn.nodemanager.remote-app-log-dir
Handling deprecation for dfs.namenode.inotify.max.events.per.rpc
Handling deprecation for mapreduce.task.profile.maps
Handling deprecation for mapreduce.shuffle.ssl.file.buffer.size
Handling deprecation for mapreduce.tasktracker.healthchecker.script.timeout
Handling deprecation for yarn.timeline-service.webapp.https.address
Handling deprecation for yarn.nodemanager.resource.percentage-physical-cpu-limit
Handling deprecation for yarn.app.mapreduce.am.command-opts
Handling deprecation for dfs.namenode.fs-limits.max-xattr-size
Handling deprecation for dfs.datanode.http.address
Handling deprecation for dfs.namenode.blocks.per.postponedblocks.rescan
Handling deprecation for yarn.sharedcache.nm.uploader.replication.factor
Handling deprecation for hadoop.registry.zk.root
Handling deprecation for hadoop.jetty.logs.serve.aliases
Handling deprecation for yarn.client.failover-proxy-provider
Handling deprecation for mapreduce.jobhistory.admin.acl
Handling deprecation for yarn.app.mapreduce.am.hard-kill-timeout-ms
Handling deprecation for yarn.nodemanager.remote-app-log-dir-suffix
Handling deprecation for mapreduce.jobhistory.principal
Handling deprecation for yarn.resourcemanager.webapp.address
Handling deprecation for mapreduce.jobhistory.recovery.enable
Handling deprecation for yarn.sharedcache.store.in-memory.check-period-mins
Handling deprecation for nfs.mountd.port
Handling deprecation for mapreduce.reduce.merge.inmem.threshold
Handling deprecation for fs.df.interval
Handling deprecation for yarn.timeline-service.enabled
Handling deprecation for mapreduce.jobtracker.jobhistory.lru.cache.size
Handling deprecation for mapreduce.task.profile
Handling deprecation for mapreduce.job.output.key.class
Handling deprecation for yarn.nodemanager.hostname
Handling deprecation for dfs.namenode.num.checkpoints.retained
Handling deprecation for mapreduce.job.queuename
Handling deprecation for mapreduce.jobhistory.max-age-ms
Handling deprecation for mapreduce.job.token.tracking.ids.enabled
Handling deprecation for yarn.nodemanager.localizer.client.thread-count
Handling deprecation for yarn.sharedcache.uploader.server.thread-count
Handling deprecation for dfs.client.mmap.retry.timeout.ms
Handling deprecation for mapreduce.jobhistory.move.thread-count
Handling deprecation for dfs.permissions.enabled
Handling deprecation for dfs.blockreport.split.threshold
Handling deprecation for fs.AbstractFileSystem.hdfs.impl
Handling deprecation for dfs.datanode.balance.bandwidthPerSec
Handling deprecation for dfs.block.scanner.volume.bytes.per.second
Handling deprecation for hadoop.http.filter.initializers
Handling deprecation for yarn.timeline-service.http-authentication.simple.anonymous.allowed
Handling deprecation for dfs.default.chunk.view.size
Handling deprecation for yarn.sharedcache.client-server.thread-count
Handling deprecation for yarn.resourcemanager.resource-tracker.address
Handling deprecation for mapreduce.job.working.dir
Handling deprecation for mapreduce.jobhistory.datestring.cache.size
Handling deprecation for mapreduce.task.profile.params
Handling deprecation for dfs.namenode.decommission.blocks.per.interval
Handling deprecation for dfs.namenode.handler.count
Handling deprecation for dfs.image.transfer.bandwidthPerSec
Handling deprecation for rpc.metrics.quantile.enable
Handling deprecation for mapreduce.jobtracker.expire.trackers.interval
Handling deprecation for mapreduce.task.timeout
Handling deprecation for yarn.app.mapreduce.client.max-retries
Handling deprecation for yarn.nodemanager.resource.memory-mb
Handling deprecation for yarn.nodemanager.disk-health-checker.min-healthy-disks
Handling deprecation for dfs.datanode.failed.volumes.tolerated
Handling deprecation for yarn.timeline-service.handler-thread-count
Handling deprecation for ipc.server.listen.queue.size
Handling deprecation for fs.s3a.threads.max
Handling deprecation for yarn.resourcemanager.connect.max-wait.ms
Handling deprecation for mapreduce.fileoutputcommitter.algorithm.version
Handling deprecation for mapreduce.framework.name
Handling deprecation for mapreduce.map.skip.proc.count.autoincr
Handling deprecation for mapreduce.job.max.split.locations
Handling deprecation for yarn.resourcemanager.scheduler.class
Handling deprecation for yarn.resourcemanager.system-metrics-publisher.enabled
Handling deprecation for dfs.blocksize
Handling deprecation for yarn.sharedcache.nested-level
Handling deprecation for mapreduce.shuffle.connection-keep-alive.enable
Handling deprecation for fs.s3a.threads.keepalivetime
Handling deprecation for fs.s3a.connection.timeout
Handling deprecation for file.client-write-packet-size
Handling deprecation for ha.failover-controller.cli-check.rpc-timeout.ms
Handling deprecation for ha.zookeeper.acl
Handling deprecation for dfs.namenode.write.stale.datanode.ratio
Handling deprecation for dfs.encrypt.data.transfer
Handling deprecation for dfs.datanode.shared.file.descriptor.paths
Handling deprecation for mapreduce.input.lineinputformat.linespermap
Handling deprecation for yarn.resourcemanager.delayed.delegation-token.removal-interval-ms
Handling deprecation for yarn.nodemanager.localizer.fetch.thread-count
Handling deprecation for dfs.client.failover.max.attempts
Handling deprecation for yarn.resourcemanager.scheduler.address
Handling deprecation for dfs.client.read.shortcircuit.streams.cache.expiry.ms
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.start-time-write-cache-size
Handling deprecation for yarn.nodemanager.health-checker.script.timeout-ms
Handling deprecation for yarn.resourcemanager.fs.state-store.num-retries
Handling deprecation for hadoop.ssl.require.client.cert
Handling deprecation for hadoop.security.uid.cache.secs
Handling deprecation for mapreduce.jobhistory.keytab
Handling deprecation for dfs.client.read.shortcircuit.skip.checksum
Handling deprecation for yarn.resourcemanager.ha.automatic-failover.zk-base-path
Handling deprecation for mapreduce.shuffle.ssl.enabled
Handling deprecation for mapreduce.reduce.log.level
Handling deprecation for hadoop.registry.rm.enabled
Handling deprecation for mapreduce.tasktracker.dns.interface
Handling deprecation for yarn.resourcemanager.system-metrics-publisher.dispatcher.pool-size
Handling deprecation for mapreduce.job.speculative.speculative-cap-running-tasks
Handling deprecation for dfs.datanode.block.id.layout.upgrade.threads
Handling deprecation for dfs.datanode.use.datanode.hostname
Handling deprecation for dfs.client.context
Handling deprecation for yarn.resourcemanager.ha.enabled
Handling deprecation for mapred.reducer.new-api
Handling deprecation for dfs.namenode.delegation.token.renew-interval
Handling deprecation for dfs.blockreport.intervalMsec
Handling deprecation for fs.s3a.multipart.threshold
Handling deprecation for mapreduce.reduce.shuffle.memory.limit.percent
Handling deprecation for dfs.https.server.keystore.resource
Handling deprecation for io.map.index.skip
Handling deprecation for mapreduce.job.hdfs-servers
Handling deprecation for mapreduce.jobtracker.taskscheduler
Handling deprecation for dfs.namenode.kerberos.internal.spnego.principal
Handling deprecation for yarn.resourcemanager.state-store.max-completed-applications
Handling deprecation for mapreduce.map.output.compress
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.num.refill.threads
Handling deprecation for fs.s3n.multipart.uploads.block.size
Handling deprecation for mapreduce.task.merge.progress.records
Handling deprecation for dfs.datanode.dns.interface
Handling deprecation for map.sort.class
Handling deprecation for yarn.nodemanager.aux-services.mapreduce_shuffle.class
Handling deprecation for tfile.fs.output.buffer.size
Handling deprecation for fs.du.interval
Handling deprecation for dfs.client.failover.connection.retries
Handling deprecation for dfs.namenode.top.window.num.buckets
Handling deprecation for mapreduce.job.dir
Handling deprecation for fs.s3a.buffer.dir
Handling deprecation for mapreduce.reduce.shuffle.retry-delay.max.ms
Handling deprecation for yarn.sharedcache.uploader.server.address
Handling deprecation for mapreduce.client.progressmonitor.pollinterval
Handling deprecation for yarn.app.mapreduce.shuffle.log.limit.kb
Handling deprecation for dfs.datanode.max.locked.memory
Handling deprecation for dfs.namenode.retrycache.expirytime.millis
Handling deprecation for dfs.datanode.scan.period.hours
Handling deprecation for dfs.client.block.write.replace-datanode-on-failure.best-effort
Handling deprecation for mapreduce.jobhistory.move.interval-ms
Handling deprecation for dfs.ha.fencing.ssh.connect-timeout
Handling deprecation for yarn.nodemanager.log-aggregation.roll-monitoring-interval-seconds
Handling deprecation for dfs.namenode.fs-limits.max-component-length
Handling deprecation for hadoop.registry.zk.quorum
Handling deprecation for dfs.namenode.enable.retrycache
Handling deprecation for dfs.datanode.du.reserved
Handling deprecation for yarn.timeline-service.state-store-class
Handling deprecation for dfs.datanode.ipc.address
Handling deprecation for hadoop.registry.system.acls
Handling deprecation for dfs.client.block.write.replace-datanode-on-failure.policy
Handling deprecation for dfs.namenode.path.based.cache.retry.interval.ms
Handling deprecation for hadoop.security.crypto.cipher.suite
Handling deprecation for dfs.ha.tail-edits.period
Handling deprecation for mapreduce.task.profile.reduce.params
Handling deprecation for hadoop.registry.jaas.context
Handling deprecation for yarn.resourcemanager.hostname
Handling deprecation for mapreduce.reduce.memory.mb
Handling deprecation for hadoop.security.group.mapping.ldap.search.filter.group
Handling deprecation for hadoop.http.authentication.kerberos.principal
Handling deprecation for hadoop.security.group.mapping.ldap.search.filter.user
Handling deprecation for yarn.nodemanager.disk-health-checker.min-free-space-per-disk-mb
Handling deprecation for dfs.namenode.edits.dir
Handling deprecation for yarn.client.failover-retries-on-socket-timeouts
Handling deprecation for dfs.namenode.decommission.max.concurrent.tracked.nodes
Handling deprecation for mapreduce.client.completion.pollinterval
Handling deprecation for dfs.namenode.name.dir.restore
Handling deprecation for dfs.namenode.secondary.http-address
Handling deprecation for mapreduce.jobhistory.recovery.store.leveldb.path
Handling deprecation for yarn.sharedcache.store.class
Handling deprecation for s3.bytes-per-checksum
Handling deprecation for yarn.nodemanager.windows-container.cpu-limit.enabled
Handling deprecation for yarn.resourcemanager.webapp.https.address
Handling deprecation for yarn.nodemanager.vmem-pmem-ratio
Handling deprecation for dfs.namenode.checkpoint.period
Handling deprecation for dfs.ha.automatic-failover.enabled
Submitting tokens for job: job_local1326756033_0003
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.fs.FileContext.getAbstractFileSystem(FileContext.java:331)
Handling deprecation for all properties in config...
Handling deprecation for mapreduce.jobtracker.address
Handling deprecation for yarn.resourcemanager.scheduler.monitor.policies
Handling deprecation for dfs.namenode.resource.check.interval
Handling deprecation for mapreduce.jobhistory.client.thread-count
Handling deprecation for yarn.app.mapreduce.am.containerlauncher.threadpool-initial-size
Handling deprecation for mapred.child.java.opts
Handling deprecation for mapreduce.jobtracker.retiredjobs.cache.size
Handling deprecation for dfs.client.https.need-auth
Handling deprecation for yarn.admin.acl
Handling deprecation for yarn.app.mapreduce.am.job.committer.cancel-timeout
Handling deprecation for mapreduce.job.emit-timeline-data
Handling deprecation for fs.ftp.host.port
Handling deprecation for dfs.namenode.avoid.read.stale.datanode
Handling deprecation for dfs.journalnode.rpc-address
Handling deprecation for mapreduce.job.end-notification.retry.attempts
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.ttl-interval-ms
Handling deprecation for yarn.resourcemanager.leveldb-state-store.path
Handling deprecation for mapred.mapper.new-api
Handling deprecation for yarn.ipc.rpc.class
Handling deprecation for ipc.client.connection.maxidletime
Handling deprecation for yarn.nodemanager.process-kill-wait.ms
Handling deprecation for mapreduce.cluster.acls.enabled
Handling deprecation for mapreduce.jobtracker.handler.count
Handling deprecation for io.map.index.interval
Handling deprecation for dfs.namenode.https-address
Handling deprecation for mapreduce.task.profile.reduces
Handling deprecation for fs.s3n.multipart.uploads.enabled
Handling deprecation for io.seqfile.sorter.recordlimit
Handling deprecation for mapreduce.job.ubertask.maxmaps
Handling deprecation for mapreduce.tasktracker.tasks.sleeptimebeforesigkill
Handling deprecation for hadoop.util.hash.type
Handling deprecation for dfs.namenode.replication.min
Handling deprecation for yarn.nodemanager.container-manager.thread-count
Handling deprecation for mapreduce.jobtracker.jobhistory.block.size
Handling deprecation for dfs.namenode.fs-limits.min-block-size
Handling deprecation for mapreduce.app-submission.cross-platform
Handling deprecation for fs.AbstractFileSystem.file.impl
Handling deprecation for net.topology.script.number.args
Handling deprecation for yarn.resourcemanager.container-tokens.master-key-rolling-interval-secs
Handling deprecation for mapreduce.map.output.compress.codec
Handling deprecation for mapreduce.job.reducer.preempt.delay.sec
Handling deprecation for s3native.bytes-per-checksum
Handling deprecation for dfs.namenode.path.based.cache.block.map.allocation.percent
Handling deprecation for yarn.nodemanager.windows-container.memory-limit.enabled
Handling deprecation for mapreduce.input.fileinputformat.split.minsize
Handling deprecation for hadoop.security.group.mapping
Handling deprecation for mapreduce.jobtracker.system.dir
Handling deprecation for mapreduce.job.end-notification.max.attempts
Handling deprecation for mapreduce.reduce.markreset.buffer.percent
Handling deprecation for dfs.datanode.cache.revocation.polling.ms
Handling deprecation for mapreduce.reduce.speculative
Handling deprecation for yarn.nodemanager.localizer.cache.cleanup.interval-ms
Handling deprecation for dfs.namenode.lazypersist.file.scrub.interval.sec
Handling deprecation for fs.s3a.threads.core
Handling deprecation for mapreduce.jobhistory.recovery.store.fs.uri
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.start-time-read-cache-size
Handling deprecation for hadoop.registry.zk.retry.interval.ms
Handling deprecation for yarn.nodemanager.keytab
Handling deprecation for dfs.namenode.replication.interval
Handling deprecation for yarn.resourcemanager.admin.address
Handling deprecation for mapreduce.job.maps
Handling deprecation for nfs.dump.dir
Handling deprecation for mapreduce.job.user.name
Handling deprecation for mapreduce.jobtracker.maxtasks.perjob
Handling deprecation for mapreduce.job.ubertask.enable
Handling deprecation for mapreduce.job.reduce.class
Handling deprecation for yarn.nodemanager.delete.debug-delay-sec
Handling deprecation for yarn.timeline-service.ttl-enable
Handling deprecation for yarn.resourcemanager.fs.state-store.retry-policy-spec
Handling deprecation for mapreduce.reduce.skip.maxgroups
Handling deprecation for dfs.client.use.datanode.hostname
Handling deprecation for fs.trash.interval
Handling deprecation for mapreduce.job.name
Handling deprecation for mapreduce.am.max-attempts
Handling deprecation for mapreduce.jobtracker.heartbeats.in.second
Handling deprecation for yarn.resourcemanager.zk-num-retries
Handling deprecation for s3.blocksize
Handling deprecation for dfs.datanode.data.dir
Handling deprecation for mapreduce.jobtracker.persist.jobstatus.active
Handling deprecation for mapreduce.reduce.shuffle.parallelcopies
Handling deprecation for fs.s3.buffer.dir
Handling deprecation for mapreduce.jobhistory.done-dir
Handling deprecation for hadoop.security.instrumentation.requires.admin
Handling deprecation for hadoop.registry.zk.retry.ceiling.ms
Handling deprecation for nfs.rtmax
Handling deprecation for dfs.datanode.data.dir.perm
Handling deprecation for yarn.resourcemanager.container.liveness-monitor.interval-ms
Handling deprecation for yarn.nodemanager.env-whitelist
Handling deprecation for dfs.namenode.backup.address
Handling deprecation for dfs.namenode.xattrs.enabled
Handling deprecation for dfs.datanode.readahead.bytes
Handling deprecation for mapreduce.jobhistory.cleaner.enable
Handling deprecation for dfs.client.block.write.retries
Handling deprecation for mapreduce.tasktracker.http.address
Handling deprecation for yarn.nodemanager.linux-container-executor.cgroups.hierarchy
Handling deprecation for ha.failover-controller.graceful-fence.connection.retries
Handling deprecation for yarn.resourcemanager.recovery.enabled
Handling deprecation for yarn.app.mapreduce.am.container.log.backups
Handling deprecation for dfs.namenode.safemode.threshold-pct
Handling deprecation for yarn.nodemanager.disk-health-checker.interval-ms
Handling deprecation for hadoop.security.java.secure.random.algorithm
Handling deprecation for dfs.namenode.list.cache.directives.num.responses
Handling deprecation for dfs.datanode.dns.nameserver
Handling deprecation for mapreduce.cluster.temp.dir
Handling deprecation for fs.s3a.max.total.tasks
Handling deprecation for mapreduce.reduce.maxattempts
Handling deprecation for mapreduce.client.submit.file.replication
Handling deprecation for mapreduce.shuffle.port
Handling deprecation for yarn.resourcemanager.resource-tracker.client.thread-count
Handling deprecation for dfs.namenode.replication.considerLoad
Handling deprecation for dfs.namenode.edits.journal-plugin.qjournal
Handling deprecation for dfs.client.write.exclude.nodes.cache.expiry.interval.millis
Handling deprecation for yarn.nodemanager.delete.thread-count
Handling deprecation for dfs.client.mmap.cache.timeout.ms
Handling deprecation for yarn.nodemanager.admin-env
Handling deprecation for io.skip.checksum.errors
Handling deprecation for yarn.timeline-service.hostname
Handling deprecation for yarn.resourcemanager.proxy-user-privileges.enabled
Handling deprecation for mapreduce.job.speculative.speculative-cap-total-tasks
Handling deprecation for yarn.acl.enable
Handling deprecation for fs.s3a.fast.upload
Handling deprecation for file.blocksize
Handling deprecation for mapreduce.job.speculative.slowtaskthreshold
Handling deprecation for ftp.replication
Handling deprecation for yarn.sharedcache.cleaner.initial-delay-mins
Handling deprecation for s3native.client-write-packet-size
Handling deprecation for hadoop.rpc.socket.factory.class.default
Handling deprecation for file.bytes-per-checksum
Handling deprecation for dfs.datanode.slow.io.warning.threshold.ms
Handling deprecation for io.seqfile.lazydecompress
Handling deprecation for mapreduce.task.skip.start.attempts
Handling deprecation for dfs.namenode.reject-unresolved-dn-topology-mapping
Handling deprecation for hadoop.common.configuration.version
Handling deprecation for yarn.resourcemanager.client.thread-count
Handling deprecation for dfs.datanode.drop.cache.behind.reads
Handling deprecation for yarn.sharedcache.admin.address
Handling deprecation for mapreduce.job.output.value.class
Handling deprecation for mapreduce.output.fileoutputformat.outputdir
Handling deprecation for mapreduce.jobtracker.taskcache.levels
Handling deprecation for yarn.nodemanager.linux-container-executor.nonsecure-mode.user-pattern
Handling deprecation for yarn.resourcemanager.zk-timeout-ms
Handling deprecation for yarn.resourcemanager.max-completed-applications
Handling deprecation for mapreduce.job.jvm.numtasks
Handling deprecation for yarn.sharedcache.cleaner.period-mins
Handling deprecation for mapreduce.jobtracker.tasktracker.maxblacklists
Handling deprecation for dfs.namenode.top.num.users
Handling deprecation for yarn.nodemanager.linux-container-executor.cgroups.mount
Handling deprecation for yarn.sharedcache.checksum.algo.impl
Handling deprecation for mapreduce.job.end-notification.max.retry.interval
Handling deprecation for mapreduce.job.acl-view-job
Handling deprecation for mapreduce.job.classloader
Handling deprecation for yarn.log-aggregation-enable
Handling deprecation for mapreduce.reduce.shuffle.fetch.retry.interval-ms
Handling deprecation for yarn.resourcemanager.nodemanager.minimum.version
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.size
Handling deprecation for yarn.app.mapreduce.am.job.task.listener.thread-count
Handling deprecation for yarn.app.mapreduce.am.resource.cpu-vcores
Handling deprecation for dfs.namenode.edit.log.autoroll.check.interval.ms
Handling deprecation for mapreduce.output.fileoutputformat.compress.type
Handling deprecation for hadoop.hdfs.configuration.version
Handling deprecation for hadoop.security.group.mapping.ldap.search.attr.member
Handling deprecation for yarn.nodemanager.log.retain-seconds
Handling deprecation for yarn.nodemanager.local-cache.max-files-per-directory
Handling deprecation for mapreduce.job.end-notification.retry.interval
Handling deprecation for hadoop.ssl.client.conf
Handling deprecation for yarn.sharedcache.root-dir
Handling deprecation for dfs.journalnode.https-address
Handling deprecation for mapreduce.reduce.shuffle.fetch.retry.timeout-ms
Handling deprecation for dfs.bytes-per-checksum
Handling deprecation for dfs.namenode.max.objects
Handling deprecation for mapreduce.tasktracker.instrumentation
Handling deprecation for dfs.datanode.max.transfer.threads
Handling deprecation for dfs.block.access.key.update.interval
Handling deprecation for mapreduce.jobtracker.jobhistory.task.numberprogresssplits
Handling deprecation for mapreduce.map.memory.mb
Handling deprecation for ha.failover-controller.new-active.rpc-timeout.ms
Handling deprecation for hadoop.ssl.hostname.verifier
Handling deprecation for dfs.client.read.shortcircuit
Handling deprecation for dfs.datanode.hdfs-blocks-metadata.enabled
Handling deprecation for mapreduce.tasktracker.healthchecker.interval
Handling deprecation for dfs.image.transfer.chunksize
Handling deprecation for mapreduce.tasktracker.taskmemorymanager.monitoringinterval
Handling deprecation for dfs.client.https.keystore.resource
Handling deprecation for yarn.resourcemanager.connect.retry-interval.ms
Handling deprecation for yarn.timeline-service.webapp.address
Handling deprecation for s3native.blocksize
Handling deprecation for yarn.scheduler.minimum-allocation-mb
Handling deprecation for yarn.sharedcache.cleaner.resource-sleep-ms
Handling deprecation for net.topology.impl
Handling deprecation for dfs.client.failover.sleep.base.millis
Handling deprecation for dfs.permissions.superusergroup
Handling deprecation for io.seqfile.compress.blocksize
Handling deprecation for hadoop.registry.zk.retry.times
Handling deprecation for fs.AbstractFileSystem.ftp.impl
Handling deprecation for dfs.namenode.checkpoint.edits.dir
Handling deprecation for mapreduce.job.running.reduce.limit
Handling deprecation for dfs.blockreport.initialDelay
Handling deprecation for dfs.namenode.heartbeat.recheck-interval
Handling deprecation for dfs.namenode.safemode.extension
Handling deprecation for yarn.scheduler.maximum-allocation-mb
Handling deprecation for mapreduce.job.reduce.shuffle.consumer.plugin.class
Handling deprecation for yarn.nodemanager.vmem-check-enabled
Handling deprecation for mapreduce.task.io.sort.factor
Handling deprecation for mapreduce.jobtracker.persist.jobstatus.dir
Handling deprecation for dfs.client.failover.sleep.max.millis
Handling deprecation for dfs.namenode.delegation.key.update-interval
Handling deprecation for hadoop.rpc.protection
Handling deprecation for fs.permissions.umask-mode
Handling deprecation for fs.s3.sleepTimeSeconds
Handling deprecation for ha.health-monitor.rpc-timeout.ms
Handling deprecation for hadoop.http.staticuser.user
Handling deprecation for fs.s3a.connection.maximum
Handling deprecation for yarn.nodemanager.linux-container-executor.nonsecure-mode.limit-users
Handling deprecation for fs.s3a.paging.maximum
Handling deprecation for fs.AbstractFileSystem.viewfs.impl
Handling deprecation for fs.ftp.host
Handling deprecation for yarn.nodemanager.linux-container-executor.nonsecure-mode.local-user
Handling deprecation for fs.s3a.impl
Handling deprecation for hadoop.http.authentication.kerberos.keytab
Handling deprecation for dfs.namenode.fs-limits.max-blocks-per-file
Handling deprecation for mapreduce.tasktracker.http.threads
Handling deprecation for mapreduce.tasktracker.dns.nameserver
Handling deprecation for yarn.resourcemanager.am-rm-tokens.master-key-rolling-interval-secs
Handling deprecation for dfs.client.block.write.replace-datanode-on-failure.enable
Handling deprecation for io.compression.codec.bzip2.library
Handling deprecation for mapreduce.map.skip.maxrecords
Handling deprecation for dfs.client.use.legacy.blockreader.local
Handling deprecation for dfs.namenode.checkpoint.dir
Handling deprecation for dfs.namenode.top.windows.minutes
Handling deprecation for mapreduce.job.maxtaskfailures.per.tracker
Handling deprecation for net.topology.node.switch.mapping.impl
Handling deprecation for mapreduce.shuffle.max.connections
Handling deprecation for mapreduce.jobhistory.loadedjobs.cache.size
Handling deprecation for dfs.storage.policy.enabled
Handling deprecation for yarn.client.application-client-protocol.poll-interval-ms
Handling deprecation for yarn.nodemanager.localizer.address
Handling deprecation for dfs.namenode.list.cache.pools.num.responses
Handling deprecation for nfs.server.port
Handling deprecation for mapreduce.client.output.filter
Handling deprecation for yarn.timeline-service.client.best-effort
Handling deprecation for ha.zookeeper.parent-znode
Handling deprecation for mapreduce.jobtracker.persist.jobstatus.hours
Handling deprecation for yarn.sharedcache.admin.thread-count
Handling deprecation for yarn.nodemanager.resource.cpu-vcores
Handling deprecation for dfs.datanode.block-pinning.enabled
Handling deprecation for mapreduce.jobhistory.http.policy
Handling deprecation for yarn.resourcemanager.webapp.delegation-token-auth-filter.enabled
Handling deprecation for mapreduce.job.speculative.retry-after-no-speculate
Handling deprecation for fs.s3a.attempts.maximum
Handling deprecation for s3native.stream-buffer-size
Handling deprecation for io.seqfile.local.dir
Handling deprecation for yarn.log-aggregation.retain-check-interval-seconds
Handling deprecation for fs.s3n.multipart.copy.block.size
Handling deprecation for dfs.encrypt.data.transfer.cipher.key.bitlength
Handling deprecation for dfs.datanode.sync.behind.writes
Handling deprecation for yarn.resourcemanager.zk-acl
Handling deprecation for hadoop.ssl.keystores.factory.class
Handling deprecation for mapreduce.job.split.metainfo.maxsize
Handling deprecation for fs.s3.maxRetries
Handling deprecation for hadoop.security.random.device.file.path
Handling deprecation for yarn.client.nodemanager-connect.max-wait-ms
Handling deprecation for dfs.namenode.stale.datanode.interval
Handling deprecation for mapreduce.task.io.sort.mb
Handling deprecation for yarn.resourcemanager.zk-state-store.parent-path
Handling deprecation for yarn.app.mapreduce.client-am.ipc.max-retries
Handling deprecation for fs.client.resolve.remote.symlinks
Handling deprecation for yarn.nodemanager.linux-container-executor.cgroups.strict-resource-usage
Handling deprecation for hadoop.ssl.enabled.protocols
Handling deprecation for mapreduce.reduce.cpu.vcores
Handling deprecation for yarn.client.failover-retries
Handling deprecation for mapreduce.jobhistory.address
Handling deprecation for hadoop.ssl.enabled
Handling deprecation for dfs.replication.max
Handling deprecation for dfs.namenode.name.dir
Handling deprecation for dfs.datanode.https.address
Handling deprecation for ipc.client.kill.max
Handling deprecation for mapreduce.job.committer.setup.cleanup.needed
Handling deprecation for dfs.client.domain.socket.data.traffic
Handling deprecation for yarn.nodemanager.localizer.cache.target-size-mb
Handling deprecation for yarn.resourcemanager.admin.client.thread-count
Handling deprecation for dfs.block.access.token.enable
Handling deprecation for mapreduce.job.speculative.retry-after-speculate
Handling deprecation for dfs.datanode.address
Handling deprecation for mapreduce.jobtracker.restart.recover
Handling deprecation for ipc.client.connect.max.retries
Handling deprecation for yarn.timeline-service.store-class
Handling deprecation for dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
Handling deprecation for hadoop.tmp.dir
Handling deprecation for dfs.datanode.handler.count
Handling deprecation for yarn.resourcemanager.ha.automatic-failover.embedded
Handling deprecation for yarn.timeline-service.ttl-ms
Handling deprecation for mapreduce.task.profile.map.params
Handling deprecation for yarn.resourcemanager.nodemanagers.heartbeat-interval-ms
Handling deprecation for mapreduce.map.speculative
Handling deprecation for yarn.timeline-service.recovery.enabled
Handling deprecation for mapreduce.job.map.class
Handling deprecation for dfs.namenode.resource.checked.volumes.minimum
Handling deprecation for yarn.nodemanager.recovery.dir
Handling deprecation for mapreduce.job.counters.max
Handling deprecation for yarn.resourcemanager.keytab
Handling deprecation for dfs.namenode.max.extra.edits.segments.retained
Handling deprecation for dfs.webhdfs.user.provider.user.pattern
Handling deprecation for dfs.client.mmap.enabled
Handling deprecation for mapreduce.map.log.level
Handling deprecation for dfs.client.file-block-storage-locations.timeout.millis
Handling deprecation for yarn.client.max-cached-nodemanagers-proxies
Handling deprecation for yarn.app.mapreduce.am.scheduler.heartbeat.interval-ms
Handling deprecation for hadoop.fuse.timer.period
Handling deprecation for fs.trash.checkpoint.interval
Handling deprecation for yarn.sharedcache.app-checker.class
Handling deprecation for dfs.journalnode.http-address
Handling deprecation for yarn.app.mapreduce.am.staging-dir
Handling deprecation for mapreduce.tasktracker.local.dir.minspacestart
Handling deprecation for yarn.nm.liveness-monitor.expiry-interval-ms
Handling deprecation for ha.health-monitor.check-interval.ms
Handling deprecation for mapreduce.reduce.shuffle.merge.percent
Handling deprecation for dfs.namenode.retrycache.heap.percent
Handling deprecation for yarn.nodemanager.docker-container-executor.exec-name
Handling deprecation for ipc.client.connect.timeout
Handling deprecation for yarn.resourcemanager.fs.state-store.retry-interval-ms
Handling deprecation for mapreduce.output.fileoutputformat.compress
Handling deprecation for yarn.nodemanager.local-dirs
Handling deprecation for yarn.nodemanager.recovery.enabled
Handling deprecation for io.native.lib.available
Handling deprecation for yarn.sharedcache.store.in-memory.staleness-period-mins
Handling deprecation for yarn.resourcemanager.am.max-attempts
Handling deprecation for s3.replication
Handling deprecation for mapreduce.input.fileinputformat.inputdir
Handling deprecation for fs.AbstractFileSystem.har.impl
Handling deprecation for dfs.image.compress
Handling deprecation for mapreduce.job.running.map.limit
Handling deprecation for mapreduce.reduce.input.buffer.percent
Handling deprecation for yarn.nodemanager.webapp.address
Handling deprecation for dfs.datanode.available-space-volume-choosing-policy.balanced-space-preference-fraction
Handling deprecation for dfs.namenode.edit.log.autoroll.multiplier.threshold
Handling deprecation for hadoop.security.group.mapping.ldap.ssl
Handling deprecation for dfs.namenode.checkpoint.check.period
Handling deprecation for fs.defaultFS
Handling deprecation for fs.s3a.multipart.size
Handling deprecation for dfs.client.slow.io.warning.threshold.ms
Handling deprecation for yarn.app.mapreduce.am.job.committer.commit-window
Handling deprecation for hadoop.security.group.mapping.ldap.search.attr.group.name
Handling deprecation for yarn.nodemanager.disk-health-checker.max-disk-utilization-per-disk-percentage
Handling deprecation for yarn.nodemanager.container-monitor.procfs-tree.smaps-based-rss.enabled
Handling deprecation for mapreduce.job.submithostname
Handling deprecation for mapreduce.map.sort.spill.percent
Handling deprecation for hadoop.security.crypto.codec.classes.aes.ctr.nopadding
Handling deprecation for dfs.namenode.http-address
Handling deprecation for hadoop.security.groups.negative-cache.secs
Handling deprecation for hadoop.ssl.server.conf
Handling deprecation for mapreduce.ifile.readahead
Handling deprecation for s3native.replication
Handling deprecation for yarn.client.nodemanager-client-async.thread-pool-max-size
Handling deprecation for mapreduce.jobtracker.staging.root.dir
Handling deprecation for mapreduce.jobhistory.admin.address
Handling deprecation for dfs.namenode.startup.delay.block.deletion.sec
Handling deprecation for yarn.nodemanager.health-checker.interval-ms
Handling deprecation for dfs.namenode.checkpoint.max-retries
Handling deprecation for s3.stream-buffer-size
Handling deprecation for ftp.client-write-packet-size
Handling deprecation for dfs.datanode.fsdatasetcache.max.threads.per.volume
Handling deprecation for mapreduce.output.fileoutputformat.compress.codec
Handling deprecation for yarn.timeline-service.keytab
Handling deprecation for yarn.sharedcache.store.in-memory.initial-delay-mins
Handling deprecation for mapreduce.jobhistory.webapp.address
Handling deprecation for mapreduce.task.userlog.limit.kb
Handling deprecation for mapreduce.reduce.shuffle.fetch.retry.enabled
Handling deprecation for yarn.app.mapreduce.task.container.log.backups
Handling deprecation for dfs.heartbeat.interval
Handling deprecation for ha.zookeeper.session-timeout.ms
Handling deprecation for fs.s3a.connection.ssl.enabled
Handling deprecation for yarn.sharedcache.webapp.address
Handling deprecation for hadoop.http.authentication.signature.secret.file
Handling deprecation for hadoop.fuse.connection.timeout
Handling deprecation for mapreduce.input.fileinputformat.numinputfiles
Handling deprecation for yarn.nodemanager.log-aggregation.compression-type
Handling deprecation for ipc.server.max.connections
Handling deprecation for yarn.resourcemanager.work-preserving-recovery.scheduling-wait-ms
Handling deprecation for yarn.nodemanager.log-dirs
Handling deprecation for yarn.app.mapreduce.am.resource.mb
Handling deprecation for hadoop.security.groups.cache.secs
Handling deprecation for mapreduce.job.speculative.minimum-allowed-tasks
Handling deprecation for yarn.nodemanager.container-monitor.interval-ms
Handling deprecation for dfs.datanode.cache.revocation.timeout.ms
Handling deprecation for mapreduce.jobhistory.recovery.store.class
Handling deprecation for mapreduce.task.combine.progress.records
Handling deprecation for s3.client-write-packet-size
Handling deprecation for mapreduce.jobtracker.instrumentation
Handling deprecation for dfs.replication
Handling deprecation for mapreduce.shuffle.transfer.buffer.size
Handling deprecation for hadoop.security.group.mapping.ldap.directory.search.timeout
Handling deprecation for dfs.datanode.available-space-volume-choosing-policy.balanced-space-threshold
Handling deprecation for hadoop.work.around.non.threadsafe.getpwuid
Handling deprecation for yarn.app.mapreduce.client-am.ipc.max-retries-on-timeouts
Handling deprecation for yarn.nodemanager.address
Handling deprecation for mapreduce.tasktracker.taskcontroller
Handling deprecation for mapreduce.tasktracker.indexcache.mb
Handling deprecation for yarn.scheduler.maximum-allocation-vcores
Handling deprecation for mapreduce.job.reduces
Handling deprecation for yarn.nodemanager.sleep-delay-before-sigkill.ms
Handling deprecation for yarn.timeline-service.address
Handling deprecation for yarn.resourcemanager.configuration.provider-class
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.expiry
Handling deprecation for yarn.sharedcache.enabled
Handling deprecation for tfile.io.chunk.size
Handling deprecation for mapreduce.job.acl-modify-job
Handling deprecation for hadoop.registry.zk.session.timeout.ms
Handling deprecation for fs.automatic.close
Handling deprecation for ha.health-monitor.sleep-after-disconnect.ms
Handling deprecation for mapreduce.tasktracker.reduce.tasks.maximum
Handling deprecation for mapreduce.input.fileinputformat.list-status.num-threads
Handling deprecation for dfs.datanode.directoryscan.threads
Handling deprecation for dfs.datanode.directoryscan.interval
Handling deprecation for dfs.namenode.acls.enabled
Handling deprecation for dfs.client.short.circuit.replica.stale.threshold.ms
Handling deprecation for hadoop.http.authentication.token.validity
Handling deprecation for fs.s3.block.size
Handling deprecation for ha.failover-controller.graceful-fence.rpc-timeout.ms
Handling deprecation for mapreduce.tasktracker.local.dir.minspacekill
Handling deprecation for dfs.namenode.resource.du.reserved
Handling deprecation for mapreduce.jobhistory.cleaner.interval-ms
Handling deprecation for dfs.namenode.datanode.registration.ip-hostname-check
Handling deprecation for mapreduce.jobhistory.intermediate-done-dir
Handling deprecation for mapreduce.jobtracker.http.address
Handling deprecation for dfs.namenode.backup.http-address
Handling deprecation for dfs.namenode.edits.noeditlogchannelflush
Handling deprecation for mapreduce.reduce.shuffle.input.buffer.percent
Handling deprecation for mapreduce.map.maxattempts
Handling deprecation for yarn.http.policy
Handling deprecation for dfs.namenode.audit.loggers
Handling deprecation for hadoop.security.groups.cache.warn.after.ms
Handling deprecation for io.serializations
Handling deprecation for mapreduce.tasktracker.outofband.heartbeat
Handling deprecation for mapreduce.reduce.shuffle.read.timeout
Handling deprecation for hadoop.security.crypto.buffer.size
Handling deprecation for mapreduce.reduce.skip.proc.count.autoincr
Handling deprecation for mapreduce.ifile.readahead.bytes
Handling deprecation for dfs.http.policy
Handling deprecation for hadoop.registry.secure
Handling deprecation for dfs.namenode.safemode.min.datanodes
Handling deprecation for dfs.client.file-block-storage-locations.num-threads
Handling deprecation for mapreduce.cluster.local.dir
Handling deprecation for mapreduce.tasktracker.report.address
Handling deprecation for dfs.namenode.secondary.https-address
Handling deprecation for hadoop.kerberos.kinit.command
Handling deprecation for yarn.timeline-service.http-authentication.type
Handling deprecation for dfs.block.access.token.lifetime
Handling deprecation for dfs.webhdfs.enabled
Handling deprecation for dfs.namenode.delegation.token.max-lifetime
Handling deprecation for dfs.namenode.avoid.write.stale.datanode
Handling deprecation for dfs.datanode.drop.cache.behind.writes
Handling deprecation for yarn.log-aggregation.retain-seconds
Handling deprecation for mapreduce.job.complete.cancel.delegation.tokens
Handling deprecation for mapreduce.local.clientfactory.class.name
Handling deprecation for mapreduce.shuffle.connection-keep-alive.timeout
Handling deprecation for dfs.namenode.num.extra.edits.retained
Handling deprecation for yarn.scheduler.minimum-allocation-vcores
Handling deprecation for ipc.client.connect.max.retries.on.timeouts
Handling deprecation for yarn.timeline-service.client.retry-interval-ms
Handling deprecation for yarn.timeline-service.client.max-retries
Handling deprecation for fs.s3n.block.size
Handling deprecation for mapreduce.job.map.output.collector.class
Handling deprecation for ha.health-monitor.connect-retry-interval.ms
Handling deprecation for mapreduce.shuffle.max.threads
Handling deprecation for nfs.exports.allowed.hosts
Handling deprecation for dfs.client.mmap.cache.size
Handling deprecation for mapreduce.tasktracker.map.tasks.maximum
Handling deprecation for io.file.buffer.size
Handling deprecation for dfs.client.datanode-restart.timeout
Handling deprecation for io.mapfile.bloom.size
Handling deprecation for hadoop.security.kms.client.authentication.retry-count
Handling deprecation for dfs.namenode.checkpoint.txns
Handling deprecation for ipc.client.connect.retry.interval
Handling deprecation for dfs.client-write-packet-size
Handling deprecation for mapreduce.reduce.shuffle.connect.timeout
Handling deprecation for yarn.resourcemanager.fs.state-store.uri
Handling deprecation for fs.swift.impl
Handling deprecation for hadoop.registry.zk.connection.timeout.ms
Handling deprecation for mapred.queue.default.acl-administer-jobs
Handling deprecation for mapreduce.job.submithostaddress
Handling deprecation for dfs.cachereport.intervalMsec
Handling deprecation for yarn.app.mapreduce.shuffle.log.backups
Handling deprecation for yarn.app.mapreduce.am.container.log.limit.kb
Handling deprecation for yarn.nodemanager.resourcemanager.minimum.version
Handling deprecation for ftp.blocksize
Handling deprecation for yarn.resourcemanager.address
Handling deprecation for file.stream-buffer-size
Handling deprecation for yarn.resourcemanager.scheduler.monitor.enable
Handling deprecation for mapreduce.job.ubertask.maxreduces
Handling deprecation for nfs.allow.insecure.ports
Handling deprecation for yarn.sharedcache.nm.uploader.thread-count
Handling deprecation for ipc.client.idlethreshold
Handling deprecation for ftp.stream-buffer-size
Handling deprecation for yarn.sharedcache.client-server.address
Handling deprecation for dfs.client.failover.connection.retries.on.timeouts
Handling deprecation for dfs.namenode.replication.work.multiplier.per.iteration
Handling deprecation for hadoop.http.authentication.simple.anonymous.allowed
Handling deprecation for hadoop.security.authorization
Handling deprecation for yarn.client.nodemanager-connect.retry-interval-ms
Handling deprecation for yarn.am.liveness-monitor.expiry-interval-ms
Handling deprecation for fs.har.impl.disable.cache
Handling deprecation for yarn.nodemanager.linux-container-executor.resources-handler.class
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.read-cache-size
Handling deprecation for hadoop.security.authentication
Handling deprecation for dfs.image.compression.codec
Handling deprecation for mapreduce.task.files.preserve.failedtasks
Handling deprecation for dfs.client.read.shortcircuit.streams.cache.size
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.path
Handling deprecation for mapreduce.job.reduce.slowstart.completedmaps
Handling deprecation for mapreduce.jobhistory.minicluster.fixed.ports
Handling deprecation for file.replication
Handling deprecation for yarn.resourcemanager.ha.automatic-failover.enabled
Handling deprecation for mapreduce.job.userlog.retain.hours
Handling deprecation for mapreduce.jobhistory.joblist.cache.size
Handling deprecation for dfs.namenode.accesstime.precision
Handling deprecation for yarn.resourcemanager.work-preserving-recovery.enabled
Handling deprecation for dfs.namenode.fs-limits.max-xattrs-per-inode
Handling deprecation for io.mapfile.bloom.error.rate
Handling deprecation for yarn.resourcemanager.store.class
Handling deprecation for dfs.image.transfer.timeout
Handling deprecation for yarn.timeline-service.leveldb-state-store.path
Handling deprecation for nfs.wtmax
Handling deprecation for mapreduce.job.combine.class
Handling deprecation for dfs.namenode.support.allow.format
Handling deprecation for fs.s3a.multipart.purge
Handling deprecation for dfs.secondary.namenode.kerberos.internal.spnego.principal
Handling deprecation for fs.s3a.connection.establish.timeout
Handling deprecation for dfs.stream-buffer-size
Handling deprecation for dfs.namenode.invalidate.work.pct.per.iteration
Handling deprecation for yarn.nodemanager.container-executor.class
Handling deprecation for fs.s3a.multipart.purge.age
Handling deprecation for yarn.resourcemanager.scheduler.client.thread-count
Handling deprecation for dfs.namenode.top.enabled
Handling deprecation for yarn.app.mapreduce.shuffle.log.separate
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.low-watermark
Handling deprecation for fs.s3a.fast.buffer.size
Handling deprecation for hadoop.user.group.static.mapping.overrides
Handling deprecation for tfile.fs.input.buffer.size
Handling deprecation for dfs.client.cached.conn.retry
Handling deprecation for hadoop.http.authentication.type
Handling deprecation for dfs.namenode.list.encryption.zones.num.responses
Handling deprecation for mapreduce.map.cpu.vcores
Handling deprecation for dfs.namenode.path.based.cache.refresh.interval.ms
Handling deprecation for dfs.namenode.decommission.interval
Handling deprecation for dfs.namenode.fs-limits.max-directory-items
Handling deprecation for yarn.resourcemanager.zk-retry-interval-ms
Handling deprecation for ftp.bytes-per-checksum
Handling deprecation for dfs.ha.log-roll.period
Handling deprecation for dfs.user.home.dir.prefix
Handling deprecation for ipc.client.fallback-to-simple-auth-allowed
Handling deprecation for yarn.nodemanager.pmem-check-enabled
Handling deprecation for yarn.nodemanager.remote-app-log-dir
Handling deprecation for dfs.namenode.inotify.max.events.per.rpc
Handling deprecation for mapreduce.task.profile.maps
Handling deprecation for mapreduce.shuffle.ssl.file.buffer.size
Handling deprecation for mapreduce.tasktracker.healthchecker.script.timeout
Handling deprecation for yarn.timeline-service.webapp.https.address
Handling deprecation for yarn.nodemanager.resource.percentage-physical-cpu-limit
Handling deprecation for yarn.app.mapreduce.am.command-opts
Handling deprecation for dfs.namenode.fs-limits.max-xattr-size
Handling deprecation for dfs.datanode.http.address
Handling deprecation for dfs.namenode.blocks.per.postponedblocks.rescan
Handling deprecation for yarn.sharedcache.nm.uploader.replication.factor
Handling deprecation for hadoop.registry.zk.root
Handling deprecation for hadoop.jetty.logs.serve.aliases
Handling deprecation for yarn.client.failover-proxy-provider
Handling deprecation for mapreduce.jobhistory.admin.acl
Handling deprecation for yarn.app.mapreduce.am.hard-kill-timeout-ms
Handling deprecation for yarn.nodemanager.remote-app-log-dir-suffix
Handling deprecation for mapreduce.jobhistory.principal
Handling deprecation for yarn.resourcemanager.webapp.address
Handling deprecation for mapreduce.jobhistory.recovery.enable
Handling deprecation for yarn.sharedcache.store.in-memory.check-period-mins
Handling deprecation for nfs.mountd.port
Handling deprecation for mapreduce.reduce.merge.inmem.threshold
Handling deprecation for fs.df.interval
Handling deprecation for yarn.timeline-service.enabled
Handling deprecation for mapreduce.jobtracker.jobhistory.lru.cache.size
Handling deprecation for mapreduce.task.profile
Handling deprecation for mapreduce.job.output.key.class
Handling deprecation for yarn.nodemanager.hostname
Handling deprecation for dfs.namenode.num.checkpoints.retained
Handling deprecation for mapreduce.job.queuename
Handling deprecation for mapreduce.jobhistory.max-age-ms
Handling deprecation for mapreduce.job.token.tracking.ids.enabled
Handling deprecation for yarn.nodemanager.localizer.client.thread-count
Handling deprecation for yarn.sharedcache.uploader.server.thread-count
Handling deprecation for dfs.client.mmap.retry.timeout.ms
Handling deprecation for mapreduce.jobhistory.move.thread-count
Handling deprecation for dfs.permissions.enabled
Handling deprecation for dfs.blockreport.split.threshold
Handling deprecation for fs.AbstractFileSystem.hdfs.impl
Handling deprecation for dfs.datanode.balance.bandwidthPerSec
Handling deprecation for dfs.block.scanner.volume.bytes.per.second
Handling deprecation for hadoop.http.filter.initializers
Handling deprecation for yarn.timeline-service.http-authentication.simple.anonymous.allowed
Handling deprecation for dfs.default.chunk.view.size
Handling deprecation for yarn.sharedcache.client-server.thread-count
Handling deprecation for yarn.resourcemanager.resource-tracker.address
Handling deprecation for mapreduce.job.working.dir
Handling deprecation for mapreduce.jobhistory.datestring.cache.size
Handling deprecation for mapreduce.task.profile.params
Handling deprecation for dfs.namenode.decommission.blocks.per.interval
Handling deprecation for dfs.namenode.handler.count
Handling deprecation for dfs.image.transfer.bandwidthPerSec
Handling deprecation for rpc.metrics.quantile.enable
Handling deprecation for mapreduce.jobtracker.expire.trackers.interval
Handling deprecation for mapreduce.task.timeout
Handling deprecation for yarn.app.mapreduce.client.max-retries
Handling deprecation for yarn.nodemanager.resource.memory-mb
Handling deprecation for yarn.nodemanager.disk-health-checker.min-healthy-disks
Handling deprecation for dfs.datanode.failed.volumes.tolerated
Handling deprecation for yarn.timeline-service.handler-thread-count
Handling deprecation for ipc.server.listen.queue.size
Handling deprecation for fs.s3a.threads.max
Handling deprecation for yarn.resourcemanager.connect.max-wait.ms
Handling deprecation for mapreduce.fileoutputcommitter.algorithm.version
Handling deprecation for mapreduce.framework.name
Handling deprecation for mapreduce.map.skip.proc.count.autoincr
Handling deprecation for mapreduce.job.max.split.locations
Handling deprecation for yarn.resourcemanager.scheduler.class
Handling deprecation for yarn.resourcemanager.system-metrics-publisher.enabled
Handling deprecation for dfs.blocksize
Handling deprecation for yarn.sharedcache.nested-level
Handling deprecation for mapreduce.shuffle.connection-keep-alive.enable
Handling deprecation for fs.s3a.threads.keepalivetime
Handling deprecation for fs.s3a.connection.timeout
Handling deprecation for file.client-write-packet-size
Handling deprecation for ha.failover-controller.cli-check.rpc-timeout.ms
Handling deprecation for ha.zookeeper.acl
Handling deprecation for dfs.namenode.write.stale.datanode.ratio
Handling deprecation for dfs.encrypt.data.transfer
Handling deprecation for dfs.datanode.shared.file.descriptor.paths
Handling deprecation for mapreduce.input.lineinputformat.linespermap
Handling deprecation for yarn.resourcemanager.delayed.delegation-token.removal-interval-ms
Handling deprecation for yarn.nodemanager.localizer.fetch.thread-count
Handling deprecation for dfs.client.failover.max.attempts
Handling deprecation for yarn.resourcemanager.scheduler.address
Handling deprecation for dfs.client.read.shortcircuit.streams.cache.expiry.ms
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.start-time-write-cache-size
Handling deprecation for yarn.nodemanager.health-checker.script.timeout-ms
Handling deprecation for yarn.resourcemanager.fs.state-store.num-retries
Handling deprecation for hadoop.ssl.require.client.cert
Handling deprecation for hadoop.security.uid.cache.secs
Handling deprecation for mapreduce.jobhistory.keytab
Handling deprecation for dfs.client.read.shortcircuit.skip.checksum
Handling deprecation for yarn.resourcemanager.ha.automatic-failover.zk-base-path
Handling deprecation for mapreduce.shuffle.ssl.enabled
Handling deprecation for mapreduce.reduce.log.level
Handling deprecation for hadoop.registry.rm.enabled
Handling deprecation for mapreduce.tasktracker.dns.interface
Handling deprecation for yarn.resourcemanager.system-metrics-publisher.dispatcher.pool-size
Handling deprecation for mapreduce.job.speculative.speculative-cap-running-tasks
Handling deprecation for dfs.datanode.block.id.layout.upgrade.threads
Handling deprecation for dfs.datanode.use.datanode.hostname
Handling deprecation for dfs.client.context
Handling deprecation for yarn.resourcemanager.ha.enabled
Handling deprecation for mapred.reducer.new-api
Handling deprecation for dfs.namenode.delegation.token.renew-interval
Handling deprecation for dfs.blockreport.intervalMsec
Handling deprecation for fs.s3a.multipart.threshold
Handling deprecation for mapreduce.reduce.shuffle.memory.limit.percent
Handling deprecation for dfs.https.server.keystore.resource
Handling deprecation for io.map.index.skip
Handling deprecation for mapreduce.job.hdfs-servers
Handling deprecation for mapreduce.jobtracker.taskscheduler
Handling deprecation for dfs.namenode.kerberos.internal.spnego.principal
Handling deprecation for yarn.resourcemanager.state-store.max-completed-applications
Handling deprecation for mapreduce.map.output.compress
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.num.refill.threads
Handling deprecation for fs.s3n.multipart.uploads.block.size
Handling deprecation for mapreduce.task.merge.progress.records
Handling deprecation for dfs.datanode.dns.interface
Handling deprecation for map.sort.class
Handling deprecation for yarn.nodemanager.aux-services.mapreduce_shuffle.class
Handling deprecation for tfile.fs.output.buffer.size
Handling deprecation for fs.du.interval
Handling deprecation for dfs.client.failover.connection.retries
Handling deprecation for dfs.namenode.top.window.num.buckets
Handling deprecation for mapreduce.job.dir
Handling deprecation for fs.s3a.buffer.dir
Handling deprecation for mapreduce.reduce.shuffle.retry-delay.max.ms
Handling deprecation for yarn.sharedcache.uploader.server.address
Handling deprecation for mapreduce.client.progressmonitor.pollinterval
Handling deprecation for yarn.app.mapreduce.shuffle.log.limit.kb
Handling deprecation for dfs.datanode.max.locked.memory
Handling deprecation for dfs.namenode.retrycache.expirytime.millis
Handling deprecation for dfs.datanode.scan.period.hours
Handling deprecation for dfs.client.block.write.replace-datanode-on-failure.best-effort
Handling deprecation for mapreduce.jobhistory.move.interval-ms
Handling deprecation for dfs.ha.fencing.ssh.connect-timeout
Handling deprecation for yarn.nodemanager.log-aggregation.roll-monitoring-interval-seconds
Handling deprecation for dfs.namenode.fs-limits.max-component-length
Handling deprecation for hadoop.registry.zk.quorum
Handling deprecation for dfs.namenode.enable.retrycache
Handling deprecation for dfs.datanode.du.reserved
Handling deprecation for yarn.timeline-service.state-store-class
Handling deprecation for dfs.datanode.ipc.address
Handling deprecation for hadoop.registry.system.acls
Handling deprecation for dfs.client.block.write.replace-datanode-on-failure.policy
Handling deprecation for dfs.namenode.path.based.cache.retry.interval.ms
Handling deprecation for hadoop.security.crypto.cipher.suite
Handling deprecation for dfs.ha.tail-edits.period
Handling deprecation for mapreduce.task.profile.reduce.params
Handling deprecation for hadoop.registry.jaas.context
Handling deprecation for yarn.resourcemanager.hostname
Handling deprecation for mapreduce.reduce.memory.mb
Handling deprecation for hadoop.security.group.mapping.ldap.search.filter.group
Handling deprecation for hadoop.http.authentication.kerberos.principal
Handling deprecation for hadoop.security.group.mapping.ldap.search.filter.user
Handling deprecation for yarn.nodemanager.disk-health-checker.min-free-space-per-disk-mb
Handling deprecation for dfs.namenode.edits.dir
Handling deprecation for yarn.client.failover-retries-on-socket-timeouts
Handling deprecation for dfs.namenode.decommission.max.concurrent.tracked.nodes
Handling deprecation for mapreduce.client.completion.pollinterval
Handling deprecation for dfs.namenode.name.dir.restore
Handling deprecation for dfs.namenode.secondary.http-address
Handling deprecation for mapreduce.jobhistory.recovery.store.leveldb.path
Handling deprecation for yarn.sharedcache.store.class
Handling deprecation for s3.bytes-per-checksum
Handling deprecation for yarn.nodemanager.windows-container.cpu-limit.enabled
Handling deprecation for yarn.resourcemanager.webapp.https.address
Handling deprecation for yarn.nodemanager.vmem-pmem-ratio
Handling deprecation for dfs.namenode.checkpoint.period
Handling deprecation for dfs.ha.automatic-failover.enabled
The url to track the job: http://localhost:8080/
Running job: job_local1326756033_0003
OutputCommitter set in config null
File Output Committer Algorithm version is 1
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
/user/michaeljones/wcOutputAnalysis/_temporary/0: masked=rwxr-xr-x
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #58
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #58
Call: mkdirs took 12ms
Starting mapper thread pool executor.
Max local threads: 1
Map tasks to process: 1
Waiting for map tasks
Starting task: attempt_local1326756033_0003_m_000000_0
currentIndex 0   0:0
mapreduce.cluster.local.dir for child : /tmp/hadoop-michaeljones/mapred/local/localRunner//michaeljones/jobcache/job_local1326756033_0003/attempt_local1326756033_0003_m_000000_0
using new api for output committer
File Output Committer Algorithm version is 1
ProcfsBasedProcessTree currently is supported only on Linux.
 Using ResourceCalculatorProcessTree : null
Processing split: hdfs://localhost:9000/user/michaeljones/wcInput:0+50
Trying map output collector class: org.apache.hadoop.mapred.MapTask$MapOutputBuffer
(EQUATOR) 0 kvi 26214396(104857584)
mapreduce.task.io.sort.mb: 100
soft limit at 83886080
bufstart = 0; bufvoid = 104857600
kvstart = 26214396; length = 6553600
Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #59
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #59
Call: getBlockLocations took 2ms
newInfo = LocatedBlocks{
  fileLength=50
  underConstruction=false
  blocks=[LocatedBlock{BP-1045030256-10.0.0.2-1433119149314:blk_1073741825_1002; getBlockSize()=50; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-b42c5705-9ba4-4b14-b00b-f9194bb036f0,DISK]]}]
  lastLocatedBlock=LocatedBlock{BP-1045030256-10.0.0.2-1433119149314:blk_1073741825_1002; getBlockSize()=50; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-b42c5705-9ba4-4b14-b00b-f9194bb036f0,DISK]]}
  isLastBlockComplete=true}
Connecting to datanode 127.0.0.1:50010

Starting flush of map output
Spilling map output
bufstart = 0; bufend = 82; bufvoid = 104857600
kvstart = 26214396(104857584); kvend = 26214368(104857472); length = 29/6553600
IntSumCombinerAnalyser-Bye[1]
IntSumCombinerAnalyser-Goodbye[1]
IntSumCombinerAnalyser-Hadoop[1,1]
IntSumCombinerAnalyser-Hello[1,1]
IntSumCombinerAnalyser-World[1,1]
Finished spill 0
Task:attempt_local1326756033_0003_m_000000_0 is done. And is in the process of committing
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #60
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #60
Call: getFileInfo took 4ms
map
Task 'attempt_local1326756033_0003_m_000000_0' done.
Finishing task: attempt_local1326756033_0003_m_000000_0
map task executor complete.
Starting reduce thread pool executor.
Max local threads: 1
Reduce tasks to process: 1
Waiting for reduce tasks
Starting task: attempt_local1326756033_0003_r_000000_0
currentIndex 0   0:0
mapreduce.cluster.local.dir for child : /tmp/hadoop-michaeljones/mapred/local/localRunner//michaeljones/jobcache/job_local1326756033_0003/attempt_local1326756033_0003_r_000000_0
using new api for output committer
File Output Committer Algorithm version is 1
ProcfsBasedProcessTree currently is supported only on Linux.
 Using ResourceCalculatorProcessTree : null
Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@637a9e03
MergerManager: memoryLimit=668309888, maxSingleShuffleLimit=167077472, mergeThreshold=441084544, ioSortFactor=10, memToMemMergeOutputsThreshold=10
attempt_local1326756033_0003_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
Got 0 map completion events from 0
GetMapEventsThread about to sleep for 1000
LocalFetcher 3 going to fetch: attempt_local1326756033_0003_m_000000_0
attempt_local1326756033_0003_m_000000_0: Proceeding with shuffle since usedMemory (0) is lesser than memoryLimit (668309888).CommitMemory is (0)
localfetcher#3 about to shuffle output of map attempt_local1326756033_0003_m_000000_0 decomp: 63 len: 67 to MEMORY
Read 63 bytes from map-output for attempt_local1326756033_0003_m_000000_0
closeInMemoryFile -> map-output of size: 63, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->63
map attempt_local1326756033_0003_m_000000_0 done 1 / 1 copied.
EventFetcher is interrupted.. Returning
1 / 1 copied.
finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
Merging 1 sorted segments
Down to the last merge-pass, with 1 segments left of total size: 57 bytes
Merged 1 segments, 63 bytes to disk to satisfy reduce memory limit
Disk file: /tmp/hadoop-michaeljones/mapred/local/localRunner/michaeljones/jobcache/job_local1326756033_0003/attempt_local1326756033_0003_r_000000_0/output/map_0.out.merged Length is 67
Merging 1 files, 67 bytes from disk
Merging 0 segments, 0 bytes from memory into reduce
Merging 1 sorted segments
Down to the last merge-pass, with 1 segments left of total size: 57 bytes
1 / 1 copied.
/user/michaeljones/wcOutputAnalysis/_temporary/0/_temporary/attempt_local1326756033_0003_r_000000_0/part-r-00000: masked=rw-r--r--
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #61
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #61
Call: create took 4ms
computePacketChunkSize: src=/user/michaeljones/wcOutputAnalysis/_temporary/0/_temporary/attempt_local1326756033_0003_r_000000_0/part-r-00000, chunkSize=516, chunksPerPacket=126, packetSize=65016
IntSumReducerAnalyser-Bye[1]
IntSumReducerAnalyser-Goodbye[1]
IntSumReducerAnalyser-Hadoop[2]
IntSumReducerAnalyser-Hello[2]
IntSumReducerAnalyser-World[2]
DFSClient writeChunk allocating new packet seqno=0, src=/user/michaeljones/wcOutputAnalysis/_temporary/0/_temporary/attempt_local1326756033_0003_r_000000_0/part-r-00000, packetSize=65016, chunksPerPacket=126, bytesCurBlock=0
Queued packet 0
Queued packet 1
Waiting for ack for: 1
Allocating new block
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #62
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #62
Call: addBlock took 3ms
pipeline = DatanodeInfoWithStorage[127.0.0.1:50010,DS-b42c5705-9ba4-4b14-b00b-f9194bb036f0,DISK]
Connecting to datanode 127.0.0.1:50010
Send buf size 131072
SASL client skipping handshake in unsecured configuration for addr = /127.0.0.1, datanodeId = DatanodeInfoWithStorage[127.0.0.1:50010,DS-b42c5705-9ba4-4b14-b00b-f9194bb036f0,DISK]
DataStreamer block BP-1045030256-10.0.0.2-1433119149314:blk_1073742254_1431 sending packet packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 41
DFSClient seqno: 0 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
DataStreamer block BP-1045030256-10.0.0.2-1433119149314:blk_1073742254_1431 sending packet packet seqno: 1 offsetInBlock: 41 lastPacketInBlock: true lastByteOffsetInBlock: 41
DFSClient seqno: 1 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
Closing old block BP-1045030256-10.0.0.2-1433119149314:blk_1073742254_1431
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #63
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #63
Call: complete took 3ms
Task:attempt_local1326756033_0003_r_000000_0 is done. And is in the process of committing
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #64
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #64
Call: getFileInfo took 2ms
1 / 1 copied.
Task attempt_local1326756033_0003_r_000000_0 is allowed to commit now
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #65
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #65
Call: getFileInfo took 1ms
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #66
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #66
Call: getFileInfo took 2ms
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #67
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #67
Call: rename took 6ms
Saved output of task 'attempt_local1326756033_0003_r_000000_0' to hdfs://localhost:9000/user/michaeljones/wcOutputAnalysis/_temporary/0/task_local1326756033_0003_r_000000
reduce > reduce
Task 'attempt_local1326756033_0003_r_000000_0' done.
Finishing task: attempt_local1326756033_0003_r_000000_0
reduce task executor complete.
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #68
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #68
Call: getListing took 2ms
Merging data from FileStatus{path=hdfs://localhost:9000/user/michaeljones/wcOutputAnalysis/_temporary/0/task_local1326756033_0003_r_000000; isDirectory=true; modification_time=1434167243674; access_time=0; owner=michaeljones; group=supergroup; permission=rwxr-xr-x; isSymlink=false} to hdfs://localhost:9000/user/michaeljones/wcOutputAnalysis
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #69
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #69
Call: getFileInfo took 2ms
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #70
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #70
Call: getListing took 2ms
Merging data from FileStatus{path=hdfs://localhost:9000/user/michaeljones/wcOutputAnalysis/_temporary/0/task_local1326756033_0003_r_000000/part-r-00000; isDirectory=false; length=41; replication=1; blocksize=134217728; modification_time=1434167243695; access_time=1434167243674; owner=michaeljones; group=supergroup; permission=rw-r--r--; isSymlink=false} to hdfs://localhost:9000/user/michaeljones/wcOutputAnalysis/part-r-00000
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #71
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #71
Call: getFileInfo took 2ms
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #72
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #72
Call: rename took 3ms
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #73
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #73
Call: delete took 3ms
/user/michaeljones/wcOutputAnalysis/_SUCCESS: masked=rw-r--r--
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #74
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #74
Call: create took 11ms
computePacketChunkSize: src=/user/michaeljones/wcOutputAnalysis/_SUCCESS, chunkSize=516, chunksPerPacket=126, packetSize=65016
Waiting for ack for: -1
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #75
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #75
Call: complete took 4ms
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.fs.FileContext.getAbstractFileSystem(FileContext.java:331)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
Job job_local1326756033_0003 running in uber mode : false
 map 100% reduce 100%
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.getTaskCompletionEvents(Job.java:670)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.getTaskCompletionEvents(Job.java:670)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
Job job_local1326756033_0003 completed successfully
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.getCounters(Job.java:758)
Counters: 35
	File System Counters
		FILE: Number of bytes read=1892
		FILE: Number of bytes written=1694207
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=340
		HDFS: Number of bytes written=245
		HDFS: Number of read operations=71
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=38
	Map-Reduce Framework
		Map input records=2
		Map output records=8
		Map output bytes=82
		Map output materialized bytes=67
		Input split bytes=112
		Combine input records=8
		Combine output records=5
		Reduce input groups=5
		Reduce shuffle bytes=67
		Reduce input records=5
		Reduce output records=5
		Spilled Records=10
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=873463808
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=50
	File Output Format Counters 
		Bytes Written=41
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 5][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://localhost:50070
Connecting to localhost/127.0.0.1:50070
Connection established 127.0.0.1:49817<->127.0.0.1:50070
Executing request GET /webhdfs/v1/user/michaeljones/?op=LISTSTATUS HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-5 >> GET /webhdfs/v1/user/michaeljones/?op=LISTSTATUS HTTP/1.1
http-outgoing-5 >> accept: application/json
http-outgoing-5 >> Host: localhost:50070
http-outgoing-5 >> Connection: Keep-Alive
http-outgoing-5 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-5 >> Accept-Encoding: gzip,deflate
http-outgoing-5 >> "GET /webhdfs/v1/user/michaeljones/?op=LISTSTATUS HTTP/1.1[\r][\n]"
http-outgoing-5 >> "accept: application/json[\r][\n]"
http-outgoing-5 >> "Host: localhost:50070[\r][\n]"
http-outgoing-5 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-5 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-5 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-5 >> "[\r][\n]"
http-outgoing-5 << "HTTP/1.1 200 OK[\r][\n]"
http-outgoing-5 << "Cache-Control: no-cache[\r][\n]"
http-outgoing-5 << "Expires: Sat, 13 Jun 2015 03:47:24 GMT[\r][\n]"
http-outgoing-5 << "Date: Sat, 13 Jun 2015 03:47:24 GMT[\r][\n]"
http-outgoing-5 << "Pragma: no-cache[\r][\n]"
http-outgoing-5 << "Expires: Sat, 13 Jun 2015 03:47:24 GMT[\r][\n]"
http-outgoing-5 << "Date: Sat, 13 Jun 2015 03:47:24 GMT[\r][\n]"
http-outgoing-5 << "Pragma: no-cache[\r][\n]"
http-outgoing-5 << "Content-Type: application/json[\r][\n]"
http-outgoing-5 << "Transfer-Encoding: chunked[\r][\n]"
http-outgoing-5 << "Server: Jetty(6.1.26)[\r][\n]"
http-outgoing-5 << "[\r][\n]"
http-outgoing-5 << "FB4[\r][\n]"
http-outgoing-5 << "{"FileStatuses":{"FileStatus":[[\n]"
http-outgoing-5 << "{"accessTime":1434167234338,"blockSize":134217728,"childrenNum":0,"fileId":18506,"group":"supergroup","length":10899,"modificationTime":1434167234365,"owner":"michaeljones","pathSuffix":"README.md","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-5 << "{"accessTime":1434159020549,"blockSize":134217728,"childrenNum":0,"fileId":18464,"group":"supergroup","length":0,"modificationTime":1434159020554,"owner":"michaeljones","pathSuffix":"apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-5 << "{"accessTime":1434159021414,"blockSize":134217728,"childrenNum":0,"fileId":18467,"group":"supergroup","length":0,"modificationTime":1434159021420,"owner":"michaeljones","pathSuffix":"empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-5 << "{"accessTime":1434167233781,"blockSize":134217728,"childrenNum":0,"fileId":18503,"group":"supergroup","length":0,"modificationTime":1434167233788,"owner":"michaeljones","pathSuffix":"hello-apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-5 << "{"accessTime":1434091626279,"blockSize":134217728,"childrenNum":0,"fileId":18298,"group":"supergroup","length":0,"modificationTime":1434091626286,"owner":"michaeljones","pathSuffix":"hello-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-5 << "{"accessTime":1434167233712,"blockSize":134217728,"childrenNum":0,"fileId":18502,"group":"supergroup","length":0,"modificationTime":1434167233719,"owner":"michaeljones","pathSuffix":"hello-jersey-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-5 << "{"accessTime":1434159021522,"blockSize":134217728,"childrenNum":0,"fileId":18468,"group":"supergroup","length":869081,"modificationTime":1434159021575,"owner":"michaeljones","pathSuffix":"hello.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-5 << "{"accessTime":1434167234105,"blockSize":134217728,"childrenNum":0,"fileId":18505,"group":"supergroup","length":3678856,"modificationTime":1434167234236,"owner":"michaeljones","pathSuffix":"hello.log.2015-06-12","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-5 << "{"accessTime":1434167237362,"blockSize":134217728,"childrenNum":0,"fileId":18507,"group":"supergroup","length":20,"modificationTime":1434167237859,"owner":"michaeljones","pathSuffix":"hello.txt","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-5 << "{"accessTime":1434167233980,"blockSize":134217728,"childrenNum":0,"fileId":18504,"group":"supergroup","length":62912,"modificationTime":1434167234012,"owner":"michaeljones","pathSuffix":"hellohadoop.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-5 << "{"accessTime":1434159020604,"blockSize":134217728,"childrenNum":0,"fileId":18465,"group":"supergroup","length":2134,"modificationTime":1434159020632,"owner":"michaeljones","pathSuffix":"pom.xml","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-5 << "{"accessTime":1434167238722,"blockSize":134217728,"childrenNum":0,"fileId":16388,"group":"supergroup","length":50,"modificationTime":1433119638967,"owner":"michaeljones","pathSuffix":"wcInput","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-5 << "{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18515,"group":"supergroup","length":0,"modificationTime":1434167242193,"owner":"michaeljones","pathSuffix":"wcOutput","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},[\n]"
http-outgoing-5 << "{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18522,"group":"supergroup","length":0,"modificationTime":1434167243736,"owner":"michaeljones","pathSuffix":"wcOutputAnalysis","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},[\n]"
http-outgoing-5 << "{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18508,"group":"supergroup","length":0,"modificationTime":1434167240780,"owner":"michaeljones","pathSuffix":"wcOutputMain","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"}[\n]"
http-outgoing-5 << "]}}[\n]"
http-outgoing-5 << "[\r][\n]"
http-outgoing-5 << HTTP/1.1 200 OK
http-outgoing-5 << Cache-Control: no-cache
http-outgoing-5 << Expires: Sat, 13 Jun 2015 03:47:24 GMT
http-outgoing-5 << Date: Sat, 13 Jun 2015 03:47:24 GMT
http-outgoing-5 << Pragma: no-cache
http-outgoing-5 << Expires: Sat, 13 Jun 2015 03:47:24 GMT
http-outgoing-5 << Date: Sat, 13 Jun 2015 03:47:24 GMT
http-outgoing-5 << Pragma: no-cache
http-outgoing-5 << Content-Type: application/json
http-outgoing-5 << Transfer-Encoding: chunked
http-outgoing-5 << Server: Jetty(6.1.26)
Connection can be kept alive indefinitely
http-outgoing-5 << "0[\r][\n]"
http-outgoing-5 << "[\r][\n]"
Connection [id: 5][route: {}->http://localhost:50070] can be kept alive indefinitely
Connection released: [id: 5][route: {}->http://localhost:50070][total kept alive: 1; route allocated: 1 of 2; total allocated: 1 of 20]
Apache client testGetStringContent
{"FileStatuses":{"FileStatus":[
{"accessTime":1434167234338,"blockSize":134217728,"childrenNum":0,"fileId":18506,"group":"supergroup","length":10899,"modificationTime":1434167234365,"owner":"michaeljones","pathSuffix":"README.md","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434159020549,"blockSize":134217728,"childrenNum":0,"fileId":18464,"group":"supergroup","length":0,"modificationTime":1434159020554,"owner":"michaeljones","pathSuffix":"apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434159021414,"blockSize":134217728,"childrenNum":0,"fileId":18467,"group":"supergroup","length":0,"modificationTime":1434159021420,"owner":"michaeljones","pathSuffix":"empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434167233781,"blockSize":134217728,"childrenNum":0,"fileId":18503,"group":"supergroup","length":0,"modificationTime":1434167233788,"owner":"michaeljones","pathSuffix":"hello-apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434091626279,"blockSize":134217728,"childrenNum":0,"fileId":18298,"group":"supergroup","length":0,"modificationTime":1434091626286,"owner":"michaeljones","pathSuffix":"hello-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434167233712,"blockSize":134217728,"childrenNum":0,"fileId":18502,"group":"supergroup","length":0,"modificationTime":1434167233719,"owner":"michaeljones","pathSuffix":"hello-jersey-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434159021522,"blockSize":134217728,"childrenNum":0,"fileId":18468,"group":"supergroup","length":869081,"modificationTime":1434159021575,"owner":"michaeljones","pathSuffix":"hello.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434167234105,"blockSize":134217728,"childrenNum":0,"fileId":18505,"group":"supergroup","length":3678856,"modificationTime":1434167234236,"owner":"michaeljones","pathSuffix":"hello.log.2015-06-12","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434167237362,"blockSize":134217728,"childrenNum":0,"fileId":18507,"group":"supergroup","length":20,"modificationTime":1434167237859,"owner":"michaeljones","pathSuffix":"hello.txt","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434167233980,"blockSize":134217728,"childrenNum":0,"fileId":18504,"group":"supergroup","length":62912,"modificationTime":1434167234012,"owner":"michaeljones","pathSuffix":"hellohadoop.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434159020604,"blockSize":134217728,"childrenNum":0,"fileId":18465,"group":"supergroup","length":2134,"modificationTime":1434159020632,"owner":"michaeljones","pathSuffix":"pom.xml","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434167238722,"blockSize":134217728,"childrenNum":0,"fileId":16388,"group":"supergroup","length":50,"modificationTime":1433119638967,"owner":"michaeljones","pathSuffix":"wcInput","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18515,"group":"supergroup","length":0,"modificationTime":1434167242193,"owner":"michaeljones","pathSuffix":"wcOutput","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},
{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18522,"group":"supergroup","length":0,"modificationTime":1434167243736,"owner":"michaeljones","pathSuffix":"wcOutputAnalysis","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},
{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18508,"group":"supergroup","length":0,"modificationTime":1434167240780,"owner":"michaeljones","pathSuffix":"wcOutputMain","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"}
]}}

Connection manager is shutting down
http-outgoing-5: Close connection
http-outgoing-5: Close connection
Connection manager shut down
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 6][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://localhost:50070
Connecting to localhost/127.0.0.1:50070
Connection established 127.0.0.1:49818<->127.0.0.1:50070
Executing request PUT /webhdfs/v1/user/michaeljones/apache-empty.txt?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-6 >> PUT /webhdfs/v1/user/michaeljones/apache-empty.txt?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1
http-outgoing-6 >> Content-Length: 0
http-outgoing-6 >> Host: localhost:50070
http-outgoing-6 >> Connection: Keep-Alive
http-outgoing-6 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-6 >> Accept-Encoding: gzip,deflate
http-outgoing-6 >> "PUT /webhdfs/v1/user/michaeljones/apache-empty.txt?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1[\r][\n]"
http-outgoing-6 >> "Content-Length: 0[\r][\n]"
http-outgoing-6 >> "Host: localhost:50070[\r][\n]"
http-outgoing-6 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-6 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-6 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-6 >> "[\r][\n]"
http-outgoing-6 << "HTTP/1.1 307 TEMPORARY_REDIRECT[\r][\n]"
http-outgoing-6 << "Cache-Control: no-cache[\r][\n]"
http-outgoing-6 << "Expires: Sat, 13 Jun 2015 03:47:24 GMT[\r][\n]"
http-outgoing-6 << "Date: Sat, 13 Jun 2015 03:47:24 GMT[\r][\n]"
http-outgoing-6 << "Pragma: no-cache[\r][\n]"
http-outgoing-6 << "Expires: Sat, 13 Jun 2015 03:47:24 GMT[\r][\n]"
http-outgoing-6 << "Date: Sat, 13 Jun 2015 03:47:24 GMT[\r][\n]"
http-outgoing-6 << "Pragma: no-cache[\r][\n]"
http-outgoing-6 << "Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434203244682&s=BV8ybHicqcmqOlgdn76ZWPc1uRE="; Path=/; Expires=Sat, 13-Jun-2015 13:47:24 GMT; HttpOnly[\r][\n]"
http-outgoing-6 << "Location: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true[\r][\n]"
http-outgoing-6 << "Content-Type: application/octet-stream[\r][\n]"
http-outgoing-6 << "Content-Length: 0[\r][\n]"
http-outgoing-6 << "Server: Jetty(6.1.26)[\r][\n]"
http-outgoing-6 << "[\r][\n]"
http-outgoing-6 << HTTP/1.1 307 TEMPORARY_REDIRECT
http-outgoing-6 << Cache-Control: no-cache
http-outgoing-6 << Expires: Sat, 13 Jun 2015 03:47:24 GMT
http-outgoing-6 << Date: Sat, 13 Jun 2015 03:47:24 GMT
http-outgoing-6 << Pragma: no-cache
http-outgoing-6 << Expires: Sat, 13 Jun 2015 03:47:24 GMT
http-outgoing-6 << Date: Sat, 13 Jun 2015 03:47:24 GMT
http-outgoing-6 << Pragma: no-cache
http-outgoing-6 << Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434203244682&s=BV8ybHicqcmqOlgdn76ZWPc1uRE="; Path=/; Expires=Sat, 13-Jun-2015 13:47:24 GMT; HttpOnly
http-outgoing-6 << Location: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
http-outgoing-6 << Content-Type: application/octet-stream
http-outgoing-6 << Content-Length: 0
http-outgoing-6 << Server: Jetty(6.1.26)
Connection can be kept alive indefinitely
Cookie accepted [hadoop.auth=""u=michaeljones&p=michaeljones&t=simple&e=1434203244682&s=BV8ybHicqcmqOlgdn76ZWPc1uRE="", version:0, domain:localhost, path:/, expiry:Sat Jun 13 23:47:24 AEST 2015]
Redirect to: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
http-outgoing-6: Shutdown connection
Connection discarded
http-outgoing-6: Close connection
Connection released: [id: 6][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
PUT file redirect: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 7][route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://michaels-air.bigpond:50075
Connecting to Michaels-Air.BigPond/10.0.0.2:50075
Connection established 10.0.0.2:49819<->10.0.0.2:50075
Executing request PUT /webhdfs/v1/user/michaeljones/apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-7 >> PUT /webhdfs/v1/user/michaeljones/apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1
http-outgoing-7 >> Content-Length: 0
http-outgoing-7 >> Host: michaels-air.bigpond:50075
http-outgoing-7 >> Connection: Keep-Alive
http-outgoing-7 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-7 >> Accept-Encoding: gzip,deflate
http-outgoing-7 >> "PUT /webhdfs/v1/user/michaeljones/apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1[\r][\n]"
http-outgoing-7 >> "Content-Length: 0[\r][\n]"
http-outgoing-7 >> "Host: michaels-air.bigpond:50075[\r][\n]"
http-outgoing-7 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-7 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-7 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-7 >> "[\r][\n]"
http-outgoing-7 << "HTTP/1.1 100 Continue[\r][\n]"
http-outgoing-7 << "[\r][\n]"
http-outgoing-7 << HTTP/1.1 100 Continue
http-outgoing-7 << "HTTP/1.1 201 Created[\r][\n]"
http-outgoing-7 << "Location: hdfs://localhost:9000/user/michaeljones/apache-empty.txt[\r][\n]"
http-outgoing-7 << "Content-Length: 0[\r][\n]"
http-outgoing-7 << "Connection: close[\r][\n]"
http-outgoing-7 << "[\r][\n]"
http-outgoing-7 << HTTP/1.1 201 Created
http-outgoing-7 << Location: hdfs://localhost:9000/user/michaeljones/apache-empty.txt
http-outgoing-7 << Content-Length: 0
http-outgoing-7 << Connection: close
http-outgoing-7: Shutdown connection
Connection discarded
http-outgoing-7: Close connection
Connection released: [id: 7][route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 8][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://localhost:50070
Connecting to localhost/127.0.0.1:50070
Connection established 127.0.0.1:49821<->127.0.0.1:50070
Executing request PUT /webhdfs/v1/user/michaeljones/pom.xml?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-8 >> PUT /webhdfs/v1/user/michaeljones/pom.xml?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1
http-outgoing-8 >> Content-Length: 0
http-outgoing-8 >> Host: localhost:50070
http-outgoing-8 >> Connection: Keep-Alive
http-outgoing-8 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-8 >> Accept-Encoding: gzip,deflate
http-outgoing-8 >> "PUT /webhdfs/v1/user/michaeljones/pom.xml?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1[\r][\n]"
http-outgoing-8 >> "Content-Length: 0[\r][\n]"
http-outgoing-8 >> "Host: localhost:50070[\r][\n]"
http-outgoing-8 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-8 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-8 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-8 >> "[\r][\n]"
http-outgoing-8 << "HTTP/1.1 307 TEMPORARY_REDIRECT[\r][\n]"
http-outgoing-8 << "Cache-Control: no-cache[\r][\n]"
http-outgoing-8 << "Expires: Sat, 13 Jun 2015 03:47:24 GMT[\r][\n]"
http-outgoing-8 << "Date: Sat, 13 Jun 2015 03:47:24 GMT[\r][\n]"
http-outgoing-8 << "Pragma: no-cache[\r][\n]"
http-outgoing-8 << "Expires: Sat, 13 Jun 2015 03:47:24 GMT[\r][\n]"
http-outgoing-8 << "Date: Sat, 13 Jun 2015 03:47:24 GMT[\r][\n]"
http-outgoing-8 << "Pragma: no-cache[\r][\n]"
http-outgoing-8 << "Content-Type: application/octet-stream[\r][\n]"
http-outgoing-8 << "Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434203244740&s=4zz9OgnH+kE6FkyP0emW/4Ba8/k="; Path=/; Expires=Sat, 13-Jun-2015 13:47:24 GMT; HttpOnly[\r][\n]"
http-outgoing-8 << "Location: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/pom.xml?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true[\r][\n]"
http-outgoing-8 << "Content-Length: 0[\r][\n]"
http-outgoing-8 << "Server: Jetty(6.1.26)[\r][\n]"
http-outgoing-8 << "[\r][\n]"
http-outgoing-8 << HTTP/1.1 307 TEMPORARY_REDIRECT
http-outgoing-8 << Cache-Control: no-cache
http-outgoing-8 << Expires: Sat, 13 Jun 2015 03:47:24 GMT
http-outgoing-8 << Date: Sat, 13 Jun 2015 03:47:24 GMT
http-outgoing-8 << Pragma: no-cache
http-outgoing-8 << Expires: Sat, 13 Jun 2015 03:47:24 GMT
http-outgoing-8 << Date: Sat, 13 Jun 2015 03:47:24 GMT
http-outgoing-8 << Pragma: no-cache
http-outgoing-8 << Content-Type: application/octet-stream
http-outgoing-8 << Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434203244740&s=4zz9OgnH+kE6FkyP0emW/4Ba8/k="; Path=/; Expires=Sat, 13-Jun-2015 13:47:24 GMT; HttpOnly
http-outgoing-8 << Location: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/pom.xml?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
http-outgoing-8 << Content-Length: 0
http-outgoing-8 << Server: Jetty(6.1.26)
Connection can be kept alive indefinitely
Cookie accepted [hadoop.auth=""u=michaeljones&p=michaeljones&t=simple&e=1434203244740&s=4zz9OgnH+kE6FkyP0emW/4Ba8/k="", version:0, domain:localhost, path:/, expiry:Sat Jun 13 23:47:24 AEST 2015]
Redirect to: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/pom.xml?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
http-outgoing-8: Shutdown connection
Connection discarded
http-outgoing-8: Close connection
Connection released: [id: 8][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
PUT file redirect: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/pom.xml?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 9][route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://michaels-air.bigpond:50075
Connecting to Michaels-Air.BigPond/10.0.0.2:50075
Connection established 10.0.0.2:49822<->10.0.0.2:50075
Executing request PUT /webhdfs/v1/user/michaeljones/pom.xml?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-9 >> PUT /webhdfs/v1/user/michaeljones/pom.xml?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1
http-outgoing-9 >> Transfer-Encoding: chunked
http-outgoing-9 >> Content-Type: application/octet-stream
http-outgoing-9 >> Host: michaels-air.bigpond:50075
http-outgoing-9 >> Connection: Keep-Alive
http-outgoing-9 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-9 >> Accept-Encoding: gzip,deflate
http-outgoing-9 >> "PUT /webhdfs/v1/user/michaeljones/pom.xml?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1[\r][\n]"
http-outgoing-9 >> "Transfer-Encoding: chunked[\r][\n]"
http-outgoing-9 >> "Content-Type: application/octet-stream[\r][\n]"
http-outgoing-9 >> "Host: michaels-air.bigpond:50075[\r][\n]"
http-outgoing-9 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-9 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-9 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-9 >> "[\r][\n]"
http-outgoing-9 >> "856[\r][\n]"
http-outgoing-9 >> "<?xml version="1.0" encoding="UTF-8"?>[\n]"
http-outgoing-9 >> "<project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">[\n]"
http-outgoing-9 >> "    <modelVersion>4.0.0</modelVersion>[\n]"
http-outgoing-9 >> "    <groupId>com.michaeljones</groupId>[\n]"
http-outgoing-9 >> "    <artifactId>HelloHadoopWorldMaven</artifactId>[\n]"
http-outgoing-9 >> "    <version>1.0-SNAPSHOT</version>[\n]"
http-outgoing-9 >> "    <packaging>jar</packaging>[\n]"
http-outgoing-9 >> "    <dependencies>[\n]"
http-outgoing-9 >> "        <!-- run bin/hadoop version to see the jar it was built with, which is this dependency -->[\n]"
http-outgoing-9 >> "        <dependency>[\n]"
http-outgoing-9 >> "            <groupId>org.apache.hadoop</groupId>[\n]"
http-outgoing-9 >> "            <artifactId>hadoop-common</artifactId>[\n]"
http-outgoing-9 >> "            <version>2.7.0</version>[\n]"
http-outgoing-9 >> "        </dependency>[\n]"
http-outgoing-9 >> "        <dependency>[\n]"
http-outgoing-9 >> "            <groupId>org.apache.hadoop</groupId>[\n]"
http-outgoing-9 >> "            <artifactId>hadoop-hdfs</artifactId>[\n]"
http-outgoing-9 >> "            <version>2.7.0</version>[\n]"
http-outgoing-9 >> "        </dependency>[\n]"
http-outgoing-9 >> "        <dependency>[\n]"
http-outgoing-9 >> "            <groupId>junit</groupId>[\n]"
http-outgoing-9 >> "            <artifactId>junit</artifactId>[\n]"
http-outgoing-9 >> "            <version>4.10</version>[\n]"
http-outgoing-9 >> "            <scope>test</scope>[\n]"
http-outgoing-9 >> "        </dependency>[\n]"
http-outgoing-9 >> "        <dependency>[\n]"
http-outgoing-9 >> "            <groupId>org.apache.hadoop</groupId>[\n]"
http-outgoing-9 >> "            <artifactId>hadoop-mapreduce-client-core</artifactId>[\n]"
http-outgoing-9 >> "            <version>2.7.0</version>[\n]"
http-outgoing-9 >> "        </dependency>[\n]"
http-outgoing-9 >> "        <dependency>[\n]"
http-outgoing-9 >> "            <groupId>org.apache.hadoop</groupId>[\n]"
http-outgoing-9 >> "            <artifactId>hadoop-mapreduce-client-common</artifactId>[\n]"
http-outgoing-9 >> "            <version>2.7.0</version>[\n]"
http-outgoing-9 >> "        </dependency>[\n]"
http-outgoing-9 >> "        <dependency>[\n]"
http-outgoing-9 >> "            <groupId>com.googlecode.json-simple</groupId>[\n]"
http-outgoing-9 >> "            <artifactId>json-simple</artifactId>[\n]"
http-outgoing-9 >> "            <version>1.1.1</version>[\n]"
http-outgoing-9 >> "        </dependency>[\n]"
http-outgoing-9 >> "        <dependency>[\n]"
http-outgoing-9 >> "            <groupId>org.apache.httpcomponents</groupId>[\n]"
http-outgoing-9 >> "            <artifactId>httpclient</artifactId>[\n]"
http-outgoing-9 >> "            <version>4.4-beta1</version>[\n]"
http-outgoing-9 >> "        </dependency>[\n]"
http-outgoing-9 >> "    </dependencies>[\n]"
http-outgoing-9 >> "    <properties>[\n]"
http-outgoing-9 >> "        <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>[\n]"
http-outgoing-9 >> "        <maven.compiler.source>1.7</maven.compiler.source>[\n]"
http-outgoing-9 >> "        <maven.compiler.target>1.7</maven.compiler.target>[\n]"
http-outgoing-9 >> "    </properties>[\n]"
http-outgoing-9 >> "</project>[\r][\n]"
http-outgoing-9 >> "0[\r][\n]"
http-outgoing-9 >> "[\r][\n]"
http-outgoing-9 << "HTTP/1.1 100 Continue[\r][\n]"
http-outgoing-9 << "[\r][\n]"
http-outgoing-9 << HTTP/1.1 100 Continue
http-outgoing-9 << "HTTP/1.1 201 Created[\r][\n]"
http-outgoing-9 << "Location: hdfs://localhost:9000/user/michaeljones/pom.xml[\r][\n]"
http-outgoing-9 << "Content-Length: 0[\r][\n]"
http-outgoing-9 << "Connection: close[\r][\n]"
http-outgoing-9 << "[\r][\n]"
http-outgoing-9 << HTTP/1.1 201 Created
http-outgoing-9 << Location: hdfs://localhost:9000/user/michaeljones/pom.xml
http-outgoing-9 << Content-Length: 0
http-outgoing-9 << Connection: close
http-outgoing-9: Shutdown connection
Connection discarded
http-outgoing-9: Close connection
Connection released: [id: 9][route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection manager is shutting down
Connection manager shut down
Jersey client testGetStringContent
{"FileStatuses":{"FileStatus":[
{"accessTime":1434167234338,"blockSize":134217728,"childrenNum":0,"fileId":18506,"group":"supergroup","length":10899,"modificationTime":1434167234365,"owner":"michaeljones","pathSuffix":"README.md","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434167244718,"blockSize":134217728,"childrenNum":0,"fileId":18529,"group":"supergroup","length":0,"modificationTime":1434167244724,"owner":"michaeljones","pathSuffix":"apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434159021414,"blockSize":134217728,"childrenNum":0,"fileId":18467,"group":"supergroup","length":0,"modificationTime":1434159021420,"owner":"michaeljones","pathSuffix":"empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434167233781,"blockSize":134217728,"childrenNum":0,"fileId":18503,"group":"supergroup","length":0,"modificationTime":1434167233788,"owner":"michaeljones","pathSuffix":"hello-apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434091626279,"blockSize":134217728,"childrenNum":0,"fileId":18298,"group":"supergroup","length":0,"modificationTime":1434091626286,"owner":"michaeljones","pathSuffix":"hello-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434167233712,"blockSize":134217728,"childrenNum":0,"fileId":18502,"group":"supergroup","length":0,"modificationTime":1434167233719,"owner":"michaeljones","pathSuffix":"hello-jersey-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434159021522,"blockSize":134217728,"childrenNum":0,"fileId":18468,"group":"supergroup","length":869081,"modificationTime":1434159021575,"owner":"michaeljones","pathSuffix":"hello.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434167234105,"blockSize":134217728,"childrenNum":0,"fileId":18505,"group":"supergroup","length":3678856,"modificationTime":1434167234236,"owner":"michaeljones","pathSuffix":"hello.log.2015-06-12","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434167237362,"blockSize":134217728,"childrenNum":0,"fileId":18507,"group":"supergroup","length":20,"modificationTime":1434167237859,"owner":"michaeljones","pathSuffix":"hello.txt","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434167233980,"blockSize":134217728,"childrenNum":0,"fileId":18504,"group":"supergroup","length":62912,"modificationTime":1434167234012,"owner":"michaeljones","pathSuffix":"hellohadoop.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434167244774,"blockSize":134217728,"childrenNum":0,"fileId":18530,"group":"supergroup","length":2134,"modificationTime":1434167244805,"owner":"michaeljones","pathSuffix":"pom.xml","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434167238722,"blockSize":134217728,"childrenNum":0,"fileId":16388,"group":"supergroup","length":50,"modificationTime":1433119638967,"owner":"michaeljones","pathSuffix":"wcInput","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18515,"group":"supergroup","length":0,"modificationTime":1434167242193,"owner":"michaeljones","pathSuffix":"wcOutput","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},
{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18522,"group":"supergroup","length":0,"modificationTime":1434167243736,"owner":"michaeljones","pathSuffix":"wcOutputAnalysis","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},
{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18508,"group":"supergroup","length":0,"modificationTime":1434167240780,"owner":"michaeljones","pathSuffix":"wcOutputMain","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"}
]}}

com.sun.jersey.client.property.chunkedEncodingSize: 1048576
Jersey client Redirect to: hdfs://localhost:9000/user/michaeljones/hello.log
stopping client from cache: org.apache.hadoop.ipc.Client@22d7b4f8
removing client from cache: org.apache.hadoop.ipc.Client@22d7b4f8
stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@22d7b4f8
Stopping client
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones: closed
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones: stopped, remaining connections 0
Jersey client testGetStringContent
{"FileStatuses":{"FileStatus":[
{"accessTime":1434167234338,"blockSize":134217728,"childrenNum":0,"fileId":18506,"group":"supergroup","length":10899,"modificationTime":1434167234365,"owner":"michaeljones","pathSuffix":"README.md","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434167244718,"blockSize":134217728,"childrenNum":0,"fileId":18529,"group":"supergroup","length":0,"modificationTime":1434167244724,"owner":"michaeljones","pathSuffix":"apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434167245630,"blockSize":134217728,"childrenNum":0,"fileId":18532,"group":"supergroup","length":0,"modificationTime":1434167245638,"owner":"michaeljones","pathSuffix":"empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434167233781,"blockSize":134217728,"childrenNum":0,"fileId":18503,"group":"supergroup","length":0,"modificationTime":1434167233788,"owner":"michaeljones","pathSuffix":"hello-apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434091626279,"blockSize":134217728,"childrenNum":0,"fileId":18298,"group":"supergroup","length":0,"modificationTime":1434091626286,"owner":"michaeljones","pathSuffix":"hello-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434167233712,"blockSize":134217728,"childrenNum":0,"fileId":18502,"group":"supergroup","length":0,"modificationTime":1434167233719,"owner":"michaeljones","pathSuffix":"hello-jersey-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434167245832,"blockSize":134217728,"childrenNum":0,"fileId":18533,"group":"supergroup","length":1497068,"modificationTime":1434167245892,"owner":"michaeljones","pathSuffix":"hello.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434167234105,"blockSize":134217728,"childrenNum":0,"fileId":18505,"group":"supergroup","length":3678856,"modificationTime":1434167234236,"owner":"michaeljones","pathSuffix":"hello.log.2015-06-12","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434167237362,"blockSize":134217728,"childrenNum":0,"fileId":18507,"group":"supergroup","length":20,"modificationTime":1434167237859,"owner":"michaeljones","pathSuffix":"hello.txt","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434167233980,"blockSize":134217728,"childrenNum":0,"fileId":18504,"group":"supergroup","length":62912,"modificationTime":1434167234012,"owner":"michaeljones","pathSuffix":"hellohadoop.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434167244774,"blockSize":134217728,"childrenNum":0,"fileId":18530,"group":"supergroup","length":2134,"modificationTime":1434167244805,"owner":"michaeljones","pathSuffix":"pom.xml","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434167238722,"blockSize":134217728,"childrenNum":0,"fileId":16388,"group":"supergroup","length":50,"modificationTime":1433119638967,"owner":"michaeljones","pathSuffix":"wcInput","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18515,"group":"supergroup","length":0,"modificationTime":1434167242193,"owner":"michaeljones","pathSuffix":"wcOutput","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},
{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18522,"group":"supergroup","length":0,"modificationTime":1434167243736,"owner":"michaeljones","pathSuffix":"wcOutputAnalysis","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},
{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18508,"group":"supergroup","length":0,"modificationTime":1434167240780,"owner":"michaeljones","pathSuffix":"wcOutputMain","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"}
]}}

Jersey client Redirect to: hdfs://localhost:9000/user/michaeljones/hello.log
Jersey client testGetStringContent
{"FileStatuses":{"FileStatus":[
{"accessTime":1434167234338,"blockSize":134217728,"childrenNum":0,"fileId":18506,"group":"supergroup","length":10899,"modificationTime":1434167234365,"owner":"michaeljones","pathSuffix":"README.md","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434167244718,"blockSize":134217728,"childrenNum":0,"fileId":18529,"group":"supergroup","length":0,"modificationTime":1434167244724,"owner":"michaeljones","pathSuffix":"apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434167456598,"blockSize":134217728,"childrenNum":0,"fileId":18534,"group":"supergroup","length":0,"modificationTime":1434167456604,"owner":"michaeljones","pathSuffix":"empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434167233781,"blockSize":134217728,"childrenNum":0,"fileId":18503,"group":"supergroup","length":0,"modificationTime":1434167233788,"owner":"michaeljones","pathSuffix":"hello-apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434091626279,"blockSize":134217728,"childrenNum":0,"fileId":18298,"group":"supergroup","length":0,"modificationTime":1434091626286,"owner":"michaeljones","pathSuffix":"hello-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434167233712,"blockSize":134217728,"childrenNum":0,"fileId":18502,"group":"supergroup","length":0,"modificationTime":1434167233719,"owner":"michaeljones","pathSuffix":"hello-jersey-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434167456842,"blockSize":134217728,"childrenNum":0,"fileId":18535,"group":"supergroup","length":1501650,"modificationTime":1434167456891,"owner":"michaeljones","pathSuffix":"hello.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434167234105,"blockSize":134217728,"childrenNum":0,"fileId":18505,"group":"supergroup","length":3678856,"modificationTime":1434167234236,"owner":"michaeljones","pathSuffix":"hello.log.2015-06-12","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434167237362,"blockSize":134217728,"childrenNum":0,"fileId":18507,"group":"supergroup","length":20,"modificationTime":1434167237859,"owner":"michaeljones","pathSuffix":"hello.txt","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434167233980,"blockSize":134217728,"childrenNum":0,"fileId":18504,"group":"supergroup","length":62912,"modificationTime":1434167234012,"owner":"michaeljones","pathSuffix":"hellohadoop.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434167244774,"blockSize":134217728,"childrenNum":0,"fileId":18530,"group":"supergroup","length":2134,"modificationTime":1434167244805,"owner":"michaeljones","pathSuffix":"pom.xml","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434167238722,"blockSize":134217728,"childrenNum":0,"fileId":16388,"group":"supergroup","length":50,"modificationTime":1433119638967,"owner":"michaeljones","pathSuffix":"wcInput","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18515,"group":"supergroup","length":0,"modificationTime":1434167242193,"owner":"michaeljones","pathSuffix":"wcOutput","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},
{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18522,"group":"supergroup","length":0,"modificationTime":1434167243736,"owner":"michaeljones","pathSuffix":"wcOutputAnalysis","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},
{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18508,"group":"supergroup","length":0,"modificationTime":1434167240780,"owner":"michaeljones","pathSuffix":"wcOutputMain","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"}
]}}

Jersey client Redirect to: hdfs://localhost:9000/user/michaeljones/hello.log
com.sun.jersey.client.property.chunkedEncodingSize: 1048576
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 0][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://localhost:50070
Connecting to localhost/127.0.0.1:50070
Connection established 127.0.0.1:50032<->127.0.0.1:50070
Executing request GET /webhdfs/v1/user/michaeljones/?user.name=michaeljones&op=LISTSTATUS HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-0 >> GET /webhdfs/v1/user/michaeljones/?user.name=michaeljones&op=LISTSTATUS HTTP/1.1
http-outgoing-0 >> accept: application/json
http-outgoing-0 >> Host: localhost:50070
http-outgoing-0 >> Connection: Keep-Alive
http-outgoing-0 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-0 >> Accept-Encoding: gzip,deflate
http-outgoing-0 >> "GET /webhdfs/v1/user/michaeljones/?user.name=michaeljones&op=LISTSTATUS HTTP/1.1[\r][\n]"
http-outgoing-0 >> "accept: application/json[\r][\n]"
http-outgoing-0 >> "Host: localhost:50070[\r][\n]"
http-outgoing-0 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-0 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-0 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-0 >> "[\r][\n]"
http-outgoing-0 << "HTTP/1.1 200 OK[\r][\n]"
http-outgoing-0 << "Cache-Control: no-cache[\r][\n]"
http-outgoing-0 << "Expires: Sat, 13 Jun 2015 03:57:48 GMT[\r][\n]"
http-outgoing-0 << "Date: Sat, 13 Jun 2015 03:57:48 GMT[\r][\n]"
http-outgoing-0 << "Pragma: no-cache[\r][\n]"
http-outgoing-0 << "Expires: Sat, 13 Jun 2015 03:57:48 GMT[\r][\n]"
http-outgoing-0 << "Date: Sat, 13 Jun 2015 03:57:48 GMT[\r][\n]"
http-outgoing-0 << "Pragma: no-cache[\r][\n]"
http-outgoing-0 << "Content-Type: application/json[\r][\n]"
http-outgoing-0 << "Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434203868507&s=+QkNklNn1hh92ZXLvryTtG4OW50="; Path=/; Expires=Sat, 13-Jun-2015 13:57:48 GMT; HttpOnly[\r][\n]"
http-outgoing-0 << "Transfer-Encoding: chunked[\r][\n]"
http-outgoing-0 << "Server: Jetty(6.1.26)[\r][\n]"
http-outgoing-0 << "[\r][\n]"
http-outgoing-0 << "FB5[\r][\n]"
http-outgoing-0 << "{"FileStatuses":{"FileStatus":[[\n]"
http-outgoing-0 << "{"accessTime":1434167234338,"blockSize":134217728,"childrenNum":0,"fileId":18506,"group":"supergroup","length":10899,"modificationTime":1434167234365,"owner":"michaeljones","pathSuffix":"README.md","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434167244718,"blockSize":134217728,"childrenNum":0,"fileId":18529,"group":"supergroup","length":0,"modificationTime":1434167244724,"owner":"michaeljones","pathSuffix":"apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434167800851,"blockSize":134217728,"childrenNum":0,"fileId":18536,"group":"supergroup","length":0,"modificationTime":1434167800857,"owner":"michaeljones","pathSuffix":"empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434167233781,"blockSize":134217728,"childrenNum":0,"fileId":18503,"group":"supergroup","length":0,"modificationTime":1434167233788,"owner":"michaeljones","pathSuffix":"hello-apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434091626279,"blockSize":134217728,"childrenNum":0,"fileId":18298,"group":"supergroup","length":0,"modificationTime":1434091626286,"owner":"michaeljones","pathSuffix":"hello-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434167233712,"blockSize":134217728,"childrenNum":0,"fileId":18502,"group":"supergroup","length":0,"modificationTime":1434167233719,"owner":"michaeljones","pathSuffix":"hello-jersey-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434167801365,"blockSize":134217728,"childrenNum":0,"fileId":18538,"group":"supergroup","length":1505861,"modificationTime":1434167801408,"owner":"michaeljones","pathSuffix":"hello.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434167234105,"blockSize":134217728,"childrenNum":0,"fileId":18505,"group":"supergroup","length":3678856,"modificationTime":1434167234236,"owner":"michaeljones","pathSuffix":"hello.log.2015-06-12","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434167237362,"blockSize":134217728,"childrenNum":0,"fileId":18507,"group":"supergroup","length":20,"modificationTime":1434167237859,"owner":"michaeljones","pathSuffix":"hello.txt","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434167233980,"blockSize":134217728,"childrenNum":0,"fileId":18504,"group":"supergroup","length":62912,"modificationTime":1434167234012,"owner":"michaeljones","pathSuffix":"hellohadoop.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434167244774,"blockSize":134217728,"childrenNum":0,"fileId":18530,"group":"supergroup","length":2134,"modificationTime":1434167244805,"owner":"michaeljones","pathSuffix":"pom.xml","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434167238722,"blockSize":134217728,"childrenNum":0,"fileId":16388,"group":"supergroup","length":50,"modificationTime":1433119638967,"owner":"michaeljones","pathSuffix":"wcInput","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18515,"group":"supergroup","length":0,"modificationTime":1434167242193,"owner":"michaeljones","pathSuffix":"wcOutput","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},[\n]"
http-outgoing-0 << "{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18522,"group":"supergroup","length":0,"modificationTime":1434167243736,"owner":"michaeljones","pathSuffix":"wcOutputAnalysis","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},[\n]"
http-outgoing-0 << "{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18508,"group":"supergroup","length":0,"modificationTime":1434167240780,"owner":"michaeljones","pathSuffix":"wcOutputMain","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"}[\n]"
http-outgoing-0 << "]}}[\n]"
http-outgoing-0 << "[\r][\n]"
http-outgoing-0 << HTTP/1.1 200 OK
http-outgoing-0 << Cache-Control: no-cache
http-outgoing-0 << Expires: Sat, 13 Jun 2015 03:57:48 GMT
http-outgoing-0 << Date: Sat, 13 Jun 2015 03:57:48 GMT
http-outgoing-0 << Pragma: no-cache
http-outgoing-0 << Expires: Sat, 13 Jun 2015 03:57:48 GMT
http-outgoing-0 << Date: Sat, 13 Jun 2015 03:57:48 GMT
http-outgoing-0 << Pragma: no-cache
http-outgoing-0 << Content-Type: application/json
http-outgoing-0 << Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434203868507&s=+QkNklNn1hh92ZXLvryTtG4OW50="; Path=/; Expires=Sat, 13-Jun-2015 13:57:48 GMT; HttpOnly
http-outgoing-0 << Transfer-Encoding: chunked
http-outgoing-0 << Server: Jetty(6.1.26)
Connection can be kept alive indefinitely
Cookie accepted [hadoop.auth=""u=michaeljones&p=michaeljones&t=simple&e=1434203868507&s=+QkNklNn1hh92ZXLvryTtG4OW50="", version:0, domain:localhost, path:/, expiry:Sat Jun 13 23:57:48 AEST 2015]
http-outgoing-0 << "0[\r][\n]"
http-outgoing-0 << "[\r][\n]"
Connection [id: 0][route: {}->http://localhost:50070] can be kept alive indefinitely
Connection released: [id: 0][route: {}->http://localhost:50070][total kept alive: 1; route allocated: 1 of 2; total allocated: 1 of 20]
Connection manager is shutting down
http-outgoing-0: Close connection
http-outgoing-0: Close connection
Connection manager shut down
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 1][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://localhost:50070
Connecting to localhost/127.0.0.1:50070
Connection established 127.0.0.1:50035<->127.0.0.1:50070
Executing request PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-1 >> PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1
http-outgoing-1 >> Content-Length: 0
http-outgoing-1 >> Host: localhost:50070
http-outgoing-1 >> Connection: Keep-Alive
http-outgoing-1 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-1 >> Accept-Encoding: gzip,deflate
http-outgoing-1 >> "PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1[\r][\n]"
http-outgoing-1 >> "Content-Length: 0[\r][\n]"
http-outgoing-1 >> "Host: localhost:50070[\r][\n]"
http-outgoing-1 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-1 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-1 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-1 >> "[\r][\n]"
http-outgoing-1 << "HTTP/1.1 307 TEMPORARY_REDIRECT[\r][\n]"
http-outgoing-1 << "Cache-Control: no-cache[\r][\n]"
http-outgoing-1 << "Expires: Sat, 13 Jun 2015 03:57:48 GMT[\r][\n]"
http-outgoing-1 << "Date: Sat, 13 Jun 2015 03:57:48 GMT[\r][\n]"
http-outgoing-1 << "Pragma: no-cache[\r][\n]"
http-outgoing-1 << "Expires: Sat, 13 Jun 2015 03:57:48 GMT[\r][\n]"
http-outgoing-1 << "Date: Sat, 13 Jun 2015 03:57:48 GMT[\r][\n]"
http-outgoing-1 << "Pragma: no-cache[\r][\n]"
http-outgoing-1 << "Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434203868942&s=Zc6kzknVjCyiFb5eg49aoKcdbqc="; Path=/; Expires=Sat, 13-Jun-2015 13:57:48 GMT; HttpOnly[\r][\n]"
http-outgoing-1 << "Location: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true[\r][\n]"
http-outgoing-1 << "Content-Type: application/octet-stream[\r][\n]"
http-outgoing-1 << "Content-Length: 0[\r][\n]"
http-outgoing-1 << "Server: Jetty(6.1.26)[\r][\n]"
http-outgoing-1 << "[\r][\n]"
http-outgoing-1 << HTTP/1.1 307 TEMPORARY_REDIRECT
http-outgoing-1 << Cache-Control: no-cache
http-outgoing-1 << Expires: Sat, 13 Jun 2015 03:57:48 GMT
http-outgoing-1 << Date: Sat, 13 Jun 2015 03:57:48 GMT
http-outgoing-1 << Pragma: no-cache
http-outgoing-1 << Expires: Sat, 13 Jun 2015 03:57:48 GMT
http-outgoing-1 << Date: Sat, 13 Jun 2015 03:57:48 GMT
http-outgoing-1 << Pragma: no-cache
http-outgoing-1 << Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434203868942&s=Zc6kzknVjCyiFb5eg49aoKcdbqc="; Path=/; Expires=Sat, 13-Jun-2015 13:57:48 GMT; HttpOnly
http-outgoing-1 << Location: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
http-outgoing-1 << Content-Type: application/octet-stream
http-outgoing-1 << Content-Length: 0
http-outgoing-1 << Server: Jetty(6.1.26)
Connection can be kept alive indefinitely
Cookie accepted [hadoop.auth=""u=michaeljones&p=michaeljones&t=simple&e=1434203868942&s=Zc6kzknVjCyiFb5eg49aoKcdbqc="", version:0, domain:localhost, path:/, expiry:Sat Jun 13 23:57:48 AEST 2015]
Redirect to: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
http-outgoing-1: Shutdown connection
Connection discarded
http-outgoing-1: Close connection
Connection released: [id: 1][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 2][route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://michaels-air.bigpond:50075
Connecting to michaels-air.bigpond/10.0.0.2:50075
Connection established 10.0.0.2:50036<->10.0.0.2:50075
Executing request PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-2 >> PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1
http-outgoing-2 >> Content-Length: 0
http-outgoing-2 >> Host: michaels-air.bigpond:50075
http-outgoing-2 >> Connection: Keep-Alive
http-outgoing-2 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-2 >> Accept-Encoding: gzip,deflate
http-outgoing-2 >> "PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1[\r][\n]"
http-outgoing-2 >> "Content-Length: 0[\r][\n]"
http-outgoing-2 >> "Host: michaels-air.bigpond:50075[\r][\n]"
http-outgoing-2 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-2 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-2 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-2 >> "[\r][\n]"
http-outgoing-2 << "HTTP/1.1 100 Continue[\r][\n]"
http-outgoing-2 << "[\r][\n]"
http-outgoing-2 << HTTP/1.1 100 Continue
http-outgoing-2 << "HTTP/1.1 201 Created[\r][\n]"
http-outgoing-2 << "Location: hdfs://localhost:9000/user/michaeljones/hello-apache-empty.txt[\r][\n]"
http-outgoing-2 << "Content-Length: 0[\r][\n]"
http-outgoing-2 << "Connection: close[\r][\n]"
http-outgoing-2 << "[\r][\n]"
http-outgoing-2 << HTTP/1.1 201 Created
http-outgoing-2 << Location: hdfs://localhost:9000/user/michaeljones/hello-apache-empty.txt
http-outgoing-2 << Content-Length: 0
http-outgoing-2 << Connection: close
http-outgoing-2: Shutdown connection
Connection discarded
http-outgoing-2: Close connection
Connection released: [id: 2][route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection manager is shutting down
Connection manager shut down
Jersey client Redirect to: hdfs://localhost:9000/user/michaeljones/hellohadoop.log
com.sun.jersey.client.property.chunkedEncodingSize: 1048576
Jersey client Redirect to: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/hello.log.2015-06-12?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 3][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://localhost:50070
Connecting to localhost/127.0.0.1:50070
Connection established 127.0.0.1:50046<->127.0.0.1:50070
Executing request PUT /webhdfs/v1/user/michaeljones/README.md?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-3 >> PUT /webhdfs/v1/user/michaeljones/README.md?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1
http-outgoing-3 >> Transfer-Encoding: chunked
http-outgoing-3 >> Content-Type: application/octet-stream
http-outgoing-3 >> Host: localhost:50070
http-outgoing-3 >> Connection: Keep-Alive
http-outgoing-3 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-3 >> Accept-Encoding: gzip,deflate
http-outgoing-3 >> "PUT /webhdfs/v1/user/michaeljones/README.md?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1[\r][\n]"
http-outgoing-3 >> "Transfer-Encoding: chunked[\r][\n]"
http-outgoing-3 >> "Content-Type: application/octet-stream[\r][\n]"
http-outgoing-3 >> "Host: localhost:50070[\r][\n]"
http-outgoing-3 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-3 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-3 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-3 >> "[\r][\n]"
http-outgoing-3 >> "1000[\r][\n]"
http-outgoing-3 >> "# Hello-Hadoop-netbeans-OS-X[\n]"
http-outgoing-3 >> "Java Maven project for playing with the HDFS API without any 3rd party hadoop plugins.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## Aim of project[\n]"
http-outgoing-3 >> "Hello world/tutorial level for programmatically operating with a pseudo distributed hadoop configuration on OS X. Hadoop 2.7 on Yosemite.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## What this project demonstrates[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "This is work in progress and so far the following functionality is demonstrated:[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "1. Direct programmatic control of the HDFS and running map reduce jobs - all unit tests run from the IDE with hadoop configuration built into this project and under git control.[\n]"
http-outgoing-3 >> "2. Uploading of files to the HDFS by implementing a Web REST API client.[\n]"
http-outgoing-3 >> "3. Layered application code for maximum re-use and ease of test driven development. The client I wrote uses an interface which has allowed me to provide both a Jersey HTTP client implementation and an Apache HTTP client implementation for comparison between the two toolkits.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "The initial difficulty was working out how to run the program in the IDE and talk to the local pseudo distributed setup without using a 3rd party Hadoop plugin. Apparently there used to be a plugin for netbeans, but it has been discontinued. I am a newbie with this technology.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "The Apache Hadoop instructions for building and running java programs are via their command line build/run utility only. Getting the yahoo hadoop HDFS tutorial program to build in the IDE wasn't too hard. However, by default it will ignore the local Hadoop configuration and only operate with the local file system in local debug mode.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## Wading through the configuration[\n]"
http-outgoing-3 >> "Hadoop is designed to work with a number of different topologies, directory locations, levels of replication, simulated environments etc. so as we would expect nothing works unless the configuration is right.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "First Hadoop needs to be installed and configured in pseudo distributed mode such that it builds and runs test programs on the command line. The hadoop documentation has instructions for doing this. Documentation is online and also included in the installation: share/doc/hadoop/index.html. However this is not enough to get it to work in the IDE.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## The netbeans project settings that are needed to run with the HDFS from the IDE:[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "1. Get log4j configured to work in the IDE. Absence of log4j configuration won't stop hadoop from running, but we won't get to see useful error messages from hadoop without it.[\n]"
http-outgoing-3 >> "2. HADOOP_HOME environment variable project run (and test) property.[\n]"
http-outgoing-3 >> "3. Duplicate hadoop configuration in the classpath. The above environment variable does not pick up the hadoop configuration from its usual place. Yahoo's only suggestion is to run from the command line via the hadoop script. The Apache HDFS API documention says that configuration is looked for in the classpath, so I took the approach of duplicating the configuration (just 2 files) instead of figuring out how to get it to look in the installation path.[\n]"
http-outgoing-3 >> "4. The correct Maven dependencies. If not all the jar depenencies are there the program may build and run, but it won't talk to the HDFS if it doesn't load the HDFS jars.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "I think that the setup of this project would probably work on Linux too.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## Working through trouble shooting the HDFS project settings[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "Issue 1 above shows up as:[\n]"
http-outgoing-3 >> "<pre><code>[\n]"
http-outgoing-3 >> "log4j:WARN No appenders could be found for logger (org.apache.hadoop.util.Shell).[\n]"
http-outgoing-3 >> "log4j:WARN Please initialize the log4j system properly.[\n]"
http-outgoing-3 >> "log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.[\n]"
http-outgoing-3 >> "</pre></code>[\n]"
http-outgoing-3 >> "This is solved by putting a log4j.properties configuration file in the classpath. For a Maven build getting files into the classpath can be achieved by putting them in src/main/resources. I don't think this is in the classpath, but the build will then copy the file into ./target/classes/ which is in the classpath.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "Issue 2 above shows up as:[\n]"
http-outgoing-3 >> "<pre><code>[\n]"
http-outgoing-3 >> "Failed to detect a valid hadoop home directory[\n]"
http-outgoing-3 >> "java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.[\n]"
http-outgoing-3 >> "</code></pre>[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "This is fixed by going into the project properties => Build => Actions => Run Project and adding the environmen[\r][\n]"
http-outgoing-3 >> "1000[\r][\n]"
http-outgoing-3 >> "t variable for HADOOP_HOME. This will result in an entry in the Maven POM. Repeat for "Test Project", "Debug Project" etc.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "Issue 3. shows up as running, but creating a file on the local file system instead of the HDFS. This was fixed       looking at the HDFS API documentation for org.apache.hadoop.conf.Configuration. This documentation is under the chapter: C API libhdfs HDFS which has a link to the HDFS API under "The APIs" (I strangely cannot find this in the main index). On my installation the HDFS API documentation link is file:///opt/local/hadoop-2.7.0/share/doc/hadoop/api/org/apache/hadoop/fs/FileSystem.html.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "This documentation told me that hadoop loads core-site.xml and core-default.xml in the classpath. Classpath for a Maven build can be reached by placing these files in the directory src/main/resources (see logging configuration above). I added hdfs-site instead of core-default (which doesn't exist on my 2.7 install) into the src/main/resources project directory.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "Issue 3 shows up as:[\n]"
http-outgoing-3 >> "<pre><code>[\n]"
http-outgoing-3 >> "java.io.IOException: "hadoop No FileSystem for scheme: hdfs".[\n]"
http-outgoing-3 >> "</code></pre>[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "This is part of the build dependency problem. The various threads on stackoverflow etc. suggested that a minimum dependency was the jar for hadoop-core. However, there is no such jar on 2.7. I ran the hadoop command to dump version and got this:[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "<pre><code>[\n]"
http-outgoing-3 >> "bin/hadoop version[\n]"
http-outgoing-3 >> "Hadoop 2.7.0[\n]"
http-outgoing-3 >> "Subversion https://git-wip-us.apache.org/repos/asf/hadoop.git -r d4c8d4d4d203c934e8074b31289a28724c0842cf[\n]"
http-outgoing-3 >> "Compiled by jenkins on 2015-04-10T18:40Z[\n]"
http-outgoing-3 >> "Compiled with protoc 2.5.0[\n]"
http-outgoing-3 >> "From source with checksum a9e90912c37a35c3195d23951fd18f[\n]"
http-outgoing-3 >> "This command was run using /opt/local/hadoop-2.7.0/share/hadoop/common/hadoop-common-2.7.0.jar[\n]"
http-outgoing-3 >> "</code></pre>[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "I noted the jar name at the end and added it as a dependency to the POM. This can either be hand coded in or right click pom.xml => Insert Code => Add Dependency => Search => query hadoop-common and select version which was 2.7.0 [jar] - central. Maven will then add dependencies to other hadoop jars in the "Dependencies" group in the project explorer. Netbeans will then download these dependencies before the next build. They go into ~/.m2/repository should they ever need to be cleaned out (Netbeans doesn't seem to have an IDE remove dependency option).[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "After doing the above project built, but showed up the "no filesystem error". I noticed that Maven had not pulled in any hdfs jars matching the jars in my share/hadoop/hdfs installation directory. So I took a guess that it needed only the top level hadoop-hdfs-2.7.0.jar and added this as a dependency to the POM and all was good :)[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## Working through trouble shooting the Map Reduce project settings[\n]"
http-outgoing-3 >> "After getting the HDFS API working in the IDE it was time to move on to getting the famous Word Count map-reduce tutorial running.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "So coded it, set the main program to the word count main as the one to run. From the IDE: project Properties => Run => Main Class. Provide input and output arguments for the word count program. I noted that the netbeans properties pop-up window does not persist these settings next time it pops up. However this setting is persistant and ends up in nbactions.xml.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "However, running the word count map reduce program resulted in an ioException:[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "<pre><code>[\n]"
http-outgoing-3 >> "Please check your configuration for mapreduce.framework.name and the correspond server addresses.[\n]"
http-outgoing-3 >> "</pre></code>[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "Because the resources directory only contains 2 configuration files from my hadoop installation I thought maybe I was missing a map reduce one. So the first thing I did was go into the configuration directory of my installation and grep all files to see if there was a configuration file with mapreduce framework property. There was not. I checked my programatic configuration dump from my test program. This property was not mentioned either. The only map reduce configuration was to do with some environment variables for heap size in one of the shell scripts. Note to self: this may be relevant and I can consider setting this in the IDE. However, that didn't look like the problem.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "I then chec[\r][\n]"
http-outgoing-3 >> "a93[\r][\n]"
http-outgoing-3 >> "ked my dependencies and noted there were no map reduce jars pulled in by Maven. So I added hadoop-mapreduce-client-core. Still not running. Checked the web and a thread on stackoverflow mentioned a number of other jars: hadoop-mapreduce-client-common and hadoop-mapreduce-client shuffle. I added just the hadoop-mapreduce-client-common and it runs :) I have a feeling that I might need some of the other jars for other API calls and that there must be a better way of working out dependencies than this trial and error. As mentioned I am a newbie with this, so if anyone has any comments feel free to email me.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## Logging from application code[\n]"
http-outgoing-3 >> "Although the hadoop libraries log correctly with a properly located log4.properties file, application code calling the log4j logger seems to ignore this file. Using the log4j logger as per instructions in the log4j manual and many online tutorials did not result in getting any logging redirected to file configured in the properties file. Instead console output only is obtained. A clue to this mystery was that a most basic of hello world netbeans maven projects which did not import any hadoop stuff also failed to log to a file and did not even give the "No appenders" warning. Then I noticed that there were org.sl4j depencies in the hadoop build, so using sl4j instead solved the problem. Once my hello world project used sl4j's LoggerFactory and had sl4j-api and sl4j-12 as a dependencies it started to use the properties file. See http://www.slf4j.org/manual.html[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## Upload a file from local storage to the HDFS via the REST API[\n]"
http-outgoing-3 >> "The WebHDFS REST API documentation which came with the installation specifies that file creation is a two stage operation where an initial PUT to the namenode is sent. This responds with a redirect to the datanode and another PUT should be made to this redirection which can contain the chunked data stream. This does not sound REST to me as it relies on holding redirection state (a fully distributed configuration could presumably return a redirection to any one of the datanodes). Hadoop say this is because of a bug in some HTTP client implementations - incorrect implementation of [0xe2][0x80][0x9c]Expect: 100-continue[0xe2][0x80][0x9d].[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "However, the 2 stage PUT not being REST seems to be a moot point, at least with the Jersey client. I do not get a redirection and a file creates/uploads all in one go.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "Since writing the above paragraph I have implemented the Apache Client back end option to my HDFS Web client interface and this client behaves differently. It does indeed cause a redirect as per Hadoop documentation. The follow up PUT to the redirected location with the chunked file stream works as per documentation.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "To be continued ...[\n]"
http-outgoing-3 >> "[\r][\n]"
http-outgoing-3 >> "0[\r][\n]"
http-outgoing-3 >> "[\r][\n]"
http-outgoing-3 << "HTTP/1.1 307 TEMPORARY_REDIRECT[\r][\n]"
http-outgoing-3 << "Cache-Control: no-cache[\r][\n]"
http-outgoing-3 << "Expires: Sat, 13 Jun 2015 03:57:49 GMT[\r][\n]"
http-outgoing-3 << "Date: Sat, 13 Jun 2015 03:57:49 GMT[\r][\n]"
http-outgoing-3 << "Pragma: no-cache[\r][\n]"
http-outgoing-3 << "Expires: Sat, 13 Jun 2015 03:57:49 GMT[\r][\n]"
http-outgoing-3 << "Date: Sat, 13 Jun 2015 03:57:49 GMT[\r][\n]"
http-outgoing-3 << "Pragma: no-cache[\r][\n]"
http-outgoing-3 << "Content-Type: application/octet-stream[\r][\n]"
http-outgoing-3 << "Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434203869591&s=xisvjjJuy0EYD3yuYj0zieKEPGs="; Path=/; Expires=Sat, 13-Jun-2015 13:57:49 GMT; HttpOnly[\r][\n]"
http-outgoing-3 << "Location: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/README.md?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true[\r][\n]"
http-outgoing-3 << "Content-Length: 0[\r][\n]"
http-outgoing-3 << "Server: Jetty(6.1.26)[\r][\n]"
http-outgoing-3 << "[\r][\n]"
http-outgoing-3 << HTTP/1.1 307 TEMPORARY_REDIRECT
http-outgoing-3 << Cache-Control: no-cache
http-outgoing-3 << Expires: Sat, 13 Jun 2015 03:57:49 GMT
http-outgoing-3 << Date: Sat, 13 Jun 2015 03:57:49 GMT
http-outgoing-3 << Pragma: no-cache
http-outgoing-3 << Expires: Sat, 13 Jun 2015 03:57:49 GMT
http-outgoing-3 << Date: Sat, 13 Jun 2015 03:57:49 GMT
http-outgoing-3 << Pragma: no-cache
http-outgoing-3 << Content-Type: application/octet-stream
http-outgoing-3 << Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434203869591&s=xisvjjJuy0EYD3yuYj0zieKEPGs="; Path=/; Expires=Sat, 13-Jun-2015 13:57:49 GMT; HttpOnly
http-outgoing-3 << Location: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/README.md?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
http-outgoing-3 << Content-Length: 0
http-outgoing-3 << Server: Jetty(6.1.26)
Connection can be kept alive indefinitely
Cookie accepted [hadoop.auth=""u=michaeljones&p=michaeljones&t=simple&e=1434203869591&s=xisvjjJuy0EYD3yuYj0zieKEPGs="", version:0, domain:localhost, path:/, expiry:Sat Jun 13 23:57:49 AEST 2015]
Redirect to: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/README.md?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
http-outgoing-3: Shutdown connection
Connection discarded
http-outgoing-3: Close connection
Connection released: [id: 3][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 4][route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://michaels-air.bigpond:50075
Connecting to michaels-air.bigpond/10.0.0.2:50075
Connection established 10.0.0.2:50047<->10.0.0.2:50075
Executing request PUT /webhdfs/v1/user/michaeljones/README.md?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-4 >> PUT /webhdfs/v1/user/michaeljones/README.md?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1
http-outgoing-4 >> Transfer-Encoding: chunked
http-outgoing-4 >> Content-Type: application/octet-stream
http-outgoing-4 >> Host: michaels-air.bigpond:50075
http-outgoing-4 >> Connection: Keep-Alive
http-outgoing-4 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-4 >> Accept-Encoding: gzip,deflate
http-outgoing-4 >> "PUT /webhdfs/v1/user/michaeljones/README.md?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1[\r][\n]"
http-outgoing-4 >> "Transfer-Encoding: chunked[\r][\n]"
http-outgoing-4 >> "Content-Type: application/octet-stream[\r][\n]"
http-outgoing-4 >> "Host: michaels-air.bigpond:50075[\r][\n]"
http-outgoing-4 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-4 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-4 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-4 >> "[\r][\n]"
http-outgoing-4 >> "1000[\r][\n]"
http-outgoing-4 >> "# Hello-Hadoop-netbeans-OS-X[\n]"
http-outgoing-4 >> "Java Maven project for playing with the HDFS API without any 3rd party hadoop plugins.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## Aim of project[\n]"
http-outgoing-4 >> "Hello world/tutorial level for programmatically operating with a pseudo distributed hadoop configuration on OS X. Hadoop 2.7 on Yosemite.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## What this project demonstrates[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "This is work in progress and so far the following functionality is demonstrated:[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "1. Direct programmatic control of the HDFS and running map reduce jobs - all unit tests run from the IDE with hadoop configuration built into this project and under git control.[\n]"
http-outgoing-4 >> "2. Uploading of files to the HDFS by implementing a Web REST API client.[\n]"
http-outgoing-4 >> "3. Layered application code for maximum re-use and ease of test driven development. The client I wrote uses an interface which has allowed me to provide both a Jersey HTTP client implementation and an Apache HTTP client implementation for comparison between the two toolkits.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "The initial difficulty was working out how to run the program in the IDE and talk to the local pseudo distributed setup without using a 3rd party Hadoop plugin. Apparently there used to be a plugin for netbeans, but it has been discontinued. I am a newbie with this technology.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "The Apache Hadoop instructions for building and running java programs are via their command line build/run utility only. Getting the yahoo hadoop HDFS tutorial program to build in the IDE wasn't too hard. However, by default it will ignore the local Hadoop configuration and only operate with the local file system in local debug mode.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## Wading through the configuration[\n]"
http-outgoing-4 >> "Hadoop is designed to work with a number of different topologies, directory locations, levels of replication, simulated environments etc. so as we would expect nothing works unless the configuration is right.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "First Hadoop needs to be installed and configured in pseudo distributed mode such that it builds and runs test programs on the command line. The hadoop documentation has instructions for doing this. Documentation is online and also included in the installation: share/doc/hadoop/index.html. However this is not enough to get it to work in the IDE.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## The netbeans project settings that are needed to run with the HDFS from the IDE:[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "1. Get log4j configured to work in the IDE. Absence of log4j configuration won't stop hadoop from running, but we won't get to see useful error messages from hadoop without it.[\n]"
http-outgoing-4 >> "2. HADOOP_HOME environment variable project run (and test) property.[\n]"
http-outgoing-4 >> "3. Duplicate hadoop configuration in the classpath. The above environment variable does not pick up the hadoop configuration from its usual place. Yahoo's only suggestion is to run from the command line via the hadoop script. The Apache HDFS API documention says that configuration is looked for in the classpath, so I took the approach of duplicating the configuration (just 2 files) instead of figuring out how to get it to look in the installation path.[\n]"
http-outgoing-4 >> "4. The correct Maven dependencies. If not all the jar depenencies are there the program may build and run, but it won't talk to the HDFS if it doesn't load the HDFS jars.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "I think that the setup of this project would probably work on Linux too.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## Working through trouble shooting the HDFS project settings[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "Issue 1 above shows up as:[\n]"
http-outgoing-4 >> "<pre><code>[\n]"
http-outgoing-4 >> "log4j:WARN No appenders could be found for logger (org.apache.hadoop.util.Shell).[\n]"
http-outgoing-4 >> "log4j:WARN Please initialize the log4j system properly.[\n]"
http-outgoing-4 >> "log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.[\n]"
http-outgoing-4 >> "</pre></code>[\n]"
http-outgoing-4 >> "This is solved by putting a log4j.properties configuration file in the classpath. For a Maven build getting files into the classpath can be achieved by putting them in src/main/resources. I don't think this is in the classpath, but the build will then copy the file into ./target/classes/ which is in the classpath.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "Issue 2 above shows up as:[\n]"
http-outgoing-4 >> "<pre><code>[\n]"
http-outgoing-4 >> "Failed to detect a valid hadoop home directory[\n]"
http-outgoing-4 >> "java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.[\n]"
http-outgoing-4 >> "</code></pre>[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "This is fixed by going into the project properties => Build => Actions => Run Project and adding the environmen[\r][\n]"
http-outgoing-4 >> "1000[\r][\n]"
http-outgoing-4 >> "t variable for HADOOP_HOME. This will result in an entry in the Maven POM. Repeat for "Test Project", "Debug Project" etc.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "Issue 3. shows up as running, but creating a file on the local file system instead of the HDFS. This was fixed       looking at the HDFS API documentation for org.apache.hadoop.conf.Configuration. This documentation is under the chapter: C API libhdfs HDFS which has a link to the HDFS API under "The APIs" (I strangely cannot find this in the main index). On my installation the HDFS API documentation link is file:///opt/local/hadoop-2.7.0/share/doc/hadoop/api/org/apache/hadoop/fs/FileSystem.html.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "This documentation told me that hadoop loads core-site.xml and core-default.xml in the classpath. Classpath for a Maven build can be reached by placing these files in the directory src/main/resources (see logging configuration above). I added hdfs-site instead of core-default (which doesn't exist on my 2.7 install) into the src/main/resources project directory.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "Issue 3 shows up as:[\n]"
http-outgoing-4 >> "<pre><code>[\n]"
http-outgoing-4 >> "java.io.IOException: "hadoop No FileSystem for scheme: hdfs".[\n]"
http-outgoing-4 >> "</code></pre>[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "This is part of the build dependency problem. The various threads on stackoverflow etc. suggested that a minimum dependency was the jar for hadoop-core. However, there is no such jar on 2.7. I ran the hadoop command to dump version and got this:[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "<pre><code>[\n]"
http-outgoing-4 >> "bin/hadoop version[\n]"
http-outgoing-4 >> "Hadoop 2.7.0[\n]"
http-outgoing-4 >> "Subversion https://git-wip-us.apache.org/repos/asf/hadoop.git -r d4c8d4d4d203c934e8074b31289a28724c0842cf[\n]"
http-outgoing-4 >> "Compiled by jenkins on 2015-04-10T18:40Z[\n]"
http-outgoing-4 >> "Compiled with protoc 2.5.0[\n]"
http-outgoing-4 >> "From source with checksum a9e90912c37a35c3195d23951fd18f[\n]"
http-outgoing-4 >> "This command was run using /opt/local/hadoop-2.7.0/share/hadoop/common/hadoop-common-2.7.0.jar[\n]"
http-outgoing-4 >> "</code></pre>[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "I noted the jar name at the end and added it as a dependency to the POM. This can either be hand coded in or right click pom.xml => Insert Code => Add Dependency => Search => query hadoop-common and select version which was 2.7.0 [jar] - central. Maven will then add dependencies to other hadoop jars in the "Dependencies" group in the project explorer. Netbeans will then download these dependencies before the next build. They go into ~/.m2/repository should they ever need to be cleaned out (Netbeans doesn't seem to have an IDE remove dependency option).[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "After doing the above project built, but showed up the "no filesystem error". I noticed that Maven had not pulled in any hdfs jars matching the jars in my share/hadoop/hdfs installation directory. So I took a guess that it needed only the top level hadoop-hdfs-2.7.0.jar and added this as a dependency to the POM and all was good :)[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## Working through trouble shooting the Map Reduce project settings[\n]"
http-outgoing-4 >> "After getting the HDFS API working in the IDE it was time to move on to getting the famous Word Count map-reduce tutorial running.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "So coded it, set the main program to the word count main as the one to run. From the IDE: project Properties => Run => Main Class. Provide input and output arguments for the word count program. I noted that the netbeans properties pop-up window does not persist these settings next time it pops up. However this setting is persistant and ends up in nbactions.xml.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "However, running the word count map reduce program resulted in an ioException:[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "<pre><code>[\n]"
http-outgoing-4 >> "Please check your configuration for mapreduce.framework.name and the correspond server addresses.[\n]"
http-outgoing-4 >> "</pre></code>[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "Because the resources directory only contains 2 configuration files from my hadoop installation I thought maybe I was missing a map reduce one. So the first thing I did was go into the configuration directory of my installation and grep all files to see if there was a configuration file with mapreduce framework property. There was not. I checked my programatic configuration dump from my test program. This property was not mentioned either. The only map reduce configuration was to do with some environment variables for heap size in one of the shell scripts. Note to self: this may be relevant and I can consider setting this in the IDE. However, that didn't look like the problem.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "I then chec[\r][\n]"
http-outgoing-4 >> "a93[\r][\n]"
http-outgoing-4 >> "ked my dependencies and noted there were no map reduce jars pulled in by Maven. So I added hadoop-mapreduce-client-core. Still not running. Checked the web and a thread on stackoverflow mentioned a number of other jars: hadoop-mapreduce-client-common and hadoop-mapreduce-client shuffle. I added just the hadoop-mapreduce-client-common and it runs :) I have a feeling that I might need some of the other jars for other API calls and that there must be a better way of working out dependencies than this trial and error. As mentioned I am a newbie with this, so if anyone has any comments feel free to email me.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## Logging from application code[\n]"
http-outgoing-4 >> "Although the hadoop libraries log correctly with a properly located log4.properties file, application code calling the log4j logger seems to ignore this file. Using the log4j logger as per instructions in the log4j manual and many online tutorials did not result in getting any logging redirected to file configured in the properties file. Instead console output only is obtained. A clue to this mystery was that a most basic of hello world netbeans maven projects which did not import any hadoop stuff also failed to log to a file and did not even give the "No appenders" warning. Then I noticed that there were org.sl4j depencies in the hadoop build, so using sl4j instead solved the problem. Once my hello world project used sl4j's LoggerFactory and had sl4j-api and sl4j-12 as a dependencies it started to use the properties file. See http://www.slf4j.org/manual.html[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## Upload a file from local storage to the HDFS via the REST API[\n]"
http-outgoing-4 >> "The WebHDFS REST API documentation which came with the installation specifies that file creation is a two stage operation where an initial PUT to the namenode is sent. This responds with a redirect to the datanode and another PUT should be made to this redirection which can contain the chunked data stream. This does not sound REST to me as it relies on holding redirection state (a fully distributed configuration could presumably return a redirection to any one of the datanodes). Hadoop say this is because of a bug in some HTTP client implementations - incorrect implementation of [0xe2][0x80][0x9c]Expect: 100-continue[0xe2][0x80][0x9d].[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "However, the 2 stage PUT not being REST seems to be a moot point, at least with the Jersey client. I do not get a redirection and a file creates/uploads all in one go.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "Since writing the above paragraph I have implemented the Apache Client back end option to my HDFS Web client interface and this client behaves differently. It does indeed cause a redirect as per Hadoop documentation. The follow up PUT to the redirected location with the chunked file stream works as per documentation.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "To be continued ...[\n]"
http-outgoing-4 >> "[\r][\n]"
http-outgoing-4 >> "0[\r][\n]"
http-outgoing-4 >> "[\r][\n]"
http-outgoing-4 << "HTTP/1.1 100 Continue[\r][\n]"
http-outgoing-4 << "[\r][\n]"
http-outgoing-4 << HTTP/1.1 100 Continue
http-outgoing-4 << "HTTP/1.1 201 Created[\r][\n]"
http-outgoing-4 << "Location: hdfs://localhost:9000/user/michaeljones/README.md[\r][\n]"
http-outgoing-4 << "Content-Length: 0[\r][\n]"
http-outgoing-4 << "Connection: close[\r][\n]"
http-outgoing-4 << "[\r][\n]"
http-outgoing-4 << HTTP/1.1 201 Created
http-outgoing-4 << Location: hdfs://localhost:9000/user/michaeljones/README.md
http-outgoing-4 << Content-Length: 0
http-outgoing-4 << Connection: close
http-outgoing-4: Shutdown connection
Connection discarded
http-outgoing-4: Close connection
Connection released: [id: 4][route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection manager is shutting down
Connection manager shut down
setsid is not available on this machine. So not using it.
setsid exited with exit code 0
field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, always=false, sampleName=Ops, type=DEFAULT, value=[Rate of successful kerberos logins and latency (milliseconds)], valueName=Time)
field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, always=false, sampleName=Ops, type=DEFAULT, value=[Rate of failed kerberos logins and latency (milliseconds)], valueName=Time)
field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, always=false, sampleName=Ops, type=DEFAULT, value=[GetGroups], valueName=Time)
UgiMetrics, User and group related metrics
Kerberos krb5 configuration not found, setting default realm to empty
 Creating new Groups object
Trying to load the custom-built native-hadoop library...
Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
java.library.path=/Applications/NetBeans/NetBeans 8.0.2.app/Contents/Resources/NetBeans/webcommon/bin::/Users/michaeljones/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:.
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Falling back to shell based
Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
hadoop login
hadoop login commit
using local user:UnixPrincipal: michaeljones
Using user: "UnixPrincipal: michaeljones" with name michaeljones
User entry: "michaeljones"
UGI loginUser:michaeljones (auth:SIMPLE)
dfs.client.use.legacy.blockreader.local = false
dfs.client.read.shortcircuit = false
dfs.client.domain.socket.data.traffic = false
dfs.domain.socket.path = 
multipleLinearRandomRetry = null
Connection manager is shutting down
Connection manager shut down
rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWrapper, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@1a6c1270
getting client out of cache: org.apache.hadoop.ipc.Client@22d7b4f8
Both short-circuit local reads and UNIX domain socket are disabled.
DataTransferProtocol not using SaslPropertiesResolver, no QOP found in configuration for dfs.data.transfer.protection
The ping interval is 60000 ms.
Connecting to localhost/127.0.0.1:9000
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones: starting, having connections 1
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #0
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #0
Call: getFileInfo took 140ms
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #1
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #1
Call: delete took 3ms
/user/michaeljones/hello.txt: masked=rw-r--r--
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #2
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #2
Call: create took 6ms
computePacketChunkSize: src=/user/michaeljones/hello.txt, chunkSize=516, chunksPerPacket=126, packetSize=65016
Lease renewer daemon for [DFSClient_NONMAPREDUCE_1091877400_1] with renew id 1 started
DFSClient writeChunk allocating new packet seqno=0, src=/user/michaeljones/hello.txt, packetSize=65016, chunksPerPacket=126, bytesCurBlock=0
Queued packet 0
Queued packet 1
Allocating new block
Waiting for ack for: 1
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #3
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #3
Call: addBlock took 7ms
pipeline = DatanodeInfoWithStorage[127.0.0.1:50010,DS-b42c5705-9ba4-4b14-b00b-f9194bb036f0,DISK]
Connecting to datanode 127.0.0.1:50010
Send buf size 131072
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #4
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #4
Call: getServerDefaults took 2ms
SASL client skipping handshake in unsecured configuration for addr = /127.0.0.1, datanodeId = DatanodeInfoWithStorage[127.0.0.1:50010,DS-b42c5705-9ba4-4b14-b00b-f9194bb036f0,DISK]
DataStreamer block BP-1045030256-10.0.0.2-1433119149314:blk_1073742264_1441 sending packet packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 20
DFSClient seqno: 0 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
DataStreamer block BP-1045030256-10.0.0.2-1433119149314:blk_1073742264_1441 sending packet packet seqno: 1 offsetInBlock: 20 lastPacketInBlock: true lastByteOffsetInBlock: 20
DFSClient seqno: 1 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
Closing old block BP-1045030256-10.0.0.2-1433119149314:blk_1073742264_1441
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #5
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #5
Call: complete took 3ms
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #6
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #6
Call: getBlockLocations took 3ms
newInfo = LocatedBlocks{
  fileLength=20
  underConstruction=false
  blocks=[LocatedBlock{BP-1045030256-10.0.0.2-1433119149314:blk_1073742264_1441; getBlockSize()=20; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-b42c5705-9ba4-4b14-b00b-f9194bb036f0,DISK]]}]
  lastLocatedBlock=LocatedBlock{BP-1045030256-10.0.0.2-1433119149314:blk_1073742264_1441; getBlockSize()=20; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-b42c5705-9ba4-4b14-b00b-f9194bb036f0,DISK]]}
  isLastBlockComplete=true}
Connecting to datanode 127.0.0.1:50010
SASL client skipping handshake in unsecured configuration for addr = /127.0.0.1, datanodeId = DatanodeInfoWithStorage[127.0.0.1:50010,DS-b42c5705-9ba4-4b14-b00b-f9194bb036f0,DISK]
testMain
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #7
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #7
Call: getFileInfo took 3ms
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #8
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #8
Call: delete took 5ms
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.connect(Job.java:1256)
Trying ClientProtocolProvider : org.apache.hadoop.mapred.LocalClientProtocolProvider
session.id is deprecated. Instead, use dfs.metrics.session-id
Initializing JVM Metrics with processName=JobTracker, sessionId=
Picked org.apache.hadoop.mapred.LocalClientProtocolProvider as the ClientProtocolProvider
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Cluster.getFileSystem(Cluster.java:162)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.submit(Job.java:1287)
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #9
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #9
Call: getFileInfo took 2ms
Configuring job job_local425895704_0001 with file:/tmp/hadoop-michaeljones/mapred/staging/michaeljones425895704/.staging/job_local425895704_0001 as the submit dir
adding the following namenodes' delegation tokens:[hdfs://localhost:9000]
Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
default FileSystem: file:///
No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
Creating splits at file:/tmp/hadoop-michaeljones/mapred/staging/michaeljones425895704/.staging/job_local425895704_0001
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #10
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #10
Call: getFileInfo took 2ms
Time taken to get FileStatuses: 6
Total input paths to process : 1
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #11
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #11
Call: getBlockLocations took 3ms
Total # of splits generated by getSplits: 1, TimeTaken: 31
number of splits:1
Handling deprecation for all properties in config...
Handling deprecation for mapreduce.jobtracker.address
Handling deprecation for yarn.resourcemanager.scheduler.monitor.policies
Handling deprecation for dfs.namenode.resource.check.interval
Handling deprecation for mapreduce.jobhistory.client.thread-count
Handling deprecation for yarn.app.mapreduce.am.containerlauncher.threadpool-initial-size
Handling deprecation for mapred.child.java.opts
Handling deprecation for mapreduce.jobtracker.retiredjobs.cache.size
Handling deprecation for dfs.client.https.need-auth
Handling deprecation for yarn.admin.acl
Handling deprecation for yarn.app.mapreduce.am.job.committer.cancel-timeout
Handling deprecation for mapreduce.job.emit-timeline-data
Handling deprecation for fs.ftp.host.port
Handling deprecation for dfs.namenode.avoid.read.stale.datanode
Handling deprecation for dfs.journalnode.rpc-address
Handling deprecation for mapreduce.job.end-notification.retry.attempts
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.ttl-interval-ms
Handling deprecation for yarn.resourcemanager.leveldb-state-store.path
Handling deprecation for mapred.mapper.new-api
Handling deprecation for yarn.ipc.rpc.class
Handling deprecation for ipc.client.connection.maxidletime
Handling deprecation for yarn.nodemanager.process-kill-wait.ms
Handling deprecation for mapreduce.cluster.acls.enabled
Handling deprecation for mapreduce.jobtracker.handler.count
Handling deprecation for io.map.index.interval
Handling deprecation for dfs.namenode.https-address
Handling deprecation for mapreduce.task.profile.reduces
Handling deprecation for fs.s3n.multipart.uploads.enabled
Handling deprecation for io.seqfile.sorter.recordlimit
Handling deprecation for mapreduce.job.ubertask.maxmaps
Handling deprecation for mapreduce.tasktracker.tasks.sleeptimebeforesigkill
Handling deprecation for hadoop.util.hash.type
Handling deprecation for dfs.namenode.replication.min
Handling deprecation for yarn.nodemanager.container-manager.thread-count
Handling deprecation for mapreduce.jobtracker.jobhistory.block.size
Handling deprecation for dfs.namenode.fs-limits.min-block-size
Handling deprecation for mapreduce.app-submission.cross-platform
Handling deprecation for fs.AbstractFileSystem.file.impl
Handling deprecation for net.topology.script.number.args
Handling deprecation for yarn.resourcemanager.container-tokens.master-key-rolling-interval-secs
Handling deprecation for mapreduce.map.output.compress.codec
Handling deprecation for mapreduce.job.reducer.preempt.delay.sec
Handling deprecation for s3native.bytes-per-checksum
Handling deprecation for dfs.namenode.path.based.cache.block.map.allocation.percent
Handling deprecation for yarn.nodemanager.windows-container.memory-limit.enabled
Handling deprecation for mapreduce.input.fileinputformat.split.minsize
Handling deprecation for hadoop.security.group.mapping
Handling deprecation for mapreduce.jobtracker.system.dir
Handling deprecation for mapreduce.job.end-notification.max.attempts
Handling deprecation for mapreduce.reduce.markreset.buffer.percent
Handling deprecation for dfs.datanode.cache.revocation.polling.ms
Handling deprecation for mapreduce.reduce.speculative
Handling deprecation for yarn.nodemanager.localizer.cache.cleanup.interval-ms
Handling deprecation for dfs.namenode.lazypersist.file.scrub.interval.sec
Handling deprecation for fs.s3a.threads.core
Handling deprecation for mapreduce.jobhistory.recovery.store.fs.uri
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.start-time-read-cache-size
Handling deprecation for hadoop.registry.zk.retry.interval.ms
Handling deprecation for yarn.nodemanager.keytab
Handling deprecation for dfs.namenode.replication.interval
Handling deprecation for yarn.resourcemanager.admin.address
Handling deprecation for mapreduce.job.maps
Handling deprecation for nfs.dump.dir
Handling deprecation for mapreduce.job.user.name
Handling deprecation for mapreduce.jobtracker.maxtasks.perjob
Handling deprecation for mapreduce.job.ubertask.enable
Handling deprecation for mapreduce.job.reduce.class
Handling deprecation for yarn.nodemanager.delete.debug-delay-sec
Handling deprecation for yarn.timeline-service.ttl-enable
Handling deprecation for yarn.resourcemanager.fs.state-store.retry-policy-spec
Handling deprecation for mapreduce.reduce.skip.maxgroups
Handling deprecation for dfs.client.use.datanode.hostname
Handling deprecation for fs.trash.interval
Handling deprecation for mapreduce.job.name
Handling deprecation for mapreduce.am.max-attempts
Handling deprecation for mapreduce.jobtracker.heartbeats.in.second
Handling deprecation for yarn.resourcemanager.zk-num-retries
Handling deprecation for s3.blocksize
Handling deprecation for dfs.datanode.data.dir
Handling deprecation for mapreduce.jobtracker.persist.jobstatus.active
Handling deprecation for mapreduce.reduce.shuffle.parallelcopies
Handling deprecation for fs.s3.buffer.dir
Handling deprecation for mapreduce.jobhistory.done-dir
Handling deprecation for hadoop.security.instrumentation.requires.admin
Handling deprecation for hadoop.registry.zk.retry.ceiling.ms
Handling deprecation for nfs.rtmax
Handling deprecation for dfs.datanode.data.dir.perm
Handling deprecation for yarn.resourcemanager.container.liveness-monitor.interval-ms
Handling deprecation for yarn.nodemanager.env-whitelist
Handling deprecation for dfs.namenode.backup.address
Handling deprecation for dfs.namenode.xattrs.enabled
Handling deprecation for dfs.datanode.readahead.bytes
Handling deprecation for mapreduce.jobhistory.cleaner.enable
Handling deprecation for dfs.client.block.write.retries
Handling deprecation for mapreduce.tasktracker.http.address
Handling deprecation for yarn.nodemanager.linux-container-executor.cgroups.hierarchy
Handling deprecation for ha.failover-controller.graceful-fence.connection.retries
Handling deprecation for yarn.resourcemanager.recovery.enabled
Handling deprecation for yarn.app.mapreduce.am.container.log.backups
Handling deprecation for dfs.namenode.safemode.threshold-pct
Handling deprecation for yarn.nodemanager.disk-health-checker.interval-ms
Handling deprecation for hadoop.security.java.secure.random.algorithm
Handling deprecation for dfs.namenode.list.cache.directives.num.responses
Handling deprecation for dfs.datanode.dns.nameserver
Handling deprecation for mapreduce.cluster.temp.dir
Handling deprecation for fs.s3a.max.total.tasks
Handling deprecation for mapreduce.reduce.maxattempts
Handling deprecation for mapreduce.client.submit.file.replication
Handling deprecation for mapreduce.shuffle.port
Handling deprecation for yarn.resourcemanager.resource-tracker.client.thread-count
Handling deprecation for dfs.namenode.replication.considerLoad
Handling deprecation for dfs.namenode.edits.journal-plugin.qjournal
Handling deprecation for dfs.client.write.exclude.nodes.cache.expiry.interval.millis
Handling deprecation for yarn.nodemanager.delete.thread-count
Handling deprecation for dfs.client.mmap.cache.timeout.ms
Handling deprecation for yarn.nodemanager.admin-env
Handling deprecation for io.skip.checksum.errors
Handling deprecation for yarn.timeline-service.hostname
Handling deprecation for yarn.resourcemanager.proxy-user-privileges.enabled
Handling deprecation for mapreduce.job.speculative.speculative-cap-total-tasks
Handling deprecation for yarn.acl.enable
Handling deprecation for fs.s3a.fast.upload
Handling deprecation for file.blocksize
Handling deprecation for mapreduce.job.speculative.slowtaskthreshold
Handling deprecation for ftp.replication
Handling deprecation for yarn.sharedcache.cleaner.initial-delay-mins
Handling deprecation for s3native.client-write-packet-size
Handling deprecation for hadoop.rpc.socket.factory.class.default
Handling deprecation for file.bytes-per-checksum
Handling deprecation for dfs.datanode.slow.io.warning.threshold.ms
Handling deprecation for io.seqfile.lazydecompress
Handling deprecation for mapreduce.task.skip.start.attempts
Handling deprecation for dfs.namenode.reject-unresolved-dn-topology-mapping
Handling deprecation for hadoop.common.configuration.version
Handling deprecation for yarn.resourcemanager.client.thread-count
Handling deprecation for dfs.datanode.drop.cache.behind.reads
Handling deprecation for yarn.sharedcache.admin.address
Handling deprecation for mapreduce.job.output.value.class
Handling deprecation for mapreduce.output.fileoutputformat.outputdir
Handling deprecation for mapreduce.jobtracker.taskcache.levels
Handling deprecation for yarn.nodemanager.linux-container-executor.nonsecure-mode.user-pattern
Handling deprecation for yarn.resourcemanager.zk-timeout-ms
Handling deprecation for yarn.resourcemanager.max-completed-applications
Handling deprecation for mapreduce.job.jvm.numtasks
Handling deprecation for yarn.sharedcache.cleaner.period-mins
Handling deprecation for mapreduce.jobtracker.tasktracker.maxblacklists
Handling deprecation for dfs.namenode.top.num.users
Handling deprecation for yarn.nodemanager.linux-container-executor.cgroups.mount
Handling deprecation for yarn.sharedcache.checksum.algo.impl
Handling deprecation for mapreduce.job.end-notification.max.retry.interval
Handling deprecation for mapreduce.job.acl-view-job
Handling deprecation for mapreduce.job.classloader
Handling deprecation for yarn.log-aggregation-enable
Handling deprecation for mapreduce.reduce.shuffle.fetch.retry.interval-ms
Handling deprecation for yarn.resourcemanager.nodemanager.minimum.version
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.size
Handling deprecation for yarn.app.mapreduce.am.job.task.listener.thread-count
Handling deprecation for yarn.app.mapreduce.am.resource.cpu-vcores
Handling deprecation for dfs.namenode.edit.log.autoroll.check.interval.ms
Handling deprecation for mapreduce.output.fileoutputformat.compress.type
Handling deprecation for hadoop.hdfs.configuration.version
Handling deprecation for hadoop.security.group.mapping.ldap.search.attr.member
Handling deprecation for yarn.nodemanager.log.retain-seconds
Handling deprecation for yarn.nodemanager.local-cache.max-files-per-directory
Handling deprecation for mapreduce.job.end-notification.retry.interval
Handling deprecation for hadoop.ssl.client.conf
Handling deprecation for yarn.sharedcache.root-dir
Handling deprecation for dfs.journalnode.https-address
Handling deprecation for mapreduce.reduce.shuffle.fetch.retry.timeout-ms
Handling deprecation for dfs.bytes-per-checksum
Handling deprecation for dfs.namenode.max.objects
Handling deprecation for mapreduce.tasktracker.instrumentation
Handling deprecation for dfs.datanode.max.transfer.threads
Handling deprecation for dfs.block.access.key.update.interval
Handling deprecation for mapreduce.jobtracker.jobhistory.task.numberprogresssplits
Handling deprecation for mapreduce.map.memory.mb
Handling deprecation for ha.failover-controller.new-active.rpc-timeout.ms
Handling deprecation for hadoop.ssl.hostname.verifier
Handling deprecation for dfs.client.read.shortcircuit
Handling deprecation for dfs.datanode.hdfs-blocks-metadata.enabled
Handling deprecation for mapreduce.tasktracker.healthchecker.interval
Handling deprecation for dfs.image.transfer.chunksize
Handling deprecation for mapreduce.tasktracker.taskmemorymanager.monitoringinterval
Handling deprecation for dfs.client.https.keystore.resource
Handling deprecation for yarn.resourcemanager.connect.retry-interval.ms
Handling deprecation for yarn.timeline-service.webapp.address
Handling deprecation for s3native.blocksize
Handling deprecation for yarn.scheduler.minimum-allocation-mb
Handling deprecation for yarn.sharedcache.cleaner.resource-sleep-ms
Handling deprecation for net.topology.impl
Handling deprecation for dfs.client.failover.sleep.base.millis
Handling deprecation for dfs.permissions.superusergroup
Handling deprecation for io.seqfile.compress.blocksize
Handling deprecation for hadoop.registry.zk.retry.times
Handling deprecation for fs.AbstractFileSystem.ftp.impl
Handling deprecation for dfs.namenode.checkpoint.edits.dir
Handling deprecation for mapreduce.job.running.reduce.limit
Handling deprecation for dfs.blockreport.initialDelay
Handling deprecation for dfs.namenode.heartbeat.recheck-interval
Handling deprecation for dfs.namenode.safemode.extension
Handling deprecation for yarn.scheduler.maximum-allocation-mb
Handling deprecation for mapreduce.job.reduce.shuffle.consumer.plugin.class
Handling deprecation for yarn.nodemanager.vmem-check-enabled
Handling deprecation for mapreduce.task.io.sort.factor
Handling deprecation for mapreduce.jobtracker.persist.jobstatus.dir
Handling deprecation for dfs.client.failover.sleep.max.millis
Handling deprecation for dfs.namenode.delegation.key.update-interval
Handling deprecation for hadoop.rpc.protection
Handling deprecation for fs.permissions.umask-mode
Handling deprecation for fs.s3.sleepTimeSeconds
Handling deprecation for ha.health-monitor.rpc-timeout.ms
Handling deprecation for hadoop.http.staticuser.user
Handling deprecation for fs.s3a.connection.maximum
Handling deprecation for yarn.nodemanager.linux-container-executor.nonsecure-mode.limit-users
Handling deprecation for fs.s3a.paging.maximum
Handling deprecation for fs.AbstractFileSystem.viewfs.impl
Handling deprecation for fs.ftp.host
Handling deprecation for yarn.nodemanager.linux-container-executor.nonsecure-mode.local-user
Handling deprecation for fs.s3a.impl
Handling deprecation for hadoop.http.authentication.kerberos.keytab
Handling deprecation for dfs.namenode.fs-limits.max-blocks-per-file
Handling deprecation for mapreduce.tasktracker.http.threads
Handling deprecation for mapreduce.tasktracker.dns.nameserver
Handling deprecation for yarn.resourcemanager.am-rm-tokens.master-key-rolling-interval-secs
Handling deprecation for dfs.client.block.write.replace-datanode-on-failure.enable
Handling deprecation for io.compression.codec.bzip2.library
Handling deprecation for mapreduce.map.skip.maxrecords
Handling deprecation for dfs.client.use.legacy.blockreader.local
Handling deprecation for dfs.namenode.checkpoint.dir
Handling deprecation for dfs.namenode.top.windows.minutes
Handling deprecation for mapreduce.job.maxtaskfailures.per.tracker
Handling deprecation for net.topology.node.switch.mapping.impl
Handling deprecation for mapreduce.shuffle.max.connections
Handling deprecation for mapreduce.jobhistory.loadedjobs.cache.size
Handling deprecation for dfs.storage.policy.enabled
Handling deprecation for yarn.client.application-client-protocol.poll-interval-ms
Handling deprecation for yarn.nodemanager.localizer.address
Handling deprecation for dfs.namenode.list.cache.pools.num.responses
Handling deprecation for nfs.server.port
Handling deprecation for mapreduce.client.output.filter
Handling deprecation for yarn.timeline-service.client.best-effort
Handling deprecation for ha.zookeeper.parent-znode
Handling deprecation for mapreduce.jobtracker.persist.jobstatus.hours
Handling deprecation for yarn.sharedcache.admin.thread-count
Handling deprecation for yarn.nodemanager.resource.cpu-vcores
Handling deprecation for dfs.datanode.block-pinning.enabled
Handling deprecation for mapreduce.jobhistory.http.policy
Handling deprecation for yarn.resourcemanager.webapp.delegation-token-auth-filter.enabled
Handling deprecation for mapreduce.job.speculative.retry-after-no-speculate
Handling deprecation for fs.s3a.attempts.maximum
Handling deprecation for s3native.stream-buffer-size
Handling deprecation for io.seqfile.local.dir
Handling deprecation for yarn.log-aggregation.retain-check-interval-seconds
Handling deprecation for fs.s3n.multipart.copy.block.size
Handling deprecation for dfs.encrypt.data.transfer.cipher.key.bitlength
Handling deprecation for dfs.datanode.sync.behind.writes
Handling deprecation for yarn.resourcemanager.zk-acl
Handling deprecation for hadoop.ssl.keystores.factory.class
Handling deprecation for mapreduce.job.split.metainfo.maxsize
Handling deprecation for fs.s3.maxRetries
Handling deprecation for hadoop.security.random.device.file.path
Handling deprecation for yarn.client.nodemanager-connect.max-wait-ms
Handling deprecation for dfs.namenode.stale.datanode.interval
Handling deprecation for mapreduce.task.io.sort.mb
Handling deprecation for yarn.resourcemanager.zk-state-store.parent-path
Handling deprecation for yarn.app.mapreduce.client-am.ipc.max-retries
Handling deprecation for fs.client.resolve.remote.symlinks
Handling deprecation for yarn.nodemanager.linux-container-executor.cgroups.strict-resource-usage
Handling deprecation for hadoop.ssl.enabled.protocols
Handling deprecation for mapreduce.reduce.cpu.vcores
Handling deprecation for yarn.client.failover-retries
Handling deprecation for mapreduce.jobhistory.address
Handling deprecation for hadoop.ssl.enabled
Handling deprecation for dfs.replication.max
Handling deprecation for dfs.namenode.name.dir
Handling deprecation for dfs.datanode.https.address
Handling deprecation for ipc.client.kill.max
Handling deprecation for mapreduce.job.committer.setup.cleanup.needed
Handling deprecation for dfs.client.domain.socket.data.traffic
Handling deprecation for yarn.nodemanager.localizer.cache.target-size-mb
Handling deprecation for yarn.resourcemanager.admin.client.thread-count
Handling deprecation for dfs.block.access.token.enable
Handling deprecation for mapreduce.job.speculative.retry-after-speculate
Handling deprecation for dfs.datanode.address
Handling deprecation for mapreduce.jobtracker.restart.recover
Handling deprecation for ipc.client.connect.max.retries
Handling deprecation for yarn.timeline-service.store-class
Handling deprecation for dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
Handling deprecation for hadoop.tmp.dir
Handling deprecation for dfs.datanode.handler.count
Handling deprecation for yarn.resourcemanager.ha.automatic-failover.embedded
Handling deprecation for yarn.timeline-service.ttl-ms
Handling deprecation for mapreduce.task.profile.map.params
Handling deprecation for yarn.resourcemanager.nodemanagers.heartbeat-interval-ms
Handling deprecation for mapreduce.map.speculative
Handling deprecation for yarn.timeline-service.recovery.enabled
Handling deprecation for mapreduce.job.map.class
Handling deprecation for dfs.namenode.resource.checked.volumes.minimum
Handling deprecation for yarn.nodemanager.recovery.dir
Handling deprecation for mapreduce.job.counters.max
Handling deprecation for yarn.resourcemanager.keytab
Handling deprecation for dfs.namenode.max.extra.edits.segments.retained
Handling deprecation for dfs.webhdfs.user.provider.user.pattern
Handling deprecation for dfs.client.mmap.enabled
Handling deprecation for mapreduce.map.log.level
Handling deprecation for dfs.client.file-block-storage-locations.timeout.millis
Handling deprecation for yarn.client.max-cached-nodemanagers-proxies
Handling deprecation for yarn.app.mapreduce.am.scheduler.heartbeat.interval-ms
Handling deprecation for hadoop.fuse.timer.period
Handling deprecation for fs.trash.checkpoint.interval
Handling deprecation for yarn.sharedcache.app-checker.class
Handling deprecation for dfs.journalnode.http-address
Handling deprecation for yarn.app.mapreduce.am.staging-dir
Handling deprecation for mapreduce.tasktracker.local.dir.minspacestart
Handling deprecation for yarn.nm.liveness-monitor.expiry-interval-ms
Handling deprecation for ha.health-monitor.check-interval.ms
Handling deprecation for mapreduce.reduce.shuffle.merge.percent
Handling deprecation for dfs.namenode.retrycache.heap.percent
Handling deprecation for yarn.nodemanager.docker-container-executor.exec-name
Handling deprecation for ipc.client.connect.timeout
Handling deprecation for yarn.resourcemanager.fs.state-store.retry-interval-ms
Handling deprecation for mapreduce.output.fileoutputformat.compress
Handling deprecation for yarn.nodemanager.local-dirs
Handling deprecation for yarn.nodemanager.recovery.enabled
Handling deprecation for io.native.lib.available
Handling deprecation for yarn.sharedcache.store.in-memory.staleness-period-mins
Handling deprecation for yarn.resourcemanager.am.max-attempts
Handling deprecation for s3.replication
Handling deprecation for mapreduce.input.fileinputformat.inputdir
Handling deprecation for fs.AbstractFileSystem.har.impl
Handling deprecation for dfs.image.compress
Handling deprecation for mapreduce.job.running.map.limit
Handling deprecation for mapreduce.reduce.input.buffer.percent
Handling deprecation for yarn.nodemanager.webapp.address
Handling deprecation for dfs.datanode.available-space-volume-choosing-policy.balanced-space-preference-fraction
Handling deprecation for dfs.namenode.edit.log.autoroll.multiplier.threshold
Handling deprecation for hadoop.security.group.mapping.ldap.ssl
Handling deprecation for dfs.namenode.checkpoint.check.period
Handling deprecation for fs.defaultFS
Handling deprecation for fs.s3a.multipart.size
Handling deprecation for dfs.client.slow.io.warning.threshold.ms
Handling deprecation for yarn.app.mapreduce.am.job.committer.commit-window
Handling deprecation for hadoop.security.group.mapping.ldap.search.attr.group.name
Handling deprecation for yarn.nodemanager.disk-health-checker.max-disk-utilization-per-disk-percentage
Handling deprecation for yarn.nodemanager.container-monitor.procfs-tree.smaps-based-rss.enabled
Handling deprecation for mapreduce.job.submithostname
Handling deprecation for mapreduce.map.sort.spill.percent
Handling deprecation for hadoop.security.crypto.codec.classes.aes.ctr.nopadding
Handling deprecation for dfs.namenode.http-address
Handling deprecation for hadoop.security.groups.negative-cache.secs
Handling deprecation for hadoop.ssl.server.conf
Handling deprecation for mapreduce.ifile.readahead
Handling deprecation for s3native.replication
Handling deprecation for yarn.client.nodemanager-client-async.thread-pool-max-size
Handling deprecation for mapreduce.jobtracker.staging.root.dir
Handling deprecation for mapreduce.jobhistory.admin.address
Handling deprecation for dfs.namenode.startup.delay.block.deletion.sec
Handling deprecation for yarn.nodemanager.health-checker.interval-ms
Handling deprecation for dfs.namenode.checkpoint.max-retries
Handling deprecation for s3.stream-buffer-size
Handling deprecation for ftp.client-write-packet-size
Handling deprecation for dfs.datanode.fsdatasetcache.max.threads.per.volume
Handling deprecation for mapreduce.output.fileoutputformat.compress.codec
Handling deprecation for yarn.timeline-service.keytab
Handling deprecation for yarn.sharedcache.store.in-memory.initial-delay-mins
Handling deprecation for mapreduce.jobhistory.webapp.address
Handling deprecation for mapreduce.task.userlog.limit.kb
Handling deprecation for mapreduce.reduce.shuffle.fetch.retry.enabled
Handling deprecation for yarn.app.mapreduce.task.container.log.backups
Handling deprecation for dfs.heartbeat.interval
Handling deprecation for ha.zookeeper.session-timeout.ms
Handling deprecation for fs.s3a.connection.ssl.enabled
Handling deprecation for yarn.sharedcache.webapp.address
Handling deprecation for hadoop.http.authentication.signature.secret.file
Handling deprecation for hadoop.fuse.connection.timeout
Handling deprecation for mapreduce.input.fileinputformat.numinputfiles
Handling deprecation for yarn.nodemanager.log-aggregation.compression-type
Handling deprecation for ipc.server.max.connections
Handling deprecation for yarn.resourcemanager.work-preserving-recovery.scheduling-wait-ms
Handling deprecation for yarn.nodemanager.log-dirs
Handling deprecation for yarn.app.mapreduce.am.resource.mb
Handling deprecation for hadoop.security.groups.cache.secs
Handling deprecation for mapreduce.job.speculative.minimum-allowed-tasks
Handling deprecation for yarn.nodemanager.container-monitor.interval-ms
Handling deprecation for dfs.datanode.cache.revocation.timeout.ms
Handling deprecation for mapreduce.jobhistory.recovery.store.class
Handling deprecation for mapreduce.task.combine.progress.records
Handling deprecation for s3.client-write-packet-size
Handling deprecation for mapreduce.jobtracker.instrumentation
Handling deprecation for dfs.replication
Handling deprecation for mapreduce.shuffle.transfer.buffer.size
Handling deprecation for hadoop.security.group.mapping.ldap.directory.search.timeout
Handling deprecation for dfs.datanode.available-space-volume-choosing-policy.balanced-space-threshold
Handling deprecation for hadoop.work.around.non.threadsafe.getpwuid
Handling deprecation for yarn.app.mapreduce.client-am.ipc.max-retries-on-timeouts
Handling deprecation for yarn.nodemanager.address
Handling deprecation for mapreduce.tasktracker.taskcontroller
Handling deprecation for mapreduce.tasktracker.indexcache.mb
Handling deprecation for yarn.scheduler.maximum-allocation-vcores
Handling deprecation for mapreduce.job.reduces
Handling deprecation for yarn.nodemanager.sleep-delay-before-sigkill.ms
Handling deprecation for yarn.timeline-service.address
Handling deprecation for yarn.resourcemanager.configuration.provider-class
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.expiry
Handling deprecation for yarn.sharedcache.enabled
Handling deprecation for tfile.io.chunk.size
Handling deprecation for mapreduce.job.acl-modify-job
Handling deprecation for hadoop.registry.zk.session.timeout.ms
Handling deprecation for fs.automatic.close
Handling deprecation for ha.health-monitor.sleep-after-disconnect.ms
Handling deprecation for mapreduce.tasktracker.reduce.tasks.maximum
Handling deprecation for mapreduce.input.fileinputformat.list-status.num-threads
Handling deprecation for dfs.datanode.directoryscan.threads
Handling deprecation for dfs.datanode.directoryscan.interval
Handling deprecation for dfs.namenode.acls.enabled
Handling deprecation for dfs.client.short.circuit.replica.stale.threshold.ms
Handling deprecation for hadoop.http.authentication.token.validity
Handling deprecation for fs.s3.block.size
Handling deprecation for ha.failover-controller.graceful-fence.rpc-timeout.ms
Handling deprecation for mapreduce.tasktracker.local.dir.minspacekill
Handling deprecation for dfs.namenode.resource.du.reserved
Handling deprecation for mapreduce.jobhistory.cleaner.interval-ms
Handling deprecation for dfs.namenode.datanode.registration.ip-hostname-check
Handling deprecation for mapreduce.jobhistory.intermediate-done-dir
Handling deprecation for mapreduce.jobtracker.http.address
Handling deprecation for dfs.namenode.backup.http-address
Handling deprecation for dfs.namenode.edits.noeditlogchannelflush
Handling deprecation for mapreduce.reduce.shuffle.input.buffer.percent
Handling deprecation for mapreduce.map.maxattempts
Handling deprecation for yarn.http.policy
Handling deprecation for dfs.namenode.audit.loggers
Handling deprecation for hadoop.security.groups.cache.warn.after.ms
Handling deprecation for io.serializations
Handling deprecation for mapreduce.tasktracker.outofband.heartbeat
Handling deprecation for mapreduce.reduce.shuffle.read.timeout
Handling deprecation for hadoop.security.crypto.buffer.size
Handling deprecation for mapreduce.reduce.skip.proc.count.autoincr
Handling deprecation for mapreduce.ifile.readahead.bytes
Handling deprecation for dfs.http.policy
Handling deprecation for hadoop.registry.secure
Handling deprecation for dfs.namenode.safemode.min.datanodes
Handling deprecation for dfs.client.file-block-storage-locations.num-threads
Handling deprecation for mapreduce.cluster.local.dir
Handling deprecation for mapreduce.tasktracker.report.address
Handling deprecation for dfs.namenode.secondary.https-address
Handling deprecation for hadoop.kerberos.kinit.command
Handling deprecation for yarn.timeline-service.http-authentication.type
Handling deprecation for dfs.block.access.token.lifetime
Handling deprecation for dfs.webhdfs.enabled
Handling deprecation for dfs.namenode.delegation.token.max-lifetime
Handling deprecation for dfs.namenode.avoid.write.stale.datanode
Handling deprecation for dfs.datanode.drop.cache.behind.writes
Handling deprecation for yarn.log-aggregation.retain-seconds
Handling deprecation for mapreduce.job.complete.cancel.delegation.tokens
Handling deprecation for mapreduce.local.clientfactory.class.name
Handling deprecation for mapreduce.shuffle.connection-keep-alive.timeout
Handling deprecation for dfs.namenode.num.extra.edits.retained
Handling deprecation for yarn.scheduler.minimum-allocation-vcores
Handling deprecation for ipc.client.connect.max.retries.on.timeouts
Handling deprecation for yarn.timeline-service.client.retry-interval-ms
Handling deprecation for yarn.timeline-service.client.max-retries
Handling deprecation for fs.s3n.block.size
Handling deprecation for mapreduce.job.map.output.collector.class
Handling deprecation for ha.health-monitor.connect-retry-interval.ms
Handling deprecation for mapreduce.shuffle.max.threads
Handling deprecation for nfs.exports.allowed.hosts
Handling deprecation for dfs.client.mmap.cache.size
Handling deprecation for mapreduce.tasktracker.map.tasks.maximum
Handling deprecation for io.file.buffer.size
Handling deprecation for dfs.client.datanode-restart.timeout
Handling deprecation for io.mapfile.bloom.size
Handling deprecation for hadoop.security.kms.client.authentication.retry-count
Handling deprecation for dfs.namenode.checkpoint.txns
Handling deprecation for ipc.client.connect.retry.interval
Handling deprecation for dfs.client-write-packet-size
Handling deprecation for mapreduce.reduce.shuffle.connect.timeout
Handling deprecation for yarn.resourcemanager.fs.state-store.uri
Handling deprecation for fs.swift.impl
Handling deprecation for hadoop.registry.zk.connection.timeout.ms
Handling deprecation for mapred.queue.default.acl-administer-jobs
Handling deprecation for mapreduce.job.submithostaddress
Handling deprecation for dfs.cachereport.intervalMsec
Handling deprecation for yarn.app.mapreduce.shuffle.log.backups
Handling deprecation for yarn.app.mapreduce.am.container.log.limit.kb
Handling deprecation for yarn.nodemanager.resourcemanager.minimum.version
Handling deprecation for ftp.blocksize
Handling deprecation for yarn.resourcemanager.address
Handling deprecation for file.stream-buffer-size
Handling deprecation for yarn.resourcemanager.scheduler.monitor.enable
Handling deprecation for mapreduce.job.ubertask.maxreduces
Handling deprecation for nfs.allow.insecure.ports
Handling deprecation for yarn.sharedcache.nm.uploader.thread-count
Handling deprecation for ipc.client.idlethreshold
Handling deprecation for ftp.stream-buffer-size
Handling deprecation for yarn.sharedcache.client-server.address
Handling deprecation for dfs.client.failover.connection.retries.on.timeouts
Handling deprecation for dfs.namenode.replication.work.multiplier.per.iteration
Handling deprecation for hadoop.http.authentication.simple.anonymous.allowed
Handling deprecation for hadoop.security.authorization
Handling deprecation for yarn.client.nodemanager-connect.retry-interval-ms
Handling deprecation for yarn.am.liveness-monitor.expiry-interval-ms
Handling deprecation for fs.har.impl.disable.cache
Handling deprecation for yarn.nodemanager.linux-container-executor.resources-handler.class
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.read-cache-size
Handling deprecation for hadoop.security.authentication
Handling deprecation for dfs.image.compression.codec
Handling deprecation for mapreduce.task.files.preserve.failedtasks
Handling deprecation for dfs.client.read.shortcircuit.streams.cache.size
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.path
Handling deprecation for mapreduce.job.reduce.slowstart.completedmaps
Handling deprecation for mapreduce.jobhistory.minicluster.fixed.ports
Handling deprecation for file.replication
Handling deprecation for yarn.resourcemanager.ha.automatic-failover.enabled
Handling deprecation for mapreduce.job.userlog.retain.hours
Handling deprecation for mapreduce.jobhistory.joblist.cache.size
Handling deprecation for dfs.namenode.accesstime.precision
Handling deprecation for yarn.resourcemanager.work-preserving-recovery.enabled
Handling deprecation for dfs.namenode.fs-limits.max-xattrs-per-inode
Handling deprecation for io.mapfile.bloom.error.rate
Handling deprecation for yarn.resourcemanager.store.class
Handling deprecation for dfs.image.transfer.timeout
Handling deprecation for yarn.timeline-service.leveldb-state-store.path
Handling deprecation for nfs.wtmax
Handling deprecation for mapreduce.job.combine.class
Handling deprecation for dfs.namenode.support.allow.format
Handling deprecation for fs.s3a.multipart.purge
Handling deprecation for dfs.secondary.namenode.kerberos.internal.spnego.principal
Handling deprecation for fs.s3a.connection.establish.timeout
Handling deprecation for dfs.stream-buffer-size
Handling deprecation for dfs.namenode.invalidate.work.pct.per.iteration
Handling deprecation for yarn.nodemanager.container-executor.class
Handling deprecation for fs.s3a.multipart.purge.age
Handling deprecation for yarn.resourcemanager.scheduler.client.thread-count
Handling deprecation for dfs.namenode.top.enabled
Handling deprecation for yarn.app.mapreduce.shuffle.log.separate
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.low-watermark
Handling deprecation for fs.s3a.fast.buffer.size
Handling deprecation for hadoop.user.group.static.mapping.overrides
Handling deprecation for tfile.fs.input.buffer.size
Handling deprecation for dfs.client.cached.conn.retry
Handling deprecation for hadoop.http.authentication.type
Handling deprecation for dfs.namenode.list.encryption.zones.num.responses
Handling deprecation for mapreduce.map.cpu.vcores
Handling deprecation for dfs.namenode.path.based.cache.refresh.interval.ms
Handling deprecation for dfs.namenode.decommission.interval
Handling deprecation for dfs.namenode.fs-limits.max-directory-items
Handling deprecation for yarn.resourcemanager.zk-retry-interval-ms
Handling deprecation for ftp.bytes-per-checksum
Handling deprecation for dfs.ha.log-roll.period
Handling deprecation for dfs.user.home.dir.prefix
Handling deprecation for ipc.client.fallback-to-simple-auth-allowed
Handling deprecation for yarn.nodemanager.pmem-check-enabled
Handling deprecation for yarn.nodemanager.remote-app-log-dir
Handling deprecation for dfs.namenode.inotify.max.events.per.rpc
Handling deprecation for mapreduce.task.profile.maps
Handling deprecation for mapreduce.shuffle.ssl.file.buffer.size
Handling deprecation for mapreduce.tasktracker.healthchecker.script.timeout
Handling deprecation for yarn.timeline-service.webapp.https.address
Handling deprecation for yarn.nodemanager.resource.percentage-physical-cpu-limit
Handling deprecation for yarn.app.mapreduce.am.command-opts
Handling deprecation for dfs.namenode.fs-limits.max-xattr-size
Handling deprecation for dfs.datanode.http.address
Handling deprecation for dfs.namenode.blocks.per.postponedblocks.rescan
Handling deprecation for yarn.sharedcache.nm.uploader.replication.factor
Handling deprecation for hadoop.registry.zk.root
Handling deprecation for hadoop.jetty.logs.serve.aliases
Handling deprecation for yarn.client.failover-proxy-provider
Handling deprecation for mapreduce.jobhistory.admin.acl
Handling deprecation for yarn.app.mapreduce.am.hard-kill-timeout-ms
Handling deprecation for yarn.nodemanager.remote-app-log-dir-suffix
Handling deprecation for mapreduce.jobhistory.principal
Handling deprecation for yarn.resourcemanager.webapp.address
Handling deprecation for mapreduce.jobhistory.recovery.enable
Handling deprecation for yarn.sharedcache.store.in-memory.check-period-mins
Handling deprecation for nfs.mountd.port
Handling deprecation for mapreduce.reduce.merge.inmem.threshold
Handling deprecation for fs.df.interval
Handling deprecation for yarn.timeline-service.enabled
Handling deprecation for mapreduce.jobtracker.jobhistory.lru.cache.size
Handling deprecation for mapreduce.task.profile
Handling deprecation for mapreduce.job.output.key.class
Handling deprecation for yarn.nodemanager.hostname
Handling deprecation for dfs.namenode.num.checkpoints.retained
Handling deprecation for mapreduce.job.queuename
Handling deprecation for mapreduce.jobhistory.max-age-ms
Handling deprecation for mapreduce.job.token.tracking.ids.enabled
Handling deprecation for yarn.nodemanager.localizer.client.thread-count
Handling deprecation for yarn.sharedcache.uploader.server.thread-count
Handling deprecation for dfs.client.mmap.retry.timeout.ms
Handling deprecation for mapreduce.jobhistory.move.thread-count
Handling deprecation for dfs.permissions.enabled
Handling deprecation for dfs.blockreport.split.threshold
Handling deprecation for fs.AbstractFileSystem.hdfs.impl
Handling deprecation for dfs.datanode.balance.bandwidthPerSec
Handling deprecation for dfs.block.scanner.volume.bytes.per.second
Handling deprecation for hadoop.http.filter.initializers
Handling deprecation for yarn.timeline-service.http-authentication.simple.anonymous.allowed
Handling deprecation for dfs.default.chunk.view.size
Handling deprecation for yarn.sharedcache.client-server.thread-count
Handling deprecation for yarn.resourcemanager.resource-tracker.address
Handling deprecation for mapreduce.job.working.dir
Handling deprecation for mapreduce.jobhistory.datestring.cache.size
Handling deprecation for mapreduce.task.profile.params
Handling deprecation for dfs.namenode.decommission.blocks.per.interval
Handling deprecation for dfs.namenode.handler.count
Handling deprecation for dfs.image.transfer.bandwidthPerSec
Handling deprecation for rpc.metrics.quantile.enable
Handling deprecation for mapreduce.jobtracker.expire.trackers.interval
Handling deprecation for mapreduce.task.timeout
Handling deprecation for yarn.app.mapreduce.client.max-retries
Handling deprecation for yarn.nodemanager.resource.memory-mb
Handling deprecation for yarn.nodemanager.disk-health-checker.min-healthy-disks
Handling deprecation for dfs.datanode.failed.volumes.tolerated
Handling deprecation for yarn.timeline-service.handler-thread-count
Handling deprecation for ipc.server.listen.queue.size
Handling deprecation for fs.s3a.threads.max
Handling deprecation for yarn.resourcemanager.connect.max-wait.ms
Handling deprecation for mapreduce.fileoutputcommitter.algorithm.version
Handling deprecation for mapreduce.framework.name
Handling deprecation for mapreduce.map.skip.proc.count.autoincr
Handling deprecation for mapreduce.job.max.split.locations
Handling deprecation for yarn.resourcemanager.scheduler.class
Handling deprecation for yarn.resourcemanager.system-metrics-publisher.enabled
Handling deprecation for dfs.blocksize
Handling deprecation for yarn.sharedcache.nested-level
Handling deprecation for mapreduce.shuffle.connection-keep-alive.enable
Handling deprecation for fs.s3a.threads.keepalivetime
Handling deprecation for fs.s3a.connection.timeout
Handling deprecation for file.client-write-packet-size
Handling deprecation for ha.failover-controller.cli-check.rpc-timeout.ms
Handling deprecation for ha.zookeeper.acl
Handling deprecation for dfs.namenode.write.stale.datanode.ratio
Handling deprecation for dfs.encrypt.data.transfer
Handling deprecation for dfs.datanode.shared.file.descriptor.paths
Handling deprecation for mapreduce.input.lineinputformat.linespermap
Handling deprecation for yarn.resourcemanager.delayed.delegation-token.removal-interval-ms
Handling deprecation for yarn.nodemanager.localizer.fetch.thread-count
Handling deprecation for dfs.client.failover.max.attempts
Handling deprecation for yarn.resourcemanager.scheduler.address
Handling deprecation for dfs.client.read.shortcircuit.streams.cache.expiry.ms
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.start-time-write-cache-size
Handling deprecation for yarn.nodemanager.health-checker.script.timeout-ms
Handling deprecation for yarn.resourcemanager.fs.state-store.num-retries
Handling deprecation for hadoop.ssl.require.client.cert
Handling deprecation for hadoop.security.uid.cache.secs
Handling deprecation for mapreduce.jobhistory.keytab
Handling deprecation for dfs.client.read.shortcircuit.skip.checksum
Handling deprecation for yarn.resourcemanager.ha.automatic-failover.zk-base-path
Handling deprecation for mapreduce.shuffle.ssl.enabled
Handling deprecation for mapreduce.reduce.log.level
Handling deprecation for hadoop.registry.rm.enabled
Handling deprecation for mapreduce.tasktracker.dns.interface
Handling deprecation for yarn.resourcemanager.system-metrics-publisher.dispatcher.pool-size
Handling deprecation for mapreduce.job.speculative.speculative-cap-running-tasks
Handling deprecation for dfs.datanode.block.id.layout.upgrade.threads
Handling deprecation for dfs.datanode.use.datanode.hostname
Handling deprecation for dfs.client.context
Handling deprecation for yarn.resourcemanager.ha.enabled
Handling deprecation for mapred.reducer.new-api
Handling deprecation for dfs.namenode.delegation.token.renew-interval
Handling deprecation for dfs.blockreport.intervalMsec
Handling deprecation for fs.s3a.multipart.threshold
Handling deprecation for mapreduce.reduce.shuffle.memory.limit.percent
Handling deprecation for dfs.https.server.keystore.resource
Handling deprecation for io.map.index.skip
Handling deprecation for mapreduce.job.hdfs-servers
Handling deprecation for mapreduce.jobtracker.taskscheduler
Handling deprecation for dfs.namenode.kerberos.internal.spnego.principal
Handling deprecation for yarn.resourcemanager.state-store.max-completed-applications
Handling deprecation for mapreduce.map.output.compress
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.num.refill.threads
Handling deprecation for fs.s3n.multipart.uploads.block.size
Handling deprecation for mapreduce.task.merge.progress.records
Handling deprecation for dfs.datanode.dns.interface
Handling deprecation for map.sort.class
Handling deprecation for yarn.nodemanager.aux-services.mapreduce_shuffle.class
Handling deprecation for tfile.fs.output.buffer.size
Handling deprecation for fs.du.interval
Handling deprecation for dfs.client.failover.connection.retries
Handling deprecation for dfs.namenode.top.window.num.buckets
Handling deprecation for mapreduce.job.dir
Handling deprecation for fs.s3a.buffer.dir
Handling deprecation for mapreduce.reduce.shuffle.retry-delay.max.ms
Handling deprecation for yarn.sharedcache.uploader.server.address
Handling deprecation for mapreduce.client.progressmonitor.pollinterval
Handling deprecation for yarn.app.mapreduce.shuffle.log.limit.kb
Handling deprecation for dfs.datanode.max.locked.memory
Handling deprecation for dfs.namenode.retrycache.expirytime.millis
Handling deprecation for dfs.datanode.scan.period.hours
Handling deprecation for dfs.client.block.write.replace-datanode-on-failure.best-effort
Handling deprecation for mapreduce.jobhistory.move.interval-ms
Handling deprecation for dfs.ha.fencing.ssh.connect-timeout
Handling deprecation for yarn.nodemanager.log-aggregation.roll-monitoring-interval-seconds
Handling deprecation for dfs.namenode.fs-limits.max-component-length
Handling deprecation for hadoop.registry.zk.quorum
Handling deprecation for dfs.namenode.enable.retrycache
Handling deprecation for dfs.datanode.du.reserved
Handling deprecation for yarn.timeline-service.state-store-class
Handling deprecation for dfs.datanode.ipc.address
Handling deprecation for hadoop.registry.system.acls
Handling deprecation for dfs.client.block.write.replace-datanode-on-failure.policy
Handling deprecation for dfs.namenode.path.based.cache.retry.interval.ms
Handling deprecation for hadoop.security.crypto.cipher.suite
Handling deprecation for dfs.ha.tail-edits.period
Handling deprecation for mapreduce.task.profile.reduce.params
Handling deprecation for hadoop.registry.jaas.context
Handling deprecation for yarn.resourcemanager.hostname
Handling deprecation for mapreduce.reduce.memory.mb
Handling deprecation for hadoop.security.group.mapping.ldap.search.filter.group
Handling deprecation for hadoop.http.authentication.kerberos.principal
Handling deprecation for hadoop.security.group.mapping.ldap.search.filter.user
Handling deprecation for yarn.nodemanager.disk-health-checker.min-free-space-per-disk-mb
Handling deprecation for dfs.namenode.edits.dir
Handling deprecation for yarn.client.failover-retries-on-socket-timeouts
Handling deprecation for dfs.namenode.decommission.max.concurrent.tracked.nodes
Handling deprecation for mapreduce.client.completion.pollinterval
Handling deprecation for dfs.namenode.name.dir.restore
Handling deprecation for dfs.namenode.secondary.http-address
Handling deprecation for mapreduce.jobhistory.recovery.store.leveldb.path
Handling deprecation for yarn.sharedcache.store.class
Handling deprecation for s3.bytes-per-checksum
Handling deprecation for yarn.nodemanager.windows-container.cpu-limit.enabled
Handling deprecation for yarn.resourcemanager.webapp.https.address
Handling deprecation for yarn.nodemanager.vmem-pmem-ratio
Handling deprecation for dfs.namenode.checkpoint.period
Handling deprecation for dfs.ha.automatic-failover.enabled
Submitting tokens for job: job_local425895704_0001
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.fs.FileContext.getAbstractFileSystem(FileContext.java:331)
Handling deprecation for all properties in config...
Handling deprecation for mapreduce.jobtracker.address
Handling deprecation for yarn.resourcemanager.scheduler.monitor.policies
Handling deprecation for dfs.namenode.resource.check.interval
Handling deprecation for mapreduce.jobhistory.client.thread-count
Handling deprecation for yarn.app.mapreduce.am.containerlauncher.threadpool-initial-size
Handling deprecation for mapred.child.java.opts
Handling deprecation for mapreduce.jobtracker.retiredjobs.cache.size
Handling deprecation for dfs.client.https.need-auth
Handling deprecation for yarn.admin.acl
Handling deprecation for yarn.app.mapreduce.am.job.committer.cancel-timeout
Handling deprecation for mapreduce.job.emit-timeline-data
Handling deprecation for fs.ftp.host.port
Handling deprecation for dfs.namenode.avoid.read.stale.datanode
Handling deprecation for dfs.journalnode.rpc-address
Handling deprecation for mapreduce.job.end-notification.retry.attempts
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.ttl-interval-ms
Handling deprecation for yarn.resourcemanager.leveldb-state-store.path
Handling deprecation for mapred.mapper.new-api
Handling deprecation for yarn.ipc.rpc.class
Handling deprecation for ipc.client.connection.maxidletime
Handling deprecation for yarn.nodemanager.process-kill-wait.ms
Handling deprecation for mapreduce.cluster.acls.enabled
Handling deprecation for mapreduce.jobtracker.handler.count
Handling deprecation for io.map.index.interval
Handling deprecation for dfs.namenode.https-address
Handling deprecation for mapreduce.task.profile.reduces
Handling deprecation for fs.s3n.multipart.uploads.enabled
Handling deprecation for io.seqfile.sorter.recordlimit
Handling deprecation for mapreduce.job.ubertask.maxmaps
Handling deprecation for mapreduce.tasktracker.tasks.sleeptimebeforesigkill
Handling deprecation for hadoop.util.hash.type
Handling deprecation for dfs.namenode.replication.min
Handling deprecation for yarn.nodemanager.container-manager.thread-count
Handling deprecation for mapreduce.jobtracker.jobhistory.block.size
Handling deprecation for dfs.namenode.fs-limits.min-block-size
Handling deprecation for mapreduce.app-submission.cross-platform
Handling deprecation for fs.AbstractFileSystem.file.impl
Handling deprecation for net.topology.script.number.args
Handling deprecation for yarn.resourcemanager.container-tokens.master-key-rolling-interval-secs
Handling deprecation for mapreduce.map.output.compress.codec
Handling deprecation for mapreduce.job.reducer.preempt.delay.sec
Handling deprecation for s3native.bytes-per-checksum
Handling deprecation for dfs.namenode.path.based.cache.block.map.allocation.percent
Handling deprecation for yarn.nodemanager.windows-container.memory-limit.enabled
Handling deprecation for mapreduce.input.fileinputformat.split.minsize
Handling deprecation for hadoop.security.group.mapping
Handling deprecation for mapreduce.jobtracker.system.dir
Handling deprecation for mapreduce.job.end-notification.max.attempts
Handling deprecation for mapreduce.reduce.markreset.buffer.percent
Handling deprecation for dfs.datanode.cache.revocation.polling.ms
Handling deprecation for mapreduce.reduce.speculative
Handling deprecation for yarn.nodemanager.localizer.cache.cleanup.interval-ms
Handling deprecation for dfs.namenode.lazypersist.file.scrub.interval.sec
Handling deprecation for fs.s3a.threads.core
Handling deprecation for mapreduce.jobhistory.recovery.store.fs.uri
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.start-time-read-cache-size
Handling deprecation for hadoop.registry.zk.retry.interval.ms
Handling deprecation for yarn.nodemanager.keytab
Handling deprecation for dfs.namenode.replication.interval
Handling deprecation for yarn.resourcemanager.admin.address
Handling deprecation for mapreduce.job.maps
Handling deprecation for nfs.dump.dir
Handling deprecation for mapreduce.job.user.name
Handling deprecation for mapreduce.jobtracker.maxtasks.perjob
Handling deprecation for mapreduce.job.ubertask.enable
Handling deprecation for mapreduce.job.reduce.class
Handling deprecation for yarn.nodemanager.delete.debug-delay-sec
Handling deprecation for yarn.timeline-service.ttl-enable
Handling deprecation for yarn.resourcemanager.fs.state-store.retry-policy-spec
Handling deprecation for mapreduce.reduce.skip.maxgroups
Handling deprecation for dfs.client.use.datanode.hostname
Handling deprecation for fs.trash.interval
Handling deprecation for mapreduce.job.name
Handling deprecation for mapreduce.am.max-attempts
Handling deprecation for mapreduce.jobtracker.heartbeats.in.second
Handling deprecation for yarn.resourcemanager.zk-num-retries
Handling deprecation for s3.blocksize
Handling deprecation for dfs.datanode.data.dir
Handling deprecation for mapreduce.jobtracker.persist.jobstatus.active
Handling deprecation for mapreduce.reduce.shuffle.parallelcopies
Handling deprecation for fs.s3.buffer.dir
Handling deprecation for mapreduce.jobhistory.done-dir
Handling deprecation for hadoop.security.instrumentation.requires.admin
Handling deprecation for hadoop.registry.zk.retry.ceiling.ms
Handling deprecation for nfs.rtmax
Handling deprecation for dfs.datanode.data.dir.perm
Handling deprecation for yarn.resourcemanager.container.liveness-monitor.interval-ms
Handling deprecation for yarn.nodemanager.env-whitelist
Handling deprecation for dfs.namenode.backup.address
Handling deprecation for dfs.namenode.xattrs.enabled
Handling deprecation for dfs.datanode.readahead.bytes
Handling deprecation for mapreduce.jobhistory.cleaner.enable
Handling deprecation for dfs.client.block.write.retries
Handling deprecation for mapreduce.tasktracker.http.address
Handling deprecation for yarn.nodemanager.linux-container-executor.cgroups.hierarchy
Handling deprecation for ha.failover-controller.graceful-fence.connection.retries
Handling deprecation for yarn.resourcemanager.recovery.enabled
Handling deprecation for yarn.app.mapreduce.am.container.log.backups
Handling deprecation for dfs.namenode.safemode.threshold-pct
Handling deprecation for yarn.nodemanager.disk-health-checker.interval-ms
Handling deprecation for hadoop.security.java.secure.random.algorithm
Handling deprecation for dfs.namenode.list.cache.directives.num.responses
Handling deprecation for dfs.datanode.dns.nameserver
Handling deprecation for mapreduce.cluster.temp.dir
Handling deprecation for fs.s3a.max.total.tasks
Handling deprecation for mapreduce.reduce.maxattempts
Handling deprecation for mapreduce.client.submit.file.replication
Handling deprecation for mapreduce.shuffle.port
Handling deprecation for yarn.resourcemanager.resource-tracker.client.thread-count
Handling deprecation for dfs.namenode.replication.considerLoad
Handling deprecation for dfs.namenode.edits.journal-plugin.qjournal
Handling deprecation for dfs.client.write.exclude.nodes.cache.expiry.interval.millis
Handling deprecation for yarn.nodemanager.delete.thread-count
Handling deprecation for dfs.client.mmap.cache.timeout.ms
Handling deprecation for yarn.nodemanager.admin-env
Handling deprecation for io.skip.checksum.errors
Handling deprecation for yarn.timeline-service.hostname
Handling deprecation for yarn.resourcemanager.proxy-user-privileges.enabled
Handling deprecation for mapreduce.job.speculative.speculative-cap-total-tasks
Handling deprecation for yarn.acl.enable
Handling deprecation for fs.s3a.fast.upload
Handling deprecation for file.blocksize
Handling deprecation for mapreduce.job.speculative.slowtaskthreshold
Handling deprecation for ftp.replication
Handling deprecation for yarn.sharedcache.cleaner.initial-delay-mins
Handling deprecation for s3native.client-write-packet-size
Handling deprecation for hadoop.rpc.socket.factory.class.default
Handling deprecation for file.bytes-per-checksum
Handling deprecation for dfs.datanode.slow.io.warning.threshold.ms
Handling deprecation for io.seqfile.lazydecompress
Handling deprecation for mapreduce.task.skip.start.attempts
Handling deprecation for dfs.namenode.reject-unresolved-dn-topology-mapping
Handling deprecation for hadoop.common.configuration.version
Handling deprecation for yarn.resourcemanager.client.thread-count
Handling deprecation for dfs.datanode.drop.cache.behind.reads
Handling deprecation for yarn.sharedcache.admin.address
Handling deprecation for mapreduce.job.output.value.class
Handling deprecation for mapreduce.output.fileoutputformat.outputdir
Handling deprecation for mapreduce.jobtracker.taskcache.levels
Handling deprecation for yarn.nodemanager.linux-container-executor.nonsecure-mode.user-pattern
Handling deprecation for yarn.resourcemanager.zk-timeout-ms
Handling deprecation for yarn.resourcemanager.max-completed-applications
Handling deprecation for mapreduce.job.jvm.numtasks
Handling deprecation for yarn.sharedcache.cleaner.period-mins
Handling deprecation for mapreduce.jobtracker.tasktracker.maxblacklists
Handling deprecation for dfs.namenode.top.num.users
Handling deprecation for yarn.nodemanager.linux-container-executor.cgroups.mount
Handling deprecation for yarn.sharedcache.checksum.algo.impl
Handling deprecation for mapreduce.job.end-notification.max.retry.interval
Handling deprecation for mapreduce.job.acl-view-job
Handling deprecation for mapreduce.job.classloader
Handling deprecation for yarn.log-aggregation-enable
Handling deprecation for mapreduce.reduce.shuffle.fetch.retry.interval-ms
Handling deprecation for yarn.resourcemanager.nodemanager.minimum.version
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.size
Handling deprecation for yarn.app.mapreduce.am.job.task.listener.thread-count
Handling deprecation for yarn.app.mapreduce.am.resource.cpu-vcores
Handling deprecation for dfs.namenode.edit.log.autoroll.check.interval.ms
Handling deprecation for mapreduce.output.fileoutputformat.compress.type
Handling deprecation for hadoop.hdfs.configuration.version
Handling deprecation for hadoop.security.group.mapping.ldap.search.attr.member
Handling deprecation for yarn.nodemanager.log.retain-seconds
Handling deprecation for yarn.nodemanager.local-cache.max-files-per-directory
Handling deprecation for mapreduce.job.end-notification.retry.interval
Handling deprecation for hadoop.ssl.client.conf
Handling deprecation for yarn.sharedcache.root-dir
Handling deprecation for dfs.journalnode.https-address
Handling deprecation for mapreduce.reduce.shuffle.fetch.retry.timeout-ms
Handling deprecation for dfs.bytes-per-checksum
Handling deprecation for dfs.namenode.max.objects
Handling deprecation for mapreduce.tasktracker.instrumentation
Handling deprecation for dfs.datanode.max.transfer.threads
Handling deprecation for dfs.block.access.key.update.interval
Handling deprecation for mapreduce.jobtracker.jobhistory.task.numberprogresssplits
Handling deprecation for mapreduce.map.memory.mb
Handling deprecation for ha.failover-controller.new-active.rpc-timeout.ms
Handling deprecation for hadoop.ssl.hostname.verifier
Handling deprecation for dfs.client.read.shortcircuit
Handling deprecation for dfs.datanode.hdfs-blocks-metadata.enabled
Handling deprecation for mapreduce.tasktracker.healthchecker.interval
Handling deprecation for dfs.image.transfer.chunksize
Handling deprecation for mapreduce.tasktracker.taskmemorymanager.monitoringinterval
Handling deprecation for dfs.client.https.keystore.resource
Handling deprecation for yarn.resourcemanager.connect.retry-interval.ms
Handling deprecation for yarn.timeline-service.webapp.address
Handling deprecation for s3native.blocksize
Handling deprecation for yarn.scheduler.minimum-allocation-mb
Handling deprecation for yarn.sharedcache.cleaner.resource-sleep-ms
Handling deprecation for net.topology.impl
Handling deprecation for dfs.client.failover.sleep.base.millis
Handling deprecation for dfs.permissions.superusergroup
Handling deprecation for io.seqfile.compress.blocksize
Handling deprecation for hadoop.registry.zk.retry.times
Handling deprecation for fs.AbstractFileSystem.ftp.impl
Handling deprecation for dfs.namenode.checkpoint.edits.dir
Handling deprecation for mapreduce.job.running.reduce.limit
Handling deprecation for dfs.blockreport.initialDelay
Handling deprecation for dfs.namenode.heartbeat.recheck-interval
Handling deprecation for dfs.namenode.safemode.extension
Handling deprecation for yarn.scheduler.maximum-allocation-mb
Handling deprecation for mapreduce.job.reduce.shuffle.consumer.plugin.class
Handling deprecation for yarn.nodemanager.vmem-check-enabled
Handling deprecation for mapreduce.task.io.sort.factor
Handling deprecation for mapreduce.jobtracker.persist.jobstatus.dir
Handling deprecation for dfs.client.failover.sleep.max.millis
Handling deprecation for dfs.namenode.delegation.key.update-interval
Handling deprecation for hadoop.rpc.protection
Handling deprecation for fs.permissions.umask-mode
Handling deprecation for fs.s3.sleepTimeSeconds
Handling deprecation for ha.health-monitor.rpc-timeout.ms
Handling deprecation for hadoop.http.staticuser.user
Handling deprecation for fs.s3a.connection.maximum
Handling deprecation for yarn.nodemanager.linux-container-executor.nonsecure-mode.limit-users
Handling deprecation for fs.s3a.paging.maximum
Handling deprecation for fs.AbstractFileSystem.viewfs.impl
Handling deprecation for fs.ftp.host
Handling deprecation for yarn.nodemanager.linux-container-executor.nonsecure-mode.local-user
Handling deprecation for fs.s3a.impl
Handling deprecation for hadoop.http.authentication.kerberos.keytab
Handling deprecation for dfs.namenode.fs-limits.max-blocks-per-file
Handling deprecation for mapreduce.tasktracker.http.threads
Handling deprecation for mapreduce.tasktracker.dns.nameserver
Handling deprecation for yarn.resourcemanager.am-rm-tokens.master-key-rolling-interval-secs
Handling deprecation for dfs.client.block.write.replace-datanode-on-failure.enable
Handling deprecation for io.compression.codec.bzip2.library
Handling deprecation for mapreduce.map.skip.maxrecords
Handling deprecation for dfs.client.use.legacy.blockreader.local
Handling deprecation for dfs.namenode.checkpoint.dir
Handling deprecation for dfs.namenode.top.windows.minutes
Handling deprecation for mapreduce.job.maxtaskfailures.per.tracker
Handling deprecation for net.topology.node.switch.mapping.impl
Handling deprecation for mapreduce.shuffle.max.connections
Handling deprecation for mapreduce.jobhistory.loadedjobs.cache.size
Handling deprecation for dfs.storage.policy.enabled
Handling deprecation for yarn.client.application-client-protocol.poll-interval-ms
Handling deprecation for yarn.nodemanager.localizer.address
Handling deprecation for dfs.namenode.list.cache.pools.num.responses
Handling deprecation for nfs.server.port
Handling deprecation for mapreduce.client.output.filter
Handling deprecation for yarn.timeline-service.client.best-effort
Handling deprecation for ha.zookeeper.parent-znode
Handling deprecation for mapreduce.jobtracker.persist.jobstatus.hours
Handling deprecation for yarn.sharedcache.admin.thread-count
Handling deprecation for yarn.nodemanager.resource.cpu-vcores
Handling deprecation for dfs.datanode.block-pinning.enabled
Handling deprecation for mapreduce.jobhistory.http.policy
Handling deprecation for yarn.resourcemanager.webapp.delegation-token-auth-filter.enabled
Handling deprecation for mapreduce.job.speculative.retry-after-no-speculate
Handling deprecation for fs.s3a.attempts.maximum
Handling deprecation for s3native.stream-buffer-size
Handling deprecation for io.seqfile.local.dir
Handling deprecation for yarn.log-aggregation.retain-check-interval-seconds
Handling deprecation for fs.s3n.multipart.copy.block.size
Handling deprecation for dfs.encrypt.data.transfer.cipher.key.bitlength
Handling deprecation for dfs.datanode.sync.behind.writes
Handling deprecation for yarn.resourcemanager.zk-acl
Handling deprecation for hadoop.ssl.keystores.factory.class
Handling deprecation for mapreduce.job.split.metainfo.maxsize
Handling deprecation for fs.s3.maxRetries
Handling deprecation for hadoop.security.random.device.file.path
Handling deprecation for yarn.client.nodemanager-connect.max-wait-ms
Handling deprecation for dfs.namenode.stale.datanode.interval
Handling deprecation for mapreduce.task.io.sort.mb
Handling deprecation for yarn.resourcemanager.zk-state-store.parent-path
Handling deprecation for yarn.app.mapreduce.client-am.ipc.max-retries
Handling deprecation for fs.client.resolve.remote.symlinks
Handling deprecation for yarn.nodemanager.linux-container-executor.cgroups.strict-resource-usage
Handling deprecation for hadoop.ssl.enabled.protocols
Handling deprecation for mapreduce.reduce.cpu.vcores
Handling deprecation for yarn.client.failover-retries
Handling deprecation for mapreduce.jobhistory.address
Handling deprecation for hadoop.ssl.enabled
Handling deprecation for dfs.replication.max
Handling deprecation for dfs.namenode.name.dir
Handling deprecation for dfs.datanode.https.address
Handling deprecation for ipc.client.kill.max
Handling deprecation for mapreduce.job.committer.setup.cleanup.needed
Handling deprecation for dfs.client.domain.socket.data.traffic
Handling deprecation for yarn.nodemanager.localizer.cache.target-size-mb
Handling deprecation for yarn.resourcemanager.admin.client.thread-count
Handling deprecation for dfs.block.access.token.enable
Handling deprecation for mapreduce.job.speculative.retry-after-speculate
Handling deprecation for dfs.datanode.address
Handling deprecation for mapreduce.jobtracker.restart.recover
Handling deprecation for ipc.client.connect.max.retries
Handling deprecation for yarn.timeline-service.store-class
Handling deprecation for dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
Handling deprecation for hadoop.tmp.dir
Handling deprecation for dfs.datanode.handler.count
Handling deprecation for yarn.resourcemanager.ha.automatic-failover.embedded
Handling deprecation for yarn.timeline-service.ttl-ms
Handling deprecation for mapreduce.task.profile.map.params
Handling deprecation for yarn.resourcemanager.nodemanagers.heartbeat-interval-ms
Handling deprecation for mapreduce.map.speculative
Handling deprecation for yarn.timeline-service.recovery.enabled
Handling deprecation for mapreduce.job.map.class
Handling deprecation for dfs.namenode.resource.checked.volumes.minimum
Handling deprecation for yarn.nodemanager.recovery.dir
Handling deprecation for mapreduce.job.counters.max
Handling deprecation for yarn.resourcemanager.keytab
Handling deprecation for dfs.namenode.max.extra.edits.segments.retained
Handling deprecation for dfs.webhdfs.user.provider.user.pattern
Handling deprecation for dfs.client.mmap.enabled
Handling deprecation for mapreduce.map.log.level
Handling deprecation for dfs.client.file-block-storage-locations.timeout.millis
Handling deprecation for yarn.client.max-cached-nodemanagers-proxies
Handling deprecation for yarn.app.mapreduce.am.scheduler.heartbeat.interval-ms
Handling deprecation for hadoop.fuse.timer.period
Handling deprecation for fs.trash.checkpoint.interval
Handling deprecation for yarn.sharedcache.app-checker.class
Handling deprecation for dfs.journalnode.http-address
Handling deprecation for yarn.app.mapreduce.am.staging-dir
Handling deprecation for mapreduce.tasktracker.local.dir.minspacestart
Handling deprecation for yarn.nm.liveness-monitor.expiry-interval-ms
Handling deprecation for ha.health-monitor.check-interval.ms
Handling deprecation for mapreduce.reduce.shuffle.merge.percent
Handling deprecation for dfs.namenode.retrycache.heap.percent
Handling deprecation for yarn.nodemanager.docker-container-executor.exec-name
Handling deprecation for ipc.client.connect.timeout
Handling deprecation for yarn.resourcemanager.fs.state-store.retry-interval-ms
Handling deprecation for mapreduce.output.fileoutputformat.compress
Handling deprecation for yarn.nodemanager.local-dirs
Handling deprecation for yarn.nodemanager.recovery.enabled
Handling deprecation for io.native.lib.available
Handling deprecation for yarn.sharedcache.store.in-memory.staleness-period-mins
Handling deprecation for yarn.resourcemanager.am.max-attempts
Handling deprecation for s3.replication
Handling deprecation for mapreduce.input.fileinputformat.inputdir
Handling deprecation for fs.AbstractFileSystem.har.impl
Handling deprecation for dfs.image.compress
Handling deprecation for mapreduce.job.running.map.limit
Handling deprecation for mapreduce.reduce.input.buffer.percent
Handling deprecation for yarn.nodemanager.webapp.address
Handling deprecation for dfs.datanode.available-space-volume-choosing-policy.balanced-space-preference-fraction
Handling deprecation for dfs.namenode.edit.log.autoroll.multiplier.threshold
Handling deprecation for hadoop.security.group.mapping.ldap.ssl
Handling deprecation for dfs.namenode.checkpoint.check.period
Handling deprecation for fs.defaultFS
Handling deprecation for fs.s3a.multipart.size
Handling deprecation for dfs.client.slow.io.warning.threshold.ms
Handling deprecation for yarn.app.mapreduce.am.job.committer.commit-window
Handling deprecation for hadoop.security.group.mapping.ldap.search.attr.group.name
Handling deprecation for yarn.nodemanager.disk-health-checker.max-disk-utilization-per-disk-percentage
Handling deprecation for yarn.nodemanager.container-monitor.procfs-tree.smaps-based-rss.enabled
Handling deprecation for mapreduce.job.submithostname
Handling deprecation for mapreduce.map.sort.spill.percent
Handling deprecation for hadoop.security.crypto.codec.classes.aes.ctr.nopadding
Handling deprecation for dfs.namenode.http-address
Handling deprecation for hadoop.security.groups.negative-cache.secs
Handling deprecation for hadoop.ssl.server.conf
Handling deprecation for mapreduce.ifile.readahead
Handling deprecation for s3native.replication
Handling deprecation for yarn.client.nodemanager-client-async.thread-pool-max-size
Handling deprecation for mapreduce.jobtracker.staging.root.dir
Handling deprecation for mapreduce.jobhistory.admin.address
Handling deprecation for dfs.namenode.startup.delay.block.deletion.sec
Handling deprecation for yarn.nodemanager.health-checker.interval-ms
Handling deprecation for dfs.namenode.checkpoint.max-retries
Handling deprecation for s3.stream-buffer-size
Handling deprecation for ftp.client-write-packet-size
Handling deprecation for dfs.datanode.fsdatasetcache.max.threads.per.volume
Handling deprecation for mapreduce.output.fileoutputformat.compress.codec
Handling deprecation for yarn.timeline-service.keytab
Handling deprecation for yarn.sharedcache.store.in-memory.initial-delay-mins
Handling deprecation for mapreduce.jobhistory.webapp.address
Handling deprecation for mapreduce.task.userlog.limit.kb
Handling deprecation for mapreduce.reduce.shuffle.fetch.retry.enabled
Handling deprecation for yarn.app.mapreduce.task.container.log.backups
Handling deprecation for dfs.heartbeat.interval
Handling deprecation for ha.zookeeper.session-timeout.ms
Handling deprecation for fs.s3a.connection.ssl.enabled
Handling deprecation for yarn.sharedcache.webapp.address
Handling deprecation for hadoop.http.authentication.signature.secret.file
Handling deprecation for hadoop.fuse.connection.timeout
Handling deprecation for mapreduce.input.fileinputformat.numinputfiles
Handling deprecation for yarn.nodemanager.log-aggregation.compression-type
Handling deprecation for ipc.server.max.connections
Handling deprecation for yarn.resourcemanager.work-preserving-recovery.scheduling-wait-ms
Handling deprecation for yarn.nodemanager.log-dirs
Handling deprecation for yarn.app.mapreduce.am.resource.mb
Handling deprecation for hadoop.security.groups.cache.secs
Handling deprecation for mapreduce.job.speculative.minimum-allowed-tasks
Handling deprecation for yarn.nodemanager.container-monitor.interval-ms
Handling deprecation for dfs.datanode.cache.revocation.timeout.ms
Handling deprecation for mapreduce.jobhistory.recovery.store.class
Handling deprecation for mapreduce.task.combine.progress.records
Handling deprecation for s3.client-write-packet-size
Handling deprecation for mapreduce.jobtracker.instrumentation
Handling deprecation for dfs.replication
Handling deprecation for mapreduce.shuffle.transfer.buffer.size
Handling deprecation for hadoop.security.group.mapping.ldap.directory.search.timeout
Handling deprecation for dfs.datanode.available-space-volume-choosing-policy.balanced-space-threshold
Handling deprecation for hadoop.work.around.non.threadsafe.getpwuid
Handling deprecation for yarn.app.mapreduce.client-am.ipc.max-retries-on-timeouts
Handling deprecation for yarn.nodemanager.address
Handling deprecation for mapreduce.tasktracker.taskcontroller
Handling deprecation for mapreduce.tasktracker.indexcache.mb
Handling deprecation for yarn.scheduler.maximum-allocation-vcores
Handling deprecation for mapreduce.job.reduces
Handling deprecation for yarn.nodemanager.sleep-delay-before-sigkill.ms
Handling deprecation for yarn.timeline-service.address
Handling deprecation for yarn.resourcemanager.configuration.provider-class
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.expiry
Handling deprecation for yarn.sharedcache.enabled
Handling deprecation for tfile.io.chunk.size
Handling deprecation for mapreduce.job.acl-modify-job
Handling deprecation for hadoop.registry.zk.session.timeout.ms
Handling deprecation for fs.automatic.close
Handling deprecation for ha.health-monitor.sleep-after-disconnect.ms
Handling deprecation for mapreduce.tasktracker.reduce.tasks.maximum
Handling deprecation for mapreduce.input.fileinputformat.list-status.num-threads
Handling deprecation for dfs.datanode.directoryscan.threads
Handling deprecation for dfs.datanode.directoryscan.interval
Handling deprecation for dfs.namenode.acls.enabled
Handling deprecation for dfs.client.short.circuit.replica.stale.threshold.ms
Handling deprecation for hadoop.http.authentication.token.validity
Handling deprecation for fs.s3.block.size
Handling deprecation for ha.failover-controller.graceful-fence.rpc-timeout.ms
Handling deprecation for mapreduce.tasktracker.local.dir.minspacekill
Handling deprecation for dfs.namenode.resource.du.reserved
Handling deprecation for mapreduce.jobhistory.cleaner.interval-ms
Handling deprecation for dfs.namenode.datanode.registration.ip-hostname-check
Handling deprecation for mapreduce.jobhistory.intermediate-done-dir
Handling deprecation for mapreduce.jobtracker.http.address
Handling deprecation for dfs.namenode.backup.http-address
Handling deprecation for dfs.namenode.edits.noeditlogchannelflush
Handling deprecation for mapreduce.reduce.shuffle.input.buffer.percent
Handling deprecation for mapreduce.map.maxattempts
Handling deprecation for yarn.http.policy
Handling deprecation for dfs.namenode.audit.loggers
Handling deprecation for hadoop.security.groups.cache.warn.after.ms
Handling deprecation for io.serializations
Handling deprecation for mapreduce.tasktracker.outofband.heartbeat
Handling deprecation for mapreduce.reduce.shuffle.read.timeout
Handling deprecation for hadoop.security.crypto.buffer.size
Handling deprecation for mapreduce.reduce.skip.proc.count.autoincr
Handling deprecation for mapreduce.ifile.readahead.bytes
Handling deprecation for dfs.http.policy
Handling deprecation for hadoop.registry.secure
Handling deprecation for dfs.namenode.safemode.min.datanodes
Handling deprecation for dfs.client.file-block-storage-locations.num-threads
Handling deprecation for mapreduce.cluster.local.dir
Handling deprecation for mapreduce.tasktracker.report.address
Handling deprecation for dfs.namenode.secondary.https-address
Handling deprecation for hadoop.kerberos.kinit.command
Handling deprecation for yarn.timeline-service.http-authentication.type
Handling deprecation for dfs.block.access.token.lifetime
Handling deprecation for dfs.webhdfs.enabled
Handling deprecation for dfs.namenode.delegation.token.max-lifetime
Handling deprecation for dfs.namenode.avoid.write.stale.datanode
Handling deprecation for dfs.datanode.drop.cache.behind.writes
Handling deprecation for yarn.log-aggregation.retain-seconds
Handling deprecation for mapreduce.job.complete.cancel.delegation.tokens
Handling deprecation for mapreduce.local.clientfactory.class.name
Handling deprecation for mapreduce.shuffle.connection-keep-alive.timeout
Handling deprecation for dfs.namenode.num.extra.edits.retained
Handling deprecation for yarn.scheduler.minimum-allocation-vcores
Handling deprecation for ipc.client.connect.max.retries.on.timeouts
Handling deprecation for yarn.timeline-service.client.retry-interval-ms
Handling deprecation for yarn.timeline-service.client.max-retries
Handling deprecation for fs.s3n.block.size
Handling deprecation for mapreduce.job.map.output.collector.class
Handling deprecation for ha.health-monitor.connect-retry-interval.ms
Handling deprecation for mapreduce.shuffle.max.threads
Handling deprecation for nfs.exports.allowed.hosts
Handling deprecation for dfs.client.mmap.cache.size
Handling deprecation for mapreduce.tasktracker.map.tasks.maximum
Handling deprecation for io.file.buffer.size
Handling deprecation for dfs.client.datanode-restart.timeout
Handling deprecation for io.mapfile.bloom.size
Handling deprecation for hadoop.security.kms.client.authentication.retry-count
Handling deprecation for dfs.namenode.checkpoint.txns
Handling deprecation for ipc.client.connect.retry.interval
Handling deprecation for dfs.client-write-packet-size
Handling deprecation for mapreduce.reduce.shuffle.connect.timeout
Handling deprecation for yarn.resourcemanager.fs.state-store.uri
Handling deprecation for fs.swift.impl
Handling deprecation for hadoop.registry.zk.connection.timeout.ms
Handling deprecation for mapred.queue.default.acl-administer-jobs
Handling deprecation for mapreduce.job.submithostaddress
Handling deprecation for dfs.cachereport.intervalMsec
Handling deprecation for yarn.app.mapreduce.shuffle.log.backups
Handling deprecation for yarn.app.mapreduce.am.container.log.limit.kb
Handling deprecation for yarn.nodemanager.resourcemanager.minimum.version
Handling deprecation for ftp.blocksize
Handling deprecation for yarn.resourcemanager.address
Handling deprecation for file.stream-buffer-size
Handling deprecation for yarn.resourcemanager.scheduler.monitor.enable
Handling deprecation for mapreduce.job.ubertask.maxreduces
Handling deprecation for nfs.allow.insecure.ports
Handling deprecation for yarn.sharedcache.nm.uploader.thread-count
Handling deprecation for ipc.client.idlethreshold
Handling deprecation for ftp.stream-buffer-size
Handling deprecation for yarn.sharedcache.client-server.address
Handling deprecation for dfs.client.failover.connection.retries.on.timeouts
Handling deprecation for dfs.namenode.replication.work.multiplier.per.iteration
Handling deprecation for hadoop.http.authentication.simple.anonymous.allowed
Handling deprecation for hadoop.security.authorization
Handling deprecation for yarn.client.nodemanager-connect.retry-interval-ms
Handling deprecation for yarn.am.liveness-monitor.expiry-interval-ms
Handling deprecation for fs.har.impl.disable.cache
Handling deprecation for yarn.nodemanager.linux-container-executor.resources-handler.class
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.read-cache-size
Handling deprecation for hadoop.security.authentication
Handling deprecation for dfs.image.compression.codec
Handling deprecation for mapreduce.task.files.preserve.failedtasks
Handling deprecation for dfs.client.read.shortcircuit.streams.cache.size
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.path
Handling deprecation for mapreduce.job.reduce.slowstart.completedmaps
Handling deprecation for mapreduce.jobhistory.minicluster.fixed.ports
Handling deprecation for file.replication
Handling deprecation for yarn.resourcemanager.ha.automatic-failover.enabled
Handling deprecation for mapreduce.job.userlog.retain.hours
Handling deprecation for mapreduce.jobhistory.joblist.cache.size
Handling deprecation for dfs.namenode.accesstime.precision
Handling deprecation for yarn.resourcemanager.work-preserving-recovery.enabled
Handling deprecation for dfs.namenode.fs-limits.max-xattrs-per-inode
Handling deprecation for io.mapfile.bloom.error.rate
Handling deprecation for yarn.resourcemanager.store.class
Handling deprecation for dfs.image.transfer.timeout
Handling deprecation for yarn.timeline-service.leveldb-state-store.path
Handling deprecation for nfs.wtmax
Handling deprecation for mapreduce.job.combine.class
Handling deprecation for dfs.namenode.support.allow.format
Handling deprecation for fs.s3a.multipart.purge
Handling deprecation for dfs.secondary.namenode.kerberos.internal.spnego.principal
Handling deprecation for fs.s3a.connection.establish.timeout
Handling deprecation for dfs.stream-buffer-size
Handling deprecation for dfs.namenode.invalidate.work.pct.per.iteration
Handling deprecation for yarn.nodemanager.container-executor.class
Handling deprecation for fs.s3a.multipart.purge.age
Handling deprecation for yarn.resourcemanager.scheduler.client.thread-count
Handling deprecation for dfs.namenode.top.enabled
Handling deprecation for yarn.app.mapreduce.shuffle.log.separate
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.low-watermark
Handling deprecation for fs.s3a.fast.buffer.size
Handling deprecation for hadoop.user.group.static.mapping.overrides
Handling deprecation for tfile.fs.input.buffer.size
Handling deprecation for dfs.client.cached.conn.retry
Handling deprecation for hadoop.http.authentication.type
Handling deprecation for dfs.namenode.list.encryption.zones.num.responses
Handling deprecation for mapreduce.map.cpu.vcores
Handling deprecation for dfs.namenode.path.based.cache.refresh.interval.ms
Handling deprecation for dfs.namenode.decommission.interval
Handling deprecation for dfs.namenode.fs-limits.max-directory-items
Handling deprecation for yarn.resourcemanager.zk-retry-interval-ms
Handling deprecation for ftp.bytes-per-checksum
Handling deprecation for dfs.ha.log-roll.period
Handling deprecation for dfs.user.home.dir.prefix
Handling deprecation for ipc.client.fallback-to-simple-auth-allowed
Handling deprecation for yarn.nodemanager.pmem-check-enabled
Handling deprecation for yarn.nodemanager.remote-app-log-dir
Handling deprecation for dfs.namenode.inotify.max.events.per.rpc
Handling deprecation for mapreduce.task.profile.maps
Handling deprecation for mapreduce.shuffle.ssl.file.buffer.size
Handling deprecation for mapreduce.tasktracker.healthchecker.script.timeout
Handling deprecation for yarn.timeline-service.webapp.https.address
Handling deprecation for yarn.nodemanager.resource.percentage-physical-cpu-limit
Handling deprecation for yarn.app.mapreduce.am.command-opts
Handling deprecation for dfs.namenode.fs-limits.max-xattr-size
Handling deprecation for dfs.datanode.http.address
Handling deprecation for dfs.namenode.blocks.per.postponedblocks.rescan
Handling deprecation for yarn.sharedcache.nm.uploader.replication.factor
Handling deprecation for hadoop.registry.zk.root
Handling deprecation for hadoop.jetty.logs.serve.aliases
Handling deprecation for yarn.client.failover-proxy-provider
Handling deprecation for mapreduce.jobhistory.admin.acl
Handling deprecation for yarn.app.mapreduce.am.hard-kill-timeout-ms
Handling deprecation for yarn.nodemanager.remote-app-log-dir-suffix
Handling deprecation for mapreduce.jobhistory.principal
Handling deprecation for yarn.resourcemanager.webapp.address
Handling deprecation for mapreduce.jobhistory.recovery.enable
Handling deprecation for yarn.sharedcache.store.in-memory.check-period-mins
Handling deprecation for nfs.mountd.port
Handling deprecation for mapreduce.reduce.merge.inmem.threshold
Handling deprecation for fs.df.interval
Handling deprecation for yarn.timeline-service.enabled
Handling deprecation for mapreduce.jobtracker.jobhistory.lru.cache.size
Handling deprecation for mapreduce.task.profile
Handling deprecation for mapreduce.job.output.key.class
Handling deprecation for yarn.nodemanager.hostname
Handling deprecation for dfs.namenode.num.checkpoints.retained
Handling deprecation for mapreduce.job.queuename
Handling deprecation for mapreduce.jobhistory.max-age-ms
Handling deprecation for mapreduce.job.token.tracking.ids.enabled
Handling deprecation for yarn.nodemanager.localizer.client.thread-count
Handling deprecation for yarn.sharedcache.uploader.server.thread-count
Handling deprecation for dfs.client.mmap.retry.timeout.ms
Handling deprecation for mapreduce.jobhistory.move.thread-count
Handling deprecation for dfs.permissions.enabled
Handling deprecation for dfs.blockreport.split.threshold
Handling deprecation for fs.AbstractFileSystem.hdfs.impl
Handling deprecation for dfs.datanode.balance.bandwidthPerSec
Handling deprecation for dfs.block.scanner.volume.bytes.per.second
Handling deprecation for hadoop.http.filter.initializers
Handling deprecation for yarn.timeline-service.http-authentication.simple.anonymous.allowed
Handling deprecation for dfs.default.chunk.view.size
Handling deprecation for yarn.sharedcache.client-server.thread-count
Handling deprecation for yarn.resourcemanager.resource-tracker.address
Handling deprecation for mapreduce.job.working.dir
Handling deprecation for mapreduce.jobhistory.datestring.cache.size
Handling deprecation for mapreduce.task.profile.params
Handling deprecation for dfs.namenode.decommission.blocks.per.interval
Handling deprecation for dfs.namenode.handler.count
Handling deprecation for dfs.image.transfer.bandwidthPerSec
Handling deprecation for rpc.metrics.quantile.enable
Handling deprecation for mapreduce.jobtracker.expire.trackers.interval
Handling deprecation for mapreduce.task.timeout
Handling deprecation for yarn.app.mapreduce.client.max-retries
Handling deprecation for yarn.nodemanager.resource.memory-mb
Handling deprecation for yarn.nodemanager.disk-health-checker.min-healthy-disks
Handling deprecation for dfs.datanode.failed.volumes.tolerated
Handling deprecation for yarn.timeline-service.handler-thread-count
Handling deprecation for ipc.server.listen.queue.size
Handling deprecation for fs.s3a.threads.max
Handling deprecation for yarn.resourcemanager.connect.max-wait.ms
Handling deprecation for mapreduce.fileoutputcommitter.algorithm.version
Handling deprecation for mapreduce.framework.name
Handling deprecation for mapreduce.map.skip.proc.count.autoincr
Handling deprecation for mapreduce.job.max.split.locations
Handling deprecation for yarn.resourcemanager.scheduler.class
Handling deprecation for yarn.resourcemanager.system-metrics-publisher.enabled
Handling deprecation for dfs.blocksize
Handling deprecation for yarn.sharedcache.nested-level
Handling deprecation for mapreduce.shuffle.connection-keep-alive.enable
Handling deprecation for fs.s3a.threads.keepalivetime
Handling deprecation for fs.s3a.connection.timeout
Handling deprecation for file.client-write-packet-size
Handling deprecation for ha.failover-controller.cli-check.rpc-timeout.ms
Handling deprecation for ha.zookeeper.acl
Handling deprecation for dfs.namenode.write.stale.datanode.ratio
Handling deprecation for dfs.encrypt.data.transfer
Handling deprecation for dfs.datanode.shared.file.descriptor.paths
Handling deprecation for mapreduce.input.lineinputformat.linespermap
Handling deprecation for yarn.resourcemanager.delayed.delegation-token.removal-interval-ms
Handling deprecation for yarn.nodemanager.localizer.fetch.thread-count
Handling deprecation for dfs.client.failover.max.attempts
Handling deprecation for yarn.resourcemanager.scheduler.address
Handling deprecation for dfs.client.read.shortcircuit.streams.cache.expiry.ms
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.start-time-write-cache-size
Handling deprecation for yarn.nodemanager.health-checker.script.timeout-ms
Handling deprecation for yarn.resourcemanager.fs.state-store.num-retries
Handling deprecation for hadoop.ssl.require.client.cert
Handling deprecation for hadoop.security.uid.cache.secs
Handling deprecation for mapreduce.jobhistory.keytab
Handling deprecation for dfs.client.read.shortcircuit.skip.checksum
Handling deprecation for yarn.resourcemanager.ha.automatic-failover.zk-base-path
Handling deprecation for mapreduce.shuffle.ssl.enabled
Handling deprecation for mapreduce.reduce.log.level
Handling deprecation for hadoop.registry.rm.enabled
Handling deprecation for mapreduce.tasktracker.dns.interface
Handling deprecation for yarn.resourcemanager.system-metrics-publisher.dispatcher.pool-size
Handling deprecation for mapreduce.job.speculative.speculative-cap-running-tasks
Handling deprecation for dfs.datanode.block.id.layout.upgrade.threads
Handling deprecation for dfs.datanode.use.datanode.hostname
Handling deprecation for dfs.client.context
Handling deprecation for yarn.resourcemanager.ha.enabled
Handling deprecation for mapred.reducer.new-api
Handling deprecation for dfs.namenode.delegation.token.renew-interval
Handling deprecation for dfs.blockreport.intervalMsec
Handling deprecation for fs.s3a.multipart.threshold
Handling deprecation for mapreduce.reduce.shuffle.memory.limit.percent
Handling deprecation for dfs.https.server.keystore.resource
Handling deprecation for io.map.index.skip
Handling deprecation for mapreduce.job.hdfs-servers
Handling deprecation for mapreduce.jobtracker.taskscheduler
Handling deprecation for dfs.namenode.kerberos.internal.spnego.principal
Handling deprecation for yarn.resourcemanager.state-store.max-completed-applications
Handling deprecation for mapreduce.map.output.compress
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.num.refill.threads
Handling deprecation for fs.s3n.multipart.uploads.block.size
Handling deprecation for mapreduce.task.merge.progress.records
Handling deprecation for dfs.datanode.dns.interface
Handling deprecation for map.sort.class
Handling deprecation for yarn.nodemanager.aux-services.mapreduce_shuffle.class
Handling deprecation for tfile.fs.output.buffer.size
Handling deprecation for fs.du.interval
Handling deprecation for dfs.client.failover.connection.retries
Handling deprecation for dfs.namenode.top.window.num.buckets
Handling deprecation for mapreduce.job.dir
Handling deprecation for fs.s3a.buffer.dir
Handling deprecation for mapreduce.reduce.shuffle.retry-delay.max.ms
Handling deprecation for yarn.sharedcache.uploader.server.address
Handling deprecation for mapreduce.client.progressmonitor.pollinterval
Handling deprecation for yarn.app.mapreduce.shuffle.log.limit.kb
Handling deprecation for dfs.datanode.max.locked.memory
Handling deprecation for dfs.namenode.retrycache.expirytime.millis
Handling deprecation for dfs.datanode.scan.period.hours
Handling deprecation for dfs.client.block.write.replace-datanode-on-failure.best-effort
Handling deprecation for mapreduce.jobhistory.move.interval-ms
Handling deprecation for dfs.ha.fencing.ssh.connect-timeout
Handling deprecation for yarn.nodemanager.log-aggregation.roll-monitoring-interval-seconds
Handling deprecation for dfs.namenode.fs-limits.max-component-length
Handling deprecation for hadoop.registry.zk.quorum
Handling deprecation for dfs.namenode.enable.retrycache
Handling deprecation for dfs.datanode.du.reserved
Handling deprecation for yarn.timeline-service.state-store-class
Handling deprecation for dfs.datanode.ipc.address
Handling deprecation for hadoop.registry.system.acls
Handling deprecation for dfs.client.block.write.replace-datanode-on-failure.policy
Handling deprecation for dfs.namenode.path.based.cache.retry.interval.ms
Handling deprecation for hadoop.security.crypto.cipher.suite
Handling deprecation for dfs.ha.tail-edits.period
Handling deprecation for mapreduce.task.profile.reduce.params
Handling deprecation for hadoop.registry.jaas.context
Handling deprecation for yarn.resourcemanager.hostname
Handling deprecation for mapreduce.reduce.memory.mb
Handling deprecation for hadoop.security.group.mapping.ldap.search.filter.group
Handling deprecation for hadoop.http.authentication.kerberos.principal
Handling deprecation for hadoop.security.group.mapping.ldap.search.filter.user
Handling deprecation for yarn.nodemanager.disk-health-checker.min-free-space-per-disk-mb
Handling deprecation for dfs.namenode.edits.dir
Handling deprecation for yarn.client.failover-retries-on-socket-timeouts
Handling deprecation for dfs.namenode.decommission.max.concurrent.tracked.nodes
Handling deprecation for mapreduce.client.completion.pollinterval
Handling deprecation for dfs.namenode.name.dir.restore
Handling deprecation for dfs.namenode.secondary.http-address
Handling deprecation for mapreduce.jobhistory.recovery.store.leveldb.path
Handling deprecation for yarn.sharedcache.store.class
Handling deprecation for s3.bytes-per-checksum
Handling deprecation for yarn.nodemanager.windows-container.cpu-limit.enabled
Handling deprecation for yarn.resourcemanager.webapp.https.address
Handling deprecation for yarn.nodemanager.vmem-pmem-ratio
Handling deprecation for dfs.namenode.checkpoint.period
Handling deprecation for dfs.ha.automatic-failover.enabled
The url to track the job: http://localhost:8080/
Running job: job_local425895704_0001
OutputCommitter set in config null
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
File Output Committer Algorithm version is 1
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
/user/michaeljones/wcOutputMain/_temporary/0: masked=rwxr-xr-x
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #12
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #12
Call: mkdirs took 6ms
Starting mapper thread pool executor.
Max local threads: 1
Map tasks to process: 1
Waiting for map tasks
Starting task: attempt_local425895704_0001_m_000000_0
currentIndex 0   0:0
mapreduce.cluster.local.dir for child : /tmp/hadoop-michaeljones/mapred/local/localRunner//michaeljones/jobcache/job_local425895704_0001/attempt_local425895704_0001_m_000000_0
using new api for output committer
File Output Committer Algorithm version is 1
ProcfsBasedProcessTree currently is supported only on Linux.
 Using ResourceCalculatorProcessTree : null
Processing split: hdfs://localhost:9000/user/michaeljones/wcInput:0+50
Trying map output collector class: org.apache.hadoop.mapred.MapTask$MapOutputBuffer
(EQUATOR) 0 kvi 26214396(104857584)
mapreduce.task.io.sort.mb: 100
soft limit at 83886080
bufstart = 0; bufvoid = 104857600
kvstart = 26214396; length = 6553600
Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #13
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #13
Call: getBlockLocations took 6ms
newInfo = LocatedBlocks{
  fileLength=50
  underConstruction=false
  blocks=[LocatedBlock{BP-1045030256-10.0.0.2-1433119149314:blk_1073741825_1002; getBlockSize()=50; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-b42c5705-9ba4-4b14-b00b-f9194bb036f0,DISK]]}]
  lastLocatedBlock=LocatedBlock{BP-1045030256-10.0.0.2-1433119149314:blk_1073741825_1002; getBlockSize()=50; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-b42c5705-9ba4-4b14-b00b-f9194bb036f0,DISK]]}
  isLastBlockComplete=true}
Connecting to datanode 127.0.0.1:50010

Starting flush of map output
Spilling map output
bufstart = 0; bufend = 82; bufvoid = 104857600
kvstart = 26214396(104857584); kvend = 26214368(104857472); length = 29/6553600
Finished spill 0
Task:attempt_local425895704_0001_m_000000_0 is done. And is in the process of committing
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #14
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #14
Call: getFileInfo took 2ms
map
Task 'attempt_local425895704_0001_m_000000_0' done.
Finishing task: attempt_local425895704_0001_m_000000_0
map task executor complete.
Starting reduce thread pool executor.
Max local threads: 1
Reduce tasks to process: 1
Waiting for reduce tasks
Starting task: attempt_local425895704_0001_r_000000_0
currentIndex 0   0:0
mapreduce.cluster.local.dir for child : /tmp/hadoop-michaeljones/mapred/local/localRunner//michaeljones/jobcache/job_local425895704_0001/attempt_local425895704_0001_r_000000_0
using new api for output committer
File Output Committer Algorithm version is 1
ProcfsBasedProcessTree currently is supported only on Linux.
 Using ResourceCalculatorProcessTree : null
Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@1a71c0d0
MergerManager: memoryLimit=668309888, maxSingleShuffleLimit=167077472, mergeThreshold=441084544, ioSortFactor=10, memToMemMergeOutputsThreshold=10
attempt_local425895704_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
Got 0 map completion events from 0
GetMapEventsThread about to sleep for 1000
LocalFetcher 1 going to fetch: attempt_local425895704_0001_m_000000_0
attempt_local425895704_0001_m_000000_0: Proceeding with shuffle since usedMemory (0) is lesser than memoryLimit (668309888).CommitMemory is (0)
localfetcher#1 about to shuffle output of map attempt_local425895704_0001_m_000000_0 decomp: 63 len: 67 to MEMORY
Read 63 bytes from map-output for attempt_local425895704_0001_m_000000_0
closeInMemoryFile -> map-output of size: 63, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->63
map attempt_local425895704_0001_m_000000_0 done 1 / 1 copied.
EventFetcher is interrupted.. Returning
1 / 1 copied.
finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
Merging 1 sorted segments
Down to the last merge-pass, with 1 segments left of total size: 57 bytes
Merged 1 segments, 63 bytes to disk to satisfy reduce memory limit
Disk file: /tmp/hadoop-michaeljones/mapred/local/localRunner/michaeljones/jobcache/job_local425895704_0001/attempt_local425895704_0001_r_000000_0/output/map_0.out.merged Length is 67
Merging 1 files, 67 bytes from disk
Merging 0 segments, 0 bytes from memory into reduce
Merging 1 sorted segments
Down to the last merge-pass, with 1 segments left of total size: 57 bytes
1 / 1 copied.
/user/michaeljones/wcOutputMain/_temporary/0/_temporary/attempt_local425895704_0001_r_000000_0/part-r-00000: masked=rw-r--r--
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #15
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #15
Call: create took 7ms
computePacketChunkSize: src=/user/michaeljones/wcOutputMain/_temporary/0/_temporary/attempt_local425895704_0001_r_000000_0/part-r-00000, chunkSize=516, chunksPerPacket=126, packetSize=65016
mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
DFSClient writeChunk allocating new packet seqno=0, src=/user/michaeljones/wcOutputMain/_temporary/0/_temporary/attempt_local425895704_0001_r_000000_0/part-r-00000, packetSize=65016, chunksPerPacket=126, bytesCurBlock=0
Queued packet 0
Allocating new block
Queued packet 1
Waiting for ack for: 1
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #16
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #16
Call: addBlock took 4ms
pipeline = DatanodeInfoWithStorage[127.0.0.1:50010,DS-b42c5705-9ba4-4b14-b00b-f9194bb036f0,DISK]
Connecting to datanode 127.0.0.1:50010
Send buf size 131072
SASL client skipping handshake in unsecured configuration for addr = /127.0.0.1, datanodeId = DatanodeInfoWithStorage[127.0.0.1:50010,DS-b42c5705-9ba4-4b14-b00b-f9194bb036f0,DISK]
DataStreamer block BP-1045030256-10.0.0.2-1433119149314:blk_1073742265_1442 sending packet packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 41
DFSClient seqno: 0 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
DataStreamer block BP-1045030256-10.0.0.2-1433119149314:blk_1073742265_1442 sending packet packet seqno: 1 offsetInBlock: 41 lastPacketInBlock: true lastByteOffsetInBlock: 41
DFSClient seqno: 1 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #17
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #17
Call: complete took 7ms
Task:attempt_local425895704_0001_r_000000_0 is done. And is in the process of committing
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #18
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #18
Call: getFileInfo took 2ms
1 / 1 copied.
Task attempt_local425895704_0001_r_000000_0 is allowed to commit now
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #19
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #19
Call: getFileInfo took 2ms
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #20
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #20
Call: getFileInfo took 2ms
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #21
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #21
Call: rename took 4ms
Saved output of task 'attempt_local425895704_0001_r_000000_0' to hdfs://localhost:9000/user/michaeljones/wcOutputMain/_temporary/0/task_local425895704_0001_r_000000
reduce > reduce
Task 'attempt_local425895704_0001_r_000000_0' done.
Finishing task: attempt_local425895704_0001_r_000000_0
reduce task executor complete.
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #22
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #22
Call: getListing took 2ms
Merging data from FileStatus{path=hdfs://localhost:9000/user/michaeljones/wcOutputMain/_temporary/0/task_local425895704_0001_r_000000; isDirectory=true; modification_time=1434167875337; access_time=0; owner=michaeljones; group=supergroup; permission=rwxr-xr-x; isSymlink=false} to hdfs://localhost:9000/user/michaeljones/wcOutputMain
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #23
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #23
Call: getFileInfo took 3ms
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #24
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #24
Call: getListing took 2ms
Merging data from FileStatus{path=hdfs://localhost:9000/user/michaeljones/wcOutputMain/_temporary/0/task_local425895704_0001_r_000000/part-r-00000; isDirectory=false; length=41; replication=1; blocksize=134217728; modification_time=1434167875370; access_time=1434167875337; owner=michaeljones; group=supergroup; permission=rw-r--r--; isSymlink=false} to hdfs://localhost:9000/user/michaeljones/wcOutputMain/part-r-00000
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #25
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #25
Call: getFileInfo took 3ms
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #26
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #26
Call: rename took 4ms
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #27
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #27
Call: delete took 2ms
/user/michaeljones/wcOutputMain/_SUCCESS: masked=rw-r--r--
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #28
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #28
Call: create took 5ms
computePacketChunkSize: src=/user/michaeljones/wcOutputMain/_SUCCESS, chunkSize=516, chunksPerPacket=126, packetSize=65016
Waiting for ack for: -1
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #29
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #29
Call: complete took 5ms
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.fs.FileContext.getAbstractFileSystem(FileContext.java:331)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
Job job_local425895704_0001 running in uber mode : false
 map 100% reduce 100%
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.getTaskCompletionEvents(Job.java:670)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.getTaskCompletionEvents(Job.java:670)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
Job job_local425895704_0001 completed successfully
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.getCounters(Job.java:758)
Counters: 35
	File System Counters
		FILE: Number of bytes read=520
		FILE: Number of bytes written=562719
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=140
		HDFS: Number of bytes written=81
		HDFS: Number of read operations=19
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=10
	Map-Reduce Framework
		Map input records=2
		Map output records=8
		Map output bytes=82
		Map output materialized bytes=67
		Input split bytes=112
		Combine input records=8
		Combine output records=5
		Reduce input groups=5
		Reduce shuffle bytes=67
		Reduce input records=5
		Reduce output records=5
		Spilled Records=10
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=563085312
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=50
	File Output Format Counters 
		Bytes Written=41
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
RunJobAsync
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #30
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #30
Call: getFileInfo took 2ms
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #31
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #31
Call: delete took 4ms
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.connect(Job.java:1256)
Trying ClientProtocolProvider : org.apache.hadoop.mapred.LocalClientProtocolProvider
Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
Picked org.apache.hadoop.mapred.LocalClientProtocolProvider as the ClientProtocolProvider
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Cluster.getFileSystem(Cluster.java:162)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.submit(Job.java:1287)
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #32
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #32
Call: getFileInfo took 2ms
Configuring job job_local1582810212_0002 with file:/tmp/hadoop-michaeljones/mapred/staging/michaeljones1582810212/.staging/job_local1582810212_0002 as the submit dir
adding the following namenodes' delegation tokens:[hdfs://localhost:9000]
Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
default FileSystem: file:///
No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
Creating splits at file:/tmp/hadoop-michaeljones/mapred/staging/michaeljones1582810212/.staging/job_local1582810212_0002
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #33
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #33
Call: getFileInfo took 2ms
Time taken to get FileStatuses: 3
Total input paths to process : 1
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #34
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #34
Call: getBlockLocations took 3ms
Total # of splits generated by getSplits: 1, TimeTaken: 8
number of splits:1
Handling deprecation for all properties in config...
Handling deprecation for mapreduce.jobtracker.address
Handling deprecation for yarn.resourcemanager.scheduler.monitor.policies
Handling deprecation for dfs.namenode.resource.check.interval
Handling deprecation for mapreduce.jobhistory.client.thread-count
Handling deprecation for yarn.app.mapreduce.am.containerlauncher.threadpool-initial-size
Handling deprecation for mapred.child.java.opts
Handling deprecation for mapreduce.jobtracker.retiredjobs.cache.size
Handling deprecation for dfs.client.https.need-auth
Handling deprecation for yarn.admin.acl
Handling deprecation for yarn.app.mapreduce.am.job.committer.cancel-timeout
Handling deprecation for mapreduce.job.emit-timeline-data
Handling deprecation for fs.ftp.host.port
Handling deprecation for dfs.namenode.avoid.read.stale.datanode
Handling deprecation for dfs.journalnode.rpc-address
Handling deprecation for mapreduce.job.end-notification.retry.attempts
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.ttl-interval-ms
Handling deprecation for yarn.resourcemanager.leveldb-state-store.path
Handling deprecation for mapred.mapper.new-api
Handling deprecation for yarn.ipc.rpc.class
Handling deprecation for ipc.client.connection.maxidletime
Handling deprecation for yarn.nodemanager.process-kill-wait.ms
Handling deprecation for mapreduce.cluster.acls.enabled
Handling deprecation for mapreduce.jobtracker.handler.count
Handling deprecation for io.map.index.interval
Handling deprecation for dfs.namenode.https-address
Handling deprecation for mapreduce.task.profile.reduces
Handling deprecation for fs.s3n.multipart.uploads.enabled
Handling deprecation for io.seqfile.sorter.recordlimit
Handling deprecation for mapreduce.job.ubertask.maxmaps
Handling deprecation for mapreduce.tasktracker.tasks.sleeptimebeforesigkill
Handling deprecation for hadoop.util.hash.type
Handling deprecation for dfs.namenode.replication.min
Handling deprecation for yarn.nodemanager.container-manager.thread-count
Handling deprecation for mapreduce.jobtracker.jobhistory.block.size
Handling deprecation for dfs.namenode.fs-limits.min-block-size
Handling deprecation for mapreduce.app-submission.cross-platform
Handling deprecation for fs.AbstractFileSystem.file.impl
Handling deprecation for net.topology.script.number.args
Handling deprecation for yarn.resourcemanager.container-tokens.master-key-rolling-interval-secs
Handling deprecation for mapreduce.map.output.compress.codec
Handling deprecation for mapreduce.job.reducer.preempt.delay.sec
Handling deprecation for s3native.bytes-per-checksum
Handling deprecation for dfs.namenode.path.based.cache.block.map.allocation.percent
Handling deprecation for yarn.nodemanager.windows-container.memory-limit.enabled
Handling deprecation for mapreduce.input.fileinputformat.split.minsize
Handling deprecation for hadoop.security.group.mapping
Handling deprecation for mapreduce.jobtracker.system.dir
Handling deprecation for mapreduce.job.end-notification.max.attempts
Handling deprecation for mapreduce.reduce.markreset.buffer.percent
Handling deprecation for dfs.datanode.cache.revocation.polling.ms
Handling deprecation for mapreduce.reduce.speculative
Handling deprecation for yarn.nodemanager.localizer.cache.cleanup.interval-ms
Handling deprecation for dfs.namenode.lazypersist.file.scrub.interval.sec
Handling deprecation for fs.s3a.threads.core
Handling deprecation for mapreduce.jobhistory.recovery.store.fs.uri
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.start-time-read-cache-size
Handling deprecation for hadoop.registry.zk.retry.interval.ms
Handling deprecation for yarn.nodemanager.keytab
Handling deprecation for dfs.namenode.replication.interval
Handling deprecation for yarn.resourcemanager.admin.address
Handling deprecation for mapreduce.job.maps
Handling deprecation for nfs.dump.dir
Handling deprecation for mapreduce.job.user.name
Handling deprecation for mapreduce.jobtracker.maxtasks.perjob
Handling deprecation for mapreduce.job.ubertask.enable
Handling deprecation for mapreduce.job.reduce.class
Handling deprecation for yarn.nodemanager.delete.debug-delay-sec
Handling deprecation for yarn.timeline-service.ttl-enable
Handling deprecation for yarn.resourcemanager.fs.state-store.retry-policy-spec
Handling deprecation for mapreduce.reduce.skip.maxgroups
Handling deprecation for dfs.client.use.datanode.hostname
Handling deprecation for fs.trash.interval
Handling deprecation for mapreduce.job.name
Handling deprecation for mapreduce.am.max-attempts
Handling deprecation for mapreduce.jobtracker.heartbeats.in.second
Handling deprecation for yarn.resourcemanager.zk-num-retries
Handling deprecation for s3.blocksize
Handling deprecation for dfs.datanode.data.dir
Handling deprecation for mapreduce.jobtracker.persist.jobstatus.active
Handling deprecation for mapreduce.reduce.shuffle.parallelcopies
Handling deprecation for fs.s3.buffer.dir
Handling deprecation for mapreduce.jobhistory.done-dir
Handling deprecation for hadoop.security.instrumentation.requires.admin
Handling deprecation for hadoop.registry.zk.retry.ceiling.ms
Handling deprecation for nfs.rtmax
Handling deprecation for dfs.datanode.data.dir.perm
Handling deprecation for yarn.resourcemanager.container.liveness-monitor.interval-ms
Handling deprecation for yarn.nodemanager.env-whitelist
Handling deprecation for dfs.namenode.backup.address
Handling deprecation for dfs.namenode.xattrs.enabled
Handling deprecation for dfs.datanode.readahead.bytes
Handling deprecation for mapreduce.jobhistory.cleaner.enable
Handling deprecation for dfs.client.block.write.retries
Handling deprecation for mapreduce.tasktracker.http.address
Handling deprecation for yarn.nodemanager.linux-container-executor.cgroups.hierarchy
Handling deprecation for ha.failover-controller.graceful-fence.connection.retries
Handling deprecation for yarn.resourcemanager.recovery.enabled
Handling deprecation for yarn.app.mapreduce.am.container.log.backups
Handling deprecation for dfs.namenode.safemode.threshold-pct
Handling deprecation for yarn.nodemanager.disk-health-checker.interval-ms
Handling deprecation for hadoop.security.java.secure.random.algorithm
Handling deprecation for dfs.namenode.list.cache.directives.num.responses
Handling deprecation for dfs.datanode.dns.nameserver
Handling deprecation for mapreduce.cluster.temp.dir
Handling deprecation for fs.s3a.max.total.tasks
Handling deprecation for mapreduce.reduce.maxattempts
Handling deprecation for mapreduce.client.submit.file.replication
Handling deprecation for mapreduce.shuffle.port
Handling deprecation for yarn.resourcemanager.resource-tracker.client.thread-count
Handling deprecation for dfs.namenode.replication.considerLoad
Handling deprecation for dfs.namenode.edits.journal-plugin.qjournal
Handling deprecation for dfs.client.write.exclude.nodes.cache.expiry.interval.millis
Handling deprecation for yarn.nodemanager.delete.thread-count
Handling deprecation for dfs.client.mmap.cache.timeout.ms
Handling deprecation for yarn.nodemanager.admin-env
Handling deprecation for io.skip.checksum.errors
Handling deprecation for yarn.timeline-service.hostname
Handling deprecation for yarn.resourcemanager.proxy-user-privileges.enabled
Handling deprecation for mapreduce.job.speculative.speculative-cap-total-tasks
Handling deprecation for yarn.acl.enable
Handling deprecation for fs.s3a.fast.upload
Handling deprecation for file.blocksize
Handling deprecation for mapreduce.job.speculative.slowtaskthreshold
Handling deprecation for ftp.replication
Handling deprecation for yarn.sharedcache.cleaner.initial-delay-mins
Handling deprecation for s3native.client-write-packet-size
Handling deprecation for hadoop.rpc.socket.factory.class.default
Handling deprecation for file.bytes-per-checksum
Handling deprecation for dfs.datanode.slow.io.warning.threshold.ms
Handling deprecation for io.seqfile.lazydecompress
Handling deprecation for mapreduce.task.skip.start.attempts
Handling deprecation for dfs.namenode.reject-unresolved-dn-topology-mapping
Handling deprecation for hadoop.common.configuration.version
Handling deprecation for yarn.resourcemanager.client.thread-count
Handling deprecation for dfs.datanode.drop.cache.behind.reads
Handling deprecation for yarn.sharedcache.admin.address
Handling deprecation for mapreduce.job.output.value.class
Handling deprecation for mapreduce.output.fileoutputformat.outputdir
Handling deprecation for mapreduce.jobtracker.taskcache.levels
Handling deprecation for yarn.nodemanager.linux-container-executor.nonsecure-mode.user-pattern
Handling deprecation for yarn.resourcemanager.zk-timeout-ms
Handling deprecation for yarn.resourcemanager.max-completed-applications
Handling deprecation for mapreduce.job.jvm.numtasks
Handling deprecation for yarn.sharedcache.cleaner.period-mins
Handling deprecation for mapreduce.jobtracker.tasktracker.maxblacklists
Handling deprecation for dfs.namenode.top.num.users
Handling deprecation for yarn.nodemanager.linux-container-executor.cgroups.mount
Handling deprecation for yarn.sharedcache.checksum.algo.impl
Handling deprecation for mapreduce.job.end-notification.max.retry.interval
Handling deprecation for mapreduce.job.acl-view-job
Handling deprecation for mapreduce.job.classloader
Handling deprecation for yarn.log-aggregation-enable
Handling deprecation for mapreduce.reduce.shuffle.fetch.retry.interval-ms
Handling deprecation for yarn.resourcemanager.nodemanager.minimum.version
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.size
Handling deprecation for yarn.app.mapreduce.am.job.task.listener.thread-count
Handling deprecation for yarn.app.mapreduce.am.resource.cpu-vcores
Handling deprecation for dfs.namenode.edit.log.autoroll.check.interval.ms
Handling deprecation for mapreduce.output.fileoutputformat.compress.type
Handling deprecation for hadoop.hdfs.configuration.version
Handling deprecation for hadoop.security.group.mapping.ldap.search.attr.member
Handling deprecation for yarn.nodemanager.log.retain-seconds
Handling deprecation for yarn.nodemanager.local-cache.max-files-per-directory
Handling deprecation for mapreduce.job.end-notification.retry.interval
Handling deprecation for hadoop.ssl.client.conf
Handling deprecation for yarn.sharedcache.root-dir
Handling deprecation for dfs.journalnode.https-address
Handling deprecation for mapreduce.reduce.shuffle.fetch.retry.timeout-ms
Handling deprecation for dfs.bytes-per-checksum
Handling deprecation for dfs.namenode.max.objects
Handling deprecation for mapreduce.tasktracker.instrumentation
Handling deprecation for dfs.datanode.max.transfer.threads
Handling deprecation for dfs.block.access.key.update.interval
Handling deprecation for mapreduce.jobtracker.jobhistory.task.numberprogresssplits
Handling deprecation for mapreduce.map.memory.mb
Handling deprecation for ha.failover-controller.new-active.rpc-timeout.ms
Handling deprecation for hadoop.ssl.hostname.verifier
Handling deprecation for dfs.client.read.shortcircuit
Handling deprecation for dfs.datanode.hdfs-blocks-metadata.enabled
Handling deprecation for mapreduce.tasktracker.healthchecker.interval
Handling deprecation for dfs.image.transfer.chunksize
Handling deprecation for mapreduce.tasktracker.taskmemorymanager.monitoringinterval
Handling deprecation for dfs.client.https.keystore.resource
Handling deprecation for yarn.resourcemanager.connect.retry-interval.ms
Handling deprecation for yarn.timeline-service.webapp.address
Handling deprecation for s3native.blocksize
Handling deprecation for yarn.scheduler.minimum-allocation-mb
Handling deprecation for yarn.sharedcache.cleaner.resource-sleep-ms
Handling deprecation for net.topology.impl
Handling deprecation for dfs.client.failover.sleep.base.millis
Handling deprecation for dfs.permissions.superusergroup
Handling deprecation for io.seqfile.compress.blocksize
Handling deprecation for hadoop.registry.zk.retry.times
Handling deprecation for fs.AbstractFileSystem.ftp.impl
Handling deprecation for dfs.namenode.checkpoint.edits.dir
Handling deprecation for mapreduce.job.running.reduce.limit
Handling deprecation for dfs.blockreport.initialDelay
Handling deprecation for dfs.namenode.heartbeat.recheck-interval
Handling deprecation for dfs.namenode.safemode.extension
Handling deprecation for yarn.scheduler.maximum-allocation-mb
Handling deprecation for mapreduce.job.reduce.shuffle.consumer.plugin.class
Handling deprecation for yarn.nodemanager.vmem-check-enabled
Handling deprecation for mapreduce.task.io.sort.factor
Handling deprecation for mapreduce.jobtracker.persist.jobstatus.dir
Handling deprecation for dfs.client.failover.sleep.max.millis
Handling deprecation for dfs.namenode.delegation.key.update-interval
Handling deprecation for hadoop.rpc.protection
Handling deprecation for fs.permissions.umask-mode
Handling deprecation for fs.s3.sleepTimeSeconds
Handling deprecation for ha.health-monitor.rpc-timeout.ms
Handling deprecation for hadoop.http.staticuser.user
Handling deprecation for fs.s3a.connection.maximum
Handling deprecation for yarn.nodemanager.linux-container-executor.nonsecure-mode.limit-users
Handling deprecation for fs.s3a.paging.maximum
Handling deprecation for fs.AbstractFileSystem.viewfs.impl
Handling deprecation for fs.ftp.host
Handling deprecation for yarn.nodemanager.linux-container-executor.nonsecure-mode.local-user
Handling deprecation for fs.s3a.impl
Handling deprecation for hadoop.http.authentication.kerberos.keytab
Handling deprecation for dfs.namenode.fs-limits.max-blocks-per-file
Handling deprecation for mapreduce.tasktracker.http.threads
Handling deprecation for mapreduce.tasktracker.dns.nameserver
Handling deprecation for yarn.resourcemanager.am-rm-tokens.master-key-rolling-interval-secs
Handling deprecation for dfs.client.block.write.replace-datanode-on-failure.enable
Handling deprecation for io.compression.codec.bzip2.library
Handling deprecation for mapreduce.map.skip.maxrecords
Handling deprecation for dfs.client.use.legacy.blockreader.local
Handling deprecation for dfs.namenode.checkpoint.dir
Handling deprecation for dfs.namenode.top.windows.minutes
Handling deprecation for mapreduce.job.maxtaskfailures.per.tracker
Handling deprecation for net.topology.node.switch.mapping.impl
Handling deprecation for mapreduce.shuffle.max.connections
Handling deprecation for mapreduce.jobhistory.loadedjobs.cache.size
Handling deprecation for dfs.storage.policy.enabled
Handling deprecation for yarn.client.application-client-protocol.poll-interval-ms
Handling deprecation for yarn.nodemanager.localizer.address
Handling deprecation for dfs.namenode.list.cache.pools.num.responses
Handling deprecation for nfs.server.port
Handling deprecation for mapreduce.client.output.filter
Handling deprecation for yarn.timeline-service.client.best-effort
Handling deprecation for ha.zookeeper.parent-znode
Handling deprecation for mapreduce.jobtracker.persist.jobstatus.hours
Handling deprecation for yarn.sharedcache.admin.thread-count
Handling deprecation for yarn.nodemanager.resource.cpu-vcores
Handling deprecation for dfs.datanode.block-pinning.enabled
Handling deprecation for mapreduce.jobhistory.http.policy
Handling deprecation for yarn.resourcemanager.webapp.delegation-token-auth-filter.enabled
Handling deprecation for mapreduce.job.speculative.retry-after-no-speculate
Handling deprecation for fs.s3a.attempts.maximum
Handling deprecation for s3native.stream-buffer-size
Handling deprecation for io.seqfile.local.dir
Handling deprecation for yarn.log-aggregation.retain-check-interval-seconds
Handling deprecation for fs.s3n.multipart.copy.block.size
Handling deprecation for dfs.encrypt.data.transfer.cipher.key.bitlength
Handling deprecation for dfs.datanode.sync.behind.writes
Handling deprecation for yarn.resourcemanager.zk-acl
Handling deprecation for hadoop.ssl.keystores.factory.class
Handling deprecation for mapreduce.job.split.metainfo.maxsize
Handling deprecation for fs.s3.maxRetries
Handling deprecation for hadoop.security.random.device.file.path
Handling deprecation for yarn.client.nodemanager-connect.max-wait-ms
Handling deprecation for dfs.namenode.stale.datanode.interval
Handling deprecation for mapreduce.task.io.sort.mb
Handling deprecation for yarn.resourcemanager.zk-state-store.parent-path
Handling deprecation for yarn.app.mapreduce.client-am.ipc.max-retries
Handling deprecation for fs.client.resolve.remote.symlinks
Handling deprecation for yarn.nodemanager.linux-container-executor.cgroups.strict-resource-usage
Handling deprecation for hadoop.ssl.enabled.protocols
Handling deprecation for mapreduce.reduce.cpu.vcores
Handling deprecation for yarn.client.failover-retries
Handling deprecation for mapreduce.jobhistory.address
Handling deprecation for hadoop.ssl.enabled
Handling deprecation for dfs.replication.max
Handling deprecation for dfs.namenode.name.dir
Handling deprecation for dfs.datanode.https.address
Handling deprecation for ipc.client.kill.max
Handling deprecation for mapreduce.job.committer.setup.cleanup.needed
Handling deprecation for dfs.client.domain.socket.data.traffic
Handling deprecation for yarn.nodemanager.localizer.cache.target-size-mb
Handling deprecation for yarn.resourcemanager.admin.client.thread-count
Handling deprecation for dfs.block.access.token.enable
Handling deprecation for mapreduce.job.speculative.retry-after-speculate
Handling deprecation for dfs.datanode.address
Handling deprecation for mapreduce.jobtracker.restart.recover
Handling deprecation for ipc.client.connect.max.retries
Handling deprecation for yarn.timeline-service.store-class
Handling deprecation for dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
Handling deprecation for hadoop.tmp.dir
Handling deprecation for dfs.datanode.handler.count
Handling deprecation for yarn.resourcemanager.ha.automatic-failover.embedded
Handling deprecation for yarn.timeline-service.ttl-ms
Handling deprecation for mapreduce.task.profile.map.params
Handling deprecation for yarn.resourcemanager.nodemanagers.heartbeat-interval-ms
Handling deprecation for mapreduce.map.speculative
Handling deprecation for yarn.timeline-service.recovery.enabled
Handling deprecation for mapreduce.job.map.class
Handling deprecation for dfs.namenode.resource.checked.volumes.minimum
Handling deprecation for yarn.nodemanager.recovery.dir
Handling deprecation for mapreduce.job.counters.max
Handling deprecation for yarn.resourcemanager.keytab
Handling deprecation for dfs.namenode.max.extra.edits.segments.retained
Handling deprecation for dfs.webhdfs.user.provider.user.pattern
Handling deprecation for dfs.client.mmap.enabled
Handling deprecation for mapreduce.map.log.level
Handling deprecation for dfs.client.file-block-storage-locations.timeout.millis
Handling deprecation for yarn.client.max-cached-nodemanagers-proxies
Handling deprecation for yarn.app.mapreduce.am.scheduler.heartbeat.interval-ms
Handling deprecation for hadoop.fuse.timer.period
Handling deprecation for fs.trash.checkpoint.interval
Handling deprecation for yarn.sharedcache.app-checker.class
Handling deprecation for dfs.journalnode.http-address
Handling deprecation for yarn.app.mapreduce.am.staging-dir
Handling deprecation for mapreduce.tasktracker.local.dir.minspacestart
Handling deprecation for yarn.nm.liveness-monitor.expiry-interval-ms
Handling deprecation for ha.health-monitor.check-interval.ms
Handling deprecation for mapreduce.reduce.shuffle.merge.percent
Handling deprecation for dfs.namenode.retrycache.heap.percent
Handling deprecation for yarn.nodemanager.docker-container-executor.exec-name
Handling deprecation for ipc.client.connect.timeout
Handling deprecation for yarn.resourcemanager.fs.state-store.retry-interval-ms
Handling deprecation for mapreduce.output.fileoutputformat.compress
Handling deprecation for yarn.nodemanager.local-dirs
Handling deprecation for yarn.nodemanager.recovery.enabled
Handling deprecation for io.native.lib.available
Handling deprecation for yarn.sharedcache.store.in-memory.staleness-period-mins
Handling deprecation for yarn.resourcemanager.am.max-attempts
Handling deprecation for s3.replication
Handling deprecation for mapreduce.input.fileinputformat.inputdir
Handling deprecation for fs.AbstractFileSystem.har.impl
Handling deprecation for dfs.image.compress
Handling deprecation for mapreduce.job.running.map.limit
Handling deprecation for mapreduce.reduce.input.buffer.percent
Handling deprecation for yarn.nodemanager.webapp.address
Handling deprecation for dfs.datanode.available-space-volume-choosing-policy.balanced-space-preference-fraction
Handling deprecation for dfs.namenode.edit.log.autoroll.multiplier.threshold
Handling deprecation for hadoop.security.group.mapping.ldap.ssl
Handling deprecation for dfs.namenode.checkpoint.check.period
Handling deprecation for fs.defaultFS
Handling deprecation for fs.s3a.multipart.size
Handling deprecation for dfs.client.slow.io.warning.threshold.ms
Handling deprecation for yarn.app.mapreduce.am.job.committer.commit-window
Handling deprecation for hadoop.security.group.mapping.ldap.search.attr.group.name
Handling deprecation for yarn.nodemanager.disk-health-checker.max-disk-utilization-per-disk-percentage
Handling deprecation for yarn.nodemanager.container-monitor.procfs-tree.smaps-based-rss.enabled
Handling deprecation for mapreduce.job.submithostname
Handling deprecation for mapreduce.map.sort.spill.percent
Handling deprecation for hadoop.security.crypto.codec.classes.aes.ctr.nopadding
Handling deprecation for dfs.namenode.http-address
Handling deprecation for hadoop.security.groups.negative-cache.secs
Handling deprecation for hadoop.ssl.server.conf
Handling deprecation for mapreduce.ifile.readahead
Handling deprecation for s3native.replication
Handling deprecation for yarn.client.nodemanager-client-async.thread-pool-max-size
Handling deprecation for mapreduce.jobtracker.staging.root.dir
Handling deprecation for mapreduce.jobhistory.admin.address
Handling deprecation for dfs.namenode.startup.delay.block.deletion.sec
Handling deprecation for yarn.nodemanager.health-checker.interval-ms
Handling deprecation for dfs.namenode.checkpoint.max-retries
Handling deprecation for s3.stream-buffer-size
Handling deprecation for ftp.client-write-packet-size
Handling deprecation for dfs.datanode.fsdatasetcache.max.threads.per.volume
Handling deprecation for mapreduce.output.fileoutputformat.compress.codec
Handling deprecation for yarn.timeline-service.keytab
Handling deprecation for yarn.sharedcache.store.in-memory.initial-delay-mins
Handling deprecation for mapreduce.jobhistory.webapp.address
Handling deprecation for mapreduce.task.userlog.limit.kb
Handling deprecation for mapreduce.reduce.shuffle.fetch.retry.enabled
Handling deprecation for yarn.app.mapreduce.task.container.log.backups
Handling deprecation for dfs.heartbeat.interval
Handling deprecation for ha.zookeeper.session-timeout.ms
Handling deprecation for fs.s3a.connection.ssl.enabled
Handling deprecation for yarn.sharedcache.webapp.address
Handling deprecation for hadoop.http.authentication.signature.secret.file
Handling deprecation for hadoop.fuse.connection.timeout
Handling deprecation for mapreduce.input.fileinputformat.numinputfiles
Handling deprecation for yarn.nodemanager.log-aggregation.compression-type
Handling deprecation for ipc.server.max.connections
Handling deprecation for yarn.resourcemanager.work-preserving-recovery.scheduling-wait-ms
Handling deprecation for yarn.nodemanager.log-dirs
Handling deprecation for yarn.app.mapreduce.am.resource.mb
Handling deprecation for hadoop.security.groups.cache.secs
Handling deprecation for mapreduce.job.speculative.minimum-allowed-tasks
Handling deprecation for yarn.nodemanager.container-monitor.interval-ms
Handling deprecation for dfs.datanode.cache.revocation.timeout.ms
Handling deprecation for mapreduce.jobhistory.recovery.store.class
Handling deprecation for mapreduce.task.combine.progress.records
Handling deprecation for s3.client-write-packet-size
Handling deprecation for mapreduce.jobtracker.instrumentation
Handling deprecation for dfs.replication
Handling deprecation for mapreduce.shuffle.transfer.buffer.size
Handling deprecation for hadoop.security.group.mapping.ldap.directory.search.timeout
Handling deprecation for dfs.datanode.available-space-volume-choosing-policy.balanced-space-threshold
Handling deprecation for hadoop.work.around.non.threadsafe.getpwuid
Handling deprecation for yarn.app.mapreduce.client-am.ipc.max-retries-on-timeouts
Handling deprecation for yarn.nodemanager.address
Handling deprecation for mapreduce.tasktracker.taskcontroller
Handling deprecation for mapreduce.tasktracker.indexcache.mb
Handling deprecation for yarn.scheduler.maximum-allocation-vcores
Handling deprecation for mapreduce.job.reduces
Handling deprecation for yarn.nodemanager.sleep-delay-before-sigkill.ms
Handling deprecation for yarn.timeline-service.address
Handling deprecation for yarn.resourcemanager.configuration.provider-class
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.expiry
Handling deprecation for yarn.sharedcache.enabled
Handling deprecation for tfile.io.chunk.size
Handling deprecation for mapreduce.job.acl-modify-job
Handling deprecation for hadoop.registry.zk.session.timeout.ms
Handling deprecation for fs.automatic.close
Handling deprecation for ha.health-monitor.sleep-after-disconnect.ms
Handling deprecation for mapreduce.tasktracker.reduce.tasks.maximum
Handling deprecation for mapreduce.input.fileinputformat.list-status.num-threads
Handling deprecation for dfs.datanode.directoryscan.threads
Handling deprecation for dfs.datanode.directoryscan.interval
Handling deprecation for dfs.namenode.acls.enabled
Handling deprecation for dfs.client.short.circuit.replica.stale.threshold.ms
Handling deprecation for hadoop.http.authentication.token.validity
Handling deprecation for fs.s3.block.size
Handling deprecation for ha.failover-controller.graceful-fence.rpc-timeout.ms
Handling deprecation for mapreduce.tasktracker.local.dir.minspacekill
Handling deprecation for dfs.namenode.resource.du.reserved
Handling deprecation for mapreduce.jobhistory.cleaner.interval-ms
Handling deprecation for dfs.namenode.datanode.registration.ip-hostname-check
Handling deprecation for mapreduce.jobhistory.intermediate-done-dir
Handling deprecation for mapreduce.jobtracker.http.address
Handling deprecation for dfs.namenode.backup.http-address
Handling deprecation for dfs.namenode.edits.noeditlogchannelflush
Handling deprecation for mapreduce.reduce.shuffle.input.buffer.percent
Handling deprecation for mapreduce.map.maxattempts
Handling deprecation for yarn.http.policy
Handling deprecation for dfs.namenode.audit.loggers
Handling deprecation for hadoop.security.groups.cache.warn.after.ms
Handling deprecation for io.serializations
Handling deprecation for mapreduce.tasktracker.outofband.heartbeat
Handling deprecation for mapreduce.reduce.shuffle.read.timeout
Handling deprecation for hadoop.security.crypto.buffer.size
Handling deprecation for mapreduce.reduce.skip.proc.count.autoincr
Handling deprecation for mapreduce.ifile.readahead.bytes
Handling deprecation for dfs.http.policy
Handling deprecation for hadoop.registry.secure
Handling deprecation for dfs.namenode.safemode.min.datanodes
Handling deprecation for dfs.client.file-block-storage-locations.num-threads
Handling deprecation for mapreduce.cluster.local.dir
Handling deprecation for mapreduce.tasktracker.report.address
Handling deprecation for dfs.namenode.secondary.https-address
Handling deprecation for hadoop.kerberos.kinit.command
Handling deprecation for yarn.timeline-service.http-authentication.type
Handling deprecation for dfs.block.access.token.lifetime
Handling deprecation for dfs.webhdfs.enabled
Handling deprecation for dfs.namenode.delegation.token.max-lifetime
Handling deprecation for dfs.namenode.avoid.write.stale.datanode
Handling deprecation for dfs.datanode.drop.cache.behind.writes
Handling deprecation for yarn.log-aggregation.retain-seconds
Handling deprecation for mapreduce.job.complete.cancel.delegation.tokens
Handling deprecation for mapreduce.local.clientfactory.class.name
Handling deprecation for mapreduce.shuffle.connection-keep-alive.timeout
Handling deprecation for dfs.namenode.num.extra.edits.retained
Handling deprecation for yarn.scheduler.minimum-allocation-vcores
Handling deprecation for ipc.client.connect.max.retries.on.timeouts
Handling deprecation for yarn.timeline-service.client.retry-interval-ms
Handling deprecation for yarn.timeline-service.client.max-retries
Handling deprecation for fs.s3n.block.size
Handling deprecation for mapreduce.job.map.output.collector.class
Handling deprecation for ha.health-monitor.connect-retry-interval.ms
Handling deprecation for mapreduce.shuffle.max.threads
Handling deprecation for nfs.exports.allowed.hosts
Handling deprecation for dfs.client.mmap.cache.size
Handling deprecation for mapreduce.tasktracker.map.tasks.maximum
Handling deprecation for io.file.buffer.size
Handling deprecation for dfs.client.datanode-restart.timeout
Handling deprecation for io.mapfile.bloom.size
Handling deprecation for hadoop.security.kms.client.authentication.retry-count
Handling deprecation for dfs.namenode.checkpoint.txns
Handling deprecation for ipc.client.connect.retry.interval
Handling deprecation for dfs.client-write-packet-size
Handling deprecation for mapreduce.reduce.shuffle.connect.timeout
Handling deprecation for yarn.resourcemanager.fs.state-store.uri
Handling deprecation for fs.swift.impl
Handling deprecation for hadoop.registry.zk.connection.timeout.ms
Handling deprecation for mapred.queue.default.acl-administer-jobs
Handling deprecation for mapreduce.job.submithostaddress
Handling deprecation for dfs.cachereport.intervalMsec
Handling deprecation for yarn.app.mapreduce.shuffle.log.backups
Handling deprecation for yarn.app.mapreduce.am.container.log.limit.kb
Handling deprecation for yarn.nodemanager.resourcemanager.minimum.version
Handling deprecation for ftp.blocksize
Handling deprecation for yarn.resourcemanager.address
Handling deprecation for file.stream-buffer-size
Handling deprecation for yarn.resourcemanager.scheduler.monitor.enable
Handling deprecation for mapreduce.job.ubertask.maxreduces
Handling deprecation for nfs.allow.insecure.ports
Handling deprecation for yarn.sharedcache.nm.uploader.thread-count
Handling deprecation for ipc.client.idlethreshold
Handling deprecation for ftp.stream-buffer-size
Handling deprecation for yarn.sharedcache.client-server.address
Handling deprecation for dfs.client.failover.connection.retries.on.timeouts
Handling deprecation for dfs.namenode.replication.work.multiplier.per.iteration
Handling deprecation for hadoop.http.authentication.simple.anonymous.allowed
Handling deprecation for hadoop.security.authorization
Handling deprecation for yarn.client.nodemanager-connect.retry-interval-ms
Handling deprecation for yarn.am.liveness-monitor.expiry-interval-ms
Handling deprecation for fs.har.impl.disable.cache
Handling deprecation for yarn.nodemanager.linux-container-executor.resources-handler.class
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.read-cache-size
Handling deprecation for hadoop.security.authentication
Handling deprecation for dfs.image.compression.codec
Handling deprecation for mapreduce.task.files.preserve.failedtasks
Handling deprecation for dfs.client.read.shortcircuit.streams.cache.size
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.path
Handling deprecation for mapreduce.job.reduce.slowstart.completedmaps
Handling deprecation for mapreduce.jobhistory.minicluster.fixed.ports
Handling deprecation for file.replication
Handling deprecation for yarn.resourcemanager.ha.automatic-failover.enabled
Handling deprecation for mapreduce.job.userlog.retain.hours
Handling deprecation for mapreduce.jobhistory.joblist.cache.size
Handling deprecation for dfs.namenode.accesstime.precision
Handling deprecation for yarn.resourcemanager.work-preserving-recovery.enabled
Handling deprecation for dfs.namenode.fs-limits.max-xattrs-per-inode
Handling deprecation for io.mapfile.bloom.error.rate
Handling deprecation for yarn.resourcemanager.store.class
Handling deprecation for dfs.image.transfer.timeout
Handling deprecation for yarn.timeline-service.leveldb-state-store.path
Handling deprecation for nfs.wtmax
Handling deprecation for mapreduce.job.combine.class
Handling deprecation for dfs.namenode.support.allow.format
Handling deprecation for fs.s3a.multipart.purge
Handling deprecation for dfs.secondary.namenode.kerberos.internal.spnego.principal
Handling deprecation for fs.s3a.connection.establish.timeout
Handling deprecation for dfs.stream-buffer-size
Handling deprecation for dfs.namenode.invalidate.work.pct.per.iteration
Handling deprecation for yarn.nodemanager.container-executor.class
Handling deprecation for fs.s3a.multipart.purge.age
Handling deprecation for yarn.resourcemanager.scheduler.client.thread-count
Handling deprecation for dfs.namenode.top.enabled
Handling deprecation for yarn.app.mapreduce.shuffle.log.separate
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.low-watermark
Handling deprecation for fs.s3a.fast.buffer.size
Handling deprecation for hadoop.user.group.static.mapping.overrides
Handling deprecation for tfile.fs.input.buffer.size
Handling deprecation for dfs.client.cached.conn.retry
Handling deprecation for hadoop.http.authentication.type
Handling deprecation for dfs.namenode.list.encryption.zones.num.responses
Handling deprecation for mapreduce.map.cpu.vcores
Handling deprecation for dfs.namenode.path.based.cache.refresh.interval.ms
Handling deprecation for dfs.namenode.decommission.interval
Handling deprecation for dfs.namenode.fs-limits.max-directory-items
Handling deprecation for yarn.resourcemanager.zk-retry-interval-ms
Handling deprecation for ftp.bytes-per-checksum
Handling deprecation for dfs.ha.log-roll.period
Handling deprecation for dfs.user.home.dir.prefix
Handling deprecation for ipc.client.fallback-to-simple-auth-allowed
Handling deprecation for yarn.nodemanager.pmem-check-enabled
Handling deprecation for yarn.nodemanager.remote-app-log-dir
Handling deprecation for dfs.namenode.inotify.max.events.per.rpc
Handling deprecation for mapreduce.task.profile.maps
Handling deprecation for mapreduce.shuffle.ssl.file.buffer.size
Handling deprecation for mapreduce.tasktracker.healthchecker.script.timeout
Handling deprecation for yarn.timeline-service.webapp.https.address
Handling deprecation for yarn.nodemanager.resource.percentage-physical-cpu-limit
Handling deprecation for yarn.app.mapreduce.am.command-opts
Handling deprecation for dfs.namenode.fs-limits.max-xattr-size
Handling deprecation for dfs.datanode.http.address
Handling deprecation for dfs.namenode.blocks.per.postponedblocks.rescan
Handling deprecation for yarn.sharedcache.nm.uploader.replication.factor
Handling deprecation for hadoop.registry.zk.root
Handling deprecation for hadoop.jetty.logs.serve.aliases
Handling deprecation for yarn.client.failover-proxy-provider
Handling deprecation for mapreduce.jobhistory.admin.acl
Handling deprecation for yarn.app.mapreduce.am.hard-kill-timeout-ms
Handling deprecation for yarn.nodemanager.remote-app-log-dir-suffix
Handling deprecation for mapreduce.jobhistory.principal
Handling deprecation for yarn.resourcemanager.webapp.address
Handling deprecation for mapreduce.jobhistory.recovery.enable
Handling deprecation for yarn.sharedcache.store.in-memory.check-period-mins
Handling deprecation for nfs.mountd.port
Handling deprecation for mapreduce.reduce.merge.inmem.threshold
Handling deprecation for fs.df.interval
Handling deprecation for yarn.timeline-service.enabled
Handling deprecation for mapreduce.jobtracker.jobhistory.lru.cache.size
Handling deprecation for mapreduce.task.profile
Handling deprecation for mapreduce.job.output.key.class
Handling deprecation for yarn.nodemanager.hostname
Handling deprecation for dfs.namenode.num.checkpoints.retained
Handling deprecation for mapreduce.job.queuename
Handling deprecation for mapreduce.jobhistory.max-age-ms
Handling deprecation for mapreduce.job.token.tracking.ids.enabled
Handling deprecation for yarn.nodemanager.localizer.client.thread-count
Handling deprecation for yarn.sharedcache.uploader.server.thread-count
Handling deprecation for dfs.client.mmap.retry.timeout.ms
Handling deprecation for mapreduce.jobhistory.move.thread-count
Handling deprecation for dfs.permissions.enabled
Handling deprecation for dfs.blockreport.split.threshold
Handling deprecation for fs.AbstractFileSystem.hdfs.impl
Handling deprecation for dfs.datanode.balance.bandwidthPerSec
Handling deprecation for dfs.block.scanner.volume.bytes.per.second
Handling deprecation for hadoop.http.filter.initializers
Handling deprecation for yarn.timeline-service.http-authentication.simple.anonymous.allowed
Handling deprecation for dfs.default.chunk.view.size
Handling deprecation for yarn.sharedcache.client-server.thread-count
Handling deprecation for yarn.resourcemanager.resource-tracker.address
Handling deprecation for mapreduce.job.working.dir
Handling deprecation for mapreduce.jobhistory.datestring.cache.size
Handling deprecation for mapreduce.task.profile.params
Handling deprecation for dfs.namenode.decommission.blocks.per.interval
Handling deprecation for dfs.namenode.handler.count
Handling deprecation for dfs.image.transfer.bandwidthPerSec
Handling deprecation for rpc.metrics.quantile.enable
Handling deprecation for mapreduce.jobtracker.expire.trackers.interval
Handling deprecation for mapreduce.task.timeout
Handling deprecation for yarn.app.mapreduce.client.max-retries
Handling deprecation for yarn.nodemanager.resource.memory-mb
Handling deprecation for yarn.nodemanager.disk-health-checker.min-healthy-disks
Handling deprecation for dfs.datanode.failed.volumes.tolerated
Handling deprecation for yarn.timeline-service.handler-thread-count
Handling deprecation for ipc.server.listen.queue.size
Handling deprecation for fs.s3a.threads.max
Handling deprecation for yarn.resourcemanager.connect.max-wait.ms
Handling deprecation for mapreduce.fileoutputcommitter.algorithm.version
Handling deprecation for mapreduce.framework.name
Handling deprecation for mapreduce.map.skip.proc.count.autoincr
Handling deprecation for mapreduce.job.max.split.locations
Handling deprecation for yarn.resourcemanager.scheduler.class
Handling deprecation for yarn.resourcemanager.system-metrics-publisher.enabled
Handling deprecation for dfs.blocksize
Handling deprecation for yarn.sharedcache.nested-level
Handling deprecation for mapreduce.shuffle.connection-keep-alive.enable
Handling deprecation for fs.s3a.threads.keepalivetime
Handling deprecation for fs.s3a.connection.timeout
Handling deprecation for file.client-write-packet-size
Handling deprecation for ha.failover-controller.cli-check.rpc-timeout.ms
Handling deprecation for ha.zookeeper.acl
Handling deprecation for dfs.namenode.write.stale.datanode.ratio
Handling deprecation for dfs.encrypt.data.transfer
Handling deprecation for dfs.datanode.shared.file.descriptor.paths
Handling deprecation for mapreduce.input.lineinputformat.linespermap
Handling deprecation for yarn.resourcemanager.delayed.delegation-token.removal-interval-ms
Handling deprecation for yarn.nodemanager.localizer.fetch.thread-count
Handling deprecation for dfs.client.failover.max.attempts
Handling deprecation for yarn.resourcemanager.scheduler.address
Handling deprecation for dfs.client.read.shortcircuit.streams.cache.expiry.ms
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.start-time-write-cache-size
Handling deprecation for yarn.nodemanager.health-checker.script.timeout-ms
Handling deprecation for yarn.resourcemanager.fs.state-store.num-retries
Handling deprecation for hadoop.ssl.require.client.cert
Handling deprecation for hadoop.security.uid.cache.secs
Handling deprecation for mapreduce.jobhistory.keytab
Handling deprecation for dfs.client.read.shortcircuit.skip.checksum
Handling deprecation for yarn.resourcemanager.ha.automatic-failover.zk-base-path
Handling deprecation for mapreduce.shuffle.ssl.enabled
Handling deprecation for mapreduce.reduce.log.level
Handling deprecation for hadoop.registry.rm.enabled
Handling deprecation for mapreduce.tasktracker.dns.interface
Handling deprecation for yarn.resourcemanager.system-metrics-publisher.dispatcher.pool-size
Handling deprecation for mapreduce.job.speculative.speculative-cap-running-tasks
Handling deprecation for dfs.datanode.block.id.layout.upgrade.threads
Handling deprecation for dfs.datanode.use.datanode.hostname
Handling deprecation for dfs.client.context
Handling deprecation for yarn.resourcemanager.ha.enabled
Handling deprecation for mapred.reducer.new-api
Handling deprecation for dfs.namenode.delegation.token.renew-interval
Handling deprecation for dfs.blockreport.intervalMsec
Handling deprecation for fs.s3a.multipart.threshold
Handling deprecation for mapreduce.reduce.shuffle.memory.limit.percent
Handling deprecation for dfs.https.server.keystore.resource
Handling deprecation for io.map.index.skip
Handling deprecation for mapreduce.job.hdfs-servers
Handling deprecation for mapreduce.jobtracker.taskscheduler
Handling deprecation for dfs.namenode.kerberos.internal.spnego.principal
Handling deprecation for yarn.resourcemanager.state-store.max-completed-applications
Handling deprecation for mapreduce.map.output.compress
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.num.refill.threads
Handling deprecation for fs.s3n.multipart.uploads.block.size
Handling deprecation for mapreduce.task.merge.progress.records
Handling deprecation for dfs.datanode.dns.interface
Handling deprecation for map.sort.class
Handling deprecation for yarn.nodemanager.aux-services.mapreduce_shuffle.class
Handling deprecation for tfile.fs.output.buffer.size
Handling deprecation for fs.du.interval
Handling deprecation for dfs.client.failover.connection.retries
Handling deprecation for dfs.namenode.top.window.num.buckets
Handling deprecation for mapreduce.job.dir
Handling deprecation for fs.s3a.buffer.dir
Handling deprecation for mapreduce.reduce.shuffle.retry-delay.max.ms
Handling deprecation for yarn.sharedcache.uploader.server.address
Handling deprecation for mapreduce.client.progressmonitor.pollinterval
Handling deprecation for yarn.app.mapreduce.shuffle.log.limit.kb
Handling deprecation for dfs.datanode.max.locked.memory
Handling deprecation for dfs.namenode.retrycache.expirytime.millis
Handling deprecation for dfs.datanode.scan.period.hours
Handling deprecation for dfs.client.block.write.replace-datanode-on-failure.best-effort
Handling deprecation for mapreduce.jobhistory.move.interval-ms
Handling deprecation for dfs.ha.fencing.ssh.connect-timeout
Handling deprecation for yarn.nodemanager.log-aggregation.roll-monitoring-interval-seconds
Handling deprecation for dfs.namenode.fs-limits.max-component-length
Handling deprecation for hadoop.registry.zk.quorum
Handling deprecation for dfs.namenode.enable.retrycache
Handling deprecation for dfs.datanode.du.reserved
Handling deprecation for yarn.timeline-service.state-store-class
Handling deprecation for dfs.datanode.ipc.address
Handling deprecation for hadoop.registry.system.acls
Handling deprecation for dfs.client.block.write.replace-datanode-on-failure.policy
Handling deprecation for dfs.namenode.path.based.cache.retry.interval.ms
Handling deprecation for hadoop.security.crypto.cipher.suite
Handling deprecation for dfs.ha.tail-edits.period
Handling deprecation for mapreduce.task.profile.reduce.params
Handling deprecation for hadoop.registry.jaas.context
Handling deprecation for yarn.resourcemanager.hostname
Handling deprecation for mapreduce.reduce.memory.mb
Handling deprecation for hadoop.security.group.mapping.ldap.search.filter.group
Handling deprecation for hadoop.http.authentication.kerberos.principal
Handling deprecation for hadoop.security.group.mapping.ldap.search.filter.user
Handling deprecation for yarn.nodemanager.disk-health-checker.min-free-space-per-disk-mb
Handling deprecation for dfs.namenode.edits.dir
Handling deprecation for yarn.client.failover-retries-on-socket-timeouts
Handling deprecation for dfs.namenode.decommission.max.concurrent.tracked.nodes
Handling deprecation for mapreduce.client.completion.pollinterval
Handling deprecation for dfs.namenode.name.dir.restore
Handling deprecation for dfs.namenode.secondary.http-address
Handling deprecation for mapreduce.jobhistory.recovery.store.leveldb.path
Handling deprecation for yarn.sharedcache.store.class
Handling deprecation for s3.bytes-per-checksum
Handling deprecation for yarn.nodemanager.windows-container.cpu-limit.enabled
Handling deprecation for yarn.resourcemanager.webapp.https.address
Handling deprecation for yarn.nodemanager.vmem-pmem-ratio
Handling deprecation for dfs.namenode.checkpoint.period
Handling deprecation for dfs.ha.automatic-failover.enabled
Submitting tokens for job: job_local1582810212_0002
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.fs.FileContext.getAbstractFileSystem(FileContext.java:331)
Handling deprecation for all properties in config...
Handling deprecation for mapreduce.jobtracker.address
Handling deprecation for yarn.resourcemanager.scheduler.monitor.policies
Handling deprecation for dfs.namenode.resource.check.interval
Handling deprecation for mapreduce.jobhistory.client.thread-count
Handling deprecation for yarn.app.mapreduce.am.containerlauncher.threadpool-initial-size
Handling deprecation for mapred.child.java.opts
Handling deprecation for mapreduce.jobtracker.retiredjobs.cache.size
Handling deprecation for dfs.client.https.need-auth
Handling deprecation for yarn.admin.acl
Handling deprecation for yarn.app.mapreduce.am.job.committer.cancel-timeout
Handling deprecation for mapreduce.job.emit-timeline-data
Handling deprecation for fs.ftp.host.port
Handling deprecation for dfs.namenode.avoid.read.stale.datanode
Handling deprecation for dfs.journalnode.rpc-address
Handling deprecation for mapreduce.job.end-notification.retry.attempts
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.ttl-interval-ms
Handling deprecation for yarn.resourcemanager.leveldb-state-store.path
Handling deprecation for mapred.mapper.new-api
Handling deprecation for yarn.ipc.rpc.class
Handling deprecation for ipc.client.connection.maxidletime
Handling deprecation for yarn.nodemanager.process-kill-wait.ms
Handling deprecation for mapreduce.cluster.acls.enabled
Handling deprecation for mapreduce.jobtracker.handler.count
Handling deprecation for io.map.index.interval
Handling deprecation for dfs.namenode.https-address
Handling deprecation for mapreduce.task.profile.reduces
Handling deprecation for fs.s3n.multipart.uploads.enabled
Handling deprecation for io.seqfile.sorter.recordlimit
Handling deprecation for mapreduce.job.ubertask.maxmaps
Handling deprecation for mapreduce.tasktracker.tasks.sleeptimebeforesigkill
Handling deprecation for hadoop.util.hash.type
Handling deprecation for dfs.namenode.replication.min
Handling deprecation for yarn.nodemanager.container-manager.thread-count
Handling deprecation for mapreduce.jobtracker.jobhistory.block.size
Handling deprecation for dfs.namenode.fs-limits.min-block-size
Handling deprecation for mapreduce.app-submission.cross-platform
Handling deprecation for fs.AbstractFileSystem.file.impl
Handling deprecation for net.topology.script.number.args
Handling deprecation for yarn.resourcemanager.container-tokens.master-key-rolling-interval-secs
Handling deprecation for mapreduce.map.output.compress.codec
Handling deprecation for mapreduce.job.reducer.preempt.delay.sec
Handling deprecation for s3native.bytes-per-checksum
Handling deprecation for dfs.namenode.path.based.cache.block.map.allocation.percent
Handling deprecation for yarn.nodemanager.windows-container.memory-limit.enabled
Handling deprecation for mapreduce.input.fileinputformat.split.minsize
Handling deprecation for hadoop.security.group.mapping
Handling deprecation for mapreduce.jobtracker.system.dir
Handling deprecation for mapreduce.job.end-notification.max.attempts
Handling deprecation for mapreduce.reduce.markreset.buffer.percent
Handling deprecation for dfs.datanode.cache.revocation.polling.ms
Handling deprecation for mapreduce.reduce.speculative
Handling deprecation for yarn.nodemanager.localizer.cache.cleanup.interval-ms
Handling deprecation for dfs.namenode.lazypersist.file.scrub.interval.sec
Handling deprecation for fs.s3a.threads.core
Handling deprecation for mapreduce.jobhistory.recovery.store.fs.uri
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.start-time-read-cache-size
Handling deprecation for hadoop.registry.zk.retry.interval.ms
Handling deprecation for yarn.nodemanager.keytab
Handling deprecation for dfs.namenode.replication.interval
Handling deprecation for yarn.resourcemanager.admin.address
Handling deprecation for mapreduce.job.maps
Handling deprecation for nfs.dump.dir
Handling deprecation for mapreduce.job.user.name
Handling deprecation for mapreduce.jobtracker.maxtasks.perjob
Handling deprecation for mapreduce.job.ubertask.enable
Handling deprecation for mapreduce.job.reduce.class
Handling deprecation for yarn.nodemanager.delete.debug-delay-sec
Handling deprecation for yarn.timeline-service.ttl-enable
Handling deprecation for yarn.resourcemanager.fs.state-store.retry-policy-spec
Handling deprecation for mapreduce.reduce.skip.maxgroups
Handling deprecation for dfs.client.use.datanode.hostname
Handling deprecation for fs.trash.interval
Handling deprecation for mapreduce.job.name
Handling deprecation for mapreduce.am.max-attempts
Handling deprecation for mapreduce.jobtracker.heartbeats.in.second
Handling deprecation for yarn.resourcemanager.zk-num-retries
Handling deprecation for s3.blocksize
Handling deprecation for dfs.datanode.data.dir
Handling deprecation for mapreduce.jobtracker.persist.jobstatus.active
Handling deprecation for mapreduce.reduce.shuffle.parallelcopies
Handling deprecation for fs.s3.buffer.dir
Handling deprecation for mapreduce.jobhistory.done-dir
Handling deprecation for hadoop.security.instrumentation.requires.admin
Handling deprecation for hadoop.registry.zk.retry.ceiling.ms
Handling deprecation for nfs.rtmax
Handling deprecation for dfs.datanode.data.dir.perm
Handling deprecation for yarn.resourcemanager.container.liveness-monitor.interval-ms
Handling deprecation for yarn.nodemanager.env-whitelist
Handling deprecation for dfs.namenode.backup.address
Handling deprecation for dfs.namenode.xattrs.enabled
Handling deprecation for dfs.datanode.readahead.bytes
Handling deprecation for mapreduce.jobhistory.cleaner.enable
Handling deprecation for dfs.client.block.write.retries
Handling deprecation for mapreduce.tasktracker.http.address
Handling deprecation for yarn.nodemanager.linux-container-executor.cgroups.hierarchy
Handling deprecation for ha.failover-controller.graceful-fence.connection.retries
Handling deprecation for yarn.resourcemanager.recovery.enabled
Handling deprecation for yarn.app.mapreduce.am.container.log.backups
Handling deprecation for dfs.namenode.safemode.threshold-pct
Handling deprecation for yarn.nodemanager.disk-health-checker.interval-ms
Handling deprecation for hadoop.security.java.secure.random.algorithm
Handling deprecation for dfs.namenode.list.cache.directives.num.responses
Handling deprecation for dfs.datanode.dns.nameserver
Handling deprecation for mapreduce.cluster.temp.dir
Handling deprecation for fs.s3a.max.total.tasks
Handling deprecation for mapreduce.reduce.maxattempts
Handling deprecation for mapreduce.client.submit.file.replication
Handling deprecation for mapreduce.shuffle.port
Handling deprecation for yarn.resourcemanager.resource-tracker.client.thread-count
Handling deprecation for dfs.namenode.replication.considerLoad
Handling deprecation for dfs.namenode.edits.journal-plugin.qjournal
Handling deprecation for dfs.client.write.exclude.nodes.cache.expiry.interval.millis
Handling deprecation for yarn.nodemanager.delete.thread-count
Handling deprecation for dfs.client.mmap.cache.timeout.ms
Handling deprecation for yarn.nodemanager.admin-env
Handling deprecation for io.skip.checksum.errors
Handling deprecation for yarn.timeline-service.hostname
Handling deprecation for yarn.resourcemanager.proxy-user-privileges.enabled
Handling deprecation for mapreduce.job.speculative.speculative-cap-total-tasks
Handling deprecation for yarn.acl.enable
Handling deprecation for fs.s3a.fast.upload
Handling deprecation for file.blocksize
Handling deprecation for mapreduce.job.speculative.slowtaskthreshold
Handling deprecation for ftp.replication
Handling deprecation for yarn.sharedcache.cleaner.initial-delay-mins
Handling deprecation for s3native.client-write-packet-size
Handling deprecation for hadoop.rpc.socket.factory.class.default
Handling deprecation for file.bytes-per-checksum
Handling deprecation for dfs.datanode.slow.io.warning.threshold.ms
Handling deprecation for io.seqfile.lazydecompress
Handling deprecation for mapreduce.task.skip.start.attempts
Handling deprecation for dfs.namenode.reject-unresolved-dn-topology-mapping
Handling deprecation for hadoop.common.configuration.version
Handling deprecation for yarn.resourcemanager.client.thread-count
Handling deprecation for dfs.datanode.drop.cache.behind.reads
Handling deprecation for yarn.sharedcache.admin.address
Handling deprecation for mapreduce.job.output.value.class
Handling deprecation for mapreduce.output.fileoutputformat.outputdir
Handling deprecation for mapreduce.jobtracker.taskcache.levels
Handling deprecation for yarn.nodemanager.linux-container-executor.nonsecure-mode.user-pattern
Handling deprecation for yarn.resourcemanager.zk-timeout-ms
Handling deprecation for yarn.resourcemanager.max-completed-applications
Handling deprecation for mapreduce.job.jvm.numtasks
Handling deprecation for yarn.sharedcache.cleaner.period-mins
Handling deprecation for mapreduce.jobtracker.tasktracker.maxblacklists
Handling deprecation for dfs.namenode.top.num.users
Handling deprecation for yarn.nodemanager.linux-container-executor.cgroups.mount
Handling deprecation for yarn.sharedcache.checksum.algo.impl
Handling deprecation for mapreduce.job.end-notification.max.retry.interval
Handling deprecation for mapreduce.job.acl-view-job
Handling deprecation for mapreduce.job.classloader
Handling deprecation for yarn.log-aggregation-enable
Handling deprecation for mapreduce.reduce.shuffle.fetch.retry.interval-ms
Handling deprecation for yarn.resourcemanager.nodemanager.minimum.version
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.size
Handling deprecation for yarn.app.mapreduce.am.job.task.listener.thread-count
Handling deprecation for yarn.app.mapreduce.am.resource.cpu-vcores
Handling deprecation for dfs.namenode.edit.log.autoroll.check.interval.ms
Handling deprecation for mapreduce.output.fileoutputformat.compress.type
Handling deprecation for hadoop.hdfs.configuration.version
Handling deprecation for hadoop.security.group.mapping.ldap.search.attr.member
Handling deprecation for yarn.nodemanager.log.retain-seconds
Handling deprecation for yarn.nodemanager.local-cache.max-files-per-directory
Handling deprecation for mapreduce.job.end-notification.retry.interval
Handling deprecation for hadoop.ssl.client.conf
Handling deprecation for yarn.sharedcache.root-dir
Handling deprecation for dfs.journalnode.https-address
Handling deprecation for mapreduce.reduce.shuffle.fetch.retry.timeout-ms
Handling deprecation for dfs.bytes-per-checksum
Handling deprecation for dfs.namenode.max.objects
Handling deprecation for mapreduce.tasktracker.instrumentation
Handling deprecation for dfs.datanode.max.transfer.threads
Handling deprecation for dfs.block.access.key.update.interval
Handling deprecation for mapreduce.jobtracker.jobhistory.task.numberprogresssplits
Handling deprecation for mapreduce.map.memory.mb
Handling deprecation for ha.failover-controller.new-active.rpc-timeout.ms
Handling deprecation for hadoop.ssl.hostname.verifier
Handling deprecation for dfs.client.read.shortcircuit
Handling deprecation for dfs.datanode.hdfs-blocks-metadata.enabled
Handling deprecation for mapreduce.tasktracker.healthchecker.interval
Handling deprecation for dfs.image.transfer.chunksize
Handling deprecation for mapreduce.tasktracker.taskmemorymanager.monitoringinterval
Handling deprecation for dfs.client.https.keystore.resource
Handling deprecation for yarn.resourcemanager.connect.retry-interval.ms
Handling deprecation for yarn.timeline-service.webapp.address
Handling deprecation for s3native.blocksize
Handling deprecation for yarn.scheduler.minimum-allocation-mb
Handling deprecation for yarn.sharedcache.cleaner.resource-sleep-ms
Handling deprecation for net.topology.impl
Handling deprecation for dfs.client.failover.sleep.base.millis
Handling deprecation for dfs.permissions.superusergroup
Handling deprecation for io.seqfile.compress.blocksize
Handling deprecation for hadoop.registry.zk.retry.times
Handling deprecation for fs.AbstractFileSystem.ftp.impl
Handling deprecation for dfs.namenode.checkpoint.edits.dir
Handling deprecation for mapreduce.job.running.reduce.limit
Handling deprecation for dfs.blockreport.initialDelay
Handling deprecation for dfs.namenode.heartbeat.recheck-interval
Handling deprecation for dfs.namenode.safemode.extension
Handling deprecation for yarn.scheduler.maximum-allocation-mb
Handling deprecation for mapreduce.job.reduce.shuffle.consumer.plugin.class
Handling deprecation for yarn.nodemanager.vmem-check-enabled
Handling deprecation for mapreduce.task.io.sort.factor
Handling deprecation for mapreduce.jobtracker.persist.jobstatus.dir
Handling deprecation for dfs.client.failover.sleep.max.millis
Handling deprecation for dfs.namenode.delegation.key.update-interval
Handling deprecation for hadoop.rpc.protection
Handling deprecation for fs.permissions.umask-mode
Handling deprecation for fs.s3.sleepTimeSeconds
Handling deprecation for ha.health-monitor.rpc-timeout.ms
Handling deprecation for hadoop.http.staticuser.user
Handling deprecation for fs.s3a.connection.maximum
Handling deprecation for yarn.nodemanager.linux-container-executor.nonsecure-mode.limit-users
Handling deprecation for fs.s3a.paging.maximum
Handling deprecation for fs.AbstractFileSystem.viewfs.impl
Handling deprecation for fs.ftp.host
Handling deprecation for yarn.nodemanager.linux-container-executor.nonsecure-mode.local-user
Handling deprecation for fs.s3a.impl
Handling deprecation for hadoop.http.authentication.kerberos.keytab
Handling deprecation for dfs.namenode.fs-limits.max-blocks-per-file
Handling deprecation for mapreduce.tasktracker.http.threads
Handling deprecation for mapreduce.tasktracker.dns.nameserver
Handling deprecation for yarn.resourcemanager.am-rm-tokens.master-key-rolling-interval-secs
Handling deprecation for dfs.client.block.write.replace-datanode-on-failure.enable
Handling deprecation for io.compression.codec.bzip2.library
Handling deprecation for mapreduce.map.skip.maxrecords
Handling deprecation for dfs.client.use.legacy.blockreader.local
Handling deprecation for dfs.namenode.checkpoint.dir
Handling deprecation for dfs.namenode.top.windows.minutes
Handling deprecation for mapreduce.job.maxtaskfailures.per.tracker
Handling deprecation for net.topology.node.switch.mapping.impl
Handling deprecation for mapreduce.shuffle.max.connections
Handling deprecation for mapreduce.jobhistory.loadedjobs.cache.size
Handling deprecation for dfs.storage.policy.enabled
Handling deprecation for yarn.client.application-client-protocol.poll-interval-ms
Handling deprecation for yarn.nodemanager.localizer.address
Handling deprecation for dfs.namenode.list.cache.pools.num.responses
Handling deprecation for nfs.server.port
Handling deprecation for mapreduce.client.output.filter
Handling deprecation for yarn.timeline-service.client.best-effort
Handling deprecation for ha.zookeeper.parent-znode
Handling deprecation for mapreduce.jobtracker.persist.jobstatus.hours
Handling deprecation for yarn.sharedcache.admin.thread-count
Handling deprecation for yarn.nodemanager.resource.cpu-vcores
Handling deprecation for dfs.datanode.block-pinning.enabled
Handling deprecation for mapreduce.jobhistory.http.policy
Handling deprecation for yarn.resourcemanager.webapp.delegation-token-auth-filter.enabled
Handling deprecation for mapreduce.job.speculative.retry-after-no-speculate
Handling deprecation for fs.s3a.attempts.maximum
Handling deprecation for s3native.stream-buffer-size
Handling deprecation for io.seqfile.local.dir
Handling deprecation for yarn.log-aggregation.retain-check-interval-seconds
Handling deprecation for fs.s3n.multipart.copy.block.size
Handling deprecation for dfs.encrypt.data.transfer.cipher.key.bitlength
Handling deprecation for dfs.datanode.sync.behind.writes
Handling deprecation for yarn.resourcemanager.zk-acl
Handling deprecation for hadoop.ssl.keystores.factory.class
Handling deprecation for mapreduce.job.split.metainfo.maxsize
Handling deprecation for fs.s3.maxRetries
Handling deprecation for hadoop.security.random.device.file.path
Handling deprecation for yarn.client.nodemanager-connect.max-wait-ms
Handling deprecation for dfs.namenode.stale.datanode.interval
Handling deprecation for mapreduce.task.io.sort.mb
Handling deprecation for yarn.resourcemanager.zk-state-store.parent-path
Handling deprecation for yarn.app.mapreduce.client-am.ipc.max-retries
Handling deprecation for fs.client.resolve.remote.symlinks
Handling deprecation for yarn.nodemanager.linux-container-executor.cgroups.strict-resource-usage
Handling deprecation for hadoop.ssl.enabled.protocols
Handling deprecation for mapreduce.reduce.cpu.vcores
Handling deprecation for yarn.client.failover-retries
Handling deprecation for mapreduce.jobhistory.address
Handling deprecation for hadoop.ssl.enabled
Handling deprecation for dfs.replication.max
Handling deprecation for dfs.namenode.name.dir
Handling deprecation for dfs.datanode.https.address
Handling deprecation for ipc.client.kill.max
Handling deprecation for mapreduce.job.committer.setup.cleanup.needed
Handling deprecation for dfs.client.domain.socket.data.traffic
Handling deprecation for yarn.nodemanager.localizer.cache.target-size-mb
Handling deprecation for yarn.resourcemanager.admin.client.thread-count
Handling deprecation for dfs.block.access.token.enable
Handling deprecation for mapreduce.job.speculative.retry-after-speculate
Handling deprecation for dfs.datanode.address
Handling deprecation for mapreduce.jobtracker.restart.recover
Handling deprecation for ipc.client.connect.max.retries
Handling deprecation for yarn.timeline-service.store-class
Handling deprecation for dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
Handling deprecation for hadoop.tmp.dir
Handling deprecation for dfs.datanode.handler.count
Handling deprecation for yarn.resourcemanager.ha.automatic-failover.embedded
Handling deprecation for yarn.timeline-service.ttl-ms
Handling deprecation for mapreduce.task.profile.map.params
Handling deprecation for yarn.resourcemanager.nodemanagers.heartbeat-interval-ms
Handling deprecation for mapreduce.map.speculative
Handling deprecation for yarn.timeline-service.recovery.enabled
Handling deprecation for mapreduce.job.map.class
Handling deprecation for dfs.namenode.resource.checked.volumes.minimum
Handling deprecation for yarn.nodemanager.recovery.dir
Handling deprecation for mapreduce.job.counters.max
Handling deprecation for yarn.resourcemanager.keytab
Handling deprecation for dfs.namenode.max.extra.edits.segments.retained
Handling deprecation for dfs.webhdfs.user.provider.user.pattern
Handling deprecation for dfs.client.mmap.enabled
Handling deprecation for mapreduce.map.log.level
Handling deprecation for dfs.client.file-block-storage-locations.timeout.millis
Handling deprecation for yarn.client.max-cached-nodemanagers-proxies
Handling deprecation for yarn.app.mapreduce.am.scheduler.heartbeat.interval-ms
Handling deprecation for hadoop.fuse.timer.period
Handling deprecation for fs.trash.checkpoint.interval
Handling deprecation for yarn.sharedcache.app-checker.class
Handling deprecation for dfs.journalnode.http-address
Handling deprecation for yarn.app.mapreduce.am.staging-dir
Handling deprecation for mapreduce.tasktracker.local.dir.minspacestart
Handling deprecation for yarn.nm.liveness-monitor.expiry-interval-ms
Handling deprecation for ha.health-monitor.check-interval.ms
Handling deprecation for mapreduce.reduce.shuffle.merge.percent
Handling deprecation for dfs.namenode.retrycache.heap.percent
Handling deprecation for yarn.nodemanager.docker-container-executor.exec-name
Handling deprecation for ipc.client.connect.timeout
Handling deprecation for yarn.resourcemanager.fs.state-store.retry-interval-ms
Handling deprecation for mapreduce.output.fileoutputformat.compress
Handling deprecation for yarn.nodemanager.local-dirs
Handling deprecation for yarn.nodemanager.recovery.enabled
Handling deprecation for io.native.lib.available
Handling deprecation for yarn.sharedcache.store.in-memory.staleness-period-mins
Handling deprecation for yarn.resourcemanager.am.max-attempts
Handling deprecation for s3.replication
Handling deprecation for mapreduce.input.fileinputformat.inputdir
Handling deprecation for fs.AbstractFileSystem.har.impl
Handling deprecation for dfs.image.compress
Handling deprecation for mapreduce.job.running.map.limit
Handling deprecation for mapreduce.reduce.input.buffer.percent
Handling deprecation for yarn.nodemanager.webapp.address
Handling deprecation for dfs.datanode.available-space-volume-choosing-policy.balanced-space-preference-fraction
Handling deprecation for dfs.namenode.edit.log.autoroll.multiplier.threshold
Handling deprecation for hadoop.security.group.mapping.ldap.ssl
Handling deprecation for dfs.namenode.checkpoint.check.period
Handling deprecation for fs.defaultFS
Handling deprecation for fs.s3a.multipart.size
Handling deprecation for dfs.client.slow.io.warning.threshold.ms
Handling deprecation for yarn.app.mapreduce.am.job.committer.commit-window
Handling deprecation for hadoop.security.group.mapping.ldap.search.attr.group.name
Handling deprecation for yarn.nodemanager.disk-health-checker.max-disk-utilization-per-disk-percentage
Handling deprecation for yarn.nodemanager.container-monitor.procfs-tree.smaps-based-rss.enabled
Handling deprecation for mapreduce.job.submithostname
Handling deprecation for mapreduce.map.sort.spill.percent
Handling deprecation for hadoop.security.crypto.codec.classes.aes.ctr.nopadding
Handling deprecation for dfs.namenode.http-address
Handling deprecation for hadoop.security.groups.negative-cache.secs
Handling deprecation for hadoop.ssl.server.conf
Handling deprecation for mapreduce.ifile.readahead
Handling deprecation for s3native.replication
Handling deprecation for yarn.client.nodemanager-client-async.thread-pool-max-size
Handling deprecation for mapreduce.jobtracker.staging.root.dir
Handling deprecation for mapreduce.jobhistory.admin.address
Handling deprecation for dfs.namenode.startup.delay.block.deletion.sec
Handling deprecation for yarn.nodemanager.health-checker.interval-ms
Handling deprecation for dfs.namenode.checkpoint.max-retries
Handling deprecation for s3.stream-buffer-size
Handling deprecation for ftp.client-write-packet-size
Handling deprecation for dfs.datanode.fsdatasetcache.max.threads.per.volume
Handling deprecation for mapreduce.output.fileoutputformat.compress.codec
Handling deprecation for yarn.timeline-service.keytab
Handling deprecation for yarn.sharedcache.store.in-memory.initial-delay-mins
Handling deprecation for mapreduce.jobhistory.webapp.address
Handling deprecation for mapreduce.task.userlog.limit.kb
Handling deprecation for mapreduce.reduce.shuffle.fetch.retry.enabled
Handling deprecation for yarn.app.mapreduce.task.container.log.backups
Handling deprecation for dfs.heartbeat.interval
Handling deprecation for ha.zookeeper.session-timeout.ms
Handling deprecation for fs.s3a.connection.ssl.enabled
Handling deprecation for yarn.sharedcache.webapp.address
Handling deprecation for hadoop.http.authentication.signature.secret.file
Handling deprecation for hadoop.fuse.connection.timeout
Handling deprecation for mapreduce.input.fileinputformat.numinputfiles
Handling deprecation for yarn.nodemanager.log-aggregation.compression-type
Handling deprecation for ipc.server.max.connections
Handling deprecation for yarn.resourcemanager.work-preserving-recovery.scheduling-wait-ms
Handling deprecation for yarn.nodemanager.log-dirs
Handling deprecation for yarn.app.mapreduce.am.resource.mb
Handling deprecation for hadoop.security.groups.cache.secs
Handling deprecation for mapreduce.job.speculative.minimum-allowed-tasks
Handling deprecation for yarn.nodemanager.container-monitor.interval-ms
Handling deprecation for dfs.datanode.cache.revocation.timeout.ms
Handling deprecation for mapreduce.jobhistory.recovery.store.class
Handling deprecation for mapreduce.task.combine.progress.records
Handling deprecation for s3.client-write-packet-size
Handling deprecation for mapreduce.jobtracker.instrumentation
Handling deprecation for dfs.replication
Handling deprecation for mapreduce.shuffle.transfer.buffer.size
Handling deprecation for hadoop.security.group.mapping.ldap.directory.search.timeout
Handling deprecation for dfs.datanode.available-space-volume-choosing-policy.balanced-space-threshold
Handling deprecation for hadoop.work.around.non.threadsafe.getpwuid
Handling deprecation for yarn.app.mapreduce.client-am.ipc.max-retries-on-timeouts
Handling deprecation for yarn.nodemanager.address
Handling deprecation for mapreduce.tasktracker.taskcontroller
Handling deprecation for mapreduce.tasktracker.indexcache.mb
Handling deprecation for yarn.scheduler.maximum-allocation-vcores
Handling deprecation for mapreduce.job.reduces
Handling deprecation for yarn.nodemanager.sleep-delay-before-sigkill.ms
Handling deprecation for yarn.timeline-service.address
Handling deprecation for yarn.resourcemanager.configuration.provider-class
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.expiry
Handling deprecation for yarn.sharedcache.enabled
Handling deprecation for tfile.io.chunk.size
Handling deprecation for mapreduce.job.acl-modify-job
Handling deprecation for hadoop.registry.zk.session.timeout.ms
Handling deprecation for fs.automatic.close
Handling deprecation for ha.health-monitor.sleep-after-disconnect.ms
Handling deprecation for mapreduce.tasktracker.reduce.tasks.maximum
Handling deprecation for mapreduce.input.fileinputformat.list-status.num-threads
Handling deprecation for dfs.datanode.directoryscan.threads
Handling deprecation for dfs.datanode.directoryscan.interval
Handling deprecation for dfs.namenode.acls.enabled
Handling deprecation for dfs.client.short.circuit.replica.stale.threshold.ms
Handling deprecation for hadoop.http.authentication.token.validity
Handling deprecation for fs.s3.block.size
Handling deprecation for ha.failover-controller.graceful-fence.rpc-timeout.ms
Handling deprecation for mapreduce.tasktracker.local.dir.minspacekill
Handling deprecation for dfs.namenode.resource.du.reserved
Handling deprecation for mapreduce.jobhistory.cleaner.interval-ms
Handling deprecation for dfs.namenode.datanode.registration.ip-hostname-check
Handling deprecation for mapreduce.jobhistory.intermediate-done-dir
Handling deprecation for mapreduce.jobtracker.http.address
Handling deprecation for dfs.namenode.backup.http-address
Handling deprecation for dfs.namenode.edits.noeditlogchannelflush
Handling deprecation for mapreduce.reduce.shuffle.input.buffer.percent
Handling deprecation for mapreduce.map.maxattempts
Handling deprecation for yarn.http.policy
Handling deprecation for dfs.namenode.audit.loggers
Handling deprecation for hadoop.security.groups.cache.warn.after.ms
Handling deprecation for io.serializations
Handling deprecation for mapreduce.tasktracker.outofband.heartbeat
Handling deprecation for mapreduce.reduce.shuffle.read.timeout
Handling deprecation for hadoop.security.crypto.buffer.size
Handling deprecation for mapreduce.reduce.skip.proc.count.autoincr
Handling deprecation for mapreduce.ifile.readahead.bytes
Handling deprecation for dfs.http.policy
Handling deprecation for hadoop.registry.secure
Handling deprecation for dfs.namenode.safemode.min.datanodes
Handling deprecation for dfs.client.file-block-storage-locations.num-threads
Handling deprecation for mapreduce.cluster.local.dir
Handling deprecation for mapreduce.tasktracker.report.address
Handling deprecation for dfs.namenode.secondary.https-address
Handling deprecation for hadoop.kerberos.kinit.command
Handling deprecation for yarn.timeline-service.http-authentication.type
Handling deprecation for dfs.block.access.token.lifetime
Handling deprecation for dfs.webhdfs.enabled
Handling deprecation for dfs.namenode.delegation.token.max-lifetime
Handling deprecation for dfs.namenode.avoid.write.stale.datanode
Handling deprecation for dfs.datanode.drop.cache.behind.writes
Handling deprecation for yarn.log-aggregation.retain-seconds
Handling deprecation for mapreduce.job.complete.cancel.delegation.tokens
Handling deprecation for mapreduce.local.clientfactory.class.name
Handling deprecation for mapreduce.shuffle.connection-keep-alive.timeout
Handling deprecation for dfs.namenode.num.extra.edits.retained
Handling deprecation for yarn.scheduler.minimum-allocation-vcores
Handling deprecation for ipc.client.connect.max.retries.on.timeouts
Handling deprecation for yarn.timeline-service.client.retry-interval-ms
Handling deprecation for yarn.timeline-service.client.max-retries
Handling deprecation for fs.s3n.block.size
Handling deprecation for mapreduce.job.map.output.collector.class
Handling deprecation for ha.health-monitor.connect-retry-interval.ms
Handling deprecation for mapreduce.shuffle.max.threads
Handling deprecation for nfs.exports.allowed.hosts
Handling deprecation for dfs.client.mmap.cache.size
Handling deprecation for mapreduce.tasktracker.map.tasks.maximum
Handling deprecation for io.file.buffer.size
Handling deprecation for dfs.client.datanode-restart.timeout
Handling deprecation for io.mapfile.bloom.size
Handling deprecation for hadoop.security.kms.client.authentication.retry-count
Handling deprecation for dfs.namenode.checkpoint.txns
Handling deprecation for ipc.client.connect.retry.interval
Handling deprecation for dfs.client-write-packet-size
Handling deprecation for mapreduce.reduce.shuffle.connect.timeout
Handling deprecation for yarn.resourcemanager.fs.state-store.uri
Handling deprecation for fs.swift.impl
Handling deprecation for hadoop.registry.zk.connection.timeout.ms
Handling deprecation for mapred.queue.default.acl-administer-jobs
Handling deprecation for mapreduce.job.submithostaddress
Handling deprecation for dfs.cachereport.intervalMsec
Handling deprecation for yarn.app.mapreduce.shuffle.log.backups
Handling deprecation for yarn.app.mapreduce.am.container.log.limit.kb
Handling deprecation for yarn.nodemanager.resourcemanager.minimum.version
Handling deprecation for ftp.blocksize
Handling deprecation for yarn.resourcemanager.address
Handling deprecation for file.stream-buffer-size
Handling deprecation for yarn.resourcemanager.scheduler.monitor.enable
Handling deprecation for mapreduce.job.ubertask.maxreduces
Handling deprecation for nfs.allow.insecure.ports
Handling deprecation for yarn.sharedcache.nm.uploader.thread-count
Handling deprecation for ipc.client.idlethreshold
Handling deprecation for ftp.stream-buffer-size
Handling deprecation for yarn.sharedcache.client-server.address
Handling deprecation for dfs.client.failover.connection.retries.on.timeouts
Handling deprecation for dfs.namenode.replication.work.multiplier.per.iteration
Handling deprecation for hadoop.http.authentication.simple.anonymous.allowed
Handling deprecation for hadoop.security.authorization
Handling deprecation for yarn.client.nodemanager-connect.retry-interval-ms
Handling deprecation for yarn.am.liveness-monitor.expiry-interval-ms
Handling deprecation for fs.har.impl.disable.cache
Handling deprecation for yarn.nodemanager.linux-container-executor.resources-handler.class
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.read-cache-size
Handling deprecation for hadoop.security.authentication
Handling deprecation for dfs.image.compression.codec
Handling deprecation for mapreduce.task.files.preserve.failedtasks
Handling deprecation for dfs.client.read.shortcircuit.streams.cache.size
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.path
Handling deprecation for mapreduce.job.reduce.slowstart.completedmaps
Handling deprecation for mapreduce.jobhistory.minicluster.fixed.ports
Handling deprecation for file.replication
Handling deprecation for yarn.resourcemanager.ha.automatic-failover.enabled
Handling deprecation for mapreduce.job.userlog.retain.hours
Handling deprecation for mapreduce.jobhistory.joblist.cache.size
Handling deprecation for dfs.namenode.accesstime.precision
Handling deprecation for yarn.resourcemanager.work-preserving-recovery.enabled
Handling deprecation for dfs.namenode.fs-limits.max-xattrs-per-inode
Handling deprecation for io.mapfile.bloom.error.rate
Handling deprecation for yarn.resourcemanager.store.class
Handling deprecation for dfs.image.transfer.timeout
Handling deprecation for yarn.timeline-service.leveldb-state-store.path
Handling deprecation for nfs.wtmax
Handling deprecation for mapreduce.job.combine.class
Handling deprecation for dfs.namenode.support.allow.format
Handling deprecation for fs.s3a.multipart.purge
Handling deprecation for dfs.secondary.namenode.kerberos.internal.spnego.principal
Handling deprecation for fs.s3a.connection.establish.timeout
Handling deprecation for dfs.stream-buffer-size
Handling deprecation for dfs.namenode.invalidate.work.pct.per.iteration
Handling deprecation for yarn.nodemanager.container-executor.class
Handling deprecation for fs.s3a.multipart.purge.age
Handling deprecation for yarn.resourcemanager.scheduler.client.thread-count
Handling deprecation for dfs.namenode.top.enabled
Handling deprecation for yarn.app.mapreduce.shuffle.log.separate
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.low-watermark
Handling deprecation for fs.s3a.fast.buffer.size
Handling deprecation for hadoop.user.group.static.mapping.overrides
Handling deprecation for tfile.fs.input.buffer.size
Handling deprecation for dfs.client.cached.conn.retry
Handling deprecation for hadoop.http.authentication.type
Handling deprecation for dfs.namenode.list.encryption.zones.num.responses
Handling deprecation for mapreduce.map.cpu.vcores
Handling deprecation for dfs.namenode.path.based.cache.refresh.interval.ms
Handling deprecation for dfs.namenode.decommission.interval
Handling deprecation for dfs.namenode.fs-limits.max-directory-items
Handling deprecation for yarn.resourcemanager.zk-retry-interval-ms
Handling deprecation for ftp.bytes-per-checksum
Handling deprecation for dfs.ha.log-roll.period
Handling deprecation for dfs.user.home.dir.prefix
Handling deprecation for ipc.client.fallback-to-simple-auth-allowed
Handling deprecation for yarn.nodemanager.pmem-check-enabled
Handling deprecation for yarn.nodemanager.remote-app-log-dir
Handling deprecation for dfs.namenode.inotify.max.events.per.rpc
Handling deprecation for mapreduce.task.profile.maps
Handling deprecation for mapreduce.shuffle.ssl.file.buffer.size
Handling deprecation for mapreduce.tasktracker.healthchecker.script.timeout
Handling deprecation for yarn.timeline-service.webapp.https.address
Handling deprecation for yarn.nodemanager.resource.percentage-physical-cpu-limit
Handling deprecation for yarn.app.mapreduce.am.command-opts
Handling deprecation for dfs.namenode.fs-limits.max-xattr-size
Handling deprecation for dfs.datanode.http.address
Handling deprecation for dfs.namenode.blocks.per.postponedblocks.rescan
Handling deprecation for yarn.sharedcache.nm.uploader.replication.factor
Handling deprecation for hadoop.registry.zk.root
Handling deprecation for hadoop.jetty.logs.serve.aliases
Handling deprecation for yarn.client.failover-proxy-provider
Handling deprecation for mapreduce.jobhistory.admin.acl
Handling deprecation for yarn.app.mapreduce.am.hard-kill-timeout-ms
Handling deprecation for yarn.nodemanager.remote-app-log-dir-suffix
Handling deprecation for mapreduce.jobhistory.principal
Handling deprecation for yarn.resourcemanager.webapp.address
Handling deprecation for mapreduce.jobhistory.recovery.enable
Handling deprecation for yarn.sharedcache.store.in-memory.check-period-mins
Handling deprecation for nfs.mountd.port
Handling deprecation for mapreduce.reduce.merge.inmem.threshold
Handling deprecation for fs.df.interval
Handling deprecation for yarn.timeline-service.enabled
Handling deprecation for mapreduce.jobtracker.jobhistory.lru.cache.size
Handling deprecation for mapreduce.task.profile
Handling deprecation for mapreduce.job.output.key.class
Handling deprecation for yarn.nodemanager.hostname
Handling deprecation for dfs.namenode.num.checkpoints.retained
Handling deprecation for mapreduce.job.queuename
Handling deprecation for mapreduce.jobhistory.max-age-ms
Handling deprecation for mapreduce.job.token.tracking.ids.enabled
Handling deprecation for yarn.nodemanager.localizer.client.thread-count
Handling deprecation for yarn.sharedcache.uploader.server.thread-count
Handling deprecation for dfs.client.mmap.retry.timeout.ms
Handling deprecation for mapreduce.jobhistory.move.thread-count
Handling deprecation for dfs.permissions.enabled
Handling deprecation for dfs.blockreport.split.threshold
Handling deprecation for fs.AbstractFileSystem.hdfs.impl
Handling deprecation for dfs.datanode.balance.bandwidthPerSec
Handling deprecation for dfs.block.scanner.volume.bytes.per.second
Handling deprecation for hadoop.http.filter.initializers
Handling deprecation for yarn.timeline-service.http-authentication.simple.anonymous.allowed
Handling deprecation for dfs.default.chunk.view.size
Handling deprecation for yarn.sharedcache.client-server.thread-count
Handling deprecation for yarn.resourcemanager.resource-tracker.address
Handling deprecation for mapreduce.job.working.dir
Handling deprecation for mapreduce.jobhistory.datestring.cache.size
Handling deprecation for mapreduce.task.profile.params
Handling deprecation for dfs.namenode.decommission.blocks.per.interval
Handling deprecation for dfs.namenode.handler.count
Handling deprecation for dfs.image.transfer.bandwidthPerSec
Handling deprecation for rpc.metrics.quantile.enable
Handling deprecation for mapreduce.jobtracker.expire.trackers.interval
Handling deprecation for mapreduce.task.timeout
Handling deprecation for yarn.app.mapreduce.client.max-retries
Handling deprecation for yarn.nodemanager.resource.memory-mb
Handling deprecation for yarn.nodemanager.disk-health-checker.min-healthy-disks
Handling deprecation for dfs.datanode.failed.volumes.tolerated
Handling deprecation for yarn.timeline-service.handler-thread-count
Handling deprecation for ipc.server.listen.queue.size
Handling deprecation for fs.s3a.threads.max
Handling deprecation for yarn.resourcemanager.connect.max-wait.ms
Handling deprecation for mapreduce.fileoutputcommitter.algorithm.version
Handling deprecation for mapreduce.framework.name
Handling deprecation for mapreduce.map.skip.proc.count.autoincr
Handling deprecation for mapreduce.job.max.split.locations
Handling deprecation for yarn.resourcemanager.scheduler.class
Handling deprecation for yarn.resourcemanager.system-metrics-publisher.enabled
Handling deprecation for dfs.blocksize
Handling deprecation for yarn.sharedcache.nested-level
Handling deprecation for mapreduce.shuffle.connection-keep-alive.enable
Handling deprecation for fs.s3a.threads.keepalivetime
Handling deprecation for fs.s3a.connection.timeout
Handling deprecation for file.client-write-packet-size
Handling deprecation for ha.failover-controller.cli-check.rpc-timeout.ms
Handling deprecation for ha.zookeeper.acl
Handling deprecation for dfs.namenode.write.stale.datanode.ratio
Handling deprecation for dfs.encrypt.data.transfer
Handling deprecation for dfs.datanode.shared.file.descriptor.paths
Handling deprecation for mapreduce.input.lineinputformat.linespermap
Handling deprecation for yarn.resourcemanager.delayed.delegation-token.removal-interval-ms
Handling deprecation for yarn.nodemanager.localizer.fetch.thread-count
Handling deprecation for dfs.client.failover.max.attempts
Handling deprecation for yarn.resourcemanager.scheduler.address
Handling deprecation for dfs.client.read.shortcircuit.streams.cache.expiry.ms
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.start-time-write-cache-size
Handling deprecation for yarn.nodemanager.health-checker.script.timeout-ms
Handling deprecation for yarn.resourcemanager.fs.state-store.num-retries
Handling deprecation for hadoop.ssl.require.client.cert
Handling deprecation for hadoop.security.uid.cache.secs
Handling deprecation for mapreduce.jobhistory.keytab
Handling deprecation for dfs.client.read.shortcircuit.skip.checksum
Handling deprecation for yarn.resourcemanager.ha.automatic-failover.zk-base-path
Handling deprecation for mapreduce.shuffle.ssl.enabled
Handling deprecation for mapreduce.reduce.log.level
Handling deprecation for hadoop.registry.rm.enabled
Handling deprecation for mapreduce.tasktracker.dns.interface
Handling deprecation for yarn.resourcemanager.system-metrics-publisher.dispatcher.pool-size
Handling deprecation for mapreduce.job.speculative.speculative-cap-running-tasks
Handling deprecation for dfs.datanode.block.id.layout.upgrade.threads
Handling deprecation for dfs.datanode.use.datanode.hostname
Handling deprecation for dfs.client.context
Handling deprecation for yarn.resourcemanager.ha.enabled
Handling deprecation for mapred.reducer.new-api
Handling deprecation for dfs.namenode.delegation.token.renew-interval
Handling deprecation for dfs.blockreport.intervalMsec
Handling deprecation for fs.s3a.multipart.threshold
Handling deprecation for mapreduce.reduce.shuffle.memory.limit.percent
Handling deprecation for dfs.https.server.keystore.resource
Handling deprecation for io.map.index.skip
Handling deprecation for mapreduce.job.hdfs-servers
Handling deprecation for mapreduce.jobtracker.taskscheduler
Handling deprecation for dfs.namenode.kerberos.internal.spnego.principal
Handling deprecation for yarn.resourcemanager.state-store.max-completed-applications
Handling deprecation for mapreduce.map.output.compress
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.num.refill.threads
Handling deprecation for fs.s3n.multipart.uploads.block.size
Handling deprecation for mapreduce.task.merge.progress.records
Handling deprecation for dfs.datanode.dns.interface
Handling deprecation for map.sort.class
Handling deprecation for yarn.nodemanager.aux-services.mapreduce_shuffle.class
Handling deprecation for tfile.fs.output.buffer.size
Handling deprecation for fs.du.interval
Handling deprecation for dfs.client.failover.connection.retries
Handling deprecation for dfs.namenode.top.window.num.buckets
Handling deprecation for mapreduce.job.dir
Handling deprecation for fs.s3a.buffer.dir
Handling deprecation for mapreduce.reduce.shuffle.retry-delay.max.ms
Handling deprecation for yarn.sharedcache.uploader.server.address
Handling deprecation for mapreduce.client.progressmonitor.pollinterval
Handling deprecation for yarn.app.mapreduce.shuffle.log.limit.kb
Handling deprecation for dfs.datanode.max.locked.memory
Handling deprecation for dfs.namenode.retrycache.expirytime.millis
Handling deprecation for dfs.datanode.scan.period.hours
Handling deprecation for dfs.client.block.write.replace-datanode-on-failure.best-effort
Handling deprecation for mapreduce.jobhistory.move.interval-ms
Handling deprecation for dfs.ha.fencing.ssh.connect-timeout
Handling deprecation for yarn.nodemanager.log-aggregation.roll-monitoring-interval-seconds
Handling deprecation for dfs.namenode.fs-limits.max-component-length
Handling deprecation for hadoop.registry.zk.quorum
Handling deprecation for dfs.namenode.enable.retrycache
Handling deprecation for dfs.datanode.du.reserved
Handling deprecation for yarn.timeline-service.state-store-class
Handling deprecation for dfs.datanode.ipc.address
Handling deprecation for hadoop.registry.system.acls
Handling deprecation for dfs.client.block.write.replace-datanode-on-failure.policy
Handling deprecation for dfs.namenode.path.based.cache.retry.interval.ms
Handling deprecation for hadoop.security.crypto.cipher.suite
Handling deprecation for dfs.ha.tail-edits.period
Handling deprecation for mapreduce.task.profile.reduce.params
Handling deprecation for hadoop.registry.jaas.context
Handling deprecation for yarn.resourcemanager.hostname
Handling deprecation for mapreduce.reduce.memory.mb
Handling deprecation for hadoop.security.group.mapping.ldap.search.filter.group
Handling deprecation for hadoop.http.authentication.kerberos.principal
Handling deprecation for hadoop.security.group.mapping.ldap.search.filter.user
Handling deprecation for yarn.nodemanager.disk-health-checker.min-free-space-per-disk-mb
Handling deprecation for dfs.namenode.edits.dir
Handling deprecation for yarn.client.failover-retries-on-socket-timeouts
Handling deprecation for dfs.namenode.decommission.max.concurrent.tracked.nodes
Handling deprecation for mapreduce.client.completion.pollinterval
Handling deprecation for dfs.namenode.name.dir.restore
Handling deprecation for dfs.namenode.secondary.http-address
Handling deprecation for mapreduce.jobhistory.recovery.store.leveldb.path
Handling deprecation for yarn.sharedcache.store.class
Handling deprecation for s3.bytes-per-checksum
Handling deprecation for yarn.nodemanager.windows-container.cpu-limit.enabled
Handling deprecation for yarn.resourcemanager.webapp.https.address
Handling deprecation for yarn.nodemanager.vmem-pmem-ratio
Handling deprecation for dfs.namenode.checkpoint.period
Handling deprecation for dfs.ha.automatic-failover.enabled
The url to track the job: http://localhost:8080/
Running job: job_local1582810212_0002
OutputCommitter set in config null
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
File Output Committer Algorithm version is 1
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
/user/michaeljones/wcOutput/_temporary/0: masked=rwxr-xr-x
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #35
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #35
Call: mkdirs took 7ms
Starting mapper thread pool executor.
Max local threads: 1
Map tasks to process: 1
Waiting for map tasks
Starting task: attempt_local1582810212_0002_m_000000_0
currentIndex 0   0:0
mapreduce.cluster.local.dir for child : /tmp/hadoop-michaeljones/mapred/local/localRunner//michaeljones/jobcache/job_local1582810212_0002/attempt_local1582810212_0002_m_000000_0
using new api for output committer
File Output Committer Algorithm version is 1
ProcfsBasedProcessTree currently is supported only on Linux.
 Using ResourceCalculatorProcessTree : null
Processing split: hdfs://localhost:9000/user/michaeljones/wcInput:0+50
Trying map output collector class: org.apache.hadoop.mapred.MapTask$MapOutputBuffer
(EQUATOR) 0 kvi 26214396(104857584)
mapreduce.task.io.sort.mb: 100
soft limit at 83886080
bufstart = 0; bufvoid = 104857600
kvstart = 26214396; length = 6553600
Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #36
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #36
Call: getBlockLocations took 3ms
newInfo = LocatedBlocks{
  fileLength=50
  underConstruction=false
  blocks=[LocatedBlock{BP-1045030256-10.0.0.2-1433119149314:blk_1073741825_1002; getBlockSize()=50; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-b42c5705-9ba4-4b14-b00b-f9194bb036f0,DISK]]}]
  lastLocatedBlock=LocatedBlock{BP-1045030256-10.0.0.2-1433119149314:blk_1073741825_1002; getBlockSize()=50; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-b42c5705-9ba4-4b14-b00b-f9194bb036f0,DISK]]}
  isLastBlockComplete=true}
Connecting to datanode 127.0.0.1:50010

Starting flush of map output
Spilling map output
bufstart = 0; bufend = 82; bufvoid = 104857600
kvstart = 26214396(104857584); kvend = 26214368(104857472); length = 29/6553600
Finished spill 0
Task:attempt_local1582810212_0002_m_000000_0 is done. And is in the process of committing
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #37
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #37
Call: getFileInfo took 3ms
map
Task 'attempt_local1582810212_0002_m_000000_0' done.
Finishing task: attempt_local1582810212_0002_m_000000_0
map task executor complete.
Starting reduce thread pool executor.
Max local threads: 1
Reduce tasks to process: 1
Waiting for reduce tasks
Starting task: attempt_local1582810212_0002_r_000000_0
currentIndex 0   0:0
mapreduce.cluster.local.dir for child : /tmp/hadoop-michaeljones/mapred/local/localRunner//michaeljones/jobcache/job_local1582810212_0002/attempt_local1582810212_0002_r_000000_0
using new api for output committer
File Output Committer Algorithm version is 1
ProcfsBasedProcessTree currently is supported only on Linux.
 Using ResourceCalculatorProcessTree : null
Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@3928c4ea
MergerManager: memoryLimit=668309888, maxSingleShuffleLimit=167077472, mergeThreshold=441084544, ioSortFactor=10, memToMemMergeOutputsThreshold=10
attempt_local1582810212_0002_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
Got 0 map completion events from 0
GetMapEventsThread about to sleep for 1000
LocalFetcher 2 going to fetch: attempt_local1582810212_0002_m_000000_0
attempt_local1582810212_0002_m_000000_0: Proceeding with shuffle since usedMemory (0) is lesser than memoryLimit (668309888).CommitMemory is (0)
localfetcher#2 about to shuffle output of map attempt_local1582810212_0002_m_000000_0 decomp: 63 len: 67 to MEMORY
Read 63 bytes from map-output for attempt_local1582810212_0002_m_000000_0
closeInMemoryFile -> map-output of size: 63, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->63
map attempt_local1582810212_0002_m_000000_0 done 1 / 1 copied.
EventFetcher is interrupted.. Returning
1 / 1 copied.
finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
Merging 1 sorted segments
Down to the last merge-pass, with 1 segments left of total size: 57 bytes
Merged 1 segments, 63 bytes to disk to satisfy reduce memory limit
Disk file: /tmp/hadoop-michaeljones/mapred/local/localRunner/michaeljones/jobcache/job_local1582810212_0002/attempt_local1582810212_0002_r_000000_0/output/map_0.out.merged Length is 67
Merging 1 files, 67 bytes from disk
Merging 0 segments, 0 bytes from memory into reduce
Merging 1 sorted segments
Down to the last merge-pass, with 1 segments left of total size: 57 bytes
1 / 1 copied.
/user/michaeljones/wcOutput/_temporary/0/_temporary/attempt_local1582810212_0002_r_000000_0/part-r-00000: masked=rw-r--r--
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #38
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #38
Call: create took 5ms
computePacketChunkSize: src=/user/michaeljones/wcOutput/_temporary/0/_temporary/attempt_local1582810212_0002_r_000000_0/part-r-00000, chunkSize=516, chunksPerPacket=126, packetSize=65016
DFSClient writeChunk allocating new packet seqno=0, src=/user/michaeljones/wcOutput/_temporary/0/_temporary/attempt_local1582810212_0002_r_000000_0/part-r-00000, packetSize=65016, chunksPerPacket=126, bytesCurBlock=0
Queued packet 0
Queued packet 1
Waiting for ack for: 1
Allocating new block
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #39
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #39
Call: addBlock took 3ms
pipeline = DatanodeInfoWithStorage[127.0.0.1:50010,DS-b42c5705-9ba4-4b14-b00b-f9194bb036f0,DISK]
Connecting to datanode 127.0.0.1:50010
Send buf size 131072
SASL client skipping handshake in unsecured configuration for addr = /127.0.0.1, datanodeId = DatanodeInfoWithStorage[127.0.0.1:50010,DS-b42c5705-9ba4-4b14-b00b-f9194bb036f0,DISK]
DataStreamer block BP-1045030256-10.0.0.2-1433119149314:blk_1073742266_1443 sending packet packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 41
DFSClient seqno: 0 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
DataStreamer block BP-1045030256-10.0.0.2-1433119149314:blk_1073742266_1443 sending packet packet seqno: 1 offsetInBlock: 41 lastPacketInBlock: true lastByteOffsetInBlock: 41
DFSClient seqno: 1 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
Closing old block BP-1045030256-10.0.0.2-1433119149314:blk_1073742266_1443
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #40
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #40
Call: complete took 2ms
Task:attempt_local1582810212_0002_r_000000_0 is done. And is in the process of committing
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #41
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #41
Call: getFileInfo took 2ms
1 / 1 copied.
Task attempt_local1582810212_0002_r_000000_0 is allowed to commit now
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #42
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #42
Call: getFileInfo took 2ms
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #43
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #43
Call: getFileInfo took 2ms
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #44
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #44
Call: rename took 3ms
Saved output of task 'attempt_local1582810212_0002_r_000000_0' to hdfs://localhost:9000/user/michaeljones/wcOutput/_temporary/0/task_local1582810212_0002_r_000000
reduce > reduce
Task 'attempt_local1582810212_0002_r_000000_0' done.
Finishing task: attempt_local1582810212_0002_r_000000_0
reduce task executor complete.
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #45
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #45
Call: getListing took 3ms
Merging data from FileStatus{path=hdfs://localhost:9000/user/michaeljones/wcOutput/_temporary/0/task_local1582810212_0002_r_000000; isDirectory=true; modification_time=1434167876465; access_time=0; owner=michaeljones; group=supergroup; permission=rwxr-xr-x; isSymlink=false} to hdfs://localhost:9000/user/michaeljones/wcOutput
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #46
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #46
Call: getFileInfo took 2ms
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #47
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #47
Call: getListing took 2ms
Merging data from FileStatus{path=hdfs://localhost:9000/user/michaeljones/wcOutput/_temporary/0/task_local1582810212_0002_r_000000/part-r-00000; isDirectory=false; length=41; replication=1; blocksize=134217728; modification_time=1434167876490; access_time=1434167876465; owner=michaeljones; group=supergroup; permission=rw-r--r--; isSymlink=false} to hdfs://localhost:9000/user/michaeljones/wcOutput/part-r-00000
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #48
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #48
Call: getFileInfo took 2ms
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #49
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #49
Call: rename took 2ms
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #50
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #50
Call: delete took 3ms
/user/michaeljones/wcOutput/_SUCCESS: masked=rw-r--r--
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #51
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #51
Call: create took 4ms
computePacketChunkSize: src=/user/michaeljones/wcOutput/_SUCCESS, chunkSize=516, chunksPerPacket=126, packetSize=65016
Waiting for ack for: -1
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #52
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #52
Call: complete took 3ms
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.fs.FileContext.getAbstractFileSystem(FileContext.java:331)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
Job job_local1582810212_0002 running in uber mode : false
 map 100% reduce 100%
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.getTaskCompletionEvents(Job.java:670)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.getTaskCompletionEvents(Job.java:670)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
Job job_local1582810212_0002 completed successfully
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.getCounters(Job.java:758)
Counters: 35
	File System Counters
		FILE: Number of bytes read=1206
		FILE: Number of bytes written=1128413
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=240
		HDFS: Number of bytes written=163
		HDFS: Number of read operations=45
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=24
	Map-Reduce Framework
		Map input records=2
		Map output records=8
		Map output bytes=82
		Map output materialized bytes=67
		Input split bytes=112
		Combine input records=8
		Combine output records=5
		Reduce input groups=5
		Reduce shuffle bytes=67
		Reduce input records=5
		Reduce output records=5
		Spilled Records=10
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=865075200
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=50
	File Output Format Counters 
		Bytes Written=41
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
RunJobAnalysisAsync
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #53
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #53
Call: getFileInfo took 5ms
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #54
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #54
Call: delete took 5ms
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.connect(Job.java:1256)
Trying ClientProtocolProvider : org.apache.hadoop.mapred.LocalClientProtocolProvider
Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
Picked org.apache.hadoop.mapred.LocalClientProtocolProvider as the ClientProtocolProvider
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Cluster.getFileSystem(Cluster.java:162)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.submit(Job.java:1287)
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #55
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #55
Call: getFileInfo took 4ms
Configuring job job_local87253821_0003 with file:/tmp/hadoop-michaeljones/mapred/staging/michaeljones87253821/.staging/job_local87253821_0003 as the submit dir
adding the following namenodes' delegation tokens:[hdfs://localhost:9000]
Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
default FileSystem: file:///
No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
Creating splits at file:/tmp/hadoop-michaeljones/mapred/staging/michaeljones87253821/.staging/job_local87253821_0003
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #56
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #56
Call: getFileInfo took 2ms
Time taken to get FileStatuses: 3
Total input paths to process : 1
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #57
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #57
Call: getBlockLocations took 2ms
Total # of splits generated by getSplits: 1, TimeTaken: 7
number of splits:1
Handling deprecation for all properties in config...
Handling deprecation for mapreduce.jobtracker.address
Handling deprecation for yarn.resourcemanager.scheduler.monitor.policies
Handling deprecation for dfs.namenode.resource.check.interval
Handling deprecation for mapreduce.jobhistory.client.thread-count
Handling deprecation for yarn.app.mapreduce.am.containerlauncher.threadpool-initial-size
Handling deprecation for mapred.child.java.opts
Handling deprecation for mapreduce.jobtracker.retiredjobs.cache.size
Handling deprecation for dfs.client.https.need-auth
Handling deprecation for yarn.admin.acl
Handling deprecation for yarn.app.mapreduce.am.job.committer.cancel-timeout
Handling deprecation for mapreduce.job.emit-timeline-data
Handling deprecation for fs.ftp.host.port
Handling deprecation for dfs.namenode.avoid.read.stale.datanode
Handling deprecation for dfs.journalnode.rpc-address
Handling deprecation for mapreduce.job.end-notification.retry.attempts
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.ttl-interval-ms
Handling deprecation for yarn.resourcemanager.leveldb-state-store.path
Handling deprecation for mapred.mapper.new-api
Handling deprecation for yarn.ipc.rpc.class
Handling deprecation for ipc.client.connection.maxidletime
Handling deprecation for yarn.nodemanager.process-kill-wait.ms
Handling deprecation for mapreduce.cluster.acls.enabled
Handling deprecation for mapreduce.jobtracker.handler.count
Handling deprecation for io.map.index.interval
Handling deprecation for dfs.namenode.https-address
Handling deprecation for mapreduce.task.profile.reduces
Handling deprecation for fs.s3n.multipart.uploads.enabled
Handling deprecation for io.seqfile.sorter.recordlimit
Handling deprecation for mapreduce.job.ubertask.maxmaps
Handling deprecation for mapreduce.tasktracker.tasks.sleeptimebeforesigkill
Handling deprecation for hadoop.util.hash.type
Handling deprecation for dfs.namenode.replication.min
Handling deprecation for yarn.nodemanager.container-manager.thread-count
Handling deprecation for mapreduce.jobtracker.jobhistory.block.size
Handling deprecation for dfs.namenode.fs-limits.min-block-size
Handling deprecation for mapreduce.app-submission.cross-platform
Handling deprecation for fs.AbstractFileSystem.file.impl
Handling deprecation for net.topology.script.number.args
Handling deprecation for yarn.resourcemanager.container-tokens.master-key-rolling-interval-secs
Handling deprecation for mapreduce.map.output.compress.codec
Handling deprecation for mapreduce.job.reducer.preempt.delay.sec
Handling deprecation for s3native.bytes-per-checksum
Handling deprecation for dfs.namenode.path.based.cache.block.map.allocation.percent
Handling deprecation for yarn.nodemanager.windows-container.memory-limit.enabled
Handling deprecation for mapreduce.input.fileinputformat.split.minsize
Handling deprecation for hadoop.security.group.mapping
Handling deprecation for mapreduce.jobtracker.system.dir
Handling deprecation for mapreduce.job.end-notification.max.attempts
Handling deprecation for mapreduce.reduce.markreset.buffer.percent
Handling deprecation for dfs.datanode.cache.revocation.polling.ms
Handling deprecation for mapreduce.reduce.speculative
Handling deprecation for yarn.nodemanager.localizer.cache.cleanup.interval-ms
Handling deprecation for dfs.namenode.lazypersist.file.scrub.interval.sec
Handling deprecation for fs.s3a.threads.core
Handling deprecation for mapreduce.jobhistory.recovery.store.fs.uri
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.start-time-read-cache-size
Handling deprecation for hadoop.registry.zk.retry.interval.ms
Handling deprecation for yarn.nodemanager.keytab
Handling deprecation for dfs.namenode.replication.interval
Handling deprecation for yarn.resourcemanager.admin.address
Handling deprecation for mapreduce.job.maps
Handling deprecation for nfs.dump.dir
Handling deprecation for mapreduce.job.user.name
Handling deprecation for mapreduce.jobtracker.maxtasks.perjob
Handling deprecation for mapreduce.job.ubertask.enable
Handling deprecation for mapreduce.job.reduce.class
Handling deprecation for yarn.nodemanager.delete.debug-delay-sec
Handling deprecation for yarn.timeline-service.ttl-enable
Handling deprecation for yarn.resourcemanager.fs.state-store.retry-policy-spec
Handling deprecation for mapreduce.reduce.skip.maxgroups
Handling deprecation for dfs.client.use.datanode.hostname
Handling deprecation for fs.trash.interval
Handling deprecation for mapreduce.job.name
Handling deprecation for mapreduce.am.max-attempts
Handling deprecation for mapreduce.jobtracker.heartbeats.in.second
Handling deprecation for yarn.resourcemanager.zk-num-retries
Handling deprecation for s3.blocksize
Handling deprecation for dfs.datanode.data.dir
Handling deprecation for mapreduce.jobtracker.persist.jobstatus.active
Handling deprecation for mapreduce.reduce.shuffle.parallelcopies
Handling deprecation for fs.s3.buffer.dir
Handling deprecation for mapreduce.jobhistory.done-dir
Handling deprecation for hadoop.security.instrumentation.requires.admin
Handling deprecation for hadoop.registry.zk.retry.ceiling.ms
Handling deprecation for nfs.rtmax
Handling deprecation for dfs.datanode.data.dir.perm
Handling deprecation for yarn.resourcemanager.container.liveness-monitor.interval-ms
Handling deprecation for yarn.nodemanager.env-whitelist
Handling deprecation for dfs.namenode.backup.address
Handling deprecation for dfs.namenode.xattrs.enabled
Handling deprecation for dfs.datanode.readahead.bytes
Handling deprecation for mapreduce.jobhistory.cleaner.enable
Handling deprecation for dfs.client.block.write.retries
Handling deprecation for mapreduce.tasktracker.http.address
Handling deprecation for yarn.nodemanager.linux-container-executor.cgroups.hierarchy
Handling deprecation for ha.failover-controller.graceful-fence.connection.retries
Handling deprecation for yarn.resourcemanager.recovery.enabled
Handling deprecation for yarn.app.mapreduce.am.container.log.backups
Handling deprecation for dfs.namenode.safemode.threshold-pct
Handling deprecation for yarn.nodemanager.disk-health-checker.interval-ms
Handling deprecation for hadoop.security.java.secure.random.algorithm
Handling deprecation for dfs.namenode.list.cache.directives.num.responses
Handling deprecation for dfs.datanode.dns.nameserver
Handling deprecation for mapreduce.cluster.temp.dir
Handling deprecation for fs.s3a.max.total.tasks
Handling deprecation for mapreduce.reduce.maxattempts
Handling deprecation for mapreduce.client.submit.file.replication
Handling deprecation for mapreduce.shuffle.port
Handling deprecation for yarn.resourcemanager.resource-tracker.client.thread-count
Handling deprecation for dfs.namenode.replication.considerLoad
Handling deprecation for dfs.namenode.edits.journal-plugin.qjournal
Handling deprecation for dfs.client.write.exclude.nodes.cache.expiry.interval.millis
Handling deprecation for yarn.nodemanager.delete.thread-count
Handling deprecation for dfs.client.mmap.cache.timeout.ms
Handling deprecation for yarn.nodemanager.admin-env
Handling deprecation for io.skip.checksum.errors
Handling deprecation for yarn.timeline-service.hostname
Handling deprecation for yarn.resourcemanager.proxy-user-privileges.enabled
Handling deprecation for mapreduce.job.speculative.speculative-cap-total-tasks
Handling deprecation for yarn.acl.enable
Handling deprecation for fs.s3a.fast.upload
Handling deprecation for file.blocksize
Handling deprecation for mapreduce.job.speculative.slowtaskthreshold
Handling deprecation for ftp.replication
Handling deprecation for yarn.sharedcache.cleaner.initial-delay-mins
Handling deprecation for s3native.client-write-packet-size
Handling deprecation for hadoop.rpc.socket.factory.class.default
Handling deprecation for file.bytes-per-checksum
Handling deprecation for dfs.datanode.slow.io.warning.threshold.ms
Handling deprecation for io.seqfile.lazydecompress
Handling deprecation for mapreduce.task.skip.start.attempts
Handling deprecation for dfs.namenode.reject-unresolved-dn-topology-mapping
Handling deprecation for hadoop.common.configuration.version
Handling deprecation for yarn.resourcemanager.client.thread-count
Handling deprecation for dfs.datanode.drop.cache.behind.reads
Handling deprecation for yarn.sharedcache.admin.address
Handling deprecation for mapreduce.job.output.value.class
Handling deprecation for mapreduce.output.fileoutputformat.outputdir
Handling deprecation for mapreduce.jobtracker.taskcache.levels
Handling deprecation for yarn.nodemanager.linux-container-executor.nonsecure-mode.user-pattern
Handling deprecation for yarn.resourcemanager.zk-timeout-ms
Handling deprecation for yarn.resourcemanager.max-completed-applications
Handling deprecation for mapreduce.job.jvm.numtasks
Handling deprecation for yarn.sharedcache.cleaner.period-mins
Handling deprecation for mapreduce.jobtracker.tasktracker.maxblacklists
Handling deprecation for dfs.namenode.top.num.users
Handling deprecation for yarn.nodemanager.linux-container-executor.cgroups.mount
Handling deprecation for yarn.sharedcache.checksum.algo.impl
Handling deprecation for mapreduce.job.end-notification.max.retry.interval
Handling deprecation for mapreduce.job.acl-view-job
Handling deprecation for mapreduce.job.classloader
Handling deprecation for yarn.log-aggregation-enable
Handling deprecation for mapreduce.reduce.shuffle.fetch.retry.interval-ms
Handling deprecation for yarn.resourcemanager.nodemanager.minimum.version
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.size
Handling deprecation for yarn.app.mapreduce.am.job.task.listener.thread-count
Handling deprecation for yarn.app.mapreduce.am.resource.cpu-vcores
Handling deprecation for dfs.namenode.edit.log.autoroll.check.interval.ms
Handling deprecation for mapreduce.output.fileoutputformat.compress.type
Handling deprecation for hadoop.hdfs.configuration.version
Handling deprecation for hadoop.security.group.mapping.ldap.search.attr.member
Handling deprecation for yarn.nodemanager.log.retain-seconds
Handling deprecation for yarn.nodemanager.local-cache.max-files-per-directory
Handling deprecation for mapreduce.job.end-notification.retry.interval
Handling deprecation for hadoop.ssl.client.conf
Handling deprecation for yarn.sharedcache.root-dir
Handling deprecation for dfs.journalnode.https-address
Handling deprecation for mapreduce.reduce.shuffle.fetch.retry.timeout-ms
Handling deprecation for dfs.bytes-per-checksum
Handling deprecation for dfs.namenode.max.objects
Handling deprecation for mapreduce.tasktracker.instrumentation
Handling deprecation for dfs.datanode.max.transfer.threads
Handling deprecation for dfs.block.access.key.update.interval
Handling deprecation for mapreduce.jobtracker.jobhistory.task.numberprogresssplits
Handling deprecation for mapreduce.map.memory.mb
Handling deprecation for ha.failover-controller.new-active.rpc-timeout.ms
Handling deprecation for hadoop.ssl.hostname.verifier
Handling deprecation for dfs.client.read.shortcircuit
Handling deprecation for dfs.datanode.hdfs-blocks-metadata.enabled
Handling deprecation for mapreduce.tasktracker.healthchecker.interval
Handling deprecation for dfs.image.transfer.chunksize
Handling deprecation for mapreduce.tasktracker.taskmemorymanager.monitoringinterval
Handling deprecation for dfs.client.https.keystore.resource
Handling deprecation for yarn.resourcemanager.connect.retry-interval.ms
Handling deprecation for yarn.timeline-service.webapp.address
Handling deprecation for s3native.blocksize
Handling deprecation for yarn.scheduler.minimum-allocation-mb
Handling deprecation for yarn.sharedcache.cleaner.resource-sleep-ms
Handling deprecation for net.topology.impl
Handling deprecation for dfs.client.failover.sleep.base.millis
Handling deprecation for dfs.permissions.superusergroup
Handling deprecation for io.seqfile.compress.blocksize
Handling deprecation for hadoop.registry.zk.retry.times
Handling deprecation for fs.AbstractFileSystem.ftp.impl
Handling deprecation for dfs.namenode.checkpoint.edits.dir
Handling deprecation for mapreduce.job.running.reduce.limit
Handling deprecation for dfs.blockreport.initialDelay
Handling deprecation for dfs.namenode.heartbeat.recheck-interval
Handling deprecation for dfs.namenode.safemode.extension
Handling deprecation for yarn.scheduler.maximum-allocation-mb
Handling deprecation for mapreduce.job.reduce.shuffle.consumer.plugin.class
Handling deprecation for yarn.nodemanager.vmem-check-enabled
Handling deprecation for mapreduce.task.io.sort.factor
Handling deprecation for mapreduce.jobtracker.persist.jobstatus.dir
Handling deprecation for dfs.client.failover.sleep.max.millis
Handling deprecation for dfs.namenode.delegation.key.update-interval
Handling deprecation for hadoop.rpc.protection
Handling deprecation for fs.permissions.umask-mode
Handling deprecation for fs.s3.sleepTimeSeconds
Handling deprecation for ha.health-monitor.rpc-timeout.ms
Handling deprecation for hadoop.http.staticuser.user
Handling deprecation for fs.s3a.connection.maximum
Handling deprecation for yarn.nodemanager.linux-container-executor.nonsecure-mode.limit-users
Handling deprecation for fs.s3a.paging.maximum
Handling deprecation for fs.AbstractFileSystem.viewfs.impl
Handling deprecation for fs.ftp.host
Handling deprecation for yarn.nodemanager.linux-container-executor.nonsecure-mode.local-user
Handling deprecation for fs.s3a.impl
Handling deprecation for hadoop.http.authentication.kerberos.keytab
Handling deprecation for dfs.namenode.fs-limits.max-blocks-per-file
Handling deprecation for mapreduce.tasktracker.http.threads
Handling deprecation for mapreduce.tasktracker.dns.nameserver
Handling deprecation for yarn.resourcemanager.am-rm-tokens.master-key-rolling-interval-secs
Handling deprecation for dfs.client.block.write.replace-datanode-on-failure.enable
Handling deprecation for io.compression.codec.bzip2.library
Handling deprecation for mapreduce.map.skip.maxrecords
Handling deprecation for dfs.client.use.legacy.blockreader.local
Handling deprecation for dfs.namenode.checkpoint.dir
Handling deprecation for dfs.namenode.top.windows.minutes
Handling deprecation for mapreduce.job.maxtaskfailures.per.tracker
Handling deprecation for net.topology.node.switch.mapping.impl
Handling deprecation for mapreduce.shuffle.max.connections
Handling deprecation for mapreduce.jobhistory.loadedjobs.cache.size
Handling deprecation for dfs.storage.policy.enabled
Handling deprecation for yarn.client.application-client-protocol.poll-interval-ms
Handling deprecation for yarn.nodemanager.localizer.address
Handling deprecation for dfs.namenode.list.cache.pools.num.responses
Handling deprecation for nfs.server.port
Handling deprecation for mapreduce.client.output.filter
Handling deprecation for yarn.timeline-service.client.best-effort
Handling deprecation for ha.zookeeper.parent-znode
Handling deprecation for mapreduce.jobtracker.persist.jobstatus.hours
Handling deprecation for yarn.sharedcache.admin.thread-count
Handling deprecation for yarn.nodemanager.resource.cpu-vcores
Handling deprecation for dfs.datanode.block-pinning.enabled
Handling deprecation for mapreduce.jobhistory.http.policy
Handling deprecation for yarn.resourcemanager.webapp.delegation-token-auth-filter.enabled
Handling deprecation for mapreduce.job.speculative.retry-after-no-speculate
Handling deprecation for fs.s3a.attempts.maximum
Handling deprecation for s3native.stream-buffer-size
Handling deprecation for io.seqfile.local.dir
Handling deprecation for yarn.log-aggregation.retain-check-interval-seconds
Handling deprecation for fs.s3n.multipart.copy.block.size
Handling deprecation for dfs.encrypt.data.transfer.cipher.key.bitlength
Handling deprecation for dfs.datanode.sync.behind.writes
Handling deprecation for yarn.resourcemanager.zk-acl
Handling deprecation for hadoop.ssl.keystores.factory.class
Handling deprecation for mapreduce.job.split.metainfo.maxsize
Handling deprecation for fs.s3.maxRetries
Handling deprecation for hadoop.security.random.device.file.path
Handling deprecation for yarn.client.nodemanager-connect.max-wait-ms
Handling deprecation for dfs.namenode.stale.datanode.interval
Handling deprecation for mapreduce.task.io.sort.mb
Handling deprecation for yarn.resourcemanager.zk-state-store.parent-path
Handling deprecation for yarn.app.mapreduce.client-am.ipc.max-retries
Handling deprecation for fs.client.resolve.remote.symlinks
Handling deprecation for yarn.nodemanager.linux-container-executor.cgroups.strict-resource-usage
Handling deprecation for hadoop.ssl.enabled.protocols
Handling deprecation for mapreduce.reduce.cpu.vcores
Handling deprecation for yarn.client.failover-retries
Handling deprecation for mapreduce.jobhistory.address
Handling deprecation for hadoop.ssl.enabled
Handling deprecation for dfs.replication.max
Handling deprecation for dfs.namenode.name.dir
Handling deprecation for dfs.datanode.https.address
Handling deprecation for ipc.client.kill.max
Handling deprecation for mapreduce.job.committer.setup.cleanup.needed
Handling deprecation for dfs.client.domain.socket.data.traffic
Handling deprecation for yarn.nodemanager.localizer.cache.target-size-mb
Handling deprecation for yarn.resourcemanager.admin.client.thread-count
Handling deprecation for dfs.block.access.token.enable
Handling deprecation for mapreduce.job.speculative.retry-after-speculate
Handling deprecation for dfs.datanode.address
Handling deprecation for mapreduce.jobtracker.restart.recover
Handling deprecation for ipc.client.connect.max.retries
Handling deprecation for yarn.timeline-service.store-class
Handling deprecation for dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
Handling deprecation for hadoop.tmp.dir
Handling deprecation for dfs.datanode.handler.count
Handling deprecation for yarn.resourcemanager.ha.automatic-failover.embedded
Handling deprecation for yarn.timeline-service.ttl-ms
Handling deprecation for mapreduce.task.profile.map.params
Handling deprecation for yarn.resourcemanager.nodemanagers.heartbeat-interval-ms
Handling deprecation for mapreduce.map.speculative
Handling deprecation for yarn.timeline-service.recovery.enabled
Handling deprecation for mapreduce.job.map.class
Handling deprecation for dfs.namenode.resource.checked.volumes.minimum
Handling deprecation for yarn.nodemanager.recovery.dir
Handling deprecation for mapreduce.job.counters.max
Handling deprecation for yarn.resourcemanager.keytab
Handling deprecation for dfs.namenode.max.extra.edits.segments.retained
Handling deprecation for dfs.webhdfs.user.provider.user.pattern
Handling deprecation for dfs.client.mmap.enabled
Handling deprecation for mapreduce.map.log.level
Handling deprecation for dfs.client.file-block-storage-locations.timeout.millis
Handling deprecation for yarn.client.max-cached-nodemanagers-proxies
Handling deprecation for yarn.app.mapreduce.am.scheduler.heartbeat.interval-ms
Handling deprecation for hadoop.fuse.timer.period
Handling deprecation for fs.trash.checkpoint.interval
Handling deprecation for yarn.sharedcache.app-checker.class
Handling deprecation for dfs.journalnode.http-address
Handling deprecation for yarn.app.mapreduce.am.staging-dir
Handling deprecation for mapreduce.tasktracker.local.dir.minspacestart
Handling deprecation for yarn.nm.liveness-monitor.expiry-interval-ms
Handling deprecation for ha.health-monitor.check-interval.ms
Handling deprecation for mapreduce.reduce.shuffle.merge.percent
Handling deprecation for dfs.namenode.retrycache.heap.percent
Handling deprecation for yarn.nodemanager.docker-container-executor.exec-name
Handling deprecation for ipc.client.connect.timeout
Handling deprecation for yarn.resourcemanager.fs.state-store.retry-interval-ms
Handling deprecation for mapreduce.output.fileoutputformat.compress
Handling deprecation for yarn.nodemanager.local-dirs
Handling deprecation for yarn.nodemanager.recovery.enabled
Handling deprecation for io.native.lib.available
Handling deprecation for yarn.sharedcache.store.in-memory.staleness-period-mins
Handling deprecation for yarn.resourcemanager.am.max-attempts
Handling deprecation for s3.replication
Handling deprecation for mapreduce.input.fileinputformat.inputdir
Handling deprecation for fs.AbstractFileSystem.har.impl
Handling deprecation for dfs.image.compress
Handling deprecation for mapreduce.job.running.map.limit
Handling deprecation for mapreduce.reduce.input.buffer.percent
Handling deprecation for yarn.nodemanager.webapp.address
Handling deprecation for dfs.datanode.available-space-volume-choosing-policy.balanced-space-preference-fraction
Handling deprecation for dfs.namenode.edit.log.autoroll.multiplier.threshold
Handling deprecation for hadoop.security.group.mapping.ldap.ssl
Handling deprecation for dfs.namenode.checkpoint.check.period
Handling deprecation for fs.defaultFS
Handling deprecation for fs.s3a.multipart.size
Handling deprecation for dfs.client.slow.io.warning.threshold.ms
Handling deprecation for yarn.app.mapreduce.am.job.committer.commit-window
Handling deprecation for hadoop.security.group.mapping.ldap.search.attr.group.name
Handling deprecation for yarn.nodemanager.disk-health-checker.max-disk-utilization-per-disk-percentage
Handling deprecation for yarn.nodemanager.container-monitor.procfs-tree.smaps-based-rss.enabled
Handling deprecation for mapreduce.job.submithostname
Handling deprecation for mapreduce.map.sort.spill.percent
Handling deprecation for hadoop.security.crypto.codec.classes.aes.ctr.nopadding
Handling deprecation for dfs.namenode.http-address
Handling deprecation for hadoop.security.groups.negative-cache.secs
Handling deprecation for hadoop.ssl.server.conf
Handling deprecation for mapreduce.ifile.readahead
Handling deprecation for s3native.replication
Handling deprecation for yarn.client.nodemanager-client-async.thread-pool-max-size
Handling deprecation for mapreduce.jobtracker.staging.root.dir
Handling deprecation for mapreduce.jobhistory.admin.address
Handling deprecation for dfs.namenode.startup.delay.block.deletion.sec
Handling deprecation for yarn.nodemanager.health-checker.interval-ms
Handling deprecation for dfs.namenode.checkpoint.max-retries
Handling deprecation for s3.stream-buffer-size
Handling deprecation for ftp.client-write-packet-size
Handling deprecation for dfs.datanode.fsdatasetcache.max.threads.per.volume
Handling deprecation for mapreduce.output.fileoutputformat.compress.codec
Handling deprecation for yarn.timeline-service.keytab
Handling deprecation for yarn.sharedcache.store.in-memory.initial-delay-mins
Handling deprecation for mapreduce.jobhistory.webapp.address
Handling deprecation for mapreduce.task.userlog.limit.kb
Handling deprecation for mapreduce.reduce.shuffle.fetch.retry.enabled
Handling deprecation for yarn.app.mapreduce.task.container.log.backups
Handling deprecation for dfs.heartbeat.interval
Handling deprecation for ha.zookeeper.session-timeout.ms
Handling deprecation for fs.s3a.connection.ssl.enabled
Handling deprecation for yarn.sharedcache.webapp.address
Handling deprecation for hadoop.http.authentication.signature.secret.file
Handling deprecation for hadoop.fuse.connection.timeout
Handling deprecation for mapreduce.input.fileinputformat.numinputfiles
Handling deprecation for yarn.nodemanager.log-aggregation.compression-type
Handling deprecation for ipc.server.max.connections
Handling deprecation for yarn.resourcemanager.work-preserving-recovery.scheduling-wait-ms
Handling deprecation for yarn.nodemanager.log-dirs
Handling deprecation for yarn.app.mapreduce.am.resource.mb
Handling deprecation for hadoop.security.groups.cache.secs
Handling deprecation for mapreduce.job.speculative.minimum-allowed-tasks
Handling deprecation for yarn.nodemanager.container-monitor.interval-ms
Handling deprecation for dfs.datanode.cache.revocation.timeout.ms
Handling deprecation for mapreduce.jobhistory.recovery.store.class
Handling deprecation for mapreduce.task.combine.progress.records
Handling deprecation for s3.client-write-packet-size
Handling deprecation for mapreduce.jobtracker.instrumentation
Handling deprecation for dfs.replication
Handling deprecation for mapreduce.shuffle.transfer.buffer.size
Handling deprecation for hadoop.security.group.mapping.ldap.directory.search.timeout
Handling deprecation for dfs.datanode.available-space-volume-choosing-policy.balanced-space-threshold
Handling deprecation for hadoop.work.around.non.threadsafe.getpwuid
Handling deprecation for yarn.app.mapreduce.client-am.ipc.max-retries-on-timeouts
Handling deprecation for yarn.nodemanager.address
Handling deprecation for mapreduce.tasktracker.taskcontroller
Handling deprecation for mapreduce.tasktracker.indexcache.mb
Handling deprecation for yarn.scheduler.maximum-allocation-vcores
Handling deprecation for mapreduce.job.reduces
Handling deprecation for yarn.nodemanager.sleep-delay-before-sigkill.ms
Handling deprecation for yarn.timeline-service.address
Handling deprecation for yarn.resourcemanager.configuration.provider-class
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.expiry
Handling deprecation for yarn.sharedcache.enabled
Handling deprecation for tfile.io.chunk.size
Handling deprecation for mapreduce.job.acl-modify-job
Handling deprecation for hadoop.registry.zk.session.timeout.ms
Handling deprecation for fs.automatic.close
Handling deprecation for ha.health-monitor.sleep-after-disconnect.ms
Handling deprecation for mapreduce.tasktracker.reduce.tasks.maximum
Handling deprecation for mapreduce.input.fileinputformat.list-status.num-threads
Handling deprecation for dfs.datanode.directoryscan.threads
Handling deprecation for dfs.datanode.directoryscan.interval
Handling deprecation for dfs.namenode.acls.enabled
Handling deprecation for dfs.client.short.circuit.replica.stale.threshold.ms
Handling deprecation for hadoop.http.authentication.token.validity
Handling deprecation for fs.s3.block.size
Handling deprecation for ha.failover-controller.graceful-fence.rpc-timeout.ms
Handling deprecation for mapreduce.tasktracker.local.dir.minspacekill
Handling deprecation for dfs.namenode.resource.du.reserved
Handling deprecation for mapreduce.jobhistory.cleaner.interval-ms
Handling deprecation for dfs.namenode.datanode.registration.ip-hostname-check
Handling deprecation for mapreduce.jobhistory.intermediate-done-dir
Handling deprecation for mapreduce.jobtracker.http.address
Handling deprecation for dfs.namenode.backup.http-address
Handling deprecation for dfs.namenode.edits.noeditlogchannelflush
Handling deprecation for mapreduce.reduce.shuffle.input.buffer.percent
Handling deprecation for mapreduce.map.maxattempts
Handling deprecation for yarn.http.policy
Handling deprecation for dfs.namenode.audit.loggers
Handling deprecation for hadoop.security.groups.cache.warn.after.ms
Handling deprecation for io.serializations
Handling deprecation for mapreduce.tasktracker.outofband.heartbeat
Handling deprecation for mapreduce.reduce.shuffle.read.timeout
Handling deprecation for hadoop.security.crypto.buffer.size
Handling deprecation for mapreduce.reduce.skip.proc.count.autoincr
Handling deprecation for mapreduce.ifile.readahead.bytes
Handling deprecation for dfs.http.policy
Handling deprecation for hadoop.registry.secure
Handling deprecation for dfs.namenode.safemode.min.datanodes
Handling deprecation for dfs.client.file-block-storage-locations.num-threads
Handling deprecation for mapreduce.cluster.local.dir
Handling deprecation for mapreduce.tasktracker.report.address
Handling deprecation for dfs.namenode.secondary.https-address
Handling deprecation for hadoop.kerberos.kinit.command
Handling deprecation for yarn.timeline-service.http-authentication.type
Handling deprecation for dfs.block.access.token.lifetime
Handling deprecation for dfs.webhdfs.enabled
Handling deprecation for dfs.namenode.delegation.token.max-lifetime
Handling deprecation for dfs.namenode.avoid.write.stale.datanode
Handling deprecation for dfs.datanode.drop.cache.behind.writes
Handling deprecation for yarn.log-aggregation.retain-seconds
Handling deprecation for mapreduce.job.complete.cancel.delegation.tokens
Handling deprecation for mapreduce.local.clientfactory.class.name
Handling deprecation for mapreduce.shuffle.connection-keep-alive.timeout
Handling deprecation for dfs.namenode.num.extra.edits.retained
Handling deprecation for yarn.scheduler.minimum-allocation-vcores
Handling deprecation for ipc.client.connect.max.retries.on.timeouts
Handling deprecation for yarn.timeline-service.client.retry-interval-ms
Handling deprecation for yarn.timeline-service.client.max-retries
Handling deprecation for fs.s3n.block.size
Handling deprecation for mapreduce.job.map.output.collector.class
Handling deprecation for ha.health-monitor.connect-retry-interval.ms
Handling deprecation for mapreduce.shuffle.max.threads
Handling deprecation for nfs.exports.allowed.hosts
Handling deprecation for dfs.client.mmap.cache.size
Handling deprecation for mapreduce.tasktracker.map.tasks.maximum
Handling deprecation for io.file.buffer.size
Handling deprecation for dfs.client.datanode-restart.timeout
Handling deprecation for io.mapfile.bloom.size
Handling deprecation for hadoop.security.kms.client.authentication.retry-count
Handling deprecation for dfs.namenode.checkpoint.txns
Handling deprecation for ipc.client.connect.retry.interval
Handling deprecation for dfs.client-write-packet-size
Handling deprecation for mapreduce.reduce.shuffle.connect.timeout
Handling deprecation for yarn.resourcemanager.fs.state-store.uri
Handling deprecation for fs.swift.impl
Handling deprecation for hadoop.registry.zk.connection.timeout.ms
Handling deprecation for mapred.queue.default.acl-administer-jobs
Handling deprecation for mapreduce.job.submithostaddress
Handling deprecation for dfs.cachereport.intervalMsec
Handling deprecation for yarn.app.mapreduce.shuffle.log.backups
Handling deprecation for yarn.app.mapreduce.am.container.log.limit.kb
Handling deprecation for yarn.nodemanager.resourcemanager.minimum.version
Handling deprecation for ftp.blocksize
Handling deprecation for yarn.resourcemanager.address
Handling deprecation for file.stream-buffer-size
Handling deprecation for yarn.resourcemanager.scheduler.monitor.enable
Handling deprecation for mapreduce.job.ubertask.maxreduces
Handling deprecation for nfs.allow.insecure.ports
Handling deprecation for yarn.sharedcache.nm.uploader.thread-count
Handling deprecation for ipc.client.idlethreshold
Handling deprecation for ftp.stream-buffer-size
Handling deprecation for yarn.sharedcache.client-server.address
Handling deprecation for dfs.client.failover.connection.retries.on.timeouts
Handling deprecation for dfs.namenode.replication.work.multiplier.per.iteration
Handling deprecation for hadoop.http.authentication.simple.anonymous.allowed
Handling deprecation for hadoop.security.authorization
Handling deprecation for yarn.client.nodemanager-connect.retry-interval-ms
Handling deprecation for yarn.am.liveness-monitor.expiry-interval-ms
Handling deprecation for fs.har.impl.disable.cache
Handling deprecation for yarn.nodemanager.linux-container-executor.resources-handler.class
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.read-cache-size
Handling deprecation for hadoop.security.authentication
Handling deprecation for dfs.image.compression.codec
Handling deprecation for mapreduce.task.files.preserve.failedtasks
Handling deprecation for dfs.client.read.shortcircuit.streams.cache.size
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.path
Handling deprecation for mapreduce.job.reduce.slowstart.completedmaps
Handling deprecation for mapreduce.jobhistory.minicluster.fixed.ports
Handling deprecation for file.replication
Handling deprecation for yarn.resourcemanager.ha.automatic-failover.enabled
Handling deprecation for mapreduce.job.userlog.retain.hours
Handling deprecation for mapreduce.jobhistory.joblist.cache.size
Handling deprecation for dfs.namenode.accesstime.precision
Handling deprecation for yarn.resourcemanager.work-preserving-recovery.enabled
Handling deprecation for dfs.namenode.fs-limits.max-xattrs-per-inode
Handling deprecation for io.mapfile.bloom.error.rate
Handling deprecation for yarn.resourcemanager.store.class
Handling deprecation for dfs.image.transfer.timeout
Handling deprecation for yarn.timeline-service.leveldb-state-store.path
Handling deprecation for nfs.wtmax
Handling deprecation for mapreduce.job.combine.class
Handling deprecation for dfs.namenode.support.allow.format
Handling deprecation for fs.s3a.multipart.purge
Handling deprecation for dfs.secondary.namenode.kerberos.internal.spnego.principal
Handling deprecation for fs.s3a.connection.establish.timeout
Handling deprecation for dfs.stream-buffer-size
Handling deprecation for dfs.namenode.invalidate.work.pct.per.iteration
Handling deprecation for yarn.nodemanager.container-executor.class
Handling deprecation for fs.s3a.multipart.purge.age
Handling deprecation for yarn.resourcemanager.scheduler.client.thread-count
Handling deprecation for dfs.namenode.top.enabled
Handling deprecation for yarn.app.mapreduce.shuffle.log.separate
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.low-watermark
Handling deprecation for fs.s3a.fast.buffer.size
Handling deprecation for hadoop.user.group.static.mapping.overrides
Handling deprecation for tfile.fs.input.buffer.size
Handling deprecation for dfs.client.cached.conn.retry
Handling deprecation for hadoop.http.authentication.type
Handling deprecation for dfs.namenode.list.encryption.zones.num.responses
Handling deprecation for mapreduce.map.cpu.vcores
Handling deprecation for dfs.namenode.path.based.cache.refresh.interval.ms
Handling deprecation for dfs.namenode.decommission.interval
Handling deprecation for dfs.namenode.fs-limits.max-directory-items
Handling deprecation for yarn.resourcemanager.zk-retry-interval-ms
Handling deprecation for ftp.bytes-per-checksum
Handling deprecation for dfs.ha.log-roll.period
Handling deprecation for dfs.user.home.dir.prefix
Handling deprecation for ipc.client.fallback-to-simple-auth-allowed
Handling deprecation for yarn.nodemanager.pmem-check-enabled
Handling deprecation for yarn.nodemanager.remote-app-log-dir
Handling deprecation for dfs.namenode.inotify.max.events.per.rpc
Handling deprecation for mapreduce.task.profile.maps
Handling deprecation for mapreduce.shuffle.ssl.file.buffer.size
Handling deprecation for mapreduce.tasktracker.healthchecker.script.timeout
Handling deprecation for yarn.timeline-service.webapp.https.address
Handling deprecation for yarn.nodemanager.resource.percentage-physical-cpu-limit
Handling deprecation for yarn.app.mapreduce.am.command-opts
Handling deprecation for dfs.namenode.fs-limits.max-xattr-size
Handling deprecation for dfs.datanode.http.address
Handling deprecation for dfs.namenode.blocks.per.postponedblocks.rescan
Handling deprecation for yarn.sharedcache.nm.uploader.replication.factor
Handling deprecation for hadoop.registry.zk.root
Handling deprecation for hadoop.jetty.logs.serve.aliases
Handling deprecation for yarn.client.failover-proxy-provider
Handling deprecation for mapreduce.jobhistory.admin.acl
Handling deprecation for yarn.app.mapreduce.am.hard-kill-timeout-ms
Handling deprecation for yarn.nodemanager.remote-app-log-dir-suffix
Handling deprecation for mapreduce.jobhistory.principal
Handling deprecation for yarn.resourcemanager.webapp.address
Handling deprecation for mapreduce.jobhistory.recovery.enable
Handling deprecation for yarn.sharedcache.store.in-memory.check-period-mins
Handling deprecation for nfs.mountd.port
Handling deprecation for mapreduce.reduce.merge.inmem.threshold
Handling deprecation for fs.df.interval
Handling deprecation for yarn.timeline-service.enabled
Handling deprecation for mapreduce.jobtracker.jobhistory.lru.cache.size
Handling deprecation for mapreduce.task.profile
Handling deprecation for mapreduce.job.output.key.class
Handling deprecation for yarn.nodemanager.hostname
Handling deprecation for dfs.namenode.num.checkpoints.retained
Handling deprecation for mapreduce.job.queuename
Handling deprecation for mapreduce.jobhistory.max-age-ms
Handling deprecation for mapreduce.job.token.tracking.ids.enabled
Handling deprecation for yarn.nodemanager.localizer.client.thread-count
Handling deprecation for yarn.sharedcache.uploader.server.thread-count
Handling deprecation for dfs.client.mmap.retry.timeout.ms
Handling deprecation for mapreduce.jobhistory.move.thread-count
Handling deprecation for dfs.permissions.enabled
Handling deprecation for dfs.blockreport.split.threshold
Handling deprecation for fs.AbstractFileSystem.hdfs.impl
Handling deprecation for dfs.datanode.balance.bandwidthPerSec
Handling deprecation for dfs.block.scanner.volume.bytes.per.second
Handling deprecation for hadoop.http.filter.initializers
Handling deprecation for yarn.timeline-service.http-authentication.simple.anonymous.allowed
Handling deprecation for dfs.default.chunk.view.size
Handling deprecation for yarn.sharedcache.client-server.thread-count
Handling deprecation for yarn.resourcemanager.resource-tracker.address
Handling deprecation for mapreduce.job.working.dir
Handling deprecation for mapreduce.jobhistory.datestring.cache.size
Handling deprecation for mapreduce.task.profile.params
Handling deprecation for dfs.namenode.decommission.blocks.per.interval
Handling deprecation for dfs.namenode.handler.count
Handling deprecation for dfs.image.transfer.bandwidthPerSec
Handling deprecation for rpc.metrics.quantile.enable
Handling deprecation for mapreduce.jobtracker.expire.trackers.interval
Handling deprecation for mapreduce.task.timeout
Handling deprecation for yarn.app.mapreduce.client.max-retries
Handling deprecation for yarn.nodemanager.resource.memory-mb
Handling deprecation for yarn.nodemanager.disk-health-checker.min-healthy-disks
Handling deprecation for dfs.datanode.failed.volumes.tolerated
Handling deprecation for yarn.timeline-service.handler-thread-count
Handling deprecation for ipc.server.listen.queue.size
Handling deprecation for fs.s3a.threads.max
Handling deprecation for yarn.resourcemanager.connect.max-wait.ms
Handling deprecation for mapreduce.fileoutputcommitter.algorithm.version
Handling deprecation for mapreduce.framework.name
Handling deprecation for mapreduce.map.skip.proc.count.autoincr
Handling deprecation for mapreduce.job.max.split.locations
Handling deprecation for yarn.resourcemanager.scheduler.class
Handling deprecation for yarn.resourcemanager.system-metrics-publisher.enabled
Handling deprecation for dfs.blocksize
Handling deprecation for yarn.sharedcache.nested-level
Handling deprecation for mapreduce.shuffle.connection-keep-alive.enable
Handling deprecation for fs.s3a.threads.keepalivetime
Handling deprecation for fs.s3a.connection.timeout
Handling deprecation for file.client-write-packet-size
Handling deprecation for ha.failover-controller.cli-check.rpc-timeout.ms
Handling deprecation for ha.zookeeper.acl
Handling deprecation for dfs.namenode.write.stale.datanode.ratio
Handling deprecation for dfs.encrypt.data.transfer
Handling deprecation for dfs.datanode.shared.file.descriptor.paths
Handling deprecation for mapreduce.input.lineinputformat.linespermap
Handling deprecation for yarn.resourcemanager.delayed.delegation-token.removal-interval-ms
Handling deprecation for yarn.nodemanager.localizer.fetch.thread-count
Handling deprecation for dfs.client.failover.max.attempts
Handling deprecation for yarn.resourcemanager.scheduler.address
Handling deprecation for dfs.client.read.shortcircuit.streams.cache.expiry.ms
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.start-time-write-cache-size
Handling deprecation for yarn.nodemanager.health-checker.script.timeout-ms
Handling deprecation for yarn.resourcemanager.fs.state-store.num-retries
Handling deprecation for hadoop.ssl.require.client.cert
Handling deprecation for hadoop.security.uid.cache.secs
Handling deprecation for mapreduce.jobhistory.keytab
Handling deprecation for dfs.client.read.shortcircuit.skip.checksum
Handling deprecation for yarn.resourcemanager.ha.automatic-failover.zk-base-path
Handling deprecation for mapreduce.shuffle.ssl.enabled
Handling deprecation for mapreduce.reduce.log.level
Handling deprecation for hadoop.registry.rm.enabled
Handling deprecation for mapreduce.tasktracker.dns.interface
Handling deprecation for yarn.resourcemanager.system-metrics-publisher.dispatcher.pool-size
Handling deprecation for mapreduce.job.speculative.speculative-cap-running-tasks
Handling deprecation for dfs.datanode.block.id.layout.upgrade.threads
Handling deprecation for dfs.datanode.use.datanode.hostname
Handling deprecation for dfs.client.context
Handling deprecation for yarn.resourcemanager.ha.enabled
Handling deprecation for mapred.reducer.new-api
Handling deprecation for dfs.namenode.delegation.token.renew-interval
Handling deprecation for dfs.blockreport.intervalMsec
Handling deprecation for fs.s3a.multipart.threshold
Handling deprecation for mapreduce.reduce.shuffle.memory.limit.percent
Handling deprecation for dfs.https.server.keystore.resource
Handling deprecation for io.map.index.skip
Handling deprecation for mapreduce.job.hdfs-servers
Handling deprecation for mapreduce.jobtracker.taskscheduler
Handling deprecation for dfs.namenode.kerberos.internal.spnego.principal
Handling deprecation for yarn.resourcemanager.state-store.max-completed-applications
Handling deprecation for mapreduce.map.output.compress
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.num.refill.threads
Handling deprecation for fs.s3n.multipart.uploads.block.size
Handling deprecation for mapreduce.task.merge.progress.records
Handling deprecation for dfs.datanode.dns.interface
Handling deprecation for map.sort.class
Handling deprecation for yarn.nodemanager.aux-services.mapreduce_shuffle.class
Handling deprecation for tfile.fs.output.buffer.size
Handling deprecation for fs.du.interval
Handling deprecation for dfs.client.failover.connection.retries
Handling deprecation for dfs.namenode.top.window.num.buckets
Handling deprecation for mapreduce.job.dir
Handling deprecation for fs.s3a.buffer.dir
Handling deprecation for mapreduce.reduce.shuffle.retry-delay.max.ms
Handling deprecation for yarn.sharedcache.uploader.server.address
Handling deprecation for mapreduce.client.progressmonitor.pollinterval
Handling deprecation for yarn.app.mapreduce.shuffle.log.limit.kb
Handling deprecation for dfs.datanode.max.locked.memory
Handling deprecation for dfs.namenode.retrycache.expirytime.millis
Handling deprecation for dfs.datanode.scan.period.hours
Handling deprecation for dfs.client.block.write.replace-datanode-on-failure.best-effort
Handling deprecation for mapreduce.jobhistory.move.interval-ms
Handling deprecation for dfs.ha.fencing.ssh.connect-timeout
Handling deprecation for yarn.nodemanager.log-aggregation.roll-monitoring-interval-seconds
Handling deprecation for dfs.namenode.fs-limits.max-component-length
Handling deprecation for hadoop.registry.zk.quorum
Handling deprecation for dfs.namenode.enable.retrycache
Handling deprecation for dfs.datanode.du.reserved
Handling deprecation for yarn.timeline-service.state-store-class
Handling deprecation for dfs.datanode.ipc.address
Handling deprecation for hadoop.registry.system.acls
Handling deprecation for dfs.client.block.write.replace-datanode-on-failure.policy
Handling deprecation for dfs.namenode.path.based.cache.retry.interval.ms
Handling deprecation for hadoop.security.crypto.cipher.suite
Handling deprecation for dfs.ha.tail-edits.period
Handling deprecation for mapreduce.task.profile.reduce.params
Handling deprecation for hadoop.registry.jaas.context
Handling deprecation for yarn.resourcemanager.hostname
Handling deprecation for mapreduce.reduce.memory.mb
Handling deprecation for hadoop.security.group.mapping.ldap.search.filter.group
Handling deprecation for hadoop.http.authentication.kerberos.principal
Handling deprecation for hadoop.security.group.mapping.ldap.search.filter.user
Handling deprecation for yarn.nodemanager.disk-health-checker.min-free-space-per-disk-mb
Handling deprecation for dfs.namenode.edits.dir
Handling deprecation for yarn.client.failover-retries-on-socket-timeouts
Handling deprecation for dfs.namenode.decommission.max.concurrent.tracked.nodes
Handling deprecation for mapreduce.client.completion.pollinterval
Handling deprecation for dfs.namenode.name.dir.restore
Handling deprecation for dfs.namenode.secondary.http-address
Handling deprecation for mapreduce.jobhistory.recovery.store.leveldb.path
Handling deprecation for yarn.sharedcache.store.class
Handling deprecation for s3.bytes-per-checksum
Handling deprecation for yarn.nodemanager.windows-container.cpu-limit.enabled
Handling deprecation for yarn.resourcemanager.webapp.https.address
Handling deprecation for yarn.nodemanager.vmem-pmem-ratio
Handling deprecation for dfs.namenode.checkpoint.period
Handling deprecation for dfs.ha.automatic-failover.enabled
Submitting tokens for job: job_local87253821_0003
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.fs.FileContext.getAbstractFileSystem(FileContext.java:331)
Handling deprecation for all properties in config...
Handling deprecation for mapreduce.jobtracker.address
Handling deprecation for yarn.resourcemanager.scheduler.monitor.policies
Handling deprecation for dfs.namenode.resource.check.interval
Handling deprecation for mapreduce.jobhistory.client.thread-count
Handling deprecation for yarn.app.mapreduce.am.containerlauncher.threadpool-initial-size
Handling deprecation for mapred.child.java.opts
Handling deprecation for mapreduce.jobtracker.retiredjobs.cache.size
Handling deprecation for dfs.client.https.need-auth
Handling deprecation for yarn.admin.acl
Handling deprecation for yarn.app.mapreduce.am.job.committer.cancel-timeout
Handling deprecation for mapreduce.job.emit-timeline-data
Handling deprecation for fs.ftp.host.port
Handling deprecation for dfs.namenode.avoid.read.stale.datanode
Handling deprecation for dfs.journalnode.rpc-address
Handling deprecation for mapreduce.job.end-notification.retry.attempts
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.ttl-interval-ms
Handling deprecation for yarn.resourcemanager.leveldb-state-store.path
Handling deprecation for mapred.mapper.new-api
Handling deprecation for yarn.ipc.rpc.class
Handling deprecation for ipc.client.connection.maxidletime
Handling deprecation for yarn.nodemanager.process-kill-wait.ms
Handling deprecation for mapreduce.cluster.acls.enabled
Handling deprecation for mapreduce.jobtracker.handler.count
Handling deprecation for io.map.index.interval
Handling deprecation for dfs.namenode.https-address
Handling deprecation for mapreduce.task.profile.reduces
Handling deprecation for fs.s3n.multipart.uploads.enabled
Handling deprecation for io.seqfile.sorter.recordlimit
Handling deprecation for mapreduce.job.ubertask.maxmaps
Handling deprecation for mapreduce.tasktracker.tasks.sleeptimebeforesigkill
Handling deprecation for hadoop.util.hash.type
Handling deprecation for dfs.namenode.replication.min
Handling deprecation for yarn.nodemanager.container-manager.thread-count
Handling deprecation for mapreduce.jobtracker.jobhistory.block.size
Handling deprecation for dfs.namenode.fs-limits.min-block-size
Handling deprecation for mapreduce.app-submission.cross-platform
Handling deprecation for fs.AbstractFileSystem.file.impl
Handling deprecation for net.topology.script.number.args
Handling deprecation for yarn.resourcemanager.container-tokens.master-key-rolling-interval-secs
Handling deprecation for mapreduce.map.output.compress.codec
Handling deprecation for mapreduce.job.reducer.preempt.delay.sec
Handling deprecation for s3native.bytes-per-checksum
Handling deprecation for dfs.namenode.path.based.cache.block.map.allocation.percent
Handling deprecation for yarn.nodemanager.windows-container.memory-limit.enabled
Handling deprecation for mapreduce.input.fileinputformat.split.minsize
Handling deprecation for hadoop.security.group.mapping
Handling deprecation for mapreduce.jobtracker.system.dir
Handling deprecation for mapreduce.job.end-notification.max.attempts
Handling deprecation for mapreduce.reduce.markreset.buffer.percent
Handling deprecation for dfs.datanode.cache.revocation.polling.ms
Handling deprecation for mapreduce.reduce.speculative
Handling deprecation for yarn.nodemanager.localizer.cache.cleanup.interval-ms
Handling deprecation for dfs.namenode.lazypersist.file.scrub.interval.sec
Handling deprecation for fs.s3a.threads.core
Handling deprecation for mapreduce.jobhistory.recovery.store.fs.uri
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.start-time-read-cache-size
Handling deprecation for hadoop.registry.zk.retry.interval.ms
Handling deprecation for yarn.nodemanager.keytab
Handling deprecation for dfs.namenode.replication.interval
Handling deprecation for yarn.resourcemanager.admin.address
Handling deprecation for mapreduce.job.maps
Handling deprecation for nfs.dump.dir
Handling deprecation for mapreduce.job.user.name
Handling deprecation for mapreduce.jobtracker.maxtasks.perjob
Handling deprecation for mapreduce.job.ubertask.enable
Handling deprecation for mapreduce.job.reduce.class
Handling deprecation for yarn.nodemanager.delete.debug-delay-sec
Handling deprecation for yarn.timeline-service.ttl-enable
Handling deprecation for yarn.resourcemanager.fs.state-store.retry-policy-spec
Handling deprecation for mapreduce.reduce.skip.maxgroups
Handling deprecation for dfs.client.use.datanode.hostname
Handling deprecation for fs.trash.interval
Handling deprecation for mapreduce.job.name
Handling deprecation for mapreduce.am.max-attempts
Handling deprecation for mapreduce.jobtracker.heartbeats.in.second
Handling deprecation for yarn.resourcemanager.zk-num-retries
Handling deprecation for s3.blocksize
Handling deprecation for dfs.datanode.data.dir
Handling deprecation for mapreduce.jobtracker.persist.jobstatus.active
Handling deprecation for mapreduce.reduce.shuffle.parallelcopies
Handling deprecation for fs.s3.buffer.dir
Handling deprecation for mapreduce.jobhistory.done-dir
Handling deprecation for hadoop.security.instrumentation.requires.admin
Handling deprecation for hadoop.registry.zk.retry.ceiling.ms
Handling deprecation for nfs.rtmax
Handling deprecation for dfs.datanode.data.dir.perm
Handling deprecation for yarn.resourcemanager.container.liveness-monitor.interval-ms
Handling deprecation for yarn.nodemanager.env-whitelist
Handling deprecation for dfs.namenode.backup.address
Handling deprecation for dfs.namenode.xattrs.enabled
Handling deprecation for dfs.datanode.readahead.bytes
Handling deprecation for mapreduce.jobhistory.cleaner.enable
Handling deprecation for dfs.client.block.write.retries
Handling deprecation for mapreduce.tasktracker.http.address
Handling deprecation for yarn.nodemanager.linux-container-executor.cgroups.hierarchy
Handling deprecation for ha.failover-controller.graceful-fence.connection.retries
Handling deprecation for yarn.resourcemanager.recovery.enabled
Handling deprecation for yarn.app.mapreduce.am.container.log.backups
Handling deprecation for dfs.namenode.safemode.threshold-pct
Handling deprecation for yarn.nodemanager.disk-health-checker.interval-ms
Handling deprecation for hadoop.security.java.secure.random.algorithm
Handling deprecation for dfs.namenode.list.cache.directives.num.responses
Handling deprecation for dfs.datanode.dns.nameserver
Handling deprecation for mapreduce.cluster.temp.dir
Handling deprecation for fs.s3a.max.total.tasks
Handling deprecation for mapreduce.reduce.maxattempts
Handling deprecation for mapreduce.client.submit.file.replication
Handling deprecation for mapreduce.shuffle.port
Handling deprecation for yarn.resourcemanager.resource-tracker.client.thread-count
Handling deprecation for dfs.namenode.replication.considerLoad
Handling deprecation for dfs.namenode.edits.journal-plugin.qjournal
Handling deprecation for dfs.client.write.exclude.nodes.cache.expiry.interval.millis
Handling deprecation for yarn.nodemanager.delete.thread-count
Handling deprecation for dfs.client.mmap.cache.timeout.ms
Handling deprecation for yarn.nodemanager.admin-env
Handling deprecation for io.skip.checksum.errors
Handling deprecation for yarn.timeline-service.hostname
Handling deprecation for yarn.resourcemanager.proxy-user-privileges.enabled
Handling deprecation for mapreduce.job.speculative.speculative-cap-total-tasks
Handling deprecation for yarn.acl.enable
Handling deprecation for fs.s3a.fast.upload
Handling deprecation for file.blocksize
Handling deprecation for mapreduce.job.speculative.slowtaskthreshold
Handling deprecation for ftp.replication
Handling deprecation for yarn.sharedcache.cleaner.initial-delay-mins
Handling deprecation for s3native.client-write-packet-size
Handling deprecation for hadoop.rpc.socket.factory.class.default
Handling deprecation for file.bytes-per-checksum
Handling deprecation for dfs.datanode.slow.io.warning.threshold.ms
Handling deprecation for io.seqfile.lazydecompress
Handling deprecation for mapreduce.task.skip.start.attempts
Handling deprecation for dfs.namenode.reject-unresolved-dn-topology-mapping
Handling deprecation for hadoop.common.configuration.version
Handling deprecation for yarn.resourcemanager.client.thread-count
Handling deprecation for dfs.datanode.drop.cache.behind.reads
Handling deprecation for yarn.sharedcache.admin.address
Handling deprecation for mapreduce.job.output.value.class
Handling deprecation for mapreduce.output.fileoutputformat.outputdir
Handling deprecation for mapreduce.jobtracker.taskcache.levels
Handling deprecation for yarn.nodemanager.linux-container-executor.nonsecure-mode.user-pattern
Handling deprecation for yarn.resourcemanager.zk-timeout-ms
Handling deprecation for yarn.resourcemanager.max-completed-applications
Handling deprecation for mapreduce.job.jvm.numtasks
Handling deprecation for yarn.sharedcache.cleaner.period-mins
Handling deprecation for mapreduce.jobtracker.tasktracker.maxblacklists
Handling deprecation for dfs.namenode.top.num.users
Handling deprecation for yarn.nodemanager.linux-container-executor.cgroups.mount
Handling deprecation for yarn.sharedcache.checksum.algo.impl
Handling deprecation for mapreduce.job.end-notification.max.retry.interval
Handling deprecation for mapreduce.job.acl-view-job
Handling deprecation for mapreduce.job.classloader
Handling deprecation for yarn.log-aggregation-enable
Handling deprecation for mapreduce.reduce.shuffle.fetch.retry.interval-ms
Handling deprecation for yarn.resourcemanager.nodemanager.minimum.version
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.size
Handling deprecation for yarn.app.mapreduce.am.job.task.listener.thread-count
Handling deprecation for yarn.app.mapreduce.am.resource.cpu-vcores
Handling deprecation for dfs.namenode.edit.log.autoroll.check.interval.ms
Handling deprecation for mapreduce.output.fileoutputformat.compress.type
Handling deprecation for hadoop.hdfs.configuration.version
Handling deprecation for hadoop.security.group.mapping.ldap.search.attr.member
Handling deprecation for yarn.nodemanager.log.retain-seconds
Handling deprecation for yarn.nodemanager.local-cache.max-files-per-directory
Handling deprecation for mapreduce.job.end-notification.retry.interval
Handling deprecation for hadoop.ssl.client.conf
Handling deprecation for yarn.sharedcache.root-dir
Handling deprecation for dfs.journalnode.https-address
Handling deprecation for mapreduce.reduce.shuffle.fetch.retry.timeout-ms
Handling deprecation for dfs.bytes-per-checksum
Handling deprecation for dfs.namenode.max.objects
Handling deprecation for mapreduce.tasktracker.instrumentation
Handling deprecation for dfs.datanode.max.transfer.threads
Handling deprecation for dfs.block.access.key.update.interval
Handling deprecation for mapreduce.jobtracker.jobhistory.task.numberprogresssplits
Handling deprecation for mapreduce.map.memory.mb
Handling deprecation for ha.failover-controller.new-active.rpc-timeout.ms
Handling deprecation for hadoop.ssl.hostname.verifier
Handling deprecation for dfs.client.read.shortcircuit
Handling deprecation for dfs.datanode.hdfs-blocks-metadata.enabled
Handling deprecation for mapreduce.tasktracker.healthchecker.interval
Handling deprecation for dfs.image.transfer.chunksize
Handling deprecation for mapreduce.tasktracker.taskmemorymanager.monitoringinterval
Handling deprecation for dfs.client.https.keystore.resource
Handling deprecation for yarn.resourcemanager.connect.retry-interval.ms
Handling deprecation for yarn.timeline-service.webapp.address
Handling deprecation for s3native.blocksize
Handling deprecation for yarn.scheduler.minimum-allocation-mb
Handling deprecation for yarn.sharedcache.cleaner.resource-sleep-ms
Handling deprecation for net.topology.impl
Handling deprecation for dfs.client.failover.sleep.base.millis
Handling deprecation for dfs.permissions.superusergroup
Handling deprecation for io.seqfile.compress.blocksize
Handling deprecation for hadoop.registry.zk.retry.times
Handling deprecation for fs.AbstractFileSystem.ftp.impl
Handling deprecation for dfs.namenode.checkpoint.edits.dir
Handling deprecation for mapreduce.job.running.reduce.limit
Handling deprecation for dfs.blockreport.initialDelay
Handling deprecation for dfs.namenode.heartbeat.recheck-interval
Handling deprecation for dfs.namenode.safemode.extension
Handling deprecation for yarn.scheduler.maximum-allocation-mb
Handling deprecation for mapreduce.job.reduce.shuffle.consumer.plugin.class
Handling deprecation for yarn.nodemanager.vmem-check-enabled
Handling deprecation for mapreduce.task.io.sort.factor
Handling deprecation for mapreduce.jobtracker.persist.jobstatus.dir
Handling deprecation for dfs.client.failover.sleep.max.millis
Handling deprecation for dfs.namenode.delegation.key.update-interval
Handling deprecation for hadoop.rpc.protection
Handling deprecation for fs.permissions.umask-mode
Handling deprecation for fs.s3.sleepTimeSeconds
Handling deprecation for ha.health-monitor.rpc-timeout.ms
Handling deprecation for hadoop.http.staticuser.user
Handling deprecation for fs.s3a.connection.maximum
Handling deprecation for yarn.nodemanager.linux-container-executor.nonsecure-mode.limit-users
Handling deprecation for fs.s3a.paging.maximum
Handling deprecation for fs.AbstractFileSystem.viewfs.impl
Handling deprecation for fs.ftp.host
Handling deprecation for yarn.nodemanager.linux-container-executor.nonsecure-mode.local-user
Handling deprecation for fs.s3a.impl
Handling deprecation for hadoop.http.authentication.kerberos.keytab
Handling deprecation for dfs.namenode.fs-limits.max-blocks-per-file
Handling deprecation for mapreduce.tasktracker.http.threads
Handling deprecation for mapreduce.tasktracker.dns.nameserver
Handling deprecation for yarn.resourcemanager.am-rm-tokens.master-key-rolling-interval-secs
Handling deprecation for dfs.client.block.write.replace-datanode-on-failure.enable
Handling deprecation for io.compression.codec.bzip2.library
Handling deprecation for mapreduce.map.skip.maxrecords
Handling deprecation for dfs.client.use.legacy.blockreader.local
Handling deprecation for dfs.namenode.checkpoint.dir
Handling deprecation for dfs.namenode.top.windows.minutes
Handling deprecation for mapreduce.job.maxtaskfailures.per.tracker
Handling deprecation for net.topology.node.switch.mapping.impl
Handling deprecation for mapreduce.shuffle.max.connections
Handling deprecation for mapreduce.jobhistory.loadedjobs.cache.size
Handling deprecation for dfs.storage.policy.enabled
Handling deprecation for yarn.client.application-client-protocol.poll-interval-ms
Handling deprecation for yarn.nodemanager.localizer.address
Handling deprecation for dfs.namenode.list.cache.pools.num.responses
Handling deprecation for nfs.server.port
Handling deprecation for mapreduce.client.output.filter
Handling deprecation for yarn.timeline-service.client.best-effort
Handling deprecation for ha.zookeeper.parent-znode
Handling deprecation for mapreduce.jobtracker.persist.jobstatus.hours
Handling deprecation for yarn.sharedcache.admin.thread-count
Handling deprecation for yarn.nodemanager.resource.cpu-vcores
Handling deprecation for dfs.datanode.block-pinning.enabled
Handling deprecation for mapreduce.jobhistory.http.policy
Handling deprecation for yarn.resourcemanager.webapp.delegation-token-auth-filter.enabled
Handling deprecation for mapreduce.job.speculative.retry-after-no-speculate
Handling deprecation for fs.s3a.attempts.maximum
Handling deprecation for s3native.stream-buffer-size
Handling deprecation for io.seqfile.local.dir
Handling deprecation for yarn.log-aggregation.retain-check-interval-seconds
Handling deprecation for fs.s3n.multipart.copy.block.size
Handling deprecation for dfs.encrypt.data.transfer.cipher.key.bitlength
Handling deprecation for dfs.datanode.sync.behind.writes
Handling deprecation for yarn.resourcemanager.zk-acl
Handling deprecation for hadoop.ssl.keystores.factory.class
Handling deprecation for mapreduce.job.split.metainfo.maxsize
Handling deprecation for fs.s3.maxRetries
Handling deprecation for hadoop.security.random.device.file.path
Handling deprecation for yarn.client.nodemanager-connect.max-wait-ms
Handling deprecation for dfs.namenode.stale.datanode.interval
Handling deprecation for mapreduce.task.io.sort.mb
Handling deprecation for yarn.resourcemanager.zk-state-store.parent-path
Handling deprecation for yarn.app.mapreduce.client-am.ipc.max-retries
Handling deprecation for fs.client.resolve.remote.symlinks
Handling deprecation for yarn.nodemanager.linux-container-executor.cgroups.strict-resource-usage
Handling deprecation for hadoop.ssl.enabled.protocols
Handling deprecation for mapreduce.reduce.cpu.vcores
Handling deprecation for yarn.client.failover-retries
Handling deprecation for mapreduce.jobhistory.address
Handling deprecation for hadoop.ssl.enabled
Handling deprecation for dfs.replication.max
Handling deprecation for dfs.namenode.name.dir
Handling deprecation for dfs.datanode.https.address
Handling deprecation for ipc.client.kill.max
Handling deprecation for mapreduce.job.committer.setup.cleanup.needed
Handling deprecation for dfs.client.domain.socket.data.traffic
Handling deprecation for yarn.nodemanager.localizer.cache.target-size-mb
Handling deprecation for yarn.resourcemanager.admin.client.thread-count
Handling deprecation for dfs.block.access.token.enable
Handling deprecation for mapreduce.job.speculative.retry-after-speculate
Handling deprecation for dfs.datanode.address
Handling deprecation for mapreduce.jobtracker.restart.recover
Handling deprecation for ipc.client.connect.max.retries
Handling deprecation for yarn.timeline-service.store-class
Handling deprecation for dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
Handling deprecation for hadoop.tmp.dir
Handling deprecation for dfs.datanode.handler.count
Handling deprecation for yarn.resourcemanager.ha.automatic-failover.embedded
Handling deprecation for yarn.timeline-service.ttl-ms
Handling deprecation for mapreduce.task.profile.map.params
Handling deprecation for yarn.resourcemanager.nodemanagers.heartbeat-interval-ms
Handling deprecation for mapreduce.map.speculative
Handling deprecation for yarn.timeline-service.recovery.enabled
Handling deprecation for mapreduce.job.map.class
Handling deprecation for dfs.namenode.resource.checked.volumes.minimum
Handling deprecation for yarn.nodemanager.recovery.dir
Handling deprecation for mapreduce.job.counters.max
Handling deprecation for yarn.resourcemanager.keytab
Handling deprecation for dfs.namenode.max.extra.edits.segments.retained
Handling deprecation for dfs.webhdfs.user.provider.user.pattern
Handling deprecation for dfs.client.mmap.enabled
Handling deprecation for mapreduce.map.log.level
Handling deprecation for dfs.client.file-block-storage-locations.timeout.millis
Handling deprecation for yarn.client.max-cached-nodemanagers-proxies
Handling deprecation for yarn.app.mapreduce.am.scheduler.heartbeat.interval-ms
Handling deprecation for hadoop.fuse.timer.period
Handling deprecation for fs.trash.checkpoint.interval
Handling deprecation for yarn.sharedcache.app-checker.class
Handling deprecation for dfs.journalnode.http-address
Handling deprecation for yarn.app.mapreduce.am.staging-dir
Handling deprecation for mapreduce.tasktracker.local.dir.minspacestart
Handling deprecation for yarn.nm.liveness-monitor.expiry-interval-ms
Handling deprecation for ha.health-monitor.check-interval.ms
Handling deprecation for mapreduce.reduce.shuffle.merge.percent
Handling deprecation for dfs.namenode.retrycache.heap.percent
Handling deprecation for yarn.nodemanager.docker-container-executor.exec-name
Handling deprecation for ipc.client.connect.timeout
Handling deprecation for yarn.resourcemanager.fs.state-store.retry-interval-ms
Handling deprecation for mapreduce.output.fileoutputformat.compress
Handling deprecation for yarn.nodemanager.local-dirs
Handling deprecation for yarn.nodemanager.recovery.enabled
Handling deprecation for io.native.lib.available
Handling deprecation for yarn.sharedcache.store.in-memory.staleness-period-mins
Handling deprecation for yarn.resourcemanager.am.max-attempts
Handling deprecation for s3.replication
Handling deprecation for mapreduce.input.fileinputformat.inputdir
Handling deprecation for fs.AbstractFileSystem.har.impl
Handling deprecation for dfs.image.compress
Handling deprecation for mapreduce.job.running.map.limit
Handling deprecation for mapreduce.reduce.input.buffer.percent
Handling deprecation for yarn.nodemanager.webapp.address
Handling deprecation for dfs.datanode.available-space-volume-choosing-policy.balanced-space-preference-fraction
Handling deprecation for dfs.namenode.edit.log.autoroll.multiplier.threshold
Handling deprecation for hadoop.security.group.mapping.ldap.ssl
Handling deprecation for dfs.namenode.checkpoint.check.period
Handling deprecation for fs.defaultFS
Handling deprecation for fs.s3a.multipart.size
Handling deprecation for dfs.client.slow.io.warning.threshold.ms
Handling deprecation for yarn.app.mapreduce.am.job.committer.commit-window
Handling deprecation for hadoop.security.group.mapping.ldap.search.attr.group.name
Handling deprecation for yarn.nodemanager.disk-health-checker.max-disk-utilization-per-disk-percentage
Handling deprecation for yarn.nodemanager.container-monitor.procfs-tree.smaps-based-rss.enabled
Handling deprecation for mapreduce.job.submithostname
Handling deprecation for mapreduce.map.sort.spill.percent
Handling deprecation for hadoop.security.crypto.codec.classes.aes.ctr.nopadding
Handling deprecation for dfs.namenode.http-address
Handling deprecation for hadoop.security.groups.negative-cache.secs
Handling deprecation for hadoop.ssl.server.conf
Handling deprecation for mapreduce.ifile.readahead
Handling deprecation for s3native.replication
Handling deprecation for yarn.client.nodemanager-client-async.thread-pool-max-size
Handling deprecation for mapreduce.jobtracker.staging.root.dir
Handling deprecation for mapreduce.jobhistory.admin.address
Handling deprecation for dfs.namenode.startup.delay.block.deletion.sec
Handling deprecation for yarn.nodemanager.health-checker.interval-ms
Handling deprecation for dfs.namenode.checkpoint.max-retries
Handling deprecation for s3.stream-buffer-size
Handling deprecation for ftp.client-write-packet-size
Handling deprecation for dfs.datanode.fsdatasetcache.max.threads.per.volume
Handling deprecation for mapreduce.output.fileoutputformat.compress.codec
Handling deprecation for yarn.timeline-service.keytab
Handling deprecation for yarn.sharedcache.store.in-memory.initial-delay-mins
Handling deprecation for mapreduce.jobhistory.webapp.address
Handling deprecation for mapreduce.task.userlog.limit.kb
Handling deprecation for mapreduce.reduce.shuffle.fetch.retry.enabled
Handling deprecation for yarn.app.mapreduce.task.container.log.backups
Handling deprecation for dfs.heartbeat.interval
Handling deprecation for ha.zookeeper.session-timeout.ms
Handling deprecation for fs.s3a.connection.ssl.enabled
Handling deprecation for yarn.sharedcache.webapp.address
Handling deprecation for hadoop.http.authentication.signature.secret.file
Handling deprecation for hadoop.fuse.connection.timeout
Handling deprecation for mapreduce.input.fileinputformat.numinputfiles
Handling deprecation for yarn.nodemanager.log-aggregation.compression-type
Handling deprecation for ipc.server.max.connections
Handling deprecation for yarn.resourcemanager.work-preserving-recovery.scheduling-wait-ms
Handling deprecation for yarn.nodemanager.log-dirs
Handling deprecation for yarn.app.mapreduce.am.resource.mb
Handling deprecation for hadoop.security.groups.cache.secs
Handling deprecation for mapreduce.job.speculative.minimum-allowed-tasks
Handling deprecation for yarn.nodemanager.container-monitor.interval-ms
Handling deprecation for dfs.datanode.cache.revocation.timeout.ms
Handling deprecation for mapreduce.jobhistory.recovery.store.class
Handling deprecation for mapreduce.task.combine.progress.records
Handling deprecation for s3.client-write-packet-size
Handling deprecation for mapreduce.jobtracker.instrumentation
Handling deprecation for dfs.replication
Handling deprecation for mapreduce.shuffle.transfer.buffer.size
Handling deprecation for hadoop.security.group.mapping.ldap.directory.search.timeout
Handling deprecation for dfs.datanode.available-space-volume-choosing-policy.balanced-space-threshold
Handling deprecation for hadoop.work.around.non.threadsafe.getpwuid
Handling deprecation for yarn.app.mapreduce.client-am.ipc.max-retries-on-timeouts
Handling deprecation for yarn.nodemanager.address
Handling deprecation for mapreduce.tasktracker.taskcontroller
Handling deprecation for mapreduce.tasktracker.indexcache.mb
Handling deprecation for yarn.scheduler.maximum-allocation-vcores
Handling deprecation for mapreduce.job.reduces
Handling deprecation for yarn.nodemanager.sleep-delay-before-sigkill.ms
Handling deprecation for yarn.timeline-service.address
Handling deprecation for yarn.resourcemanager.configuration.provider-class
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.expiry
Handling deprecation for yarn.sharedcache.enabled
Handling deprecation for tfile.io.chunk.size
Handling deprecation for mapreduce.job.acl-modify-job
Handling deprecation for hadoop.registry.zk.session.timeout.ms
Handling deprecation for fs.automatic.close
Handling deprecation for ha.health-monitor.sleep-after-disconnect.ms
Handling deprecation for mapreduce.tasktracker.reduce.tasks.maximum
Handling deprecation for mapreduce.input.fileinputformat.list-status.num-threads
Handling deprecation for dfs.datanode.directoryscan.threads
Handling deprecation for dfs.datanode.directoryscan.interval
Handling deprecation for dfs.namenode.acls.enabled
Handling deprecation for dfs.client.short.circuit.replica.stale.threshold.ms
Handling deprecation for hadoop.http.authentication.token.validity
Handling deprecation for fs.s3.block.size
Handling deprecation for ha.failover-controller.graceful-fence.rpc-timeout.ms
Handling deprecation for mapreduce.tasktracker.local.dir.minspacekill
Handling deprecation for dfs.namenode.resource.du.reserved
Handling deprecation for mapreduce.jobhistory.cleaner.interval-ms
Handling deprecation for dfs.namenode.datanode.registration.ip-hostname-check
Handling deprecation for mapreduce.jobhistory.intermediate-done-dir
Handling deprecation for mapreduce.jobtracker.http.address
Handling deprecation for dfs.namenode.backup.http-address
Handling deprecation for dfs.namenode.edits.noeditlogchannelflush
Handling deprecation for mapreduce.reduce.shuffle.input.buffer.percent
Handling deprecation for mapreduce.map.maxattempts
Handling deprecation for yarn.http.policy
Handling deprecation for dfs.namenode.audit.loggers
Handling deprecation for hadoop.security.groups.cache.warn.after.ms
Handling deprecation for io.serializations
Handling deprecation for mapreduce.tasktracker.outofband.heartbeat
Handling deprecation for mapreduce.reduce.shuffle.read.timeout
Handling deprecation for hadoop.security.crypto.buffer.size
Handling deprecation for mapreduce.reduce.skip.proc.count.autoincr
Handling deprecation for mapreduce.ifile.readahead.bytes
Handling deprecation for dfs.http.policy
Handling deprecation for hadoop.registry.secure
Handling deprecation for dfs.namenode.safemode.min.datanodes
Handling deprecation for dfs.client.file-block-storage-locations.num-threads
Handling deprecation for mapreduce.cluster.local.dir
Handling deprecation for mapreduce.tasktracker.report.address
Handling deprecation for dfs.namenode.secondary.https-address
Handling deprecation for hadoop.kerberos.kinit.command
Handling deprecation for yarn.timeline-service.http-authentication.type
Handling deprecation for dfs.block.access.token.lifetime
Handling deprecation for dfs.webhdfs.enabled
Handling deprecation for dfs.namenode.delegation.token.max-lifetime
Handling deprecation for dfs.namenode.avoid.write.stale.datanode
Handling deprecation for dfs.datanode.drop.cache.behind.writes
Handling deprecation for yarn.log-aggregation.retain-seconds
Handling deprecation for mapreduce.job.complete.cancel.delegation.tokens
Handling deprecation for mapreduce.local.clientfactory.class.name
Handling deprecation for mapreduce.shuffle.connection-keep-alive.timeout
Handling deprecation for dfs.namenode.num.extra.edits.retained
Handling deprecation for yarn.scheduler.minimum-allocation-vcores
Handling deprecation for ipc.client.connect.max.retries.on.timeouts
Handling deprecation for yarn.timeline-service.client.retry-interval-ms
Handling deprecation for yarn.timeline-service.client.max-retries
Handling deprecation for fs.s3n.block.size
Handling deprecation for mapreduce.job.map.output.collector.class
Handling deprecation for ha.health-monitor.connect-retry-interval.ms
Handling deprecation for mapreduce.shuffle.max.threads
Handling deprecation for nfs.exports.allowed.hosts
Handling deprecation for dfs.client.mmap.cache.size
Handling deprecation for mapreduce.tasktracker.map.tasks.maximum
Handling deprecation for io.file.buffer.size
Handling deprecation for dfs.client.datanode-restart.timeout
Handling deprecation for io.mapfile.bloom.size
Handling deprecation for hadoop.security.kms.client.authentication.retry-count
Handling deprecation for dfs.namenode.checkpoint.txns
Handling deprecation for ipc.client.connect.retry.interval
Handling deprecation for dfs.client-write-packet-size
Handling deprecation for mapreduce.reduce.shuffle.connect.timeout
Handling deprecation for yarn.resourcemanager.fs.state-store.uri
Handling deprecation for fs.swift.impl
Handling deprecation for hadoop.registry.zk.connection.timeout.ms
Handling deprecation for mapred.queue.default.acl-administer-jobs
Handling deprecation for mapreduce.job.submithostaddress
Handling deprecation for dfs.cachereport.intervalMsec
Handling deprecation for yarn.app.mapreduce.shuffle.log.backups
Handling deprecation for yarn.app.mapreduce.am.container.log.limit.kb
Handling deprecation for yarn.nodemanager.resourcemanager.minimum.version
Handling deprecation for ftp.blocksize
Handling deprecation for yarn.resourcemanager.address
Handling deprecation for file.stream-buffer-size
Handling deprecation for yarn.resourcemanager.scheduler.monitor.enable
Handling deprecation for mapreduce.job.ubertask.maxreduces
Handling deprecation for nfs.allow.insecure.ports
Handling deprecation for yarn.sharedcache.nm.uploader.thread-count
Handling deprecation for ipc.client.idlethreshold
Handling deprecation for ftp.stream-buffer-size
Handling deprecation for yarn.sharedcache.client-server.address
Handling deprecation for dfs.client.failover.connection.retries.on.timeouts
Handling deprecation for dfs.namenode.replication.work.multiplier.per.iteration
Handling deprecation for hadoop.http.authentication.simple.anonymous.allowed
Handling deprecation for hadoop.security.authorization
Handling deprecation for yarn.client.nodemanager-connect.retry-interval-ms
Handling deprecation for yarn.am.liveness-monitor.expiry-interval-ms
Handling deprecation for fs.har.impl.disable.cache
Handling deprecation for yarn.nodemanager.linux-container-executor.resources-handler.class
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.read-cache-size
Handling deprecation for hadoop.security.authentication
Handling deprecation for dfs.image.compression.codec
Handling deprecation for mapreduce.task.files.preserve.failedtasks
Handling deprecation for dfs.client.read.shortcircuit.streams.cache.size
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.path
Handling deprecation for mapreduce.job.reduce.slowstart.completedmaps
Handling deprecation for mapreduce.jobhistory.minicluster.fixed.ports
Handling deprecation for file.replication
Handling deprecation for yarn.resourcemanager.ha.automatic-failover.enabled
Handling deprecation for mapreduce.job.userlog.retain.hours
Handling deprecation for mapreduce.jobhistory.joblist.cache.size
Handling deprecation for dfs.namenode.accesstime.precision
Handling deprecation for yarn.resourcemanager.work-preserving-recovery.enabled
Handling deprecation for dfs.namenode.fs-limits.max-xattrs-per-inode
Handling deprecation for io.mapfile.bloom.error.rate
Handling deprecation for yarn.resourcemanager.store.class
Handling deprecation for dfs.image.transfer.timeout
Handling deprecation for yarn.timeline-service.leveldb-state-store.path
Handling deprecation for nfs.wtmax
Handling deprecation for mapreduce.job.combine.class
Handling deprecation for dfs.namenode.support.allow.format
Handling deprecation for fs.s3a.multipart.purge
Handling deprecation for dfs.secondary.namenode.kerberos.internal.spnego.principal
Handling deprecation for fs.s3a.connection.establish.timeout
Handling deprecation for dfs.stream-buffer-size
Handling deprecation for dfs.namenode.invalidate.work.pct.per.iteration
Handling deprecation for yarn.nodemanager.container-executor.class
Handling deprecation for fs.s3a.multipart.purge.age
Handling deprecation for yarn.resourcemanager.scheduler.client.thread-count
Handling deprecation for dfs.namenode.top.enabled
Handling deprecation for yarn.app.mapreduce.shuffle.log.separate
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.low-watermark
Handling deprecation for fs.s3a.fast.buffer.size
Handling deprecation for hadoop.user.group.static.mapping.overrides
Handling deprecation for tfile.fs.input.buffer.size
Handling deprecation for dfs.client.cached.conn.retry
Handling deprecation for hadoop.http.authentication.type
Handling deprecation for dfs.namenode.list.encryption.zones.num.responses
Handling deprecation for mapreduce.map.cpu.vcores
Handling deprecation for dfs.namenode.path.based.cache.refresh.interval.ms
Handling deprecation for dfs.namenode.decommission.interval
Handling deprecation for dfs.namenode.fs-limits.max-directory-items
Handling deprecation for yarn.resourcemanager.zk-retry-interval-ms
Handling deprecation for ftp.bytes-per-checksum
Handling deprecation for dfs.ha.log-roll.period
Handling deprecation for dfs.user.home.dir.prefix
Handling deprecation for ipc.client.fallback-to-simple-auth-allowed
Handling deprecation for yarn.nodemanager.pmem-check-enabled
Handling deprecation for yarn.nodemanager.remote-app-log-dir
Handling deprecation for dfs.namenode.inotify.max.events.per.rpc
Handling deprecation for mapreduce.task.profile.maps
Handling deprecation for mapreduce.shuffle.ssl.file.buffer.size
Handling deprecation for mapreduce.tasktracker.healthchecker.script.timeout
Handling deprecation for yarn.timeline-service.webapp.https.address
Handling deprecation for yarn.nodemanager.resource.percentage-physical-cpu-limit
Handling deprecation for yarn.app.mapreduce.am.command-opts
Handling deprecation for dfs.namenode.fs-limits.max-xattr-size
Handling deprecation for dfs.datanode.http.address
Handling deprecation for dfs.namenode.blocks.per.postponedblocks.rescan
Handling deprecation for yarn.sharedcache.nm.uploader.replication.factor
Handling deprecation for hadoop.registry.zk.root
Handling deprecation for hadoop.jetty.logs.serve.aliases
Handling deprecation for yarn.client.failover-proxy-provider
Handling deprecation for mapreduce.jobhistory.admin.acl
Handling deprecation for yarn.app.mapreduce.am.hard-kill-timeout-ms
Handling deprecation for yarn.nodemanager.remote-app-log-dir-suffix
Handling deprecation for mapreduce.jobhistory.principal
Handling deprecation for yarn.resourcemanager.webapp.address
Handling deprecation for mapreduce.jobhistory.recovery.enable
Handling deprecation for yarn.sharedcache.store.in-memory.check-period-mins
Handling deprecation for nfs.mountd.port
Handling deprecation for mapreduce.reduce.merge.inmem.threshold
Handling deprecation for fs.df.interval
Handling deprecation for yarn.timeline-service.enabled
Handling deprecation for mapreduce.jobtracker.jobhistory.lru.cache.size
Handling deprecation for mapreduce.task.profile
Handling deprecation for mapreduce.job.output.key.class
Handling deprecation for yarn.nodemanager.hostname
Handling deprecation for dfs.namenode.num.checkpoints.retained
Handling deprecation for mapreduce.job.queuename
Handling deprecation for mapreduce.jobhistory.max-age-ms
Handling deprecation for mapreduce.job.token.tracking.ids.enabled
Handling deprecation for yarn.nodemanager.localizer.client.thread-count
Handling deprecation for yarn.sharedcache.uploader.server.thread-count
Handling deprecation for dfs.client.mmap.retry.timeout.ms
Handling deprecation for mapreduce.jobhistory.move.thread-count
Handling deprecation for dfs.permissions.enabled
Handling deprecation for dfs.blockreport.split.threshold
Handling deprecation for fs.AbstractFileSystem.hdfs.impl
Handling deprecation for dfs.datanode.balance.bandwidthPerSec
Handling deprecation for dfs.block.scanner.volume.bytes.per.second
Handling deprecation for hadoop.http.filter.initializers
Handling deprecation for yarn.timeline-service.http-authentication.simple.anonymous.allowed
Handling deprecation for dfs.default.chunk.view.size
Handling deprecation for yarn.sharedcache.client-server.thread-count
Handling deprecation for yarn.resourcemanager.resource-tracker.address
Handling deprecation for mapreduce.job.working.dir
Handling deprecation for mapreduce.jobhistory.datestring.cache.size
Handling deprecation for mapreduce.task.profile.params
Handling deprecation for dfs.namenode.decommission.blocks.per.interval
Handling deprecation for dfs.namenode.handler.count
Handling deprecation for dfs.image.transfer.bandwidthPerSec
Handling deprecation for rpc.metrics.quantile.enable
Handling deprecation for mapreduce.jobtracker.expire.trackers.interval
Handling deprecation for mapreduce.task.timeout
Handling deprecation for yarn.app.mapreduce.client.max-retries
Handling deprecation for yarn.nodemanager.resource.memory-mb
Handling deprecation for yarn.nodemanager.disk-health-checker.min-healthy-disks
Handling deprecation for dfs.datanode.failed.volumes.tolerated
Handling deprecation for yarn.timeline-service.handler-thread-count
Handling deprecation for ipc.server.listen.queue.size
Handling deprecation for fs.s3a.threads.max
Handling deprecation for yarn.resourcemanager.connect.max-wait.ms
Handling deprecation for mapreduce.fileoutputcommitter.algorithm.version
Handling deprecation for mapreduce.framework.name
Handling deprecation for mapreduce.map.skip.proc.count.autoincr
Handling deprecation for mapreduce.job.max.split.locations
Handling deprecation for yarn.resourcemanager.scheduler.class
Handling deprecation for yarn.resourcemanager.system-metrics-publisher.enabled
Handling deprecation for dfs.blocksize
Handling deprecation for yarn.sharedcache.nested-level
Handling deprecation for mapreduce.shuffle.connection-keep-alive.enable
Handling deprecation for fs.s3a.threads.keepalivetime
Handling deprecation for fs.s3a.connection.timeout
Handling deprecation for file.client-write-packet-size
Handling deprecation for ha.failover-controller.cli-check.rpc-timeout.ms
Handling deprecation for ha.zookeeper.acl
Handling deprecation for dfs.namenode.write.stale.datanode.ratio
Handling deprecation for dfs.encrypt.data.transfer
Handling deprecation for dfs.datanode.shared.file.descriptor.paths
Handling deprecation for mapreduce.input.lineinputformat.linespermap
Handling deprecation for yarn.resourcemanager.delayed.delegation-token.removal-interval-ms
Handling deprecation for yarn.nodemanager.localizer.fetch.thread-count
Handling deprecation for dfs.client.failover.max.attempts
Handling deprecation for yarn.resourcemanager.scheduler.address
Handling deprecation for dfs.client.read.shortcircuit.streams.cache.expiry.ms
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.start-time-write-cache-size
Handling deprecation for yarn.nodemanager.health-checker.script.timeout-ms
Handling deprecation for yarn.resourcemanager.fs.state-store.num-retries
Handling deprecation for hadoop.ssl.require.client.cert
Handling deprecation for hadoop.security.uid.cache.secs
Handling deprecation for mapreduce.jobhistory.keytab
Handling deprecation for dfs.client.read.shortcircuit.skip.checksum
Handling deprecation for yarn.resourcemanager.ha.automatic-failover.zk-base-path
Handling deprecation for mapreduce.shuffle.ssl.enabled
Handling deprecation for mapreduce.reduce.log.level
Handling deprecation for hadoop.registry.rm.enabled
Handling deprecation for mapreduce.tasktracker.dns.interface
Handling deprecation for yarn.resourcemanager.system-metrics-publisher.dispatcher.pool-size
Handling deprecation for mapreduce.job.speculative.speculative-cap-running-tasks
Handling deprecation for dfs.datanode.block.id.layout.upgrade.threads
Handling deprecation for dfs.datanode.use.datanode.hostname
Handling deprecation for dfs.client.context
Handling deprecation for yarn.resourcemanager.ha.enabled
Handling deprecation for mapred.reducer.new-api
Handling deprecation for dfs.namenode.delegation.token.renew-interval
Handling deprecation for dfs.blockreport.intervalMsec
Handling deprecation for fs.s3a.multipart.threshold
Handling deprecation for mapreduce.reduce.shuffle.memory.limit.percent
Handling deprecation for dfs.https.server.keystore.resource
Handling deprecation for io.map.index.skip
Handling deprecation for mapreduce.job.hdfs-servers
Handling deprecation for mapreduce.jobtracker.taskscheduler
Handling deprecation for dfs.namenode.kerberos.internal.spnego.principal
Handling deprecation for yarn.resourcemanager.state-store.max-completed-applications
Handling deprecation for mapreduce.map.output.compress
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.num.refill.threads
Handling deprecation for fs.s3n.multipart.uploads.block.size
Handling deprecation for mapreduce.task.merge.progress.records
Handling deprecation for dfs.datanode.dns.interface
Handling deprecation for map.sort.class
Handling deprecation for yarn.nodemanager.aux-services.mapreduce_shuffle.class
Handling deprecation for tfile.fs.output.buffer.size
Handling deprecation for fs.du.interval
Handling deprecation for dfs.client.failover.connection.retries
Handling deprecation for dfs.namenode.top.window.num.buckets
Handling deprecation for mapreduce.job.dir
Handling deprecation for fs.s3a.buffer.dir
Handling deprecation for mapreduce.reduce.shuffle.retry-delay.max.ms
Handling deprecation for yarn.sharedcache.uploader.server.address
Handling deprecation for mapreduce.client.progressmonitor.pollinterval
Handling deprecation for yarn.app.mapreduce.shuffle.log.limit.kb
Handling deprecation for dfs.datanode.max.locked.memory
Handling deprecation for dfs.namenode.retrycache.expirytime.millis
Handling deprecation for dfs.datanode.scan.period.hours
Handling deprecation for dfs.client.block.write.replace-datanode-on-failure.best-effort
Handling deprecation for mapreduce.jobhistory.move.interval-ms
Handling deprecation for dfs.ha.fencing.ssh.connect-timeout
Handling deprecation for yarn.nodemanager.log-aggregation.roll-monitoring-interval-seconds
Handling deprecation for dfs.namenode.fs-limits.max-component-length
Handling deprecation for hadoop.registry.zk.quorum
Handling deprecation for dfs.namenode.enable.retrycache
Handling deprecation for dfs.datanode.du.reserved
Handling deprecation for yarn.timeline-service.state-store-class
Handling deprecation for dfs.datanode.ipc.address
Handling deprecation for hadoop.registry.system.acls
Handling deprecation for dfs.client.block.write.replace-datanode-on-failure.policy
Handling deprecation for dfs.namenode.path.based.cache.retry.interval.ms
Handling deprecation for hadoop.security.crypto.cipher.suite
Handling deprecation for dfs.ha.tail-edits.period
Handling deprecation for mapreduce.task.profile.reduce.params
Handling deprecation for hadoop.registry.jaas.context
Handling deprecation for yarn.resourcemanager.hostname
Handling deprecation for mapreduce.reduce.memory.mb
Handling deprecation for hadoop.security.group.mapping.ldap.search.filter.group
Handling deprecation for hadoop.http.authentication.kerberos.principal
Handling deprecation for hadoop.security.group.mapping.ldap.search.filter.user
Handling deprecation for yarn.nodemanager.disk-health-checker.min-free-space-per-disk-mb
Handling deprecation for dfs.namenode.edits.dir
Handling deprecation for yarn.client.failover-retries-on-socket-timeouts
Handling deprecation for dfs.namenode.decommission.max.concurrent.tracked.nodes
Handling deprecation for mapreduce.client.completion.pollinterval
Handling deprecation for dfs.namenode.name.dir.restore
Handling deprecation for dfs.namenode.secondary.http-address
Handling deprecation for mapreduce.jobhistory.recovery.store.leveldb.path
Handling deprecation for yarn.sharedcache.store.class
Handling deprecation for s3.bytes-per-checksum
Handling deprecation for yarn.nodemanager.windows-container.cpu-limit.enabled
Handling deprecation for yarn.resourcemanager.webapp.https.address
Handling deprecation for yarn.nodemanager.vmem-pmem-ratio
Handling deprecation for dfs.namenode.checkpoint.period
Handling deprecation for dfs.ha.automatic-failover.enabled
The url to track the job: http://localhost:8080/
Running job: job_local87253821_0003
OutputCommitter set in config null
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
File Output Committer Algorithm version is 1
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
/user/michaeljones/wcOutputAnalysis/_temporary/0: masked=rwxr-xr-x
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #58
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #58
Call: mkdirs took 4ms
Starting mapper thread pool executor.
Max local threads: 1
Map tasks to process: 1
Waiting for map tasks
Starting task: attempt_local87253821_0003_m_000000_0
currentIndex 0   0:0
mapreduce.cluster.local.dir for child : /tmp/hadoop-michaeljones/mapred/local/localRunner//michaeljones/jobcache/job_local87253821_0003/attempt_local87253821_0003_m_000000_0
using new api for output committer
File Output Committer Algorithm version is 1
ProcfsBasedProcessTree currently is supported only on Linux.
 Using ResourceCalculatorProcessTree : null
Processing split: hdfs://localhost:9000/user/michaeljones/wcInput:0+50
Trying map output collector class: org.apache.hadoop.mapred.MapTask$MapOutputBuffer
(EQUATOR) 0 kvi 26214396(104857584)
mapreduce.task.io.sort.mb: 100
soft limit at 83886080
bufstart = 0; bufvoid = 104857600
kvstart = 26214396; length = 6553600
Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #59
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #59
Call: getBlockLocations took 5ms
newInfo = LocatedBlocks{
  fileLength=50
  underConstruction=false
  blocks=[LocatedBlock{BP-1045030256-10.0.0.2-1433119149314:blk_1073741825_1002; getBlockSize()=50; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-b42c5705-9ba4-4b14-b00b-f9194bb036f0,DISK]]}]
  lastLocatedBlock=LocatedBlock{BP-1045030256-10.0.0.2-1433119149314:blk_1073741825_1002; getBlockSize()=50; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-b42c5705-9ba4-4b14-b00b-f9194bb036f0,DISK]]}
  isLastBlockComplete=true}
Connecting to datanode 127.0.0.1:50010

Starting flush of map output
Spilling map output
bufstart = 0; bufend = 82; bufvoid = 104857600
kvstart = 26214396(104857584); kvend = 26214368(104857472); length = 29/6553600
IntSumCombinerAnalyser-Bye[1]
IntSumCombinerAnalyser-Goodbye[1]
IntSumCombinerAnalyser-Hadoop[1,1]
IntSumCombinerAnalyser-Hello[1,1]
IntSumCombinerAnalyser-World[1,1]
Finished spill 0
Task:attempt_local87253821_0003_m_000000_0 is done. And is in the process of committing
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #60
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #60
Call: getFileInfo took 2ms
map
Task 'attempt_local87253821_0003_m_000000_0' done.
Finishing task: attempt_local87253821_0003_m_000000_0
map task executor complete.
Starting reduce thread pool executor.
Max local threads: 1
Reduce tasks to process: 1
Waiting for reduce tasks
Starting task: attempt_local87253821_0003_r_000000_0
currentIndex 0   0:0
mapreduce.cluster.local.dir for child : /tmp/hadoop-michaeljones/mapred/local/localRunner//michaeljones/jobcache/job_local87253821_0003/attempt_local87253821_0003_r_000000_0
using new api for output committer
File Output Committer Algorithm version is 1
ProcfsBasedProcessTree currently is supported only on Linux.
 Using ResourceCalculatorProcessTree : null
Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@410a767
MergerManager: memoryLimit=668309888, maxSingleShuffleLimit=167077472, mergeThreshold=441084544, ioSortFactor=10, memToMemMergeOutputsThreshold=10
attempt_local87253821_0003_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
Got 0 map completion events from 0
GetMapEventsThread about to sleep for 1000
LocalFetcher 3 going to fetch: attempt_local87253821_0003_m_000000_0
attempt_local87253821_0003_m_000000_0: Proceeding with shuffle since usedMemory (0) is lesser than memoryLimit (668309888).CommitMemory is (0)
localfetcher#3 about to shuffle output of map attempt_local87253821_0003_m_000000_0 decomp: 63 len: 67 to MEMORY
Read 63 bytes from map-output for attempt_local87253821_0003_m_000000_0
closeInMemoryFile -> map-output of size: 63, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->63
map attempt_local87253821_0003_m_000000_0 done 1 / 1 copied.
EventFetcher is interrupted.. Returning
1 / 1 copied.
finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
Merging 1 sorted segments
Down to the last merge-pass, with 1 segments left of total size: 57 bytes
Merged 1 segments, 63 bytes to disk to satisfy reduce memory limit
Disk file: /tmp/hadoop-michaeljones/mapred/local/localRunner/michaeljones/jobcache/job_local87253821_0003/attempt_local87253821_0003_r_000000_0/output/map_0.out.merged Length is 67
Merging 1 files, 67 bytes from disk
Merging 0 segments, 0 bytes from memory into reduce
Merging 1 sorted segments
Down to the last merge-pass, with 1 segments left of total size: 57 bytes
1 / 1 copied.
/user/michaeljones/wcOutputAnalysis/_temporary/0/_temporary/attempt_local87253821_0003_r_000000_0/part-r-00000: masked=rw-r--r--
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #61
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #61
Call: create took 4ms
computePacketChunkSize: src=/user/michaeljones/wcOutputAnalysis/_temporary/0/_temporary/attempt_local87253821_0003_r_000000_0/part-r-00000, chunkSize=516, chunksPerPacket=126, packetSize=65016
IntSumReducerAnalyser-Bye[1]
IntSumReducerAnalyser-Goodbye[1]
IntSumReducerAnalyser-Hadoop[2]
IntSumReducerAnalyser-Hello[2]
IntSumReducerAnalyser-World[2]
DFSClient writeChunk allocating new packet seqno=0, src=/user/michaeljones/wcOutputAnalysis/_temporary/0/_temporary/attempt_local87253821_0003_r_000000_0/part-r-00000, packetSize=65016, chunksPerPacket=126, bytesCurBlock=0
Queued packet 0
Queued packet 1
Waiting for ack for: 1
Allocating new block
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #62
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #62
Call: addBlock took 4ms
pipeline = DatanodeInfoWithStorage[127.0.0.1:50010,DS-b42c5705-9ba4-4b14-b00b-f9194bb036f0,DISK]
Connecting to datanode 127.0.0.1:50010
Send buf size 131072
SASL client skipping handshake in unsecured configuration for addr = /127.0.0.1, datanodeId = DatanodeInfoWithStorage[127.0.0.1:50010,DS-b42c5705-9ba4-4b14-b00b-f9194bb036f0,DISK]
DataStreamer block BP-1045030256-10.0.0.2-1433119149314:blk_1073742267_1444 sending packet packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 41
DFSClient seqno: 0 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
DataStreamer block BP-1045030256-10.0.0.2-1433119149314:blk_1073742267_1444 sending packet packet seqno: 1 offsetInBlock: 41 lastPacketInBlock: true lastByteOffsetInBlock: 41
DFSClient seqno: 1 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
Closing old block BP-1045030256-10.0.0.2-1433119149314:blk_1073742267_1444
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #63
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #63
Call: complete took 4ms
Task:attempt_local87253821_0003_r_000000_0 is done. And is in the process of committing
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #64
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #64
Call: getFileInfo took 1ms
1 / 1 copied.
Task attempt_local87253821_0003_r_000000_0 is allowed to commit now
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #65
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #65
Call: getFileInfo took 2ms
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #66
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #66
Call: getFileInfo took 2ms
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #67
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #67
Call: rename took 5ms
Saved output of task 'attempt_local87253821_0003_r_000000_0' to hdfs://localhost:9000/user/michaeljones/wcOutputAnalysis/_temporary/0/task_local87253821_0003_r_000000
reduce > reduce
Task 'attempt_local87253821_0003_r_000000_0' done.
Finishing task: attempt_local87253821_0003_r_000000_0
reduce task executor complete.
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #68
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #68
Call: getListing took 2ms
Merging data from FileStatus{path=hdfs://localhost:9000/user/michaeljones/wcOutputAnalysis/_temporary/0/task_local87253821_0003_r_000000; isDirectory=true; modification_time=1434167878019; access_time=0; owner=michaeljones; group=supergroup; permission=rwxr-xr-x; isSymlink=false} to hdfs://localhost:9000/user/michaeljones/wcOutputAnalysis
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #69
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #69
Call: getFileInfo took 2ms
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #70
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #70
Call: getListing took 3ms
Merging data from FileStatus{path=hdfs://localhost:9000/user/michaeljones/wcOutputAnalysis/_temporary/0/task_local87253821_0003_r_000000/part-r-00000; isDirectory=false; length=41; replication=1; blocksize=134217728; modification_time=1434167878052; access_time=1434167878019; owner=michaeljones; group=supergroup; permission=rw-r--r--; isSymlink=false} to hdfs://localhost:9000/user/michaeljones/wcOutputAnalysis/part-r-00000
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #71
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #71
Call: getFileInfo took 1ms
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #72
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #72
Call: rename took 3ms
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #73
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #73
Call: delete took 2ms
/user/michaeljones/wcOutputAnalysis/_SUCCESS: masked=rw-r--r--
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #74
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #74
Call: create took 3ms
computePacketChunkSize: src=/user/michaeljones/wcOutputAnalysis/_SUCCESS, chunkSize=516, chunksPerPacket=126, packetSize=65016
Waiting for ack for: -1
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #75
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #75
Call: complete took 4ms
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.fs.FileContext.getAbstractFileSystem(FileContext.java:331)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
Job job_local87253821_0003 running in uber mode : false
 map 100% reduce 100%
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.getTaskCompletionEvents(Job.java:670)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.getTaskCompletionEvents(Job.java:670)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
Job job_local87253821_0003 completed successfully
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.getCounters(Job.java:758)
Counters: 35
	File System Counters
		FILE: Number of bytes read=1892
		FILE: Number of bytes written=1688367
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=340
		HDFS: Number of bytes written=245
		HDFS: Number of read operations=71
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=38
	Map-Reduce Framework
		Map input records=2
		Map output records=8
		Map output bytes=82
		Map output materialized bytes=67
		Input split bytes=112
		Combine input records=8
		Combine output records=5
		Reduce input groups=5
		Reduce shuffle bytes=67
		Reduce input records=5
		Reduce output records=5
		Spilled Records=10
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=8
		Total committed heap usage (bytes)=932184064
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=50
	File Output Format Counters 
		Bytes Written=41
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 5][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://localhost:50070
Connecting to localhost/127.0.0.1:50070
Connection established 127.0.0.1:50056<->127.0.0.1:50070
Executing request GET /webhdfs/v1/user/michaeljones/?op=LISTSTATUS HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-5 >> GET /webhdfs/v1/user/michaeljones/?op=LISTSTATUS HTTP/1.1
http-outgoing-5 >> accept: application/json
http-outgoing-5 >> Host: localhost:50070
http-outgoing-5 >> Connection: Keep-Alive
http-outgoing-5 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-5 >> Accept-Encoding: gzip,deflate
http-outgoing-5 >> "GET /webhdfs/v1/user/michaeljones/?op=LISTSTATUS HTTP/1.1[\r][\n]"
http-outgoing-5 >> "accept: application/json[\r][\n]"
http-outgoing-5 >> "Host: localhost:50070[\r][\n]"
http-outgoing-5 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-5 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-5 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-5 >> "[\r][\n]"
http-outgoing-5 << "HTTP/1.1 200 OK[\r][\n]"
http-outgoing-5 << "Cache-Control: no-cache[\r][\n]"
http-outgoing-5 << "Expires: Sat, 13 Jun 2015 03:57:58 GMT[\r][\n]"
http-outgoing-5 << "Date: Sat, 13 Jun 2015 03:57:58 GMT[\r][\n]"
http-outgoing-5 << "Pragma: no-cache[\r][\n]"
http-outgoing-5 << "Expires: Sat, 13 Jun 2015 03:57:58 GMT[\r][\n]"
http-outgoing-5 << "Date: Sat, 13 Jun 2015 03:57:58 GMT[\r][\n]"
http-outgoing-5 << "Pragma: no-cache[\r][\n]"
http-outgoing-5 << "Content-Type: application/json[\r][\n]"
http-outgoing-5 << "Transfer-Encoding: chunked[\r][\n]"
http-outgoing-5 << "Server: Jetty(6.1.26)[\r][\n]"
http-outgoing-5 << "[\r][\n]"
http-outgoing-5 << "FB5[\r][\n]"
http-outgoing-5 << "{"FileStatuses":{"FileStatus":[[\n]"
http-outgoing-5 << "{"accessTime":1434167869661,"blockSize":134217728,"childrenNum":0,"fileId":18543,"group":"supergroup","length":10899,"modificationTime":1434167869692,"owner":"michaeljones","pathSuffix":"README.md","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-5 << "{"accessTime":1434167244718,"blockSize":134217728,"childrenNum":0,"fileId":18529,"group":"supergroup","length":0,"modificationTime":1434167244724,"owner":"michaeljones","pathSuffix":"apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-5 << "{"accessTime":1434167800851,"blockSize":134217728,"childrenNum":0,"fileId":18536,"group":"supergroup","length":0,"modificationTime":1434167800857,"owner":"michaeljones","pathSuffix":"empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-5 << "{"accessTime":1434167868991,"blockSize":134217728,"childrenNum":0,"fileId":18540,"group":"supergroup","length":0,"modificationTime":1434167868996,"owner":"michaeljones","pathSuffix":"hello-apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-5 << "{"accessTime":1434091626279,"blockSize":134217728,"childrenNum":0,"fileId":18298,"group":"supergroup","length":0,"modificationTime":1434091626286,"owner":"michaeljones","pathSuffix":"hello-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-5 << "{"accessTime":1434167868891,"blockSize":134217728,"childrenNum":0,"fileId":18539,"group":"supergroup","length":0,"modificationTime":1434167868901,"owner":"michaeljones","pathSuffix":"hello-jersey-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-5 << "{"accessTime":1434167801365,"blockSize":134217728,"childrenNum":0,"fileId":18538,"group":"supergroup","length":1505861,"modificationTime":1434167801408,"owner":"michaeljones","pathSuffix":"hello.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-5 << "{"accessTime":1434167869373,"blockSize":134217728,"childrenNum":0,"fileId":18542,"group":"supergroup","length":3678856,"modificationTime":1434167869495,"owner":"michaeljones","pathSuffix":"hello.log.2015-06-12","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-5 << "{"accessTime":1434167872655,"blockSize":134217728,"childrenNum":0,"fileId":18544,"group":"supergroup","length":20,"modificationTime":1434167873103,"owner":"michaeljones","pathSuffix":"hello.txt","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-5 << "{"accessTime":1434167869241,"blockSize":134217728,"childrenNum":0,"fileId":18541,"group":"supergroup","length":79855,"modificationTime":1434167869268,"owner":"michaeljones","pathSuffix":"hellohadoop.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-5 << "{"accessTime":1434167244774,"blockSize":134217728,"childrenNum":0,"fileId":18530,"group":"supergroup","length":2134,"modificationTime":1434167244805,"owner":"michaeljones","pathSuffix":"pom.xml","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-5 << "{"accessTime":1434167238722,"blockSize":134217728,"childrenNum":0,"fileId":16388,"group":"supergroup","length":50,"modificationTime":1433119638967,"owner":"michaeljones","pathSuffix":"wcInput","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-5 << "{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18552,"group":"supergroup","length":0,"modificationTime":1434167876530,"owner":"michaeljones","pathSuffix":"wcOutput","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},[\n]"
http-outgoing-5 << "{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18559,"group":"supergroup","length":0,"modificationTime":1434167878094,"owner":"michaeljones","pathSuffix":"wcOutputAnalysis","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},[\n]"
http-outgoing-5 << "{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18545,"group":"supergroup","length":0,"modificationTime":1434167875444,"owner":"michaeljones","pathSuffix":"wcOutputMain","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"}[\n]"
http-outgoing-5 << "]}}[\n]"
http-outgoing-5 << "[\r][\n]"
http-outgoing-5 << HTTP/1.1 200 OK
http-outgoing-5 << Cache-Control: no-cache
http-outgoing-5 << Expires: Sat, 13 Jun 2015 03:57:58 GMT
http-outgoing-5 << Date: Sat, 13 Jun 2015 03:57:58 GMT
http-outgoing-5 << Pragma: no-cache
http-outgoing-5 << Expires: Sat, 13 Jun 2015 03:57:58 GMT
http-outgoing-5 << Date: Sat, 13 Jun 2015 03:57:58 GMT
http-outgoing-5 << Pragma: no-cache
http-outgoing-5 << Content-Type: application/json
http-outgoing-5 << Transfer-Encoding: chunked
http-outgoing-5 << Server: Jetty(6.1.26)
Connection can be kept alive indefinitely
http-outgoing-5 << "0[\r][\n]"
http-outgoing-5 << "[\r][\n]"
Connection [id: 5][route: {}->http://localhost:50070] can be kept alive indefinitely
Connection released: [id: 5][route: {}->http://localhost:50070][total kept alive: 1; route allocated: 1 of 2; total allocated: 1 of 20]
Apache client testGetStringContent
{"FileStatuses":{"FileStatus":[
{"accessTime":1434167869661,"blockSize":134217728,"childrenNum":0,"fileId":18543,"group":"supergroup","length":10899,"modificationTime":1434167869692,"owner":"michaeljones","pathSuffix":"README.md","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434167244718,"blockSize":134217728,"childrenNum":0,"fileId":18529,"group":"supergroup","length":0,"modificationTime":1434167244724,"owner":"michaeljones","pathSuffix":"apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434167800851,"blockSize":134217728,"childrenNum":0,"fileId":18536,"group":"supergroup","length":0,"modificationTime":1434167800857,"owner":"michaeljones","pathSuffix":"empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434167868991,"blockSize":134217728,"childrenNum":0,"fileId":18540,"group":"supergroup","length":0,"modificationTime":1434167868996,"owner":"michaeljones","pathSuffix":"hello-apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434091626279,"blockSize":134217728,"childrenNum":0,"fileId":18298,"group":"supergroup","length":0,"modificationTime":1434091626286,"owner":"michaeljones","pathSuffix":"hello-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434167868891,"blockSize":134217728,"childrenNum":0,"fileId":18539,"group":"supergroup","length":0,"modificationTime":1434167868901,"owner":"michaeljones","pathSuffix":"hello-jersey-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434167801365,"blockSize":134217728,"childrenNum":0,"fileId":18538,"group":"supergroup","length":1505861,"modificationTime":1434167801408,"owner":"michaeljones","pathSuffix":"hello.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434167869373,"blockSize":134217728,"childrenNum":0,"fileId":18542,"group":"supergroup","length":3678856,"modificationTime":1434167869495,"owner":"michaeljones","pathSuffix":"hello.log.2015-06-12","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434167872655,"blockSize":134217728,"childrenNum":0,"fileId":18544,"group":"supergroup","length":20,"modificationTime":1434167873103,"owner":"michaeljones","pathSuffix":"hello.txt","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434167869241,"blockSize":134217728,"childrenNum":0,"fileId":18541,"group":"supergroup","length":79855,"modificationTime":1434167869268,"owner":"michaeljones","pathSuffix":"hellohadoop.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434167244774,"blockSize":134217728,"childrenNum":0,"fileId":18530,"group":"supergroup","length":2134,"modificationTime":1434167244805,"owner":"michaeljones","pathSuffix":"pom.xml","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434167238722,"blockSize":134217728,"childrenNum":0,"fileId":16388,"group":"supergroup","length":50,"modificationTime":1433119638967,"owner":"michaeljones","pathSuffix":"wcInput","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18552,"group":"supergroup","length":0,"modificationTime":1434167876530,"owner":"michaeljones","pathSuffix":"wcOutput","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},
{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18559,"group":"supergroup","length":0,"modificationTime":1434167878094,"owner":"michaeljones","pathSuffix":"wcOutputAnalysis","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},
{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18545,"group":"supergroup","length":0,"modificationTime":1434167875444,"owner":"michaeljones","pathSuffix":"wcOutputMain","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"}
]}}

CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 6][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://localhost:50070
Connecting to localhost/127.0.0.1:50070
Connection established 127.0.0.1:50057<->127.0.0.1:50070
Executing request PUT /webhdfs/v1/user/michaeljones/apache-empty.txt?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-6 >> PUT /webhdfs/v1/user/michaeljones/apache-empty.txt?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1
http-outgoing-6 >> Content-Length: 0
http-outgoing-6 >> Host: localhost:50070
http-outgoing-6 >> Connection: Keep-Alive
http-outgoing-6 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-6 >> Accept-Encoding: gzip,deflate
http-outgoing-6 >> "PUT /webhdfs/v1/user/michaeljones/apache-empty.txt?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1[\r][\n]"
http-outgoing-6 >> "Content-Length: 0[\r][\n]"
http-outgoing-6 >> "Host: localhost:50070[\r][\n]"
http-outgoing-6 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-6 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-6 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-6 >> "[\r][\n]"
http-outgoing-6 << "HTTP/1.1 307 TEMPORARY_REDIRECT[\r][\n]"
http-outgoing-6 << "Cache-Control: no-cache[\r][\n]"
http-outgoing-6 << "Expires: Sat, 13 Jun 2015 03:57:58 GMT[\r][\n]"
http-outgoing-6 << "Date: Sat, 13 Jun 2015 03:57:58 GMT[\r][\n]"
http-outgoing-6 << "Pragma: no-cache[\r][\n]"
http-outgoing-6 << "Expires: Sat, 13 Jun 2015 03:57:58 GMT[\r][\n]"
http-outgoing-6 << "Date: Sat, 13 Jun 2015 03:57:58 GMT[\r][\n]"
http-outgoing-6 << "Pragma: no-cache[\r][\n]"
http-outgoing-6 << "Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434203878978&s=LZ7krL5DLRudjo+j96SDMCGwJWg="; Path=/; Expires=Sat, 13-Jun-2015 13:57:58 GMT; HttpOnly[\r][\n]"
http-outgoing-6 << "Location: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true[\r][\n]"
http-outgoing-6 << "Content-Type: application/octet-stream[\r][\n]"
http-outgoing-6 << "Content-Length: 0[\r][\n]"
http-outgoing-6 << "Server: Jetty(6.1.26)[\r][\n]"
http-outgoing-6 << "[\r][\n]"
http-outgoing-6 << HTTP/1.1 307 TEMPORARY_REDIRECT
http-outgoing-6 << Cache-Control: no-cache
http-outgoing-6 << Expires: Sat, 13 Jun 2015 03:57:58 GMT
http-outgoing-6 << Date: Sat, 13 Jun 2015 03:57:58 GMT
http-outgoing-6 << Pragma: no-cache
http-outgoing-6 << Expires: Sat, 13 Jun 2015 03:57:58 GMT
http-outgoing-6 << Date: Sat, 13 Jun 2015 03:57:58 GMT
http-outgoing-6 << Pragma: no-cache
http-outgoing-6 << Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434203878978&s=LZ7krL5DLRudjo+j96SDMCGwJWg="; Path=/; Expires=Sat, 13-Jun-2015 13:57:58 GMT; HttpOnly
http-outgoing-6 << Location: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
http-outgoing-6 << Content-Type: application/octet-stream
http-outgoing-6 << Content-Length: 0
http-outgoing-6 << Server: Jetty(6.1.26)
Connection can be kept alive indefinitely
Cookie accepted [hadoop.auth=""u=michaeljones&p=michaeljones&t=simple&e=1434203878978&s=LZ7krL5DLRudjo+j96SDMCGwJWg="", version:0, domain:localhost, path:/, expiry:Sat Jun 13 23:57:58 AEST 2015]
Redirect to: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
http-outgoing-6: Shutdown connection
Connection discarded
http-outgoing-6: Close connection
Connection released: [id: 6][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
PUT file redirect: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 7][route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://michaels-air.bigpond:50075
Connecting to Michaels-Air.BigPond/10.0.0.2:50075
Connection established 10.0.0.2:50058<->10.0.0.2:50075
Executing request PUT /webhdfs/v1/user/michaeljones/apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-7 >> PUT /webhdfs/v1/user/michaeljones/apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1
http-outgoing-7 >> Content-Length: 0
http-outgoing-7 >> Host: michaels-air.bigpond:50075
http-outgoing-7 >> Connection: Keep-Alive
http-outgoing-7 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-7 >> Accept-Encoding: gzip,deflate
http-outgoing-7 >> "PUT /webhdfs/v1/user/michaeljones/apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1[\r][\n]"
http-outgoing-7 >> "Content-Length: 0[\r][\n]"
http-outgoing-7 >> "Host: michaels-air.bigpond:50075[\r][\n]"
http-outgoing-7 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-7 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-7 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-7 >> "[\r][\n]"
http-outgoing-7 << "HTTP/1.1 100 Continue[\r][\n]"
http-outgoing-7 << "[\r][\n]"
http-outgoing-7 << HTTP/1.1 100 Continue
http-outgoing-7 << "HTTP/1.1 201 Created[\r][\n]"
http-outgoing-7 << "Location: hdfs://localhost:9000/user/michaeljones/apache-empty.txt[\r][\n]"
http-outgoing-7 << "Content-Length: 0[\r][\n]"
http-outgoing-7 << "Connection: close[\r][\n]"
http-outgoing-7 << "[\r][\n]"
http-outgoing-7 << HTTP/1.1 201 Created
http-outgoing-7 << Location: hdfs://localhost:9000/user/michaeljones/apache-empty.txt
http-outgoing-7 << Content-Length: 0
http-outgoing-7 << Connection: close
http-outgoing-7: Shutdown connection
Connection discarded
http-outgoing-7: Close connection
Connection released: [id: 7][route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 8][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://localhost:50070
Connecting to localhost/127.0.0.1:50070
Connection established 127.0.0.1:50060<->127.0.0.1:50070
Executing request PUT /webhdfs/v1/user/michaeljones/pom.xml?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-8 >> PUT /webhdfs/v1/user/michaeljones/pom.xml?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1
http-outgoing-8 >> Content-Length: 0
http-outgoing-8 >> Host: localhost:50070
http-outgoing-8 >> Connection: Keep-Alive
http-outgoing-8 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-8 >> Accept-Encoding: gzip,deflate
http-outgoing-8 >> "PUT /webhdfs/v1/user/michaeljones/pom.xml?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1[\r][\n]"
http-outgoing-8 >> "Content-Length: 0[\r][\n]"
http-outgoing-8 >> "Host: localhost:50070[\r][\n]"
http-outgoing-8 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-8 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-8 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-8 >> "[\r][\n]"
http-outgoing-8 << "HTTP/1.1 307 TEMPORARY_REDIRECT[\r][\n]"
http-outgoing-8 << "Cache-Control: no-cache[\r][\n]"
http-outgoing-8 << "Expires: Sat, 13 Jun 2015 03:57:59 GMT[\r][\n]"
http-outgoing-8 << "Date: Sat, 13 Jun 2015 03:57:59 GMT[\r][\n]"
http-outgoing-8 << "Pragma: no-cache[\r][\n]"
http-outgoing-8 << "Expires: Sat, 13 Jun 2015 03:57:59 GMT[\r][\n]"
http-outgoing-8 << "Date: Sat, 13 Jun 2015 03:57:59 GMT[\r][\n]"
http-outgoing-8 << "Pragma: no-cache[\r][\n]"
http-outgoing-8 << "Content-Type: application/octet-stream[\r][\n]"
http-outgoing-8 << "Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434203879009&s=1dSgWgM/20UpyDyoiqiWg6eg0fY="; Path=/; Expires=Sat, 13-Jun-2015 13:57:59 GMT; HttpOnly[\r][\n]"
http-outgoing-8 << "Location: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/pom.xml?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true[\r][\n]"
http-outgoing-8 << "Content-Length: 0[\r][\n]"
http-outgoing-8 << "Server: Jetty(6.1.26)[\r][\n]"
http-outgoing-8 << "[\r][\n]"
http-outgoing-8 << HTTP/1.1 307 TEMPORARY_REDIRECT
http-outgoing-8 << Cache-Control: no-cache
http-outgoing-8 << Expires: Sat, 13 Jun 2015 03:57:59 GMT
http-outgoing-8 << Date: Sat, 13 Jun 2015 03:57:59 GMT
http-outgoing-8 << Pragma: no-cache
http-outgoing-8 << Expires: Sat, 13 Jun 2015 03:57:59 GMT
http-outgoing-8 << Date: Sat, 13 Jun 2015 03:57:59 GMT
http-outgoing-8 << Pragma: no-cache
http-outgoing-8 << Content-Type: application/octet-stream
http-outgoing-8 << Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434203879009&s=1dSgWgM/20UpyDyoiqiWg6eg0fY="; Path=/; Expires=Sat, 13-Jun-2015 13:57:59 GMT; HttpOnly
http-outgoing-8 << Location: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/pom.xml?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
http-outgoing-8 << Content-Length: 0
http-outgoing-8 << Server: Jetty(6.1.26)
Connection can be kept alive indefinitely
Cookie accepted [hadoop.auth=""u=michaeljones&p=michaeljones&t=simple&e=1434203879009&s=1dSgWgM/20UpyDyoiqiWg6eg0fY="", version:0, domain:localhost, path:/, expiry:Sat Jun 13 23:57:59 AEST 2015]
Redirect to: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/pom.xml?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
http-outgoing-8: Shutdown connection
Connection discarded
http-outgoing-8: Close connection
Connection released: [id: 8][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
PUT file redirect: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/pom.xml?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 9][route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://michaels-air.bigpond:50075
Connecting to Michaels-Air.BigPond/10.0.0.2:50075
Connection established 10.0.0.2:50061<->10.0.0.2:50075
Executing request PUT /webhdfs/v1/user/michaeljones/pom.xml?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-9 >> PUT /webhdfs/v1/user/michaeljones/pom.xml?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1
http-outgoing-9 >> Transfer-Encoding: chunked
http-outgoing-9 >> Content-Type: application/octet-stream
http-outgoing-9 >> Host: michaels-air.bigpond:50075
http-outgoing-9 >> Connection: Keep-Alive
http-outgoing-9 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-9 >> Accept-Encoding: gzip,deflate
http-outgoing-9 >> "PUT /webhdfs/v1/user/michaeljones/pom.xml?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1[\r][\n]"
http-outgoing-9 >> "Transfer-Encoding: chunked[\r][\n]"
http-outgoing-9 >> "Content-Type: application/octet-stream[\r][\n]"
http-outgoing-9 >> "Host: michaels-air.bigpond:50075[\r][\n]"
http-outgoing-9 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-9 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-9 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-9 >> "[\r][\n]"
http-outgoing-9 >> "856[\r][\n]"
http-outgoing-9 >> "<?xml version="1.0" encoding="UTF-8"?>[\n]"
http-outgoing-9 >> "<project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">[\n]"
http-outgoing-9 >> "    <modelVersion>4.0.0</modelVersion>[\n]"
http-outgoing-9 >> "    <groupId>com.michaeljones</groupId>[\n]"
http-outgoing-9 >> "    <artifactId>HelloHadoopWorldMaven</artifactId>[\n]"
http-outgoing-9 >> "    <version>1.0-SNAPSHOT</version>[\n]"
http-outgoing-9 >> "    <packaging>jar</packaging>[\n]"
http-outgoing-9 >> "    <dependencies>[\n]"
http-outgoing-9 >> "        <!-- run bin/hadoop version to see the jar it was built with, which is this dependency -->[\n]"
http-outgoing-9 >> "        <dependency>[\n]"
http-outgoing-9 >> "            <groupId>org.apache.hadoop</groupId>[\n]"
http-outgoing-9 >> "            <artifactId>hadoop-common</artifactId>[\n]"
http-outgoing-9 >> "            <version>2.7.0</version>[\n]"
http-outgoing-9 >> "        </dependency>[\n]"
http-outgoing-9 >> "        <dependency>[\n]"
http-outgoing-9 >> "            <groupId>org.apache.hadoop</groupId>[\n]"
http-outgoing-9 >> "            <artifactId>hadoop-hdfs</artifactId>[\n]"
http-outgoing-9 >> "            <version>2.7.0</version>[\n]"
http-outgoing-9 >> "        </dependency>[\n]"
http-outgoing-9 >> "        <dependency>[\n]"
http-outgoing-9 >> "            <groupId>junit</groupId>[\n]"
http-outgoing-9 >> "            <artifactId>junit</artifactId>[\n]"
http-outgoing-9 >> "            <version>4.10</version>[\n]"
http-outgoing-9 >> "            <scope>test</scope>[\n]"
http-outgoing-9 >> "        </dependency>[\n]"
http-outgoing-9 >> "        <dependency>[\n]"
http-outgoing-9 >> "            <groupId>org.apache.hadoop</groupId>[\n]"
http-outgoing-9 >> "            <artifactId>hadoop-mapreduce-client-core</artifactId>[\n]"
http-outgoing-9 >> "            <version>2.7.0</version>[\n]"
http-outgoing-9 >> "        </dependency>[\n]"
http-outgoing-9 >> "        <dependency>[\n]"
http-outgoing-9 >> "            <groupId>org.apache.hadoop</groupId>[\n]"
http-outgoing-9 >> "            <artifactId>hadoop-mapreduce-client-common</artifactId>[\n]"
http-outgoing-9 >> "            <version>2.7.0</version>[\n]"
http-outgoing-9 >> "        </dependency>[\n]"
http-outgoing-9 >> "        <dependency>[\n]"
http-outgoing-9 >> "            <groupId>com.googlecode.json-simple</groupId>[\n]"
http-outgoing-9 >> "            <artifactId>json-simple</artifactId>[\n]"
http-outgoing-9 >> "            <version>1.1.1</version>[\n]"
http-outgoing-9 >> "        </dependency>[\n]"
http-outgoing-9 >> "        <dependency>[\n]"
http-outgoing-9 >> "            <groupId>org.apache.httpcomponents</groupId>[\n]"
http-outgoing-9 >> "            <artifactId>httpclient</artifactId>[\n]"
http-outgoing-9 >> "            <version>4.4-beta1</version>[\n]"
http-outgoing-9 >> "        </dependency>[\n]"
http-outgoing-9 >> "    </dependencies>[\n]"
http-outgoing-9 >> "    <properties>[\n]"
http-outgoing-9 >> "        <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>[\n]"
http-outgoing-9 >> "        <maven.compiler.source>1.7</maven.compiler.source>[\n]"
http-outgoing-9 >> "        <maven.compiler.target>1.7</maven.compiler.target>[\n]"
http-outgoing-9 >> "    </properties>[\n]"
http-outgoing-9 >> "</project>[\r][\n]"
http-outgoing-9 >> "0[\r][\n]"
http-outgoing-9 >> "[\r][\n]"
http-outgoing-9 << "HTTP/1.1 100 Continue[\r][\n]"
http-outgoing-9 << "[\r][\n]"
http-outgoing-9 << HTTP/1.1 100 Continue
http-outgoing-9 << "HTTP/1.1 201 Created[\r][\n]"
http-outgoing-9 << "Location: hdfs://localhost:9000/user/michaeljones/pom.xml[\r][\n]"
http-outgoing-9 << "Content-Length: 0[\r][\n]"
http-outgoing-9 << "Connection: close[\r][\n]"
http-outgoing-9 << "[\r][\n]"
http-outgoing-9 << HTTP/1.1 201 Created
http-outgoing-9 << Location: hdfs://localhost:9000/user/michaeljones/pom.xml
http-outgoing-9 << Content-Length: 0
http-outgoing-9 << Connection: close
http-outgoing-9: Shutdown connection
Connection discarded
http-outgoing-9: Close connection
Connection released: [id: 9][route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection manager is shutting down
Connection manager shut down
Jersey client testGetStringContent
{"FileStatuses":{"FileStatus":[
{"accessTime":1434167869661,"blockSize":134217728,"childrenNum":0,"fileId":18543,"group":"supergroup","length":10899,"modificationTime":1434167869692,"owner":"michaeljones","pathSuffix":"README.md","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434167878992,"blockSize":134217728,"childrenNum":0,"fileId":18566,"group":"supergroup","length":0,"modificationTime":1434167878996,"owner":"michaeljones","pathSuffix":"apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434167800851,"blockSize":134217728,"childrenNum":0,"fileId":18536,"group":"supergroup","length":0,"modificationTime":1434167800857,"owner":"michaeljones","pathSuffix":"empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434167868991,"blockSize":134217728,"childrenNum":0,"fileId":18540,"group":"supergroup","length":0,"modificationTime":1434167868996,"owner":"michaeljones","pathSuffix":"hello-apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434091626279,"blockSize":134217728,"childrenNum":0,"fileId":18298,"group":"supergroup","length":0,"modificationTime":1434091626286,"owner":"michaeljones","pathSuffix":"hello-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434167868891,"blockSize":134217728,"childrenNum":0,"fileId":18539,"group":"supergroup","length":0,"modificationTime":1434167868901,"owner":"michaeljones","pathSuffix":"hello-jersey-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434167801365,"blockSize":134217728,"childrenNum":0,"fileId":18538,"group":"supergroup","length":1505861,"modificationTime":1434167801408,"owner":"michaeljones","pathSuffix":"hello.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434167869373,"blockSize":134217728,"childrenNum":0,"fileId":18542,"group":"supergroup","length":3678856,"modificationTime":1434167869495,"owner":"michaeljones","pathSuffix":"hello.log.2015-06-12","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434167872655,"blockSize":134217728,"childrenNum":0,"fileId":18544,"group":"supergroup","length":20,"modificationTime":1434167873103,"owner":"michaeljones","pathSuffix":"hello.txt","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434167869241,"blockSize":134217728,"childrenNum":0,"fileId":18541,"group":"supergroup","length":79855,"modificationTime":1434167869268,"owner":"michaeljones","pathSuffix":"hellohadoop.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434167879043,"blockSize":134217728,"childrenNum":0,"fileId":18567,"group":"supergroup","length":2134,"modificationTime":1434167879075,"owner":"michaeljones","pathSuffix":"pom.xml","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434167238722,"blockSize":134217728,"childrenNum":0,"fileId":16388,"group":"supergroup","length":50,"modificationTime":1433119638967,"owner":"michaeljones","pathSuffix":"wcInput","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18552,"group":"supergroup","length":0,"modificationTime":1434167876530,"owner":"michaeljones","pathSuffix":"wcOutput","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},
{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18559,"group":"supergroup","length":0,"modificationTime":1434167878094,"owner":"michaeljones","pathSuffix":"wcOutputAnalysis","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},
{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18545,"group":"supergroup","length":0,"modificationTime":1434167875444,"owner":"michaeljones","pathSuffix":"wcOutputMain","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"}
]}}

com.sun.jersey.client.property.chunkedEncodingSize: 1048576
Jersey client Redirect to: hdfs://localhost:9000/user/michaeljones/hello.log
Jersey redirected to IPC: hdfs://localhost:9000/user/michaeljones/hello.log
stopping client from cache: org.apache.hadoop.ipc.Client@22d7b4f8
removing client from cache: org.apache.hadoop.ipc.Client@22d7b4f8
stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@22d7b4f8
Stopping client
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones: closed
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones: stopped, remaining connections 0
com.sun.jersey.client.property.chunkedEncodingSize: 1048576
com.sun.jersey.client.property.chunkedEncodingSize: 1048576
Jersey client testGetStringContent
{"FileStatuses":{"FileStatus":[
{"accessTime":1434167869661,"blockSize":134217728,"childrenNum":0,"fileId":18543,"group":"supergroup","length":10899,"modificationTime":1434167869692,"owner":"michaeljones","pathSuffix":"README.md","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434167878992,"blockSize":134217728,"childrenNum":0,"fileId":18566,"group":"supergroup","length":0,"modificationTime":1434167878996,"owner":"michaeljones","pathSuffix":"apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434167879763,"blockSize":134217728,"childrenNum":0,"fileId":18569,"group":"supergroup","length":0,"modificationTime":1434167879767,"owner":"michaeljones","pathSuffix":"empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434167868991,"blockSize":134217728,"childrenNum":0,"fileId":18540,"group":"supergroup","length":0,"modificationTime":1434167868996,"owner":"michaeljones","pathSuffix":"hello-apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434091626279,"blockSize":134217728,"childrenNum":0,"fileId":18298,"group":"supergroup","length":0,"modificationTime":1434091626286,"owner":"michaeljones","pathSuffix":"hello-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434167868891,"blockSize":134217728,"childrenNum":0,"fileId":18539,"group":"supergroup","length":0,"modificationTime":1434167868901,"owner":"michaeljones","pathSuffix":"hello-jersey-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434167879896,"blockSize":134217728,"childrenNum":0,"fileId":18570,"group":"supergroup","length":1915003,"modificationTime":1434167879946,"owner":"michaeljones","pathSuffix":"hello.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434167869373,"blockSize":134217728,"childrenNum":0,"fileId":18542,"group":"supergroup","length":3678856,"modificationTime":1434167869495,"owner":"michaeljones","pathSuffix":"hello.log.2015-06-12","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434167872655,"blockSize":134217728,"childrenNum":0,"fileId":18544,"group":"supergroup","length":20,"modificationTime":1434167873103,"owner":"michaeljones","pathSuffix":"hello.txt","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434167869241,"blockSize":134217728,"childrenNum":0,"fileId":18541,"group":"supergroup","length":79855,"modificationTime":1434167869268,"owner":"michaeljones","pathSuffix":"hellohadoop.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434167879043,"blockSize":134217728,"childrenNum":0,"fileId":18567,"group":"supergroup","length":2134,"modificationTime":1434167879075,"owner":"michaeljones","pathSuffix":"pom.xml","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434167238722,"blockSize":134217728,"childrenNum":0,"fileId":16388,"group":"supergroup","length":50,"modificationTime":1433119638967,"owner":"michaeljones","pathSuffix":"wcInput","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18552,"group":"supergroup","length":0,"modificationTime":1434167876530,"owner":"michaeljones","pathSuffix":"wcOutput","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},
{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18559,"group":"supergroup","length":0,"modificationTime":1434167878094,"owner":"michaeljones","pathSuffix":"wcOutputAnalysis","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},
{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18545,"group":"supergroup","length":0,"modificationTime":1434167875444,"owner":"michaeljones","pathSuffix":"wcOutputMain","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"}
]}}

Jersey client Redirect to: hdfs://localhost:9000/user/michaeljones/hello.log
Jersey redirected to IPC: hdfs://localhost:9000/user/michaeljones/hello.log
com.sun.jersey.client.property.chunkedEncodingSize: 1048576
com.sun.jersey.client.property.chunkedEncodingSize: 1048576
com.sun.jersey.client.property.chunkedEncodingSize: 1048576
com.sun.jersey.client.property.chunkedEncodingSize: 1048576
Jersey client Redirect to: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/hello.log?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
Jersey client testGetStringContent
{"FileStatuses":{"FileStatus":[
{"accessTime":1434167869661,"blockSize":134217728,"childrenNum":0,"fileId":18543,"group":"supergroup","length":10899,"modificationTime":1434167869692,"owner":"michaeljones","pathSuffix":"README.md","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434167878992,"blockSize":134217728,"childrenNum":0,"fileId":18566,"group":"supergroup","length":0,"modificationTime":1434167878996,"owner":"michaeljones","pathSuffix":"apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434180144304,"blockSize":134217728,"childrenNum":0,"fileId":18571,"group":"supergroup","length":0,"modificationTime":1434180144392,"owner":"michaeljones","pathSuffix":"empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434167868991,"blockSize":134217728,"childrenNum":0,"fileId":18540,"group":"supergroup","length":0,"modificationTime":1434167868996,"owner":"michaeljones","pathSuffix":"hello-apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434091626279,"blockSize":134217728,"childrenNum":0,"fileId":18298,"group":"supergroup","length":0,"modificationTime":1434091626286,"owner":"michaeljones","pathSuffix":"hello-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434167868891,"blockSize":134217728,"childrenNum":0,"fileId":18539,"group":"supergroup","length":0,"modificationTime":1434167868901,"owner":"michaeljones","pathSuffix":"hello-jersey-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434180146274,"blockSize":134217728,"childrenNum":0,"fileId":18574,"group":"supergroup","length":0,"modificationTime":1434180146309,"owner":"michaeljones","pathSuffix":"hello.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434167869373,"blockSize":134217728,"childrenNum":0,"fileId":18542,"group":"supergroup","length":3678856,"modificationTime":1434167869495,"owner":"michaeljones","pathSuffix":"hello.log.2015-06-12","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434167872655,"blockSize":134217728,"childrenNum":0,"fileId":18544,"group":"supergroup","length":20,"modificationTime":1434167873103,"owner":"michaeljones","pathSuffix":"hello.txt","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434167869241,"blockSize":134217728,"childrenNum":0,"fileId":18541,"group":"supergroup","length":79855,"modificationTime":1434167869268,"owner":"michaeljones","pathSuffix":"hellohadoop.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434167879043,"blockSize":134217728,"childrenNum":0,"fileId":18567,"group":"supergroup","length":2134,"modificationTime":1434167879075,"owner":"michaeljones","pathSuffix":"pom.xml","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434167238722,"blockSize":134217728,"childrenNum":0,"fileId":16388,"group":"supergroup","length":50,"modificationTime":1433119638967,"owner":"michaeljones","pathSuffix":"wcInput","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18552,"group":"supergroup","length":0,"modificationTime":1434167876530,"owner":"michaeljones","pathSuffix":"wcOutput","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},
{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18559,"group":"supergroup","length":0,"modificationTime":1434167878094,"owner":"michaeljones","pathSuffix":"wcOutputAnalysis","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},
{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18545,"group":"supergroup","length":0,"modificationTime":1434167875444,"owner":"michaeljones","pathSuffix":"wcOutputMain","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"}
]}}

Jersey client Redirect to: hdfs://localhost:9000/user/michaeljones/hello.log
Jersey redirected to IPC: hdfs://localhost:9000/user/michaeljones/hello.log
Jersey client testGetStringContent
{"FileStatuses":{"FileStatus":[
{"accessTime":1434167869661,"blockSize":134217728,"childrenNum":0,"fileId":18543,"group":"supergroup","length":10899,"modificationTime":1434167869692,"owner":"michaeljones","pathSuffix":"README.md","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434167878992,"blockSize":134217728,"childrenNum":0,"fileId":18566,"group":"supergroup","length":0,"modificationTime":1434167878996,"owner":"michaeljones","pathSuffix":"apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434180267201,"blockSize":134217728,"childrenNum":0,"fileId":18575,"group":"supergroup","length":0,"modificationTime":1434180267207,"owner":"michaeljones","pathSuffix":"empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434167868991,"blockSize":134217728,"childrenNum":0,"fileId":18540,"group":"supergroup","length":0,"modificationTime":1434167868996,"owner":"michaeljones","pathSuffix":"hello-apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434091626279,"blockSize":134217728,"childrenNum":0,"fileId":18298,"group":"supergroup","length":0,"modificationTime":1434091626286,"owner":"michaeljones","pathSuffix":"hello-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434167868891,"blockSize":134217728,"childrenNum":0,"fileId":18539,"group":"supergroup","length":0,"modificationTime":1434167868901,"owner":"michaeljones","pathSuffix":"hello-jersey-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434180267831,"blockSize":134217728,"childrenNum":0,"fileId":18577,"group":"supergroup","length":1924560,"modificationTime":1434180267890,"owner":"michaeljones","pathSuffix":"hello.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434167869373,"blockSize":134217728,"childrenNum":0,"fileId":18542,"group":"supergroup","length":3678856,"modificationTime":1434167869495,"owner":"michaeljones","pathSuffix":"hello.log.2015-06-12","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434167872655,"blockSize":134217728,"childrenNum":0,"fileId":18544,"group":"supergroup","length":20,"modificationTime":1434167873103,"owner":"michaeljones","pathSuffix":"hello.txt","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434167869241,"blockSize":134217728,"childrenNum":0,"fileId":18541,"group":"supergroup","length":79855,"modificationTime":1434167869268,"owner":"michaeljones","pathSuffix":"hellohadoop.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434167879043,"blockSize":134217728,"childrenNum":0,"fileId":18567,"group":"supergroup","length":2134,"modificationTime":1434167879075,"owner":"michaeljones","pathSuffix":"pom.xml","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434167238722,"blockSize":134217728,"childrenNum":0,"fileId":16388,"group":"supergroup","length":50,"modificationTime":1433119638967,"owner":"michaeljones","pathSuffix":"wcInput","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18552,"group":"supergroup","length":0,"modificationTime":1434167876530,"owner":"michaeljones","pathSuffix":"wcOutput","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},
{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18559,"group":"supergroup","length":0,"modificationTime":1434167878094,"owner":"michaeljones","pathSuffix":"wcOutputAnalysis","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},
{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18545,"group":"supergroup","length":0,"modificationTime":1434167875444,"owner":"michaeljones","pathSuffix":"wcOutputMain","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"}
]}}

Jersey client Redirect to: hdfs://localhost:9000/user/michaeljones/hello.log
Jersey redirected to IPC: hdfs://localhost:9000/user/michaeljones/hello.log
com.sun.jersey.client.property.chunkedEncodingSize: 1048576
com.sun.jersey.client.property.chunkedEncodingSize: 1048576
Jersey client Redirect to: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/hello.log?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
Jersey client testGetStringContent
{"FileStatuses":{"FileStatus":[
{"accessTime":1434167869661,"blockSize":134217728,"childrenNum":0,"fileId":18543,"group":"supergroup","length":10899,"modificationTime":1434167869692,"owner":"michaeljones","pathSuffix":"README.md","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434167878992,"blockSize":134217728,"childrenNum":0,"fileId":18566,"group":"supergroup","length":0,"modificationTime":1434167878996,"owner":"michaeljones","pathSuffix":"apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434180319804,"blockSize":134217728,"childrenNum":0,"fileId":18578,"group":"supergroup","length":0,"modificationTime":1434180319811,"owner":"michaeljones","pathSuffix":"empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434167868991,"blockSize":134217728,"childrenNum":0,"fileId":18540,"group":"supergroup","length":0,"modificationTime":1434167868996,"owner":"michaeljones","pathSuffix":"hello-apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434091626279,"blockSize":134217728,"childrenNum":0,"fileId":18298,"group":"supergroup","length":0,"modificationTime":1434091626286,"owner":"michaeljones","pathSuffix":"hello-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434167868891,"blockSize":134217728,"childrenNum":0,"fileId":18539,"group":"supergroup","length":0,"modificationTime":1434167868901,"owner":"michaeljones","pathSuffix":"hello-jersey-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434180349849,"blockSize":134217728,"childrenNum":0,"fileId":18581,"group":"supergroup","length":1929072,"modificationTime":1434180349912,"owner":"michaeljones","pathSuffix":"hello.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434167869373,"blockSize":134217728,"childrenNum":0,"fileId":18542,"group":"supergroup","length":3678856,"modificationTime":1434167869495,"owner":"michaeljones","pathSuffix":"hello.log.2015-06-12","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434167872655,"blockSize":134217728,"childrenNum":0,"fileId":18544,"group":"supergroup","length":20,"modificationTime":1434167873103,"owner":"michaeljones","pathSuffix":"hello.txt","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434167869241,"blockSize":134217728,"childrenNum":0,"fileId":18541,"group":"supergroup","length":79855,"modificationTime":1434167869268,"owner":"michaeljones","pathSuffix":"hellohadoop.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434167879043,"blockSize":134217728,"childrenNum":0,"fileId":18567,"group":"supergroup","length":2134,"modificationTime":1434167879075,"owner":"michaeljones","pathSuffix":"pom.xml","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434167238722,"blockSize":134217728,"childrenNum":0,"fileId":16388,"group":"supergroup","length":50,"modificationTime":1433119638967,"owner":"michaeljones","pathSuffix":"wcInput","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18552,"group":"supergroup","length":0,"modificationTime":1434167876530,"owner":"michaeljones","pathSuffix":"wcOutput","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},
{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18559,"group":"supergroup","length":0,"modificationTime":1434167878094,"owner":"michaeljones","pathSuffix":"wcOutputAnalysis","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},
{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18545,"group":"supergroup","length":0,"modificationTime":1434167875444,"owner":"michaeljones","pathSuffix":"wcOutputMain","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"}
]}}

Jersey client Redirect to: hdfs://localhost:9000/user/michaeljones/hello.log
Jersey redirected to IPC: hdfs://localhost:9000/user/michaeljones/hello.log
com.sun.jersey.client.property.chunkedEncodingSize: 1048576
com.sun.jersey.client.property.chunkedEncodingSize: 1048576
Jersey client Redirect to: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/hello.log?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
Jersey client Redirect to: hdfs://localhost:9000/user/michaeljones/hello.log
Jersey redirected to IPC: hdfs://localhost:9000/user/michaeljones/hello.log
com.sun.jersey.client.property.chunkedEncodingSize: 1048576
com.sun.jersey.client.property.chunkedEncodingSize: 1048576
Jersey client Redirect to: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/pom.xml?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
Jersey client testGetStringContent
{"FileStatuses":{"FileStatus":[
{"accessTime":1434167869661,"blockSize":134217728,"childrenNum":0,"fileId":18543,"group":"supergroup","length":10899,"modificationTime":1434167869692,"owner":"michaeljones","pathSuffix":"README.md","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434167878992,"blockSize":134217728,"childrenNum":0,"fileId":18566,"group":"supergroup","length":0,"modificationTime":1434167878996,"owner":"michaeljones","pathSuffix":"apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434180565728,"blockSize":134217728,"childrenNum":0,"fileId":18586,"group":"supergroup","length":0,"modificationTime":1434180565736,"owner":"michaeljones","pathSuffix":"empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434167868991,"blockSize":134217728,"childrenNum":0,"fileId":18540,"group":"supergroup","length":0,"modificationTime":1434167868996,"owner":"michaeljones","pathSuffix":"hello-apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434091626279,"blockSize":134217728,"childrenNum":0,"fileId":18298,"group":"supergroup","length":0,"modificationTime":1434091626286,"owner":"michaeljones","pathSuffix":"hello-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434167868891,"blockSize":134217728,"childrenNum":0,"fileId":18539,"group":"supergroup","length":0,"modificationTime":1434167868901,"owner":"michaeljones","pathSuffix":"hello-jersey-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434180566460,"blockSize":134217728,"childrenNum":0,"fileId":18588,"group":"supergroup","length":1933737,"modificationTime":1434180566503,"owner":"michaeljones","pathSuffix":"hello.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434167869373,"blockSize":134217728,"childrenNum":0,"fileId":18542,"group":"supergroup","length":3678856,"modificationTime":1434167869495,"owner":"michaeljones","pathSuffix":"hello.log.2015-06-12","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434167872655,"blockSize":134217728,"childrenNum":0,"fileId":18544,"group":"supergroup","length":20,"modificationTime":1434167873103,"owner":"michaeljones","pathSuffix":"hello.txt","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434167869241,"blockSize":134217728,"childrenNum":0,"fileId":18541,"group":"supergroup","length":79855,"modificationTime":1434167869268,"owner":"michaeljones","pathSuffix":"hellohadoop.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434180567125,"blockSize":134217728,"childrenNum":0,"fileId":18589,"group":"supergroup","length":2134,"modificationTime":1434180567151,"owner":"michaeljones","pathSuffix":"pom.xml","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434167238722,"blockSize":134217728,"childrenNum":0,"fileId":16388,"group":"supergroup","length":50,"modificationTime":1433119638967,"owner":"michaeljones","pathSuffix":"wcInput","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18552,"group":"supergroup","length":0,"modificationTime":1434167876530,"owner":"michaeljones","pathSuffix":"wcOutput","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},
{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18559,"group":"supergroup","length":0,"modificationTime":1434167878094,"owner":"michaeljones","pathSuffix":"wcOutputAnalysis","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},
{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18545,"group":"supergroup","length":0,"modificationTime":1434167875444,"owner":"michaeljones","pathSuffix":"wcOutputMain","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"}
]}}

Jersey client testGetStringContent
{"FileStatuses":{"FileStatus":[
{"accessTime":1434167869661,"blockSize":134217728,"childrenNum":0,"fileId":18543,"group":"supergroup","length":10899,"modificationTime":1434167869692,"owner":"michaeljones","pathSuffix":"README.md","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434167878992,"blockSize":134217728,"childrenNum":0,"fileId":18566,"group":"supergroup","length":0,"modificationTime":1434167878996,"owner":"michaeljones","pathSuffix":"apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434180565728,"blockSize":134217728,"childrenNum":0,"fileId":18586,"group":"supergroup","length":0,"modificationTime":1434180565736,"owner":"michaeljones","pathSuffix":"empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434167868991,"blockSize":134217728,"childrenNum":0,"fileId":18540,"group":"supergroup","length":0,"modificationTime":1434167868996,"owner":"michaeljones","pathSuffix":"hello-apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434091626279,"blockSize":134217728,"childrenNum":0,"fileId":18298,"group":"supergroup","length":0,"modificationTime":1434091626286,"owner":"michaeljones","pathSuffix":"hello-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434167868891,"blockSize":134217728,"childrenNum":0,"fileId":18539,"group":"supergroup","length":0,"modificationTime":1434167868901,"owner":"michaeljones","pathSuffix":"hello-jersey-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434180566460,"blockSize":134217728,"childrenNum":0,"fileId":18588,"group":"supergroup","length":1933737,"modificationTime":1434180566503,"owner":"michaeljones","pathSuffix":"hello.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434167869373,"blockSize":134217728,"childrenNum":0,"fileId":18542,"group":"supergroup","length":3678856,"modificationTime":1434167869495,"owner":"michaeljones","pathSuffix":"hello.log.2015-06-12","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434167872655,"blockSize":134217728,"childrenNum":0,"fileId":18544,"group":"supergroup","length":20,"modificationTime":1434167873103,"owner":"michaeljones","pathSuffix":"hello.txt","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434167869241,"blockSize":134217728,"childrenNum":0,"fileId":18541,"group":"supergroup","length":79855,"modificationTime":1434167869268,"owner":"michaeljones","pathSuffix":"hellohadoop.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434180567125,"blockSize":134217728,"childrenNum":0,"fileId":18589,"group":"supergroup","length":2134,"modificationTime":1434180567151,"owner":"michaeljones","pathSuffix":"pom.xml","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434167238722,"blockSize":134217728,"childrenNum":0,"fileId":16388,"group":"supergroup","length":50,"modificationTime":1433119638967,"owner":"michaeljones","pathSuffix":"wcInput","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18552,"group":"supergroup","length":0,"modificationTime":1434167876530,"owner":"michaeljones","pathSuffix":"wcOutput","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},
{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18559,"group":"supergroup","length":0,"modificationTime":1434167878094,"owner":"michaeljones","pathSuffix":"wcOutputAnalysis","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},
{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18545,"group":"supergroup","length":0,"modificationTime":1434167875444,"owner":"michaeljones","pathSuffix":"wcOutputMain","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"}
]}}

Jersey client Redirect to: hdfs://localhost:9000/user/michaeljones/hello.log
Jersey redirected to IPC: hdfs://localhost:9000/user/michaeljones/hello.log
com.sun.jersey.client.property.chunkedEncodingSize: 1048576
com.sun.jersey.client.property.chunkedEncodingSize: 1048576
Jersey client Redirect to: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/nbactions.xml?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 0][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://localhost:50070
Connecting to localhost/127.0.0.1:50070
Connection established 127.0.0.1:49936<->127.0.0.1:50070
Executing request GET /webhdfs/v1/user/michaeljones/?user.name=michaeljones&op=LISTSTATUS HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-0 >> GET /webhdfs/v1/user/michaeljones/?user.name=michaeljones&op=LISTSTATUS HTTP/1.1
http-outgoing-0 >> accept: application/json
http-outgoing-0 >> Host: localhost:50070
http-outgoing-0 >> Connection: Keep-Alive
http-outgoing-0 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-0 >> Accept-Encoding: gzip,deflate
http-outgoing-0 >> "GET /webhdfs/v1/user/michaeljones/?user.name=michaeljones&op=LISTSTATUS HTTP/1.1[\r][\n]"
http-outgoing-0 >> "accept: application/json[\r][\n]"
http-outgoing-0 >> "Host: localhost:50070[\r][\n]"
http-outgoing-0 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-0 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-0 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-0 >> "[\r][\n]"
http-outgoing-0 << "HTTP/1.1 200 OK[\r][\n]"
http-outgoing-0 << "Cache-Control: no-cache[\r][\n]"
http-outgoing-0 << "Expires: Sat, 13 Jun 2015 07:32:31 GMT[\r][\n]"
http-outgoing-0 << "Date: Sat, 13 Jun 2015 07:32:31 GMT[\r][\n]"
http-outgoing-0 << "Pragma: no-cache[\r][\n]"
http-outgoing-0 << "Expires: Sat, 13 Jun 2015 07:32:31 GMT[\r][\n]"
http-outgoing-0 << "Date: Sat, 13 Jun 2015 07:32:31 GMT[\r][\n]"
http-outgoing-0 << "Pragma: no-cache[\r][\n]"
http-outgoing-0 << "Content-Type: application/json[\r][\n]"
http-outgoing-0 << "Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434216751821&s=95dJlz2YW4cks1jP9Z31p/urkbA="; Path=/; Expires=Sat, 13-Jun-2015 17:32:31 GMT; HttpOnly[\r][\n]"
http-outgoing-0 << "Transfer-Encoding: chunked[\r][\n]"
http-outgoing-0 << "Server: Jetty(6.1.26)[\r][\n]"
http-outgoing-0 << "[\r][\n]"
http-outgoing-0 << "10C3[\r][\n]"
http-outgoing-0 << "{"FileStatuses":{"FileStatus":[[\n]"
http-outgoing-0 << "{"accessTime":1434167869661,"blockSize":134217728,"childrenNum":0,"fileId":18543,"group":"supergroup","length":10899,"modificationTime":1434167869692,"owner":"michaeljones","pathSuffix":"README.md","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434167878992,"blockSize":134217728,"childrenNum":0,"fileId":18566,"group":"supergroup","length":0,"modificationTime":1434167878996,"owner":"michaeljones","pathSuffix":"apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434180637491,"blockSize":134217728,"childrenNum":0,"fileId":18590,"group":"supergroup","length":0,"modificationTime":1434180637503,"owner":"michaeljones","pathSuffix":"empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434167868991,"blockSize":134217728,"childrenNum":0,"fileId":18540,"group":"supergroup","length":0,"modificationTime":1434167868996,"owner":"michaeljones","pathSuffix":"hello-apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434091626279,"blockSize":134217728,"childrenNum":0,"fileId":18298,"group":"supergroup","length":0,"modificationTime":1434091626286,"owner":"michaeljones","pathSuffix":"hello-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434167868891,"blockSize":134217728,"childrenNum":0,"fileId":18539,"group":"supergroup","length":0,"modificationTime":1434167868901,"owner":"michaeljones","pathSuffix":"hello-jersey-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434180638087,"blockSize":134217728,"childrenNum":0,"fileId":18592,"group":"supergroup","length":1942304,"modificationTime":1434180638134,"owner":"michaeljones","pathSuffix":"hello.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434167869373,"blockSize":134217728,"childrenNum":0,"fileId":18542,"group":"supergroup","length":3678856,"modificationTime":1434167869495,"owner":"michaeljones","pathSuffix":"hello.log.2015-06-12","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434167872655,"blockSize":134217728,"childrenNum":0,"fileId":18544,"group":"supergroup","length":20,"modificationTime":1434167873103,"owner":"michaeljones","pathSuffix":"hello.txt","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434167869241,"blockSize":134217728,"childrenNum":0,"fileId":18541,"group":"supergroup","length":79855,"modificationTime":1434167869268,"owner":"michaeljones","pathSuffix":"hellohadoop.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434180638675,"blockSize":134217728,"childrenNum":0,"fileId":18593,"group":"supergroup","length":3644,"modificationTime":1434180638702,"owner":"michaeljones","pathSuffix":"nbactions.xml","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434180567125,"blockSize":134217728,"childrenNum":0,"fileId":18589,"group":"supergroup","length":2134,"modificationTime":1434180567151,"owner":"michaeljones","pathSuffix":"pom.xml","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434167238722,"blockSize":134217728,"childrenNum":0,"fileId":16388,"group":"supergroup","length":50,"modificationTime":1433119638967,"owner":"michaeljones","pathSuffix":"wcInput","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18552,"group":"supergroup","length":0,"modificationTime":1434167876530,"owner":"michaeljones","pathSuffix":"wcOutput","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},[\n]"
http-outgoing-0 << "{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18559,"group":"supergroup","length":0,"modificationTime":1434167878094,"owner":"michaeljones","pathSuffix":"wcOutputAnalysis","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},[\n]"
http-outgoing-0 << "{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18545,"group":"supergroup","length":0,"modificationTime":1434167875444,"owner":"michaeljones","pathSuffix":"wcOutputMain","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"}[\n]"
http-outgoing-0 << "]}}[\n]"
http-outgoing-0 << "[\r][\n]"
http-outgoing-0 << HTTP/1.1 200 OK
http-outgoing-0 << Cache-Control: no-cache
http-outgoing-0 << Expires: Sat, 13 Jun 2015 07:32:31 GMT
http-outgoing-0 << Date: Sat, 13 Jun 2015 07:32:31 GMT
http-outgoing-0 << Pragma: no-cache
http-outgoing-0 << Expires: Sat, 13 Jun 2015 07:32:31 GMT
http-outgoing-0 << Date: Sat, 13 Jun 2015 07:32:31 GMT
http-outgoing-0 << Pragma: no-cache
http-outgoing-0 << Content-Type: application/json
http-outgoing-0 << Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434216751821&s=95dJlz2YW4cks1jP9Z31p/urkbA="; Path=/; Expires=Sat, 13-Jun-2015 17:32:31 GMT; HttpOnly
http-outgoing-0 << Transfer-Encoding: chunked
http-outgoing-0 << Server: Jetty(6.1.26)
Connection can be kept alive indefinitely
Cookie accepted [hadoop.auth=""u=michaeljones&p=michaeljones&t=simple&e=1434216751821&s=95dJlz2YW4cks1jP9Z31p/urkbA="", version:0, domain:localhost, path:/, expiry:Sun Jun 14 03:32:31 AEST 2015]
http-outgoing-0 << "0[\r][\n]"
http-outgoing-0 << "[\r][\n]"
Connection [id: 0][route: {}->http://localhost:50070] can be kept alive indefinitely
Connection released: [id: 0][route: {}->http://localhost:50070][total kept alive: 1; route allocated: 1 of 2; total allocated: 1 of 20]
Connection manager is shutting down
http-outgoing-0: Close connection
http-outgoing-0: Close connection
Connection manager shut down
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 1][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://localhost:50070
Connecting to localhost/127.0.0.1:50070
Connection established 127.0.0.1:49939<->127.0.0.1:50070
Executing request PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-1 >> PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1
http-outgoing-1 >> Content-Length: 0
http-outgoing-1 >> Host: localhost:50070
http-outgoing-1 >> Connection: Keep-Alive
http-outgoing-1 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-1 >> Accept-Encoding: gzip,deflate
http-outgoing-1 >> "PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1[\r][\n]"
http-outgoing-1 >> "Content-Length: 0[\r][\n]"
http-outgoing-1 >> "Host: localhost:50070[\r][\n]"
http-outgoing-1 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-1 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-1 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-1 >> "[\r][\n]"
http-outgoing-1 << "HTTP/1.1 307 TEMPORARY_REDIRECT[\r][\n]"
http-outgoing-1 << "Cache-Control: no-cache[\r][\n]"
http-outgoing-1 << "Expires: Sat, 13 Jun 2015 07:32:32 GMT[\r][\n]"
http-outgoing-1 << "Date: Sat, 13 Jun 2015 07:32:32 GMT[\r][\n]"
http-outgoing-1 << "Pragma: no-cache[\r][\n]"
http-outgoing-1 << "Expires: Sat, 13 Jun 2015 07:32:32 GMT[\r][\n]"
http-outgoing-1 << "Date: Sat, 13 Jun 2015 07:32:32 GMT[\r][\n]"
http-outgoing-1 << "Pragma: no-cache[\r][\n]"
http-outgoing-1 << "Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434216752371&s=z3zDjaIDUIVtt9uopMByZ5b7Gbw="; Path=/; Expires=Sat, 13-Jun-2015 17:32:32 GMT; HttpOnly[\r][\n]"
http-outgoing-1 << "Location: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true[\r][\n]"
http-outgoing-1 << "Content-Type: application/octet-stream[\r][\n]"
http-outgoing-1 << "Content-Length: 0[\r][\n]"
http-outgoing-1 << "Server: Jetty(6.1.26)[\r][\n]"
http-outgoing-1 << "[\r][\n]"
http-outgoing-1 << HTTP/1.1 307 TEMPORARY_REDIRECT
http-outgoing-1 << Cache-Control: no-cache
http-outgoing-1 << Expires: Sat, 13 Jun 2015 07:32:32 GMT
http-outgoing-1 << Date: Sat, 13 Jun 2015 07:32:32 GMT
http-outgoing-1 << Pragma: no-cache
http-outgoing-1 << Expires: Sat, 13 Jun 2015 07:32:32 GMT
http-outgoing-1 << Date: Sat, 13 Jun 2015 07:32:32 GMT
http-outgoing-1 << Pragma: no-cache
http-outgoing-1 << Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434216752371&s=z3zDjaIDUIVtt9uopMByZ5b7Gbw="; Path=/; Expires=Sat, 13-Jun-2015 17:32:32 GMT; HttpOnly
http-outgoing-1 << Location: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
http-outgoing-1 << Content-Type: application/octet-stream
http-outgoing-1 << Content-Length: 0
http-outgoing-1 << Server: Jetty(6.1.26)
Connection can be kept alive indefinitely
Cookie accepted [hadoop.auth=""u=michaeljones&p=michaeljones&t=simple&e=1434216752371&s=z3zDjaIDUIVtt9uopMByZ5b7Gbw="", version:0, domain:localhost, path:/, expiry:Sun Jun 14 03:32:32 AEST 2015]
Redirect to: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
http-outgoing-1: Shutdown connection
Connection discarded
http-outgoing-1: Close connection
Connection released: [id: 1][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 2][route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://michaels-air.bigpond:50075
Connecting to michaels-air.bigpond/10.0.0.2:50075
Connection established 10.0.0.2:49940<->10.0.0.2:50075
Executing request PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-2 >> PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1
http-outgoing-2 >> Content-Length: 0
http-outgoing-2 >> Host: michaels-air.bigpond:50075
http-outgoing-2 >> Connection: Keep-Alive
http-outgoing-2 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-2 >> Accept-Encoding: gzip,deflate
http-outgoing-2 >> "PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1[\r][\n]"
http-outgoing-2 >> "Content-Length: 0[\r][\n]"
http-outgoing-2 >> "Host: michaels-air.bigpond:50075[\r][\n]"
http-outgoing-2 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-2 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-2 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-2 >> "[\r][\n]"
http-outgoing-2 << "HTTP/1.1 100 Continue[\r][\n]"
http-outgoing-2 << "[\r][\n]"
http-outgoing-2 << HTTP/1.1 100 Continue
http-outgoing-2 << "HTTP/1.1 201 Created[\r][\n]"
http-outgoing-2 << "Location: hdfs://localhost:9000/user/michaeljones/hello-apache-empty.txt[\r][\n]"
http-outgoing-2 << "Content-Length: 0[\r][\n]"
http-outgoing-2 << "Connection: close[\r][\n]"
http-outgoing-2 << "[\r][\n]"
http-outgoing-2 << HTTP/1.1 201 Created
http-outgoing-2 << Location: hdfs://localhost:9000/user/michaeljones/hello-apache-empty.txt
http-outgoing-2 << Content-Length: 0
http-outgoing-2 << Connection: close
http-outgoing-2: Shutdown connection
Connection discarded
http-outgoing-2: Close connection
Connection released: [id: 2][route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection manager is shutting down
Connection manager shut down
Jersey client Redirect to: hdfs://localhost:9000/user/michaeljones/hellohadoop.log
com.sun.jersey.client.property.chunkedEncodingSize: 1048576
Jersey client Redirect to: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/hello.log.2015-06-12?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 3][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://localhost:50070
Connecting to localhost/127.0.0.1:50070
Connection established 127.0.0.1:49950<->127.0.0.1:50070
Executing request PUT /webhdfs/v1/user/michaeljones/README.md?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-3 >> PUT /webhdfs/v1/user/michaeljones/README.md?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1
http-outgoing-3 >> Transfer-Encoding: chunked
http-outgoing-3 >> Content-Type: application/octet-stream
http-outgoing-3 >> Host: localhost:50070
http-outgoing-3 >> Connection: Keep-Alive
http-outgoing-3 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-3 >> Accept-Encoding: gzip,deflate
http-outgoing-3 >> "PUT /webhdfs/v1/user/michaeljones/README.md?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1[\r][\n]"
http-outgoing-3 >> "Transfer-Encoding: chunked[\r][\n]"
http-outgoing-3 >> "Content-Type: application/octet-stream[\r][\n]"
http-outgoing-3 >> "Host: localhost:50070[\r][\n]"
http-outgoing-3 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-3 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-3 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-3 >> "[\r][\n]"
http-outgoing-3 >> "1000[\r][\n]"
http-outgoing-3 >> "# Hello-Hadoop-netbeans-OS-X[\n]"
http-outgoing-3 >> "Java Maven project for playing with the HDFS API without any 3rd party hadoop plugins.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## Aim of project[\n]"
http-outgoing-3 >> "Hello world/tutorial level for programmatically operating with a pseudo distributed hadoop configuration on OS X. Hadoop 2.7 on Yosemite.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## What this project demonstrates[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "This is work in progress and so far the following functionality is demonstrated:[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "1. Direct programmatic control of the HDFS and running map reduce jobs - all unit tests run from the IDE with hadoop configuration built into this project and under git control.[\n]"
http-outgoing-3 >> "2. Uploading of files to the HDFS by implementing a Web REST API client.[\n]"
http-outgoing-3 >> "3. Layered application code for maximum re-use and ease of test driven development. The client I wrote uses an interface which has allowed me to provide both a Jersey HTTP client implementation and an Apache HTTP client implementation for comparison between the two toolkits.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "The initial difficulty was working out how to run the program in the IDE and talk to the local pseudo distributed setup without using a 3rd party Hadoop plugin. Apparently there used to be a plugin for netbeans, but it has been discontinued. I am a newbie with this technology.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "The Apache Hadoop instructions for building and running java programs are via their command line build/run utility only. Getting the yahoo hadoop HDFS tutorial program to build in the IDE wasn't too hard. However, by default it will ignore the local Hadoop configuration and only operate with the local file system in local debug mode.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## Wading through the configuration[\n]"
http-outgoing-3 >> "Hadoop is designed to work with a number of different topologies, directory locations, levels of replication, simulated environments etc. so as we would expect nothing works unless the configuration is right.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "First Hadoop needs to be installed and configured in pseudo distributed mode such that it builds and runs test programs on the command line. The hadoop documentation has instructions for doing this. Documentation is online and also included in the installation: share/doc/hadoop/index.html. However this is not enough to get it to work in the IDE.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## The netbeans project settings that are needed to run with the HDFS from the IDE:[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "1. Get log4j configured to work in the IDE. Absence of log4j configuration won't stop hadoop from running, but we won't get to see useful error messages from hadoop without it.[\n]"
http-outgoing-3 >> "2. HADOOP_HOME environment variable project run (and test) property.[\n]"
http-outgoing-3 >> "3. Duplicate hadoop configuration in the classpath. The above environment variable does not pick up the hadoop configuration from its usual place. Yahoo's only suggestion is to run from the command line via the hadoop script. The Apache HDFS API documention says that configuration is looked for in the classpath, so I took the approach of duplicating the configuration (just 2 files) instead of figuring out how to get it to look in the installation path.[\n]"
http-outgoing-3 >> "4. The correct Maven dependencies. If not all the jar depenencies are there the program may build and run, but it won't talk to the HDFS if it doesn't load the HDFS jars.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "I think that the setup of this project would probably work on Linux too.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## Working through trouble shooting the HDFS project settings[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "Issue 1 above shows up as:[\n]"
http-outgoing-3 >> "<pre><code>[\n]"
http-outgoing-3 >> "log4j:WARN No appenders could be found for logger (org.apache.hadoop.util.Shell).[\n]"
http-outgoing-3 >> "log4j:WARN Please initialize the log4j system properly.[\n]"
http-outgoing-3 >> "log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.[\n]"
http-outgoing-3 >> "</pre></code>[\n]"
http-outgoing-3 >> "This is solved by putting a log4j.properties configuration file in the classpath. For a Maven build getting files into the classpath can be achieved by putting them in src/main/resources. I don't think this is in the classpath, but the build will then copy the file into ./target/classes/ which is in the classpath.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "Issue 2 above shows up as:[\n]"
http-outgoing-3 >> "<pre><code>[\n]"
http-outgoing-3 >> "Failed to detect a valid hadoop home directory[\n]"
http-outgoing-3 >> "java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.[\n]"
http-outgoing-3 >> "</code></pre>[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "This is fixed by going into the project properties => Build => Actions => Run Project and adding the environmen[\r][\n]"
http-outgoing-3 >> "1000[\r][\n]"
http-outgoing-3 >> "t variable for HADOOP_HOME. This will result in an entry in the Maven POM. Repeat for "Test Project", "Debug Project" etc.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "Issue 3. shows up as running, but creating a file on the local file system instead of the HDFS. This was fixed       looking at the HDFS API documentation for org.apache.hadoop.conf.Configuration. This documentation is under the chapter: C API libhdfs HDFS which has a link to the HDFS API under "The APIs" (I strangely cannot find this in the main index). On my installation the HDFS API documentation link is file:///opt/local/hadoop-2.7.0/share/doc/hadoop/api/org/apache/hadoop/fs/FileSystem.html.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "This documentation told me that hadoop loads core-site.xml and core-default.xml in the classpath. Classpath for a Maven build can be reached by placing these files in the directory src/main/resources (see logging configuration above). I added hdfs-site instead of core-default (which doesn't exist on my 2.7 install) into the src/main/resources project directory.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "Issue 3 shows up as:[\n]"
http-outgoing-3 >> "<pre><code>[\n]"
http-outgoing-3 >> "java.io.IOException: "hadoop No FileSystem for scheme: hdfs".[\n]"
http-outgoing-3 >> "</code></pre>[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "This is part of the build dependency problem. The various threads on stackoverflow etc. suggested that a minimum dependency was the jar for hadoop-core. However, there is no such jar on 2.7. I ran the hadoop command to dump version and got this:[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "<pre><code>[\n]"
http-outgoing-3 >> "bin/hadoop version[\n]"
http-outgoing-3 >> "Hadoop 2.7.0[\n]"
http-outgoing-3 >> "Subversion https://git-wip-us.apache.org/repos/asf/hadoop.git -r d4c8d4d4d203c934e8074b31289a28724c0842cf[\n]"
http-outgoing-3 >> "Compiled by jenkins on 2015-04-10T18:40Z[\n]"
http-outgoing-3 >> "Compiled with protoc 2.5.0[\n]"
http-outgoing-3 >> "From source with checksum a9e90912c37a35c3195d23951fd18f[\n]"
http-outgoing-3 >> "This command was run using /opt/local/hadoop-2.7.0/share/hadoop/common/hadoop-common-2.7.0.jar[\n]"
http-outgoing-3 >> "</code></pre>[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "I noted the jar name at the end and added it as a dependency to the POM. This can either be hand coded in or right click pom.xml => Insert Code => Add Dependency => Search => query hadoop-common and select version which was 2.7.0 [jar] - central. Maven will then add dependencies to other hadoop jars in the "Dependencies" group in the project explorer. Netbeans will then download these dependencies before the next build. They go into ~/.m2/repository should they ever need to be cleaned out (Netbeans doesn't seem to have an IDE remove dependency option).[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "After doing the above project built, but showed up the "no filesystem error". I noticed that Maven had not pulled in any hdfs jars matching the jars in my share/hadoop/hdfs installation directory. So I took a guess that it needed only the top level hadoop-hdfs-2.7.0.jar and added this as a dependency to the POM and all was good :)[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## Working through trouble shooting the Map Reduce project settings[\n]"
http-outgoing-3 >> "After getting the HDFS API working in the IDE it was time to move on to getting the famous Word Count map-reduce tutorial running.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "So coded it, set the main program to the word count main as the one to run. From the IDE: project Properties => Run => Main Class. Provide input and output arguments for the word count program. I noted that the netbeans properties pop-up window does not persist these settings next time it pops up. However this setting is persistant and ends up in nbactions.xml.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "However, running the word count map reduce program resulted in an ioException:[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "<pre><code>[\n]"
http-outgoing-3 >> "Please check your configuration for mapreduce.framework.name and the correspond server addresses.[\n]"
http-outgoing-3 >> "</pre></code>[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "Because the resources directory only contains 2 configuration files from my hadoop installation I thought maybe I was missing a map reduce one. So the first thing I did was go into the configuration directory of my installation and grep all files to see if there was a configuration file with mapreduce framework property. There was not. I checked my programatic configuration dump from my test program. This property was not mentioned either. The only map reduce configuration was to do with some environment variables for heap size in one of the shell scripts. Note to self: this may be relevant and I can consider setting this in the IDE. However, that didn't look like the problem.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "I then chec[\r][\n]"
http-outgoing-3 >> "a93[\r][\n]"
http-outgoing-3 >> "ked my dependencies and noted there were no map reduce jars pulled in by Maven. So I added hadoop-mapreduce-client-core. Still not running. Checked the web and a thread on stackoverflow mentioned a number of other jars: hadoop-mapreduce-client-common and hadoop-mapreduce-client shuffle. I added just the hadoop-mapreduce-client-common and it runs :) I have a feeling that I might need some of the other jars for other API calls and that there must be a better way of working out dependencies than this trial and error. As mentioned I am a newbie with this, so if anyone has any comments feel free to email me.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## Logging from application code[\n]"
http-outgoing-3 >> "Although the hadoop libraries log correctly with a properly located log4.properties file, application code calling the log4j logger seems to ignore this file. Using the log4j logger as per instructions in the log4j manual and many online tutorials did not result in getting any logging redirected to file configured in the properties file. Instead console output only is obtained. A clue to this mystery was that a most basic of hello world netbeans maven projects which did not import any hadoop stuff also failed to log to a file and did not even give the "No appenders" warning. Then I noticed that there were org.sl4j depencies in the hadoop build, so using sl4j instead solved the problem. Once my hello world project used sl4j's LoggerFactory and had sl4j-api and sl4j-12 as a dependencies it started to use the properties file. See http://www.slf4j.org/manual.html[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## Upload a file from local storage to the HDFS via the REST API[\n]"
http-outgoing-3 >> "The WebHDFS REST API documentation which came with the installation specifies that file creation is a two stage operation where an initial PUT to the namenode is sent. This responds with a redirect to the datanode and another PUT should be made to this redirection which can contain the chunked data stream. This does not sound REST to me as it relies on holding redirection state (a fully distributed configuration could presumably return a redirection to any one of the datanodes). Hadoop say this is because of a bug in some HTTP client implementations - incorrect implementation of [0xe2][0x80][0x9c]Expect: 100-continue[0xe2][0x80][0x9d].[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "However, the 2 stage PUT not being REST seems to be a moot point, at least with the Jersey client. I do not get a redirection and a file creates/uploads all in one go.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "Since writing the above paragraph I have implemented the Apache Client back end option to my HDFS Web client interface and this client behaves differently. It does indeed cause a redirect as per Hadoop documentation. The follow up PUT to the redirected location with the chunked file stream works as per documentation.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "To be continued ...[\n]"
http-outgoing-3 >> "[\r][\n]"
http-outgoing-3 >> "0[\r][\n]"
http-outgoing-3 >> "[\r][\n]"
http-outgoing-3 << "HTTP/1.1 307 TEMPORARY_REDIRECT[\r][\n]"
http-outgoing-3 << "Cache-Control: no-cache[\r][\n]"
http-outgoing-3 << "Expires: Sat, 13 Jun 2015 07:32:33 GMT[\r][\n]"
http-outgoing-3 << "Date: Sat, 13 Jun 2015 07:32:33 GMT[\r][\n]"
http-outgoing-3 << "Pragma: no-cache[\r][\n]"
http-outgoing-3 << "Expires: Sat, 13 Jun 2015 07:32:33 GMT[\r][\n]"
http-outgoing-3 << "Date: Sat, 13 Jun 2015 07:32:33 GMT[\r][\n]"
http-outgoing-3 << "Pragma: no-cache[\r][\n]"
http-outgoing-3 << "Content-Type: application/octet-stream[\r][\n]"
http-outgoing-3 << "Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434216753070&s=/40uS6hXLrehbF/rL3nxFOaPwro="; Path=/; Expires=Sat, 13-Jun-2015 17:32:33 GMT; HttpOnly[\r][\n]"
http-outgoing-3 << "Location: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/README.md?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true[\r][\n]"
http-outgoing-3 << "Content-Length: 0[\r][\n]"
http-outgoing-3 << "Server: Jetty(6.1.26)[\r][\n]"
http-outgoing-3 << "[\r][\n]"
http-outgoing-3 << HTTP/1.1 307 TEMPORARY_REDIRECT
http-outgoing-3 << Cache-Control: no-cache
http-outgoing-3 << Expires: Sat, 13 Jun 2015 07:32:33 GMT
http-outgoing-3 << Date: Sat, 13 Jun 2015 07:32:33 GMT
http-outgoing-3 << Pragma: no-cache
http-outgoing-3 << Expires: Sat, 13 Jun 2015 07:32:33 GMT
http-outgoing-3 << Date: Sat, 13 Jun 2015 07:32:33 GMT
http-outgoing-3 << Pragma: no-cache
http-outgoing-3 << Content-Type: application/octet-stream
http-outgoing-3 << Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434216753070&s=/40uS6hXLrehbF/rL3nxFOaPwro="; Path=/; Expires=Sat, 13-Jun-2015 17:32:33 GMT; HttpOnly
http-outgoing-3 << Location: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/README.md?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
http-outgoing-3 << Content-Length: 0
http-outgoing-3 << Server: Jetty(6.1.26)
Connection can be kept alive indefinitely
Cookie accepted [hadoop.auth=""u=michaeljones&p=michaeljones&t=simple&e=1434216753070&s=/40uS6hXLrehbF/rL3nxFOaPwro="", version:0, domain:localhost, path:/, expiry:Sun Jun 14 03:32:33 AEST 2015]
Redirect to: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/README.md?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
http-outgoing-3: Shutdown connection
Connection discarded
http-outgoing-3: Close connection
Connection released: [id: 3][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 4][route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://michaels-air.bigpond:50075
Connecting to michaels-air.bigpond/10.0.0.2:50075
Connection established 10.0.0.2:49951<->10.0.0.2:50075
Executing request PUT /webhdfs/v1/user/michaeljones/README.md?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-4 >> PUT /webhdfs/v1/user/michaeljones/README.md?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1
http-outgoing-4 >> Transfer-Encoding: chunked
http-outgoing-4 >> Content-Type: application/octet-stream
http-outgoing-4 >> Host: michaels-air.bigpond:50075
http-outgoing-4 >> Connection: Keep-Alive
http-outgoing-4 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-4 >> Accept-Encoding: gzip,deflate
http-outgoing-4 >> "PUT /webhdfs/v1/user/michaeljones/README.md?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1[\r][\n]"
http-outgoing-4 >> "Transfer-Encoding: chunked[\r][\n]"
http-outgoing-4 >> "Content-Type: application/octet-stream[\r][\n]"
http-outgoing-4 >> "Host: michaels-air.bigpond:50075[\r][\n]"
http-outgoing-4 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-4 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-4 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-4 >> "[\r][\n]"
http-outgoing-4 >> "1000[\r][\n]"
http-outgoing-4 >> "# Hello-Hadoop-netbeans-OS-X[\n]"
http-outgoing-4 >> "Java Maven project for playing with the HDFS API without any 3rd party hadoop plugins.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## Aim of project[\n]"
http-outgoing-4 >> "Hello world/tutorial level for programmatically operating with a pseudo distributed hadoop configuration on OS X. Hadoop 2.7 on Yosemite.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## What this project demonstrates[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "This is work in progress and so far the following functionality is demonstrated:[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "1. Direct programmatic control of the HDFS and running map reduce jobs - all unit tests run from the IDE with hadoop configuration built into this project and under git control.[\n]"
http-outgoing-4 >> "2. Uploading of files to the HDFS by implementing a Web REST API client.[\n]"
http-outgoing-4 >> "3. Layered application code for maximum re-use and ease of test driven development. The client I wrote uses an interface which has allowed me to provide both a Jersey HTTP client implementation and an Apache HTTP client implementation for comparison between the two toolkits.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "The initial difficulty was working out how to run the program in the IDE and talk to the local pseudo distributed setup without using a 3rd party Hadoop plugin. Apparently there used to be a plugin for netbeans, but it has been discontinued. I am a newbie with this technology.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "The Apache Hadoop instructions for building and running java programs are via their command line build/run utility only. Getting the yahoo hadoop HDFS tutorial program to build in the IDE wasn't too hard. However, by default it will ignore the local Hadoop configuration and only operate with the local file system in local debug mode.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## Wading through the configuration[\n]"
http-outgoing-4 >> "Hadoop is designed to work with a number of different topologies, directory locations, levels of replication, simulated environments etc. so as we would expect nothing works unless the configuration is right.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "First Hadoop needs to be installed and configured in pseudo distributed mode such that it builds and runs test programs on the command line. The hadoop documentation has instructions for doing this. Documentation is online and also included in the installation: share/doc/hadoop/index.html. However this is not enough to get it to work in the IDE.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## The netbeans project settings that are needed to run with the HDFS from the IDE:[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "1. Get log4j configured to work in the IDE. Absence of log4j configuration won't stop hadoop from running, but we won't get to see useful error messages from hadoop without it.[\n]"
http-outgoing-4 >> "2. HADOOP_HOME environment variable project run (and test) property.[\n]"
http-outgoing-4 >> "3. Duplicate hadoop configuration in the classpath. The above environment variable does not pick up the hadoop configuration from its usual place. Yahoo's only suggestion is to run from the command line via the hadoop script. The Apache HDFS API documention says that configuration is looked for in the classpath, so I took the approach of duplicating the configuration (just 2 files) instead of figuring out how to get it to look in the installation path.[\n]"
http-outgoing-4 >> "4. The correct Maven dependencies. If not all the jar depenencies are there the program may build and run, but it won't talk to the HDFS if it doesn't load the HDFS jars.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "I think that the setup of this project would probably work on Linux too.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## Working through trouble shooting the HDFS project settings[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "Issue 1 above shows up as:[\n]"
http-outgoing-4 >> "<pre><code>[\n]"
http-outgoing-4 >> "log4j:WARN No appenders could be found for logger (org.apache.hadoop.util.Shell).[\n]"
http-outgoing-4 >> "log4j:WARN Please initialize the log4j system properly.[\n]"
http-outgoing-4 >> "log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.[\n]"
http-outgoing-4 >> "</pre></code>[\n]"
http-outgoing-4 >> "This is solved by putting a log4j.properties configuration file in the classpath. For a Maven build getting files into the classpath can be achieved by putting them in src/main/resources. I don't think this is in the classpath, but the build will then copy the file into ./target/classes/ which is in the classpath.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "Issue 2 above shows up as:[\n]"
http-outgoing-4 >> "<pre><code>[\n]"
http-outgoing-4 >> "Failed to detect a valid hadoop home directory[\n]"
http-outgoing-4 >> "java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.[\n]"
http-outgoing-4 >> "</code></pre>[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "This is fixed by going into the project properties => Build => Actions => Run Project and adding the environmen[\r][\n]"
http-outgoing-4 >> "1000[\r][\n]"
http-outgoing-4 >> "t variable for HADOOP_HOME. This will result in an entry in the Maven POM. Repeat for "Test Project", "Debug Project" etc.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "Issue 3. shows up as running, but creating a file on the local file system instead of the HDFS. This was fixed       looking at the HDFS API documentation for org.apache.hadoop.conf.Configuration. This documentation is under the chapter: C API libhdfs HDFS which has a link to the HDFS API under "The APIs" (I strangely cannot find this in the main index). On my installation the HDFS API documentation link is file:///opt/local/hadoop-2.7.0/share/doc/hadoop/api/org/apache/hadoop/fs/FileSystem.html.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "This documentation told me that hadoop loads core-site.xml and core-default.xml in the classpath. Classpath for a Maven build can be reached by placing these files in the directory src/main/resources (see logging configuration above). I added hdfs-site instead of core-default (which doesn't exist on my 2.7 install) into the src/main/resources project directory.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "Issue 3 shows up as:[\n]"
http-outgoing-4 >> "<pre><code>[\n]"
http-outgoing-4 >> "java.io.IOException: "hadoop No FileSystem for scheme: hdfs".[\n]"
http-outgoing-4 >> "</code></pre>[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "This is part of the build dependency problem. The various threads on stackoverflow etc. suggested that a minimum dependency was the jar for hadoop-core. However, there is no such jar on 2.7. I ran the hadoop command to dump version and got this:[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "<pre><code>[\n]"
http-outgoing-4 >> "bin/hadoop version[\n]"
http-outgoing-4 >> "Hadoop 2.7.0[\n]"
http-outgoing-4 >> "Subversion https://git-wip-us.apache.org/repos/asf/hadoop.git -r d4c8d4d4d203c934e8074b31289a28724c0842cf[\n]"
http-outgoing-4 >> "Compiled by jenkins on 2015-04-10T18:40Z[\n]"
http-outgoing-4 >> "Compiled with protoc 2.5.0[\n]"
http-outgoing-4 >> "From source with checksum a9e90912c37a35c3195d23951fd18f[\n]"
http-outgoing-4 >> "This command was run using /opt/local/hadoop-2.7.0/share/hadoop/common/hadoop-common-2.7.0.jar[\n]"
http-outgoing-4 >> "</code></pre>[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "I noted the jar name at the end and added it as a dependency to the POM. This can either be hand coded in or right click pom.xml => Insert Code => Add Dependency => Search => query hadoop-common and select version which was 2.7.0 [jar] - central. Maven will then add dependencies to other hadoop jars in the "Dependencies" group in the project explorer. Netbeans will then download these dependencies before the next build. They go into ~/.m2/repository should they ever need to be cleaned out (Netbeans doesn't seem to have an IDE remove dependency option).[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "After doing the above project built, but showed up the "no filesystem error". I noticed that Maven had not pulled in any hdfs jars matching the jars in my share/hadoop/hdfs installation directory. So I took a guess that it needed only the top level hadoop-hdfs-2.7.0.jar and added this as a dependency to the POM and all was good :)[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## Working through trouble shooting the Map Reduce project settings[\n]"
http-outgoing-4 >> "After getting the HDFS API working in the IDE it was time to move on to getting the famous Word Count map-reduce tutorial running.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "So coded it, set the main program to the word count main as the one to run. From the IDE: project Properties => Run => Main Class. Provide input and output arguments for the word count program. I noted that the netbeans properties pop-up window does not persist these settings next time it pops up. However this setting is persistant and ends up in nbactions.xml.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "However, running the word count map reduce program resulted in an ioException:[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "<pre><code>[\n]"
http-outgoing-4 >> "Please check your configuration for mapreduce.framework.name and the correspond server addresses.[\n]"
http-outgoing-4 >> "</pre></code>[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "Because the resources directory only contains 2 configuration files from my hadoop installation I thought maybe I was missing a map reduce one. So the first thing I did was go into the configuration directory of my installation and grep all files to see if there was a configuration file with mapreduce framework property. There was not. I checked my programatic configuration dump from my test program. This property was not mentioned either. The only map reduce configuration was to do with some environment variables for heap size in one of the shell scripts. Note to self: this may be relevant and I can consider setting this in the IDE. However, that didn't look like the problem.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "I then chec[\r][\n]"
http-outgoing-4 >> "a93[\r][\n]"
http-outgoing-4 >> "ked my dependencies and noted there were no map reduce jars pulled in by Maven. So I added hadoop-mapreduce-client-core. Still not running. Checked the web and a thread on stackoverflow mentioned a number of other jars: hadoop-mapreduce-client-common and hadoop-mapreduce-client shuffle. I added just the hadoop-mapreduce-client-common and it runs :) I have a feeling that I might need some of the other jars for other API calls and that there must be a better way of working out dependencies than this trial and error. As mentioned I am a newbie with this, so if anyone has any comments feel free to email me.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## Logging from application code[\n]"
http-outgoing-4 >> "Although the hadoop libraries log correctly with a properly located log4.properties file, application code calling the log4j logger seems to ignore this file. Using the log4j logger as per instructions in the log4j manual and many online tutorials did not result in getting any logging redirected to file configured in the properties file. Instead console output only is obtained. A clue to this mystery was that a most basic of hello world netbeans maven projects which did not import any hadoop stuff also failed to log to a file and did not even give the "No appenders" warning. Then I noticed that there were org.sl4j depencies in the hadoop build, so using sl4j instead solved the problem. Once my hello world project used sl4j's LoggerFactory and had sl4j-api and sl4j-12 as a dependencies it started to use the properties file. See http://www.slf4j.org/manual.html[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## Upload a file from local storage to the HDFS via the REST API[\n]"
http-outgoing-4 >> "The WebHDFS REST API documentation which came with the installation specifies that file creation is a two stage operation where an initial PUT to the namenode is sent. This responds with a redirect to the datanode and another PUT should be made to this redirection which can contain the chunked data stream. This does not sound REST to me as it relies on holding redirection state (a fully distributed configuration could presumably return a redirection to any one of the datanodes). Hadoop say this is because of a bug in some HTTP client implementations - incorrect implementation of [0xe2][0x80][0x9c]Expect: 100-continue[0xe2][0x80][0x9d].[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "However, the 2 stage PUT not being REST seems to be a moot point, at least with the Jersey client. I do not get a redirection and a file creates/uploads all in one go.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "Since writing the above paragraph I have implemented the Apache Client back end option to my HDFS Web client interface and this client behaves differently. It does indeed cause a redirect as per Hadoop documentation. The follow up PUT to the redirected location with the chunked file stream works as per documentation.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "To be continued ...[\n]"
http-outgoing-4 >> "[\r][\n]"
http-outgoing-4 >> "0[\r][\n]"
http-outgoing-4 >> "[\r][\n]"
http-outgoing-4 << "HTTP/1.1 100 Continue[\r][\n]"
http-outgoing-4 << "[\r][\n]"
http-outgoing-4 << HTTP/1.1 100 Continue
http-outgoing-4 << "HTTP/1.1 201 Created[\r][\n]"
http-outgoing-4 << "Location: hdfs://localhost:9000/user/michaeljones/README.md[\r][\n]"
http-outgoing-4 << "Content-Length: 0[\r][\n]"
http-outgoing-4 << "Connection: close[\r][\n]"
http-outgoing-4 << "[\r][\n]"
http-outgoing-4 << HTTP/1.1 201 Created
http-outgoing-4 << Location: hdfs://localhost:9000/user/michaeljones/README.md
http-outgoing-4 << Content-Length: 0
http-outgoing-4 << Connection: close
http-outgoing-4: Shutdown connection
Connection discarded
http-outgoing-4: Close connection
Connection released: [id: 4][route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection manager is shutting down
Connection manager shut down
Connection manager is shutting down
Connection manager shut down
setsid is not available on this machine. So not using it.
setsid exited with exit code 0
field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, always=false, sampleName=Ops, type=DEFAULT, value=[Rate of successful kerberos logins and latency (milliseconds)], valueName=Time)
field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, always=false, sampleName=Ops, type=DEFAULT, value=[Rate of failed kerberos logins and latency (milliseconds)], valueName=Time)
field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, always=false, sampleName=Ops, type=DEFAULT, value=[GetGroups], valueName=Time)
UgiMetrics, User and group related metrics
Kerberos krb5 configuration not found, setting default realm to empty
 Creating new Groups object
Trying to load the custom-built native-hadoop library...
Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
java.library.path=/Applications/NetBeans/NetBeans 8.0.2.app/Contents/Resources/NetBeans/webcommon/bin::/Users/michaeljones/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:.
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Falling back to shell based
Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
hadoop login
hadoop login commit
using local user:UnixPrincipal: michaeljones
Using user: "UnixPrincipal: michaeljones" with name michaeljones
User entry: "michaeljones"
UGI loginUser:michaeljones (auth:SIMPLE)
dfs.client.use.legacy.blockreader.local = false
dfs.client.read.shortcircuit = false
dfs.client.domain.socket.data.traffic = false
dfs.domain.socket.path = 
multipleLinearRandomRetry = null
rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWrapper, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@1a6c1270
getting client out of cache: org.apache.hadoop.ipc.Client@22d7b4f8
Both short-circuit local reads and UNIX domain socket are disabled.
DataTransferProtocol not using SaslPropertiesResolver, no QOP found in configuration for dfs.data.transfer.protection
The ping interval is 60000 ms.
Connecting to localhost/127.0.0.1:9000
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones: starting, having connections 1
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #0
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #0
Call: getFileInfo took 174ms
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #1
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #1
Call: delete took 14ms
/user/michaeljones/hello.txt: masked=rw-r--r--
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #2
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #2
Call: create took 3ms
computePacketChunkSize: src=/user/michaeljones/hello.txt, chunkSize=516, chunksPerPacket=126, packetSize=65016
Lease renewer daemon for [DFSClient_NONMAPREDUCE_-195452301_1] with renew id 1 started
DFSClient writeChunk allocating new packet seqno=0, src=/user/michaeljones/hello.txt, packetSize=65016, chunksPerPacket=126, bytesCurBlock=0
Queued packet 0
Queued packet 1
Allocating new block
Waiting for ack for: 1
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #3
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #3
Call: addBlock took 6ms
pipeline = DatanodeInfoWithStorage[127.0.0.1:50010,DS-b42c5705-9ba4-4b14-b00b-f9194bb036f0,DISK]
Connecting to datanode 127.0.0.1:50010
Send buf size 131072
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #4
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #4
Call: getServerDefaults took 2ms
SASL client skipping handshake in unsecured configuration for addr = /127.0.0.1, datanodeId = DatanodeInfoWithStorage[127.0.0.1:50010,DS-b42c5705-9ba4-4b14-b00b-f9194bb036f0,DISK]
DataStreamer block BP-1045030256-10.0.0.2-1433119149314:blk_1073742290_1467 sending packet packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 20
DFSClient seqno: 0 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
DataStreamer block BP-1045030256-10.0.0.2-1433119149314:blk_1073742290_1467 sending packet packet seqno: 1 offsetInBlock: 20 lastPacketInBlock: true lastByteOffsetInBlock: 20
DFSClient seqno: 1 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
Closing old block BP-1045030256-10.0.0.2-1433119149314:blk_1073742290_1467
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #5
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #5
Call: complete took 2ms
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #6
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #6
Call: getBlockLocations took 22ms
newInfo = LocatedBlocks{
  fileLength=20
  underConstruction=false
  blocks=[LocatedBlock{BP-1045030256-10.0.0.2-1433119149314:blk_1073742290_1467; getBlockSize()=20; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-b42c5705-9ba4-4b14-b00b-f9194bb036f0,DISK]]}]
  lastLocatedBlock=LocatedBlock{BP-1045030256-10.0.0.2-1433119149314:blk_1073742290_1467; getBlockSize()=20; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-b42c5705-9ba4-4b14-b00b-f9194bb036f0,DISK]]}
  isLastBlockComplete=true}
Connecting to datanode 127.0.0.1:50010
SASL client skipping handshake in unsecured configuration for addr = /127.0.0.1, datanodeId = DatanodeInfoWithStorage[127.0.0.1:50010,DS-b42c5705-9ba4-4b14-b00b-f9194bb036f0,DISK]
RunJobAsync
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #7
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #7
Call: getFileInfo took 3ms
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #8
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #8
Call: delete took 9ms
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.connect(Job.java:1256)
Trying ClientProtocolProvider : org.apache.hadoop.mapred.LocalClientProtocolProvider
session.id is deprecated. Instead, use dfs.metrics.session-id
Initializing JVM Metrics with processName=JobTracker, sessionId=
Picked org.apache.hadoop.mapred.LocalClientProtocolProvider as the ClientProtocolProvider
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Cluster.getFileSystem(Cluster.java:162)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.submit(Job.java:1287)
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #9
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #9
Call: getFileInfo took 2ms
Configuring job job_local1723068883_0001 with file:/tmp/hadoop-michaeljones/mapred/staging/michaeljones1723068883/.staging/job_local1723068883_0001 as the submit dir
adding the following namenodes' delegation tokens:[hdfs://localhost:9000]
Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
default FileSystem: file:///
No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
Creating splits at file:/tmp/hadoop-michaeljones/mapred/staging/michaeljones1723068883/.staging/job_local1723068883_0001
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #10
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #10
Call: getFileInfo took 1ms
Time taken to get FileStatuses: 7
Total input paths to process : 1
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #11
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #11
Call: getBlockLocations took 6ms
Total # of splits generated by getSplits: 1, TimeTaken: 40
number of splits:1
Handling deprecation for all properties in config...
Handling deprecation for mapreduce.jobtracker.address
Handling deprecation for yarn.resourcemanager.scheduler.monitor.policies
Handling deprecation for dfs.namenode.resource.check.interval
Handling deprecation for mapreduce.jobhistory.client.thread-count
Handling deprecation for yarn.app.mapreduce.am.containerlauncher.threadpool-initial-size
Handling deprecation for mapred.child.java.opts
Handling deprecation for mapreduce.jobtracker.retiredjobs.cache.size
Handling deprecation for dfs.client.https.need-auth
Handling deprecation for yarn.admin.acl
Handling deprecation for yarn.app.mapreduce.am.job.committer.cancel-timeout
Handling deprecation for mapreduce.job.emit-timeline-data
Handling deprecation for fs.ftp.host.port
Handling deprecation for dfs.namenode.avoid.read.stale.datanode
Handling deprecation for dfs.journalnode.rpc-address
Handling deprecation for mapreduce.job.end-notification.retry.attempts
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.ttl-interval-ms
Handling deprecation for yarn.resourcemanager.leveldb-state-store.path
Handling deprecation for mapred.mapper.new-api
Handling deprecation for yarn.ipc.rpc.class
Handling deprecation for ipc.client.connection.maxidletime
Handling deprecation for yarn.nodemanager.process-kill-wait.ms
Handling deprecation for mapreduce.cluster.acls.enabled
Handling deprecation for mapreduce.jobtracker.handler.count
Handling deprecation for io.map.index.interval
Handling deprecation for dfs.namenode.https-address
Handling deprecation for mapreduce.task.profile.reduces
Handling deprecation for fs.s3n.multipart.uploads.enabled
Handling deprecation for io.seqfile.sorter.recordlimit
Handling deprecation for mapreduce.job.ubertask.maxmaps
Handling deprecation for mapreduce.tasktracker.tasks.sleeptimebeforesigkill
Handling deprecation for hadoop.util.hash.type
Handling deprecation for dfs.namenode.replication.min
Handling deprecation for yarn.nodemanager.container-manager.thread-count
Handling deprecation for mapreduce.jobtracker.jobhistory.block.size
Handling deprecation for dfs.namenode.fs-limits.min-block-size
Handling deprecation for mapreduce.app-submission.cross-platform
Handling deprecation for fs.AbstractFileSystem.file.impl
Handling deprecation for net.topology.script.number.args
Handling deprecation for yarn.resourcemanager.container-tokens.master-key-rolling-interval-secs
Handling deprecation for mapreduce.map.output.compress.codec
Handling deprecation for mapreduce.job.reducer.preempt.delay.sec
Handling deprecation for s3native.bytes-per-checksum
Handling deprecation for dfs.namenode.path.based.cache.block.map.allocation.percent
Handling deprecation for yarn.nodemanager.windows-container.memory-limit.enabled
Handling deprecation for mapreduce.input.fileinputformat.split.minsize
Handling deprecation for hadoop.security.group.mapping
Handling deprecation for mapreduce.jobtracker.system.dir
Handling deprecation for mapreduce.job.end-notification.max.attempts
Handling deprecation for mapreduce.reduce.markreset.buffer.percent
Handling deprecation for dfs.datanode.cache.revocation.polling.ms
Handling deprecation for mapreduce.reduce.speculative
Handling deprecation for yarn.nodemanager.localizer.cache.cleanup.interval-ms
Handling deprecation for dfs.namenode.lazypersist.file.scrub.interval.sec
Handling deprecation for fs.s3a.threads.core
Handling deprecation for mapreduce.jobhistory.recovery.store.fs.uri
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.start-time-read-cache-size
Handling deprecation for hadoop.registry.zk.retry.interval.ms
Handling deprecation for yarn.nodemanager.keytab
Handling deprecation for dfs.namenode.replication.interval
Handling deprecation for yarn.resourcemanager.admin.address
Handling deprecation for mapreduce.job.maps
Handling deprecation for nfs.dump.dir
Handling deprecation for mapreduce.job.user.name
Handling deprecation for mapreduce.jobtracker.maxtasks.perjob
Handling deprecation for mapreduce.job.ubertask.enable
Handling deprecation for mapreduce.job.reduce.class
Handling deprecation for yarn.nodemanager.delete.debug-delay-sec
Handling deprecation for yarn.timeline-service.ttl-enable
Handling deprecation for yarn.resourcemanager.fs.state-store.retry-policy-spec
Handling deprecation for mapreduce.reduce.skip.maxgroups
Handling deprecation for dfs.client.use.datanode.hostname
Handling deprecation for fs.trash.interval
Handling deprecation for mapreduce.job.name
Handling deprecation for mapreduce.am.max-attempts
Handling deprecation for mapreduce.jobtracker.heartbeats.in.second
Handling deprecation for yarn.resourcemanager.zk-num-retries
Handling deprecation for s3.blocksize
Handling deprecation for dfs.datanode.data.dir
Handling deprecation for mapreduce.jobtracker.persist.jobstatus.active
Handling deprecation for mapreduce.reduce.shuffle.parallelcopies
Handling deprecation for fs.s3.buffer.dir
Handling deprecation for mapreduce.jobhistory.done-dir
Handling deprecation for hadoop.security.instrumentation.requires.admin
Handling deprecation for hadoop.registry.zk.retry.ceiling.ms
Handling deprecation for nfs.rtmax
Handling deprecation for dfs.datanode.data.dir.perm
Handling deprecation for yarn.resourcemanager.container.liveness-monitor.interval-ms
Handling deprecation for yarn.nodemanager.env-whitelist
Handling deprecation for dfs.namenode.backup.address
Handling deprecation for dfs.namenode.xattrs.enabled
Handling deprecation for dfs.datanode.readahead.bytes
Handling deprecation for mapreduce.jobhistory.cleaner.enable
Handling deprecation for dfs.client.block.write.retries
Handling deprecation for mapreduce.tasktracker.http.address
Handling deprecation for yarn.nodemanager.linux-container-executor.cgroups.hierarchy
Handling deprecation for ha.failover-controller.graceful-fence.connection.retries
Handling deprecation for yarn.resourcemanager.recovery.enabled
Handling deprecation for yarn.app.mapreduce.am.container.log.backups
Handling deprecation for dfs.namenode.safemode.threshold-pct
Handling deprecation for yarn.nodemanager.disk-health-checker.interval-ms
Handling deprecation for hadoop.security.java.secure.random.algorithm
Handling deprecation for dfs.namenode.list.cache.directives.num.responses
Handling deprecation for dfs.datanode.dns.nameserver
Handling deprecation for mapreduce.cluster.temp.dir
Handling deprecation for fs.s3a.max.total.tasks
Handling deprecation for mapreduce.reduce.maxattempts
Handling deprecation for mapreduce.client.submit.file.replication
Handling deprecation for mapreduce.shuffle.port
Handling deprecation for yarn.resourcemanager.resource-tracker.client.thread-count
Handling deprecation for dfs.namenode.replication.considerLoad
Handling deprecation for dfs.namenode.edits.journal-plugin.qjournal
Handling deprecation for dfs.client.write.exclude.nodes.cache.expiry.interval.millis
Handling deprecation for yarn.nodemanager.delete.thread-count
Handling deprecation for dfs.client.mmap.cache.timeout.ms
Handling deprecation for yarn.nodemanager.admin-env
Handling deprecation for io.skip.checksum.errors
Handling deprecation for yarn.timeline-service.hostname
Handling deprecation for yarn.resourcemanager.proxy-user-privileges.enabled
Handling deprecation for mapreduce.job.speculative.speculative-cap-total-tasks
Handling deprecation for yarn.acl.enable
Handling deprecation for fs.s3a.fast.upload
Handling deprecation for file.blocksize
Handling deprecation for mapreduce.job.speculative.slowtaskthreshold
Handling deprecation for ftp.replication
Handling deprecation for yarn.sharedcache.cleaner.initial-delay-mins
Handling deprecation for s3native.client-write-packet-size
Handling deprecation for hadoop.rpc.socket.factory.class.default
Handling deprecation for file.bytes-per-checksum
Handling deprecation for dfs.datanode.slow.io.warning.threshold.ms
Handling deprecation for io.seqfile.lazydecompress
Handling deprecation for mapreduce.task.skip.start.attempts
Handling deprecation for dfs.namenode.reject-unresolved-dn-topology-mapping
Handling deprecation for hadoop.common.configuration.version
Handling deprecation for yarn.resourcemanager.client.thread-count
Handling deprecation for dfs.datanode.drop.cache.behind.reads
Handling deprecation for yarn.sharedcache.admin.address
Handling deprecation for mapreduce.job.output.value.class
Handling deprecation for mapreduce.output.fileoutputformat.outputdir
Handling deprecation for mapreduce.jobtracker.taskcache.levels
Handling deprecation for yarn.nodemanager.linux-container-executor.nonsecure-mode.user-pattern
Handling deprecation for yarn.resourcemanager.zk-timeout-ms
Handling deprecation for yarn.resourcemanager.max-completed-applications
Handling deprecation for mapreduce.job.jvm.numtasks
Handling deprecation for yarn.sharedcache.cleaner.period-mins
Handling deprecation for mapreduce.jobtracker.tasktracker.maxblacklists
Handling deprecation for dfs.namenode.top.num.users
Handling deprecation for yarn.nodemanager.linux-container-executor.cgroups.mount
Handling deprecation for yarn.sharedcache.checksum.algo.impl
Handling deprecation for mapreduce.job.end-notification.max.retry.interval
Handling deprecation for mapreduce.job.acl-view-job
Handling deprecation for mapreduce.job.classloader
Handling deprecation for yarn.log-aggregation-enable
Handling deprecation for mapreduce.reduce.shuffle.fetch.retry.interval-ms
Handling deprecation for yarn.resourcemanager.nodemanager.minimum.version
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.size
Handling deprecation for yarn.app.mapreduce.am.job.task.listener.thread-count
Handling deprecation for yarn.app.mapreduce.am.resource.cpu-vcores
Handling deprecation for dfs.namenode.edit.log.autoroll.check.interval.ms
Handling deprecation for mapreduce.output.fileoutputformat.compress.type
Handling deprecation for hadoop.hdfs.configuration.version
Handling deprecation for hadoop.security.group.mapping.ldap.search.attr.member
Handling deprecation for yarn.nodemanager.log.retain-seconds
Handling deprecation for yarn.nodemanager.local-cache.max-files-per-directory
Handling deprecation for mapreduce.job.end-notification.retry.interval
Handling deprecation for hadoop.ssl.client.conf
Handling deprecation for yarn.sharedcache.root-dir
Handling deprecation for dfs.journalnode.https-address
Handling deprecation for mapreduce.reduce.shuffle.fetch.retry.timeout-ms
Handling deprecation for dfs.bytes-per-checksum
Handling deprecation for dfs.namenode.max.objects
Handling deprecation for mapreduce.tasktracker.instrumentation
Handling deprecation for dfs.datanode.max.transfer.threads
Handling deprecation for dfs.block.access.key.update.interval
Handling deprecation for mapreduce.jobtracker.jobhistory.task.numberprogresssplits
Handling deprecation for mapreduce.map.memory.mb
Handling deprecation for ha.failover-controller.new-active.rpc-timeout.ms
Handling deprecation for hadoop.ssl.hostname.verifier
Handling deprecation for dfs.client.read.shortcircuit
Handling deprecation for dfs.datanode.hdfs-blocks-metadata.enabled
Handling deprecation for mapreduce.tasktracker.healthchecker.interval
Handling deprecation for dfs.image.transfer.chunksize
Handling deprecation for mapreduce.tasktracker.taskmemorymanager.monitoringinterval
Handling deprecation for dfs.client.https.keystore.resource
Handling deprecation for yarn.resourcemanager.connect.retry-interval.ms
Handling deprecation for yarn.timeline-service.webapp.address
Handling deprecation for s3native.blocksize
Handling deprecation for yarn.scheduler.minimum-allocation-mb
Handling deprecation for yarn.sharedcache.cleaner.resource-sleep-ms
Handling deprecation for net.topology.impl
Handling deprecation for dfs.client.failover.sleep.base.millis
Handling deprecation for dfs.permissions.superusergroup
Handling deprecation for io.seqfile.compress.blocksize
Handling deprecation for hadoop.registry.zk.retry.times
Handling deprecation for fs.AbstractFileSystem.ftp.impl
Handling deprecation for dfs.namenode.checkpoint.edits.dir
Handling deprecation for mapreduce.job.running.reduce.limit
Handling deprecation for dfs.blockreport.initialDelay
Handling deprecation for dfs.namenode.heartbeat.recheck-interval
Handling deprecation for dfs.namenode.safemode.extension
Handling deprecation for yarn.scheduler.maximum-allocation-mb
Handling deprecation for mapreduce.job.reduce.shuffle.consumer.plugin.class
Handling deprecation for yarn.nodemanager.vmem-check-enabled
Handling deprecation for mapreduce.task.io.sort.factor
Handling deprecation for mapreduce.jobtracker.persist.jobstatus.dir
Handling deprecation for dfs.client.failover.sleep.max.millis
Handling deprecation for dfs.namenode.delegation.key.update-interval
Handling deprecation for hadoop.rpc.protection
Handling deprecation for fs.permissions.umask-mode
Handling deprecation for fs.s3.sleepTimeSeconds
Handling deprecation for ha.health-monitor.rpc-timeout.ms
Handling deprecation for hadoop.http.staticuser.user
Handling deprecation for fs.s3a.connection.maximum
Handling deprecation for yarn.nodemanager.linux-container-executor.nonsecure-mode.limit-users
Handling deprecation for fs.s3a.paging.maximum
Handling deprecation for fs.AbstractFileSystem.viewfs.impl
Handling deprecation for fs.ftp.host
Handling deprecation for yarn.nodemanager.linux-container-executor.nonsecure-mode.local-user
Handling deprecation for fs.s3a.impl
Handling deprecation for hadoop.http.authentication.kerberos.keytab
Handling deprecation for dfs.namenode.fs-limits.max-blocks-per-file
Handling deprecation for mapreduce.tasktracker.http.threads
Handling deprecation for mapreduce.tasktracker.dns.nameserver
Handling deprecation for yarn.resourcemanager.am-rm-tokens.master-key-rolling-interval-secs
Handling deprecation for dfs.client.block.write.replace-datanode-on-failure.enable
Handling deprecation for io.compression.codec.bzip2.library
Handling deprecation for mapreduce.map.skip.maxrecords
Handling deprecation for dfs.client.use.legacy.blockreader.local
Handling deprecation for dfs.namenode.checkpoint.dir
Handling deprecation for dfs.namenode.top.windows.minutes
Handling deprecation for mapreduce.job.maxtaskfailures.per.tracker
Handling deprecation for net.topology.node.switch.mapping.impl
Handling deprecation for mapreduce.shuffle.max.connections
Handling deprecation for mapreduce.jobhistory.loadedjobs.cache.size
Handling deprecation for dfs.storage.policy.enabled
Handling deprecation for yarn.client.application-client-protocol.poll-interval-ms
Handling deprecation for yarn.nodemanager.localizer.address
Handling deprecation for dfs.namenode.list.cache.pools.num.responses
Handling deprecation for nfs.server.port
Handling deprecation for mapreduce.client.output.filter
Handling deprecation for yarn.timeline-service.client.best-effort
Handling deprecation for ha.zookeeper.parent-znode
Handling deprecation for mapreduce.jobtracker.persist.jobstatus.hours
Handling deprecation for yarn.sharedcache.admin.thread-count
Handling deprecation for yarn.nodemanager.resource.cpu-vcores
Handling deprecation for dfs.datanode.block-pinning.enabled
Handling deprecation for mapreduce.jobhistory.http.policy
Handling deprecation for yarn.resourcemanager.webapp.delegation-token-auth-filter.enabled
Handling deprecation for mapreduce.job.speculative.retry-after-no-speculate
Handling deprecation for fs.s3a.attempts.maximum
Handling deprecation for s3native.stream-buffer-size
Handling deprecation for io.seqfile.local.dir
Handling deprecation for yarn.log-aggregation.retain-check-interval-seconds
Handling deprecation for fs.s3n.multipart.copy.block.size
Handling deprecation for dfs.encrypt.data.transfer.cipher.key.bitlength
Handling deprecation for dfs.datanode.sync.behind.writes
Handling deprecation for yarn.resourcemanager.zk-acl
Handling deprecation for hadoop.ssl.keystores.factory.class
Handling deprecation for mapreduce.job.split.metainfo.maxsize
Handling deprecation for fs.s3.maxRetries
Handling deprecation for hadoop.security.random.device.file.path
Handling deprecation for yarn.client.nodemanager-connect.max-wait-ms
Handling deprecation for dfs.namenode.stale.datanode.interval
Handling deprecation for mapreduce.task.io.sort.mb
Handling deprecation for yarn.resourcemanager.zk-state-store.parent-path
Handling deprecation for yarn.app.mapreduce.client-am.ipc.max-retries
Handling deprecation for fs.client.resolve.remote.symlinks
Handling deprecation for yarn.nodemanager.linux-container-executor.cgroups.strict-resource-usage
Handling deprecation for hadoop.ssl.enabled.protocols
Handling deprecation for mapreduce.reduce.cpu.vcores
Handling deprecation for yarn.client.failover-retries
Handling deprecation for mapreduce.jobhistory.address
Handling deprecation for hadoop.ssl.enabled
Handling deprecation for dfs.replication.max
Handling deprecation for dfs.namenode.name.dir
Handling deprecation for dfs.datanode.https.address
Handling deprecation for ipc.client.kill.max
Handling deprecation for mapreduce.job.committer.setup.cleanup.needed
Handling deprecation for dfs.client.domain.socket.data.traffic
Handling deprecation for yarn.nodemanager.localizer.cache.target-size-mb
Handling deprecation for yarn.resourcemanager.admin.client.thread-count
Handling deprecation for dfs.block.access.token.enable
Handling deprecation for mapreduce.job.speculative.retry-after-speculate
Handling deprecation for dfs.datanode.address
Handling deprecation for mapreduce.jobtracker.restart.recover
Handling deprecation for ipc.client.connect.max.retries
Handling deprecation for yarn.timeline-service.store-class
Handling deprecation for dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
Handling deprecation for hadoop.tmp.dir
Handling deprecation for dfs.datanode.handler.count
Handling deprecation for yarn.resourcemanager.ha.automatic-failover.embedded
Handling deprecation for yarn.timeline-service.ttl-ms
Handling deprecation for mapreduce.task.profile.map.params
Handling deprecation for yarn.resourcemanager.nodemanagers.heartbeat-interval-ms
Handling deprecation for mapreduce.map.speculative
Handling deprecation for yarn.timeline-service.recovery.enabled
Handling deprecation for mapreduce.job.map.class
Handling deprecation for dfs.namenode.resource.checked.volumes.minimum
Handling deprecation for yarn.nodemanager.recovery.dir
Handling deprecation for mapreduce.job.counters.max
Handling deprecation for yarn.resourcemanager.keytab
Handling deprecation for dfs.namenode.max.extra.edits.segments.retained
Handling deprecation for dfs.webhdfs.user.provider.user.pattern
Handling deprecation for dfs.client.mmap.enabled
Handling deprecation for mapreduce.map.log.level
Handling deprecation for dfs.client.file-block-storage-locations.timeout.millis
Handling deprecation for yarn.client.max-cached-nodemanagers-proxies
Handling deprecation for yarn.app.mapreduce.am.scheduler.heartbeat.interval-ms
Handling deprecation for hadoop.fuse.timer.period
Handling deprecation for fs.trash.checkpoint.interval
Handling deprecation for yarn.sharedcache.app-checker.class
Handling deprecation for dfs.journalnode.http-address
Handling deprecation for yarn.app.mapreduce.am.staging-dir
Handling deprecation for mapreduce.tasktracker.local.dir.minspacestart
Handling deprecation for yarn.nm.liveness-monitor.expiry-interval-ms
Handling deprecation for ha.health-monitor.check-interval.ms
Handling deprecation for mapreduce.reduce.shuffle.merge.percent
Handling deprecation for dfs.namenode.retrycache.heap.percent
Handling deprecation for yarn.nodemanager.docker-container-executor.exec-name
Handling deprecation for ipc.client.connect.timeout
Handling deprecation for yarn.resourcemanager.fs.state-store.retry-interval-ms
Handling deprecation for mapreduce.output.fileoutputformat.compress
Handling deprecation for yarn.nodemanager.local-dirs
Handling deprecation for yarn.nodemanager.recovery.enabled
Handling deprecation for io.native.lib.available
Handling deprecation for yarn.sharedcache.store.in-memory.staleness-period-mins
Handling deprecation for yarn.resourcemanager.am.max-attempts
Handling deprecation for s3.replication
Handling deprecation for mapreduce.input.fileinputformat.inputdir
Handling deprecation for fs.AbstractFileSystem.har.impl
Handling deprecation for dfs.image.compress
Handling deprecation for mapreduce.job.running.map.limit
Handling deprecation for mapreduce.reduce.input.buffer.percent
Handling deprecation for yarn.nodemanager.webapp.address
Handling deprecation for dfs.datanode.available-space-volume-choosing-policy.balanced-space-preference-fraction
Handling deprecation for dfs.namenode.edit.log.autoroll.multiplier.threshold
Handling deprecation for hadoop.security.group.mapping.ldap.ssl
Handling deprecation for dfs.namenode.checkpoint.check.period
Handling deprecation for fs.defaultFS
Handling deprecation for fs.s3a.multipart.size
Handling deprecation for dfs.client.slow.io.warning.threshold.ms
Handling deprecation for yarn.app.mapreduce.am.job.committer.commit-window
Handling deprecation for hadoop.security.group.mapping.ldap.search.attr.group.name
Handling deprecation for yarn.nodemanager.disk-health-checker.max-disk-utilization-per-disk-percentage
Handling deprecation for yarn.nodemanager.container-monitor.procfs-tree.smaps-based-rss.enabled
Handling deprecation for mapreduce.job.submithostname
Handling deprecation for mapreduce.map.sort.spill.percent
Handling deprecation for hadoop.security.crypto.codec.classes.aes.ctr.nopadding
Handling deprecation for dfs.namenode.http-address
Handling deprecation for hadoop.security.groups.negative-cache.secs
Handling deprecation for hadoop.ssl.server.conf
Handling deprecation for mapreduce.ifile.readahead
Handling deprecation for s3native.replication
Handling deprecation for yarn.client.nodemanager-client-async.thread-pool-max-size
Handling deprecation for mapreduce.jobtracker.staging.root.dir
Handling deprecation for mapreduce.jobhistory.admin.address
Handling deprecation for dfs.namenode.startup.delay.block.deletion.sec
Handling deprecation for yarn.nodemanager.health-checker.interval-ms
Handling deprecation for dfs.namenode.checkpoint.max-retries
Handling deprecation for s3.stream-buffer-size
Handling deprecation for ftp.client-write-packet-size
Handling deprecation for dfs.datanode.fsdatasetcache.max.threads.per.volume
Handling deprecation for mapreduce.output.fileoutputformat.compress.codec
Handling deprecation for yarn.timeline-service.keytab
Handling deprecation for yarn.sharedcache.store.in-memory.initial-delay-mins
Handling deprecation for mapreduce.jobhistory.webapp.address
Handling deprecation for mapreduce.task.userlog.limit.kb
Handling deprecation for mapreduce.reduce.shuffle.fetch.retry.enabled
Handling deprecation for yarn.app.mapreduce.task.container.log.backups
Handling deprecation for dfs.heartbeat.interval
Handling deprecation for ha.zookeeper.session-timeout.ms
Handling deprecation for fs.s3a.connection.ssl.enabled
Handling deprecation for yarn.sharedcache.webapp.address
Handling deprecation for hadoop.http.authentication.signature.secret.file
Handling deprecation for hadoop.fuse.connection.timeout
Handling deprecation for mapreduce.input.fileinputformat.numinputfiles
Handling deprecation for yarn.nodemanager.log-aggregation.compression-type
Handling deprecation for ipc.server.max.connections
Handling deprecation for yarn.resourcemanager.work-preserving-recovery.scheduling-wait-ms
Handling deprecation for yarn.nodemanager.log-dirs
Handling deprecation for yarn.app.mapreduce.am.resource.mb
Handling deprecation for hadoop.security.groups.cache.secs
Handling deprecation for mapreduce.job.speculative.minimum-allowed-tasks
Handling deprecation for yarn.nodemanager.container-monitor.interval-ms
Handling deprecation for dfs.datanode.cache.revocation.timeout.ms
Handling deprecation for mapreduce.jobhistory.recovery.store.class
Handling deprecation for mapreduce.task.combine.progress.records
Handling deprecation for s3.client-write-packet-size
Handling deprecation for mapreduce.jobtracker.instrumentation
Handling deprecation for dfs.replication
Handling deprecation for mapreduce.shuffle.transfer.buffer.size
Handling deprecation for hadoop.security.group.mapping.ldap.directory.search.timeout
Handling deprecation for dfs.datanode.available-space-volume-choosing-policy.balanced-space-threshold
Handling deprecation for hadoop.work.around.non.threadsafe.getpwuid
Handling deprecation for yarn.app.mapreduce.client-am.ipc.max-retries-on-timeouts
Handling deprecation for yarn.nodemanager.address
Handling deprecation for mapreduce.tasktracker.taskcontroller
Handling deprecation for mapreduce.tasktracker.indexcache.mb
Handling deprecation for yarn.scheduler.maximum-allocation-vcores
Handling deprecation for mapreduce.job.reduces
Handling deprecation for yarn.nodemanager.sleep-delay-before-sigkill.ms
Handling deprecation for yarn.timeline-service.address
Handling deprecation for yarn.resourcemanager.configuration.provider-class
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.expiry
Handling deprecation for yarn.sharedcache.enabled
Handling deprecation for tfile.io.chunk.size
Handling deprecation for mapreduce.job.acl-modify-job
Handling deprecation for hadoop.registry.zk.session.timeout.ms
Handling deprecation for fs.automatic.close
Handling deprecation for ha.health-monitor.sleep-after-disconnect.ms
Handling deprecation for mapreduce.tasktracker.reduce.tasks.maximum
Handling deprecation for mapreduce.input.fileinputformat.list-status.num-threads
Handling deprecation for dfs.datanode.directoryscan.threads
Handling deprecation for dfs.datanode.directoryscan.interval
Handling deprecation for dfs.namenode.acls.enabled
Handling deprecation for dfs.client.short.circuit.replica.stale.threshold.ms
Handling deprecation for hadoop.http.authentication.token.validity
Handling deprecation for fs.s3.block.size
Handling deprecation for ha.failover-controller.graceful-fence.rpc-timeout.ms
Handling deprecation for mapreduce.tasktracker.local.dir.minspacekill
Handling deprecation for dfs.namenode.resource.du.reserved
Handling deprecation for mapreduce.jobhistory.cleaner.interval-ms
Handling deprecation for dfs.namenode.datanode.registration.ip-hostname-check
Handling deprecation for mapreduce.jobhistory.intermediate-done-dir
Handling deprecation for mapreduce.jobtracker.http.address
Handling deprecation for dfs.namenode.backup.http-address
Handling deprecation for dfs.namenode.edits.noeditlogchannelflush
Handling deprecation for mapreduce.reduce.shuffle.input.buffer.percent
Handling deprecation for mapreduce.map.maxattempts
Handling deprecation for yarn.http.policy
Handling deprecation for dfs.namenode.audit.loggers
Handling deprecation for hadoop.security.groups.cache.warn.after.ms
Handling deprecation for io.serializations
Handling deprecation for mapreduce.tasktracker.outofband.heartbeat
Handling deprecation for mapreduce.reduce.shuffle.read.timeout
Handling deprecation for hadoop.security.crypto.buffer.size
Handling deprecation for mapreduce.reduce.skip.proc.count.autoincr
Handling deprecation for mapreduce.ifile.readahead.bytes
Handling deprecation for dfs.http.policy
Handling deprecation for hadoop.registry.secure
Handling deprecation for dfs.namenode.safemode.min.datanodes
Handling deprecation for dfs.client.file-block-storage-locations.num-threads
Handling deprecation for mapreduce.cluster.local.dir
Handling deprecation for mapreduce.tasktracker.report.address
Handling deprecation for dfs.namenode.secondary.https-address
Handling deprecation for hadoop.kerberos.kinit.command
Handling deprecation for yarn.timeline-service.http-authentication.type
Handling deprecation for dfs.block.access.token.lifetime
Handling deprecation for dfs.webhdfs.enabled
Handling deprecation for dfs.namenode.delegation.token.max-lifetime
Handling deprecation for dfs.namenode.avoid.write.stale.datanode
Handling deprecation for dfs.datanode.drop.cache.behind.writes
Handling deprecation for yarn.log-aggregation.retain-seconds
Handling deprecation for mapreduce.job.complete.cancel.delegation.tokens
Handling deprecation for mapreduce.local.clientfactory.class.name
Handling deprecation for mapreduce.shuffle.connection-keep-alive.timeout
Handling deprecation for dfs.namenode.num.extra.edits.retained
Handling deprecation for yarn.scheduler.minimum-allocation-vcores
Handling deprecation for ipc.client.connect.max.retries.on.timeouts
Handling deprecation for yarn.timeline-service.client.retry-interval-ms
Handling deprecation for yarn.timeline-service.client.max-retries
Handling deprecation for fs.s3n.block.size
Handling deprecation for mapreduce.job.map.output.collector.class
Handling deprecation for ha.health-monitor.connect-retry-interval.ms
Handling deprecation for mapreduce.shuffle.max.threads
Handling deprecation for nfs.exports.allowed.hosts
Handling deprecation for dfs.client.mmap.cache.size
Handling deprecation for mapreduce.tasktracker.map.tasks.maximum
Handling deprecation for io.file.buffer.size
Handling deprecation for dfs.client.datanode-restart.timeout
Handling deprecation for io.mapfile.bloom.size
Handling deprecation for hadoop.security.kms.client.authentication.retry-count
Handling deprecation for dfs.namenode.checkpoint.txns
Handling deprecation for ipc.client.connect.retry.interval
Handling deprecation for dfs.client-write-packet-size
Handling deprecation for mapreduce.reduce.shuffle.connect.timeout
Handling deprecation for yarn.resourcemanager.fs.state-store.uri
Handling deprecation for fs.swift.impl
Handling deprecation for hadoop.registry.zk.connection.timeout.ms
Handling deprecation for mapred.queue.default.acl-administer-jobs
Handling deprecation for mapreduce.job.submithostaddress
Handling deprecation for dfs.cachereport.intervalMsec
Handling deprecation for yarn.app.mapreduce.shuffle.log.backups
Handling deprecation for yarn.app.mapreduce.am.container.log.limit.kb
Handling deprecation for yarn.nodemanager.resourcemanager.minimum.version
Handling deprecation for ftp.blocksize
Handling deprecation for yarn.resourcemanager.address
Handling deprecation for file.stream-buffer-size
Handling deprecation for yarn.resourcemanager.scheduler.monitor.enable
Handling deprecation for mapreduce.job.ubertask.maxreduces
Handling deprecation for nfs.allow.insecure.ports
Handling deprecation for yarn.sharedcache.nm.uploader.thread-count
Handling deprecation for ipc.client.idlethreshold
Handling deprecation for ftp.stream-buffer-size
Handling deprecation for yarn.sharedcache.client-server.address
Handling deprecation for dfs.client.failover.connection.retries.on.timeouts
Handling deprecation for dfs.namenode.replication.work.multiplier.per.iteration
Handling deprecation for hadoop.http.authentication.simple.anonymous.allowed
Handling deprecation for hadoop.security.authorization
Handling deprecation for yarn.client.nodemanager-connect.retry-interval-ms
Handling deprecation for yarn.am.liveness-monitor.expiry-interval-ms
Handling deprecation for fs.har.impl.disable.cache
Handling deprecation for yarn.nodemanager.linux-container-executor.resources-handler.class
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.read-cache-size
Handling deprecation for hadoop.security.authentication
Handling deprecation for dfs.image.compression.codec
Handling deprecation for mapreduce.task.files.preserve.failedtasks
Handling deprecation for dfs.client.read.shortcircuit.streams.cache.size
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.path
Handling deprecation for mapreduce.job.reduce.slowstart.completedmaps
Handling deprecation for mapreduce.jobhistory.minicluster.fixed.ports
Handling deprecation for file.replication
Handling deprecation for yarn.resourcemanager.ha.automatic-failover.enabled
Handling deprecation for mapreduce.job.userlog.retain.hours
Handling deprecation for mapreduce.jobhistory.joblist.cache.size
Handling deprecation for dfs.namenode.accesstime.precision
Handling deprecation for yarn.resourcemanager.work-preserving-recovery.enabled
Handling deprecation for dfs.namenode.fs-limits.max-xattrs-per-inode
Handling deprecation for io.mapfile.bloom.error.rate
Handling deprecation for yarn.resourcemanager.store.class
Handling deprecation for dfs.image.transfer.timeout
Handling deprecation for yarn.timeline-service.leveldb-state-store.path
Handling deprecation for nfs.wtmax
Handling deprecation for mapreduce.job.combine.class
Handling deprecation for dfs.namenode.support.allow.format
Handling deprecation for fs.s3a.multipart.purge
Handling deprecation for dfs.secondary.namenode.kerberos.internal.spnego.principal
Handling deprecation for fs.s3a.connection.establish.timeout
Handling deprecation for dfs.stream-buffer-size
Handling deprecation for dfs.namenode.invalidate.work.pct.per.iteration
Handling deprecation for yarn.nodemanager.container-executor.class
Handling deprecation for fs.s3a.multipart.purge.age
Handling deprecation for yarn.resourcemanager.scheduler.client.thread-count
Handling deprecation for dfs.namenode.top.enabled
Handling deprecation for yarn.app.mapreduce.shuffle.log.separate
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.low-watermark
Handling deprecation for fs.s3a.fast.buffer.size
Handling deprecation for hadoop.user.group.static.mapping.overrides
Handling deprecation for tfile.fs.input.buffer.size
Handling deprecation for dfs.client.cached.conn.retry
Handling deprecation for hadoop.http.authentication.type
Handling deprecation for dfs.namenode.list.encryption.zones.num.responses
Handling deprecation for mapreduce.map.cpu.vcores
Handling deprecation for dfs.namenode.path.based.cache.refresh.interval.ms
Handling deprecation for dfs.namenode.decommission.interval
Handling deprecation for dfs.namenode.fs-limits.max-directory-items
Handling deprecation for yarn.resourcemanager.zk-retry-interval-ms
Handling deprecation for ftp.bytes-per-checksum
Handling deprecation for dfs.ha.log-roll.period
Handling deprecation for dfs.user.home.dir.prefix
Handling deprecation for ipc.client.fallback-to-simple-auth-allowed
Handling deprecation for yarn.nodemanager.pmem-check-enabled
Handling deprecation for yarn.nodemanager.remote-app-log-dir
Handling deprecation for dfs.namenode.inotify.max.events.per.rpc
Handling deprecation for mapreduce.task.profile.maps
Handling deprecation for mapreduce.shuffle.ssl.file.buffer.size
Handling deprecation for mapreduce.tasktracker.healthchecker.script.timeout
Handling deprecation for yarn.timeline-service.webapp.https.address
Handling deprecation for yarn.nodemanager.resource.percentage-physical-cpu-limit
Handling deprecation for yarn.app.mapreduce.am.command-opts
Handling deprecation for dfs.namenode.fs-limits.max-xattr-size
Handling deprecation for dfs.datanode.http.address
Handling deprecation for dfs.namenode.blocks.per.postponedblocks.rescan
Handling deprecation for yarn.sharedcache.nm.uploader.replication.factor
Handling deprecation for hadoop.registry.zk.root
Handling deprecation for hadoop.jetty.logs.serve.aliases
Handling deprecation for yarn.client.failover-proxy-provider
Handling deprecation for mapreduce.jobhistory.admin.acl
Handling deprecation for yarn.app.mapreduce.am.hard-kill-timeout-ms
Handling deprecation for yarn.nodemanager.remote-app-log-dir-suffix
Handling deprecation for mapreduce.jobhistory.principal
Handling deprecation for yarn.resourcemanager.webapp.address
Handling deprecation for mapreduce.jobhistory.recovery.enable
Handling deprecation for yarn.sharedcache.store.in-memory.check-period-mins
Handling deprecation for nfs.mountd.port
Handling deprecation for mapreduce.reduce.merge.inmem.threshold
Handling deprecation for fs.df.interval
Handling deprecation for yarn.timeline-service.enabled
Handling deprecation for mapreduce.jobtracker.jobhistory.lru.cache.size
Handling deprecation for mapreduce.task.profile
Handling deprecation for mapreduce.job.output.key.class
Handling deprecation for yarn.nodemanager.hostname
Handling deprecation for dfs.namenode.num.checkpoints.retained
Handling deprecation for mapreduce.job.queuename
Handling deprecation for mapreduce.jobhistory.max-age-ms
Handling deprecation for mapreduce.job.token.tracking.ids.enabled
Handling deprecation for yarn.nodemanager.localizer.client.thread-count
Handling deprecation for yarn.sharedcache.uploader.server.thread-count
Handling deprecation for dfs.client.mmap.retry.timeout.ms
Handling deprecation for mapreduce.jobhistory.move.thread-count
Handling deprecation for dfs.permissions.enabled
Handling deprecation for dfs.blockreport.split.threshold
Handling deprecation for fs.AbstractFileSystem.hdfs.impl
Handling deprecation for dfs.datanode.balance.bandwidthPerSec
Handling deprecation for dfs.block.scanner.volume.bytes.per.second
Handling deprecation for hadoop.http.filter.initializers
Handling deprecation for yarn.timeline-service.http-authentication.simple.anonymous.allowed
Handling deprecation for dfs.default.chunk.view.size
Handling deprecation for yarn.sharedcache.client-server.thread-count
Handling deprecation for yarn.resourcemanager.resource-tracker.address
Handling deprecation for mapreduce.job.working.dir
Handling deprecation for mapreduce.jobhistory.datestring.cache.size
Handling deprecation for mapreduce.task.profile.params
Handling deprecation for dfs.namenode.decommission.blocks.per.interval
Handling deprecation for dfs.namenode.handler.count
Handling deprecation for dfs.image.transfer.bandwidthPerSec
Handling deprecation for rpc.metrics.quantile.enable
Handling deprecation for mapreduce.jobtracker.expire.trackers.interval
Handling deprecation for mapreduce.task.timeout
Handling deprecation for yarn.app.mapreduce.client.max-retries
Handling deprecation for yarn.nodemanager.resource.memory-mb
Handling deprecation for yarn.nodemanager.disk-health-checker.min-healthy-disks
Handling deprecation for dfs.datanode.failed.volumes.tolerated
Handling deprecation for yarn.timeline-service.handler-thread-count
Handling deprecation for ipc.server.listen.queue.size
Handling deprecation for fs.s3a.threads.max
Handling deprecation for yarn.resourcemanager.connect.max-wait.ms
Handling deprecation for mapreduce.fileoutputcommitter.algorithm.version
Handling deprecation for mapreduce.framework.name
Handling deprecation for mapreduce.map.skip.proc.count.autoincr
Handling deprecation for mapreduce.job.max.split.locations
Handling deprecation for yarn.resourcemanager.scheduler.class
Handling deprecation for yarn.resourcemanager.system-metrics-publisher.enabled
Handling deprecation for dfs.blocksize
Handling deprecation for yarn.sharedcache.nested-level
Handling deprecation for mapreduce.shuffle.connection-keep-alive.enable
Handling deprecation for fs.s3a.threads.keepalivetime
Handling deprecation for fs.s3a.connection.timeout
Handling deprecation for file.client-write-packet-size
Handling deprecation for ha.failover-controller.cli-check.rpc-timeout.ms
Handling deprecation for ha.zookeeper.acl
Handling deprecation for dfs.namenode.write.stale.datanode.ratio
Handling deprecation for dfs.encrypt.data.transfer
Handling deprecation for dfs.datanode.shared.file.descriptor.paths
Handling deprecation for mapreduce.input.lineinputformat.linespermap
Handling deprecation for yarn.resourcemanager.delayed.delegation-token.removal-interval-ms
Handling deprecation for yarn.nodemanager.localizer.fetch.thread-count
Handling deprecation for dfs.client.failover.max.attempts
Handling deprecation for yarn.resourcemanager.scheduler.address
Handling deprecation for dfs.client.read.shortcircuit.streams.cache.expiry.ms
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.start-time-write-cache-size
Handling deprecation for yarn.nodemanager.health-checker.script.timeout-ms
Handling deprecation for yarn.resourcemanager.fs.state-store.num-retries
Handling deprecation for hadoop.ssl.require.client.cert
Handling deprecation for hadoop.security.uid.cache.secs
Handling deprecation for mapreduce.jobhistory.keytab
Handling deprecation for dfs.client.read.shortcircuit.skip.checksum
Handling deprecation for yarn.resourcemanager.ha.automatic-failover.zk-base-path
Handling deprecation for mapreduce.shuffle.ssl.enabled
Handling deprecation for mapreduce.reduce.log.level
Handling deprecation for hadoop.registry.rm.enabled
Handling deprecation for mapreduce.tasktracker.dns.interface
Handling deprecation for yarn.resourcemanager.system-metrics-publisher.dispatcher.pool-size
Handling deprecation for mapreduce.job.speculative.speculative-cap-running-tasks
Handling deprecation for dfs.datanode.block.id.layout.upgrade.threads
Handling deprecation for dfs.datanode.use.datanode.hostname
Handling deprecation for dfs.client.context
Handling deprecation for yarn.resourcemanager.ha.enabled
Handling deprecation for mapred.reducer.new-api
Handling deprecation for dfs.namenode.delegation.token.renew-interval
Handling deprecation for dfs.blockreport.intervalMsec
Handling deprecation for fs.s3a.multipart.threshold
Handling deprecation for mapreduce.reduce.shuffle.memory.limit.percent
Handling deprecation for dfs.https.server.keystore.resource
Handling deprecation for io.map.index.skip
Handling deprecation for mapreduce.job.hdfs-servers
Handling deprecation for mapreduce.jobtracker.taskscheduler
Handling deprecation for dfs.namenode.kerberos.internal.spnego.principal
Handling deprecation for yarn.resourcemanager.state-store.max-completed-applications
Handling deprecation for mapreduce.map.output.compress
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.num.refill.threads
Handling deprecation for fs.s3n.multipart.uploads.block.size
Handling deprecation for mapreduce.task.merge.progress.records
Handling deprecation for dfs.datanode.dns.interface
Handling deprecation for map.sort.class
Handling deprecation for yarn.nodemanager.aux-services.mapreduce_shuffle.class
Handling deprecation for tfile.fs.output.buffer.size
Handling deprecation for fs.du.interval
Handling deprecation for dfs.client.failover.connection.retries
Handling deprecation for dfs.namenode.top.window.num.buckets
Handling deprecation for mapreduce.job.dir
Handling deprecation for fs.s3a.buffer.dir
Handling deprecation for mapreduce.reduce.shuffle.retry-delay.max.ms
Handling deprecation for yarn.sharedcache.uploader.server.address
Handling deprecation for mapreduce.client.progressmonitor.pollinterval
Handling deprecation for yarn.app.mapreduce.shuffle.log.limit.kb
Handling deprecation for dfs.datanode.max.locked.memory
Handling deprecation for dfs.namenode.retrycache.expirytime.millis
Handling deprecation for dfs.datanode.scan.period.hours
Handling deprecation for dfs.client.block.write.replace-datanode-on-failure.best-effort
Handling deprecation for mapreduce.jobhistory.move.interval-ms
Handling deprecation for dfs.ha.fencing.ssh.connect-timeout
Handling deprecation for yarn.nodemanager.log-aggregation.roll-monitoring-interval-seconds
Handling deprecation for dfs.namenode.fs-limits.max-component-length
Handling deprecation for hadoop.registry.zk.quorum
Handling deprecation for dfs.namenode.enable.retrycache
Handling deprecation for dfs.datanode.du.reserved
Handling deprecation for yarn.timeline-service.state-store-class
Handling deprecation for dfs.datanode.ipc.address
Handling deprecation for hadoop.registry.system.acls
Handling deprecation for dfs.client.block.write.replace-datanode-on-failure.policy
Handling deprecation for dfs.namenode.path.based.cache.retry.interval.ms
Handling deprecation for hadoop.security.crypto.cipher.suite
Handling deprecation for dfs.ha.tail-edits.period
Handling deprecation for mapreduce.task.profile.reduce.params
Handling deprecation for hadoop.registry.jaas.context
Handling deprecation for yarn.resourcemanager.hostname
Handling deprecation for mapreduce.reduce.memory.mb
Handling deprecation for hadoop.security.group.mapping.ldap.search.filter.group
Handling deprecation for hadoop.http.authentication.kerberos.principal
Handling deprecation for hadoop.security.group.mapping.ldap.search.filter.user
Handling deprecation for yarn.nodemanager.disk-health-checker.min-free-space-per-disk-mb
Handling deprecation for dfs.namenode.edits.dir
Handling deprecation for yarn.client.failover-retries-on-socket-timeouts
Handling deprecation for dfs.namenode.decommission.max.concurrent.tracked.nodes
Handling deprecation for mapreduce.client.completion.pollinterval
Handling deprecation for dfs.namenode.name.dir.restore
Handling deprecation for dfs.namenode.secondary.http-address
Handling deprecation for mapreduce.jobhistory.recovery.store.leveldb.path
Handling deprecation for yarn.sharedcache.store.class
Handling deprecation for s3.bytes-per-checksum
Handling deprecation for yarn.nodemanager.windows-container.cpu-limit.enabled
Handling deprecation for yarn.resourcemanager.webapp.https.address
Handling deprecation for yarn.nodemanager.vmem-pmem-ratio
Handling deprecation for dfs.namenode.checkpoint.period
Handling deprecation for dfs.ha.automatic-failover.enabled
Submitting tokens for job: job_local1723068883_0001
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.fs.FileContext.getAbstractFileSystem(FileContext.java:331)
Handling deprecation for all properties in config...
Handling deprecation for mapreduce.jobtracker.address
Handling deprecation for yarn.resourcemanager.scheduler.monitor.policies
Handling deprecation for dfs.namenode.resource.check.interval
Handling deprecation for mapreduce.jobhistory.client.thread-count
Handling deprecation for yarn.app.mapreduce.am.containerlauncher.threadpool-initial-size
Handling deprecation for mapred.child.java.opts
Handling deprecation for mapreduce.jobtracker.retiredjobs.cache.size
Handling deprecation for dfs.client.https.need-auth
Handling deprecation for yarn.admin.acl
Handling deprecation for yarn.app.mapreduce.am.job.committer.cancel-timeout
Handling deprecation for mapreduce.job.emit-timeline-data
Handling deprecation for fs.ftp.host.port
Handling deprecation for dfs.namenode.avoid.read.stale.datanode
Handling deprecation for dfs.journalnode.rpc-address
Handling deprecation for mapreduce.job.end-notification.retry.attempts
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.ttl-interval-ms
Handling deprecation for yarn.resourcemanager.leveldb-state-store.path
Handling deprecation for mapred.mapper.new-api
Handling deprecation for yarn.ipc.rpc.class
Handling deprecation for ipc.client.connection.maxidletime
Handling deprecation for yarn.nodemanager.process-kill-wait.ms
Handling deprecation for mapreduce.cluster.acls.enabled
Handling deprecation for mapreduce.jobtracker.handler.count
Handling deprecation for io.map.index.interval
Handling deprecation for dfs.namenode.https-address
Handling deprecation for mapreduce.task.profile.reduces
Handling deprecation for fs.s3n.multipart.uploads.enabled
Handling deprecation for io.seqfile.sorter.recordlimit
Handling deprecation for mapreduce.job.ubertask.maxmaps
Handling deprecation for mapreduce.tasktracker.tasks.sleeptimebeforesigkill
Handling deprecation for hadoop.util.hash.type
Handling deprecation for dfs.namenode.replication.min
Handling deprecation for yarn.nodemanager.container-manager.thread-count
Handling deprecation for mapreduce.jobtracker.jobhistory.block.size
Handling deprecation for dfs.namenode.fs-limits.min-block-size
Handling deprecation for mapreduce.app-submission.cross-platform
Handling deprecation for fs.AbstractFileSystem.file.impl
Handling deprecation for net.topology.script.number.args
Handling deprecation for yarn.resourcemanager.container-tokens.master-key-rolling-interval-secs
Handling deprecation for mapreduce.map.output.compress.codec
Handling deprecation for mapreduce.job.reducer.preempt.delay.sec
Handling deprecation for s3native.bytes-per-checksum
Handling deprecation for dfs.namenode.path.based.cache.block.map.allocation.percent
Handling deprecation for yarn.nodemanager.windows-container.memory-limit.enabled
Handling deprecation for mapreduce.input.fileinputformat.split.minsize
Handling deprecation for hadoop.security.group.mapping
Handling deprecation for mapreduce.jobtracker.system.dir
Handling deprecation for mapreduce.job.end-notification.max.attempts
Handling deprecation for mapreduce.reduce.markreset.buffer.percent
Handling deprecation for dfs.datanode.cache.revocation.polling.ms
Handling deprecation for mapreduce.reduce.speculative
Handling deprecation for yarn.nodemanager.localizer.cache.cleanup.interval-ms
Handling deprecation for dfs.namenode.lazypersist.file.scrub.interval.sec
Handling deprecation for fs.s3a.threads.core
Handling deprecation for mapreduce.jobhistory.recovery.store.fs.uri
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.start-time-read-cache-size
Handling deprecation for hadoop.registry.zk.retry.interval.ms
Handling deprecation for yarn.nodemanager.keytab
Handling deprecation for dfs.namenode.replication.interval
Handling deprecation for yarn.resourcemanager.admin.address
Handling deprecation for mapreduce.job.maps
Handling deprecation for nfs.dump.dir
Handling deprecation for mapreduce.job.user.name
Handling deprecation for mapreduce.jobtracker.maxtasks.perjob
Handling deprecation for mapreduce.job.ubertask.enable
Handling deprecation for mapreduce.job.reduce.class
Handling deprecation for yarn.nodemanager.delete.debug-delay-sec
Handling deprecation for yarn.timeline-service.ttl-enable
Handling deprecation for yarn.resourcemanager.fs.state-store.retry-policy-spec
Handling deprecation for mapreduce.reduce.skip.maxgroups
Handling deprecation for dfs.client.use.datanode.hostname
Handling deprecation for fs.trash.interval
Handling deprecation for mapreduce.job.name
Handling deprecation for mapreduce.am.max-attempts
Handling deprecation for mapreduce.jobtracker.heartbeats.in.second
Handling deprecation for yarn.resourcemanager.zk-num-retries
Handling deprecation for s3.blocksize
Handling deprecation for dfs.datanode.data.dir
Handling deprecation for mapreduce.jobtracker.persist.jobstatus.active
Handling deprecation for mapreduce.reduce.shuffle.parallelcopies
Handling deprecation for fs.s3.buffer.dir
Handling deprecation for mapreduce.jobhistory.done-dir
Handling deprecation for hadoop.security.instrumentation.requires.admin
Handling deprecation for hadoop.registry.zk.retry.ceiling.ms
Handling deprecation for nfs.rtmax
Handling deprecation for dfs.datanode.data.dir.perm
Handling deprecation for yarn.resourcemanager.container.liveness-monitor.interval-ms
Handling deprecation for yarn.nodemanager.env-whitelist
Handling deprecation for dfs.namenode.backup.address
Handling deprecation for dfs.namenode.xattrs.enabled
Handling deprecation for dfs.datanode.readahead.bytes
Handling deprecation for mapreduce.jobhistory.cleaner.enable
Handling deprecation for dfs.client.block.write.retries
Handling deprecation for mapreduce.tasktracker.http.address
Handling deprecation for yarn.nodemanager.linux-container-executor.cgroups.hierarchy
Handling deprecation for ha.failover-controller.graceful-fence.connection.retries
Handling deprecation for yarn.resourcemanager.recovery.enabled
Handling deprecation for yarn.app.mapreduce.am.container.log.backups
Handling deprecation for dfs.namenode.safemode.threshold-pct
Handling deprecation for yarn.nodemanager.disk-health-checker.interval-ms
Handling deprecation for hadoop.security.java.secure.random.algorithm
Handling deprecation for dfs.namenode.list.cache.directives.num.responses
Handling deprecation for dfs.datanode.dns.nameserver
Handling deprecation for mapreduce.cluster.temp.dir
Handling deprecation for fs.s3a.max.total.tasks
Handling deprecation for mapreduce.reduce.maxattempts
Handling deprecation for mapreduce.client.submit.file.replication
Handling deprecation for mapreduce.shuffle.port
Handling deprecation for yarn.resourcemanager.resource-tracker.client.thread-count
Handling deprecation for dfs.namenode.replication.considerLoad
Handling deprecation for dfs.namenode.edits.journal-plugin.qjournal
Handling deprecation for dfs.client.write.exclude.nodes.cache.expiry.interval.millis
Handling deprecation for yarn.nodemanager.delete.thread-count
Handling deprecation for dfs.client.mmap.cache.timeout.ms
Handling deprecation for yarn.nodemanager.admin-env
Handling deprecation for io.skip.checksum.errors
Handling deprecation for yarn.timeline-service.hostname
Handling deprecation for yarn.resourcemanager.proxy-user-privileges.enabled
Handling deprecation for mapreduce.job.speculative.speculative-cap-total-tasks
Handling deprecation for yarn.acl.enable
Handling deprecation for fs.s3a.fast.upload
Handling deprecation for file.blocksize
Handling deprecation for mapreduce.job.speculative.slowtaskthreshold
Handling deprecation for ftp.replication
Handling deprecation for yarn.sharedcache.cleaner.initial-delay-mins
Handling deprecation for s3native.client-write-packet-size
Handling deprecation for hadoop.rpc.socket.factory.class.default
Handling deprecation for file.bytes-per-checksum
Handling deprecation for dfs.datanode.slow.io.warning.threshold.ms
Handling deprecation for io.seqfile.lazydecompress
Handling deprecation for mapreduce.task.skip.start.attempts
Handling deprecation for dfs.namenode.reject-unresolved-dn-topology-mapping
Handling deprecation for hadoop.common.configuration.version
Handling deprecation for yarn.resourcemanager.client.thread-count
Handling deprecation for dfs.datanode.drop.cache.behind.reads
Handling deprecation for yarn.sharedcache.admin.address
Handling deprecation for mapreduce.job.output.value.class
Handling deprecation for mapreduce.output.fileoutputformat.outputdir
Handling deprecation for mapreduce.jobtracker.taskcache.levels
Handling deprecation for yarn.nodemanager.linux-container-executor.nonsecure-mode.user-pattern
Handling deprecation for yarn.resourcemanager.zk-timeout-ms
Handling deprecation for yarn.resourcemanager.max-completed-applications
Handling deprecation for mapreduce.job.jvm.numtasks
Handling deprecation for yarn.sharedcache.cleaner.period-mins
Handling deprecation for mapreduce.jobtracker.tasktracker.maxblacklists
Handling deprecation for dfs.namenode.top.num.users
Handling deprecation for yarn.nodemanager.linux-container-executor.cgroups.mount
Handling deprecation for yarn.sharedcache.checksum.algo.impl
Handling deprecation for mapreduce.job.end-notification.max.retry.interval
Handling deprecation for mapreduce.job.acl-view-job
Handling deprecation for mapreduce.job.classloader
Handling deprecation for yarn.log-aggregation-enable
Handling deprecation for mapreduce.reduce.shuffle.fetch.retry.interval-ms
Handling deprecation for yarn.resourcemanager.nodemanager.minimum.version
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.size
Handling deprecation for yarn.app.mapreduce.am.job.task.listener.thread-count
Handling deprecation for yarn.app.mapreduce.am.resource.cpu-vcores
Handling deprecation for dfs.namenode.edit.log.autoroll.check.interval.ms
Handling deprecation for mapreduce.output.fileoutputformat.compress.type
Handling deprecation for hadoop.hdfs.configuration.version
Handling deprecation for hadoop.security.group.mapping.ldap.search.attr.member
Handling deprecation for yarn.nodemanager.log.retain-seconds
Handling deprecation for yarn.nodemanager.local-cache.max-files-per-directory
Handling deprecation for mapreduce.job.end-notification.retry.interval
Handling deprecation for hadoop.ssl.client.conf
Handling deprecation for yarn.sharedcache.root-dir
Handling deprecation for dfs.journalnode.https-address
Handling deprecation for mapreduce.reduce.shuffle.fetch.retry.timeout-ms
Handling deprecation for dfs.bytes-per-checksum
Handling deprecation for dfs.namenode.max.objects
Handling deprecation for mapreduce.tasktracker.instrumentation
Handling deprecation for dfs.datanode.max.transfer.threads
Handling deprecation for dfs.block.access.key.update.interval
Handling deprecation for mapreduce.jobtracker.jobhistory.task.numberprogresssplits
Handling deprecation for mapreduce.map.memory.mb
Handling deprecation for ha.failover-controller.new-active.rpc-timeout.ms
Handling deprecation for hadoop.ssl.hostname.verifier
Handling deprecation for dfs.client.read.shortcircuit
Handling deprecation for dfs.datanode.hdfs-blocks-metadata.enabled
Handling deprecation for mapreduce.tasktracker.healthchecker.interval
Handling deprecation for dfs.image.transfer.chunksize
Handling deprecation for mapreduce.tasktracker.taskmemorymanager.monitoringinterval
Handling deprecation for dfs.client.https.keystore.resource
Handling deprecation for yarn.resourcemanager.connect.retry-interval.ms
Handling deprecation for yarn.timeline-service.webapp.address
Handling deprecation for s3native.blocksize
Handling deprecation for yarn.scheduler.minimum-allocation-mb
Handling deprecation for yarn.sharedcache.cleaner.resource-sleep-ms
Handling deprecation for net.topology.impl
Handling deprecation for dfs.client.failover.sleep.base.millis
Handling deprecation for dfs.permissions.superusergroup
Handling deprecation for io.seqfile.compress.blocksize
Handling deprecation for hadoop.registry.zk.retry.times
Handling deprecation for fs.AbstractFileSystem.ftp.impl
Handling deprecation for dfs.namenode.checkpoint.edits.dir
Handling deprecation for mapreduce.job.running.reduce.limit
Handling deprecation for dfs.blockreport.initialDelay
Handling deprecation for dfs.namenode.heartbeat.recheck-interval
Handling deprecation for dfs.namenode.safemode.extension
Handling deprecation for yarn.scheduler.maximum-allocation-mb
Handling deprecation for mapreduce.job.reduce.shuffle.consumer.plugin.class
Handling deprecation for yarn.nodemanager.vmem-check-enabled
Handling deprecation for mapreduce.task.io.sort.factor
Handling deprecation for mapreduce.jobtracker.persist.jobstatus.dir
Handling deprecation for dfs.client.failover.sleep.max.millis
Handling deprecation for dfs.namenode.delegation.key.update-interval
Handling deprecation for hadoop.rpc.protection
Handling deprecation for fs.permissions.umask-mode
Handling deprecation for fs.s3.sleepTimeSeconds
Handling deprecation for ha.health-monitor.rpc-timeout.ms
Handling deprecation for hadoop.http.staticuser.user
Handling deprecation for fs.s3a.connection.maximum
Handling deprecation for yarn.nodemanager.linux-container-executor.nonsecure-mode.limit-users
Handling deprecation for fs.s3a.paging.maximum
Handling deprecation for fs.AbstractFileSystem.viewfs.impl
Handling deprecation for fs.ftp.host
Handling deprecation for yarn.nodemanager.linux-container-executor.nonsecure-mode.local-user
Handling deprecation for fs.s3a.impl
Handling deprecation for hadoop.http.authentication.kerberos.keytab
Handling deprecation for dfs.namenode.fs-limits.max-blocks-per-file
Handling deprecation for mapreduce.tasktracker.http.threads
Handling deprecation for mapreduce.tasktracker.dns.nameserver
Handling deprecation for yarn.resourcemanager.am-rm-tokens.master-key-rolling-interval-secs
Handling deprecation for dfs.client.block.write.replace-datanode-on-failure.enable
Handling deprecation for io.compression.codec.bzip2.library
Handling deprecation for mapreduce.map.skip.maxrecords
Handling deprecation for dfs.client.use.legacy.blockreader.local
Handling deprecation for dfs.namenode.checkpoint.dir
Handling deprecation for dfs.namenode.top.windows.minutes
Handling deprecation for mapreduce.job.maxtaskfailures.per.tracker
Handling deprecation for net.topology.node.switch.mapping.impl
Handling deprecation for mapreduce.shuffle.max.connections
Handling deprecation for mapreduce.jobhistory.loadedjobs.cache.size
Handling deprecation for dfs.storage.policy.enabled
Handling deprecation for yarn.client.application-client-protocol.poll-interval-ms
Handling deprecation for yarn.nodemanager.localizer.address
Handling deprecation for dfs.namenode.list.cache.pools.num.responses
Handling deprecation for nfs.server.port
Handling deprecation for mapreduce.client.output.filter
Handling deprecation for yarn.timeline-service.client.best-effort
Handling deprecation for ha.zookeeper.parent-znode
Handling deprecation for mapreduce.jobtracker.persist.jobstatus.hours
Handling deprecation for yarn.sharedcache.admin.thread-count
Handling deprecation for yarn.nodemanager.resource.cpu-vcores
Handling deprecation for dfs.datanode.block-pinning.enabled
Handling deprecation for mapreduce.jobhistory.http.policy
Handling deprecation for yarn.resourcemanager.webapp.delegation-token-auth-filter.enabled
Handling deprecation for mapreduce.job.speculative.retry-after-no-speculate
Handling deprecation for fs.s3a.attempts.maximum
Handling deprecation for s3native.stream-buffer-size
Handling deprecation for io.seqfile.local.dir
Handling deprecation for yarn.log-aggregation.retain-check-interval-seconds
Handling deprecation for fs.s3n.multipart.copy.block.size
Handling deprecation for dfs.encrypt.data.transfer.cipher.key.bitlength
Handling deprecation for dfs.datanode.sync.behind.writes
Handling deprecation for yarn.resourcemanager.zk-acl
Handling deprecation for hadoop.ssl.keystores.factory.class
Handling deprecation for mapreduce.job.split.metainfo.maxsize
Handling deprecation for fs.s3.maxRetries
Handling deprecation for hadoop.security.random.device.file.path
Handling deprecation for yarn.client.nodemanager-connect.max-wait-ms
Handling deprecation for dfs.namenode.stale.datanode.interval
Handling deprecation for mapreduce.task.io.sort.mb
Handling deprecation for yarn.resourcemanager.zk-state-store.parent-path
Handling deprecation for yarn.app.mapreduce.client-am.ipc.max-retries
Handling deprecation for fs.client.resolve.remote.symlinks
Handling deprecation for yarn.nodemanager.linux-container-executor.cgroups.strict-resource-usage
Handling deprecation for hadoop.ssl.enabled.protocols
Handling deprecation for mapreduce.reduce.cpu.vcores
Handling deprecation for yarn.client.failover-retries
Handling deprecation for mapreduce.jobhistory.address
Handling deprecation for hadoop.ssl.enabled
Handling deprecation for dfs.replication.max
Handling deprecation for dfs.namenode.name.dir
Handling deprecation for dfs.datanode.https.address
Handling deprecation for ipc.client.kill.max
Handling deprecation for mapreduce.job.committer.setup.cleanup.needed
Handling deprecation for dfs.client.domain.socket.data.traffic
Handling deprecation for yarn.nodemanager.localizer.cache.target-size-mb
Handling deprecation for yarn.resourcemanager.admin.client.thread-count
Handling deprecation for dfs.block.access.token.enable
Handling deprecation for mapreduce.job.speculative.retry-after-speculate
Handling deprecation for dfs.datanode.address
Handling deprecation for mapreduce.jobtracker.restart.recover
Handling deprecation for ipc.client.connect.max.retries
Handling deprecation for yarn.timeline-service.store-class
Handling deprecation for dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
Handling deprecation for hadoop.tmp.dir
Handling deprecation for dfs.datanode.handler.count
Handling deprecation for yarn.resourcemanager.ha.automatic-failover.embedded
Handling deprecation for yarn.timeline-service.ttl-ms
Handling deprecation for mapreduce.task.profile.map.params
Handling deprecation for yarn.resourcemanager.nodemanagers.heartbeat-interval-ms
Handling deprecation for mapreduce.map.speculative
Handling deprecation for yarn.timeline-service.recovery.enabled
Handling deprecation for mapreduce.job.map.class
Handling deprecation for dfs.namenode.resource.checked.volumes.minimum
Handling deprecation for yarn.nodemanager.recovery.dir
Handling deprecation for mapreduce.job.counters.max
Handling deprecation for yarn.resourcemanager.keytab
Handling deprecation for dfs.namenode.max.extra.edits.segments.retained
Handling deprecation for dfs.webhdfs.user.provider.user.pattern
Handling deprecation for dfs.client.mmap.enabled
Handling deprecation for mapreduce.map.log.level
Handling deprecation for dfs.client.file-block-storage-locations.timeout.millis
Handling deprecation for yarn.client.max-cached-nodemanagers-proxies
Handling deprecation for yarn.app.mapreduce.am.scheduler.heartbeat.interval-ms
Handling deprecation for hadoop.fuse.timer.period
Handling deprecation for fs.trash.checkpoint.interval
Handling deprecation for yarn.sharedcache.app-checker.class
Handling deprecation for dfs.journalnode.http-address
Handling deprecation for yarn.app.mapreduce.am.staging-dir
Handling deprecation for mapreduce.tasktracker.local.dir.minspacestart
Handling deprecation for yarn.nm.liveness-monitor.expiry-interval-ms
Handling deprecation for ha.health-monitor.check-interval.ms
Handling deprecation for mapreduce.reduce.shuffle.merge.percent
Handling deprecation for dfs.namenode.retrycache.heap.percent
Handling deprecation for yarn.nodemanager.docker-container-executor.exec-name
Handling deprecation for ipc.client.connect.timeout
Handling deprecation for yarn.resourcemanager.fs.state-store.retry-interval-ms
Handling deprecation for mapreduce.output.fileoutputformat.compress
Handling deprecation for yarn.nodemanager.local-dirs
Handling deprecation for yarn.nodemanager.recovery.enabled
Handling deprecation for io.native.lib.available
Handling deprecation for yarn.sharedcache.store.in-memory.staleness-period-mins
Handling deprecation for yarn.resourcemanager.am.max-attempts
Handling deprecation for s3.replication
Handling deprecation for mapreduce.input.fileinputformat.inputdir
Handling deprecation for fs.AbstractFileSystem.har.impl
Handling deprecation for dfs.image.compress
Handling deprecation for mapreduce.job.running.map.limit
Handling deprecation for mapreduce.reduce.input.buffer.percent
Handling deprecation for yarn.nodemanager.webapp.address
Handling deprecation for dfs.datanode.available-space-volume-choosing-policy.balanced-space-preference-fraction
Handling deprecation for dfs.namenode.edit.log.autoroll.multiplier.threshold
Handling deprecation for hadoop.security.group.mapping.ldap.ssl
Handling deprecation for dfs.namenode.checkpoint.check.period
Handling deprecation for fs.defaultFS
Handling deprecation for fs.s3a.multipart.size
Handling deprecation for dfs.client.slow.io.warning.threshold.ms
Handling deprecation for yarn.app.mapreduce.am.job.committer.commit-window
Handling deprecation for hadoop.security.group.mapping.ldap.search.attr.group.name
Handling deprecation for yarn.nodemanager.disk-health-checker.max-disk-utilization-per-disk-percentage
Handling deprecation for yarn.nodemanager.container-monitor.procfs-tree.smaps-based-rss.enabled
Handling deprecation for mapreduce.job.submithostname
Handling deprecation for mapreduce.map.sort.spill.percent
Handling deprecation for hadoop.security.crypto.codec.classes.aes.ctr.nopadding
Handling deprecation for dfs.namenode.http-address
Handling deprecation for hadoop.security.groups.negative-cache.secs
Handling deprecation for hadoop.ssl.server.conf
Handling deprecation for mapreduce.ifile.readahead
Handling deprecation for s3native.replication
Handling deprecation for yarn.client.nodemanager-client-async.thread-pool-max-size
Handling deprecation for mapreduce.jobtracker.staging.root.dir
Handling deprecation for mapreduce.jobhistory.admin.address
Handling deprecation for dfs.namenode.startup.delay.block.deletion.sec
Handling deprecation for yarn.nodemanager.health-checker.interval-ms
Handling deprecation for dfs.namenode.checkpoint.max-retries
Handling deprecation for s3.stream-buffer-size
Handling deprecation for ftp.client-write-packet-size
Handling deprecation for dfs.datanode.fsdatasetcache.max.threads.per.volume
Handling deprecation for mapreduce.output.fileoutputformat.compress.codec
Handling deprecation for yarn.timeline-service.keytab
Handling deprecation for yarn.sharedcache.store.in-memory.initial-delay-mins
Handling deprecation for mapreduce.jobhistory.webapp.address
Handling deprecation for mapreduce.task.userlog.limit.kb
Handling deprecation for mapreduce.reduce.shuffle.fetch.retry.enabled
Handling deprecation for yarn.app.mapreduce.task.container.log.backups
Handling deprecation for dfs.heartbeat.interval
Handling deprecation for ha.zookeeper.session-timeout.ms
Handling deprecation for fs.s3a.connection.ssl.enabled
Handling deprecation for yarn.sharedcache.webapp.address
Handling deprecation for hadoop.http.authentication.signature.secret.file
Handling deprecation for hadoop.fuse.connection.timeout
Handling deprecation for mapreduce.input.fileinputformat.numinputfiles
Handling deprecation for yarn.nodemanager.log-aggregation.compression-type
Handling deprecation for ipc.server.max.connections
Handling deprecation for yarn.resourcemanager.work-preserving-recovery.scheduling-wait-ms
Handling deprecation for yarn.nodemanager.log-dirs
Handling deprecation for yarn.app.mapreduce.am.resource.mb
Handling deprecation for hadoop.security.groups.cache.secs
Handling deprecation for mapreduce.job.speculative.minimum-allowed-tasks
Handling deprecation for yarn.nodemanager.container-monitor.interval-ms
Handling deprecation for dfs.datanode.cache.revocation.timeout.ms
Handling deprecation for mapreduce.jobhistory.recovery.store.class
Handling deprecation for mapreduce.task.combine.progress.records
Handling deprecation for s3.client-write-packet-size
Handling deprecation for mapreduce.jobtracker.instrumentation
Handling deprecation for dfs.replication
Handling deprecation for mapreduce.shuffle.transfer.buffer.size
Handling deprecation for hadoop.security.group.mapping.ldap.directory.search.timeout
Handling deprecation for dfs.datanode.available-space-volume-choosing-policy.balanced-space-threshold
Handling deprecation for hadoop.work.around.non.threadsafe.getpwuid
Handling deprecation for yarn.app.mapreduce.client-am.ipc.max-retries-on-timeouts
Handling deprecation for yarn.nodemanager.address
Handling deprecation for mapreduce.tasktracker.taskcontroller
Handling deprecation for mapreduce.tasktracker.indexcache.mb
Handling deprecation for yarn.scheduler.maximum-allocation-vcores
Handling deprecation for mapreduce.job.reduces
Handling deprecation for yarn.nodemanager.sleep-delay-before-sigkill.ms
Handling deprecation for yarn.timeline-service.address
Handling deprecation for yarn.resourcemanager.configuration.provider-class
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.expiry
Handling deprecation for yarn.sharedcache.enabled
Handling deprecation for tfile.io.chunk.size
Handling deprecation for mapreduce.job.acl-modify-job
Handling deprecation for hadoop.registry.zk.session.timeout.ms
Handling deprecation for fs.automatic.close
Handling deprecation for ha.health-monitor.sleep-after-disconnect.ms
Handling deprecation for mapreduce.tasktracker.reduce.tasks.maximum
Handling deprecation for mapreduce.input.fileinputformat.list-status.num-threads
Handling deprecation for dfs.datanode.directoryscan.threads
Handling deprecation for dfs.datanode.directoryscan.interval
Handling deprecation for dfs.namenode.acls.enabled
Handling deprecation for dfs.client.short.circuit.replica.stale.threshold.ms
Handling deprecation for hadoop.http.authentication.token.validity
Handling deprecation for fs.s3.block.size
Handling deprecation for ha.failover-controller.graceful-fence.rpc-timeout.ms
Handling deprecation for mapreduce.tasktracker.local.dir.minspacekill
Handling deprecation for dfs.namenode.resource.du.reserved
Handling deprecation for mapreduce.jobhistory.cleaner.interval-ms
Handling deprecation for dfs.namenode.datanode.registration.ip-hostname-check
Handling deprecation for mapreduce.jobhistory.intermediate-done-dir
Handling deprecation for mapreduce.jobtracker.http.address
Handling deprecation for dfs.namenode.backup.http-address
Handling deprecation for dfs.namenode.edits.noeditlogchannelflush
Handling deprecation for mapreduce.reduce.shuffle.input.buffer.percent
Handling deprecation for mapreduce.map.maxattempts
Handling deprecation for yarn.http.policy
Handling deprecation for dfs.namenode.audit.loggers
Handling deprecation for hadoop.security.groups.cache.warn.after.ms
Handling deprecation for io.serializations
Handling deprecation for mapreduce.tasktracker.outofband.heartbeat
Handling deprecation for mapreduce.reduce.shuffle.read.timeout
Handling deprecation for hadoop.security.crypto.buffer.size
Handling deprecation for mapreduce.reduce.skip.proc.count.autoincr
Handling deprecation for mapreduce.ifile.readahead.bytes
Handling deprecation for dfs.http.policy
Handling deprecation for hadoop.registry.secure
Handling deprecation for dfs.namenode.safemode.min.datanodes
Handling deprecation for dfs.client.file-block-storage-locations.num-threads
Handling deprecation for mapreduce.cluster.local.dir
Handling deprecation for mapreduce.tasktracker.report.address
Handling deprecation for dfs.namenode.secondary.https-address
Handling deprecation for hadoop.kerberos.kinit.command
Handling deprecation for yarn.timeline-service.http-authentication.type
Handling deprecation for dfs.block.access.token.lifetime
Handling deprecation for dfs.webhdfs.enabled
Handling deprecation for dfs.namenode.delegation.token.max-lifetime
Handling deprecation for dfs.namenode.avoid.write.stale.datanode
Handling deprecation for dfs.datanode.drop.cache.behind.writes
Handling deprecation for yarn.log-aggregation.retain-seconds
Handling deprecation for mapreduce.job.complete.cancel.delegation.tokens
Handling deprecation for mapreduce.local.clientfactory.class.name
Handling deprecation for mapreduce.shuffle.connection-keep-alive.timeout
Handling deprecation for dfs.namenode.num.extra.edits.retained
Handling deprecation for yarn.scheduler.minimum-allocation-vcores
Handling deprecation for ipc.client.connect.max.retries.on.timeouts
Handling deprecation for yarn.timeline-service.client.retry-interval-ms
Handling deprecation for yarn.timeline-service.client.max-retries
Handling deprecation for fs.s3n.block.size
Handling deprecation for mapreduce.job.map.output.collector.class
Handling deprecation for ha.health-monitor.connect-retry-interval.ms
Handling deprecation for mapreduce.shuffle.max.threads
Handling deprecation for nfs.exports.allowed.hosts
Handling deprecation for dfs.client.mmap.cache.size
Handling deprecation for mapreduce.tasktracker.map.tasks.maximum
Handling deprecation for io.file.buffer.size
Handling deprecation for dfs.client.datanode-restart.timeout
Handling deprecation for io.mapfile.bloom.size
Handling deprecation for hadoop.security.kms.client.authentication.retry-count
Handling deprecation for dfs.namenode.checkpoint.txns
Handling deprecation for ipc.client.connect.retry.interval
Handling deprecation for dfs.client-write-packet-size
Handling deprecation for mapreduce.reduce.shuffle.connect.timeout
Handling deprecation for yarn.resourcemanager.fs.state-store.uri
Handling deprecation for fs.swift.impl
Handling deprecation for hadoop.registry.zk.connection.timeout.ms
Handling deprecation for mapred.queue.default.acl-administer-jobs
Handling deprecation for mapreduce.job.submithostaddress
Handling deprecation for dfs.cachereport.intervalMsec
Handling deprecation for yarn.app.mapreduce.shuffle.log.backups
Handling deprecation for yarn.app.mapreduce.am.container.log.limit.kb
Handling deprecation for yarn.nodemanager.resourcemanager.minimum.version
Handling deprecation for ftp.blocksize
Handling deprecation for yarn.resourcemanager.address
Handling deprecation for file.stream-buffer-size
Handling deprecation for yarn.resourcemanager.scheduler.monitor.enable
Handling deprecation for mapreduce.job.ubertask.maxreduces
Handling deprecation for nfs.allow.insecure.ports
Handling deprecation for yarn.sharedcache.nm.uploader.thread-count
Handling deprecation for ipc.client.idlethreshold
Handling deprecation for ftp.stream-buffer-size
Handling deprecation for yarn.sharedcache.client-server.address
Handling deprecation for dfs.client.failover.connection.retries.on.timeouts
Handling deprecation for dfs.namenode.replication.work.multiplier.per.iteration
Handling deprecation for hadoop.http.authentication.simple.anonymous.allowed
Handling deprecation for hadoop.security.authorization
Handling deprecation for yarn.client.nodemanager-connect.retry-interval-ms
Handling deprecation for yarn.am.liveness-monitor.expiry-interval-ms
Handling deprecation for fs.har.impl.disable.cache
Handling deprecation for yarn.nodemanager.linux-container-executor.resources-handler.class
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.read-cache-size
Handling deprecation for hadoop.security.authentication
Handling deprecation for dfs.image.compression.codec
Handling deprecation for mapreduce.task.files.preserve.failedtasks
Handling deprecation for dfs.client.read.shortcircuit.streams.cache.size
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.path
Handling deprecation for mapreduce.job.reduce.slowstart.completedmaps
Handling deprecation for mapreduce.jobhistory.minicluster.fixed.ports
Handling deprecation for file.replication
Handling deprecation for yarn.resourcemanager.ha.automatic-failover.enabled
Handling deprecation for mapreduce.job.userlog.retain.hours
Handling deprecation for mapreduce.jobhistory.joblist.cache.size
Handling deprecation for dfs.namenode.accesstime.precision
Handling deprecation for yarn.resourcemanager.work-preserving-recovery.enabled
Handling deprecation for dfs.namenode.fs-limits.max-xattrs-per-inode
Handling deprecation for io.mapfile.bloom.error.rate
Handling deprecation for yarn.resourcemanager.store.class
Handling deprecation for dfs.image.transfer.timeout
Handling deprecation for yarn.timeline-service.leveldb-state-store.path
Handling deprecation for nfs.wtmax
Handling deprecation for mapreduce.job.combine.class
Handling deprecation for dfs.namenode.support.allow.format
Handling deprecation for fs.s3a.multipart.purge
Handling deprecation for dfs.secondary.namenode.kerberos.internal.spnego.principal
Handling deprecation for fs.s3a.connection.establish.timeout
Handling deprecation for dfs.stream-buffer-size
Handling deprecation for dfs.namenode.invalidate.work.pct.per.iteration
Handling deprecation for yarn.nodemanager.container-executor.class
Handling deprecation for fs.s3a.multipart.purge.age
Handling deprecation for yarn.resourcemanager.scheduler.client.thread-count
Handling deprecation for dfs.namenode.top.enabled
Handling deprecation for yarn.app.mapreduce.shuffle.log.separate
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.low-watermark
Handling deprecation for fs.s3a.fast.buffer.size
Handling deprecation for hadoop.user.group.static.mapping.overrides
Handling deprecation for tfile.fs.input.buffer.size
Handling deprecation for dfs.client.cached.conn.retry
Handling deprecation for hadoop.http.authentication.type
Handling deprecation for dfs.namenode.list.encryption.zones.num.responses
Handling deprecation for mapreduce.map.cpu.vcores
Handling deprecation for dfs.namenode.path.based.cache.refresh.interval.ms
Handling deprecation for dfs.namenode.decommission.interval
Handling deprecation for dfs.namenode.fs-limits.max-directory-items
Handling deprecation for yarn.resourcemanager.zk-retry-interval-ms
Handling deprecation for ftp.bytes-per-checksum
Handling deprecation for dfs.ha.log-roll.period
Handling deprecation for dfs.user.home.dir.prefix
Handling deprecation for ipc.client.fallback-to-simple-auth-allowed
Handling deprecation for yarn.nodemanager.pmem-check-enabled
Handling deprecation for yarn.nodemanager.remote-app-log-dir
Handling deprecation for dfs.namenode.inotify.max.events.per.rpc
Handling deprecation for mapreduce.task.profile.maps
Handling deprecation for mapreduce.shuffle.ssl.file.buffer.size
Handling deprecation for mapreduce.tasktracker.healthchecker.script.timeout
Handling deprecation for yarn.timeline-service.webapp.https.address
Handling deprecation for yarn.nodemanager.resource.percentage-physical-cpu-limit
Handling deprecation for yarn.app.mapreduce.am.command-opts
Handling deprecation for dfs.namenode.fs-limits.max-xattr-size
Handling deprecation for dfs.datanode.http.address
Handling deprecation for dfs.namenode.blocks.per.postponedblocks.rescan
Handling deprecation for yarn.sharedcache.nm.uploader.replication.factor
Handling deprecation for hadoop.registry.zk.root
Handling deprecation for hadoop.jetty.logs.serve.aliases
Handling deprecation for yarn.client.failover-proxy-provider
Handling deprecation for mapreduce.jobhistory.admin.acl
Handling deprecation for yarn.app.mapreduce.am.hard-kill-timeout-ms
Handling deprecation for yarn.nodemanager.remote-app-log-dir-suffix
Handling deprecation for mapreduce.jobhistory.principal
Handling deprecation for yarn.resourcemanager.webapp.address
Handling deprecation for mapreduce.jobhistory.recovery.enable
Handling deprecation for yarn.sharedcache.store.in-memory.check-period-mins
Handling deprecation for nfs.mountd.port
Handling deprecation for mapreduce.reduce.merge.inmem.threshold
Handling deprecation for fs.df.interval
Handling deprecation for yarn.timeline-service.enabled
Handling deprecation for mapreduce.jobtracker.jobhistory.lru.cache.size
Handling deprecation for mapreduce.task.profile
Handling deprecation for mapreduce.job.output.key.class
Handling deprecation for yarn.nodemanager.hostname
Handling deprecation for dfs.namenode.num.checkpoints.retained
Handling deprecation for mapreduce.job.queuename
Handling deprecation for mapreduce.jobhistory.max-age-ms
Handling deprecation for mapreduce.job.token.tracking.ids.enabled
Handling deprecation for yarn.nodemanager.localizer.client.thread-count
Handling deprecation for yarn.sharedcache.uploader.server.thread-count
Handling deprecation for dfs.client.mmap.retry.timeout.ms
Handling deprecation for mapreduce.jobhistory.move.thread-count
Handling deprecation for dfs.permissions.enabled
Handling deprecation for dfs.blockreport.split.threshold
Handling deprecation for fs.AbstractFileSystem.hdfs.impl
Handling deprecation for dfs.datanode.balance.bandwidthPerSec
Handling deprecation for dfs.block.scanner.volume.bytes.per.second
Handling deprecation for hadoop.http.filter.initializers
Handling deprecation for yarn.timeline-service.http-authentication.simple.anonymous.allowed
Handling deprecation for dfs.default.chunk.view.size
Handling deprecation for yarn.sharedcache.client-server.thread-count
Handling deprecation for yarn.resourcemanager.resource-tracker.address
Handling deprecation for mapreduce.job.working.dir
Handling deprecation for mapreduce.jobhistory.datestring.cache.size
Handling deprecation for mapreduce.task.profile.params
Handling deprecation for dfs.namenode.decommission.blocks.per.interval
Handling deprecation for dfs.namenode.handler.count
Handling deprecation for dfs.image.transfer.bandwidthPerSec
Handling deprecation for rpc.metrics.quantile.enable
Handling deprecation for mapreduce.jobtracker.expire.trackers.interval
Handling deprecation for mapreduce.task.timeout
Handling deprecation for yarn.app.mapreduce.client.max-retries
Handling deprecation for yarn.nodemanager.resource.memory-mb
Handling deprecation for yarn.nodemanager.disk-health-checker.min-healthy-disks
Handling deprecation for dfs.datanode.failed.volumes.tolerated
Handling deprecation for yarn.timeline-service.handler-thread-count
Handling deprecation for ipc.server.listen.queue.size
Handling deprecation for fs.s3a.threads.max
Handling deprecation for yarn.resourcemanager.connect.max-wait.ms
Handling deprecation for mapreduce.fileoutputcommitter.algorithm.version
Handling deprecation for mapreduce.framework.name
Handling deprecation for mapreduce.map.skip.proc.count.autoincr
Handling deprecation for mapreduce.job.max.split.locations
Handling deprecation for yarn.resourcemanager.scheduler.class
Handling deprecation for yarn.resourcemanager.system-metrics-publisher.enabled
Handling deprecation for dfs.blocksize
Handling deprecation for yarn.sharedcache.nested-level
Handling deprecation for mapreduce.shuffle.connection-keep-alive.enable
Handling deprecation for fs.s3a.threads.keepalivetime
Handling deprecation for fs.s3a.connection.timeout
Handling deprecation for file.client-write-packet-size
Handling deprecation for ha.failover-controller.cli-check.rpc-timeout.ms
Handling deprecation for ha.zookeeper.acl
Handling deprecation for dfs.namenode.write.stale.datanode.ratio
Handling deprecation for dfs.encrypt.data.transfer
Handling deprecation for dfs.datanode.shared.file.descriptor.paths
Handling deprecation for mapreduce.input.lineinputformat.linespermap
Handling deprecation for yarn.resourcemanager.delayed.delegation-token.removal-interval-ms
Handling deprecation for yarn.nodemanager.localizer.fetch.thread-count
Handling deprecation for dfs.client.failover.max.attempts
Handling deprecation for yarn.resourcemanager.scheduler.address
Handling deprecation for dfs.client.read.shortcircuit.streams.cache.expiry.ms
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.start-time-write-cache-size
Handling deprecation for yarn.nodemanager.health-checker.script.timeout-ms
Handling deprecation for yarn.resourcemanager.fs.state-store.num-retries
Handling deprecation for hadoop.ssl.require.client.cert
Handling deprecation for hadoop.security.uid.cache.secs
Handling deprecation for mapreduce.jobhistory.keytab
Handling deprecation for dfs.client.read.shortcircuit.skip.checksum
Handling deprecation for yarn.resourcemanager.ha.automatic-failover.zk-base-path
Handling deprecation for mapreduce.shuffle.ssl.enabled
Handling deprecation for mapreduce.reduce.log.level
Handling deprecation for hadoop.registry.rm.enabled
Handling deprecation for mapreduce.tasktracker.dns.interface
Handling deprecation for yarn.resourcemanager.system-metrics-publisher.dispatcher.pool-size
Handling deprecation for mapreduce.job.speculative.speculative-cap-running-tasks
Handling deprecation for dfs.datanode.block.id.layout.upgrade.threads
Handling deprecation for dfs.datanode.use.datanode.hostname
Handling deprecation for dfs.client.context
Handling deprecation for yarn.resourcemanager.ha.enabled
Handling deprecation for mapred.reducer.new-api
Handling deprecation for dfs.namenode.delegation.token.renew-interval
Handling deprecation for dfs.blockreport.intervalMsec
Handling deprecation for fs.s3a.multipart.threshold
Handling deprecation for mapreduce.reduce.shuffle.memory.limit.percent
Handling deprecation for dfs.https.server.keystore.resource
Handling deprecation for io.map.index.skip
Handling deprecation for mapreduce.job.hdfs-servers
Handling deprecation for mapreduce.jobtracker.taskscheduler
Handling deprecation for dfs.namenode.kerberos.internal.spnego.principal
Handling deprecation for yarn.resourcemanager.state-store.max-completed-applications
Handling deprecation for mapreduce.map.output.compress
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.num.refill.threads
Handling deprecation for fs.s3n.multipart.uploads.block.size
Handling deprecation for mapreduce.task.merge.progress.records
Handling deprecation for dfs.datanode.dns.interface
Handling deprecation for map.sort.class
Handling deprecation for yarn.nodemanager.aux-services.mapreduce_shuffle.class
Handling deprecation for tfile.fs.output.buffer.size
Handling deprecation for fs.du.interval
Handling deprecation for dfs.client.failover.connection.retries
Handling deprecation for dfs.namenode.top.window.num.buckets
Handling deprecation for mapreduce.job.dir
Handling deprecation for fs.s3a.buffer.dir
Handling deprecation for mapreduce.reduce.shuffle.retry-delay.max.ms
Handling deprecation for yarn.sharedcache.uploader.server.address
Handling deprecation for mapreduce.client.progressmonitor.pollinterval
Handling deprecation for yarn.app.mapreduce.shuffle.log.limit.kb
Handling deprecation for dfs.datanode.max.locked.memory
Handling deprecation for dfs.namenode.retrycache.expirytime.millis
Handling deprecation for dfs.datanode.scan.period.hours
Handling deprecation for dfs.client.block.write.replace-datanode-on-failure.best-effort
Handling deprecation for mapreduce.jobhistory.move.interval-ms
Handling deprecation for dfs.ha.fencing.ssh.connect-timeout
Handling deprecation for yarn.nodemanager.log-aggregation.roll-monitoring-interval-seconds
Handling deprecation for dfs.namenode.fs-limits.max-component-length
Handling deprecation for hadoop.registry.zk.quorum
Handling deprecation for dfs.namenode.enable.retrycache
Handling deprecation for dfs.datanode.du.reserved
Handling deprecation for yarn.timeline-service.state-store-class
Handling deprecation for dfs.datanode.ipc.address
Handling deprecation for hadoop.registry.system.acls
Handling deprecation for dfs.client.block.write.replace-datanode-on-failure.policy
Handling deprecation for dfs.namenode.path.based.cache.retry.interval.ms
Handling deprecation for hadoop.security.crypto.cipher.suite
Handling deprecation for dfs.ha.tail-edits.period
Handling deprecation for mapreduce.task.profile.reduce.params
Handling deprecation for hadoop.registry.jaas.context
Handling deprecation for yarn.resourcemanager.hostname
Handling deprecation for mapreduce.reduce.memory.mb
Handling deprecation for hadoop.security.group.mapping.ldap.search.filter.group
Handling deprecation for hadoop.http.authentication.kerberos.principal
Handling deprecation for hadoop.security.group.mapping.ldap.search.filter.user
Handling deprecation for yarn.nodemanager.disk-health-checker.min-free-space-per-disk-mb
Handling deprecation for dfs.namenode.edits.dir
Handling deprecation for yarn.client.failover-retries-on-socket-timeouts
Handling deprecation for dfs.namenode.decommission.max.concurrent.tracked.nodes
Handling deprecation for mapreduce.client.completion.pollinterval
Handling deprecation for dfs.namenode.name.dir.restore
Handling deprecation for dfs.namenode.secondary.http-address
Handling deprecation for mapreduce.jobhistory.recovery.store.leveldb.path
Handling deprecation for yarn.sharedcache.store.class
Handling deprecation for s3.bytes-per-checksum
Handling deprecation for yarn.nodemanager.windows-container.cpu-limit.enabled
Handling deprecation for yarn.resourcemanager.webapp.https.address
Handling deprecation for yarn.nodemanager.vmem-pmem-ratio
Handling deprecation for dfs.namenode.checkpoint.period
Handling deprecation for dfs.ha.automatic-failover.enabled
The url to track the job: http://localhost:8080/
Running job: job_local1723068883_0001
OutputCommitter set in config null
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
File Output Committer Algorithm version is 1
OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
/user/michaeljones/wcOutput/_temporary/0: masked=rwxr-xr-x
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #12
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #12
Call: mkdirs took 21ms
Starting mapper thread pool executor.
Max local threads: 1
Map tasks to process: 1
Waiting for map tasks
Starting task: attempt_local1723068883_0001_m_000000_0
currentIndex 0   0:0
mapreduce.cluster.local.dir for child : /tmp/hadoop-michaeljones/mapred/local/localRunner//michaeljones/jobcache/job_local1723068883_0001/attempt_local1723068883_0001_m_000000_0
using new api for output committer
File Output Committer Algorithm version is 1
ProcfsBasedProcessTree currently is supported only on Linux.
 Using ResourceCalculatorProcessTree : null
Processing split: hdfs://localhost:9000/user/michaeljones/wcInput:0+50
Trying map output collector class: org.apache.hadoop.mapred.MapTask$MapOutputBuffer
(EQUATOR) 0 kvi 26214396(104857584)
mapreduce.task.io.sort.mb: 100
soft limit at 83886080
bufstart = 0; bufvoid = 104857600
kvstart = 26214396; length = 6553600
Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #13
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #13
Call: getBlockLocations took 4ms
newInfo = LocatedBlocks{
  fileLength=50
  underConstruction=false
  blocks=[LocatedBlock{BP-1045030256-10.0.0.2-1433119149314:blk_1073741825_1002; getBlockSize()=50; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-b42c5705-9ba4-4b14-b00b-f9194bb036f0,DISK]]}]
  lastLocatedBlock=LocatedBlock{BP-1045030256-10.0.0.2-1433119149314:blk_1073741825_1002; getBlockSize()=50; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-b42c5705-9ba4-4b14-b00b-f9194bb036f0,DISK]]}
  isLastBlockComplete=true}
Connecting to datanode 127.0.0.1:50010

Starting flush of map output
Spilling map output
bufstart = 0; bufend = 82; bufvoid = 104857600
kvstart = 26214396(104857584); kvend = 26214368(104857472); length = 29/6553600
Finished spill 0
Task:attempt_local1723068883_0001_m_000000_0 is done. And is in the process of committing
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #14
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #14
Call: getFileInfo took 3ms
map
Task 'attempt_local1723068883_0001_m_000000_0' done.
Finishing task: attempt_local1723068883_0001_m_000000_0
map task executor complete.
Starting reduce thread pool executor.
Max local threads: 1
Reduce tasks to process: 1
Waiting for reduce tasks
Starting task: attempt_local1723068883_0001_r_000000_0
currentIndex 0   0:0
mapreduce.cluster.local.dir for child : /tmp/hadoop-michaeljones/mapred/local/localRunner//michaeljones/jobcache/job_local1723068883_0001/attempt_local1723068883_0001_r_000000_0
using new api for output committer
File Output Committer Algorithm version is 1
ProcfsBasedProcessTree currently is supported only on Linux.
 Using ResourceCalculatorProcessTree : null
Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@168a2d37
MergerManager: memoryLimit=668309888, maxSingleShuffleLimit=167077472, mergeThreshold=441084544, ioSortFactor=10, memToMemMergeOutputsThreshold=10
attempt_local1723068883_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
Got 0 map completion events from 0
GetMapEventsThread about to sleep for 1000
LocalFetcher 1 going to fetch: attempt_local1723068883_0001_m_000000_0
attempt_local1723068883_0001_m_000000_0: Proceeding with shuffle since usedMemory (0) is lesser than memoryLimit (668309888).CommitMemory is (0)
localfetcher#1 about to shuffle output of map attempt_local1723068883_0001_m_000000_0 decomp: 63 len: 67 to MEMORY
Read 63 bytes from map-output for attempt_local1723068883_0001_m_000000_0
closeInMemoryFile -> map-output of size: 63, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->63
map attempt_local1723068883_0001_m_000000_0 done 1 / 1 copied.
EventFetcher is interrupted.. Returning
1 / 1 copied.
finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
Merging 1 sorted segments
Down to the last merge-pass, with 1 segments left of total size: 57 bytes
Merged 1 segments, 63 bytes to disk to satisfy reduce memory limit
Disk file: /tmp/hadoop-michaeljones/mapred/local/localRunner/michaeljones/jobcache/job_local1723068883_0001/attempt_local1723068883_0001_r_000000_0/output/map_0.out.merged Length is 67
Merging 1 files, 67 bytes from disk
Merging 0 segments, 0 bytes from memory into reduce
Merging 1 sorted segments
Down to the last merge-pass, with 1 segments left of total size: 57 bytes
1 / 1 copied.
/user/michaeljones/wcOutput/_temporary/0/_temporary/attempt_local1723068883_0001_r_000000_0/part-r-00000: masked=rw-r--r--
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #15
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #15
Call: create took 5ms
computePacketChunkSize: src=/user/michaeljones/wcOutput/_temporary/0/_temporary/attempt_local1723068883_0001_r_000000_0/part-r-00000, chunkSize=516, chunksPerPacket=126, packetSize=65016
mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
DFSClient writeChunk allocating new packet seqno=0, src=/user/michaeljones/wcOutput/_temporary/0/_temporary/attempt_local1723068883_0001_r_000000_0/part-r-00000, packetSize=65016, chunksPerPacket=126, bytesCurBlock=0
Queued packet 0
Queued packet 1
Waiting for ack for: 1
Allocating new block
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #16
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #16
Call: addBlock took 4ms
pipeline = DatanodeInfoWithStorage[127.0.0.1:50010,DS-b42c5705-9ba4-4b14-b00b-f9194bb036f0,DISK]
Connecting to datanode 127.0.0.1:50010
Send buf size 131072
SASL client skipping handshake in unsecured configuration for addr = /127.0.0.1, datanodeId = DatanodeInfoWithStorage[127.0.0.1:50010,DS-b42c5705-9ba4-4b14-b00b-f9194bb036f0,DISK]
DataStreamer block BP-1045030256-10.0.0.2-1433119149314:blk_1073742291_1468 sending packet packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 41
DFSClient seqno: 0 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
DataStreamer block BP-1045030256-10.0.0.2-1433119149314:blk_1073742291_1468 sending packet packet seqno: 1 offsetInBlock: 41 lastPacketInBlock: true lastByteOffsetInBlock: 41
DFSClient seqno: 1 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
Closing old block BP-1045030256-10.0.0.2-1433119149314:blk_1073742291_1468
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #17
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #17
Call: complete took 5ms
Task:attempt_local1723068883_0001_r_000000_0 is done. And is in the process of committing
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #18
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #18
Call: getFileInfo took 3ms
1 / 1 copied.
Task attempt_local1723068883_0001_r_000000_0 is allowed to commit now
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #19
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #19
Call: getFileInfo took 2ms
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #20
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #20
Call: getFileInfo took 3ms
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #21
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #21
Call: rename took 28ms
Saved output of task 'attempt_local1723068883_0001_r_000000_0' to hdfs://localhost:9000/user/michaeljones/wcOutput/_temporary/0/task_local1723068883_0001_r_000000
reduce > reduce
Task 'attempt_local1723068883_0001_r_000000_0' done.
Finishing task: attempt_local1723068883_0001_r_000000_0
reduce task executor complete.
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #22
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #22
Call: getListing took 3ms
Merging data from FileStatus{path=hdfs://localhost:9000/user/michaeljones/wcOutput/_temporary/0/task_local1723068883_0001_r_000000; isDirectory=true; modification_time=1434180760109; access_time=0; owner=michaeljones; group=supergroup; permission=rwxr-xr-x; isSymlink=false} to hdfs://localhost:9000/user/michaeljones/wcOutput
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #23
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #23
Call: getFileInfo took 3ms
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #24
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #24
Call: getListing took 2ms
Merging data from FileStatus{path=hdfs://localhost:9000/user/michaeljones/wcOutput/_temporary/0/task_local1723068883_0001_r_000000/part-r-00000; isDirectory=false; length=41; replication=1; blocksize=134217728; modification_time=1434180760153; access_time=1434180760109; owner=michaeljones; group=supergroup; permission=rw-r--r--; isSymlink=false} to hdfs://localhost:9000/user/michaeljones/wcOutput/part-r-00000
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #25
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #25
Call: getFileInfo took 2ms
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #26
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #26
Call: rename took 3ms
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #27
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #27
Call: delete took 2ms
/user/michaeljones/wcOutput/_SUCCESS: masked=rw-r--r--
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #28
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #28
Call: create took 3ms
computePacketChunkSize: src=/user/michaeljones/wcOutput/_SUCCESS, chunkSize=516, chunksPerPacket=126, packetSize=65016
Waiting for ack for: -1
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #29
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #29
Call: complete took 5ms
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.fs.FileContext.getAbstractFileSystem(FileContext.java:331)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
Job job_local1723068883_0001 running in uber mode : false
 map 100% reduce 100%
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.getTaskCompletionEvents(Job.java:670)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.getTaskCompletionEvents(Job.java:670)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
Job job_local1723068883_0001 completed successfully
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.getCounters(Job.java:758)
Counters: 35
	File System Counters
		FILE: Number of bytes read=520
		FILE: Number of bytes written=565651
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=140
		HDFS: Number of bytes written=81
		HDFS: Number of read operations=19
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=10
	Map-Reduce Framework
		Map input records=2
		Map output records=8
		Map output bytes=82
		Map output materialized bytes=67
		Input split bytes=112
		Combine input records=8
		Combine output records=5
		Reduce input groups=5
		Reduce shuffle bytes=67
		Reduce input records=5
		Reduce output records=5
		Spilled Records=10
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=25
		Total committed heap usage (bytes)=478150656
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=50
	File Output Format Counters 
		Bytes Written=41
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
RunJobAnalysisAsync
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #30
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #30
Call: getFileInfo took 4ms
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #31
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #31
Call: delete took 4ms
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.connect(Job.java:1256)
Trying ClientProtocolProvider : org.apache.hadoop.mapred.LocalClientProtocolProvider
Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
Picked org.apache.hadoop.mapred.LocalClientProtocolProvider as the ClientProtocolProvider
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Cluster.getFileSystem(Cluster.java:162)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.submit(Job.java:1287)
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #32
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #32
Call: getFileInfo took 2ms
Configuring job job_local502431174_0002 with file:/tmp/hadoop-michaeljones/mapred/staging/michaeljones502431174/.staging/job_local502431174_0002 as the submit dir
adding the following namenodes' delegation tokens:[hdfs://localhost:9000]
Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
default FileSystem: file:///
No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
Creating splits at file:/tmp/hadoop-michaeljones/mapred/staging/michaeljones502431174/.staging/job_local502431174_0002
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #33
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #33
Call: getFileInfo took 3ms
Time taken to get FileStatuses: 5
Total input paths to process : 1
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #34
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #34
Call: getBlockLocations took 4ms
Total # of splits generated by getSplits: 1, TimeTaken: 11
number of splits:1
Handling deprecation for all properties in config...
Handling deprecation for mapreduce.jobtracker.address
Handling deprecation for yarn.resourcemanager.scheduler.monitor.policies
Handling deprecation for dfs.namenode.resource.check.interval
Handling deprecation for mapreduce.jobhistory.client.thread-count
Handling deprecation for yarn.app.mapreduce.am.containerlauncher.threadpool-initial-size
Handling deprecation for mapred.child.java.opts
Handling deprecation for mapreduce.jobtracker.retiredjobs.cache.size
Handling deprecation for dfs.client.https.need-auth
Handling deprecation for yarn.admin.acl
Handling deprecation for yarn.app.mapreduce.am.job.committer.cancel-timeout
Handling deprecation for mapreduce.job.emit-timeline-data
Handling deprecation for fs.ftp.host.port
Handling deprecation for dfs.namenode.avoid.read.stale.datanode
Handling deprecation for dfs.journalnode.rpc-address
Handling deprecation for mapreduce.job.end-notification.retry.attempts
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.ttl-interval-ms
Handling deprecation for yarn.resourcemanager.leveldb-state-store.path
Handling deprecation for mapred.mapper.new-api
Handling deprecation for yarn.ipc.rpc.class
Handling deprecation for ipc.client.connection.maxidletime
Handling deprecation for yarn.nodemanager.process-kill-wait.ms
Handling deprecation for mapreduce.cluster.acls.enabled
Handling deprecation for mapreduce.jobtracker.handler.count
Handling deprecation for io.map.index.interval
Handling deprecation for dfs.namenode.https-address
Handling deprecation for mapreduce.task.profile.reduces
Handling deprecation for fs.s3n.multipart.uploads.enabled
Handling deprecation for io.seqfile.sorter.recordlimit
Handling deprecation for mapreduce.job.ubertask.maxmaps
Handling deprecation for mapreduce.tasktracker.tasks.sleeptimebeforesigkill
Handling deprecation for hadoop.util.hash.type
Handling deprecation for dfs.namenode.replication.min
Handling deprecation for yarn.nodemanager.container-manager.thread-count
Handling deprecation for mapreduce.jobtracker.jobhistory.block.size
Handling deprecation for dfs.namenode.fs-limits.min-block-size
Handling deprecation for mapreduce.app-submission.cross-platform
Handling deprecation for fs.AbstractFileSystem.file.impl
Handling deprecation for net.topology.script.number.args
Handling deprecation for yarn.resourcemanager.container-tokens.master-key-rolling-interval-secs
Handling deprecation for mapreduce.map.output.compress.codec
Handling deprecation for mapreduce.job.reducer.preempt.delay.sec
Handling deprecation for s3native.bytes-per-checksum
Handling deprecation for dfs.namenode.path.based.cache.block.map.allocation.percent
Handling deprecation for yarn.nodemanager.windows-container.memory-limit.enabled
Handling deprecation for mapreduce.input.fileinputformat.split.minsize
Handling deprecation for hadoop.security.group.mapping
Handling deprecation for mapreduce.jobtracker.system.dir
Handling deprecation for mapreduce.job.end-notification.max.attempts
Handling deprecation for mapreduce.reduce.markreset.buffer.percent
Handling deprecation for dfs.datanode.cache.revocation.polling.ms
Handling deprecation for mapreduce.reduce.speculative
Handling deprecation for yarn.nodemanager.localizer.cache.cleanup.interval-ms
Handling deprecation for dfs.namenode.lazypersist.file.scrub.interval.sec
Handling deprecation for fs.s3a.threads.core
Handling deprecation for mapreduce.jobhistory.recovery.store.fs.uri
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.start-time-read-cache-size
Handling deprecation for hadoop.registry.zk.retry.interval.ms
Handling deprecation for yarn.nodemanager.keytab
Handling deprecation for dfs.namenode.replication.interval
Handling deprecation for yarn.resourcemanager.admin.address
Handling deprecation for mapreduce.job.maps
Handling deprecation for nfs.dump.dir
Handling deprecation for mapreduce.job.user.name
Handling deprecation for mapreduce.jobtracker.maxtasks.perjob
Handling deprecation for mapreduce.job.ubertask.enable
Handling deprecation for mapreduce.job.reduce.class
Handling deprecation for yarn.nodemanager.delete.debug-delay-sec
Handling deprecation for yarn.timeline-service.ttl-enable
Handling deprecation for yarn.resourcemanager.fs.state-store.retry-policy-spec
Handling deprecation for mapreduce.reduce.skip.maxgroups
Handling deprecation for dfs.client.use.datanode.hostname
Handling deprecation for fs.trash.interval
Handling deprecation for mapreduce.job.name
Handling deprecation for mapreduce.am.max-attempts
Handling deprecation for mapreduce.jobtracker.heartbeats.in.second
Handling deprecation for yarn.resourcemanager.zk-num-retries
Handling deprecation for s3.blocksize
Handling deprecation for dfs.datanode.data.dir
Handling deprecation for mapreduce.jobtracker.persist.jobstatus.active
Handling deprecation for mapreduce.reduce.shuffle.parallelcopies
Handling deprecation for fs.s3.buffer.dir
Handling deprecation for mapreduce.jobhistory.done-dir
Handling deprecation for hadoop.security.instrumentation.requires.admin
Handling deprecation for hadoop.registry.zk.retry.ceiling.ms
Handling deprecation for nfs.rtmax
Handling deprecation for dfs.datanode.data.dir.perm
Handling deprecation for yarn.resourcemanager.container.liveness-monitor.interval-ms
Handling deprecation for yarn.nodemanager.env-whitelist
Handling deprecation for dfs.namenode.backup.address
Handling deprecation for dfs.namenode.xattrs.enabled
Handling deprecation for dfs.datanode.readahead.bytes
Handling deprecation for mapreduce.jobhistory.cleaner.enable
Handling deprecation for dfs.client.block.write.retries
Handling deprecation for mapreduce.tasktracker.http.address
Handling deprecation for yarn.nodemanager.linux-container-executor.cgroups.hierarchy
Handling deprecation for ha.failover-controller.graceful-fence.connection.retries
Handling deprecation for yarn.resourcemanager.recovery.enabled
Handling deprecation for yarn.app.mapreduce.am.container.log.backups
Handling deprecation for dfs.namenode.safemode.threshold-pct
Handling deprecation for yarn.nodemanager.disk-health-checker.interval-ms
Handling deprecation for hadoop.security.java.secure.random.algorithm
Handling deprecation for dfs.namenode.list.cache.directives.num.responses
Handling deprecation for dfs.datanode.dns.nameserver
Handling deprecation for mapreduce.cluster.temp.dir
Handling deprecation for fs.s3a.max.total.tasks
Handling deprecation for mapreduce.reduce.maxattempts
Handling deprecation for mapreduce.client.submit.file.replication
Handling deprecation for mapreduce.shuffle.port
Handling deprecation for yarn.resourcemanager.resource-tracker.client.thread-count
Handling deprecation for dfs.namenode.replication.considerLoad
Handling deprecation for dfs.namenode.edits.journal-plugin.qjournal
Handling deprecation for dfs.client.write.exclude.nodes.cache.expiry.interval.millis
Handling deprecation for yarn.nodemanager.delete.thread-count
Handling deprecation for dfs.client.mmap.cache.timeout.ms
Handling deprecation for yarn.nodemanager.admin-env
Handling deprecation for io.skip.checksum.errors
Handling deprecation for yarn.timeline-service.hostname
Handling deprecation for yarn.resourcemanager.proxy-user-privileges.enabled
Handling deprecation for mapreduce.job.speculative.speculative-cap-total-tasks
Handling deprecation for yarn.acl.enable
Handling deprecation for fs.s3a.fast.upload
Handling deprecation for file.blocksize
Handling deprecation for mapreduce.job.speculative.slowtaskthreshold
Handling deprecation for ftp.replication
Handling deprecation for yarn.sharedcache.cleaner.initial-delay-mins
Handling deprecation for s3native.client-write-packet-size
Handling deprecation for hadoop.rpc.socket.factory.class.default
Handling deprecation for file.bytes-per-checksum
Handling deprecation for dfs.datanode.slow.io.warning.threshold.ms
Handling deprecation for io.seqfile.lazydecompress
Handling deprecation for mapreduce.task.skip.start.attempts
Handling deprecation for dfs.namenode.reject-unresolved-dn-topology-mapping
Handling deprecation for hadoop.common.configuration.version
Handling deprecation for yarn.resourcemanager.client.thread-count
Handling deprecation for dfs.datanode.drop.cache.behind.reads
Handling deprecation for yarn.sharedcache.admin.address
Handling deprecation for mapreduce.job.output.value.class
Handling deprecation for mapreduce.output.fileoutputformat.outputdir
Handling deprecation for mapreduce.jobtracker.taskcache.levels
Handling deprecation for yarn.nodemanager.linux-container-executor.nonsecure-mode.user-pattern
Handling deprecation for yarn.resourcemanager.zk-timeout-ms
Handling deprecation for yarn.resourcemanager.max-completed-applications
Handling deprecation for mapreduce.job.jvm.numtasks
Handling deprecation for yarn.sharedcache.cleaner.period-mins
Handling deprecation for mapreduce.jobtracker.tasktracker.maxblacklists
Handling deprecation for dfs.namenode.top.num.users
Handling deprecation for yarn.nodemanager.linux-container-executor.cgroups.mount
Handling deprecation for yarn.sharedcache.checksum.algo.impl
Handling deprecation for mapreduce.job.end-notification.max.retry.interval
Handling deprecation for mapreduce.job.acl-view-job
Handling deprecation for mapreduce.job.classloader
Handling deprecation for yarn.log-aggregation-enable
Handling deprecation for mapreduce.reduce.shuffle.fetch.retry.interval-ms
Handling deprecation for yarn.resourcemanager.nodemanager.minimum.version
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.size
Handling deprecation for yarn.app.mapreduce.am.job.task.listener.thread-count
Handling deprecation for yarn.app.mapreduce.am.resource.cpu-vcores
Handling deprecation for dfs.namenode.edit.log.autoroll.check.interval.ms
Handling deprecation for mapreduce.output.fileoutputformat.compress.type
Handling deprecation for hadoop.hdfs.configuration.version
Handling deprecation for hadoop.security.group.mapping.ldap.search.attr.member
Handling deprecation for yarn.nodemanager.log.retain-seconds
Handling deprecation for yarn.nodemanager.local-cache.max-files-per-directory
Handling deprecation for mapreduce.job.end-notification.retry.interval
Handling deprecation for hadoop.ssl.client.conf
Handling deprecation for yarn.sharedcache.root-dir
Handling deprecation for dfs.journalnode.https-address
Handling deprecation for mapreduce.reduce.shuffle.fetch.retry.timeout-ms
Handling deprecation for dfs.bytes-per-checksum
Handling deprecation for dfs.namenode.max.objects
Handling deprecation for mapreduce.tasktracker.instrumentation
Handling deprecation for dfs.datanode.max.transfer.threads
Handling deprecation for dfs.block.access.key.update.interval
Handling deprecation for mapreduce.jobtracker.jobhistory.task.numberprogresssplits
Handling deprecation for mapreduce.map.memory.mb
Handling deprecation for ha.failover-controller.new-active.rpc-timeout.ms
Handling deprecation for hadoop.ssl.hostname.verifier
Handling deprecation for dfs.client.read.shortcircuit
Handling deprecation for dfs.datanode.hdfs-blocks-metadata.enabled
Handling deprecation for mapreduce.tasktracker.healthchecker.interval
Handling deprecation for dfs.image.transfer.chunksize
Handling deprecation for mapreduce.tasktracker.taskmemorymanager.monitoringinterval
Handling deprecation for dfs.client.https.keystore.resource
Handling deprecation for yarn.resourcemanager.connect.retry-interval.ms
Handling deprecation for yarn.timeline-service.webapp.address
Handling deprecation for s3native.blocksize
Handling deprecation for yarn.scheduler.minimum-allocation-mb
Handling deprecation for yarn.sharedcache.cleaner.resource-sleep-ms
Handling deprecation for net.topology.impl
Handling deprecation for dfs.client.failover.sleep.base.millis
Handling deprecation for dfs.permissions.superusergroup
Handling deprecation for io.seqfile.compress.blocksize
Handling deprecation for hadoop.registry.zk.retry.times
Handling deprecation for fs.AbstractFileSystem.ftp.impl
Handling deprecation for dfs.namenode.checkpoint.edits.dir
Handling deprecation for mapreduce.job.running.reduce.limit
Handling deprecation for dfs.blockreport.initialDelay
Handling deprecation for dfs.namenode.heartbeat.recheck-interval
Handling deprecation for dfs.namenode.safemode.extension
Handling deprecation for yarn.scheduler.maximum-allocation-mb
Handling deprecation for mapreduce.job.reduce.shuffle.consumer.plugin.class
Handling deprecation for yarn.nodemanager.vmem-check-enabled
Handling deprecation for mapreduce.task.io.sort.factor
Handling deprecation for mapreduce.jobtracker.persist.jobstatus.dir
Handling deprecation for dfs.client.failover.sleep.max.millis
Handling deprecation for dfs.namenode.delegation.key.update-interval
Handling deprecation for hadoop.rpc.protection
Handling deprecation for fs.permissions.umask-mode
Handling deprecation for fs.s3.sleepTimeSeconds
Handling deprecation for ha.health-monitor.rpc-timeout.ms
Handling deprecation for hadoop.http.staticuser.user
Handling deprecation for fs.s3a.connection.maximum
Handling deprecation for yarn.nodemanager.linux-container-executor.nonsecure-mode.limit-users
Handling deprecation for fs.s3a.paging.maximum
Handling deprecation for fs.AbstractFileSystem.viewfs.impl
Handling deprecation for fs.ftp.host
Handling deprecation for yarn.nodemanager.linux-container-executor.nonsecure-mode.local-user
Handling deprecation for fs.s3a.impl
Handling deprecation for hadoop.http.authentication.kerberos.keytab
Handling deprecation for dfs.namenode.fs-limits.max-blocks-per-file
Handling deprecation for mapreduce.tasktracker.http.threads
Handling deprecation for mapreduce.tasktracker.dns.nameserver
Handling deprecation for yarn.resourcemanager.am-rm-tokens.master-key-rolling-interval-secs
Handling deprecation for dfs.client.block.write.replace-datanode-on-failure.enable
Handling deprecation for io.compression.codec.bzip2.library
Handling deprecation for mapreduce.map.skip.maxrecords
Handling deprecation for dfs.client.use.legacy.blockreader.local
Handling deprecation for dfs.namenode.checkpoint.dir
Handling deprecation for dfs.namenode.top.windows.minutes
Handling deprecation for mapreduce.job.maxtaskfailures.per.tracker
Handling deprecation for net.topology.node.switch.mapping.impl
Handling deprecation for mapreduce.shuffle.max.connections
Handling deprecation for mapreduce.jobhistory.loadedjobs.cache.size
Handling deprecation for dfs.storage.policy.enabled
Handling deprecation for yarn.client.application-client-protocol.poll-interval-ms
Handling deprecation for yarn.nodemanager.localizer.address
Handling deprecation for dfs.namenode.list.cache.pools.num.responses
Handling deprecation for nfs.server.port
Handling deprecation for mapreduce.client.output.filter
Handling deprecation for yarn.timeline-service.client.best-effort
Handling deprecation for ha.zookeeper.parent-znode
Handling deprecation for mapreduce.jobtracker.persist.jobstatus.hours
Handling deprecation for yarn.sharedcache.admin.thread-count
Handling deprecation for yarn.nodemanager.resource.cpu-vcores
Handling deprecation for dfs.datanode.block-pinning.enabled
Handling deprecation for mapreduce.jobhistory.http.policy
Handling deprecation for yarn.resourcemanager.webapp.delegation-token-auth-filter.enabled
Handling deprecation for mapreduce.job.speculative.retry-after-no-speculate
Handling deprecation for fs.s3a.attempts.maximum
Handling deprecation for s3native.stream-buffer-size
Handling deprecation for io.seqfile.local.dir
Handling deprecation for yarn.log-aggregation.retain-check-interval-seconds
Handling deprecation for fs.s3n.multipart.copy.block.size
Handling deprecation for dfs.encrypt.data.transfer.cipher.key.bitlength
Handling deprecation for dfs.datanode.sync.behind.writes
Handling deprecation for yarn.resourcemanager.zk-acl
Handling deprecation for hadoop.ssl.keystores.factory.class
Handling deprecation for mapreduce.job.split.metainfo.maxsize
Handling deprecation for fs.s3.maxRetries
Handling deprecation for hadoop.security.random.device.file.path
Handling deprecation for yarn.client.nodemanager-connect.max-wait-ms
Handling deprecation for dfs.namenode.stale.datanode.interval
Handling deprecation for mapreduce.task.io.sort.mb
Handling deprecation for yarn.resourcemanager.zk-state-store.parent-path
Handling deprecation for yarn.app.mapreduce.client-am.ipc.max-retries
Handling deprecation for fs.client.resolve.remote.symlinks
Handling deprecation for yarn.nodemanager.linux-container-executor.cgroups.strict-resource-usage
Handling deprecation for hadoop.ssl.enabled.protocols
Handling deprecation for mapreduce.reduce.cpu.vcores
Handling deprecation for yarn.client.failover-retries
Handling deprecation for mapreduce.jobhistory.address
Handling deprecation for hadoop.ssl.enabled
Handling deprecation for dfs.replication.max
Handling deprecation for dfs.namenode.name.dir
Handling deprecation for dfs.datanode.https.address
Handling deprecation for ipc.client.kill.max
Handling deprecation for mapreduce.job.committer.setup.cleanup.needed
Handling deprecation for dfs.client.domain.socket.data.traffic
Handling deprecation for yarn.nodemanager.localizer.cache.target-size-mb
Handling deprecation for yarn.resourcemanager.admin.client.thread-count
Handling deprecation for dfs.block.access.token.enable
Handling deprecation for mapreduce.job.speculative.retry-after-speculate
Handling deprecation for dfs.datanode.address
Handling deprecation for mapreduce.jobtracker.restart.recover
Handling deprecation for ipc.client.connect.max.retries
Handling deprecation for yarn.timeline-service.store-class
Handling deprecation for dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
Handling deprecation for hadoop.tmp.dir
Handling deprecation for dfs.datanode.handler.count
Handling deprecation for yarn.resourcemanager.ha.automatic-failover.embedded
Handling deprecation for yarn.timeline-service.ttl-ms
Handling deprecation for mapreduce.task.profile.map.params
Handling deprecation for yarn.resourcemanager.nodemanagers.heartbeat-interval-ms
Handling deprecation for mapreduce.map.speculative
Handling deprecation for yarn.timeline-service.recovery.enabled
Handling deprecation for mapreduce.job.map.class
Handling deprecation for dfs.namenode.resource.checked.volumes.minimum
Handling deprecation for yarn.nodemanager.recovery.dir
Handling deprecation for mapreduce.job.counters.max
Handling deprecation for yarn.resourcemanager.keytab
Handling deprecation for dfs.namenode.max.extra.edits.segments.retained
Handling deprecation for dfs.webhdfs.user.provider.user.pattern
Handling deprecation for dfs.client.mmap.enabled
Handling deprecation for mapreduce.map.log.level
Handling deprecation for dfs.client.file-block-storage-locations.timeout.millis
Handling deprecation for yarn.client.max-cached-nodemanagers-proxies
Handling deprecation for yarn.app.mapreduce.am.scheduler.heartbeat.interval-ms
Handling deprecation for hadoop.fuse.timer.period
Handling deprecation for fs.trash.checkpoint.interval
Handling deprecation for yarn.sharedcache.app-checker.class
Handling deprecation for dfs.journalnode.http-address
Handling deprecation for yarn.app.mapreduce.am.staging-dir
Handling deprecation for mapreduce.tasktracker.local.dir.minspacestart
Handling deprecation for yarn.nm.liveness-monitor.expiry-interval-ms
Handling deprecation for ha.health-monitor.check-interval.ms
Handling deprecation for mapreduce.reduce.shuffle.merge.percent
Handling deprecation for dfs.namenode.retrycache.heap.percent
Handling deprecation for yarn.nodemanager.docker-container-executor.exec-name
Handling deprecation for ipc.client.connect.timeout
Handling deprecation for yarn.resourcemanager.fs.state-store.retry-interval-ms
Handling deprecation for mapreduce.output.fileoutputformat.compress
Handling deprecation for yarn.nodemanager.local-dirs
Handling deprecation for yarn.nodemanager.recovery.enabled
Handling deprecation for io.native.lib.available
Handling deprecation for yarn.sharedcache.store.in-memory.staleness-period-mins
Handling deprecation for yarn.resourcemanager.am.max-attempts
Handling deprecation for s3.replication
Handling deprecation for mapreduce.input.fileinputformat.inputdir
Handling deprecation for fs.AbstractFileSystem.har.impl
Handling deprecation for dfs.image.compress
Handling deprecation for mapreduce.job.running.map.limit
Handling deprecation for mapreduce.reduce.input.buffer.percent
Handling deprecation for yarn.nodemanager.webapp.address
Handling deprecation for dfs.datanode.available-space-volume-choosing-policy.balanced-space-preference-fraction
Handling deprecation for dfs.namenode.edit.log.autoroll.multiplier.threshold
Handling deprecation for hadoop.security.group.mapping.ldap.ssl
Handling deprecation for dfs.namenode.checkpoint.check.period
Handling deprecation for fs.defaultFS
Handling deprecation for fs.s3a.multipart.size
Handling deprecation for dfs.client.slow.io.warning.threshold.ms
Handling deprecation for yarn.app.mapreduce.am.job.committer.commit-window
Handling deprecation for hadoop.security.group.mapping.ldap.search.attr.group.name
Handling deprecation for yarn.nodemanager.disk-health-checker.max-disk-utilization-per-disk-percentage
Handling deprecation for yarn.nodemanager.container-monitor.procfs-tree.smaps-based-rss.enabled
Handling deprecation for mapreduce.job.submithostname
Handling deprecation for mapreduce.map.sort.spill.percent
Handling deprecation for hadoop.security.crypto.codec.classes.aes.ctr.nopadding
Handling deprecation for dfs.namenode.http-address
Handling deprecation for hadoop.security.groups.negative-cache.secs
Handling deprecation for hadoop.ssl.server.conf
Handling deprecation for mapreduce.ifile.readahead
Handling deprecation for s3native.replication
Handling deprecation for yarn.client.nodemanager-client-async.thread-pool-max-size
Handling deprecation for mapreduce.jobtracker.staging.root.dir
Handling deprecation for mapreduce.jobhistory.admin.address
Handling deprecation for dfs.namenode.startup.delay.block.deletion.sec
Handling deprecation for yarn.nodemanager.health-checker.interval-ms
Handling deprecation for dfs.namenode.checkpoint.max-retries
Handling deprecation for s3.stream-buffer-size
Handling deprecation for ftp.client-write-packet-size
Handling deprecation for dfs.datanode.fsdatasetcache.max.threads.per.volume
Handling deprecation for mapreduce.output.fileoutputformat.compress.codec
Handling deprecation for yarn.timeline-service.keytab
Handling deprecation for yarn.sharedcache.store.in-memory.initial-delay-mins
Handling deprecation for mapreduce.jobhistory.webapp.address
Handling deprecation for mapreduce.task.userlog.limit.kb
Handling deprecation for mapreduce.reduce.shuffle.fetch.retry.enabled
Handling deprecation for yarn.app.mapreduce.task.container.log.backups
Handling deprecation for dfs.heartbeat.interval
Handling deprecation for ha.zookeeper.session-timeout.ms
Handling deprecation for fs.s3a.connection.ssl.enabled
Handling deprecation for yarn.sharedcache.webapp.address
Handling deprecation for hadoop.http.authentication.signature.secret.file
Handling deprecation for hadoop.fuse.connection.timeout
Handling deprecation for mapreduce.input.fileinputformat.numinputfiles
Handling deprecation for yarn.nodemanager.log-aggregation.compression-type
Handling deprecation for ipc.server.max.connections
Handling deprecation for yarn.resourcemanager.work-preserving-recovery.scheduling-wait-ms
Handling deprecation for yarn.nodemanager.log-dirs
Handling deprecation for yarn.app.mapreduce.am.resource.mb
Handling deprecation for hadoop.security.groups.cache.secs
Handling deprecation for mapreduce.job.speculative.minimum-allowed-tasks
Handling deprecation for yarn.nodemanager.container-monitor.interval-ms
Handling deprecation for dfs.datanode.cache.revocation.timeout.ms
Handling deprecation for mapreduce.jobhistory.recovery.store.class
Handling deprecation for mapreduce.task.combine.progress.records
Handling deprecation for s3.client-write-packet-size
Handling deprecation for mapreduce.jobtracker.instrumentation
Handling deprecation for dfs.replication
Handling deprecation for mapreduce.shuffle.transfer.buffer.size
Handling deprecation for hadoop.security.group.mapping.ldap.directory.search.timeout
Handling deprecation for dfs.datanode.available-space-volume-choosing-policy.balanced-space-threshold
Handling deprecation for hadoop.work.around.non.threadsafe.getpwuid
Handling deprecation for yarn.app.mapreduce.client-am.ipc.max-retries-on-timeouts
Handling deprecation for yarn.nodemanager.address
Handling deprecation for mapreduce.tasktracker.taskcontroller
Handling deprecation for mapreduce.tasktracker.indexcache.mb
Handling deprecation for yarn.scheduler.maximum-allocation-vcores
Handling deprecation for mapreduce.job.reduces
Handling deprecation for yarn.nodemanager.sleep-delay-before-sigkill.ms
Handling deprecation for yarn.timeline-service.address
Handling deprecation for yarn.resourcemanager.configuration.provider-class
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.expiry
Handling deprecation for yarn.sharedcache.enabled
Handling deprecation for tfile.io.chunk.size
Handling deprecation for mapreduce.job.acl-modify-job
Handling deprecation for hadoop.registry.zk.session.timeout.ms
Handling deprecation for fs.automatic.close
Handling deprecation for ha.health-monitor.sleep-after-disconnect.ms
Handling deprecation for mapreduce.tasktracker.reduce.tasks.maximum
Handling deprecation for mapreduce.input.fileinputformat.list-status.num-threads
Handling deprecation for dfs.datanode.directoryscan.threads
Handling deprecation for dfs.datanode.directoryscan.interval
Handling deprecation for dfs.namenode.acls.enabled
Handling deprecation for dfs.client.short.circuit.replica.stale.threshold.ms
Handling deprecation for hadoop.http.authentication.token.validity
Handling deprecation for fs.s3.block.size
Handling deprecation for ha.failover-controller.graceful-fence.rpc-timeout.ms
Handling deprecation for mapreduce.tasktracker.local.dir.minspacekill
Handling deprecation for dfs.namenode.resource.du.reserved
Handling deprecation for mapreduce.jobhistory.cleaner.interval-ms
Handling deprecation for dfs.namenode.datanode.registration.ip-hostname-check
Handling deprecation for mapreduce.jobhistory.intermediate-done-dir
Handling deprecation for mapreduce.jobtracker.http.address
Handling deprecation for dfs.namenode.backup.http-address
Handling deprecation for dfs.namenode.edits.noeditlogchannelflush
Handling deprecation for mapreduce.reduce.shuffle.input.buffer.percent
Handling deprecation for mapreduce.map.maxattempts
Handling deprecation for yarn.http.policy
Handling deprecation for dfs.namenode.audit.loggers
Handling deprecation for hadoop.security.groups.cache.warn.after.ms
Handling deprecation for io.serializations
Handling deprecation for mapreduce.tasktracker.outofband.heartbeat
Handling deprecation for mapreduce.reduce.shuffle.read.timeout
Handling deprecation for hadoop.security.crypto.buffer.size
Handling deprecation for mapreduce.reduce.skip.proc.count.autoincr
Handling deprecation for mapreduce.ifile.readahead.bytes
Handling deprecation for dfs.http.policy
Handling deprecation for hadoop.registry.secure
Handling deprecation for dfs.namenode.safemode.min.datanodes
Handling deprecation for dfs.client.file-block-storage-locations.num-threads
Handling deprecation for mapreduce.cluster.local.dir
Handling deprecation for mapreduce.tasktracker.report.address
Handling deprecation for dfs.namenode.secondary.https-address
Handling deprecation for hadoop.kerberos.kinit.command
Handling deprecation for yarn.timeline-service.http-authentication.type
Handling deprecation for dfs.block.access.token.lifetime
Handling deprecation for dfs.webhdfs.enabled
Handling deprecation for dfs.namenode.delegation.token.max-lifetime
Handling deprecation for dfs.namenode.avoid.write.stale.datanode
Handling deprecation for dfs.datanode.drop.cache.behind.writes
Handling deprecation for yarn.log-aggregation.retain-seconds
Handling deprecation for mapreduce.job.complete.cancel.delegation.tokens
Handling deprecation for mapreduce.local.clientfactory.class.name
Handling deprecation for mapreduce.shuffle.connection-keep-alive.timeout
Handling deprecation for dfs.namenode.num.extra.edits.retained
Handling deprecation for yarn.scheduler.minimum-allocation-vcores
Handling deprecation for ipc.client.connect.max.retries.on.timeouts
Handling deprecation for yarn.timeline-service.client.retry-interval-ms
Handling deprecation for yarn.timeline-service.client.max-retries
Handling deprecation for fs.s3n.block.size
Handling deprecation for mapreduce.job.map.output.collector.class
Handling deprecation for ha.health-monitor.connect-retry-interval.ms
Handling deprecation for mapreduce.shuffle.max.threads
Handling deprecation for nfs.exports.allowed.hosts
Handling deprecation for dfs.client.mmap.cache.size
Handling deprecation for mapreduce.tasktracker.map.tasks.maximum
Handling deprecation for io.file.buffer.size
Handling deprecation for dfs.client.datanode-restart.timeout
Handling deprecation for io.mapfile.bloom.size
Handling deprecation for hadoop.security.kms.client.authentication.retry-count
Handling deprecation for dfs.namenode.checkpoint.txns
Handling deprecation for ipc.client.connect.retry.interval
Handling deprecation for dfs.client-write-packet-size
Handling deprecation for mapreduce.reduce.shuffle.connect.timeout
Handling deprecation for yarn.resourcemanager.fs.state-store.uri
Handling deprecation for fs.swift.impl
Handling deprecation for hadoop.registry.zk.connection.timeout.ms
Handling deprecation for mapred.queue.default.acl-administer-jobs
Handling deprecation for mapreduce.job.submithostaddress
Handling deprecation for dfs.cachereport.intervalMsec
Handling deprecation for yarn.app.mapreduce.shuffle.log.backups
Handling deprecation for yarn.app.mapreduce.am.container.log.limit.kb
Handling deprecation for yarn.nodemanager.resourcemanager.minimum.version
Handling deprecation for ftp.blocksize
Handling deprecation for yarn.resourcemanager.address
Handling deprecation for file.stream-buffer-size
Handling deprecation for yarn.resourcemanager.scheduler.monitor.enable
Handling deprecation for mapreduce.job.ubertask.maxreduces
Handling deprecation for nfs.allow.insecure.ports
Handling deprecation for yarn.sharedcache.nm.uploader.thread-count
Handling deprecation for ipc.client.idlethreshold
Handling deprecation for ftp.stream-buffer-size
Handling deprecation for yarn.sharedcache.client-server.address
Handling deprecation for dfs.client.failover.connection.retries.on.timeouts
Handling deprecation for dfs.namenode.replication.work.multiplier.per.iteration
Handling deprecation for hadoop.http.authentication.simple.anonymous.allowed
Handling deprecation for hadoop.security.authorization
Handling deprecation for yarn.client.nodemanager-connect.retry-interval-ms
Handling deprecation for yarn.am.liveness-monitor.expiry-interval-ms
Handling deprecation for fs.har.impl.disable.cache
Handling deprecation for yarn.nodemanager.linux-container-executor.resources-handler.class
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.read-cache-size
Handling deprecation for hadoop.security.authentication
Handling deprecation for dfs.image.compression.codec
Handling deprecation for mapreduce.task.files.preserve.failedtasks
Handling deprecation for dfs.client.read.shortcircuit.streams.cache.size
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.path
Handling deprecation for mapreduce.job.reduce.slowstart.completedmaps
Handling deprecation for mapreduce.jobhistory.minicluster.fixed.ports
Handling deprecation for file.replication
Handling deprecation for yarn.resourcemanager.ha.automatic-failover.enabled
Handling deprecation for mapreduce.job.userlog.retain.hours
Handling deprecation for mapreduce.jobhistory.joblist.cache.size
Handling deprecation for dfs.namenode.accesstime.precision
Handling deprecation for yarn.resourcemanager.work-preserving-recovery.enabled
Handling deprecation for dfs.namenode.fs-limits.max-xattrs-per-inode
Handling deprecation for io.mapfile.bloom.error.rate
Handling deprecation for yarn.resourcemanager.store.class
Handling deprecation for dfs.image.transfer.timeout
Handling deprecation for yarn.timeline-service.leveldb-state-store.path
Handling deprecation for nfs.wtmax
Handling deprecation for mapreduce.job.combine.class
Handling deprecation for dfs.namenode.support.allow.format
Handling deprecation for fs.s3a.multipart.purge
Handling deprecation for dfs.secondary.namenode.kerberos.internal.spnego.principal
Handling deprecation for fs.s3a.connection.establish.timeout
Handling deprecation for dfs.stream-buffer-size
Handling deprecation for dfs.namenode.invalidate.work.pct.per.iteration
Handling deprecation for yarn.nodemanager.container-executor.class
Handling deprecation for fs.s3a.multipart.purge.age
Handling deprecation for yarn.resourcemanager.scheduler.client.thread-count
Handling deprecation for dfs.namenode.top.enabled
Handling deprecation for yarn.app.mapreduce.shuffle.log.separate
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.low-watermark
Handling deprecation for fs.s3a.fast.buffer.size
Handling deprecation for hadoop.user.group.static.mapping.overrides
Handling deprecation for tfile.fs.input.buffer.size
Handling deprecation for dfs.client.cached.conn.retry
Handling deprecation for hadoop.http.authentication.type
Handling deprecation for dfs.namenode.list.encryption.zones.num.responses
Handling deprecation for mapreduce.map.cpu.vcores
Handling deprecation for dfs.namenode.path.based.cache.refresh.interval.ms
Handling deprecation for dfs.namenode.decommission.interval
Handling deprecation for dfs.namenode.fs-limits.max-directory-items
Handling deprecation for yarn.resourcemanager.zk-retry-interval-ms
Handling deprecation for ftp.bytes-per-checksum
Handling deprecation for dfs.ha.log-roll.period
Handling deprecation for dfs.user.home.dir.prefix
Handling deprecation for ipc.client.fallback-to-simple-auth-allowed
Handling deprecation for yarn.nodemanager.pmem-check-enabled
Handling deprecation for yarn.nodemanager.remote-app-log-dir
Handling deprecation for dfs.namenode.inotify.max.events.per.rpc
Handling deprecation for mapreduce.task.profile.maps
Handling deprecation for mapreduce.shuffle.ssl.file.buffer.size
Handling deprecation for mapreduce.tasktracker.healthchecker.script.timeout
Handling deprecation for yarn.timeline-service.webapp.https.address
Handling deprecation for yarn.nodemanager.resource.percentage-physical-cpu-limit
Handling deprecation for yarn.app.mapreduce.am.command-opts
Handling deprecation for dfs.namenode.fs-limits.max-xattr-size
Handling deprecation for dfs.datanode.http.address
Handling deprecation for dfs.namenode.blocks.per.postponedblocks.rescan
Handling deprecation for yarn.sharedcache.nm.uploader.replication.factor
Handling deprecation for hadoop.registry.zk.root
Handling deprecation for hadoop.jetty.logs.serve.aliases
Handling deprecation for yarn.client.failover-proxy-provider
Handling deprecation for mapreduce.jobhistory.admin.acl
Handling deprecation for yarn.app.mapreduce.am.hard-kill-timeout-ms
Handling deprecation for yarn.nodemanager.remote-app-log-dir-suffix
Handling deprecation for mapreduce.jobhistory.principal
Handling deprecation for yarn.resourcemanager.webapp.address
Handling deprecation for mapreduce.jobhistory.recovery.enable
Handling deprecation for yarn.sharedcache.store.in-memory.check-period-mins
Handling deprecation for nfs.mountd.port
Handling deprecation for mapreduce.reduce.merge.inmem.threshold
Handling deprecation for fs.df.interval
Handling deprecation for yarn.timeline-service.enabled
Handling deprecation for mapreduce.jobtracker.jobhistory.lru.cache.size
Handling deprecation for mapreduce.task.profile
Handling deprecation for mapreduce.job.output.key.class
Handling deprecation for yarn.nodemanager.hostname
Handling deprecation for dfs.namenode.num.checkpoints.retained
Handling deprecation for mapreduce.job.queuename
Handling deprecation for mapreduce.jobhistory.max-age-ms
Handling deprecation for mapreduce.job.token.tracking.ids.enabled
Handling deprecation for yarn.nodemanager.localizer.client.thread-count
Handling deprecation for yarn.sharedcache.uploader.server.thread-count
Handling deprecation for dfs.client.mmap.retry.timeout.ms
Handling deprecation for mapreduce.jobhistory.move.thread-count
Handling deprecation for dfs.permissions.enabled
Handling deprecation for dfs.blockreport.split.threshold
Handling deprecation for fs.AbstractFileSystem.hdfs.impl
Handling deprecation for dfs.datanode.balance.bandwidthPerSec
Handling deprecation for dfs.block.scanner.volume.bytes.per.second
Handling deprecation for hadoop.http.filter.initializers
Handling deprecation for yarn.timeline-service.http-authentication.simple.anonymous.allowed
Handling deprecation for dfs.default.chunk.view.size
Handling deprecation for yarn.sharedcache.client-server.thread-count
Handling deprecation for yarn.resourcemanager.resource-tracker.address
Handling deprecation for mapreduce.job.working.dir
Handling deprecation for mapreduce.jobhistory.datestring.cache.size
Handling deprecation for mapreduce.task.profile.params
Handling deprecation for dfs.namenode.decommission.blocks.per.interval
Handling deprecation for dfs.namenode.handler.count
Handling deprecation for dfs.image.transfer.bandwidthPerSec
Handling deprecation for rpc.metrics.quantile.enable
Handling deprecation for mapreduce.jobtracker.expire.trackers.interval
Handling deprecation for mapreduce.task.timeout
Handling deprecation for yarn.app.mapreduce.client.max-retries
Handling deprecation for yarn.nodemanager.resource.memory-mb
Handling deprecation for yarn.nodemanager.disk-health-checker.min-healthy-disks
Handling deprecation for dfs.datanode.failed.volumes.tolerated
Handling deprecation for yarn.timeline-service.handler-thread-count
Handling deprecation for ipc.server.listen.queue.size
Handling deprecation for fs.s3a.threads.max
Handling deprecation for yarn.resourcemanager.connect.max-wait.ms
Handling deprecation for mapreduce.fileoutputcommitter.algorithm.version
Handling deprecation for mapreduce.framework.name
Handling deprecation for mapreduce.map.skip.proc.count.autoincr
Handling deprecation for mapreduce.job.max.split.locations
Handling deprecation for yarn.resourcemanager.scheduler.class
Handling deprecation for yarn.resourcemanager.system-metrics-publisher.enabled
Handling deprecation for dfs.blocksize
Handling deprecation for yarn.sharedcache.nested-level
Handling deprecation for mapreduce.shuffle.connection-keep-alive.enable
Handling deprecation for fs.s3a.threads.keepalivetime
Handling deprecation for fs.s3a.connection.timeout
Handling deprecation for file.client-write-packet-size
Handling deprecation for ha.failover-controller.cli-check.rpc-timeout.ms
Handling deprecation for ha.zookeeper.acl
Handling deprecation for dfs.namenode.write.stale.datanode.ratio
Handling deprecation for dfs.encrypt.data.transfer
Handling deprecation for dfs.datanode.shared.file.descriptor.paths
Handling deprecation for mapreduce.input.lineinputformat.linespermap
Handling deprecation for yarn.resourcemanager.delayed.delegation-token.removal-interval-ms
Handling deprecation for yarn.nodemanager.localizer.fetch.thread-count
Handling deprecation for dfs.client.failover.max.attempts
Handling deprecation for yarn.resourcemanager.scheduler.address
Handling deprecation for dfs.client.read.shortcircuit.streams.cache.expiry.ms
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.start-time-write-cache-size
Handling deprecation for yarn.nodemanager.health-checker.script.timeout-ms
Handling deprecation for yarn.resourcemanager.fs.state-store.num-retries
Handling deprecation for hadoop.ssl.require.client.cert
Handling deprecation for hadoop.security.uid.cache.secs
Handling deprecation for mapreduce.jobhistory.keytab
Handling deprecation for dfs.client.read.shortcircuit.skip.checksum
Handling deprecation for yarn.resourcemanager.ha.automatic-failover.zk-base-path
Handling deprecation for mapreduce.shuffle.ssl.enabled
Handling deprecation for mapreduce.reduce.log.level
Handling deprecation for hadoop.registry.rm.enabled
Handling deprecation for mapreduce.tasktracker.dns.interface
Handling deprecation for yarn.resourcemanager.system-metrics-publisher.dispatcher.pool-size
Handling deprecation for mapreduce.job.speculative.speculative-cap-running-tasks
Handling deprecation for dfs.datanode.block.id.layout.upgrade.threads
Handling deprecation for dfs.datanode.use.datanode.hostname
Handling deprecation for dfs.client.context
Handling deprecation for yarn.resourcemanager.ha.enabled
Handling deprecation for mapred.reducer.new-api
Handling deprecation for dfs.namenode.delegation.token.renew-interval
Handling deprecation for dfs.blockreport.intervalMsec
Handling deprecation for fs.s3a.multipart.threshold
Handling deprecation for mapreduce.reduce.shuffle.memory.limit.percent
Handling deprecation for dfs.https.server.keystore.resource
Handling deprecation for io.map.index.skip
Handling deprecation for mapreduce.job.hdfs-servers
Handling deprecation for mapreduce.jobtracker.taskscheduler
Handling deprecation for dfs.namenode.kerberos.internal.spnego.principal
Handling deprecation for yarn.resourcemanager.state-store.max-completed-applications
Handling deprecation for mapreduce.map.output.compress
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.num.refill.threads
Handling deprecation for fs.s3n.multipart.uploads.block.size
Handling deprecation for mapreduce.task.merge.progress.records
Handling deprecation for dfs.datanode.dns.interface
Handling deprecation for map.sort.class
Handling deprecation for yarn.nodemanager.aux-services.mapreduce_shuffle.class
Handling deprecation for tfile.fs.output.buffer.size
Handling deprecation for fs.du.interval
Handling deprecation for dfs.client.failover.connection.retries
Handling deprecation for dfs.namenode.top.window.num.buckets
Handling deprecation for mapreduce.job.dir
Handling deprecation for fs.s3a.buffer.dir
Handling deprecation for mapreduce.reduce.shuffle.retry-delay.max.ms
Handling deprecation for yarn.sharedcache.uploader.server.address
Handling deprecation for mapreduce.client.progressmonitor.pollinterval
Handling deprecation for yarn.app.mapreduce.shuffle.log.limit.kb
Handling deprecation for dfs.datanode.max.locked.memory
Handling deprecation for dfs.namenode.retrycache.expirytime.millis
Handling deprecation for dfs.datanode.scan.period.hours
Handling deprecation for dfs.client.block.write.replace-datanode-on-failure.best-effort
Handling deprecation for mapreduce.jobhistory.move.interval-ms
Handling deprecation for dfs.ha.fencing.ssh.connect-timeout
Handling deprecation for yarn.nodemanager.log-aggregation.roll-monitoring-interval-seconds
Handling deprecation for dfs.namenode.fs-limits.max-component-length
Handling deprecation for hadoop.registry.zk.quorum
Handling deprecation for dfs.namenode.enable.retrycache
Handling deprecation for dfs.datanode.du.reserved
Handling deprecation for yarn.timeline-service.state-store-class
Handling deprecation for dfs.datanode.ipc.address
Handling deprecation for hadoop.registry.system.acls
Handling deprecation for dfs.client.block.write.replace-datanode-on-failure.policy
Handling deprecation for dfs.namenode.path.based.cache.retry.interval.ms
Handling deprecation for hadoop.security.crypto.cipher.suite
Handling deprecation for dfs.ha.tail-edits.period
Handling deprecation for mapreduce.task.profile.reduce.params
Handling deprecation for hadoop.registry.jaas.context
Handling deprecation for yarn.resourcemanager.hostname
Handling deprecation for mapreduce.reduce.memory.mb
Handling deprecation for hadoop.security.group.mapping.ldap.search.filter.group
Handling deprecation for hadoop.http.authentication.kerberos.principal
Handling deprecation for hadoop.security.group.mapping.ldap.search.filter.user
Handling deprecation for yarn.nodemanager.disk-health-checker.min-free-space-per-disk-mb
Handling deprecation for dfs.namenode.edits.dir
Handling deprecation for yarn.client.failover-retries-on-socket-timeouts
Handling deprecation for dfs.namenode.decommission.max.concurrent.tracked.nodes
Handling deprecation for mapreduce.client.completion.pollinterval
Handling deprecation for dfs.namenode.name.dir.restore
Handling deprecation for dfs.namenode.secondary.http-address
Handling deprecation for mapreduce.jobhistory.recovery.store.leveldb.path
Handling deprecation for yarn.sharedcache.store.class
Handling deprecation for s3.bytes-per-checksum
Handling deprecation for yarn.nodemanager.windows-container.cpu-limit.enabled
Handling deprecation for yarn.resourcemanager.webapp.https.address
Handling deprecation for yarn.nodemanager.vmem-pmem-ratio
Handling deprecation for dfs.namenode.checkpoint.period
Handling deprecation for dfs.ha.automatic-failover.enabled
Submitting tokens for job: job_local502431174_0002
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.fs.FileContext.getAbstractFileSystem(FileContext.java:331)
Handling deprecation for all properties in config...
Handling deprecation for mapreduce.jobtracker.address
Handling deprecation for yarn.resourcemanager.scheduler.monitor.policies
Handling deprecation for dfs.namenode.resource.check.interval
Handling deprecation for mapreduce.jobhistory.client.thread-count
Handling deprecation for yarn.app.mapreduce.am.containerlauncher.threadpool-initial-size
Handling deprecation for mapred.child.java.opts
Handling deprecation for mapreduce.jobtracker.retiredjobs.cache.size
Handling deprecation for dfs.client.https.need-auth
Handling deprecation for yarn.admin.acl
Handling deprecation for yarn.app.mapreduce.am.job.committer.cancel-timeout
Handling deprecation for mapreduce.job.emit-timeline-data
Handling deprecation for fs.ftp.host.port
Handling deprecation for dfs.namenode.avoid.read.stale.datanode
Handling deprecation for dfs.journalnode.rpc-address
Handling deprecation for mapreduce.job.end-notification.retry.attempts
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.ttl-interval-ms
Handling deprecation for yarn.resourcemanager.leveldb-state-store.path
Handling deprecation for mapred.mapper.new-api
Handling deprecation for yarn.ipc.rpc.class
Handling deprecation for ipc.client.connection.maxidletime
Handling deprecation for yarn.nodemanager.process-kill-wait.ms
Handling deprecation for mapreduce.cluster.acls.enabled
Handling deprecation for mapreduce.jobtracker.handler.count
Handling deprecation for io.map.index.interval
Handling deprecation for dfs.namenode.https-address
Handling deprecation for mapreduce.task.profile.reduces
Handling deprecation for fs.s3n.multipart.uploads.enabled
Handling deprecation for io.seqfile.sorter.recordlimit
Handling deprecation for mapreduce.job.ubertask.maxmaps
Handling deprecation for mapreduce.tasktracker.tasks.sleeptimebeforesigkill
Handling deprecation for hadoop.util.hash.type
Handling deprecation for dfs.namenode.replication.min
Handling deprecation for yarn.nodemanager.container-manager.thread-count
Handling deprecation for mapreduce.jobtracker.jobhistory.block.size
Handling deprecation for dfs.namenode.fs-limits.min-block-size
Handling deprecation for mapreduce.app-submission.cross-platform
Handling deprecation for fs.AbstractFileSystem.file.impl
Handling deprecation for net.topology.script.number.args
Handling deprecation for yarn.resourcemanager.container-tokens.master-key-rolling-interval-secs
Handling deprecation for mapreduce.map.output.compress.codec
Handling deprecation for mapreduce.job.reducer.preempt.delay.sec
Handling deprecation for s3native.bytes-per-checksum
Handling deprecation for dfs.namenode.path.based.cache.block.map.allocation.percent
Handling deprecation for yarn.nodemanager.windows-container.memory-limit.enabled
Handling deprecation for mapreduce.input.fileinputformat.split.minsize
Handling deprecation for hadoop.security.group.mapping
Handling deprecation for mapreduce.jobtracker.system.dir
Handling deprecation for mapreduce.job.end-notification.max.attempts
Handling deprecation for mapreduce.reduce.markreset.buffer.percent
Handling deprecation for dfs.datanode.cache.revocation.polling.ms
Handling deprecation for mapreduce.reduce.speculative
Handling deprecation for yarn.nodemanager.localizer.cache.cleanup.interval-ms
Handling deprecation for dfs.namenode.lazypersist.file.scrub.interval.sec
Handling deprecation for fs.s3a.threads.core
Handling deprecation for mapreduce.jobhistory.recovery.store.fs.uri
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.start-time-read-cache-size
Handling deprecation for hadoop.registry.zk.retry.interval.ms
Handling deprecation for yarn.nodemanager.keytab
Handling deprecation for dfs.namenode.replication.interval
Handling deprecation for yarn.resourcemanager.admin.address
Handling deprecation for mapreduce.job.maps
Handling deprecation for nfs.dump.dir
Handling deprecation for mapreduce.job.user.name
Handling deprecation for mapreduce.jobtracker.maxtasks.perjob
Handling deprecation for mapreduce.job.ubertask.enable
Handling deprecation for mapreduce.job.reduce.class
Handling deprecation for yarn.nodemanager.delete.debug-delay-sec
Handling deprecation for yarn.timeline-service.ttl-enable
Handling deprecation for yarn.resourcemanager.fs.state-store.retry-policy-spec
Handling deprecation for mapreduce.reduce.skip.maxgroups
Handling deprecation for dfs.client.use.datanode.hostname
Handling deprecation for fs.trash.interval
Handling deprecation for mapreduce.job.name
Handling deprecation for mapreduce.am.max-attempts
Handling deprecation for mapreduce.jobtracker.heartbeats.in.second
Handling deprecation for yarn.resourcemanager.zk-num-retries
Handling deprecation for s3.blocksize
Handling deprecation for dfs.datanode.data.dir
Handling deprecation for mapreduce.jobtracker.persist.jobstatus.active
Handling deprecation for mapreduce.reduce.shuffle.parallelcopies
Handling deprecation for fs.s3.buffer.dir
Handling deprecation for mapreduce.jobhistory.done-dir
Handling deprecation for hadoop.security.instrumentation.requires.admin
Handling deprecation for hadoop.registry.zk.retry.ceiling.ms
Handling deprecation for nfs.rtmax
Handling deprecation for dfs.datanode.data.dir.perm
Handling deprecation for yarn.resourcemanager.container.liveness-monitor.interval-ms
Handling deprecation for yarn.nodemanager.env-whitelist
Handling deprecation for dfs.namenode.backup.address
Handling deprecation for dfs.namenode.xattrs.enabled
Handling deprecation for dfs.datanode.readahead.bytes
Handling deprecation for mapreduce.jobhistory.cleaner.enable
Handling deprecation for dfs.client.block.write.retries
Handling deprecation for mapreduce.tasktracker.http.address
Handling deprecation for yarn.nodemanager.linux-container-executor.cgroups.hierarchy
Handling deprecation for ha.failover-controller.graceful-fence.connection.retries
Handling deprecation for yarn.resourcemanager.recovery.enabled
Handling deprecation for yarn.app.mapreduce.am.container.log.backups
Handling deprecation for dfs.namenode.safemode.threshold-pct
Handling deprecation for yarn.nodemanager.disk-health-checker.interval-ms
Handling deprecation for hadoop.security.java.secure.random.algorithm
Handling deprecation for dfs.namenode.list.cache.directives.num.responses
Handling deprecation for dfs.datanode.dns.nameserver
Handling deprecation for mapreduce.cluster.temp.dir
Handling deprecation for fs.s3a.max.total.tasks
Handling deprecation for mapreduce.reduce.maxattempts
Handling deprecation for mapreduce.client.submit.file.replication
Handling deprecation for mapreduce.shuffle.port
Handling deprecation for yarn.resourcemanager.resource-tracker.client.thread-count
Handling deprecation for dfs.namenode.replication.considerLoad
Handling deprecation for dfs.namenode.edits.journal-plugin.qjournal
Handling deprecation for dfs.client.write.exclude.nodes.cache.expiry.interval.millis
Handling deprecation for yarn.nodemanager.delete.thread-count
Handling deprecation for dfs.client.mmap.cache.timeout.ms
Handling deprecation for yarn.nodemanager.admin-env
Handling deprecation for io.skip.checksum.errors
Handling deprecation for yarn.timeline-service.hostname
Handling deprecation for yarn.resourcemanager.proxy-user-privileges.enabled
Handling deprecation for mapreduce.job.speculative.speculative-cap-total-tasks
Handling deprecation for yarn.acl.enable
Handling deprecation for fs.s3a.fast.upload
Handling deprecation for file.blocksize
Handling deprecation for mapreduce.job.speculative.slowtaskthreshold
Handling deprecation for ftp.replication
Handling deprecation for yarn.sharedcache.cleaner.initial-delay-mins
Handling deprecation for s3native.client-write-packet-size
Handling deprecation for hadoop.rpc.socket.factory.class.default
Handling deprecation for file.bytes-per-checksum
Handling deprecation for dfs.datanode.slow.io.warning.threshold.ms
Handling deprecation for io.seqfile.lazydecompress
Handling deprecation for mapreduce.task.skip.start.attempts
Handling deprecation for dfs.namenode.reject-unresolved-dn-topology-mapping
Handling deprecation for hadoop.common.configuration.version
Handling deprecation for yarn.resourcemanager.client.thread-count
Handling deprecation for dfs.datanode.drop.cache.behind.reads
Handling deprecation for yarn.sharedcache.admin.address
Handling deprecation for mapreduce.job.output.value.class
Handling deprecation for mapreduce.output.fileoutputformat.outputdir
Handling deprecation for mapreduce.jobtracker.taskcache.levels
Handling deprecation for yarn.nodemanager.linux-container-executor.nonsecure-mode.user-pattern
Handling deprecation for yarn.resourcemanager.zk-timeout-ms
Handling deprecation for yarn.resourcemanager.max-completed-applications
Handling deprecation for mapreduce.job.jvm.numtasks
Handling deprecation for yarn.sharedcache.cleaner.period-mins
Handling deprecation for mapreduce.jobtracker.tasktracker.maxblacklists
Handling deprecation for dfs.namenode.top.num.users
Handling deprecation for yarn.nodemanager.linux-container-executor.cgroups.mount
Handling deprecation for yarn.sharedcache.checksum.algo.impl
Handling deprecation for mapreduce.job.end-notification.max.retry.interval
Handling deprecation for mapreduce.job.acl-view-job
Handling deprecation for mapreduce.job.classloader
Handling deprecation for yarn.log-aggregation-enable
Handling deprecation for mapreduce.reduce.shuffle.fetch.retry.interval-ms
Handling deprecation for yarn.resourcemanager.nodemanager.minimum.version
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.size
Handling deprecation for yarn.app.mapreduce.am.job.task.listener.thread-count
Handling deprecation for yarn.app.mapreduce.am.resource.cpu-vcores
Handling deprecation for dfs.namenode.edit.log.autoroll.check.interval.ms
Handling deprecation for mapreduce.output.fileoutputformat.compress.type
Handling deprecation for hadoop.hdfs.configuration.version
Handling deprecation for hadoop.security.group.mapping.ldap.search.attr.member
Handling deprecation for yarn.nodemanager.log.retain-seconds
Handling deprecation for yarn.nodemanager.local-cache.max-files-per-directory
Handling deprecation for mapreduce.job.end-notification.retry.interval
Handling deprecation for hadoop.ssl.client.conf
Handling deprecation for yarn.sharedcache.root-dir
Handling deprecation for dfs.journalnode.https-address
Handling deprecation for mapreduce.reduce.shuffle.fetch.retry.timeout-ms
Handling deprecation for dfs.bytes-per-checksum
Handling deprecation for dfs.namenode.max.objects
Handling deprecation for mapreduce.tasktracker.instrumentation
Handling deprecation for dfs.datanode.max.transfer.threads
Handling deprecation for dfs.block.access.key.update.interval
Handling deprecation for mapreduce.jobtracker.jobhistory.task.numberprogresssplits
Handling deprecation for mapreduce.map.memory.mb
Handling deprecation for ha.failover-controller.new-active.rpc-timeout.ms
Handling deprecation for hadoop.ssl.hostname.verifier
Handling deprecation for dfs.client.read.shortcircuit
Handling deprecation for dfs.datanode.hdfs-blocks-metadata.enabled
Handling deprecation for mapreduce.tasktracker.healthchecker.interval
Handling deprecation for dfs.image.transfer.chunksize
Handling deprecation for mapreduce.tasktracker.taskmemorymanager.monitoringinterval
Handling deprecation for dfs.client.https.keystore.resource
Handling deprecation for yarn.resourcemanager.connect.retry-interval.ms
Handling deprecation for yarn.timeline-service.webapp.address
Handling deprecation for s3native.blocksize
Handling deprecation for yarn.scheduler.minimum-allocation-mb
Handling deprecation for yarn.sharedcache.cleaner.resource-sleep-ms
Handling deprecation for net.topology.impl
Handling deprecation for dfs.client.failover.sleep.base.millis
Handling deprecation for dfs.permissions.superusergroup
Handling deprecation for io.seqfile.compress.blocksize
Handling deprecation for hadoop.registry.zk.retry.times
Handling deprecation for fs.AbstractFileSystem.ftp.impl
Handling deprecation for dfs.namenode.checkpoint.edits.dir
Handling deprecation for mapreduce.job.running.reduce.limit
Handling deprecation for dfs.blockreport.initialDelay
Handling deprecation for dfs.namenode.heartbeat.recheck-interval
Handling deprecation for dfs.namenode.safemode.extension
Handling deprecation for yarn.scheduler.maximum-allocation-mb
Handling deprecation for mapreduce.job.reduce.shuffle.consumer.plugin.class
Handling deprecation for yarn.nodemanager.vmem-check-enabled
Handling deprecation for mapreduce.task.io.sort.factor
Handling deprecation for mapreduce.jobtracker.persist.jobstatus.dir
Handling deprecation for dfs.client.failover.sleep.max.millis
Handling deprecation for dfs.namenode.delegation.key.update-interval
Handling deprecation for hadoop.rpc.protection
Handling deprecation for fs.permissions.umask-mode
Handling deprecation for fs.s3.sleepTimeSeconds
Handling deprecation for ha.health-monitor.rpc-timeout.ms
Handling deprecation for hadoop.http.staticuser.user
Handling deprecation for fs.s3a.connection.maximum
Handling deprecation for yarn.nodemanager.linux-container-executor.nonsecure-mode.limit-users
Handling deprecation for fs.s3a.paging.maximum
Handling deprecation for fs.AbstractFileSystem.viewfs.impl
Handling deprecation for fs.ftp.host
Handling deprecation for yarn.nodemanager.linux-container-executor.nonsecure-mode.local-user
Handling deprecation for fs.s3a.impl
Handling deprecation for hadoop.http.authentication.kerberos.keytab
Handling deprecation for dfs.namenode.fs-limits.max-blocks-per-file
Handling deprecation for mapreduce.tasktracker.http.threads
Handling deprecation for mapreduce.tasktracker.dns.nameserver
Handling deprecation for yarn.resourcemanager.am-rm-tokens.master-key-rolling-interval-secs
Handling deprecation for dfs.client.block.write.replace-datanode-on-failure.enable
Handling deprecation for io.compression.codec.bzip2.library
Handling deprecation for mapreduce.map.skip.maxrecords
Handling deprecation for dfs.client.use.legacy.blockreader.local
Handling deprecation for dfs.namenode.checkpoint.dir
Handling deprecation for dfs.namenode.top.windows.minutes
Handling deprecation for mapreduce.job.maxtaskfailures.per.tracker
Handling deprecation for net.topology.node.switch.mapping.impl
Handling deprecation for mapreduce.shuffle.max.connections
Handling deprecation for mapreduce.jobhistory.loadedjobs.cache.size
Handling deprecation for dfs.storage.policy.enabled
Handling deprecation for yarn.client.application-client-protocol.poll-interval-ms
Handling deprecation for yarn.nodemanager.localizer.address
Handling deprecation for dfs.namenode.list.cache.pools.num.responses
Handling deprecation for nfs.server.port
Handling deprecation for mapreduce.client.output.filter
Handling deprecation for yarn.timeline-service.client.best-effort
Handling deprecation for ha.zookeeper.parent-znode
Handling deprecation for mapreduce.jobtracker.persist.jobstatus.hours
Handling deprecation for yarn.sharedcache.admin.thread-count
Handling deprecation for yarn.nodemanager.resource.cpu-vcores
Handling deprecation for dfs.datanode.block-pinning.enabled
Handling deprecation for mapreduce.jobhistory.http.policy
Handling deprecation for yarn.resourcemanager.webapp.delegation-token-auth-filter.enabled
Handling deprecation for mapreduce.job.speculative.retry-after-no-speculate
Handling deprecation for fs.s3a.attempts.maximum
Handling deprecation for s3native.stream-buffer-size
Handling deprecation for io.seqfile.local.dir
Handling deprecation for yarn.log-aggregation.retain-check-interval-seconds
Handling deprecation for fs.s3n.multipart.copy.block.size
Handling deprecation for dfs.encrypt.data.transfer.cipher.key.bitlength
Handling deprecation for dfs.datanode.sync.behind.writes
Handling deprecation for yarn.resourcemanager.zk-acl
Handling deprecation for hadoop.ssl.keystores.factory.class
Handling deprecation for mapreduce.job.split.metainfo.maxsize
Handling deprecation for fs.s3.maxRetries
Handling deprecation for hadoop.security.random.device.file.path
Handling deprecation for yarn.client.nodemanager-connect.max-wait-ms
Handling deprecation for dfs.namenode.stale.datanode.interval
Handling deprecation for mapreduce.task.io.sort.mb
Handling deprecation for yarn.resourcemanager.zk-state-store.parent-path
Handling deprecation for yarn.app.mapreduce.client-am.ipc.max-retries
Handling deprecation for fs.client.resolve.remote.symlinks
Handling deprecation for yarn.nodemanager.linux-container-executor.cgroups.strict-resource-usage
Handling deprecation for hadoop.ssl.enabled.protocols
Handling deprecation for mapreduce.reduce.cpu.vcores
Handling deprecation for yarn.client.failover-retries
Handling deprecation for mapreduce.jobhistory.address
Handling deprecation for hadoop.ssl.enabled
Handling deprecation for dfs.replication.max
Handling deprecation for dfs.namenode.name.dir
Handling deprecation for dfs.datanode.https.address
Handling deprecation for ipc.client.kill.max
Handling deprecation for mapreduce.job.committer.setup.cleanup.needed
Handling deprecation for dfs.client.domain.socket.data.traffic
Handling deprecation for yarn.nodemanager.localizer.cache.target-size-mb
Handling deprecation for yarn.resourcemanager.admin.client.thread-count
Handling deprecation for dfs.block.access.token.enable
Handling deprecation for mapreduce.job.speculative.retry-after-speculate
Handling deprecation for dfs.datanode.address
Handling deprecation for mapreduce.jobtracker.restart.recover
Handling deprecation for ipc.client.connect.max.retries
Handling deprecation for yarn.timeline-service.store-class
Handling deprecation for dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
Handling deprecation for hadoop.tmp.dir
Handling deprecation for dfs.datanode.handler.count
Handling deprecation for yarn.resourcemanager.ha.automatic-failover.embedded
Handling deprecation for yarn.timeline-service.ttl-ms
Handling deprecation for mapreduce.task.profile.map.params
Handling deprecation for yarn.resourcemanager.nodemanagers.heartbeat-interval-ms
Handling deprecation for mapreduce.map.speculative
Handling deprecation for yarn.timeline-service.recovery.enabled
Handling deprecation for mapreduce.job.map.class
Handling deprecation for dfs.namenode.resource.checked.volumes.minimum
Handling deprecation for yarn.nodemanager.recovery.dir
Handling deprecation for mapreduce.job.counters.max
Handling deprecation for yarn.resourcemanager.keytab
Handling deprecation for dfs.namenode.max.extra.edits.segments.retained
Handling deprecation for dfs.webhdfs.user.provider.user.pattern
Handling deprecation for dfs.client.mmap.enabled
Handling deprecation for mapreduce.map.log.level
Handling deprecation for dfs.client.file-block-storage-locations.timeout.millis
Handling deprecation for yarn.client.max-cached-nodemanagers-proxies
Handling deprecation for yarn.app.mapreduce.am.scheduler.heartbeat.interval-ms
Handling deprecation for hadoop.fuse.timer.period
Handling deprecation for fs.trash.checkpoint.interval
Handling deprecation for yarn.sharedcache.app-checker.class
Handling deprecation for dfs.journalnode.http-address
Handling deprecation for yarn.app.mapreduce.am.staging-dir
Handling deprecation for mapreduce.tasktracker.local.dir.minspacestart
Handling deprecation for yarn.nm.liveness-monitor.expiry-interval-ms
Handling deprecation for ha.health-monitor.check-interval.ms
Handling deprecation for mapreduce.reduce.shuffle.merge.percent
Handling deprecation for dfs.namenode.retrycache.heap.percent
Handling deprecation for yarn.nodemanager.docker-container-executor.exec-name
Handling deprecation for ipc.client.connect.timeout
Handling deprecation for yarn.resourcemanager.fs.state-store.retry-interval-ms
Handling deprecation for mapreduce.output.fileoutputformat.compress
Handling deprecation for yarn.nodemanager.local-dirs
Handling deprecation for yarn.nodemanager.recovery.enabled
Handling deprecation for io.native.lib.available
Handling deprecation for yarn.sharedcache.store.in-memory.staleness-period-mins
Handling deprecation for yarn.resourcemanager.am.max-attempts
Handling deprecation for s3.replication
Handling deprecation for mapreduce.input.fileinputformat.inputdir
Handling deprecation for fs.AbstractFileSystem.har.impl
Handling deprecation for dfs.image.compress
Handling deprecation for mapreduce.job.running.map.limit
Handling deprecation for mapreduce.reduce.input.buffer.percent
Handling deprecation for yarn.nodemanager.webapp.address
Handling deprecation for dfs.datanode.available-space-volume-choosing-policy.balanced-space-preference-fraction
Handling deprecation for dfs.namenode.edit.log.autoroll.multiplier.threshold
Handling deprecation for hadoop.security.group.mapping.ldap.ssl
Handling deprecation for dfs.namenode.checkpoint.check.period
Handling deprecation for fs.defaultFS
Handling deprecation for fs.s3a.multipart.size
Handling deprecation for dfs.client.slow.io.warning.threshold.ms
Handling deprecation for yarn.app.mapreduce.am.job.committer.commit-window
Handling deprecation for hadoop.security.group.mapping.ldap.search.attr.group.name
Handling deprecation for yarn.nodemanager.disk-health-checker.max-disk-utilization-per-disk-percentage
Handling deprecation for yarn.nodemanager.container-monitor.procfs-tree.smaps-based-rss.enabled
Handling deprecation for mapreduce.job.submithostname
Handling deprecation for mapreduce.map.sort.spill.percent
Handling deprecation for hadoop.security.crypto.codec.classes.aes.ctr.nopadding
Handling deprecation for dfs.namenode.http-address
Handling deprecation for hadoop.security.groups.negative-cache.secs
Handling deprecation for hadoop.ssl.server.conf
Handling deprecation for mapreduce.ifile.readahead
Handling deprecation for s3native.replication
Handling deprecation for yarn.client.nodemanager-client-async.thread-pool-max-size
Handling deprecation for mapreduce.jobtracker.staging.root.dir
Handling deprecation for mapreduce.jobhistory.admin.address
Handling deprecation for dfs.namenode.startup.delay.block.deletion.sec
Handling deprecation for yarn.nodemanager.health-checker.interval-ms
Handling deprecation for dfs.namenode.checkpoint.max-retries
Handling deprecation for s3.stream-buffer-size
Handling deprecation for ftp.client-write-packet-size
Handling deprecation for dfs.datanode.fsdatasetcache.max.threads.per.volume
Handling deprecation for mapreduce.output.fileoutputformat.compress.codec
Handling deprecation for yarn.timeline-service.keytab
Handling deprecation for yarn.sharedcache.store.in-memory.initial-delay-mins
Handling deprecation for mapreduce.jobhistory.webapp.address
Handling deprecation for mapreduce.task.userlog.limit.kb
Handling deprecation for mapreduce.reduce.shuffle.fetch.retry.enabled
Handling deprecation for yarn.app.mapreduce.task.container.log.backups
Handling deprecation for dfs.heartbeat.interval
Handling deprecation for ha.zookeeper.session-timeout.ms
Handling deprecation for fs.s3a.connection.ssl.enabled
Handling deprecation for yarn.sharedcache.webapp.address
Handling deprecation for hadoop.http.authentication.signature.secret.file
Handling deprecation for hadoop.fuse.connection.timeout
Handling deprecation for mapreduce.input.fileinputformat.numinputfiles
Handling deprecation for yarn.nodemanager.log-aggregation.compression-type
Handling deprecation for ipc.server.max.connections
Handling deprecation for yarn.resourcemanager.work-preserving-recovery.scheduling-wait-ms
Handling deprecation for yarn.nodemanager.log-dirs
Handling deprecation for yarn.app.mapreduce.am.resource.mb
Handling deprecation for hadoop.security.groups.cache.secs
Handling deprecation for mapreduce.job.speculative.minimum-allowed-tasks
Handling deprecation for yarn.nodemanager.container-monitor.interval-ms
Handling deprecation for dfs.datanode.cache.revocation.timeout.ms
Handling deprecation for mapreduce.jobhistory.recovery.store.class
Handling deprecation for mapreduce.task.combine.progress.records
Handling deprecation for s3.client-write-packet-size
Handling deprecation for mapreduce.jobtracker.instrumentation
Handling deprecation for dfs.replication
Handling deprecation for mapreduce.shuffle.transfer.buffer.size
Handling deprecation for hadoop.security.group.mapping.ldap.directory.search.timeout
Handling deprecation for dfs.datanode.available-space-volume-choosing-policy.balanced-space-threshold
Handling deprecation for hadoop.work.around.non.threadsafe.getpwuid
Handling deprecation for yarn.app.mapreduce.client-am.ipc.max-retries-on-timeouts
Handling deprecation for yarn.nodemanager.address
Handling deprecation for mapreduce.tasktracker.taskcontroller
Handling deprecation for mapreduce.tasktracker.indexcache.mb
Handling deprecation for yarn.scheduler.maximum-allocation-vcores
Handling deprecation for mapreduce.job.reduces
Handling deprecation for yarn.nodemanager.sleep-delay-before-sigkill.ms
Handling deprecation for yarn.timeline-service.address
Handling deprecation for yarn.resourcemanager.configuration.provider-class
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.expiry
Handling deprecation for yarn.sharedcache.enabled
Handling deprecation for tfile.io.chunk.size
Handling deprecation for mapreduce.job.acl-modify-job
Handling deprecation for hadoop.registry.zk.session.timeout.ms
Handling deprecation for fs.automatic.close
Handling deprecation for ha.health-monitor.sleep-after-disconnect.ms
Handling deprecation for mapreduce.tasktracker.reduce.tasks.maximum
Handling deprecation for mapreduce.input.fileinputformat.list-status.num-threads
Handling deprecation for dfs.datanode.directoryscan.threads
Handling deprecation for dfs.datanode.directoryscan.interval
Handling deprecation for dfs.namenode.acls.enabled
Handling deprecation for dfs.client.short.circuit.replica.stale.threshold.ms
Handling deprecation for hadoop.http.authentication.token.validity
Handling deprecation for fs.s3.block.size
Handling deprecation for ha.failover-controller.graceful-fence.rpc-timeout.ms
Handling deprecation for mapreduce.tasktracker.local.dir.minspacekill
Handling deprecation for dfs.namenode.resource.du.reserved
Handling deprecation for mapreduce.jobhistory.cleaner.interval-ms
Handling deprecation for dfs.namenode.datanode.registration.ip-hostname-check
Handling deprecation for mapreduce.jobhistory.intermediate-done-dir
Handling deprecation for mapreduce.jobtracker.http.address
Handling deprecation for dfs.namenode.backup.http-address
Handling deprecation for dfs.namenode.edits.noeditlogchannelflush
Handling deprecation for mapreduce.reduce.shuffle.input.buffer.percent
Handling deprecation for mapreduce.map.maxattempts
Handling deprecation for yarn.http.policy
Handling deprecation for dfs.namenode.audit.loggers
Handling deprecation for hadoop.security.groups.cache.warn.after.ms
Handling deprecation for io.serializations
Handling deprecation for mapreduce.tasktracker.outofband.heartbeat
Handling deprecation for mapreduce.reduce.shuffle.read.timeout
Handling deprecation for hadoop.security.crypto.buffer.size
Handling deprecation for mapreduce.reduce.skip.proc.count.autoincr
Handling deprecation for mapreduce.ifile.readahead.bytes
Handling deprecation for dfs.http.policy
Handling deprecation for hadoop.registry.secure
Handling deprecation for dfs.namenode.safemode.min.datanodes
Handling deprecation for dfs.client.file-block-storage-locations.num-threads
Handling deprecation for mapreduce.cluster.local.dir
Handling deprecation for mapreduce.tasktracker.report.address
Handling deprecation for dfs.namenode.secondary.https-address
Handling deprecation for hadoop.kerberos.kinit.command
Handling deprecation for yarn.timeline-service.http-authentication.type
Handling deprecation for dfs.block.access.token.lifetime
Handling deprecation for dfs.webhdfs.enabled
Handling deprecation for dfs.namenode.delegation.token.max-lifetime
Handling deprecation for dfs.namenode.avoid.write.stale.datanode
Handling deprecation for dfs.datanode.drop.cache.behind.writes
Handling deprecation for yarn.log-aggregation.retain-seconds
Handling deprecation for mapreduce.job.complete.cancel.delegation.tokens
Handling deprecation for mapreduce.local.clientfactory.class.name
Handling deprecation for mapreduce.shuffle.connection-keep-alive.timeout
Handling deprecation for dfs.namenode.num.extra.edits.retained
Handling deprecation for yarn.scheduler.minimum-allocation-vcores
Handling deprecation for ipc.client.connect.max.retries.on.timeouts
Handling deprecation for yarn.timeline-service.client.retry-interval-ms
Handling deprecation for yarn.timeline-service.client.max-retries
Handling deprecation for fs.s3n.block.size
Handling deprecation for mapreduce.job.map.output.collector.class
Handling deprecation for ha.health-monitor.connect-retry-interval.ms
Handling deprecation for mapreduce.shuffle.max.threads
Handling deprecation for nfs.exports.allowed.hosts
Handling deprecation for dfs.client.mmap.cache.size
Handling deprecation for mapreduce.tasktracker.map.tasks.maximum
Handling deprecation for io.file.buffer.size
Handling deprecation for dfs.client.datanode-restart.timeout
Handling deprecation for io.mapfile.bloom.size
Handling deprecation for hadoop.security.kms.client.authentication.retry-count
Handling deprecation for dfs.namenode.checkpoint.txns
Handling deprecation for ipc.client.connect.retry.interval
Handling deprecation for dfs.client-write-packet-size
Handling deprecation for mapreduce.reduce.shuffle.connect.timeout
Handling deprecation for yarn.resourcemanager.fs.state-store.uri
Handling deprecation for fs.swift.impl
Handling deprecation for hadoop.registry.zk.connection.timeout.ms
Handling deprecation for mapred.queue.default.acl-administer-jobs
Handling deprecation for mapreduce.job.submithostaddress
Handling deprecation for dfs.cachereport.intervalMsec
Handling deprecation for yarn.app.mapreduce.shuffle.log.backups
Handling deprecation for yarn.app.mapreduce.am.container.log.limit.kb
Handling deprecation for yarn.nodemanager.resourcemanager.minimum.version
Handling deprecation for ftp.blocksize
Handling deprecation for yarn.resourcemanager.address
Handling deprecation for file.stream-buffer-size
Handling deprecation for yarn.resourcemanager.scheduler.monitor.enable
Handling deprecation for mapreduce.job.ubertask.maxreduces
Handling deprecation for nfs.allow.insecure.ports
Handling deprecation for yarn.sharedcache.nm.uploader.thread-count
Handling deprecation for ipc.client.idlethreshold
Handling deprecation for ftp.stream-buffer-size
Handling deprecation for yarn.sharedcache.client-server.address
Handling deprecation for dfs.client.failover.connection.retries.on.timeouts
Handling deprecation for dfs.namenode.replication.work.multiplier.per.iteration
Handling deprecation for hadoop.http.authentication.simple.anonymous.allowed
Handling deprecation for hadoop.security.authorization
Handling deprecation for yarn.client.nodemanager-connect.retry-interval-ms
Handling deprecation for yarn.am.liveness-monitor.expiry-interval-ms
Handling deprecation for fs.har.impl.disable.cache
Handling deprecation for yarn.nodemanager.linux-container-executor.resources-handler.class
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.read-cache-size
Handling deprecation for hadoop.security.authentication
Handling deprecation for dfs.image.compression.codec
Handling deprecation for mapreduce.task.files.preserve.failedtasks
Handling deprecation for dfs.client.read.shortcircuit.streams.cache.size
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.path
Handling deprecation for mapreduce.job.reduce.slowstart.completedmaps
Handling deprecation for mapreduce.jobhistory.minicluster.fixed.ports
Handling deprecation for file.replication
Handling deprecation for yarn.resourcemanager.ha.automatic-failover.enabled
Handling deprecation for mapreduce.job.userlog.retain.hours
Handling deprecation for mapreduce.jobhistory.joblist.cache.size
Handling deprecation for dfs.namenode.accesstime.precision
Handling deprecation for yarn.resourcemanager.work-preserving-recovery.enabled
Handling deprecation for dfs.namenode.fs-limits.max-xattrs-per-inode
Handling deprecation for io.mapfile.bloom.error.rate
Handling deprecation for yarn.resourcemanager.store.class
Handling deprecation for dfs.image.transfer.timeout
Handling deprecation for yarn.timeline-service.leveldb-state-store.path
Handling deprecation for nfs.wtmax
Handling deprecation for mapreduce.job.combine.class
Handling deprecation for dfs.namenode.support.allow.format
Handling deprecation for fs.s3a.multipart.purge
Handling deprecation for dfs.secondary.namenode.kerberos.internal.spnego.principal
Handling deprecation for fs.s3a.connection.establish.timeout
Handling deprecation for dfs.stream-buffer-size
Handling deprecation for dfs.namenode.invalidate.work.pct.per.iteration
Handling deprecation for yarn.nodemanager.container-executor.class
Handling deprecation for fs.s3a.multipart.purge.age
Handling deprecation for yarn.resourcemanager.scheduler.client.thread-count
Handling deprecation for dfs.namenode.top.enabled
Handling deprecation for yarn.app.mapreduce.shuffle.log.separate
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.low-watermark
Handling deprecation for fs.s3a.fast.buffer.size
Handling deprecation for hadoop.user.group.static.mapping.overrides
Handling deprecation for tfile.fs.input.buffer.size
Handling deprecation for dfs.client.cached.conn.retry
Handling deprecation for hadoop.http.authentication.type
Handling deprecation for dfs.namenode.list.encryption.zones.num.responses
Handling deprecation for mapreduce.map.cpu.vcores
Handling deprecation for dfs.namenode.path.based.cache.refresh.interval.ms
Handling deprecation for dfs.namenode.decommission.interval
Handling deprecation for dfs.namenode.fs-limits.max-directory-items
Handling deprecation for yarn.resourcemanager.zk-retry-interval-ms
Handling deprecation for ftp.bytes-per-checksum
Handling deprecation for dfs.ha.log-roll.period
Handling deprecation for dfs.user.home.dir.prefix
Handling deprecation for ipc.client.fallback-to-simple-auth-allowed
Handling deprecation for yarn.nodemanager.pmem-check-enabled
Handling deprecation for yarn.nodemanager.remote-app-log-dir
Handling deprecation for dfs.namenode.inotify.max.events.per.rpc
Handling deprecation for mapreduce.task.profile.maps
Handling deprecation for mapreduce.shuffle.ssl.file.buffer.size
Handling deprecation for mapreduce.tasktracker.healthchecker.script.timeout
Handling deprecation for yarn.timeline-service.webapp.https.address
Handling deprecation for yarn.nodemanager.resource.percentage-physical-cpu-limit
Handling deprecation for yarn.app.mapreduce.am.command-opts
Handling deprecation for dfs.namenode.fs-limits.max-xattr-size
Handling deprecation for dfs.datanode.http.address
Handling deprecation for dfs.namenode.blocks.per.postponedblocks.rescan
Handling deprecation for yarn.sharedcache.nm.uploader.replication.factor
Handling deprecation for hadoop.registry.zk.root
Handling deprecation for hadoop.jetty.logs.serve.aliases
Handling deprecation for yarn.client.failover-proxy-provider
Handling deprecation for mapreduce.jobhistory.admin.acl
Handling deprecation for yarn.app.mapreduce.am.hard-kill-timeout-ms
Handling deprecation for yarn.nodemanager.remote-app-log-dir-suffix
Handling deprecation for mapreduce.jobhistory.principal
Handling deprecation for yarn.resourcemanager.webapp.address
Handling deprecation for mapreduce.jobhistory.recovery.enable
Handling deprecation for yarn.sharedcache.store.in-memory.check-period-mins
Handling deprecation for nfs.mountd.port
Handling deprecation for mapreduce.reduce.merge.inmem.threshold
Handling deprecation for fs.df.interval
Handling deprecation for yarn.timeline-service.enabled
Handling deprecation for mapreduce.jobtracker.jobhistory.lru.cache.size
Handling deprecation for mapreduce.task.profile
Handling deprecation for mapreduce.job.output.key.class
Handling deprecation for yarn.nodemanager.hostname
Handling deprecation for dfs.namenode.num.checkpoints.retained
Handling deprecation for mapreduce.job.queuename
Handling deprecation for mapreduce.jobhistory.max-age-ms
Handling deprecation for mapreduce.job.token.tracking.ids.enabled
Handling deprecation for yarn.nodemanager.localizer.client.thread-count
Handling deprecation for yarn.sharedcache.uploader.server.thread-count
Handling deprecation for dfs.client.mmap.retry.timeout.ms
Handling deprecation for mapreduce.jobhistory.move.thread-count
Handling deprecation for dfs.permissions.enabled
Handling deprecation for dfs.blockreport.split.threshold
Handling deprecation for fs.AbstractFileSystem.hdfs.impl
Handling deprecation for dfs.datanode.balance.bandwidthPerSec
Handling deprecation for dfs.block.scanner.volume.bytes.per.second
Handling deprecation for hadoop.http.filter.initializers
Handling deprecation for yarn.timeline-service.http-authentication.simple.anonymous.allowed
Handling deprecation for dfs.default.chunk.view.size
Handling deprecation for yarn.sharedcache.client-server.thread-count
Handling deprecation for yarn.resourcemanager.resource-tracker.address
Handling deprecation for mapreduce.job.working.dir
Handling deprecation for mapreduce.jobhistory.datestring.cache.size
Handling deprecation for mapreduce.task.profile.params
Handling deprecation for dfs.namenode.decommission.blocks.per.interval
Handling deprecation for dfs.namenode.handler.count
Handling deprecation for dfs.image.transfer.bandwidthPerSec
Handling deprecation for rpc.metrics.quantile.enable
Handling deprecation for mapreduce.jobtracker.expire.trackers.interval
Handling deprecation for mapreduce.task.timeout
Handling deprecation for yarn.app.mapreduce.client.max-retries
Handling deprecation for yarn.nodemanager.resource.memory-mb
Handling deprecation for yarn.nodemanager.disk-health-checker.min-healthy-disks
Handling deprecation for dfs.datanode.failed.volumes.tolerated
Handling deprecation for yarn.timeline-service.handler-thread-count
Handling deprecation for ipc.server.listen.queue.size
Handling deprecation for fs.s3a.threads.max
Handling deprecation for yarn.resourcemanager.connect.max-wait.ms
Handling deprecation for mapreduce.fileoutputcommitter.algorithm.version
Handling deprecation for mapreduce.framework.name
Handling deprecation for mapreduce.map.skip.proc.count.autoincr
Handling deprecation for mapreduce.job.max.split.locations
Handling deprecation for yarn.resourcemanager.scheduler.class
Handling deprecation for yarn.resourcemanager.system-metrics-publisher.enabled
Handling deprecation for dfs.blocksize
Handling deprecation for yarn.sharedcache.nested-level
Handling deprecation for mapreduce.shuffle.connection-keep-alive.enable
Handling deprecation for fs.s3a.threads.keepalivetime
Handling deprecation for fs.s3a.connection.timeout
Handling deprecation for file.client-write-packet-size
Handling deprecation for ha.failover-controller.cli-check.rpc-timeout.ms
Handling deprecation for ha.zookeeper.acl
Handling deprecation for dfs.namenode.write.stale.datanode.ratio
Handling deprecation for dfs.encrypt.data.transfer
Handling deprecation for dfs.datanode.shared.file.descriptor.paths
Handling deprecation for mapreduce.input.lineinputformat.linespermap
Handling deprecation for yarn.resourcemanager.delayed.delegation-token.removal-interval-ms
Handling deprecation for yarn.nodemanager.localizer.fetch.thread-count
Handling deprecation for dfs.client.failover.max.attempts
Handling deprecation for yarn.resourcemanager.scheduler.address
Handling deprecation for dfs.client.read.shortcircuit.streams.cache.expiry.ms
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.start-time-write-cache-size
Handling deprecation for yarn.nodemanager.health-checker.script.timeout-ms
Handling deprecation for yarn.resourcemanager.fs.state-store.num-retries
Handling deprecation for hadoop.ssl.require.client.cert
Handling deprecation for hadoop.security.uid.cache.secs
Handling deprecation for mapreduce.jobhistory.keytab
Handling deprecation for dfs.client.read.shortcircuit.skip.checksum
Handling deprecation for yarn.resourcemanager.ha.automatic-failover.zk-base-path
Handling deprecation for mapreduce.shuffle.ssl.enabled
Handling deprecation for mapreduce.reduce.log.level
Handling deprecation for hadoop.registry.rm.enabled
Handling deprecation for mapreduce.tasktracker.dns.interface
Handling deprecation for yarn.resourcemanager.system-metrics-publisher.dispatcher.pool-size
Handling deprecation for mapreduce.job.speculative.speculative-cap-running-tasks
Handling deprecation for dfs.datanode.block.id.layout.upgrade.threads
Handling deprecation for dfs.datanode.use.datanode.hostname
Handling deprecation for dfs.client.context
Handling deprecation for yarn.resourcemanager.ha.enabled
Handling deprecation for mapred.reducer.new-api
Handling deprecation for dfs.namenode.delegation.token.renew-interval
Handling deprecation for dfs.blockreport.intervalMsec
Handling deprecation for fs.s3a.multipart.threshold
Handling deprecation for mapreduce.reduce.shuffle.memory.limit.percent
Handling deprecation for dfs.https.server.keystore.resource
Handling deprecation for io.map.index.skip
Handling deprecation for mapreduce.job.hdfs-servers
Handling deprecation for mapreduce.jobtracker.taskscheduler
Handling deprecation for dfs.namenode.kerberos.internal.spnego.principal
Handling deprecation for yarn.resourcemanager.state-store.max-completed-applications
Handling deprecation for mapreduce.map.output.compress
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.num.refill.threads
Handling deprecation for fs.s3n.multipart.uploads.block.size
Handling deprecation for mapreduce.task.merge.progress.records
Handling deprecation for dfs.datanode.dns.interface
Handling deprecation for map.sort.class
Handling deprecation for yarn.nodemanager.aux-services.mapreduce_shuffle.class
Handling deprecation for tfile.fs.output.buffer.size
Handling deprecation for fs.du.interval
Handling deprecation for dfs.client.failover.connection.retries
Handling deprecation for dfs.namenode.top.window.num.buckets
Handling deprecation for mapreduce.job.dir
Handling deprecation for fs.s3a.buffer.dir
Handling deprecation for mapreduce.reduce.shuffle.retry-delay.max.ms
Handling deprecation for yarn.sharedcache.uploader.server.address
Handling deprecation for mapreduce.client.progressmonitor.pollinterval
Handling deprecation for yarn.app.mapreduce.shuffle.log.limit.kb
Handling deprecation for dfs.datanode.max.locked.memory
Handling deprecation for dfs.namenode.retrycache.expirytime.millis
Handling deprecation for dfs.datanode.scan.period.hours
Handling deprecation for dfs.client.block.write.replace-datanode-on-failure.best-effort
Handling deprecation for mapreduce.jobhistory.move.interval-ms
Handling deprecation for dfs.ha.fencing.ssh.connect-timeout
Handling deprecation for yarn.nodemanager.log-aggregation.roll-monitoring-interval-seconds
Handling deprecation for dfs.namenode.fs-limits.max-component-length
Handling deprecation for hadoop.registry.zk.quorum
Handling deprecation for dfs.namenode.enable.retrycache
Handling deprecation for dfs.datanode.du.reserved
Handling deprecation for yarn.timeline-service.state-store-class
Handling deprecation for dfs.datanode.ipc.address
Handling deprecation for hadoop.registry.system.acls
Handling deprecation for dfs.client.block.write.replace-datanode-on-failure.policy
Handling deprecation for dfs.namenode.path.based.cache.retry.interval.ms
Handling deprecation for hadoop.security.crypto.cipher.suite
Handling deprecation for dfs.ha.tail-edits.period
Handling deprecation for mapreduce.task.profile.reduce.params
Handling deprecation for hadoop.registry.jaas.context
Handling deprecation for yarn.resourcemanager.hostname
Handling deprecation for mapreduce.reduce.memory.mb
Handling deprecation for hadoop.security.group.mapping.ldap.search.filter.group
Handling deprecation for hadoop.http.authentication.kerberos.principal
Handling deprecation for hadoop.security.group.mapping.ldap.search.filter.user
Handling deprecation for yarn.nodemanager.disk-health-checker.min-free-space-per-disk-mb
Handling deprecation for dfs.namenode.edits.dir
Handling deprecation for yarn.client.failover-retries-on-socket-timeouts
Handling deprecation for dfs.namenode.decommission.max.concurrent.tracked.nodes
Handling deprecation for mapreduce.client.completion.pollinterval
Handling deprecation for dfs.namenode.name.dir.restore
Handling deprecation for dfs.namenode.secondary.http-address
Handling deprecation for mapreduce.jobhistory.recovery.store.leveldb.path
Handling deprecation for yarn.sharedcache.store.class
Handling deprecation for s3.bytes-per-checksum
Handling deprecation for yarn.nodemanager.windows-container.cpu-limit.enabled
Handling deprecation for yarn.resourcemanager.webapp.https.address
Handling deprecation for yarn.nodemanager.vmem-pmem-ratio
Handling deprecation for dfs.namenode.checkpoint.period
Handling deprecation for dfs.ha.automatic-failover.enabled
The url to track the job: http://localhost:8080/
OutputCommitter set in config null
File Output Committer Algorithm version is 1
OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
Running job: job_local502431174_0002
/user/michaeljones/wcOutputAnalysis/_temporary/0: masked=rwxr-xr-x
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #35
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #35
Call: mkdirs took 6ms
Starting mapper thread pool executor.
Max local threads: 1
Map tasks to process: 1
Waiting for map tasks
Starting task: attempt_local502431174_0002_m_000000_0
currentIndex 0   0:0
mapreduce.cluster.local.dir for child : /tmp/hadoop-michaeljones/mapred/local/localRunner//michaeljones/jobcache/job_local502431174_0002/attempt_local502431174_0002_m_000000_0
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
using new api for output committer
File Output Committer Algorithm version is 1
ProcfsBasedProcessTree currently is supported only on Linux.
 Using ResourceCalculatorProcessTree : null
Processing split: hdfs://localhost:9000/user/michaeljones/wcInput:0+50
Trying map output collector class: org.apache.hadoop.mapred.MapTask$MapOutputBuffer
(EQUATOR) 0 kvi 26214396(104857584)
mapreduce.task.io.sort.mb: 100
soft limit at 83886080
bufstart = 0; bufvoid = 104857600
kvstart = 26214396; length = 6553600
Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #36
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #36
Call: getBlockLocations took 3ms
newInfo = LocatedBlocks{
  fileLength=50
  underConstruction=false
  blocks=[LocatedBlock{BP-1045030256-10.0.0.2-1433119149314:blk_1073741825_1002; getBlockSize()=50; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-b42c5705-9ba4-4b14-b00b-f9194bb036f0,DISK]]}]
  lastLocatedBlock=LocatedBlock{BP-1045030256-10.0.0.2-1433119149314:blk_1073741825_1002; getBlockSize()=50; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-b42c5705-9ba4-4b14-b00b-f9194bb036f0,DISK]]}
  isLastBlockComplete=true}
Connecting to datanode 127.0.0.1:50010

Starting flush of map output
Spilling map output
bufstart = 0; bufend = 82; bufvoid = 104857600
kvstart = 26214396(104857584); kvend = 26214368(104857472); length = 29/6553600
IntSumCombinerAnalyser-Bye[1]
IntSumCombinerAnalyser-Goodbye[1]
IntSumCombinerAnalyser-Hadoop[1,1]
IntSumCombinerAnalyser-Hello[1,1]
IntSumCombinerAnalyser-World[1,1]
Finished spill 0
Task:attempt_local502431174_0002_m_000000_0 is done. And is in the process of committing
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #37
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #37
Call: getFileInfo took 3ms
map
Task 'attempt_local502431174_0002_m_000000_0' done.
Finishing task: attempt_local502431174_0002_m_000000_0
map task executor complete.
Starting reduce thread pool executor.
Max local threads: 1
Reduce tasks to process: 1
Waiting for reduce tasks
Starting task: attempt_local502431174_0002_r_000000_0
currentIndex 0   0:0
mapreduce.cluster.local.dir for child : /tmp/hadoop-michaeljones/mapred/local/localRunner//michaeljones/jobcache/job_local502431174_0002/attempt_local502431174_0002_r_000000_0
using new api for output committer
File Output Committer Algorithm version is 1
ProcfsBasedProcessTree currently is supported only on Linux.
 Using ResourceCalculatorProcessTree : null
Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@52dfe1a4
MergerManager: memoryLimit=668309888, maxSingleShuffleLimit=167077472, mergeThreshold=441084544, ioSortFactor=10, memToMemMergeOutputsThreshold=10
attempt_local502431174_0002_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
Got 0 map completion events from 0
GetMapEventsThread about to sleep for 1000
LocalFetcher 2 going to fetch: attempt_local502431174_0002_m_000000_0
attempt_local502431174_0002_m_000000_0: Proceeding with shuffle since usedMemory (0) is lesser than memoryLimit (668309888).CommitMemory is (0)
localfetcher#2 about to shuffle output of map attempt_local502431174_0002_m_000000_0 decomp: 63 len: 67 to MEMORY
Read 63 bytes from map-output for attempt_local502431174_0002_m_000000_0
closeInMemoryFile -> map-output of size: 63, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->63
map attempt_local502431174_0002_m_000000_0 done 1 / 1 copied.
EventFetcher is interrupted.. Returning
1 / 1 copied.
finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
Merging 1 sorted segments
Down to the last merge-pass, with 1 segments left of total size: 57 bytes
Merged 1 segments, 63 bytes to disk to satisfy reduce memory limit
Disk file: /tmp/hadoop-michaeljones/mapred/local/localRunner/michaeljones/jobcache/job_local502431174_0002/attempt_local502431174_0002_r_000000_0/output/map_0.out.merged Length is 67
Merging 1 files, 67 bytes from disk
Merging 0 segments, 0 bytes from memory into reduce
Merging 1 sorted segments
Down to the last merge-pass, with 1 segments left of total size: 57 bytes
1 / 1 copied.
/user/michaeljones/wcOutputAnalysis/_temporary/0/_temporary/attempt_local502431174_0002_r_000000_0/part-r-00000: masked=rw-r--r--
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #38
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #38
Call: create took 4ms
computePacketChunkSize: src=/user/michaeljones/wcOutputAnalysis/_temporary/0/_temporary/attempt_local502431174_0002_r_000000_0/part-r-00000, chunkSize=516, chunksPerPacket=126, packetSize=65016
IntSumReducerAnalyser-Bye[1]
IntSumReducerAnalyser-Goodbye[1]
IntSumReducerAnalyser-Hadoop[2]
IntSumReducerAnalyser-Hello[2]
IntSumReducerAnalyser-World[2]
DFSClient writeChunk allocating new packet seqno=0, src=/user/michaeljones/wcOutputAnalysis/_temporary/0/_temporary/attempt_local502431174_0002_r_000000_0/part-r-00000, packetSize=65016, chunksPerPacket=126, bytesCurBlock=0
Queued packet 0
Queued packet 1
Waiting for ack for: 1
Allocating new block
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #39
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #39
Call: addBlock took 3ms
pipeline = DatanodeInfoWithStorage[127.0.0.1:50010,DS-b42c5705-9ba4-4b14-b00b-f9194bb036f0,DISK]
Connecting to datanode 127.0.0.1:50010
Send buf size 131072
SASL client skipping handshake in unsecured configuration for addr = /127.0.0.1, datanodeId = DatanodeInfoWithStorage[127.0.0.1:50010,DS-b42c5705-9ba4-4b14-b00b-f9194bb036f0,DISK]
DataStreamer block BP-1045030256-10.0.0.2-1433119149314:blk_1073742292_1469 sending packet packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 41
DFSClient seqno: 0 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
DataStreamer block BP-1045030256-10.0.0.2-1433119149314:blk_1073742292_1469 sending packet packet seqno: 1 offsetInBlock: 41 lastPacketInBlock: true lastByteOffsetInBlock: 41
DFSClient seqno: 1 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
Closing old block BP-1045030256-10.0.0.2-1433119149314:blk_1073742292_1469
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #40
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #40
Call: complete took 4ms
Task:attempt_local502431174_0002_r_000000_0 is done. And is in the process of committing
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #41
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #41
Call: getFileInfo took 2ms
1 / 1 copied.
Task attempt_local502431174_0002_r_000000_0 is allowed to commit now
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #42
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #42
Call: getFileInfo took 2ms
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #43
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #43
Call: getFileInfo took 2ms
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #44
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #44
Call: rename took 3ms
Saved output of task 'attempt_local502431174_0002_r_000000_0' to hdfs://localhost:9000/user/michaeljones/wcOutputAnalysis/_temporary/0/task_local502431174_0002_r_000000
reduce > reduce
Task 'attempt_local502431174_0002_r_000000_0' done.
Finishing task: attempt_local502431174_0002_r_000000_0
reduce task executor complete.
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #45
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #45
Call: getListing took 4ms
Merging data from FileStatus{path=hdfs://localhost:9000/user/michaeljones/wcOutputAnalysis/_temporary/0/task_local502431174_0002_r_000000; isDirectory=true; modification_time=1434180761479; access_time=0; owner=michaeljones; group=supergroup; permission=rwxr-xr-x; isSymlink=false} to hdfs://localhost:9000/user/michaeljones/wcOutputAnalysis
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #46
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #46
Call: getFileInfo took 2ms
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #47
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #47
Call: getListing took 2ms
Merging data from FileStatus{path=hdfs://localhost:9000/user/michaeljones/wcOutputAnalysis/_temporary/0/task_local502431174_0002_r_000000/part-r-00000; isDirectory=false; length=41; replication=1; blocksize=134217728; modification_time=1434180761500; access_time=1434180761479; owner=michaeljones; group=supergroup; permission=rw-r--r--; isSymlink=false} to hdfs://localhost:9000/user/michaeljones/wcOutputAnalysis/part-r-00000
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #48
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #48
Call: getFileInfo took 3ms
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #49
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #49
Call: rename took 4ms
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #50
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #50
Call: delete took 2ms
/user/michaeljones/wcOutputAnalysis/_SUCCESS: masked=rw-r--r--
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #51
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #51
Call: create took 3ms
computePacketChunkSize: src=/user/michaeljones/wcOutputAnalysis/_SUCCESS, chunkSize=516, chunksPerPacket=126, packetSize=65016
Waiting for ack for: -1
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #52
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #52
Call: complete took 3ms
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.fs.FileContext.getAbstractFileSystem(FileContext.java:331)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
Job job_local502431174_0002 running in uber mode : false
 map 100% reduce 100%
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.getTaskCompletionEvents(Job.java:670)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.getTaskCompletionEvents(Job.java:670)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
Job job_local502431174_0002 completed successfully
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.getCounters(Job.java:758)
Counters: 35
	File System Counters
		FILE: Number of bytes read=1206
		FILE: Number of bytes written=1128545
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=240
		HDFS: Number of bytes written=163
		HDFS: Number of read operations=45
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=24
	Map-Reduce Framework
		Map input records=2
		Map output records=8
		Map output bytes=82
		Map output materialized bytes=67
		Input split bytes=112
		Combine input records=8
		Combine output records=5
		Reduce input groups=5
		Reduce shuffle bytes=67
		Reduce input records=5
		Reduce output records=5
		Spilled Records=10
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=705691648
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=50
	File Output Format Counters 
		Bytes Written=41
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
testMain
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #53
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #53
Call: getFileInfo took 4ms
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #54
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #54
Call: delete took 7ms
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.connect(Job.java:1256)
Trying ClientProtocolProvider : org.apache.hadoop.mapred.LocalClientProtocolProvider
Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
Picked org.apache.hadoop.mapred.LocalClientProtocolProvider as the ClientProtocolProvider
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Cluster.getFileSystem(Cluster.java:162)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.submit(Job.java:1287)
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #55
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #55
Call: getFileInfo took 2ms
Configuring job job_local85066265_0003 with file:/tmp/hadoop-michaeljones/mapred/staging/michaeljones85066265/.staging/job_local85066265_0003 as the submit dir
adding the following namenodes' delegation tokens:[hdfs://localhost:9000]
Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
default FileSystem: file:///
No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
Creating splits at file:/tmp/hadoop-michaeljones/mapred/staging/michaeljones85066265/.staging/job_local85066265_0003
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #56
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #56
Call: getFileInfo took 2ms
Time taken to get FileStatuses: 2
Total input paths to process : 1
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #57
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #57
Call: getBlockLocations took 3ms
Total # of splits generated by getSplits: 1, TimeTaken: 7
number of splits:1
Handling deprecation for all properties in config...
Handling deprecation for mapreduce.jobtracker.address
Handling deprecation for yarn.resourcemanager.scheduler.monitor.policies
Handling deprecation for dfs.namenode.resource.check.interval
Handling deprecation for mapreduce.jobhistory.client.thread-count
Handling deprecation for yarn.app.mapreduce.am.containerlauncher.threadpool-initial-size
Handling deprecation for mapred.child.java.opts
Handling deprecation for mapreduce.jobtracker.retiredjobs.cache.size
Handling deprecation for dfs.client.https.need-auth
Handling deprecation for yarn.admin.acl
Handling deprecation for yarn.app.mapreduce.am.job.committer.cancel-timeout
Handling deprecation for mapreduce.job.emit-timeline-data
Handling deprecation for fs.ftp.host.port
Handling deprecation for dfs.namenode.avoid.read.stale.datanode
Handling deprecation for dfs.journalnode.rpc-address
Handling deprecation for mapreduce.job.end-notification.retry.attempts
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.ttl-interval-ms
Handling deprecation for yarn.resourcemanager.leveldb-state-store.path
Handling deprecation for mapred.mapper.new-api
Handling deprecation for yarn.ipc.rpc.class
Handling deprecation for ipc.client.connection.maxidletime
Handling deprecation for yarn.nodemanager.process-kill-wait.ms
Handling deprecation for mapreduce.cluster.acls.enabled
Handling deprecation for mapreduce.jobtracker.handler.count
Handling deprecation for io.map.index.interval
Handling deprecation for dfs.namenode.https-address
Handling deprecation for mapreduce.task.profile.reduces
Handling deprecation for fs.s3n.multipart.uploads.enabled
Handling deprecation for io.seqfile.sorter.recordlimit
Handling deprecation for mapreduce.job.ubertask.maxmaps
Handling deprecation for mapreduce.tasktracker.tasks.sleeptimebeforesigkill
Handling deprecation for hadoop.util.hash.type
Handling deprecation for dfs.namenode.replication.min
Handling deprecation for yarn.nodemanager.container-manager.thread-count
Handling deprecation for mapreduce.jobtracker.jobhistory.block.size
Handling deprecation for dfs.namenode.fs-limits.min-block-size
Handling deprecation for mapreduce.app-submission.cross-platform
Handling deprecation for fs.AbstractFileSystem.file.impl
Handling deprecation for net.topology.script.number.args
Handling deprecation for yarn.resourcemanager.container-tokens.master-key-rolling-interval-secs
Handling deprecation for mapreduce.map.output.compress.codec
Handling deprecation for mapreduce.job.reducer.preempt.delay.sec
Handling deprecation for s3native.bytes-per-checksum
Handling deprecation for dfs.namenode.path.based.cache.block.map.allocation.percent
Handling deprecation for yarn.nodemanager.windows-container.memory-limit.enabled
Handling deprecation for mapreduce.input.fileinputformat.split.minsize
Handling deprecation for hadoop.security.group.mapping
Handling deprecation for mapreduce.jobtracker.system.dir
Handling deprecation for mapreduce.job.end-notification.max.attempts
Handling deprecation for mapreduce.reduce.markreset.buffer.percent
Handling deprecation for dfs.datanode.cache.revocation.polling.ms
Handling deprecation for mapreduce.reduce.speculative
Handling deprecation for yarn.nodemanager.localizer.cache.cleanup.interval-ms
Handling deprecation for dfs.namenode.lazypersist.file.scrub.interval.sec
Handling deprecation for fs.s3a.threads.core
Handling deprecation for mapreduce.jobhistory.recovery.store.fs.uri
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.start-time-read-cache-size
Handling deprecation for hadoop.registry.zk.retry.interval.ms
Handling deprecation for yarn.nodemanager.keytab
Handling deprecation for dfs.namenode.replication.interval
Handling deprecation for yarn.resourcemanager.admin.address
Handling deprecation for mapreduce.job.maps
Handling deprecation for nfs.dump.dir
Handling deprecation for mapreduce.job.user.name
Handling deprecation for mapreduce.jobtracker.maxtasks.perjob
Handling deprecation for mapreduce.job.ubertask.enable
Handling deprecation for mapreduce.job.reduce.class
Handling deprecation for yarn.nodemanager.delete.debug-delay-sec
Handling deprecation for yarn.timeline-service.ttl-enable
Handling deprecation for yarn.resourcemanager.fs.state-store.retry-policy-spec
Handling deprecation for mapreduce.reduce.skip.maxgroups
Handling deprecation for dfs.client.use.datanode.hostname
Handling deprecation for fs.trash.interval
Handling deprecation for mapreduce.job.name
Handling deprecation for mapreduce.am.max-attempts
Handling deprecation for mapreduce.jobtracker.heartbeats.in.second
Handling deprecation for yarn.resourcemanager.zk-num-retries
Handling deprecation for s3.blocksize
Handling deprecation for dfs.datanode.data.dir
Handling deprecation for mapreduce.jobtracker.persist.jobstatus.active
Handling deprecation for mapreduce.reduce.shuffle.parallelcopies
Handling deprecation for fs.s3.buffer.dir
Handling deprecation for mapreduce.jobhistory.done-dir
Handling deprecation for hadoop.security.instrumentation.requires.admin
Handling deprecation for hadoop.registry.zk.retry.ceiling.ms
Handling deprecation for nfs.rtmax
Handling deprecation for dfs.datanode.data.dir.perm
Handling deprecation for yarn.resourcemanager.container.liveness-monitor.interval-ms
Handling deprecation for yarn.nodemanager.env-whitelist
Handling deprecation for dfs.namenode.backup.address
Handling deprecation for dfs.namenode.xattrs.enabled
Handling deprecation for dfs.datanode.readahead.bytes
Handling deprecation for mapreduce.jobhistory.cleaner.enable
Handling deprecation for dfs.client.block.write.retries
Handling deprecation for mapreduce.tasktracker.http.address
Handling deprecation for yarn.nodemanager.linux-container-executor.cgroups.hierarchy
Handling deprecation for ha.failover-controller.graceful-fence.connection.retries
Handling deprecation for yarn.resourcemanager.recovery.enabled
Handling deprecation for yarn.app.mapreduce.am.container.log.backups
Handling deprecation for dfs.namenode.safemode.threshold-pct
Handling deprecation for yarn.nodemanager.disk-health-checker.interval-ms
Handling deprecation for hadoop.security.java.secure.random.algorithm
Handling deprecation for dfs.namenode.list.cache.directives.num.responses
Handling deprecation for dfs.datanode.dns.nameserver
Handling deprecation for mapreduce.cluster.temp.dir
Handling deprecation for fs.s3a.max.total.tasks
Handling deprecation for mapreduce.reduce.maxattempts
Handling deprecation for mapreduce.client.submit.file.replication
Handling deprecation for mapreduce.shuffle.port
Handling deprecation for yarn.resourcemanager.resource-tracker.client.thread-count
Handling deprecation for dfs.namenode.replication.considerLoad
Handling deprecation for dfs.namenode.edits.journal-plugin.qjournal
Handling deprecation for dfs.client.write.exclude.nodes.cache.expiry.interval.millis
Handling deprecation for yarn.nodemanager.delete.thread-count
Handling deprecation for dfs.client.mmap.cache.timeout.ms
Handling deprecation for yarn.nodemanager.admin-env
Handling deprecation for io.skip.checksum.errors
Handling deprecation for yarn.timeline-service.hostname
Handling deprecation for yarn.resourcemanager.proxy-user-privileges.enabled
Handling deprecation for mapreduce.job.speculative.speculative-cap-total-tasks
Handling deprecation for yarn.acl.enable
Handling deprecation for fs.s3a.fast.upload
Handling deprecation for file.blocksize
Handling deprecation for mapreduce.job.speculative.slowtaskthreshold
Handling deprecation for ftp.replication
Handling deprecation for yarn.sharedcache.cleaner.initial-delay-mins
Handling deprecation for s3native.client-write-packet-size
Handling deprecation for hadoop.rpc.socket.factory.class.default
Handling deprecation for file.bytes-per-checksum
Handling deprecation for dfs.datanode.slow.io.warning.threshold.ms
Handling deprecation for io.seqfile.lazydecompress
Handling deprecation for mapreduce.task.skip.start.attempts
Handling deprecation for dfs.namenode.reject-unresolved-dn-topology-mapping
Handling deprecation for hadoop.common.configuration.version
Handling deprecation for yarn.resourcemanager.client.thread-count
Handling deprecation for dfs.datanode.drop.cache.behind.reads
Handling deprecation for yarn.sharedcache.admin.address
Handling deprecation for mapreduce.job.output.value.class
Handling deprecation for mapreduce.output.fileoutputformat.outputdir
Handling deprecation for mapreduce.jobtracker.taskcache.levels
Handling deprecation for yarn.nodemanager.linux-container-executor.nonsecure-mode.user-pattern
Handling deprecation for yarn.resourcemanager.zk-timeout-ms
Handling deprecation for yarn.resourcemanager.max-completed-applications
Handling deprecation for mapreduce.job.jvm.numtasks
Handling deprecation for yarn.sharedcache.cleaner.period-mins
Handling deprecation for mapreduce.jobtracker.tasktracker.maxblacklists
Handling deprecation for dfs.namenode.top.num.users
Handling deprecation for yarn.nodemanager.linux-container-executor.cgroups.mount
Handling deprecation for yarn.sharedcache.checksum.algo.impl
Handling deprecation for mapreduce.job.end-notification.max.retry.interval
Handling deprecation for mapreduce.job.acl-view-job
Handling deprecation for mapreduce.job.classloader
Handling deprecation for yarn.log-aggregation-enable
Handling deprecation for mapreduce.reduce.shuffle.fetch.retry.interval-ms
Handling deprecation for yarn.resourcemanager.nodemanager.minimum.version
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.size
Handling deprecation for yarn.app.mapreduce.am.job.task.listener.thread-count
Handling deprecation for yarn.app.mapreduce.am.resource.cpu-vcores
Handling deprecation for dfs.namenode.edit.log.autoroll.check.interval.ms
Handling deprecation for mapreduce.output.fileoutputformat.compress.type
Handling deprecation for hadoop.hdfs.configuration.version
Handling deprecation for hadoop.security.group.mapping.ldap.search.attr.member
Handling deprecation for yarn.nodemanager.log.retain-seconds
Handling deprecation for yarn.nodemanager.local-cache.max-files-per-directory
Handling deprecation for mapreduce.job.end-notification.retry.interval
Handling deprecation for hadoop.ssl.client.conf
Handling deprecation for yarn.sharedcache.root-dir
Handling deprecation for dfs.journalnode.https-address
Handling deprecation for mapreduce.reduce.shuffle.fetch.retry.timeout-ms
Handling deprecation for dfs.bytes-per-checksum
Handling deprecation for dfs.namenode.max.objects
Handling deprecation for mapreduce.tasktracker.instrumentation
Handling deprecation for dfs.datanode.max.transfer.threads
Handling deprecation for dfs.block.access.key.update.interval
Handling deprecation for mapreduce.jobtracker.jobhistory.task.numberprogresssplits
Handling deprecation for mapreduce.map.memory.mb
Handling deprecation for ha.failover-controller.new-active.rpc-timeout.ms
Handling deprecation for hadoop.ssl.hostname.verifier
Handling deprecation for dfs.client.read.shortcircuit
Handling deprecation for dfs.datanode.hdfs-blocks-metadata.enabled
Handling deprecation for mapreduce.tasktracker.healthchecker.interval
Handling deprecation for dfs.image.transfer.chunksize
Handling deprecation for mapreduce.tasktracker.taskmemorymanager.monitoringinterval
Handling deprecation for dfs.client.https.keystore.resource
Handling deprecation for yarn.resourcemanager.connect.retry-interval.ms
Handling deprecation for yarn.timeline-service.webapp.address
Handling deprecation for s3native.blocksize
Handling deprecation for yarn.scheduler.minimum-allocation-mb
Handling deprecation for yarn.sharedcache.cleaner.resource-sleep-ms
Handling deprecation for net.topology.impl
Handling deprecation for dfs.client.failover.sleep.base.millis
Handling deprecation for dfs.permissions.superusergroup
Handling deprecation for io.seqfile.compress.blocksize
Handling deprecation for hadoop.registry.zk.retry.times
Handling deprecation for fs.AbstractFileSystem.ftp.impl
Handling deprecation for dfs.namenode.checkpoint.edits.dir
Handling deprecation for mapreduce.job.running.reduce.limit
Handling deprecation for dfs.blockreport.initialDelay
Handling deprecation for dfs.namenode.heartbeat.recheck-interval
Handling deprecation for dfs.namenode.safemode.extension
Handling deprecation for yarn.scheduler.maximum-allocation-mb
Handling deprecation for mapreduce.job.reduce.shuffle.consumer.plugin.class
Handling deprecation for yarn.nodemanager.vmem-check-enabled
Handling deprecation for mapreduce.task.io.sort.factor
Handling deprecation for mapreduce.jobtracker.persist.jobstatus.dir
Handling deprecation for dfs.client.failover.sleep.max.millis
Handling deprecation for dfs.namenode.delegation.key.update-interval
Handling deprecation for hadoop.rpc.protection
Handling deprecation for fs.permissions.umask-mode
Handling deprecation for fs.s3.sleepTimeSeconds
Handling deprecation for ha.health-monitor.rpc-timeout.ms
Handling deprecation for hadoop.http.staticuser.user
Handling deprecation for fs.s3a.connection.maximum
Handling deprecation for yarn.nodemanager.linux-container-executor.nonsecure-mode.limit-users
Handling deprecation for fs.s3a.paging.maximum
Handling deprecation for fs.AbstractFileSystem.viewfs.impl
Handling deprecation for fs.ftp.host
Handling deprecation for yarn.nodemanager.linux-container-executor.nonsecure-mode.local-user
Handling deprecation for fs.s3a.impl
Handling deprecation for hadoop.http.authentication.kerberos.keytab
Handling deprecation for dfs.namenode.fs-limits.max-blocks-per-file
Handling deprecation for mapreduce.tasktracker.http.threads
Handling deprecation for mapreduce.tasktracker.dns.nameserver
Handling deprecation for yarn.resourcemanager.am-rm-tokens.master-key-rolling-interval-secs
Handling deprecation for dfs.client.block.write.replace-datanode-on-failure.enable
Handling deprecation for io.compression.codec.bzip2.library
Handling deprecation for mapreduce.map.skip.maxrecords
Handling deprecation for dfs.client.use.legacy.blockreader.local
Handling deprecation for dfs.namenode.checkpoint.dir
Handling deprecation for dfs.namenode.top.windows.minutes
Handling deprecation for mapreduce.job.maxtaskfailures.per.tracker
Handling deprecation for net.topology.node.switch.mapping.impl
Handling deprecation for mapreduce.shuffle.max.connections
Handling deprecation for mapreduce.jobhistory.loadedjobs.cache.size
Handling deprecation for dfs.storage.policy.enabled
Handling deprecation for yarn.client.application-client-protocol.poll-interval-ms
Handling deprecation for yarn.nodemanager.localizer.address
Handling deprecation for dfs.namenode.list.cache.pools.num.responses
Handling deprecation for nfs.server.port
Handling deprecation for mapreduce.client.output.filter
Handling deprecation for yarn.timeline-service.client.best-effort
Handling deprecation for ha.zookeeper.parent-znode
Handling deprecation for mapreduce.jobtracker.persist.jobstatus.hours
Handling deprecation for yarn.sharedcache.admin.thread-count
Handling deprecation for yarn.nodemanager.resource.cpu-vcores
Handling deprecation for dfs.datanode.block-pinning.enabled
Handling deprecation for mapreduce.jobhistory.http.policy
Handling deprecation for yarn.resourcemanager.webapp.delegation-token-auth-filter.enabled
Handling deprecation for mapreduce.job.speculative.retry-after-no-speculate
Handling deprecation for fs.s3a.attempts.maximum
Handling deprecation for s3native.stream-buffer-size
Handling deprecation for io.seqfile.local.dir
Handling deprecation for yarn.log-aggregation.retain-check-interval-seconds
Handling deprecation for fs.s3n.multipart.copy.block.size
Handling deprecation for dfs.encrypt.data.transfer.cipher.key.bitlength
Handling deprecation for dfs.datanode.sync.behind.writes
Handling deprecation for yarn.resourcemanager.zk-acl
Handling deprecation for hadoop.ssl.keystores.factory.class
Handling deprecation for mapreduce.job.split.metainfo.maxsize
Handling deprecation for fs.s3.maxRetries
Handling deprecation for hadoop.security.random.device.file.path
Handling deprecation for yarn.client.nodemanager-connect.max-wait-ms
Handling deprecation for dfs.namenode.stale.datanode.interval
Handling deprecation for mapreduce.task.io.sort.mb
Handling deprecation for yarn.resourcemanager.zk-state-store.parent-path
Handling deprecation for yarn.app.mapreduce.client-am.ipc.max-retries
Handling deprecation for fs.client.resolve.remote.symlinks
Handling deprecation for yarn.nodemanager.linux-container-executor.cgroups.strict-resource-usage
Handling deprecation for hadoop.ssl.enabled.protocols
Handling deprecation for mapreduce.reduce.cpu.vcores
Handling deprecation for yarn.client.failover-retries
Handling deprecation for mapreduce.jobhistory.address
Handling deprecation for hadoop.ssl.enabled
Handling deprecation for dfs.replication.max
Handling deprecation for dfs.namenode.name.dir
Handling deprecation for dfs.datanode.https.address
Handling deprecation for ipc.client.kill.max
Handling deprecation for mapreduce.job.committer.setup.cleanup.needed
Handling deprecation for dfs.client.domain.socket.data.traffic
Handling deprecation for yarn.nodemanager.localizer.cache.target-size-mb
Handling deprecation for yarn.resourcemanager.admin.client.thread-count
Handling deprecation for dfs.block.access.token.enable
Handling deprecation for mapreduce.job.speculative.retry-after-speculate
Handling deprecation for dfs.datanode.address
Handling deprecation for mapreduce.jobtracker.restart.recover
Handling deprecation for ipc.client.connect.max.retries
Handling deprecation for yarn.timeline-service.store-class
Handling deprecation for dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
Handling deprecation for hadoop.tmp.dir
Handling deprecation for dfs.datanode.handler.count
Handling deprecation for yarn.resourcemanager.ha.automatic-failover.embedded
Handling deprecation for yarn.timeline-service.ttl-ms
Handling deprecation for mapreduce.task.profile.map.params
Handling deprecation for yarn.resourcemanager.nodemanagers.heartbeat-interval-ms
Handling deprecation for mapreduce.map.speculative
Handling deprecation for yarn.timeline-service.recovery.enabled
Handling deprecation for mapreduce.job.map.class
Handling deprecation for dfs.namenode.resource.checked.volumes.minimum
Handling deprecation for yarn.nodemanager.recovery.dir
Handling deprecation for mapreduce.job.counters.max
Handling deprecation for yarn.resourcemanager.keytab
Handling deprecation for dfs.namenode.max.extra.edits.segments.retained
Handling deprecation for dfs.webhdfs.user.provider.user.pattern
Handling deprecation for dfs.client.mmap.enabled
Handling deprecation for mapreduce.map.log.level
Handling deprecation for dfs.client.file-block-storage-locations.timeout.millis
Handling deprecation for yarn.client.max-cached-nodemanagers-proxies
Handling deprecation for yarn.app.mapreduce.am.scheduler.heartbeat.interval-ms
Handling deprecation for hadoop.fuse.timer.period
Handling deprecation for fs.trash.checkpoint.interval
Handling deprecation for yarn.sharedcache.app-checker.class
Handling deprecation for dfs.journalnode.http-address
Handling deprecation for yarn.app.mapreduce.am.staging-dir
Handling deprecation for mapreduce.tasktracker.local.dir.minspacestart
Handling deprecation for yarn.nm.liveness-monitor.expiry-interval-ms
Handling deprecation for ha.health-monitor.check-interval.ms
Handling deprecation for mapreduce.reduce.shuffle.merge.percent
Handling deprecation for dfs.namenode.retrycache.heap.percent
Handling deprecation for yarn.nodemanager.docker-container-executor.exec-name
Handling deprecation for ipc.client.connect.timeout
Handling deprecation for yarn.resourcemanager.fs.state-store.retry-interval-ms
Handling deprecation for mapreduce.output.fileoutputformat.compress
Handling deprecation for yarn.nodemanager.local-dirs
Handling deprecation for yarn.nodemanager.recovery.enabled
Handling deprecation for io.native.lib.available
Handling deprecation for yarn.sharedcache.store.in-memory.staleness-period-mins
Handling deprecation for yarn.resourcemanager.am.max-attempts
Handling deprecation for s3.replication
Handling deprecation for mapreduce.input.fileinputformat.inputdir
Handling deprecation for fs.AbstractFileSystem.har.impl
Handling deprecation for dfs.image.compress
Handling deprecation for mapreduce.job.running.map.limit
Handling deprecation for mapreduce.reduce.input.buffer.percent
Handling deprecation for yarn.nodemanager.webapp.address
Handling deprecation for dfs.datanode.available-space-volume-choosing-policy.balanced-space-preference-fraction
Handling deprecation for dfs.namenode.edit.log.autoroll.multiplier.threshold
Handling deprecation for hadoop.security.group.mapping.ldap.ssl
Handling deprecation for dfs.namenode.checkpoint.check.period
Handling deprecation for fs.defaultFS
Handling deprecation for fs.s3a.multipart.size
Handling deprecation for dfs.client.slow.io.warning.threshold.ms
Handling deprecation for yarn.app.mapreduce.am.job.committer.commit-window
Handling deprecation for hadoop.security.group.mapping.ldap.search.attr.group.name
Handling deprecation for yarn.nodemanager.disk-health-checker.max-disk-utilization-per-disk-percentage
Handling deprecation for yarn.nodemanager.container-monitor.procfs-tree.smaps-based-rss.enabled
Handling deprecation for mapreduce.job.submithostname
Handling deprecation for mapreduce.map.sort.spill.percent
Handling deprecation for hadoop.security.crypto.codec.classes.aes.ctr.nopadding
Handling deprecation for dfs.namenode.http-address
Handling deprecation for hadoop.security.groups.negative-cache.secs
Handling deprecation for hadoop.ssl.server.conf
Handling deprecation for mapreduce.ifile.readahead
Handling deprecation for s3native.replication
Handling deprecation for yarn.client.nodemanager-client-async.thread-pool-max-size
Handling deprecation for mapreduce.jobtracker.staging.root.dir
Handling deprecation for mapreduce.jobhistory.admin.address
Handling deprecation for dfs.namenode.startup.delay.block.deletion.sec
Handling deprecation for yarn.nodemanager.health-checker.interval-ms
Handling deprecation for dfs.namenode.checkpoint.max-retries
Handling deprecation for s3.stream-buffer-size
Handling deprecation for ftp.client-write-packet-size
Handling deprecation for dfs.datanode.fsdatasetcache.max.threads.per.volume
Handling deprecation for mapreduce.output.fileoutputformat.compress.codec
Handling deprecation for yarn.timeline-service.keytab
Handling deprecation for yarn.sharedcache.store.in-memory.initial-delay-mins
Handling deprecation for mapreduce.jobhistory.webapp.address
Handling deprecation for mapreduce.task.userlog.limit.kb
Handling deprecation for mapreduce.reduce.shuffle.fetch.retry.enabled
Handling deprecation for yarn.app.mapreduce.task.container.log.backups
Handling deprecation for dfs.heartbeat.interval
Handling deprecation for ha.zookeeper.session-timeout.ms
Handling deprecation for fs.s3a.connection.ssl.enabled
Handling deprecation for yarn.sharedcache.webapp.address
Handling deprecation for hadoop.http.authentication.signature.secret.file
Handling deprecation for hadoop.fuse.connection.timeout
Handling deprecation for mapreduce.input.fileinputformat.numinputfiles
Handling deprecation for yarn.nodemanager.log-aggregation.compression-type
Handling deprecation for ipc.server.max.connections
Handling deprecation for yarn.resourcemanager.work-preserving-recovery.scheduling-wait-ms
Handling deprecation for yarn.nodemanager.log-dirs
Handling deprecation for yarn.app.mapreduce.am.resource.mb
Handling deprecation for hadoop.security.groups.cache.secs
Handling deprecation for mapreduce.job.speculative.minimum-allowed-tasks
Handling deprecation for yarn.nodemanager.container-monitor.interval-ms
Handling deprecation for dfs.datanode.cache.revocation.timeout.ms
Handling deprecation for mapreduce.jobhistory.recovery.store.class
Handling deprecation for mapreduce.task.combine.progress.records
Handling deprecation for s3.client-write-packet-size
Handling deprecation for mapreduce.jobtracker.instrumentation
Handling deprecation for dfs.replication
Handling deprecation for mapreduce.shuffle.transfer.buffer.size
Handling deprecation for hadoop.security.group.mapping.ldap.directory.search.timeout
Handling deprecation for dfs.datanode.available-space-volume-choosing-policy.balanced-space-threshold
Handling deprecation for hadoop.work.around.non.threadsafe.getpwuid
Handling deprecation for yarn.app.mapreduce.client-am.ipc.max-retries-on-timeouts
Handling deprecation for yarn.nodemanager.address
Handling deprecation for mapreduce.tasktracker.taskcontroller
Handling deprecation for mapreduce.tasktracker.indexcache.mb
Handling deprecation for yarn.scheduler.maximum-allocation-vcores
Handling deprecation for mapreduce.job.reduces
Handling deprecation for yarn.nodemanager.sleep-delay-before-sigkill.ms
Handling deprecation for yarn.timeline-service.address
Handling deprecation for yarn.resourcemanager.configuration.provider-class
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.expiry
Handling deprecation for yarn.sharedcache.enabled
Handling deprecation for tfile.io.chunk.size
Handling deprecation for mapreduce.job.acl-modify-job
Handling deprecation for hadoop.registry.zk.session.timeout.ms
Handling deprecation for fs.automatic.close
Handling deprecation for ha.health-monitor.sleep-after-disconnect.ms
Handling deprecation for mapreduce.tasktracker.reduce.tasks.maximum
Handling deprecation for mapreduce.input.fileinputformat.list-status.num-threads
Handling deprecation for dfs.datanode.directoryscan.threads
Handling deprecation for dfs.datanode.directoryscan.interval
Handling deprecation for dfs.namenode.acls.enabled
Handling deprecation for dfs.client.short.circuit.replica.stale.threshold.ms
Handling deprecation for hadoop.http.authentication.token.validity
Handling deprecation for fs.s3.block.size
Handling deprecation for ha.failover-controller.graceful-fence.rpc-timeout.ms
Handling deprecation for mapreduce.tasktracker.local.dir.minspacekill
Handling deprecation for dfs.namenode.resource.du.reserved
Handling deprecation for mapreduce.jobhistory.cleaner.interval-ms
Handling deprecation for dfs.namenode.datanode.registration.ip-hostname-check
Handling deprecation for mapreduce.jobhistory.intermediate-done-dir
Handling deprecation for mapreduce.jobtracker.http.address
Handling deprecation for dfs.namenode.backup.http-address
Handling deprecation for dfs.namenode.edits.noeditlogchannelflush
Handling deprecation for mapreduce.reduce.shuffle.input.buffer.percent
Handling deprecation for mapreduce.map.maxattempts
Handling deprecation for yarn.http.policy
Handling deprecation for dfs.namenode.audit.loggers
Handling deprecation for hadoop.security.groups.cache.warn.after.ms
Handling deprecation for io.serializations
Handling deprecation for mapreduce.tasktracker.outofband.heartbeat
Handling deprecation for mapreduce.reduce.shuffle.read.timeout
Handling deprecation for hadoop.security.crypto.buffer.size
Handling deprecation for mapreduce.reduce.skip.proc.count.autoincr
Handling deprecation for mapreduce.ifile.readahead.bytes
Handling deprecation for dfs.http.policy
Handling deprecation for hadoop.registry.secure
Handling deprecation for dfs.namenode.safemode.min.datanodes
Handling deprecation for dfs.client.file-block-storage-locations.num-threads
Handling deprecation for mapreduce.cluster.local.dir
Handling deprecation for mapreduce.tasktracker.report.address
Handling deprecation for dfs.namenode.secondary.https-address
Handling deprecation for hadoop.kerberos.kinit.command
Handling deprecation for yarn.timeline-service.http-authentication.type
Handling deprecation for dfs.block.access.token.lifetime
Handling deprecation for dfs.webhdfs.enabled
Handling deprecation for dfs.namenode.delegation.token.max-lifetime
Handling deprecation for dfs.namenode.avoid.write.stale.datanode
Handling deprecation for dfs.datanode.drop.cache.behind.writes
Handling deprecation for yarn.log-aggregation.retain-seconds
Handling deprecation for mapreduce.job.complete.cancel.delegation.tokens
Handling deprecation for mapreduce.local.clientfactory.class.name
Handling deprecation for mapreduce.shuffle.connection-keep-alive.timeout
Handling deprecation for dfs.namenode.num.extra.edits.retained
Handling deprecation for yarn.scheduler.minimum-allocation-vcores
Handling deprecation for ipc.client.connect.max.retries.on.timeouts
Handling deprecation for yarn.timeline-service.client.retry-interval-ms
Handling deprecation for yarn.timeline-service.client.max-retries
Handling deprecation for fs.s3n.block.size
Handling deprecation for mapreduce.job.map.output.collector.class
Handling deprecation for ha.health-monitor.connect-retry-interval.ms
Handling deprecation for mapreduce.shuffle.max.threads
Handling deprecation for nfs.exports.allowed.hosts
Handling deprecation for dfs.client.mmap.cache.size
Handling deprecation for mapreduce.tasktracker.map.tasks.maximum
Handling deprecation for io.file.buffer.size
Handling deprecation for dfs.client.datanode-restart.timeout
Handling deprecation for io.mapfile.bloom.size
Handling deprecation for hadoop.security.kms.client.authentication.retry-count
Handling deprecation for dfs.namenode.checkpoint.txns
Handling deprecation for ipc.client.connect.retry.interval
Handling deprecation for dfs.client-write-packet-size
Handling deprecation for mapreduce.reduce.shuffle.connect.timeout
Handling deprecation for yarn.resourcemanager.fs.state-store.uri
Handling deprecation for fs.swift.impl
Handling deprecation for hadoop.registry.zk.connection.timeout.ms
Handling deprecation for mapred.queue.default.acl-administer-jobs
Handling deprecation for mapreduce.job.submithostaddress
Handling deprecation for dfs.cachereport.intervalMsec
Handling deprecation for yarn.app.mapreduce.shuffle.log.backups
Handling deprecation for yarn.app.mapreduce.am.container.log.limit.kb
Handling deprecation for yarn.nodemanager.resourcemanager.minimum.version
Handling deprecation for ftp.blocksize
Handling deprecation for yarn.resourcemanager.address
Handling deprecation for file.stream-buffer-size
Handling deprecation for yarn.resourcemanager.scheduler.monitor.enable
Handling deprecation for mapreduce.job.ubertask.maxreduces
Handling deprecation for nfs.allow.insecure.ports
Handling deprecation for yarn.sharedcache.nm.uploader.thread-count
Handling deprecation for ipc.client.idlethreshold
Handling deprecation for ftp.stream-buffer-size
Handling deprecation for yarn.sharedcache.client-server.address
Handling deprecation for dfs.client.failover.connection.retries.on.timeouts
Handling deprecation for dfs.namenode.replication.work.multiplier.per.iteration
Handling deprecation for hadoop.http.authentication.simple.anonymous.allowed
Handling deprecation for hadoop.security.authorization
Handling deprecation for yarn.client.nodemanager-connect.retry-interval-ms
Handling deprecation for yarn.am.liveness-monitor.expiry-interval-ms
Handling deprecation for fs.har.impl.disable.cache
Handling deprecation for yarn.nodemanager.linux-container-executor.resources-handler.class
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.read-cache-size
Handling deprecation for hadoop.security.authentication
Handling deprecation for dfs.image.compression.codec
Handling deprecation for mapreduce.task.files.preserve.failedtasks
Handling deprecation for dfs.client.read.shortcircuit.streams.cache.size
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.path
Handling deprecation for mapreduce.job.reduce.slowstart.completedmaps
Handling deprecation for mapreduce.jobhistory.minicluster.fixed.ports
Handling deprecation for file.replication
Handling deprecation for yarn.resourcemanager.ha.automatic-failover.enabled
Handling deprecation for mapreduce.job.userlog.retain.hours
Handling deprecation for mapreduce.jobhistory.joblist.cache.size
Handling deprecation for dfs.namenode.accesstime.precision
Handling deprecation for yarn.resourcemanager.work-preserving-recovery.enabled
Handling deprecation for dfs.namenode.fs-limits.max-xattrs-per-inode
Handling deprecation for io.mapfile.bloom.error.rate
Handling deprecation for yarn.resourcemanager.store.class
Handling deprecation for dfs.image.transfer.timeout
Handling deprecation for yarn.timeline-service.leveldb-state-store.path
Handling deprecation for nfs.wtmax
Handling deprecation for mapreduce.job.combine.class
Handling deprecation for dfs.namenode.support.allow.format
Handling deprecation for fs.s3a.multipart.purge
Handling deprecation for dfs.secondary.namenode.kerberos.internal.spnego.principal
Handling deprecation for fs.s3a.connection.establish.timeout
Handling deprecation for dfs.stream-buffer-size
Handling deprecation for dfs.namenode.invalidate.work.pct.per.iteration
Handling deprecation for yarn.nodemanager.container-executor.class
Handling deprecation for fs.s3a.multipart.purge.age
Handling deprecation for yarn.resourcemanager.scheduler.client.thread-count
Handling deprecation for dfs.namenode.top.enabled
Handling deprecation for yarn.app.mapreduce.shuffle.log.separate
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.low-watermark
Handling deprecation for fs.s3a.fast.buffer.size
Handling deprecation for hadoop.user.group.static.mapping.overrides
Handling deprecation for tfile.fs.input.buffer.size
Handling deprecation for dfs.client.cached.conn.retry
Handling deprecation for hadoop.http.authentication.type
Handling deprecation for dfs.namenode.list.encryption.zones.num.responses
Handling deprecation for mapreduce.map.cpu.vcores
Handling deprecation for dfs.namenode.path.based.cache.refresh.interval.ms
Handling deprecation for dfs.namenode.decommission.interval
Handling deprecation for dfs.namenode.fs-limits.max-directory-items
Handling deprecation for yarn.resourcemanager.zk-retry-interval-ms
Handling deprecation for ftp.bytes-per-checksum
Handling deprecation for dfs.ha.log-roll.period
Handling deprecation for dfs.user.home.dir.prefix
Handling deprecation for ipc.client.fallback-to-simple-auth-allowed
Handling deprecation for yarn.nodemanager.pmem-check-enabled
Handling deprecation for yarn.nodemanager.remote-app-log-dir
Handling deprecation for dfs.namenode.inotify.max.events.per.rpc
Handling deprecation for mapreduce.task.profile.maps
Handling deprecation for mapreduce.shuffle.ssl.file.buffer.size
Handling deprecation for mapreduce.tasktracker.healthchecker.script.timeout
Handling deprecation for yarn.timeline-service.webapp.https.address
Handling deprecation for yarn.nodemanager.resource.percentage-physical-cpu-limit
Handling deprecation for yarn.app.mapreduce.am.command-opts
Handling deprecation for dfs.namenode.fs-limits.max-xattr-size
Handling deprecation for dfs.datanode.http.address
Handling deprecation for dfs.namenode.blocks.per.postponedblocks.rescan
Handling deprecation for yarn.sharedcache.nm.uploader.replication.factor
Handling deprecation for hadoop.registry.zk.root
Handling deprecation for hadoop.jetty.logs.serve.aliases
Handling deprecation for yarn.client.failover-proxy-provider
Handling deprecation for mapreduce.jobhistory.admin.acl
Handling deprecation for yarn.app.mapreduce.am.hard-kill-timeout-ms
Handling deprecation for yarn.nodemanager.remote-app-log-dir-suffix
Handling deprecation for mapreduce.jobhistory.principal
Handling deprecation for yarn.resourcemanager.webapp.address
Handling deprecation for mapreduce.jobhistory.recovery.enable
Handling deprecation for yarn.sharedcache.store.in-memory.check-period-mins
Handling deprecation for nfs.mountd.port
Handling deprecation for mapreduce.reduce.merge.inmem.threshold
Handling deprecation for fs.df.interval
Handling deprecation for yarn.timeline-service.enabled
Handling deprecation for mapreduce.jobtracker.jobhistory.lru.cache.size
Handling deprecation for mapreduce.task.profile
Handling deprecation for mapreduce.job.output.key.class
Handling deprecation for yarn.nodemanager.hostname
Handling deprecation for dfs.namenode.num.checkpoints.retained
Handling deprecation for mapreduce.job.queuename
Handling deprecation for mapreduce.jobhistory.max-age-ms
Handling deprecation for mapreduce.job.token.tracking.ids.enabled
Handling deprecation for yarn.nodemanager.localizer.client.thread-count
Handling deprecation for yarn.sharedcache.uploader.server.thread-count
Handling deprecation for dfs.client.mmap.retry.timeout.ms
Handling deprecation for mapreduce.jobhistory.move.thread-count
Handling deprecation for dfs.permissions.enabled
Handling deprecation for dfs.blockreport.split.threshold
Handling deprecation for fs.AbstractFileSystem.hdfs.impl
Handling deprecation for dfs.datanode.balance.bandwidthPerSec
Handling deprecation for dfs.block.scanner.volume.bytes.per.second
Handling deprecation for hadoop.http.filter.initializers
Handling deprecation for yarn.timeline-service.http-authentication.simple.anonymous.allowed
Handling deprecation for dfs.default.chunk.view.size
Handling deprecation for yarn.sharedcache.client-server.thread-count
Handling deprecation for yarn.resourcemanager.resource-tracker.address
Handling deprecation for mapreduce.job.working.dir
Handling deprecation for mapreduce.jobhistory.datestring.cache.size
Handling deprecation for mapreduce.task.profile.params
Handling deprecation for dfs.namenode.decommission.blocks.per.interval
Handling deprecation for dfs.namenode.handler.count
Handling deprecation for dfs.image.transfer.bandwidthPerSec
Handling deprecation for rpc.metrics.quantile.enable
Handling deprecation for mapreduce.jobtracker.expire.trackers.interval
Handling deprecation for mapreduce.task.timeout
Handling deprecation for yarn.app.mapreduce.client.max-retries
Handling deprecation for yarn.nodemanager.resource.memory-mb
Handling deprecation for yarn.nodemanager.disk-health-checker.min-healthy-disks
Handling deprecation for dfs.datanode.failed.volumes.tolerated
Handling deprecation for yarn.timeline-service.handler-thread-count
Handling deprecation for ipc.server.listen.queue.size
Handling deprecation for fs.s3a.threads.max
Handling deprecation for yarn.resourcemanager.connect.max-wait.ms
Handling deprecation for mapreduce.fileoutputcommitter.algorithm.version
Handling deprecation for mapreduce.framework.name
Handling deprecation for mapreduce.map.skip.proc.count.autoincr
Handling deprecation for mapreduce.job.max.split.locations
Handling deprecation for yarn.resourcemanager.scheduler.class
Handling deprecation for yarn.resourcemanager.system-metrics-publisher.enabled
Handling deprecation for dfs.blocksize
Handling deprecation for yarn.sharedcache.nested-level
Handling deprecation for mapreduce.shuffle.connection-keep-alive.enable
Handling deprecation for fs.s3a.threads.keepalivetime
Handling deprecation for fs.s3a.connection.timeout
Handling deprecation for file.client-write-packet-size
Handling deprecation for ha.failover-controller.cli-check.rpc-timeout.ms
Handling deprecation for ha.zookeeper.acl
Handling deprecation for dfs.namenode.write.stale.datanode.ratio
Handling deprecation for dfs.encrypt.data.transfer
Handling deprecation for dfs.datanode.shared.file.descriptor.paths
Handling deprecation for mapreduce.input.lineinputformat.linespermap
Handling deprecation for yarn.resourcemanager.delayed.delegation-token.removal-interval-ms
Handling deprecation for yarn.nodemanager.localizer.fetch.thread-count
Handling deprecation for dfs.client.failover.max.attempts
Handling deprecation for yarn.resourcemanager.scheduler.address
Handling deprecation for dfs.client.read.shortcircuit.streams.cache.expiry.ms
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.start-time-write-cache-size
Handling deprecation for yarn.nodemanager.health-checker.script.timeout-ms
Handling deprecation for yarn.resourcemanager.fs.state-store.num-retries
Handling deprecation for hadoop.ssl.require.client.cert
Handling deprecation for hadoop.security.uid.cache.secs
Handling deprecation for mapreduce.jobhistory.keytab
Handling deprecation for dfs.client.read.shortcircuit.skip.checksum
Handling deprecation for yarn.resourcemanager.ha.automatic-failover.zk-base-path
Handling deprecation for mapreduce.shuffle.ssl.enabled
Handling deprecation for mapreduce.reduce.log.level
Handling deprecation for hadoop.registry.rm.enabled
Handling deprecation for mapreduce.tasktracker.dns.interface
Handling deprecation for yarn.resourcemanager.system-metrics-publisher.dispatcher.pool-size
Handling deprecation for mapreduce.job.speculative.speculative-cap-running-tasks
Handling deprecation for dfs.datanode.block.id.layout.upgrade.threads
Handling deprecation for dfs.datanode.use.datanode.hostname
Handling deprecation for dfs.client.context
Handling deprecation for yarn.resourcemanager.ha.enabled
Handling deprecation for mapred.reducer.new-api
Handling deprecation for dfs.namenode.delegation.token.renew-interval
Handling deprecation for dfs.blockreport.intervalMsec
Handling deprecation for fs.s3a.multipart.threshold
Handling deprecation for mapreduce.reduce.shuffle.memory.limit.percent
Handling deprecation for dfs.https.server.keystore.resource
Handling deprecation for io.map.index.skip
Handling deprecation for mapreduce.job.hdfs-servers
Handling deprecation for mapreduce.jobtracker.taskscheduler
Handling deprecation for dfs.namenode.kerberos.internal.spnego.principal
Handling deprecation for yarn.resourcemanager.state-store.max-completed-applications
Handling deprecation for mapreduce.map.output.compress
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.num.refill.threads
Handling deprecation for fs.s3n.multipart.uploads.block.size
Handling deprecation for mapreduce.task.merge.progress.records
Handling deprecation for dfs.datanode.dns.interface
Handling deprecation for map.sort.class
Handling deprecation for yarn.nodemanager.aux-services.mapreduce_shuffle.class
Handling deprecation for tfile.fs.output.buffer.size
Handling deprecation for fs.du.interval
Handling deprecation for dfs.client.failover.connection.retries
Handling deprecation for dfs.namenode.top.window.num.buckets
Handling deprecation for mapreduce.job.dir
Handling deprecation for fs.s3a.buffer.dir
Handling deprecation for mapreduce.reduce.shuffle.retry-delay.max.ms
Handling deprecation for yarn.sharedcache.uploader.server.address
Handling deprecation for mapreduce.client.progressmonitor.pollinterval
Handling deprecation for yarn.app.mapreduce.shuffle.log.limit.kb
Handling deprecation for dfs.datanode.max.locked.memory
Handling deprecation for dfs.namenode.retrycache.expirytime.millis
Handling deprecation for dfs.datanode.scan.period.hours
Handling deprecation for dfs.client.block.write.replace-datanode-on-failure.best-effort
Handling deprecation for mapreduce.jobhistory.move.interval-ms
Handling deprecation for dfs.ha.fencing.ssh.connect-timeout
Handling deprecation for yarn.nodemanager.log-aggregation.roll-monitoring-interval-seconds
Handling deprecation for dfs.namenode.fs-limits.max-component-length
Handling deprecation for hadoop.registry.zk.quorum
Handling deprecation for dfs.namenode.enable.retrycache
Handling deprecation for dfs.datanode.du.reserved
Handling deprecation for yarn.timeline-service.state-store-class
Handling deprecation for dfs.datanode.ipc.address
Handling deprecation for hadoop.registry.system.acls
Handling deprecation for dfs.client.block.write.replace-datanode-on-failure.policy
Handling deprecation for dfs.namenode.path.based.cache.retry.interval.ms
Handling deprecation for hadoop.security.crypto.cipher.suite
Handling deprecation for dfs.ha.tail-edits.period
Handling deprecation for mapreduce.task.profile.reduce.params
Handling deprecation for hadoop.registry.jaas.context
Handling deprecation for yarn.resourcemanager.hostname
Handling deprecation for mapreduce.reduce.memory.mb
Handling deprecation for hadoop.security.group.mapping.ldap.search.filter.group
Handling deprecation for hadoop.http.authentication.kerberos.principal
Handling deprecation for hadoop.security.group.mapping.ldap.search.filter.user
Handling deprecation for yarn.nodemanager.disk-health-checker.min-free-space-per-disk-mb
Handling deprecation for dfs.namenode.edits.dir
Handling deprecation for yarn.client.failover-retries-on-socket-timeouts
Handling deprecation for dfs.namenode.decommission.max.concurrent.tracked.nodes
Handling deprecation for mapreduce.client.completion.pollinterval
Handling deprecation for dfs.namenode.name.dir.restore
Handling deprecation for dfs.namenode.secondary.http-address
Handling deprecation for mapreduce.jobhistory.recovery.store.leveldb.path
Handling deprecation for yarn.sharedcache.store.class
Handling deprecation for s3.bytes-per-checksum
Handling deprecation for yarn.nodemanager.windows-container.cpu-limit.enabled
Handling deprecation for yarn.resourcemanager.webapp.https.address
Handling deprecation for yarn.nodemanager.vmem-pmem-ratio
Handling deprecation for dfs.namenode.checkpoint.period
Handling deprecation for dfs.ha.automatic-failover.enabled
Submitting tokens for job: job_local85066265_0003
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.fs.FileContext.getAbstractFileSystem(FileContext.java:331)
Handling deprecation for all properties in config...
Handling deprecation for mapreduce.jobtracker.address
Handling deprecation for yarn.resourcemanager.scheduler.monitor.policies
Handling deprecation for dfs.namenode.resource.check.interval
Handling deprecation for mapreduce.jobhistory.client.thread-count
Handling deprecation for yarn.app.mapreduce.am.containerlauncher.threadpool-initial-size
Handling deprecation for mapred.child.java.opts
Handling deprecation for mapreduce.jobtracker.retiredjobs.cache.size
Handling deprecation for dfs.client.https.need-auth
Handling deprecation for yarn.admin.acl
Handling deprecation for yarn.app.mapreduce.am.job.committer.cancel-timeout
Handling deprecation for mapreduce.job.emit-timeline-data
Handling deprecation for fs.ftp.host.port
Handling deprecation for dfs.namenode.avoid.read.stale.datanode
Handling deprecation for dfs.journalnode.rpc-address
Handling deprecation for mapreduce.job.end-notification.retry.attempts
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.ttl-interval-ms
Handling deprecation for yarn.resourcemanager.leveldb-state-store.path
Handling deprecation for mapred.mapper.new-api
Handling deprecation for yarn.ipc.rpc.class
Handling deprecation for ipc.client.connection.maxidletime
Handling deprecation for yarn.nodemanager.process-kill-wait.ms
Handling deprecation for mapreduce.cluster.acls.enabled
Handling deprecation for mapreduce.jobtracker.handler.count
Handling deprecation for io.map.index.interval
Handling deprecation for dfs.namenode.https-address
Handling deprecation for mapreduce.task.profile.reduces
Handling deprecation for fs.s3n.multipart.uploads.enabled
Handling deprecation for io.seqfile.sorter.recordlimit
Handling deprecation for mapreduce.job.ubertask.maxmaps
Handling deprecation for mapreduce.tasktracker.tasks.sleeptimebeforesigkill
Handling deprecation for hadoop.util.hash.type
Handling deprecation for dfs.namenode.replication.min
Handling deprecation for yarn.nodemanager.container-manager.thread-count
Handling deprecation for mapreduce.jobtracker.jobhistory.block.size
Handling deprecation for dfs.namenode.fs-limits.min-block-size
Handling deprecation for mapreduce.app-submission.cross-platform
Handling deprecation for fs.AbstractFileSystem.file.impl
Handling deprecation for net.topology.script.number.args
Handling deprecation for yarn.resourcemanager.container-tokens.master-key-rolling-interval-secs
Handling deprecation for mapreduce.map.output.compress.codec
Handling deprecation for mapreduce.job.reducer.preempt.delay.sec
Handling deprecation for s3native.bytes-per-checksum
Handling deprecation for dfs.namenode.path.based.cache.block.map.allocation.percent
Handling deprecation for yarn.nodemanager.windows-container.memory-limit.enabled
Handling deprecation for mapreduce.input.fileinputformat.split.minsize
Handling deprecation for hadoop.security.group.mapping
Handling deprecation for mapreduce.jobtracker.system.dir
Handling deprecation for mapreduce.job.end-notification.max.attempts
Handling deprecation for mapreduce.reduce.markreset.buffer.percent
Handling deprecation for dfs.datanode.cache.revocation.polling.ms
Handling deprecation for mapreduce.reduce.speculative
Handling deprecation for yarn.nodemanager.localizer.cache.cleanup.interval-ms
Handling deprecation for dfs.namenode.lazypersist.file.scrub.interval.sec
Handling deprecation for fs.s3a.threads.core
Handling deprecation for mapreduce.jobhistory.recovery.store.fs.uri
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.start-time-read-cache-size
Handling deprecation for hadoop.registry.zk.retry.interval.ms
Handling deprecation for yarn.nodemanager.keytab
Handling deprecation for dfs.namenode.replication.interval
Handling deprecation for yarn.resourcemanager.admin.address
Handling deprecation for mapreduce.job.maps
Handling deprecation for nfs.dump.dir
Handling deprecation for mapreduce.job.user.name
Handling deprecation for mapreduce.jobtracker.maxtasks.perjob
Handling deprecation for mapreduce.job.ubertask.enable
Handling deprecation for mapreduce.job.reduce.class
Handling deprecation for yarn.nodemanager.delete.debug-delay-sec
Handling deprecation for yarn.timeline-service.ttl-enable
Handling deprecation for yarn.resourcemanager.fs.state-store.retry-policy-spec
Handling deprecation for mapreduce.reduce.skip.maxgroups
Handling deprecation for dfs.client.use.datanode.hostname
Handling deprecation for fs.trash.interval
Handling deprecation for mapreduce.job.name
Handling deprecation for mapreduce.am.max-attempts
Handling deprecation for mapreduce.jobtracker.heartbeats.in.second
Handling deprecation for yarn.resourcemanager.zk-num-retries
Handling deprecation for s3.blocksize
Handling deprecation for dfs.datanode.data.dir
Handling deprecation for mapreduce.jobtracker.persist.jobstatus.active
Handling deprecation for mapreduce.reduce.shuffle.parallelcopies
Handling deprecation for fs.s3.buffer.dir
Handling deprecation for mapreduce.jobhistory.done-dir
Handling deprecation for hadoop.security.instrumentation.requires.admin
Handling deprecation for hadoop.registry.zk.retry.ceiling.ms
Handling deprecation for nfs.rtmax
Handling deprecation for dfs.datanode.data.dir.perm
Handling deprecation for yarn.resourcemanager.container.liveness-monitor.interval-ms
Handling deprecation for yarn.nodemanager.env-whitelist
Handling deprecation for dfs.namenode.backup.address
Handling deprecation for dfs.namenode.xattrs.enabled
Handling deprecation for dfs.datanode.readahead.bytes
Handling deprecation for mapreduce.jobhistory.cleaner.enable
Handling deprecation for dfs.client.block.write.retries
Handling deprecation for mapreduce.tasktracker.http.address
Handling deprecation for yarn.nodemanager.linux-container-executor.cgroups.hierarchy
Handling deprecation for ha.failover-controller.graceful-fence.connection.retries
Handling deprecation for yarn.resourcemanager.recovery.enabled
Handling deprecation for yarn.app.mapreduce.am.container.log.backups
Handling deprecation for dfs.namenode.safemode.threshold-pct
Handling deprecation for yarn.nodemanager.disk-health-checker.interval-ms
Handling deprecation for hadoop.security.java.secure.random.algorithm
Handling deprecation for dfs.namenode.list.cache.directives.num.responses
Handling deprecation for dfs.datanode.dns.nameserver
Handling deprecation for mapreduce.cluster.temp.dir
Handling deprecation for fs.s3a.max.total.tasks
Handling deprecation for mapreduce.reduce.maxattempts
Handling deprecation for mapreduce.client.submit.file.replication
Handling deprecation for mapreduce.shuffle.port
Handling deprecation for yarn.resourcemanager.resource-tracker.client.thread-count
Handling deprecation for dfs.namenode.replication.considerLoad
Handling deprecation for dfs.namenode.edits.journal-plugin.qjournal
Handling deprecation for dfs.client.write.exclude.nodes.cache.expiry.interval.millis
Handling deprecation for yarn.nodemanager.delete.thread-count
Handling deprecation for dfs.client.mmap.cache.timeout.ms
Handling deprecation for yarn.nodemanager.admin-env
Handling deprecation for io.skip.checksum.errors
Handling deprecation for yarn.timeline-service.hostname
Handling deprecation for yarn.resourcemanager.proxy-user-privileges.enabled
Handling deprecation for mapreduce.job.speculative.speculative-cap-total-tasks
Handling deprecation for yarn.acl.enable
Handling deprecation for fs.s3a.fast.upload
Handling deprecation for file.blocksize
Handling deprecation for mapreduce.job.speculative.slowtaskthreshold
Handling deprecation for ftp.replication
Handling deprecation for yarn.sharedcache.cleaner.initial-delay-mins
Handling deprecation for s3native.client-write-packet-size
Handling deprecation for hadoop.rpc.socket.factory.class.default
Handling deprecation for file.bytes-per-checksum
Handling deprecation for dfs.datanode.slow.io.warning.threshold.ms
Handling deprecation for io.seqfile.lazydecompress
Handling deprecation for mapreduce.task.skip.start.attempts
Handling deprecation for dfs.namenode.reject-unresolved-dn-topology-mapping
Handling deprecation for hadoop.common.configuration.version
Handling deprecation for yarn.resourcemanager.client.thread-count
Handling deprecation for dfs.datanode.drop.cache.behind.reads
Handling deprecation for yarn.sharedcache.admin.address
Handling deprecation for mapreduce.job.output.value.class
Handling deprecation for mapreduce.output.fileoutputformat.outputdir
Handling deprecation for mapreduce.jobtracker.taskcache.levels
Handling deprecation for yarn.nodemanager.linux-container-executor.nonsecure-mode.user-pattern
Handling deprecation for yarn.resourcemanager.zk-timeout-ms
Handling deprecation for yarn.resourcemanager.max-completed-applications
Handling deprecation for mapreduce.job.jvm.numtasks
Handling deprecation for yarn.sharedcache.cleaner.period-mins
Handling deprecation for mapreduce.jobtracker.tasktracker.maxblacklists
Handling deprecation for dfs.namenode.top.num.users
Handling deprecation for yarn.nodemanager.linux-container-executor.cgroups.mount
Handling deprecation for yarn.sharedcache.checksum.algo.impl
Handling deprecation for mapreduce.job.end-notification.max.retry.interval
Handling deprecation for mapreduce.job.acl-view-job
Handling deprecation for mapreduce.job.classloader
Handling deprecation for yarn.log-aggregation-enable
Handling deprecation for mapreduce.reduce.shuffle.fetch.retry.interval-ms
Handling deprecation for yarn.resourcemanager.nodemanager.minimum.version
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.size
Handling deprecation for yarn.app.mapreduce.am.job.task.listener.thread-count
Handling deprecation for yarn.app.mapreduce.am.resource.cpu-vcores
Handling deprecation for dfs.namenode.edit.log.autoroll.check.interval.ms
Handling deprecation for mapreduce.output.fileoutputformat.compress.type
Handling deprecation for hadoop.hdfs.configuration.version
Handling deprecation for hadoop.security.group.mapping.ldap.search.attr.member
Handling deprecation for yarn.nodemanager.log.retain-seconds
Handling deprecation for yarn.nodemanager.local-cache.max-files-per-directory
Handling deprecation for mapreduce.job.end-notification.retry.interval
Handling deprecation for hadoop.ssl.client.conf
Handling deprecation for yarn.sharedcache.root-dir
Handling deprecation for dfs.journalnode.https-address
Handling deprecation for mapreduce.reduce.shuffle.fetch.retry.timeout-ms
Handling deprecation for dfs.bytes-per-checksum
Handling deprecation for dfs.namenode.max.objects
Handling deprecation for mapreduce.tasktracker.instrumentation
Handling deprecation for dfs.datanode.max.transfer.threads
Handling deprecation for dfs.block.access.key.update.interval
Handling deprecation for mapreduce.jobtracker.jobhistory.task.numberprogresssplits
Handling deprecation for mapreduce.map.memory.mb
Handling deprecation for ha.failover-controller.new-active.rpc-timeout.ms
Handling deprecation for hadoop.ssl.hostname.verifier
Handling deprecation for dfs.client.read.shortcircuit
Handling deprecation for dfs.datanode.hdfs-blocks-metadata.enabled
Handling deprecation for mapreduce.tasktracker.healthchecker.interval
Handling deprecation for dfs.image.transfer.chunksize
Handling deprecation for mapreduce.tasktracker.taskmemorymanager.monitoringinterval
Handling deprecation for dfs.client.https.keystore.resource
Handling deprecation for yarn.resourcemanager.connect.retry-interval.ms
Handling deprecation for yarn.timeline-service.webapp.address
Handling deprecation for s3native.blocksize
Handling deprecation for yarn.scheduler.minimum-allocation-mb
Handling deprecation for yarn.sharedcache.cleaner.resource-sleep-ms
Handling deprecation for net.topology.impl
Handling deprecation for dfs.client.failover.sleep.base.millis
Handling deprecation for dfs.permissions.superusergroup
Handling deprecation for io.seqfile.compress.blocksize
Handling deprecation for hadoop.registry.zk.retry.times
Handling deprecation for fs.AbstractFileSystem.ftp.impl
Handling deprecation for dfs.namenode.checkpoint.edits.dir
Handling deprecation for mapreduce.job.running.reduce.limit
Handling deprecation for dfs.blockreport.initialDelay
Handling deprecation for dfs.namenode.heartbeat.recheck-interval
Handling deprecation for dfs.namenode.safemode.extension
Handling deprecation for yarn.scheduler.maximum-allocation-mb
Handling deprecation for mapreduce.job.reduce.shuffle.consumer.plugin.class
Handling deprecation for yarn.nodemanager.vmem-check-enabled
Handling deprecation for mapreduce.task.io.sort.factor
Handling deprecation for mapreduce.jobtracker.persist.jobstatus.dir
Handling deprecation for dfs.client.failover.sleep.max.millis
Handling deprecation for dfs.namenode.delegation.key.update-interval
Handling deprecation for hadoop.rpc.protection
Handling deprecation for fs.permissions.umask-mode
Handling deprecation for fs.s3.sleepTimeSeconds
Handling deprecation for ha.health-monitor.rpc-timeout.ms
Handling deprecation for hadoop.http.staticuser.user
Handling deprecation for fs.s3a.connection.maximum
Handling deprecation for yarn.nodemanager.linux-container-executor.nonsecure-mode.limit-users
Handling deprecation for fs.s3a.paging.maximum
Handling deprecation for fs.AbstractFileSystem.viewfs.impl
Handling deprecation for fs.ftp.host
Handling deprecation for yarn.nodemanager.linux-container-executor.nonsecure-mode.local-user
Handling deprecation for fs.s3a.impl
Handling deprecation for hadoop.http.authentication.kerberos.keytab
Handling deprecation for dfs.namenode.fs-limits.max-blocks-per-file
Handling deprecation for mapreduce.tasktracker.http.threads
Handling deprecation for mapreduce.tasktracker.dns.nameserver
Handling deprecation for yarn.resourcemanager.am-rm-tokens.master-key-rolling-interval-secs
Handling deprecation for dfs.client.block.write.replace-datanode-on-failure.enable
Handling deprecation for io.compression.codec.bzip2.library
Handling deprecation for mapreduce.map.skip.maxrecords
Handling deprecation for dfs.client.use.legacy.blockreader.local
Handling deprecation for dfs.namenode.checkpoint.dir
Handling deprecation for dfs.namenode.top.windows.minutes
Handling deprecation for mapreduce.job.maxtaskfailures.per.tracker
Handling deprecation for net.topology.node.switch.mapping.impl
Handling deprecation for mapreduce.shuffle.max.connections
Handling deprecation for mapreduce.jobhistory.loadedjobs.cache.size
Handling deprecation for dfs.storage.policy.enabled
Handling deprecation for yarn.client.application-client-protocol.poll-interval-ms
Handling deprecation for yarn.nodemanager.localizer.address
Handling deprecation for dfs.namenode.list.cache.pools.num.responses
Handling deprecation for nfs.server.port
Handling deprecation for mapreduce.client.output.filter
Handling deprecation for yarn.timeline-service.client.best-effort
Handling deprecation for ha.zookeeper.parent-znode
Handling deprecation for mapreduce.jobtracker.persist.jobstatus.hours
Handling deprecation for yarn.sharedcache.admin.thread-count
Handling deprecation for yarn.nodemanager.resource.cpu-vcores
Handling deprecation for dfs.datanode.block-pinning.enabled
Handling deprecation for mapreduce.jobhistory.http.policy
Handling deprecation for yarn.resourcemanager.webapp.delegation-token-auth-filter.enabled
Handling deprecation for mapreduce.job.speculative.retry-after-no-speculate
Handling deprecation for fs.s3a.attempts.maximum
Handling deprecation for s3native.stream-buffer-size
Handling deprecation for io.seqfile.local.dir
Handling deprecation for yarn.log-aggregation.retain-check-interval-seconds
Handling deprecation for fs.s3n.multipart.copy.block.size
Handling deprecation for dfs.encrypt.data.transfer.cipher.key.bitlength
Handling deprecation for dfs.datanode.sync.behind.writes
Handling deprecation for yarn.resourcemanager.zk-acl
Handling deprecation for hadoop.ssl.keystores.factory.class
Handling deprecation for mapreduce.job.split.metainfo.maxsize
Handling deprecation for fs.s3.maxRetries
Handling deprecation for hadoop.security.random.device.file.path
Handling deprecation for yarn.client.nodemanager-connect.max-wait-ms
Handling deprecation for dfs.namenode.stale.datanode.interval
Handling deprecation for mapreduce.task.io.sort.mb
Handling deprecation for yarn.resourcemanager.zk-state-store.parent-path
Handling deprecation for yarn.app.mapreduce.client-am.ipc.max-retries
Handling deprecation for fs.client.resolve.remote.symlinks
Handling deprecation for yarn.nodemanager.linux-container-executor.cgroups.strict-resource-usage
Handling deprecation for hadoop.ssl.enabled.protocols
Handling deprecation for mapreduce.reduce.cpu.vcores
Handling deprecation for yarn.client.failover-retries
Handling deprecation for mapreduce.jobhistory.address
Handling deprecation for hadoop.ssl.enabled
Handling deprecation for dfs.replication.max
Handling deprecation for dfs.namenode.name.dir
Handling deprecation for dfs.datanode.https.address
Handling deprecation for ipc.client.kill.max
Handling deprecation for mapreduce.job.committer.setup.cleanup.needed
Handling deprecation for dfs.client.domain.socket.data.traffic
Handling deprecation for yarn.nodemanager.localizer.cache.target-size-mb
Handling deprecation for yarn.resourcemanager.admin.client.thread-count
Handling deprecation for dfs.block.access.token.enable
Handling deprecation for mapreduce.job.speculative.retry-after-speculate
Handling deprecation for dfs.datanode.address
Handling deprecation for mapreduce.jobtracker.restart.recover
Handling deprecation for ipc.client.connect.max.retries
Handling deprecation for yarn.timeline-service.store-class
Handling deprecation for dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
Handling deprecation for hadoop.tmp.dir
Handling deprecation for dfs.datanode.handler.count
Handling deprecation for yarn.resourcemanager.ha.automatic-failover.embedded
Handling deprecation for yarn.timeline-service.ttl-ms
Handling deprecation for mapreduce.task.profile.map.params
Handling deprecation for yarn.resourcemanager.nodemanagers.heartbeat-interval-ms
Handling deprecation for mapreduce.map.speculative
Handling deprecation for yarn.timeline-service.recovery.enabled
Handling deprecation for mapreduce.job.map.class
Handling deprecation for dfs.namenode.resource.checked.volumes.minimum
Handling deprecation for yarn.nodemanager.recovery.dir
Handling deprecation for mapreduce.job.counters.max
Handling deprecation for yarn.resourcemanager.keytab
Handling deprecation for dfs.namenode.max.extra.edits.segments.retained
Handling deprecation for dfs.webhdfs.user.provider.user.pattern
Handling deprecation for dfs.client.mmap.enabled
Handling deprecation for mapreduce.map.log.level
Handling deprecation for dfs.client.file-block-storage-locations.timeout.millis
Handling deprecation for yarn.client.max-cached-nodemanagers-proxies
Handling deprecation for yarn.app.mapreduce.am.scheduler.heartbeat.interval-ms
Handling deprecation for hadoop.fuse.timer.period
Handling deprecation for fs.trash.checkpoint.interval
Handling deprecation for yarn.sharedcache.app-checker.class
Handling deprecation for dfs.journalnode.http-address
Handling deprecation for yarn.app.mapreduce.am.staging-dir
Handling deprecation for mapreduce.tasktracker.local.dir.minspacestart
Handling deprecation for yarn.nm.liveness-monitor.expiry-interval-ms
Handling deprecation for ha.health-monitor.check-interval.ms
Handling deprecation for mapreduce.reduce.shuffle.merge.percent
Handling deprecation for dfs.namenode.retrycache.heap.percent
Handling deprecation for yarn.nodemanager.docker-container-executor.exec-name
Handling deprecation for ipc.client.connect.timeout
Handling deprecation for yarn.resourcemanager.fs.state-store.retry-interval-ms
Handling deprecation for mapreduce.output.fileoutputformat.compress
Handling deprecation for yarn.nodemanager.local-dirs
Handling deprecation for yarn.nodemanager.recovery.enabled
Handling deprecation for io.native.lib.available
Handling deprecation for yarn.sharedcache.store.in-memory.staleness-period-mins
Handling deprecation for yarn.resourcemanager.am.max-attempts
Handling deprecation for s3.replication
Handling deprecation for mapreduce.input.fileinputformat.inputdir
Handling deprecation for fs.AbstractFileSystem.har.impl
Handling deprecation for dfs.image.compress
Handling deprecation for mapreduce.job.running.map.limit
Handling deprecation for mapreduce.reduce.input.buffer.percent
Handling deprecation for yarn.nodemanager.webapp.address
Handling deprecation for dfs.datanode.available-space-volume-choosing-policy.balanced-space-preference-fraction
Handling deprecation for dfs.namenode.edit.log.autoroll.multiplier.threshold
Handling deprecation for hadoop.security.group.mapping.ldap.ssl
Handling deprecation for dfs.namenode.checkpoint.check.period
Handling deprecation for fs.defaultFS
Handling deprecation for fs.s3a.multipart.size
Handling deprecation for dfs.client.slow.io.warning.threshold.ms
Handling deprecation for yarn.app.mapreduce.am.job.committer.commit-window
Handling deprecation for hadoop.security.group.mapping.ldap.search.attr.group.name
Handling deprecation for yarn.nodemanager.disk-health-checker.max-disk-utilization-per-disk-percentage
Handling deprecation for yarn.nodemanager.container-monitor.procfs-tree.smaps-based-rss.enabled
Handling deprecation for mapreduce.job.submithostname
Handling deprecation for mapreduce.map.sort.spill.percent
Handling deprecation for hadoop.security.crypto.codec.classes.aes.ctr.nopadding
Handling deprecation for dfs.namenode.http-address
Handling deprecation for hadoop.security.groups.negative-cache.secs
Handling deprecation for hadoop.ssl.server.conf
Handling deprecation for mapreduce.ifile.readahead
Handling deprecation for s3native.replication
Handling deprecation for yarn.client.nodemanager-client-async.thread-pool-max-size
Handling deprecation for mapreduce.jobtracker.staging.root.dir
Handling deprecation for mapreduce.jobhistory.admin.address
Handling deprecation for dfs.namenode.startup.delay.block.deletion.sec
Handling deprecation for yarn.nodemanager.health-checker.interval-ms
Handling deprecation for dfs.namenode.checkpoint.max-retries
Handling deprecation for s3.stream-buffer-size
Handling deprecation for ftp.client-write-packet-size
Handling deprecation for dfs.datanode.fsdatasetcache.max.threads.per.volume
Handling deprecation for mapreduce.output.fileoutputformat.compress.codec
Handling deprecation for yarn.timeline-service.keytab
Handling deprecation for yarn.sharedcache.store.in-memory.initial-delay-mins
Handling deprecation for mapreduce.jobhistory.webapp.address
Handling deprecation for mapreduce.task.userlog.limit.kb
Handling deprecation for mapreduce.reduce.shuffle.fetch.retry.enabled
Handling deprecation for yarn.app.mapreduce.task.container.log.backups
Handling deprecation for dfs.heartbeat.interval
Handling deprecation for ha.zookeeper.session-timeout.ms
Handling deprecation for fs.s3a.connection.ssl.enabled
Handling deprecation for yarn.sharedcache.webapp.address
Handling deprecation for hadoop.http.authentication.signature.secret.file
Handling deprecation for hadoop.fuse.connection.timeout
Handling deprecation for mapreduce.input.fileinputformat.numinputfiles
Handling deprecation for yarn.nodemanager.log-aggregation.compression-type
Handling deprecation for ipc.server.max.connections
Handling deprecation for yarn.resourcemanager.work-preserving-recovery.scheduling-wait-ms
Handling deprecation for yarn.nodemanager.log-dirs
Handling deprecation for yarn.app.mapreduce.am.resource.mb
Handling deprecation for hadoop.security.groups.cache.secs
Handling deprecation for mapreduce.job.speculative.minimum-allowed-tasks
Handling deprecation for yarn.nodemanager.container-monitor.interval-ms
Handling deprecation for dfs.datanode.cache.revocation.timeout.ms
Handling deprecation for mapreduce.jobhistory.recovery.store.class
Handling deprecation for mapreduce.task.combine.progress.records
Handling deprecation for s3.client-write-packet-size
Handling deprecation for mapreduce.jobtracker.instrumentation
Handling deprecation for dfs.replication
Handling deprecation for mapreduce.shuffle.transfer.buffer.size
Handling deprecation for hadoop.security.group.mapping.ldap.directory.search.timeout
Handling deprecation for dfs.datanode.available-space-volume-choosing-policy.balanced-space-threshold
Handling deprecation for hadoop.work.around.non.threadsafe.getpwuid
Handling deprecation for yarn.app.mapreduce.client-am.ipc.max-retries-on-timeouts
Handling deprecation for yarn.nodemanager.address
Handling deprecation for mapreduce.tasktracker.taskcontroller
Handling deprecation for mapreduce.tasktracker.indexcache.mb
Handling deprecation for yarn.scheduler.maximum-allocation-vcores
Handling deprecation for mapreduce.job.reduces
Handling deprecation for yarn.nodemanager.sleep-delay-before-sigkill.ms
Handling deprecation for yarn.timeline-service.address
Handling deprecation for yarn.resourcemanager.configuration.provider-class
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.expiry
Handling deprecation for yarn.sharedcache.enabled
Handling deprecation for tfile.io.chunk.size
Handling deprecation for mapreduce.job.acl-modify-job
Handling deprecation for hadoop.registry.zk.session.timeout.ms
Handling deprecation for fs.automatic.close
Handling deprecation for ha.health-monitor.sleep-after-disconnect.ms
Handling deprecation for mapreduce.tasktracker.reduce.tasks.maximum
Handling deprecation for mapreduce.input.fileinputformat.list-status.num-threads
Handling deprecation for dfs.datanode.directoryscan.threads
Handling deprecation for dfs.datanode.directoryscan.interval
Handling deprecation for dfs.namenode.acls.enabled
Handling deprecation for dfs.client.short.circuit.replica.stale.threshold.ms
Handling deprecation for hadoop.http.authentication.token.validity
Handling deprecation for fs.s3.block.size
Handling deprecation for ha.failover-controller.graceful-fence.rpc-timeout.ms
Handling deprecation for mapreduce.tasktracker.local.dir.minspacekill
Handling deprecation for dfs.namenode.resource.du.reserved
Handling deprecation for mapreduce.jobhistory.cleaner.interval-ms
Handling deprecation for dfs.namenode.datanode.registration.ip-hostname-check
Handling deprecation for mapreduce.jobhistory.intermediate-done-dir
Handling deprecation for mapreduce.jobtracker.http.address
Handling deprecation for dfs.namenode.backup.http-address
Handling deprecation for dfs.namenode.edits.noeditlogchannelflush
Handling deprecation for mapreduce.reduce.shuffle.input.buffer.percent
Handling deprecation for mapreduce.map.maxattempts
Handling deprecation for yarn.http.policy
Handling deprecation for dfs.namenode.audit.loggers
Handling deprecation for hadoop.security.groups.cache.warn.after.ms
Handling deprecation for io.serializations
Handling deprecation for mapreduce.tasktracker.outofband.heartbeat
Handling deprecation for mapreduce.reduce.shuffle.read.timeout
Handling deprecation for hadoop.security.crypto.buffer.size
Handling deprecation for mapreduce.reduce.skip.proc.count.autoincr
Handling deprecation for mapreduce.ifile.readahead.bytes
Handling deprecation for dfs.http.policy
Handling deprecation for hadoop.registry.secure
Handling deprecation for dfs.namenode.safemode.min.datanodes
Handling deprecation for dfs.client.file-block-storage-locations.num-threads
Handling deprecation for mapreduce.cluster.local.dir
Handling deprecation for mapreduce.tasktracker.report.address
Handling deprecation for dfs.namenode.secondary.https-address
Handling deprecation for hadoop.kerberos.kinit.command
Handling deprecation for yarn.timeline-service.http-authentication.type
Handling deprecation for dfs.block.access.token.lifetime
Handling deprecation for dfs.webhdfs.enabled
Handling deprecation for dfs.namenode.delegation.token.max-lifetime
Handling deprecation for dfs.namenode.avoid.write.stale.datanode
Handling deprecation for dfs.datanode.drop.cache.behind.writes
Handling deprecation for yarn.log-aggregation.retain-seconds
Handling deprecation for mapreduce.job.complete.cancel.delegation.tokens
Handling deprecation for mapreduce.local.clientfactory.class.name
Handling deprecation for mapreduce.shuffle.connection-keep-alive.timeout
Handling deprecation for dfs.namenode.num.extra.edits.retained
Handling deprecation for yarn.scheduler.minimum-allocation-vcores
Handling deprecation for ipc.client.connect.max.retries.on.timeouts
Handling deprecation for yarn.timeline-service.client.retry-interval-ms
Handling deprecation for yarn.timeline-service.client.max-retries
Handling deprecation for fs.s3n.block.size
Handling deprecation for mapreduce.job.map.output.collector.class
Handling deprecation for ha.health-monitor.connect-retry-interval.ms
Handling deprecation for mapreduce.shuffle.max.threads
Handling deprecation for nfs.exports.allowed.hosts
Handling deprecation for dfs.client.mmap.cache.size
Handling deprecation for mapreduce.tasktracker.map.tasks.maximum
Handling deprecation for io.file.buffer.size
Handling deprecation for dfs.client.datanode-restart.timeout
Handling deprecation for io.mapfile.bloom.size
Handling deprecation for hadoop.security.kms.client.authentication.retry-count
Handling deprecation for dfs.namenode.checkpoint.txns
Handling deprecation for ipc.client.connect.retry.interval
Handling deprecation for dfs.client-write-packet-size
Handling deprecation for mapreduce.reduce.shuffle.connect.timeout
Handling deprecation for yarn.resourcemanager.fs.state-store.uri
Handling deprecation for fs.swift.impl
Handling deprecation for hadoop.registry.zk.connection.timeout.ms
Handling deprecation for mapred.queue.default.acl-administer-jobs
Handling deprecation for mapreduce.job.submithostaddress
Handling deprecation for dfs.cachereport.intervalMsec
Handling deprecation for yarn.app.mapreduce.shuffle.log.backups
Handling deprecation for yarn.app.mapreduce.am.container.log.limit.kb
Handling deprecation for yarn.nodemanager.resourcemanager.minimum.version
Handling deprecation for ftp.blocksize
Handling deprecation for yarn.resourcemanager.address
Handling deprecation for file.stream-buffer-size
Handling deprecation for yarn.resourcemanager.scheduler.monitor.enable
Handling deprecation for mapreduce.job.ubertask.maxreduces
Handling deprecation for nfs.allow.insecure.ports
Handling deprecation for yarn.sharedcache.nm.uploader.thread-count
Handling deprecation for ipc.client.idlethreshold
Handling deprecation for ftp.stream-buffer-size
Handling deprecation for yarn.sharedcache.client-server.address
Handling deprecation for dfs.client.failover.connection.retries.on.timeouts
Handling deprecation for dfs.namenode.replication.work.multiplier.per.iteration
Handling deprecation for hadoop.http.authentication.simple.anonymous.allowed
Handling deprecation for hadoop.security.authorization
Handling deprecation for yarn.client.nodemanager-connect.retry-interval-ms
Handling deprecation for yarn.am.liveness-monitor.expiry-interval-ms
Handling deprecation for fs.har.impl.disable.cache
Handling deprecation for yarn.nodemanager.linux-container-executor.resources-handler.class
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.read-cache-size
Handling deprecation for hadoop.security.authentication
Handling deprecation for dfs.image.compression.codec
Handling deprecation for mapreduce.task.files.preserve.failedtasks
Handling deprecation for dfs.client.read.shortcircuit.streams.cache.size
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.path
Handling deprecation for mapreduce.job.reduce.slowstart.completedmaps
Handling deprecation for mapreduce.jobhistory.minicluster.fixed.ports
Handling deprecation for file.replication
Handling deprecation for yarn.resourcemanager.ha.automatic-failover.enabled
Handling deprecation for mapreduce.job.userlog.retain.hours
Handling deprecation for mapreduce.jobhistory.joblist.cache.size
Handling deprecation for dfs.namenode.accesstime.precision
Handling deprecation for yarn.resourcemanager.work-preserving-recovery.enabled
Handling deprecation for dfs.namenode.fs-limits.max-xattrs-per-inode
Handling deprecation for io.mapfile.bloom.error.rate
Handling deprecation for yarn.resourcemanager.store.class
Handling deprecation for dfs.image.transfer.timeout
Handling deprecation for yarn.timeline-service.leveldb-state-store.path
Handling deprecation for nfs.wtmax
Handling deprecation for mapreduce.job.combine.class
Handling deprecation for dfs.namenode.support.allow.format
Handling deprecation for fs.s3a.multipart.purge
Handling deprecation for dfs.secondary.namenode.kerberos.internal.spnego.principal
Handling deprecation for fs.s3a.connection.establish.timeout
Handling deprecation for dfs.stream-buffer-size
Handling deprecation for dfs.namenode.invalidate.work.pct.per.iteration
Handling deprecation for yarn.nodemanager.container-executor.class
Handling deprecation for fs.s3a.multipart.purge.age
Handling deprecation for yarn.resourcemanager.scheduler.client.thread-count
Handling deprecation for dfs.namenode.top.enabled
Handling deprecation for yarn.app.mapreduce.shuffle.log.separate
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.low-watermark
Handling deprecation for fs.s3a.fast.buffer.size
Handling deprecation for hadoop.user.group.static.mapping.overrides
Handling deprecation for tfile.fs.input.buffer.size
Handling deprecation for dfs.client.cached.conn.retry
Handling deprecation for hadoop.http.authentication.type
Handling deprecation for dfs.namenode.list.encryption.zones.num.responses
Handling deprecation for mapreduce.map.cpu.vcores
Handling deprecation for dfs.namenode.path.based.cache.refresh.interval.ms
Handling deprecation for dfs.namenode.decommission.interval
Handling deprecation for dfs.namenode.fs-limits.max-directory-items
Handling deprecation for yarn.resourcemanager.zk-retry-interval-ms
Handling deprecation for ftp.bytes-per-checksum
Handling deprecation for dfs.ha.log-roll.period
Handling deprecation for dfs.user.home.dir.prefix
Handling deprecation for ipc.client.fallback-to-simple-auth-allowed
Handling deprecation for yarn.nodemanager.pmem-check-enabled
Handling deprecation for yarn.nodemanager.remote-app-log-dir
Handling deprecation for dfs.namenode.inotify.max.events.per.rpc
Handling deprecation for mapreduce.task.profile.maps
Handling deprecation for mapreduce.shuffle.ssl.file.buffer.size
Handling deprecation for mapreduce.tasktracker.healthchecker.script.timeout
Handling deprecation for yarn.timeline-service.webapp.https.address
Handling deprecation for yarn.nodemanager.resource.percentage-physical-cpu-limit
Handling deprecation for yarn.app.mapreduce.am.command-opts
Handling deprecation for dfs.namenode.fs-limits.max-xattr-size
Handling deprecation for dfs.datanode.http.address
Handling deprecation for dfs.namenode.blocks.per.postponedblocks.rescan
Handling deprecation for yarn.sharedcache.nm.uploader.replication.factor
Handling deprecation for hadoop.registry.zk.root
Handling deprecation for hadoop.jetty.logs.serve.aliases
Handling deprecation for yarn.client.failover-proxy-provider
Handling deprecation for mapreduce.jobhistory.admin.acl
Handling deprecation for yarn.app.mapreduce.am.hard-kill-timeout-ms
Handling deprecation for yarn.nodemanager.remote-app-log-dir-suffix
Handling deprecation for mapreduce.jobhistory.principal
Handling deprecation for yarn.resourcemanager.webapp.address
Handling deprecation for mapreduce.jobhistory.recovery.enable
Handling deprecation for yarn.sharedcache.store.in-memory.check-period-mins
Handling deprecation for nfs.mountd.port
Handling deprecation for mapreduce.reduce.merge.inmem.threshold
Handling deprecation for fs.df.interval
Handling deprecation for yarn.timeline-service.enabled
Handling deprecation for mapreduce.jobtracker.jobhistory.lru.cache.size
Handling deprecation for mapreduce.task.profile
Handling deprecation for mapreduce.job.output.key.class
Handling deprecation for yarn.nodemanager.hostname
Handling deprecation for dfs.namenode.num.checkpoints.retained
Handling deprecation for mapreduce.job.queuename
Handling deprecation for mapreduce.jobhistory.max-age-ms
Handling deprecation for mapreduce.job.token.tracking.ids.enabled
Handling deprecation for yarn.nodemanager.localizer.client.thread-count
Handling deprecation for yarn.sharedcache.uploader.server.thread-count
Handling deprecation for dfs.client.mmap.retry.timeout.ms
Handling deprecation for mapreduce.jobhistory.move.thread-count
Handling deprecation for dfs.permissions.enabled
Handling deprecation for dfs.blockreport.split.threshold
Handling deprecation for fs.AbstractFileSystem.hdfs.impl
Handling deprecation for dfs.datanode.balance.bandwidthPerSec
Handling deprecation for dfs.block.scanner.volume.bytes.per.second
Handling deprecation for hadoop.http.filter.initializers
Handling deprecation for yarn.timeline-service.http-authentication.simple.anonymous.allowed
Handling deprecation for dfs.default.chunk.view.size
Handling deprecation for yarn.sharedcache.client-server.thread-count
Handling deprecation for yarn.resourcemanager.resource-tracker.address
Handling deprecation for mapreduce.job.working.dir
Handling deprecation for mapreduce.jobhistory.datestring.cache.size
Handling deprecation for mapreduce.task.profile.params
Handling deprecation for dfs.namenode.decommission.blocks.per.interval
Handling deprecation for dfs.namenode.handler.count
Handling deprecation for dfs.image.transfer.bandwidthPerSec
Handling deprecation for rpc.metrics.quantile.enable
Handling deprecation for mapreduce.jobtracker.expire.trackers.interval
Handling deprecation for mapreduce.task.timeout
Handling deprecation for yarn.app.mapreduce.client.max-retries
Handling deprecation for yarn.nodemanager.resource.memory-mb
Handling deprecation for yarn.nodemanager.disk-health-checker.min-healthy-disks
Handling deprecation for dfs.datanode.failed.volumes.tolerated
Handling deprecation for yarn.timeline-service.handler-thread-count
Handling deprecation for ipc.server.listen.queue.size
Handling deprecation for fs.s3a.threads.max
Handling deprecation for yarn.resourcemanager.connect.max-wait.ms
Handling deprecation for mapreduce.fileoutputcommitter.algorithm.version
Handling deprecation for mapreduce.framework.name
Handling deprecation for mapreduce.map.skip.proc.count.autoincr
Handling deprecation for mapreduce.job.max.split.locations
Handling deprecation for yarn.resourcemanager.scheduler.class
Handling deprecation for yarn.resourcemanager.system-metrics-publisher.enabled
Handling deprecation for dfs.blocksize
Handling deprecation for yarn.sharedcache.nested-level
Handling deprecation for mapreduce.shuffle.connection-keep-alive.enable
Handling deprecation for fs.s3a.threads.keepalivetime
Handling deprecation for fs.s3a.connection.timeout
Handling deprecation for file.client-write-packet-size
Handling deprecation for ha.failover-controller.cli-check.rpc-timeout.ms
Handling deprecation for ha.zookeeper.acl
Handling deprecation for dfs.namenode.write.stale.datanode.ratio
Handling deprecation for dfs.encrypt.data.transfer
Handling deprecation for dfs.datanode.shared.file.descriptor.paths
Handling deprecation for mapreduce.input.lineinputformat.linespermap
Handling deprecation for yarn.resourcemanager.delayed.delegation-token.removal-interval-ms
Handling deprecation for yarn.nodemanager.localizer.fetch.thread-count
Handling deprecation for dfs.client.failover.max.attempts
Handling deprecation for yarn.resourcemanager.scheduler.address
Handling deprecation for dfs.client.read.shortcircuit.streams.cache.expiry.ms
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.start-time-write-cache-size
Handling deprecation for yarn.nodemanager.health-checker.script.timeout-ms
Handling deprecation for yarn.resourcemanager.fs.state-store.num-retries
Handling deprecation for hadoop.ssl.require.client.cert
Handling deprecation for hadoop.security.uid.cache.secs
Handling deprecation for mapreduce.jobhistory.keytab
Handling deprecation for dfs.client.read.shortcircuit.skip.checksum
Handling deprecation for yarn.resourcemanager.ha.automatic-failover.zk-base-path
Handling deprecation for mapreduce.shuffle.ssl.enabled
Handling deprecation for mapreduce.reduce.log.level
Handling deprecation for hadoop.registry.rm.enabled
Handling deprecation for mapreduce.tasktracker.dns.interface
Handling deprecation for yarn.resourcemanager.system-metrics-publisher.dispatcher.pool-size
Handling deprecation for mapreduce.job.speculative.speculative-cap-running-tasks
Handling deprecation for dfs.datanode.block.id.layout.upgrade.threads
Handling deprecation for dfs.datanode.use.datanode.hostname
Handling deprecation for dfs.client.context
Handling deprecation for yarn.resourcemanager.ha.enabled
Handling deprecation for mapred.reducer.new-api
Handling deprecation for dfs.namenode.delegation.token.renew-interval
Handling deprecation for dfs.blockreport.intervalMsec
Handling deprecation for fs.s3a.multipart.threshold
Handling deprecation for mapreduce.reduce.shuffle.memory.limit.percent
Handling deprecation for dfs.https.server.keystore.resource
Handling deprecation for io.map.index.skip
Handling deprecation for mapreduce.job.hdfs-servers
Handling deprecation for mapreduce.jobtracker.taskscheduler
Handling deprecation for dfs.namenode.kerberos.internal.spnego.principal
Handling deprecation for yarn.resourcemanager.state-store.max-completed-applications
Handling deprecation for mapreduce.map.output.compress
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.num.refill.threads
Handling deprecation for fs.s3n.multipart.uploads.block.size
Handling deprecation for mapreduce.task.merge.progress.records
Handling deprecation for dfs.datanode.dns.interface
Handling deprecation for map.sort.class
Handling deprecation for yarn.nodemanager.aux-services.mapreduce_shuffle.class
Handling deprecation for tfile.fs.output.buffer.size
Handling deprecation for fs.du.interval
Handling deprecation for dfs.client.failover.connection.retries
Handling deprecation for dfs.namenode.top.window.num.buckets
Handling deprecation for mapreduce.job.dir
Handling deprecation for fs.s3a.buffer.dir
Handling deprecation for mapreduce.reduce.shuffle.retry-delay.max.ms
Handling deprecation for yarn.sharedcache.uploader.server.address
Handling deprecation for mapreduce.client.progressmonitor.pollinterval
Handling deprecation for yarn.app.mapreduce.shuffle.log.limit.kb
Handling deprecation for dfs.datanode.max.locked.memory
Handling deprecation for dfs.namenode.retrycache.expirytime.millis
Handling deprecation for dfs.datanode.scan.period.hours
Handling deprecation for dfs.client.block.write.replace-datanode-on-failure.best-effort
Handling deprecation for mapreduce.jobhistory.move.interval-ms
Handling deprecation for dfs.ha.fencing.ssh.connect-timeout
Handling deprecation for yarn.nodemanager.log-aggregation.roll-monitoring-interval-seconds
Handling deprecation for dfs.namenode.fs-limits.max-component-length
Handling deprecation for hadoop.registry.zk.quorum
Handling deprecation for dfs.namenode.enable.retrycache
Handling deprecation for dfs.datanode.du.reserved
Handling deprecation for yarn.timeline-service.state-store-class
Handling deprecation for dfs.datanode.ipc.address
Handling deprecation for hadoop.registry.system.acls
Handling deprecation for dfs.client.block.write.replace-datanode-on-failure.policy
Handling deprecation for dfs.namenode.path.based.cache.retry.interval.ms
Handling deprecation for hadoop.security.crypto.cipher.suite
Handling deprecation for dfs.ha.tail-edits.period
Handling deprecation for mapreduce.task.profile.reduce.params
Handling deprecation for hadoop.registry.jaas.context
Handling deprecation for yarn.resourcemanager.hostname
Handling deprecation for mapreduce.reduce.memory.mb
Handling deprecation for hadoop.security.group.mapping.ldap.search.filter.group
Handling deprecation for hadoop.http.authentication.kerberos.principal
Handling deprecation for hadoop.security.group.mapping.ldap.search.filter.user
Handling deprecation for yarn.nodemanager.disk-health-checker.min-free-space-per-disk-mb
Handling deprecation for dfs.namenode.edits.dir
Handling deprecation for yarn.client.failover-retries-on-socket-timeouts
Handling deprecation for dfs.namenode.decommission.max.concurrent.tracked.nodes
Handling deprecation for mapreduce.client.completion.pollinterval
Handling deprecation for dfs.namenode.name.dir.restore
Handling deprecation for dfs.namenode.secondary.http-address
Handling deprecation for mapreduce.jobhistory.recovery.store.leveldb.path
Handling deprecation for yarn.sharedcache.store.class
Handling deprecation for s3.bytes-per-checksum
Handling deprecation for yarn.nodemanager.windows-container.cpu-limit.enabled
Handling deprecation for yarn.resourcemanager.webapp.https.address
Handling deprecation for yarn.nodemanager.vmem-pmem-ratio
Handling deprecation for dfs.namenode.checkpoint.period
Handling deprecation for dfs.ha.automatic-failover.enabled
The url to track the job: http://localhost:8080/
OutputCommitter set in config null
File Output Committer Algorithm version is 1
Running job: job_local85066265_0003
OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
/user/michaeljones/wcOutputMain/_temporary/0: masked=rwxr-xr-x
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #58
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #58
Call: mkdirs took 8ms
Starting mapper thread pool executor.
Max local threads: 1
Map tasks to process: 1
Waiting for map tasks
Starting task: attempt_local85066265_0003_m_000000_0
currentIndex 0   0:0
mapreduce.cluster.local.dir for child : /tmp/hadoop-michaeljones/mapred/local/localRunner//michaeljones/jobcache/job_local85066265_0003/attempt_local85066265_0003_m_000000_0
using new api for output committer
File Output Committer Algorithm version is 1
ProcfsBasedProcessTree currently is supported only on Linux.
 Using ResourceCalculatorProcessTree : null
Processing split: hdfs://localhost:9000/user/michaeljones/wcInput:0+50
Trying map output collector class: org.apache.hadoop.mapred.MapTask$MapOutputBuffer
(EQUATOR) 0 kvi 26214396(104857584)
mapreduce.task.io.sort.mb: 100
soft limit at 83886080
bufstart = 0; bufvoid = 104857600
kvstart = 26214396; length = 6553600
Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #59
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #59
Call: getBlockLocations took 10ms
newInfo = LocatedBlocks{
  fileLength=50
  underConstruction=false
  blocks=[LocatedBlock{BP-1045030256-10.0.0.2-1433119149314:blk_1073741825_1002; getBlockSize()=50; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-b42c5705-9ba4-4b14-b00b-f9194bb036f0,DISK]]}]
  lastLocatedBlock=LocatedBlock{BP-1045030256-10.0.0.2-1433119149314:blk_1073741825_1002; getBlockSize()=50; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-b42c5705-9ba4-4b14-b00b-f9194bb036f0,DISK]]}
  isLastBlockComplete=true}
Connecting to datanode 127.0.0.1:50010

Starting flush of map output
Spilling map output
bufstart = 0; bufend = 82; bufvoid = 104857600
kvstart = 26214396(104857584); kvend = 26214368(104857472); length = 29/6553600
Finished spill 0
Task:attempt_local85066265_0003_m_000000_0 is done. And is in the process of committing
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #60
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #60
Call: getFileInfo took 5ms
map
Task 'attempt_local85066265_0003_m_000000_0' done.
Finishing task: attempt_local85066265_0003_m_000000_0
map task executor complete.
Starting reduce thread pool executor.
Max local threads: 1
Reduce tasks to process: 1
Waiting for reduce tasks
Starting task: attempt_local85066265_0003_r_000000_0
currentIndex 0   0:0
mapreduce.cluster.local.dir for child : /tmp/hadoop-michaeljones/mapred/local/localRunner//michaeljones/jobcache/job_local85066265_0003/attempt_local85066265_0003_r_000000_0
using new api for output committer
File Output Committer Algorithm version is 1
ProcfsBasedProcessTree currently is supported only on Linux.
 Using ResourceCalculatorProcessTree : null
Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@3eb08bfa
MergerManager: memoryLimit=668309888, maxSingleShuffleLimit=167077472, mergeThreshold=441084544, ioSortFactor=10, memToMemMergeOutputsThreshold=10
attempt_local85066265_0003_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
Got 0 map completion events from 0
GetMapEventsThread about to sleep for 1000
LocalFetcher 3 going to fetch: attempt_local85066265_0003_m_000000_0
attempt_local85066265_0003_m_000000_0: Proceeding with shuffle since usedMemory (0) is lesser than memoryLimit (668309888).CommitMemory is (0)
localfetcher#3 about to shuffle output of map attempt_local85066265_0003_m_000000_0 decomp: 63 len: 67 to MEMORY
Read 63 bytes from map-output for attempt_local85066265_0003_m_000000_0
closeInMemoryFile -> map-output of size: 63, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->63
map attempt_local85066265_0003_m_000000_0 done 1 / 1 copied.
EventFetcher is interrupted.. Returning
1 / 1 copied.
finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
Merging 1 sorted segments
Down to the last merge-pass, with 1 segments left of total size: 57 bytes
Merged 1 segments, 63 bytes to disk to satisfy reduce memory limit
Disk file: /tmp/hadoop-michaeljones/mapred/local/localRunner/michaeljones/jobcache/job_local85066265_0003/attempt_local85066265_0003_r_000000_0/output/map_0.out.merged Length is 67
Merging 1 files, 67 bytes from disk
Merging 0 segments, 0 bytes from memory into reduce
Merging 1 sorted segments
Down to the last merge-pass, with 1 segments left of total size: 57 bytes
1 / 1 copied.
/user/michaeljones/wcOutputMain/_temporary/0/_temporary/attempt_local85066265_0003_r_000000_0/part-r-00000: masked=rw-r--r--
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #61
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #61
Call: create took 4ms
computePacketChunkSize: src=/user/michaeljones/wcOutputMain/_temporary/0/_temporary/attempt_local85066265_0003_r_000000_0/part-r-00000, chunkSize=516, chunksPerPacket=126, packetSize=65016
DFSClient writeChunk allocating new packet seqno=0, src=/user/michaeljones/wcOutputMain/_temporary/0/_temporary/attempt_local85066265_0003_r_000000_0/part-r-00000, packetSize=65016, chunksPerPacket=126, bytesCurBlock=0
Queued packet 0
Queued packet 1
Waiting for ack for: 1
Allocating new block
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #62
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #62
Call: addBlock took 3ms
pipeline = DatanodeInfoWithStorage[127.0.0.1:50010,DS-b42c5705-9ba4-4b14-b00b-f9194bb036f0,DISK]
Connecting to datanode 127.0.0.1:50010
Send buf size 131072
SASL client skipping handshake in unsecured configuration for addr = /127.0.0.1, datanodeId = DatanodeInfoWithStorage[127.0.0.1:50010,DS-b42c5705-9ba4-4b14-b00b-f9194bb036f0,DISK]
DataStreamer block BP-1045030256-10.0.0.2-1433119149314:blk_1073742293_1470 sending packet packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 41
DFSClient seqno: 0 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
DataStreamer block BP-1045030256-10.0.0.2-1433119149314:blk_1073742293_1470 sending packet packet seqno: 1 offsetInBlock: 41 lastPacketInBlock: true lastByteOffsetInBlock: 41
DFSClient seqno: 1 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #63
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #63
Call: complete took 3ms
Task:attempt_local85066265_0003_r_000000_0 is done. And is in the process of committing
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #64
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #64
Call: getFileInfo took 4ms
1 / 1 copied.
Task attempt_local85066265_0003_r_000000_0 is allowed to commit now
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #65
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #65
Call: getFileInfo took 3ms
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #66
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #66
Call: getFileInfo took 2ms
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #67
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #67
Call: rename took 5ms
Saved output of task 'attempt_local85066265_0003_r_000000_0' to hdfs://localhost:9000/user/michaeljones/wcOutputMain/_temporary/0/task_local85066265_0003_r_000000
reduce > reduce
Task 'attempt_local85066265_0003_r_000000_0' done.
Finishing task: attempt_local85066265_0003_r_000000_0
reduce task executor complete.
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #68
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #68
Call: getListing took 2ms
Merging data from FileStatus{path=hdfs://localhost:9000/user/michaeljones/wcOutputMain/_temporary/0/task_local85066265_0003_r_000000; isDirectory=true; modification_time=1434180763276; access_time=0; owner=michaeljones; group=supergroup; permission=rwxr-xr-x; isSymlink=false} to hdfs://localhost:9000/user/michaeljones/wcOutputMain
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #69
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #69
Call: getFileInfo took 1ms
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #70
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #70
Call: getListing took 2ms
Merging data from FileStatus{path=hdfs://localhost:9000/user/michaeljones/wcOutputMain/_temporary/0/task_local85066265_0003_r_000000/part-r-00000; isDirectory=false; length=41; replication=1; blocksize=134217728; modification_time=1434180763305; access_time=1434180763276; owner=michaeljones; group=supergroup; permission=rw-r--r--; isSymlink=false} to hdfs://localhost:9000/user/michaeljones/wcOutputMain/part-r-00000
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #71
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #71
Call: getFileInfo took 2ms
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #72
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #72
Call: rename took 3ms
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #73
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #73
Call: delete took 3ms
/user/michaeljones/wcOutputMain/_SUCCESS: masked=rw-r--r--
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #74
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #74
Call: create took 5ms
computePacketChunkSize: src=/user/michaeljones/wcOutputMain/_SUCCESS, chunkSize=516, chunksPerPacket=126, packetSize=65016
Waiting for ack for: -1
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones sending #75
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones got value #75
Call: complete took 6ms
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.fs.FileContext.getAbstractFileSystem(FileContext.java:331)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
Job job_local85066265_0003 running in uber mode : false
 map 100% reduce 100%
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.getTaskCompletionEvents(Job.java:670)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.getTaskCompletionEvents(Job.java:670)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
Job job_local85066265_0003 completed successfully
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.getCounters(Job.java:758)
Counters: 35
	File System Counters
		FILE: Number of bytes read=1892
		FILE: Number of bytes written=1688439
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=340
		HDFS: Number of bytes written=245
		HDFS: Number of read operations=71
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=38
	Map-Reduce Framework
		Map input records=2
		Map output records=8
		Map output bytes=82
		Map output materialized bytes=67
		Input split bytes=112
		Combine input records=8
		Combine output records=5
		Reduce input groups=5
		Reduce shuffle bytes=67
		Reduce input records=5
		Reduce output records=5
		Spilled Records=10
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=985661440
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=50
	File Output Format Counters 
		Bytes Written=41
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 5][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://localhost:50070
Connecting to localhost/127.0.0.1:50070
Connection established 127.0.0.1:49960<->127.0.0.1:50070
Executing request GET /webhdfs/v1/user/michaeljones/?op=LISTSTATUS HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-5 >> GET /webhdfs/v1/user/michaeljones/?op=LISTSTATUS HTTP/1.1
http-outgoing-5 >> accept: application/json
http-outgoing-5 >> Host: localhost:50070
http-outgoing-5 >> Connection: Keep-Alive
http-outgoing-5 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-5 >> Accept-Encoding: gzip,deflate
http-outgoing-5 >> "GET /webhdfs/v1/user/michaeljones/?op=LISTSTATUS HTTP/1.1[\r][\n]"
http-outgoing-5 >> "accept: application/json[\r][\n]"
http-outgoing-5 >> "Host: localhost:50070[\r][\n]"
http-outgoing-5 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-5 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-5 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-5 >> "[\r][\n]"
http-outgoing-5 << "HTTP/1.1 200 OK[\r][\n]"
http-outgoing-5 << "Cache-Control: no-cache[\r][\n]"
http-outgoing-5 << "Expires: Sat, 13 Jun 2015 07:32:44 GMT[\r][\n]"
http-outgoing-5 << "Date: Sat, 13 Jun 2015 07:32:44 GMT[\r][\n]"
http-outgoing-5 << "Pragma: no-cache[\r][\n]"
http-outgoing-5 << "Expires: Sat, 13 Jun 2015 07:32:44 GMT[\r][\n]"
http-outgoing-5 << "Date: Sat, 13 Jun 2015 07:32:44 GMT[\r][\n]"
http-outgoing-5 << "Pragma: no-cache[\r][\n]"
http-outgoing-5 << "Content-Type: application/json[\r][\n]"
http-outgoing-5 << "Transfer-Encoding: chunked[\r][\n]"
http-outgoing-5 << "Server: Jetty(6.1.26)[\r][\n]"
http-outgoing-5 << "[\r][\n]"
http-outgoing-5 << "10C4[\r][\n]"
http-outgoing-5 << "{"FileStatuses":{"FileStatus":[[\n]"
http-outgoing-5 << "{"accessTime":1434180753127,"blockSize":134217728,"childrenNum":0,"fileId":18598,"group":"supergroup","length":10899,"modificationTime":1434180753156,"owner":"michaeljones","pathSuffix":"README.md","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-5 << "{"accessTime":1434167878992,"blockSize":134217728,"childrenNum":0,"fileId":18566,"group":"supergroup","length":0,"modificationTime":1434167878996,"owner":"michaeljones","pathSuffix":"apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-5 << "{"accessTime":1434180637491,"blockSize":134217728,"childrenNum":0,"fileId":18590,"group":"supergroup","length":0,"modificationTime":1434180637503,"owner":"michaeljones","pathSuffix":"empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-5 << "{"accessTime":1434180752409,"blockSize":134217728,"childrenNum":0,"fileId":18595,"group":"supergroup","length":0,"modificationTime":1434180752419,"owner":"michaeljones","pathSuffix":"hello-apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-5 << "{"accessTime":1434091626279,"blockSize":134217728,"childrenNum":0,"fileId":18298,"group":"supergroup","length":0,"modificationTime":1434091626286,"owner":"michaeljones","pathSuffix":"hello-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-5 << "{"accessTime":1434180752331,"blockSize":134217728,"childrenNum":0,"fileId":18594,"group":"supergroup","length":0,"modificationTime":1434180752342,"owner":"michaeljones","pathSuffix":"hello-jersey-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-5 << "{"accessTime":1434180638087,"blockSize":134217728,"childrenNum":0,"fileId":18592,"group":"supergroup","length":1942304,"modificationTime":1434180638134,"owner":"michaeljones","pathSuffix":"hello.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-5 << "{"accessTime":1434180752856,"blockSize":134217728,"childrenNum":0,"fileId":18597,"group":"supergroup","length":3678856,"modificationTime":1434180753009,"owner":"michaeljones","pathSuffix":"hello.log.2015-06-12","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-5 << "{"accessTime":1434180756986,"blockSize":134217728,"childrenNum":0,"fileId":18599,"group":"supergroup","length":20,"modificationTime":1434180757588,"owner":"michaeljones","pathSuffix":"hello.txt","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-5 << "{"accessTime":1434180752714,"blockSize":134217728,"childrenNum":0,"fileId":18596,"group":"supergroup","length":113554,"modificationTime":1434180752741,"owner":"michaeljones","pathSuffix":"hellohadoop.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-5 << "{"accessTime":1434180638675,"blockSize":134217728,"childrenNum":0,"fileId":18593,"group":"supergroup","length":3644,"modificationTime":1434180638702,"owner":"michaeljones","pathSuffix":"nbactions.xml","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-5 << "{"accessTime":1434180567125,"blockSize":134217728,"childrenNum":0,"fileId":18589,"group":"supergroup","length":2134,"modificationTime":1434180567151,"owner":"michaeljones","pathSuffix":"pom.xml","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-5 << "{"accessTime":1434180758226,"blockSize":134217728,"childrenNum":0,"fileId":16388,"group":"supergroup","length":50,"modificationTime":1433119638967,"owner":"michaeljones","pathSuffix":"wcInput","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-5 << "{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18600,"group":"supergroup","length":0,"modificationTime":1434180760247,"owner":"michaeljones","pathSuffix":"wcOutput","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},[\n]"
http-outgoing-5 << "{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18607,"group":"supergroup","length":0,"modificationTime":1434180761544,"owner":"michaeljones","pathSuffix":"wcOutputAnalysis","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},[\n]"
http-outgoing-5 << "{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18614,"group":"supergroup","length":0,"modificationTime":1434180763349,"owner":"michaeljones","pathSuffix":"wcOutputMain","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"}[\n]"
http-outgoing-5 << "]}}[\n]"
http-outgoing-5 << "[\r][\n]"
http-outgoing-5 << HTTP/1.1 200 OK
http-outgoing-5 << Cache-Control: no-cache
http-outgoing-5 << Expires: Sat, 13 Jun 2015 07:32:44 GMT
http-outgoing-5 << Date: Sat, 13 Jun 2015 07:32:44 GMT
http-outgoing-5 << Pragma: no-cache
http-outgoing-5 << Expires: Sat, 13 Jun 2015 07:32:44 GMT
http-outgoing-5 << Date: Sat, 13 Jun 2015 07:32:44 GMT
http-outgoing-5 << Pragma: no-cache
http-outgoing-5 << Content-Type: application/json
http-outgoing-5 << Transfer-Encoding: chunked
http-outgoing-5 << Server: Jetty(6.1.26)
Connection can be kept alive indefinitely
http-outgoing-5 << "0[\r][\n]"
http-outgoing-5 << "[\r][\n]"
Connection [id: 5][route: {}->http://localhost:50070] can be kept alive indefinitely
Connection released: [id: 5][route: {}->http://localhost:50070][total kept alive: 1; route allocated: 1 of 2; total allocated: 1 of 20]
Apache client testGetStringContent
{"FileStatuses":{"FileStatus":[
{"accessTime":1434180753127,"blockSize":134217728,"childrenNum":0,"fileId":18598,"group":"supergroup","length":10899,"modificationTime":1434180753156,"owner":"michaeljones","pathSuffix":"README.md","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434167878992,"blockSize":134217728,"childrenNum":0,"fileId":18566,"group":"supergroup","length":0,"modificationTime":1434167878996,"owner":"michaeljones","pathSuffix":"apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434180637491,"blockSize":134217728,"childrenNum":0,"fileId":18590,"group":"supergroup","length":0,"modificationTime":1434180637503,"owner":"michaeljones","pathSuffix":"empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434180752409,"blockSize":134217728,"childrenNum":0,"fileId":18595,"group":"supergroup","length":0,"modificationTime":1434180752419,"owner":"michaeljones","pathSuffix":"hello-apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434091626279,"blockSize":134217728,"childrenNum":0,"fileId":18298,"group":"supergroup","length":0,"modificationTime":1434091626286,"owner":"michaeljones","pathSuffix":"hello-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434180752331,"blockSize":134217728,"childrenNum":0,"fileId":18594,"group":"supergroup","length":0,"modificationTime":1434180752342,"owner":"michaeljones","pathSuffix":"hello-jersey-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434180638087,"blockSize":134217728,"childrenNum":0,"fileId":18592,"group":"supergroup","length":1942304,"modificationTime":1434180638134,"owner":"michaeljones","pathSuffix":"hello.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434180752856,"blockSize":134217728,"childrenNum":0,"fileId":18597,"group":"supergroup","length":3678856,"modificationTime":1434180753009,"owner":"michaeljones","pathSuffix":"hello.log.2015-06-12","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434180756986,"blockSize":134217728,"childrenNum":0,"fileId":18599,"group":"supergroup","length":20,"modificationTime":1434180757588,"owner":"michaeljones","pathSuffix":"hello.txt","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434180752714,"blockSize":134217728,"childrenNum":0,"fileId":18596,"group":"supergroup","length":113554,"modificationTime":1434180752741,"owner":"michaeljones","pathSuffix":"hellohadoop.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434180638675,"blockSize":134217728,"childrenNum":0,"fileId":18593,"group":"supergroup","length":3644,"modificationTime":1434180638702,"owner":"michaeljones","pathSuffix":"nbactions.xml","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434180567125,"blockSize":134217728,"childrenNum":0,"fileId":18589,"group":"supergroup","length":2134,"modificationTime":1434180567151,"owner":"michaeljones","pathSuffix":"pom.xml","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434180758226,"blockSize":134217728,"childrenNum":0,"fileId":16388,"group":"supergroup","length":50,"modificationTime":1433119638967,"owner":"michaeljones","pathSuffix":"wcInput","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18600,"group":"supergroup","length":0,"modificationTime":1434180760247,"owner":"michaeljones","pathSuffix":"wcOutput","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},
{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18607,"group":"supergroup","length":0,"modificationTime":1434180761544,"owner":"michaeljones","pathSuffix":"wcOutputAnalysis","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},
{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18614,"group":"supergroup","length":0,"modificationTime":1434180763349,"owner":"michaeljones","pathSuffix":"wcOutputMain","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"}
]}}

CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 6][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://localhost:50070
Connecting to localhost/127.0.0.1:50070
Connection established 127.0.0.1:49961<->127.0.0.1:50070
Executing request PUT /webhdfs/v1/user/michaeljones/apache-empty.txt?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-6 >> PUT /webhdfs/v1/user/michaeljones/apache-empty.txt?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1
http-outgoing-6 >> Content-Length: 0
http-outgoing-6 >> Host: localhost:50070
http-outgoing-6 >> Connection: Keep-Alive
http-outgoing-6 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-6 >> Accept-Encoding: gzip,deflate
http-outgoing-6 >> "PUT /webhdfs/v1/user/michaeljones/apache-empty.txt?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1[\r][\n]"
http-outgoing-6 >> "Content-Length: 0[\r][\n]"
http-outgoing-6 >> "Host: localhost:50070[\r][\n]"
http-outgoing-6 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-6 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-6 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-6 >> "[\r][\n]"
http-outgoing-6 << "HTTP/1.1 307 TEMPORARY_REDIRECT[\r][\n]"
http-outgoing-6 << "Cache-Control: no-cache[\r][\n]"
http-outgoing-6 << "Expires: Sat, 13 Jun 2015 07:32:44 GMT[\r][\n]"
http-outgoing-6 << "Date: Sat, 13 Jun 2015 07:32:44 GMT[\r][\n]"
http-outgoing-6 << "Pragma: no-cache[\r][\n]"
http-outgoing-6 << "Expires: Sat, 13 Jun 2015 07:32:44 GMT[\r][\n]"
http-outgoing-6 << "Date: Sat, 13 Jun 2015 07:32:44 GMT[\r][\n]"
http-outgoing-6 << "Pragma: no-cache[\r][\n]"
http-outgoing-6 << "Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434216764089&s=nx1LrOxkAy53xcneK3pYupmv8yw="; Path=/; Expires=Sat, 13-Jun-2015 17:32:44 GMT; HttpOnly[\r][\n]"
http-outgoing-6 << "Location: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true[\r][\n]"
http-outgoing-6 << "Content-Type: application/octet-stream[\r][\n]"
http-outgoing-6 << "Content-Length: 0[\r][\n]"
http-outgoing-6 << "Server: Jetty(6.1.26)[\r][\n]"
http-outgoing-6 << "[\r][\n]"
http-outgoing-6 << HTTP/1.1 307 TEMPORARY_REDIRECT
http-outgoing-6 << Cache-Control: no-cache
http-outgoing-6 << Expires: Sat, 13 Jun 2015 07:32:44 GMT
http-outgoing-6 << Date: Sat, 13 Jun 2015 07:32:44 GMT
http-outgoing-6 << Pragma: no-cache
http-outgoing-6 << Expires: Sat, 13 Jun 2015 07:32:44 GMT
http-outgoing-6 << Date: Sat, 13 Jun 2015 07:32:44 GMT
http-outgoing-6 << Pragma: no-cache
http-outgoing-6 << Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434216764089&s=nx1LrOxkAy53xcneK3pYupmv8yw="; Path=/; Expires=Sat, 13-Jun-2015 17:32:44 GMT; HttpOnly
http-outgoing-6 << Location: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
http-outgoing-6 << Content-Type: application/octet-stream
http-outgoing-6 << Content-Length: 0
http-outgoing-6 << Server: Jetty(6.1.26)
Connection can be kept alive indefinitely
Cookie accepted [hadoop.auth=""u=michaeljones&p=michaeljones&t=simple&e=1434216764089&s=nx1LrOxkAy53xcneK3pYupmv8yw="", version:0, domain:localhost, path:/, expiry:Sun Jun 14 03:32:44 AEST 2015]
Redirect to: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
http-outgoing-6: Shutdown connection
Connection discarded
http-outgoing-6: Close connection
Connection released: [id: 6][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
PUT file redirect: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 7][route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://michaels-air.bigpond:50075
Connecting to michaels-air.bigpond/10.0.0.2:50075
Connection established 10.0.0.2:49962<->10.0.0.2:50075
Executing request PUT /webhdfs/v1/user/michaeljones/apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-7 >> PUT /webhdfs/v1/user/michaeljones/apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1
http-outgoing-7 >> Content-Length: 0
http-outgoing-7 >> Host: michaels-air.bigpond:50075
http-outgoing-7 >> Connection: Keep-Alive
http-outgoing-7 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-7 >> Accept-Encoding: gzip,deflate
http-outgoing-7 >> "PUT /webhdfs/v1/user/michaeljones/apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1[\r][\n]"
http-outgoing-7 >> "Content-Length: 0[\r][\n]"
http-outgoing-7 >> "Host: michaels-air.bigpond:50075[\r][\n]"
http-outgoing-7 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-7 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-7 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-7 >> "[\r][\n]"
http-outgoing-7 << "HTTP/1.1 100 Continue[\r][\n]"
http-outgoing-7 << "[\r][\n]"
http-outgoing-7 << HTTP/1.1 100 Continue
http-outgoing-7 << "HTTP/1.1 201 Created[\r][\n]"
http-outgoing-7 << "Location: hdfs://localhost:9000/user/michaeljones/apache-empty.txt[\r][\n]"
http-outgoing-7 << "Content-Length: 0[\r][\n]"
http-outgoing-7 << "Connection: close[\r][\n]"
http-outgoing-7 << "[\r][\n]"
http-outgoing-7 << HTTP/1.1 201 Created
http-outgoing-7 << Location: hdfs://localhost:9000/user/michaeljones/apache-empty.txt
http-outgoing-7 << Content-Length: 0
http-outgoing-7 << Connection: close
http-outgoing-7: Shutdown connection
Connection discarded
http-outgoing-7: Close connection
Connection released: [id: 7][route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 8][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://localhost:50070
Connecting to localhost/127.0.0.1:50070
Connection established 127.0.0.1:49964<->127.0.0.1:50070
Executing request PUT /webhdfs/v1/user/michaeljones/pom.xml?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-8 >> PUT /webhdfs/v1/user/michaeljones/pom.xml?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1
http-outgoing-8 >> Content-Length: 0
http-outgoing-8 >> Host: localhost:50070
http-outgoing-8 >> Connection: Keep-Alive
http-outgoing-8 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-8 >> Accept-Encoding: gzip,deflate
http-outgoing-8 >> "PUT /webhdfs/v1/user/michaeljones/pom.xml?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1[\r][\n]"
http-outgoing-8 >> "Content-Length: 0[\r][\n]"
http-outgoing-8 >> "Host: localhost:50070[\r][\n]"
http-outgoing-8 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-8 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-8 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-8 >> "[\r][\n]"
http-outgoing-8 << "HTTP/1.1 307 TEMPORARY_REDIRECT[\r][\n]"
http-outgoing-8 << "Cache-Control: no-cache[\r][\n]"
http-outgoing-8 << "Expires: Sat, 13 Jun 2015 07:32:44 GMT[\r][\n]"
http-outgoing-8 << "Date: Sat, 13 Jun 2015 07:32:44 GMT[\r][\n]"
http-outgoing-8 << "Pragma: no-cache[\r][\n]"
http-outgoing-8 << "Expires: Sat, 13 Jun 2015 07:32:44 GMT[\r][\n]"
http-outgoing-8 << "Date: Sat, 13 Jun 2015 07:32:44 GMT[\r][\n]"
http-outgoing-8 << "Pragma: no-cache[\r][\n]"
http-outgoing-8 << "Content-Type: application/octet-stream[\r][\n]"
http-outgoing-8 << "Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434216764142&s=fnBvxidtz5huoiPrLLpPTJRJdCM="; Path=/; Expires=Sat, 13-Jun-2015 17:32:44 GMT; HttpOnly[\r][\n]"
http-outgoing-8 << "Location: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/pom.xml?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true[\r][\n]"
http-outgoing-8 << "Content-Length: 0[\r][\n]"
http-outgoing-8 << "Server: Jetty(6.1.26)[\r][\n]"
http-outgoing-8 << "[\r][\n]"
http-outgoing-8 << HTTP/1.1 307 TEMPORARY_REDIRECT
http-outgoing-8 << Cache-Control: no-cache
http-outgoing-8 << Expires: Sat, 13 Jun 2015 07:32:44 GMT
http-outgoing-8 << Date: Sat, 13 Jun 2015 07:32:44 GMT
http-outgoing-8 << Pragma: no-cache
http-outgoing-8 << Expires: Sat, 13 Jun 2015 07:32:44 GMT
http-outgoing-8 << Date: Sat, 13 Jun 2015 07:32:44 GMT
http-outgoing-8 << Pragma: no-cache
http-outgoing-8 << Content-Type: application/octet-stream
http-outgoing-8 << Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434216764142&s=fnBvxidtz5huoiPrLLpPTJRJdCM="; Path=/; Expires=Sat, 13-Jun-2015 17:32:44 GMT; HttpOnly
http-outgoing-8 << Location: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/pom.xml?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
http-outgoing-8 << Content-Length: 0
http-outgoing-8 << Server: Jetty(6.1.26)
Connection can be kept alive indefinitely
Cookie accepted [hadoop.auth=""u=michaeljones&p=michaeljones&t=simple&e=1434216764142&s=fnBvxidtz5huoiPrLLpPTJRJdCM="", version:0, domain:localhost, path:/, expiry:Sun Jun 14 03:32:44 AEST 2015]
Redirect to: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/pom.xml?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
http-outgoing-8: Shutdown connection
Connection discarded
http-outgoing-8: Close connection
Connection released: [id: 8][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
PUT file redirect: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/pom.xml?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 9][route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://michaels-air.bigpond:50075
Connecting to michaels-air.bigpond/10.0.0.2:50075
Connection established 10.0.0.2:49965<->10.0.0.2:50075
Executing request PUT /webhdfs/v1/user/michaeljones/pom.xml?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-9 >> PUT /webhdfs/v1/user/michaeljones/pom.xml?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1
http-outgoing-9 >> Transfer-Encoding: chunked
http-outgoing-9 >> Content-Type: application/octet-stream
http-outgoing-9 >> Host: michaels-air.bigpond:50075
http-outgoing-9 >> Connection: Keep-Alive
http-outgoing-9 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-9 >> Accept-Encoding: gzip,deflate
http-outgoing-9 >> "PUT /webhdfs/v1/user/michaeljones/pom.xml?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1[\r][\n]"
http-outgoing-9 >> "Transfer-Encoding: chunked[\r][\n]"
http-outgoing-9 >> "Content-Type: application/octet-stream[\r][\n]"
http-outgoing-9 >> "Host: michaels-air.bigpond:50075[\r][\n]"
http-outgoing-9 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-9 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-9 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-9 >> "[\r][\n]"
http-outgoing-9 >> "856[\r][\n]"
http-outgoing-9 >> "<?xml version="1.0" encoding="UTF-8"?>[\n]"
http-outgoing-9 >> "<project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">[\n]"
http-outgoing-9 >> "    <modelVersion>4.0.0</modelVersion>[\n]"
http-outgoing-9 >> "    <groupId>com.michaeljones</groupId>[\n]"
http-outgoing-9 >> "    <artifactId>HelloHadoopWorldMaven</artifactId>[\n]"
http-outgoing-9 >> "    <version>1.0-SNAPSHOT</version>[\n]"
http-outgoing-9 >> "    <packaging>jar</packaging>[\n]"
http-outgoing-9 >> "    <dependencies>[\n]"
http-outgoing-9 >> "        <!-- run bin/hadoop version to see the jar it was built with, which is this dependency -->[\n]"
http-outgoing-9 >> "        <dependency>[\n]"
http-outgoing-9 >> "            <groupId>org.apache.hadoop</groupId>[\n]"
http-outgoing-9 >> "            <artifactId>hadoop-common</artifactId>[\n]"
http-outgoing-9 >> "            <version>2.7.0</version>[\n]"
http-outgoing-9 >> "        </dependency>[\n]"
http-outgoing-9 >> "        <dependency>[\n]"
http-outgoing-9 >> "            <groupId>org.apache.hadoop</groupId>[\n]"
http-outgoing-9 >> "            <artifactId>hadoop-hdfs</artifactId>[\n]"
http-outgoing-9 >> "            <version>2.7.0</version>[\n]"
http-outgoing-9 >> "        </dependency>[\n]"
http-outgoing-9 >> "        <dependency>[\n]"
http-outgoing-9 >> "            <groupId>junit</groupId>[\n]"
http-outgoing-9 >> "            <artifactId>junit</artifactId>[\n]"
http-outgoing-9 >> "            <version>4.10</version>[\n]"
http-outgoing-9 >> "            <scope>test</scope>[\n]"
http-outgoing-9 >> "        </dependency>[\n]"
http-outgoing-9 >> "        <dependency>[\n]"
http-outgoing-9 >> "            <groupId>org.apache.hadoop</groupId>[\n]"
http-outgoing-9 >> "            <artifactId>hadoop-mapreduce-client-core</artifactId>[\n]"
http-outgoing-9 >> "            <version>2.7.0</version>[\n]"
http-outgoing-9 >> "        </dependency>[\n]"
http-outgoing-9 >> "        <dependency>[\n]"
http-outgoing-9 >> "            <groupId>org.apache.hadoop</groupId>[\n]"
http-outgoing-9 >> "            <artifactId>hadoop-mapreduce-client-common</artifactId>[\n]"
http-outgoing-9 >> "            <version>2.7.0</version>[\n]"
http-outgoing-9 >> "        </dependency>[\n]"
http-outgoing-9 >> "        <dependency>[\n]"
http-outgoing-9 >> "            <groupId>com.googlecode.json-simple</groupId>[\n]"
http-outgoing-9 >> "            <artifactId>json-simple</artifactId>[\n]"
http-outgoing-9 >> "            <version>1.1.1</version>[\n]"
http-outgoing-9 >> "        </dependency>[\n]"
http-outgoing-9 >> "        <dependency>[\n]"
http-outgoing-9 >> "            <groupId>org.apache.httpcomponents</groupId>[\n]"
http-outgoing-9 >> "            <artifactId>httpclient</artifactId>[\n]"
http-outgoing-9 >> "            <version>4.4-beta1</version>[\n]"
http-outgoing-9 >> "        </dependency>[\n]"
http-outgoing-9 >> "    </dependencies>[\n]"
http-outgoing-9 >> "    <properties>[\n]"
http-outgoing-9 >> "        <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>[\n]"
http-outgoing-9 >> "        <maven.compiler.source>1.7</maven.compiler.source>[\n]"
http-outgoing-9 >> "        <maven.compiler.target>1.7</maven.compiler.target>[\n]"
http-outgoing-9 >> "    </properties>[\n]"
http-outgoing-9 >> "</project>[\r][\n]"
http-outgoing-9 >> "0[\r][\n]"
http-outgoing-9 >> "[\r][\n]"
http-outgoing-9 << "HTTP/1.1 100 Continue[\r][\n]"
http-outgoing-9 << "[\r][\n]"
http-outgoing-9 << HTTP/1.1 100 Continue
http-outgoing-9 << "HTTP/1.1 201 Created[\r][\n]"
http-outgoing-9 << "Location: hdfs://localhost:9000/user/michaeljones/pom.xml[\r][\n]"
http-outgoing-9 << "Content-Length: 0[\r][\n]"
http-outgoing-9 << "Connection: close[\r][\n]"
http-outgoing-9 << "[\r][\n]"
http-outgoing-9 << HTTP/1.1 201 Created
http-outgoing-9 << Location: hdfs://localhost:9000/user/michaeljones/pom.xml
http-outgoing-9 << Content-Length: 0
http-outgoing-9 << Connection: close
http-outgoing-9: Shutdown connection
Connection discarded
http-outgoing-9: Close connection
Connection released: [id: 9][route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection manager is shutting down
Connection manager shut down
Jersey client testGetStringContent
{"FileStatuses":{"FileStatus":[
{"accessTime":1434180753127,"blockSize":134217728,"childrenNum":0,"fileId":18598,"group":"supergroup","length":10899,"modificationTime":1434180753156,"owner":"michaeljones","pathSuffix":"README.md","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434180764122,"blockSize":134217728,"childrenNum":0,"fileId":18621,"group":"supergroup","length":0,"modificationTime":1434180764129,"owner":"michaeljones","pathSuffix":"apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434180637491,"blockSize":134217728,"childrenNum":0,"fileId":18590,"group":"supergroup","length":0,"modificationTime":1434180637503,"owner":"michaeljones","pathSuffix":"empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434180752409,"blockSize":134217728,"childrenNum":0,"fileId":18595,"group":"supergroup","length":0,"modificationTime":1434180752419,"owner":"michaeljones","pathSuffix":"hello-apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434091626279,"blockSize":134217728,"childrenNum":0,"fileId":18298,"group":"supergroup","length":0,"modificationTime":1434091626286,"owner":"michaeljones","pathSuffix":"hello-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434180752331,"blockSize":134217728,"childrenNum":0,"fileId":18594,"group":"supergroup","length":0,"modificationTime":1434180752342,"owner":"michaeljones","pathSuffix":"hello-jersey-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434180638087,"blockSize":134217728,"childrenNum":0,"fileId":18592,"group":"supergroup","length":1942304,"modificationTime":1434180638134,"owner":"michaeljones","pathSuffix":"hello.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434180752856,"blockSize":134217728,"childrenNum":0,"fileId":18597,"group":"supergroup","length":3678856,"modificationTime":1434180753009,"owner":"michaeljones","pathSuffix":"hello.log.2015-06-12","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434180756986,"blockSize":134217728,"childrenNum":0,"fileId":18599,"group":"supergroup","length":20,"modificationTime":1434180757588,"owner":"michaeljones","pathSuffix":"hello.txt","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434180752714,"blockSize":134217728,"childrenNum":0,"fileId":18596,"group":"supergroup","length":113554,"modificationTime":1434180752741,"owner":"michaeljones","pathSuffix":"hellohadoop.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434180638675,"blockSize":134217728,"childrenNum":0,"fileId":18593,"group":"supergroup","length":3644,"modificationTime":1434180638702,"owner":"michaeljones","pathSuffix":"nbactions.xml","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434180764163,"blockSize":134217728,"childrenNum":0,"fileId":18622,"group":"supergroup","length":2134,"modificationTime":1434180764193,"owner":"michaeljones","pathSuffix":"pom.xml","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434180758226,"blockSize":134217728,"childrenNum":0,"fileId":16388,"group":"supergroup","length":50,"modificationTime":1433119638967,"owner":"michaeljones","pathSuffix":"wcInput","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18600,"group":"supergroup","length":0,"modificationTime":1434180760247,"owner":"michaeljones","pathSuffix":"wcOutput","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},
{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18607,"group":"supergroup","length":0,"modificationTime":1434180761544,"owner":"michaeljones","pathSuffix":"wcOutputAnalysis","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},
{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18614,"group":"supergroup","length":0,"modificationTime":1434180763349,"owner":"michaeljones","pathSuffix":"wcOutputMain","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"}
]}}

Connection manager is shutting down
Connection manager shut down
Connection manager is shutting down
http-outgoing-5: Close connection
http-outgoing-5: Close connection
Connection manager shut down
Connection manager is shutting down
Connection manager shut down
com.sun.jersey.client.property.chunkedEncodingSize: 1048576
Jersey client Redirect to: hdfs://localhost:9000/user/michaeljones/hello.log
Jersey redirected to IPC: hdfs://localhost:9000/user/michaeljones/hello.log
com.sun.jersey.client.property.chunkedEncodingSize: 1048576
Jersey client Redirect to: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/nbactions.xml?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
stopping client from cache: org.apache.hadoop.ipc.Client@22d7b4f8
removing client from cache: org.apache.hadoop.ipc.Client@22d7b4f8
stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@22d7b4f8
Stopping client
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones: closed
IPC Client (1277108979) connection to localhost/127.0.0.1:9000 from michaeljones: stopped, remaining connections 0

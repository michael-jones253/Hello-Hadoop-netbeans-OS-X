Jersey client testGetStringContent
{"FileStatuses":{"FileStatus":[
{"accessTime":1434180753127,"blockSize":134217728,"childrenNum":0,"fileId":18598,"group":"supergroup","length":10899,"modificationTime":1434180753156,"owner":"michaeljones","pathSuffix":"README.md","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434180764122,"blockSize":134217728,"childrenNum":0,"fileId":18621,"group":"supergroup","length":0,"modificationTime":1434180764129,"owner":"michaeljones","pathSuffix":"apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434180765102,"blockSize":134217728,"childrenNum":0,"fileId":18624,"group":"supergroup","length":0,"modificationTime":1434180765107,"owner":"michaeljones","pathSuffix":"empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434180752409,"blockSize":134217728,"childrenNum":0,"fileId":18595,"group":"supergroup","length":0,"modificationTime":1434180752419,"owner":"michaeljones","pathSuffix":"hello-apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434091626279,"blockSize":134217728,"childrenNum":0,"fileId":18298,"group":"supergroup","length":0,"modificationTime":1434091626286,"owner":"michaeljones","pathSuffix":"hello-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434180752331,"blockSize":134217728,"childrenNum":0,"fileId":18594,"group":"supergroup","length":0,"modificationTime":1434180752342,"owner":"michaeljones","pathSuffix":"hello-jersey-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434180765218,"blockSize":134217728,"childrenNum":0,"fileId":18625,"group":"supergroup","length":2353098,"modificationTime":1434180765322,"owner":"michaeljones","pathSuffix":"hello.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434180752856,"blockSize":134217728,"childrenNum":0,"fileId":18597,"group":"supergroup","length":3678856,"modificationTime":1434180753009,"owner":"michaeljones","pathSuffix":"hello.log.2015-06-12","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434180756986,"blockSize":134217728,"childrenNum":0,"fileId":18599,"group":"supergroup","length":20,"modificationTime":1434180757588,"owner":"michaeljones","pathSuffix":"hello.txt","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434180752714,"blockSize":134217728,"childrenNum":0,"fileId":18596,"group":"supergroup","length":113554,"modificationTime":1434180752741,"owner":"michaeljones","pathSuffix":"hellohadoop.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434180765608,"blockSize":134217728,"childrenNum":0,"fileId":18626,"group":"supergroup","length":3644,"modificationTime":1434180765630,"owner":"michaeljones","pathSuffix":"nbactions.xml","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434180764163,"blockSize":134217728,"childrenNum":0,"fileId":18622,"group":"supergroup","length":2134,"modificationTime":1434180764193,"owner":"michaeljones","pathSuffix":"pom.xml","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434180758226,"blockSize":134217728,"childrenNum":0,"fileId":16388,"group":"supergroup","length":50,"modificationTime":1433119638967,"owner":"michaeljones","pathSuffix":"wcInput","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18600,"group":"supergroup","length":0,"modificationTime":1434180760247,"owner":"michaeljones","pathSuffix":"wcOutput","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},
{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18607,"group":"supergroup","length":0,"modificationTime":1434180761544,"owner":"michaeljones","pathSuffix":"wcOutputAnalysis","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},
{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18614,"group":"supergroup","length":0,"modificationTime":1434180763349,"owner":"michaeljones","pathSuffix":"wcOutputMain","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"}
]}}

Jersey client Redirect to: hdfs://localhost:9000/user/michaeljones/hello.log
Jersey redirected to IPC: hdfs://localhost:9000/user/michaeljones/hello.log
com.sun.jersey.client.property.chunkedEncodingSize: 1048576
com.sun.jersey.client.property.chunkedEncodingSize: 1048576
Jersey client Redirect to: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/nbactions.xml?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
com.sun.jersey.client.property.chunkedEncodingSize: 1048576
Jersey client testGetStringContent
{"FileStatuses":{"FileStatus":[
{"accessTime":1434180753127,"blockSize":134217728,"childrenNum":0,"fileId":18598,"group":"supergroup","length":10899,"modificationTime":1434180753156,"owner":"michaeljones","pathSuffix":"README.md","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434180764122,"blockSize":134217728,"childrenNum":0,"fileId":18621,"group":"supergroup","length":0,"modificationTime":1434180764129,"owner":"michaeljones","pathSuffix":"apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434239985548,"blockSize":134217728,"childrenNum":0,"fileId":18627,"group":"supergroup","length":0,"modificationTime":1434239985662,"owner":"michaeljones","pathSuffix":"empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434180752409,"blockSize":134217728,"childrenNum":0,"fileId":18595,"group":"supergroup","length":0,"modificationTime":1434180752419,"owner":"michaeljones","pathSuffix":"hello-apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434091626279,"blockSize":134217728,"childrenNum":0,"fileId":18298,"group":"supergroup","length":0,"modificationTime":1434091626286,"owner":"michaeljones","pathSuffix":"hello-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434180752331,"blockSize":134217728,"childrenNum":0,"fileId":18594,"group":"supergroup","length":0,"modificationTime":1434180752342,"owner":"michaeljones","pathSuffix":"hello-jersey-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434239987004,"blockSize":134217728,"childrenNum":0,"fileId":18629,"group":"supergroup","length":4481,"modificationTime":1434239987034,"owner":"michaeljones","pathSuffix":"hello.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434180752856,"blockSize":134217728,"childrenNum":0,"fileId":18597,"group":"supergroup","length":3678856,"modificationTime":1434180753009,"owner":"michaeljones","pathSuffix":"hello.log.2015-06-12","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434180756986,"blockSize":134217728,"childrenNum":0,"fileId":18599,"group":"supergroup","length":20,"modificationTime":1434180757588,"owner":"michaeljones","pathSuffix":"hello.txt","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434180752714,"blockSize":134217728,"childrenNum":0,"fileId":18596,"group":"supergroup","length":113554,"modificationTime":1434180752741,"owner":"michaeljones","pathSuffix":"hellohadoop.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434239987676,"blockSize":134217728,"childrenNum":0,"fileId":18630,"group":"supergroup","length":3644,"modificationTime":1434239987702,"owner":"michaeljones","pathSuffix":"nbactions.xml","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434180764163,"blockSize":134217728,"childrenNum":0,"fileId":18622,"group":"supergroup","length":2134,"modificationTime":1434180764193,"owner":"michaeljones","pathSuffix":"pom.xml","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434180758226,"blockSize":134217728,"childrenNum":0,"fileId":16388,"group":"supergroup","length":50,"modificationTime":1433119638967,"owner":"michaeljones","pathSuffix":"wcInput","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18600,"group":"supergroup","length":0,"modificationTime":1434180760247,"owner":"michaeljones","pathSuffix":"wcOutput","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},
{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18607,"group":"supergroup","length":0,"modificationTime":1434180761544,"owner":"michaeljones","pathSuffix":"wcOutputAnalysis","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},
{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18614,"group":"supergroup","length":0,"modificationTime":1434180763349,"owner":"michaeljones","pathSuffix":"wcOutputMain","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"}
]}}

Jersey client Redirect to: hdfs://localhost:9000/user/michaeljones/hello.log
Jersey redirected to IPC: hdfs://localhost:9000/user/michaeljones/hello.log
com.sun.jersey.client.property.chunkedEncodingSize: 1048576
com.sun.jersey.client.property.chunkedEncodingSize: 1048576
Jersey client Redirect to: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/nbactions.xml?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
com.sun.jersey.client.property.chunkedEncodingSize: 1048576
Jersey client Redirect to: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/nbactions.xml?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
Jersey client testGetStringContent
{"FileStatuses":{"FileStatus":[
{"accessTime":1434180753127,"blockSize":134217728,"childrenNum":0,"fileId":18598,"group":"supergroup","length":10899,"modificationTime":1434180753156,"owner":"michaeljones","pathSuffix":"README.md","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434180764122,"blockSize":134217728,"childrenNum":0,"fileId":18621,"group":"supergroup","length":0,"modificationTime":1434180764129,"owner":"michaeljones","pathSuffix":"apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434240142080,"blockSize":134217728,"childrenNum":0,"fileId":18631,"group":"supergroup","length":0,"modificationTime":1434240142086,"owner":"michaeljones","pathSuffix":"empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434180752409,"blockSize":134217728,"childrenNum":0,"fileId":18595,"group":"supergroup","length":0,"modificationTime":1434180752419,"owner":"michaeljones","pathSuffix":"hello-apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434091626279,"blockSize":134217728,"childrenNum":0,"fileId":18298,"group":"supergroup","length":0,"modificationTime":1434091626286,"owner":"michaeljones","pathSuffix":"hello-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434180752331,"blockSize":134217728,"childrenNum":0,"fileId":18594,"group":"supergroup","length":0,"modificationTime":1434180752342,"owner":"michaeljones","pathSuffix":"hello-jersey-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434240142568,"blockSize":134217728,"childrenNum":0,"fileId":18633,"group":"supergroup","length":9325,"modificationTime":1434240142601,"owner":"michaeljones","pathSuffix":"hello.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434180752856,"blockSize":134217728,"childrenNum":0,"fileId":18597,"group":"supergroup","length":3678856,"modificationTime":1434180753009,"owner":"michaeljones","pathSuffix":"hello.log.2015-06-12","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434180756986,"blockSize":134217728,"childrenNum":0,"fileId":18599,"group":"supergroup","length":20,"modificationTime":1434180757588,"owner":"michaeljones","pathSuffix":"hello.txt","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434180752714,"blockSize":134217728,"childrenNum":0,"fileId":18596,"group":"supergroup","length":113554,"modificationTime":1434180752741,"owner":"michaeljones","pathSuffix":"hellohadoop.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434240143148,"blockSize":134217728,"childrenNum":0,"fileId":18634,"group":"supergroup","length":3644,"modificationTime":1434240143188,"owner":"michaeljones","pathSuffix":"nbactions.xml","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434180764163,"blockSize":134217728,"childrenNum":0,"fileId":18622,"group":"supergroup","length":2134,"modificationTime":1434180764193,"owner":"michaeljones","pathSuffix":"pom.xml","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434180758226,"blockSize":134217728,"childrenNum":0,"fileId":16388,"group":"supergroup","length":50,"modificationTime":1433119638967,"owner":"michaeljones","pathSuffix":"wcInput","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18600,"group":"supergroup","length":0,"modificationTime":1434180760247,"owner":"michaeljones","pathSuffix":"wcOutput","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},
{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18607,"group":"supergroup","length":0,"modificationTime":1434180761544,"owner":"michaeljones","pathSuffix":"wcOutputAnalysis","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},
{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18614,"group":"supergroup","length":0,"modificationTime":1434180763349,"owner":"michaeljones","pathSuffix":"wcOutputMain","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"}
]}}

Jersey client Redirect to: hdfs://localhost:9000/user/michaeljones/hello.log
Jersey redirected to IPC: hdfs://localhost:9000/user/michaeljones/hello.log
com.sun.jersey.client.property.chunkedEncodingSize: 1048576
com.sun.jersey.client.property.chunkedEncodingSize: 1048576
Jersey client Redirect to: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/nbactions.xml?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
com.sun.jersey.client.property.chunkedEncodingSize: 1048576
Jersey client Redirect to: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/nbactions.xml?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
Get redirect location async: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/nbactions.xml?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
Jersey client testGetStringContent
{"FileStatuses":{"FileStatus":[
{"accessTime":1434180753127,"blockSize":134217728,"childrenNum":0,"fileId":18598,"group":"supergroup","length":10899,"modificationTime":1434180753156,"owner":"michaeljones","pathSuffix":"README.md","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434180764122,"blockSize":134217728,"childrenNum":0,"fileId":18621,"group":"supergroup","length":0,"modificationTime":1434180764129,"owner":"michaeljones","pathSuffix":"apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434240250112,"blockSize":134217728,"childrenNum":0,"fileId":18635,"group":"supergroup","length":0,"modificationTime":1434240250121,"owner":"michaeljones","pathSuffix":"empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434180752409,"blockSize":134217728,"childrenNum":0,"fileId":18595,"group":"supergroup","length":0,"modificationTime":1434180752419,"owner":"michaeljones","pathSuffix":"hello-apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434091626279,"blockSize":134217728,"childrenNum":0,"fileId":18298,"group":"supergroup","length":0,"modificationTime":1434091626286,"owner":"michaeljones","pathSuffix":"hello-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434180752331,"blockSize":134217728,"childrenNum":0,"fileId":18594,"group":"supergroup","length":0,"modificationTime":1434180752342,"owner":"michaeljones","pathSuffix":"hello-jersey-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434240250579,"blockSize":134217728,"childrenNum":0,"fileId":18637,"group":"supergroup","length":14355,"modificationTime":1434240250609,"owner":"michaeljones","pathSuffix":"hello.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434180752856,"blockSize":134217728,"childrenNum":0,"fileId":18597,"group":"supergroup","length":3678856,"modificationTime":1434180753009,"owner":"michaeljones","pathSuffix":"hello.log.2015-06-12","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434180756986,"blockSize":134217728,"childrenNum":0,"fileId":18599,"group":"supergroup","length":20,"modificationTime":1434180757588,"owner":"michaeljones","pathSuffix":"hello.txt","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434180752714,"blockSize":134217728,"childrenNum":0,"fileId":18596,"group":"supergroup","length":113554,"modificationTime":1434180752741,"owner":"michaeljones","pathSuffix":"hellohadoop.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434240251224,"blockSize":134217728,"childrenNum":0,"fileId":18638,"group":"supergroup","length":3644,"modificationTime":1434240251257,"owner":"michaeljones","pathSuffix":"nbactions.xml","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434180764163,"blockSize":134217728,"childrenNum":0,"fileId":18622,"group":"supergroup","length":2134,"modificationTime":1434180764193,"owner":"michaeljones","pathSuffix":"pom.xml","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434180758226,"blockSize":134217728,"childrenNum":0,"fileId":16388,"group":"supergroup","length":50,"modificationTime":1433119638967,"owner":"michaeljones","pathSuffix":"wcInput","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18600,"group":"supergroup","length":0,"modificationTime":1434180760247,"owner":"michaeljones","pathSuffix":"wcOutput","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},
{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18607,"group":"supergroup","length":0,"modificationTime":1434180761544,"owner":"michaeljones","pathSuffix":"wcOutputAnalysis","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},
{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18614,"group":"supergroup","length":0,"modificationTime":1434180763349,"owner":"michaeljones","pathSuffix":"wcOutputMain","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"}
]}}

Jersey client Redirect to: hdfs://localhost:9000/user/michaeljones/hello.log
Jersey redirected to IPC: hdfs://localhost:9000/user/michaeljones/hello.log
com.sun.jersey.client.property.chunkedEncodingSize: 1048576
com.sun.jersey.client.property.chunkedEncodingSize: 1048576
Jersey client Redirect to: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/nbactions.xml?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
com.sun.jersey.client.property.chunkedEncodingSize: 1048576
Jersey client Redirect to: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/nbactions.xml?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
Get redirect location async: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/nbactions.xml?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 0][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://localhost:50070
Connecting to localhost/127.0.0.1:50070
Connection established 127.0.0.1:49711<->127.0.0.1:50070
Executing request GET /webhdfs/v1/user/michaeljones/?user.name=michaeljones&op=LISTSTATUS HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-0 >> GET /webhdfs/v1/user/michaeljones/?user.name=michaeljones&op=LISTSTATUS HTTP/1.1
http-outgoing-0 >> accept: application/json
http-outgoing-0 >> Host: localhost:50070
http-outgoing-0 >> Connection: Keep-Alive
http-outgoing-0 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-0 >> Accept-Encoding: gzip,deflate
http-outgoing-0 >> "GET /webhdfs/v1/user/michaeljones/?user.name=michaeljones&op=LISTSTATUS HTTP/1.1[\r][\n]"
http-outgoing-0 >> "accept: application/json[\r][\n]"
http-outgoing-0 >> "Host: localhost:50070[\r][\n]"
http-outgoing-0 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-0 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-0 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-0 >> "[\r][\n]"
http-outgoing-0 << "HTTP/1.1 200 OK[\r][\n]"
http-outgoing-0 << "Cache-Control: no-cache[\r][\n]"
http-outgoing-0 << "Expires: Sun, 14 Jun 2015 00:28:43 GMT[\r][\n]"
http-outgoing-0 << "Date: Sun, 14 Jun 2015 00:28:43 GMT[\r][\n]"
http-outgoing-0 << "Pragma: no-cache[\r][\n]"
http-outgoing-0 << "Expires: Sun, 14 Jun 2015 00:28:43 GMT[\r][\n]"
http-outgoing-0 << "Date: Sun, 14 Jun 2015 00:28:43 GMT[\r][\n]"
http-outgoing-0 << "Pragma: no-cache[\r][\n]"
http-outgoing-0 << "Content-Type: application/json[\r][\n]"
http-outgoing-0 << "Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434277723456&s=l9Fivhy3+QHAh/iLs+ZaweF7ytQ="; Path=/; Expires=Sun, 14-Jun-2015 10:28:43 GMT; HttpOnly[\r][\n]"
http-outgoing-0 << "Transfer-Encoding: chunked[\r][\n]"
http-outgoing-0 << "Server: Jetty(6.1.26)[\r][\n]"
http-outgoing-0 << "[\r][\n]"
http-outgoing-0 << "10C2[\r][\n]"
http-outgoing-0 << "{"FileStatuses":{"FileStatus":[[\n]"
http-outgoing-0 << "{"accessTime":1434180753127,"blockSize":134217728,"childrenNum":0,"fileId":18598,"group":"supergroup","length":10899,"modificationTime":1434180753156,"owner":"michaeljones","pathSuffix":"README.md","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434180764122,"blockSize":134217728,"childrenNum":0,"fileId":18621,"group":"supergroup","length":0,"modificationTime":1434180764129,"owner":"michaeljones","pathSuffix":"apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434240295990,"blockSize":134217728,"childrenNum":0,"fileId":18639,"group":"supergroup","length":0,"modificationTime":1434240295996,"owner":"michaeljones","pathSuffix":"empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434180752409,"blockSize":134217728,"childrenNum":0,"fileId":18595,"group":"supergroup","length":0,"modificationTime":1434180752419,"owner":"michaeljones","pathSuffix":"hello-apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434091626279,"blockSize":134217728,"childrenNum":0,"fileId":18298,"group":"supergroup","length":0,"modificationTime":1434091626286,"owner":"michaeljones","pathSuffix":"hello-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434180752331,"blockSize":134217728,"childrenNum":0,"fileId":18594,"group":"supergroup","length":0,"modificationTime":1434180752342,"owner":"michaeljones","pathSuffix":"hello-jersey-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434240296439,"blockSize":134217728,"childrenNum":0,"fileId":18641,"group":"supergroup","length":19574,"modificationTime":1434240296468,"owner":"michaeljones","pathSuffix":"hello.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434180752856,"blockSize":134217728,"childrenNum":0,"fileId":18597,"group":"supergroup","length":3678856,"modificationTime":1434180753009,"owner":"michaeljones","pathSuffix":"hello.log.2015-06-12","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434180756986,"blockSize":134217728,"childrenNum":0,"fileId":18599,"group":"supergroup","length":20,"modificationTime":1434180757588,"owner":"michaeljones","pathSuffix":"hello.txt","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434180752714,"blockSize":134217728,"childrenNum":0,"fileId":18596,"group":"supergroup","length":113554,"modificationTime":1434180752741,"owner":"michaeljones","pathSuffix":"hellohadoop.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434240297021,"blockSize":134217728,"childrenNum":0,"fileId":18642,"group":"supergroup","length":3644,"modificationTime":1434240297054,"owner":"michaeljones","pathSuffix":"nbactions.xml","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434180764163,"blockSize":134217728,"childrenNum":0,"fileId":18622,"group":"supergroup","length":2134,"modificationTime":1434180764193,"owner":"michaeljones","pathSuffix":"pom.xml","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434180758226,"blockSize":134217728,"childrenNum":0,"fileId":16388,"group":"supergroup","length":50,"modificationTime":1433119638967,"owner":"michaeljones","pathSuffix":"wcInput","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18600,"group":"supergroup","length":0,"modificationTime":1434180760247,"owner":"michaeljones","pathSuffix":"wcOutput","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},[\n]"
http-outgoing-0 << "{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18607,"group":"supergroup","length":0,"modificationTime":1434180761544,"owner":"michaeljones","pathSuffix":"wcOutputAnalysis","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},[\n]"
http-outgoing-0 << "{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18614,"group":"supergroup","length":0,"modificationTime":1434180763349,"owner":"michaeljones","pathSuffix":"wcOutputMain","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"}[\n]"
http-outgoing-0 << "]}}[\n]"
http-outgoing-0 << "[\r][\n]"
http-outgoing-0 << "0[\r][\n]"
http-outgoing-0 << "[\r][\n]"
http-outgoing-0 << HTTP/1.1 200 OK
http-outgoing-0 << Cache-Control: no-cache
http-outgoing-0 << Expires: Sun, 14 Jun 2015 00:28:43 GMT
http-outgoing-0 << Date: Sun, 14 Jun 2015 00:28:43 GMT
http-outgoing-0 << Pragma: no-cache
http-outgoing-0 << Expires: Sun, 14 Jun 2015 00:28:43 GMT
http-outgoing-0 << Date: Sun, 14 Jun 2015 00:28:43 GMT
http-outgoing-0 << Pragma: no-cache
http-outgoing-0 << Content-Type: application/json
http-outgoing-0 << Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434277723456&s=l9Fivhy3+QHAh/iLs+ZaweF7ytQ="; Path=/; Expires=Sun, 14-Jun-2015 10:28:43 GMT; HttpOnly
http-outgoing-0 << Transfer-Encoding: chunked
http-outgoing-0 << Server: Jetty(6.1.26)
Connection can be kept alive indefinitely
Cookie accepted [hadoop.auth=""u=michaeljones&p=michaeljones&t=simple&e=1434277723456&s=l9Fivhy3+QHAh/iLs+ZaweF7ytQ="", version:0, domain:localhost, path:/, expiry:Sun Jun 14 20:28:43 AEST 2015]
Connection [id: 0][route: {}->http://localhost:50070] can be kept alive indefinitely
Connection released: [id: 0][route: {}->http://localhost:50070][total kept alive: 1; route allocated: 1 of 2; total allocated: 1 of 20]
Connection manager is shutting down
http-outgoing-0: Close connection
http-outgoing-0: Close connection
Connection manager shut down
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 1][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://localhost:50070
Connecting to localhost/127.0.0.1:50070
Connection established 127.0.0.1:49714<->127.0.0.1:50070
Executing request PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-1 >> PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1
http-outgoing-1 >> Content-Length: 0
http-outgoing-1 >> Host: localhost:50070
http-outgoing-1 >> Connection: Keep-Alive
http-outgoing-1 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-1 >> Accept-Encoding: gzip,deflate
http-outgoing-1 >> "PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1[\r][\n]"
http-outgoing-1 >> "Content-Length: 0[\r][\n]"
http-outgoing-1 >> "Host: localhost:50070[\r][\n]"
http-outgoing-1 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-1 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-1 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-1 >> "[\r][\n]"
http-outgoing-1 << "HTTP/1.1 307 TEMPORARY_REDIRECT[\r][\n]"
http-outgoing-1 << "Cache-Control: no-cache[\r][\n]"
http-outgoing-1 << "Expires: Sun, 14 Jun 2015 00:28:43 GMT[\r][\n]"
http-outgoing-1 << "Date: Sun, 14 Jun 2015 00:28:43 GMT[\r][\n]"
http-outgoing-1 << "Pragma: no-cache[\r][\n]"
http-outgoing-1 << "Expires: Sun, 14 Jun 2015 00:28:43 GMT[\r][\n]"
http-outgoing-1 << "Date: Sun, 14 Jun 2015 00:28:43 GMT[\r][\n]"
http-outgoing-1 << "Pragma: no-cache[\r][\n]"
http-outgoing-1 << "Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434277723999&s=UQiUc9ceH3dlc+4byo/DLH6eJQ0="; Path=/; Expires=Sun, 14-Jun-2015 10:28:43 GMT; HttpOnly[\r][\n]"
http-outgoing-1 << "Location: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true[\r][\n]"
http-outgoing-1 << "Content-Type: application/octet-stream[\r][\n]"
http-outgoing-1 << "Content-Length: 0[\r][\n]"
http-outgoing-1 << "Server: Jetty(6.1.26)[\r][\n]"
http-outgoing-1 << "[\r][\n]"
http-outgoing-1 << HTTP/1.1 307 TEMPORARY_REDIRECT
http-outgoing-1 << Cache-Control: no-cache
http-outgoing-1 << Expires: Sun, 14 Jun 2015 00:28:43 GMT
http-outgoing-1 << Date: Sun, 14 Jun 2015 00:28:43 GMT
http-outgoing-1 << Pragma: no-cache
http-outgoing-1 << Expires: Sun, 14 Jun 2015 00:28:43 GMT
http-outgoing-1 << Date: Sun, 14 Jun 2015 00:28:43 GMT
http-outgoing-1 << Pragma: no-cache
http-outgoing-1 << Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434277723999&s=UQiUc9ceH3dlc+4byo/DLH6eJQ0="; Path=/; Expires=Sun, 14-Jun-2015 10:28:43 GMT; HttpOnly
http-outgoing-1 << Location: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
http-outgoing-1 << Content-Type: application/octet-stream
http-outgoing-1 << Content-Length: 0
http-outgoing-1 << Server: Jetty(6.1.26)
Connection can be kept alive indefinitely
Cookie accepted [hadoop.auth=""u=michaeljones&p=michaeljones&t=simple&e=1434277723999&s=UQiUc9ceH3dlc+4byo/DLH6eJQ0="", version:0, domain:localhost, path:/, expiry:Sun Jun 14 20:28:43 AEST 2015]
Redirect to: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
http-outgoing-1: Shutdown connection
Connection discarded
http-outgoing-1: Close connection
Connection released: [id: 1][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 2][route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://michaels-air.bigpond:50075
Connecting to michaels-air.bigpond/10.0.0.2:50075
Connection established 10.0.0.2:49715<->10.0.0.2:50075
Executing request PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-2 >> PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1
http-outgoing-2 >> Content-Length: 0
http-outgoing-2 >> Host: michaels-air.bigpond:50075
http-outgoing-2 >> Connection: Keep-Alive
http-outgoing-2 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-2 >> Accept-Encoding: gzip,deflate
http-outgoing-2 >> "PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1[\r][\n]"
http-outgoing-2 >> "Content-Length: 0[\r][\n]"
http-outgoing-2 >> "Host: michaels-air.bigpond:50075[\r][\n]"
http-outgoing-2 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-2 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-2 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-2 >> "[\r][\n]"
http-outgoing-2 << "HTTP/1.1 100 Continue[\r][\n]"
http-outgoing-2 << "[\r][\n]"
http-outgoing-2 << HTTP/1.1 100 Continue
http-outgoing-2 << "HTTP/1.1 201 Created[\r][\n]"
http-outgoing-2 << "Location: hdfs://localhost:9000/user/michaeljones/hello-apache-empty.txt[\r][\n]"
http-outgoing-2 << "Content-Length: 0[\r][\n]"
http-outgoing-2 << "Connection: close[\r][\n]"
http-outgoing-2 << "[\r][\n]"
http-outgoing-2 << HTTP/1.1 201 Created
http-outgoing-2 << Location: hdfs://localhost:9000/user/michaeljones/hello-apache-empty.txt
http-outgoing-2 << Content-Length: 0
http-outgoing-2 << Connection: close
http-outgoing-2: Shutdown connection
Connection discarded
http-outgoing-2: Close connection
Connection released: [id: 2][route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection manager is shutting down
Connection manager shut down
Jersey client Redirect to: hdfs://localhost:9000/user/michaeljones/hellohadoop.log
com.sun.jersey.client.property.chunkedEncodingSize: 1048576
Jersey client Redirect to: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/hello.log.2015-06-12?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 3][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://localhost:50070
Connecting to localhost/127.0.0.1:50070
Connection established 127.0.0.1:49725<->127.0.0.1:50070
Executing request PUT /webhdfs/v1/user/michaeljones/README.md?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-3 >> PUT /webhdfs/v1/user/michaeljones/README.md?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1
http-outgoing-3 >> Transfer-Encoding: chunked
http-outgoing-3 >> Content-Type: application/octet-stream
http-outgoing-3 >> Host: localhost:50070
http-outgoing-3 >> Connection: Keep-Alive
http-outgoing-3 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-3 >> Accept-Encoding: gzip,deflate
http-outgoing-3 >> "PUT /webhdfs/v1/user/michaeljones/README.md?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1[\r][\n]"
http-outgoing-3 >> "Transfer-Encoding: chunked[\r][\n]"
http-outgoing-3 >> "Content-Type: application/octet-stream[\r][\n]"
http-outgoing-3 >> "Host: localhost:50070[\r][\n]"
http-outgoing-3 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-3 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-3 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-3 >> "[\r][\n]"
http-outgoing-3 >> "1000[\r][\n]"
http-outgoing-3 >> "# Hello-Hadoop-netbeans-OS-X[\n]"
http-outgoing-3 >> "Java Maven project for playing with the HDFS API without any 3rd party hadoop plugins.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## Aim of project[\n]"
http-outgoing-3 >> "Hello world/tutorial level for programmatically operating with a pseudo distributed hadoop configuration on OS X. Hadoop 2.7 on Yosemite.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## What this project demonstrates[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "This is work in progress and so far the following functionality is demonstrated:[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "1. Direct programmatic control of the HDFS and running map reduce jobs - all unit tests run from the IDE with hadoop configuration built into this project and under git control.[\n]"
http-outgoing-3 >> "2. Uploading of files to the HDFS by implementing a Web REST API client.[\n]"
http-outgoing-3 >> "3. Layered application code for maximum re-use and ease of test driven development. The client I wrote uses an interface which has allowed me to provide both a Jersey HTTP client implementation and an Apache HTTP client implementation for comparison between the two toolkits.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "The initial difficulty was working out how to run the program in the IDE and talk to the local pseudo distributed setup without using a 3rd party Hadoop plugin. Apparently there used to be a plugin for netbeans, but it has been discontinued. I am a newbie with this technology.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "The Apache Hadoop instructions for building and running java programs are via their command line build/run utility only. Getting the yahoo hadoop HDFS tutorial program to build in the IDE wasn't too hard. However, by default it will ignore the local Hadoop configuration and only operate with the local file system in local debug mode.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## Wading through the configuration[\n]"
http-outgoing-3 >> "Hadoop is designed to work with a number of different topologies, directory locations, levels of replication, simulated environments etc. so as we would expect nothing works unless the configuration is right.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "First Hadoop needs to be installed and configured in pseudo distributed mode such that it builds and runs test programs on the command line. The hadoop documentation has instructions for doing this. Documentation is online and also included in the installation: share/doc/hadoop/index.html. However this is not enough to get it to work in the IDE.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## The netbeans project settings that are needed to run with the HDFS from the IDE:[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "1. Get log4j configured to work in the IDE. Absence of log4j configuration won't stop hadoop from running, but we won't get to see useful error messages from hadoop without it.[\n]"
http-outgoing-3 >> "2. HADOOP_HOME environment variable project run (and test) property.[\n]"
http-outgoing-3 >> "3. Duplicate hadoop configuration in the classpath. The above environment variable does not pick up the hadoop configuration from its usual place. Yahoo's only suggestion is to run from the command line via the hadoop script. The Apache HDFS API documention says that configuration is looked for in the classpath, so I took the approach of duplicating the configuration (just 2 files) instead of figuring out how to get it to look in the installation path.[\n]"
http-outgoing-3 >> "4. The correct Maven dependencies. If not all the jar depenencies are there the program may build and run, but it won't talk to the HDFS if it doesn't load the HDFS jars.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "I think that the setup of this project would probably work on Linux too.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## Working through trouble shooting the HDFS project settings[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "Issue 1 above shows up as:[\n]"
http-outgoing-3 >> "<pre><code>[\n]"
http-outgoing-3 >> "log4j:WARN No appenders could be found for logger (org.apache.hadoop.util.Shell).[\n]"
http-outgoing-3 >> "log4j:WARN Please initialize the log4j system properly.[\n]"
http-outgoing-3 >> "log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.[\n]"
http-outgoing-3 >> "</pre></code>[\n]"
http-outgoing-3 >> "This is solved by putting a log4j.properties configuration file in the classpath. For a Maven build getting files into the classpath can be achieved by putting them in src/main/resources. I don't think this is in the classpath, but the build will then copy the file into ./target/classes/ which is in the classpath.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "Issue 2 above shows up as:[\n]"
http-outgoing-3 >> "<pre><code>[\n]"
http-outgoing-3 >> "Failed to detect a valid hadoop home directory[\n]"
http-outgoing-3 >> "java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.[\n]"
http-outgoing-3 >> "</code></pre>[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "This is fixed by going into the project properties => Build => Actions => Run Project and adding the environmen[\r][\n]"
http-outgoing-3 >> "1000[\r][\n]"
http-outgoing-3 >> "t variable for HADOOP_HOME. This will result in an entry in the Maven POM. Repeat for "Test Project", "Debug Project" etc.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "Issue 3. shows up as running, but creating a file on the local file system instead of the HDFS. This was fixed       looking at the HDFS API documentation for org.apache.hadoop.conf.Configuration. This documentation is under the chapter: C API libhdfs HDFS which has a link to the HDFS API under "The APIs" (I strangely cannot find this in the main index). On my installation the HDFS API documentation link is file:///opt/local/hadoop-2.7.0/share/doc/hadoop/api/org/apache/hadoop/fs/FileSystem.html.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "This documentation told me that hadoop loads core-site.xml and core-default.xml in the classpath. Classpath for a Maven build can be reached by placing these files in the directory src/main/resources (see logging configuration above). I added hdfs-site instead of core-default (which doesn't exist on my 2.7 install) into the src/main/resources project directory.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "Issue 3 shows up as:[\n]"
http-outgoing-3 >> "<pre><code>[\n]"
http-outgoing-3 >> "java.io.IOException: "hadoop No FileSystem for scheme: hdfs".[\n]"
http-outgoing-3 >> "</code></pre>[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "This is part of the build dependency problem. The various threads on stackoverflow etc. suggested that a minimum dependency was the jar for hadoop-core. However, there is no such jar on 2.7. I ran the hadoop command to dump version and got this:[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "<pre><code>[\n]"
http-outgoing-3 >> "bin/hadoop version[\n]"
http-outgoing-3 >> "Hadoop 2.7.0[\n]"
http-outgoing-3 >> "Subversion https://git-wip-us.apache.org/repos/asf/hadoop.git -r d4c8d4d4d203c934e8074b31289a28724c0842cf[\n]"
http-outgoing-3 >> "Compiled by jenkins on 2015-04-10T18:40Z[\n]"
http-outgoing-3 >> "Compiled with protoc 2.5.0[\n]"
http-outgoing-3 >> "From source with checksum a9e90912c37a35c3195d23951fd18f[\n]"
http-outgoing-3 >> "This command was run using /opt/local/hadoop-2.7.0/share/hadoop/common/hadoop-common-2.7.0.jar[\n]"
http-outgoing-3 >> "</code></pre>[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "I noted the jar name at the end and added it as a dependency to the POM. This can either be hand coded in or right click pom.xml => Insert Code => Add Dependency => Search => query hadoop-common and select version which was 2.7.0 [jar] - central. Maven will then add dependencies to other hadoop jars in the "Dependencies" group in the project explorer. Netbeans will then download these dependencies before the next build. They go into ~/.m2/repository should they ever need to be cleaned out (Netbeans doesn't seem to have an IDE remove dependency option).[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "After doing the above project built, but showed up the "no filesystem error". I noticed that Maven had not pulled in any hdfs jars matching the jars in my share/hadoop/hdfs installation directory. So I took a guess that it needed only the top level hadoop-hdfs-2.7.0.jar and added this as a dependency to the POM and all was good :)[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## Working through trouble shooting the Map Reduce project settings[\n]"
http-outgoing-3 >> "After getting the HDFS API working in the IDE it was time to move on to getting the famous Word Count map-reduce tutorial running.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "So coded it, set the main program to the word count main as the one to run. From the IDE: project Properties => Run => Main Class. Provide input and output arguments for the word count program. I noted that the netbeans properties pop-up window does not persist these settings next time it pops up. However this setting is persistant and ends up in nbactions.xml.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "However, running the word count map reduce program resulted in an ioException:[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "<pre><code>[\n]"
http-outgoing-3 >> "Please check your configuration for mapreduce.framework.name and the correspond server addresses.[\n]"
http-outgoing-3 >> "</pre></code>[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "Because the resources directory only contains 2 configuration files from my hadoop installation I thought maybe I was missing a map reduce one. So the first thing I did was go into the configuration directory of my installation and grep all files to see if there was a configuration file with mapreduce framework property. There was not. I checked my programatic configuration dump from my test program. This property was not mentioned either. The only map reduce configuration was to do with some environment variables for heap size in one of the shell scripts. Note to self: this may be relevant and I can consider setting this in the IDE. However, that didn't look like the problem.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "I then chec[\r][\n]"
http-outgoing-3 >> "a93[\r][\n]"
http-outgoing-3 >> "ked my dependencies and noted there were no map reduce jars pulled in by Maven. So I added hadoop-mapreduce-client-core. Still not running. Checked the web and a thread on stackoverflow mentioned a number of other jars: hadoop-mapreduce-client-common and hadoop-mapreduce-client shuffle. I added just the hadoop-mapreduce-client-common and it runs :) I have a feeling that I might need some of the other jars for other API calls and that there must be a better way of working out dependencies than this trial and error. As mentioned I am a newbie with this, so if anyone has any comments feel free to email me.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## Logging from application code[\n]"
http-outgoing-3 >> "Although the hadoop libraries log correctly with a properly located log4.properties file, application code calling the log4j logger seems to ignore this file. Using the log4j logger as per instructions in the log4j manual and many online tutorials did not result in getting any logging redirected to file configured in the properties file. Instead console output only is obtained. A clue to this mystery was that a most basic of hello world netbeans maven projects which did not import any hadoop stuff also failed to log to a file and did not even give the "No appenders" warning. Then I noticed that there were org.sl4j depencies in the hadoop build, so using sl4j instead solved the problem. Once my hello world project used sl4j's LoggerFactory and had sl4j-api and sl4j-12 as a dependencies it started to use the properties file. See http://www.slf4j.org/manual.html[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## Upload a file from local storage to the HDFS via the REST API[\n]"
http-outgoing-3 >> "The WebHDFS REST API documentation which came with the installation specifies that file creation is a two stage operation where an initial PUT to the namenode is sent. This responds with a redirect to the datanode and another PUT should be made to this redirection which can contain the chunked data stream. This does not sound REST to me as it relies on holding redirection state (a fully distributed configuration could presumably return a redirection to any one of the datanodes). Hadoop say this is because of a bug in some HTTP client implementations - incorrect implementation of [0xe2][0x80][0x9c]Expect: 100-continue[0xe2][0x80][0x9d].[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "However, the 2 stage PUT not being REST seems to be a moot point, at least with the Jersey client. I do not get a redirection and a file creates/uploads all in one go.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "Since writing the above paragraph I have implemented the Apache Client back end option to my HDFS Web client interface and this client behaves differently. It does indeed cause a redirect as per Hadoop documentation. The follow up PUT to the redirected location with the chunked file stream works as per documentation.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "To be continued ...[\n]"
http-outgoing-3 >> "[\r][\n]"
http-outgoing-3 >> "0[\r][\n]"
http-outgoing-3 >> "[\r][\n]"
http-outgoing-3 << "HTTP/1.1 307 TEMPORARY_REDIRECT[\r][\n]"
http-outgoing-3 << "Cache-Control: no-cache[\r][\n]"
http-outgoing-3 << "Expires: Sun, 14 Jun 2015 00:28:44 GMT[\r][\n]"
http-outgoing-3 << "Date: Sun, 14 Jun 2015 00:28:44 GMT[\r][\n]"
http-outgoing-3 << "Pragma: no-cache[\r][\n]"
http-outgoing-3 << "Expires: Sun, 14 Jun 2015 00:28:44 GMT[\r][\n]"
http-outgoing-3 << "Date: Sun, 14 Jun 2015 00:28:44 GMT[\r][\n]"
http-outgoing-3 << "Pragma: no-cache[\r][\n]"
http-outgoing-3 << "Content-Type: application/octet-stream[\r][\n]"
http-outgoing-3 << "Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434277724839&s=B8ZiHIYs4ZCHeHslnDQ0gTAjWkA="; Path=/; Expires=Sun, 14-Jun-2015 10:28:44 GMT; HttpOnly[\r][\n]"
http-outgoing-3 << "Location: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/README.md?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true[\r][\n]"
http-outgoing-3 << "Content-Length: 0[\r][\n]"
http-outgoing-3 << "Server: Jetty(6.1.26)[\r][\n]"
http-outgoing-3 << "[\r][\n]"
http-outgoing-3 << HTTP/1.1 307 TEMPORARY_REDIRECT
http-outgoing-3 << Cache-Control: no-cache
http-outgoing-3 << Expires: Sun, 14 Jun 2015 00:28:44 GMT
http-outgoing-3 << Date: Sun, 14 Jun 2015 00:28:44 GMT
http-outgoing-3 << Pragma: no-cache
http-outgoing-3 << Expires: Sun, 14 Jun 2015 00:28:44 GMT
http-outgoing-3 << Date: Sun, 14 Jun 2015 00:28:44 GMT
http-outgoing-3 << Pragma: no-cache
http-outgoing-3 << Content-Type: application/octet-stream
http-outgoing-3 << Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434277724839&s=B8ZiHIYs4ZCHeHslnDQ0gTAjWkA="; Path=/; Expires=Sun, 14-Jun-2015 10:28:44 GMT; HttpOnly
http-outgoing-3 << Location: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/README.md?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
http-outgoing-3 << Content-Length: 0
http-outgoing-3 << Server: Jetty(6.1.26)
Connection can be kept alive indefinitely
Cookie accepted [hadoop.auth=""u=michaeljones&p=michaeljones&t=simple&e=1434277724839&s=B8ZiHIYs4ZCHeHslnDQ0gTAjWkA="", version:0, domain:localhost, path:/, expiry:Sun Jun 14 20:28:44 AEST 2015]
Redirect to: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/README.md?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
http-outgoing-3: Shutdown connection
Connection discarded
http-outgoing-3: Close connection
Connection released: [id: 3][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 4][route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://michaels-air.bigpond:50075
Connecting to michaels-air.bigpond/10.0.0.2:50075
Connection established 10.0.0.2:49726<->10.0.0.2:50075
Executing request PUT /webhdfs/v1/user/michaeljones/README.md?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-4 >> PUT /webhdfs/v1/user/michaeljones/README.md?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1
http-outgoing-4 >> Transfer-Encoding: chunked
http-outgoing-4 >> Content-Type: application/octet-stream
http-outgoing-4 >> Host: michaels-air.bigpond:50075
http-outgoing-4 >> Connection: Keep-Alive
http-outgoing-4 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-4 >> Accept-Encoding: gzip,deflate
http-outgoing-4 >> "PUT /webhdfs/v1/user/michaeljones/README.md?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1[\r][\n]"
http-outgoing-4 >> "Transfer-Encoding: chunked[\r][\n]"
http-outgoing-4 >> "Content-Type: application/octet-stream[\r][\n]"
http-outgoing-4 >> "Host: michaels-air.bigpond:50075[\r][\n]"
http-outgoing-4 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-4 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-4 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-4 >> "[\r][\n]"
http-outgoing-4 >> "1000[\r][\n]"
http-outgoing-4 >> "# Hello-Hadoop-netbeans-OS-X[\n]"
http-outgoing-4 >> "Java Maven project for playing with the HDFS API without any 3rd party hadoop plugins.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## Aim of project[\n]"
http-outgoing-4 >> "Hello world/tutorial level for programmatically operating with a pseudo distributed hadoop configuration on OS X. Hadoop 2.7 on Yosemite.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## What this project demonstrates[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "This is work in progress and so far the following functionality is demonstrated:[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "1. Direct programmatic control of the HDFS and running map reduce jobs - all unit tests run from the IDE with hadoop configuration built into this project and under git control.[\n]"
http-outgoing-4 >> "2. Uploading of files to the HDFS by implementing a Web REST API client.[\n]"
http-outgoing-4 >> "3. Layered application code for maximum re-use and ease of test driven development. The client I wrote uses an interface which has allowed me to provide both a Jersey HTTP client implementation and an Apache HTTP client implementation for comparison between the two toolkits.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "The initial difficulty was working out how to run the program in the IDE and talk to the local pseudo distributed setup without using a 3rd party Hadoop plugin. Apparently there used to be a plugin for netbeans, but it has been discontinued. I am a newbie with this technology.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "The Apache Hadoop instructions for building and running java programs are via their command line build/run utility only. Getting the yahoo hadoop HDFS tutorial program to build in the IDE wasn't too hard. However, by default it will ignore the local Hadoop configuration and only operate with the local file system in local debug mode.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## Wading through the configuration[\n]"
http-outgoing-4 >> "Hadoop is designed to work with a number of different topologies, directory locations, levels of replication, simulated environments etc. so as we would expect nothing works unless the configuration is right.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "First Hadoop needs to be installed and configured in pseudo distributed mode such that it builds and runs test programs on the command line. The hadoop documentation has instructions for doing this. Documentation is online and also included in the installation: share/doc/hadoop/index.html. However this is not enough to get it to work in the IDE.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## The netbeans project settings that are needed to run with the HDFS from the IDE:[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "1. Get log4j configured to work in the IDE. Absence of log4j configuration won't stop hadoop from running, but we won't get to see useful error messages from hadoop without it.[\n]"
http-outgoing-4 >> "2. HADOOP_HOME environment variable project run (and test) property.[\n]"
http-outgoing-4 >> "3. Duplicate hadoop configuration in the classpath. The above environment variable does not pick up the hadoop configuration from its usual place. Yahoo's only suggestion is to run from the command line via the hadoop script. The Apache HDFS API documention says that configuration is looked for in the classpath, so I took the approach of duplicating the configuration (just 2 files) instead of figuring out how to get it to look in the installation path.[\n]"
http-outgoing-4 >> "4. The correct Maven dependencies. If not all the jar depenencies are there the program may build and run, but it won't talk to the HDFS if it doesn't load the HDFS jars.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "I think that the setup of this project would probably work on Linux too.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## Working through trouble shooting the HDFS project settings[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "Issue 1 above shows up as:[\n]"
http-outgoing-4 >> "<pre><code>[\n]"
http-outgoing-4 >> "log4j:WARN No appenders could be found for logger (org.apache.hadoop.util.Shell).[\n]"
http-outgoing-4 >> "log4j:WARN Please initialize the log4j system properly.[\n]"
http-outgoing-4 >> "log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.[\n]"
http-outgoing-4 >> "</pre></code>[\n]"
http-outgoing-4 >> "This is solved by putting a log4j.properties configuration file in the classpath. For a Maven build getting files into the classpath can be achieved by putting them in src/main/resources. I don't think this is in the classpath, but the build will then copy the file into ./target/classes/ which is in the classpath.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "Issue 2 above shows up as:[\n]"
http-outgoing-4 >> "<pre><code>[\n]"
http-outgoing-4 >> "Failed to detect a valid hadoop home directory[\n]"
http-outgoing-4 >> "java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.[\n]"
http-outgoing-4 >> "</code></pre>[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "This is fixed by going into the project properties => Build => Actions => Run Project and adding the environmen[\r][\n]"
http-outgoing-4 >> "1000[\r][\n]"
http-outgoing-4 >> "t variable for HADOOP_HOME. This will result in an entry in the Maven POM. Repeat for "Test Project", "Debug Project" etc.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "Issue 3. shows up as running, but creating a file on the local file system instead of the HDFS. This was fixed       looking at the HDFS API documentation for org.apache.hadoop.conf.Configuration. This documentation is under the chapter: C API libhdfs HDFS which has a link to the HDFS API under "The APIs" (I strangely cannot find this in the main index). On my installation the HDFS API documentation link is file:///opt/local/hadoop-2.7.0/share/doc/hadoop/api/org/apache/hadoop/fs/FileSystem.html.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "This documentation told me that hadoop loads core-site.xml and core-default.xml in the classpath. Classpath for a Maven build can be reached by placing these files in the directory src/main/resources (see logging configuration above). I added hdfs-site instead of core-default (which doesn't exist on my 2.7 install) into the src/main/resources project directory.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "Issue 3 shows up as:[\n]"
http-outgoing-4 >> "<pre><code>[\n]"
http-outgoing-4 >> "java.io.IOException: "hadoop No FileSystem for scheme: hdfs".[\n]"
http-outgoing-4 >> "</code></pre>[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "This is part of the build dependency problem. The various threads on stackoverflow etc. suggested that a minimum dependency was the jar for hadoop-core. However, there is no such jar on 2.7. I ran the hadoop command to dump version and got this:[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "<pre><code>[\n]"
http-outgoing-4 >> "bin/hadoop version[\n]"
http-outgoing-4 >> "Hadoop 2.7.0[\n]"
http-outgoing-4 >> "Subversion https://git-wip-us.apache.org/repos/asf/hadoop.git -r d4c8d4d4d203c934e8074b31289a28724c0842cf[\n]"
http-outgoing-4 >> "Compiled by jenkins on 2015-04-10T18:40Z[\n]"
http-outgoing-4 >> "Compiled with protoc 2.5.0[\n]"
http-outgoing-4 >> "From source with checksum a9e90912c37a35c3195d23951fd18f[\n]"
http-outgoing-4 >> "This command was run using /opt/local/hadoop-2.7.0/share/hadoop/common/hadoop-common-2.7.0.jar[\n]"
http-outgoing-4 >> "</code></pre>[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "I noted the jar name at the end and added it as a dependency to the POM. This can either be hand coded in or right click pom.xml => Insert Code => Add Dependency => Search => query hadoop-common and select version which was 2.7.0 [jar] - central. Maven will then add dependencies to other hadoop jars in the "Dependencies" group in the project explorer. Netbeans will then download these dependencies before the next build. They go into ~/.m2/repository should they ever need to be cleaned out (Netbeans doesn't seem to have an IDE remove dependency option).[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "After doing the above project built, but showed up the "no filesystem error". I noticed that Maven had not pulled in any hdfs jars matching the jars in my share/hadoop/hdfs installation directory. So I took a guess that it needed only the top level hadoop-hdfs-2.7.0.jar and added this as a dependency to the POM and all was good :)[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## Working through trouble shooting the Map Reduce project settings[\n]"
http-outgoing-4 >> "After getting the HDFS API working in the IDE it was time to move on to getting the famous Word Count map-reduce tutorial running.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "So coded it, set the main program to the word count main as the one to run. From the IDE: project Properties => Run => Main Class. Provide input and output arguments for the word count program. I noted that the netbeans properties pop-up window does not persist these settings next time it pops up. However this setting is persistant and ends up in nbactions.xml.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "However, running the word count map reduce program resulted in an ioException:[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "<pre><code>[\n]"
http-outgoing-4 >> "Please check your configuration for mapreduce.framework.name and the correspond server addresses.[\n]"
http-outgoing-4 >> "</pre></code>[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "Because the resources directory only contains 2 configuration files from my hadoop installation I thought maybe I was missing a map reduce one. So the first thing I did was go into the configuration directory of my installation and grep all files to see if there was a configuration file with mapreduce framework property. There was not. I checked my programatic configuration dump from my test program. This property was not mentioned either. The only map reduce configuration was to do with some environment variables for heap size in one of the shell scripts. Note to self: this may be relevant and I can consider setting this in the IDE. However, that didn't look like the problem.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "I then chec[\r][\n]"
http-outgoing-4 >> "a93[\r][\n]"
http-outgoing-4 >> "ked my dependencies and noted there were no map reduce jars pulled in by Maven. So I added hadoop-mapreduce-client-core. Still not running. Checked the web and a thread on stackoverflow mentioned a number of other jars: hadoop-mapreduce-client-common and hadoop-mapreduce-client shuffle. I added just the hadoop-mapreduce-client-common and it runs :) I have a feeling that I might need some of the other jars for other API calls and that there must be a better way of working out dependencies than this trial and error. As mentioned I am a newbie with this, so if anyone has any comments feel free to email me.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## Logging from application code[\n]"
http-outgoing-4 >> "Although the hadoop libraries log correctly with a properly located log4.properties file, application code calling the log4j logger seems to ignore this file. Using the log4j logger as per instructions in the log4j manual and many online tutorials did not result in getting any logging redirected to file configured in the properties file. Instead console output only is obtained. A clue to this mystery was that a most basic of hello world netbeans maven projects which did not import any hadoop stuff also failed to log to a file and did not even give the "No appenders" warning. Then I noticed that there were org.sl4j depencies in the hadoop build, so using sl4j instead solved the problem. Once my hello world project used sl4j's LoggerFactory and had sl4j-api and sl4j-12 as a dependencies it started to use the properties file. See http://www.slf4j.org/manual.html[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## Upload a file from local storage to the HDFS via the REST API[\n]"
http-outgoing-4 >> "The WebHDFS REST API documentation which came with the installation specifies that file creation is a two stage operation where an initial PUT to the namenode is sent. This responds with a redirect to the datanode and another PUT should be made to this redirection which can contain the chunked data stream. This does not sound REST to me as it relies on holding redirection state (a fully distributed configuration could presumably return a redirection to any one of the datanodes). Hadoop say this is because of a bug in some HTTP client implementations - incorrect implementation of [0xe2][0x80][0x9c]Expect: 100-continue[0xe2][0x80][0x9d].[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "However, the 2 stage PUT not being REST seems to be a moot point, at least with the Jersey client. I do not get a redirection and a file creates/uploads all in one go.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "Since writing the above paragraph I have implemented the Apache Client back end option to my HDFS Web client interface and this client behaves differently. It does indeed cause a redirect as per Hadoop documentation. The follow up PUT to the redirected location with the chunked file stream works as per documentation.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "To be continued ...[\n]"
http-outgoing-4 >> "[\r][\n]"
http-outgoing-4 >> "0[\r][\n]"
http-outgoing-4 >> "[\r][\n]"
http-outgoing-4 << "HTTP/1.1 100 Continue[\r][\n]"
http-outgoing-4 << "[\r][\n]"
http-outgoing-4 << HTTP/1.1 100 Continue
http-outgoing-4 << "HTTP/1.1 201 Created[\r][\n]"
http-outgoing-4 << "Location: hdfs://localhost:9000/user/michaeljones/README.md[\r][\n]"
http-outgoing-4 << "Content-Length: 0[\r][\n]"
http-outgoing-4 << "Connection: close[\r][\n]"
http-outgoing-4 << "[\r][\n]"
http-outgoing-4 << HTTP/1.1 201 Created
http-outgoing-4 << Location: hdfs://localhost:9000/user/michaeljones/README.md
http-outgoing-4 << Content-Length: 0
http-outgoing-4 << Connection: close
http-outgoing-4: Shutdown connection
Connection discarded
http-outgoing-4: Close connection
Connection released: [id: 4][route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection manager is shutting down
Connection manager shut down
Jersey client Redirect to: hdfs://localhost:9000/user/michaeljones/nbactions.xml
Jersey client Redirect to: hdfs://localhost:9000/user/michaeljones/nbactions.xml
Jersey Future: com.sun.jersey.api.client.ClientHandlerException: java.net.MalformedURLException: unknown protocol: hdfs
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 0][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://localhost:50070
Connecting to localhost/127.0.0.1:50070
Connection established 127.0.0.1:49741<->127.0.0.1:50070
Executing request GET /webhdfs/v1/user/michaeljones/?user.name=michaeljones&op=LISTSTATUS HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-0 >> GET /webhdfs/v1/user/michaeljones/?user.name=michaeljones&op=LISTSTATUS HTTP/1.1
http-outgoing-0 >> accept: application/json
http-outgoing-0 >> Host: localhost:50070
http-outgoing-0 >> Connection: Keep-Alive
http-outgoing-0 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-0 >> Accept-Encoding: gzip,deflate
http-outgoing-0 >> "GET /webhdfs/v1/user/michaeljones/?user.name=michaeljones&op=LISTSTATUS HTTP/1.1[\r][\n]"
http-outgoing-0 >> "accept: application/json[\r][\n]"
http-outgoing-0 >> "Host: localhost:50070[\r][\n]"
http-outgoing-0 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-0 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-0 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-0 >> "[\r][\n]"
http-outgoing-0 << "HTTP/1.1 200 OK[\r][\n]"
http-outgoing-0 << "Cache-Control: no-cache[\r][\n]"
http-outgoing-0 << "Expires: Sun, 14 Jun 2015 00:30:35 GMT[\r][\n]"
http-outgoing-0 << "Date: Sun, 14 Jun 2015 00:30:35 GMT[\r][\n]"
http-outgoing-0 << "Pragma: no-cache[\r][\n]"
http-outgoing-0 << "Expires: Sun, 14 Jun 2015 00:30:35 GMT[\r][\n]"
http-outgoing-0 << "Date: Sun, 14 Jun 2015 00:30:35 GMT[\r][\n]"
http-outgoing-0 << "Pragma: no-cache[\r][\n]"
http-outgoing-0 << "Content-Type: application/json[\r][\n]"
http-outgoing-0 << "Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434277835280&s=su0fqnBldVW78nGlZerrx1XX6Zc="; Path=/; Expires=Sun, 14-Jun-2015 10:30:35 GMT; HttpOnly[\r][\n]"
http-outgoing-0 << "Transfer-Encoding: chunked[\r][\n]"
http-outgoing-0 << "Server: Jetty(6.1.26)[\r][\n]"
http-outgoing-0 << "[\r][\n]"
http-outgoing-0 << "10C1[\r][\n]"
http-outgoing-0 << "{"FileStatuses":{"FileStatus":[[\n]"
http-outgoing-0 << "{"accessTime":1434241724899,"blockSize":134217728,"childrenNum":0,"fileId":18647,"group":"supergroup","length":10899,"modificationTime":1434241724928,"owner":"michaeljones","pathSuffix":"README.md","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434180764122,"blockSize":134217728,"childrenNum":0,"fileId":18621,"group":"supergroup","length":0,"modificationTime":1434180764129,"owner":"michaeljones","pathSuffix":"apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434240295990,"blockSize":134217728,"childrenNum":0,"fileId":18639,"group":"supergroup","length":0,"modificationTime":1434240295996,"owner":"michaeljones","pathSuffix":"empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434241724083,"blockSize":134217728,"childrenNum":0,"fileId":18644,"group":"supergroup","length":0,"modificationTime":1434241724092,"owner":"michaeljones","pathSuffix":"hello-apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434091626279,"blockSize":134217728,"childrenNum":0,"fileId":18298,"group":"supergroup","length":0,"modificationTime":1434091626286,"owner":"michaeljones","pathSuffix":"hello-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434241723944,"blockSize":134217728,"childrenNum":0,"fileId":18643,"group":"supergroup","length":0,"modificationTime":1434241723956,"owner":"michaeljones","pathSuffix":"hello-jersey-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434240296439,"blockSize":134217728,"childrenNum":0,"fileId":18641,"group":"supergroup","length":19574,"modificationTime":1434240296468,"owner":"michaeljones","pathSuffix":"hello.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434241724546,"blockSize":134217728,"childrenNum":0,"fileId":18646,"group":"supergroup","length":3678856,"modificationTime":1434241724777,"owner":"michaeljones","pathSuffix":"hello.log.2015-06-12","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434180756986,"blockSize":134217728,"childrenNum":0,"fileId":18599,"group":"supergroup","length":20,"modificationTime":1434180757588,"owner":"michaeljones","pathSuffix":"hello.txt","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434241724372,"blockSize":134217728,"childrenNum":0,"fileId":18645,"group":"supergroup","length":17984,"modificationTime":1434241724409,"owner":"michaeljones","pathSuffix":"hellohadoop.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434241725437,"blockSize":134217728,"childrenNum":0,"fileId":18649,"group":"supergroup","length":3644,"modificationTime":1434241725460,"owner":"michaeljones","pathSuffix":"nbactions.xml","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434180764163,"blockSize":134217728,"childrenNum":0,"fileId":18622,"group":"supergroup","length":2134,"modificationTime":1434180764193,"owner":"michaeljones","pathSuffix":"pom.xml","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434180758226,"blockSize":134217728,"childrenNum":0,"fileId":16388,"group":"supergroup","length":50,"modificationTime":1433119638967,"owner":"michaeljones","pathSuffix":"wcInput","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18600,"group":"supergroup","length":0,"modificationTime":1434180760247,"owner":"michaeljones","pathSuffix":"wcOutput","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},[\n]"
http-outgoing-0 << "{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18607,"group":"supergroup","length":0,"modificationTime":1434180761544,"owner":"michaeljones","pathSuffix":"wcOutputAnalysis","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},[\n]"
http-outgoing-0 << "{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18614,"group":"supergroup","length":0,"modificationTime":1434180763349,"owner":"michaeljones","pathSuffix":"wcOutputMain","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"}[\n]"
http-outgoing-0 << "]}}[\n]"
http-outgoing-0 << "[\r][\n]"
http-outgoing-0 << "0[\r][\n]"
http-outgoing-0 << "[\r][\n]"
http-outgoing-0 << HTTP/1.1 200 OK
http-outgoing-0 << Cache-Control: no-cache
http-outgoing-0 << Expires: Sun, 14 Jun 2015 00:30:35 GMT
http-outgoing-0 << Date: Sun, 14 Jun 2015 00:30:35 GMT
http-outgoing-0 << Pragma: no-cache
http-outgoing-0 << Expires: Sun, 14 Jun 2015 00:30:35 GMT
http-outgoing-0 << Date: Sun, 14 Jun 2015 00:30:35 GMT
http-outgoing-0 << Pragma: no-cache
http-outgoing-0 << Content-Type: application/json
http-outgoing-0 << Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434277835280&s=su0fqnBldVW78nGlZerrx1XX6Zc="; Path=/; Expires=Sun, 14-Jun-2015 10:30:35 GMT; HttpOnly
http-outgoing-0 << Transfer-Encoding: chunked
http-outgoing-0 << Server: Jetty(6.1.26)
Connection can be kept alive indefinitely
Cookie accepted [hadoop.auth=""u=michaeljones&p=michaeljones&t=simple&e=1434277835280&s=su0fqnBldVW78nGlZerrx1XX6Zc="", version:0, domain:localhost, path:/, expiry:Sun Jun 14 20:30:35 AEST 2015]
Connection [id: 0][route: {}->http://localhost:50070] can be kept alive indefinitely
Connection released: [id: 0][route: {}->http://localhost:50070][total kept alive: 1; route allocated: 1 of 2; total allocated: 1 of 20]
Connection manager is shutting down
http-outgoing-0: Close connection
http-outgoing-0: Close connection
Connection manager shut down
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 1][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://localhost:50070
Connecting to localhost/127.0.0.1:50070
Connection established 127.0.0.1:49745<->127.0.0.1:50070
Executing request PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-1 >> PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1
http-outgoing-1 >> Content-Length: 0
http-outgoing-1 >> Host: localhost:50070
http-outgoing-1 >> Connection: Keep-Alive
http-outgoing-1 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-1 >> Accept-Encoding: gzip,deflate
http-outgoing-1 >> "PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1[\r][\n]"
http-outgoing-1 >> "Content-Length: 0[\r][\n]"
http-outgoing-1 >> "Host: localhost:50070[\r][\n]"
http-outgoing-1 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-1 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-1 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-1 >> "[\r][\n]"
http-outgoing-1 << "HTTP/1.1 307 TEMPORARY_REDIRECT[\r][\n]"
http-outgoing-1 << "Cache-Control: no-cache[\r][\n]"
http-outgoing-1 << "Expires: Sun, 14 Jun 2015 00:30:35 GMT[\r][\n]"
http-outgoing-1 << "Date: Sun, 14 Jun 2015 00:30:35 GMT[\r][\n]"
http-outgoing-1 << "Pragma: no-cache[\r][\n]"
http-outgoing-1 << "Expires: Sun, 14 Jun 2015 00:30:35 GMT[\r][\n]"
http-outgoing-1 << "Date: Sun, 14 Jun 2015 00:30:35 GMT[\r][\n]"
http-outgoing-1 << "Pragma: no-cache[\r][\n]"
http-outgoing-1 << "Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434277835793&s=qnJNyDnalDy6YJse8/UNp7u0Edg="; Path=/; Expires=Sun, 14-Jun-2015 10:30:35 GMT; HttpOnly[\r][\n]"
http-outgoing-1 << "Location: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true[\r][\n]"
http-outgoing-1 << "Content-Type: application/octet-stream[\r][\n]"
http-outgoing-1 << "Content-Length: 0[\r][\n]"
http-outgoing-1 << "Server: Jetty(6.1.26)[\r][\n]"
http-outgoing-1 << "[\r][\n]"
http-outgoing-1 << HTTP/1.1 307 TEMPORARY_REDIRECT
http-outgoing-1 << Cache-Control: no-cache
http-outgoing-1 << Expires: Sun, 14 Jun 2015 00:30:35 GMT
http-outgoing-1 << Date: Sun, 14 Jun 2015 00:30:35 GMT
http-outgoing-1 << Pragma: no-cache
http-outgoing-1 << Expires: Sun, 14 Jun 2015 00:30:35 GMT
http-outgoing-1 << Date: Sun, 14 Jun 2015 00:30:35 GMT
http-outgoing-1 << Pragma: no-cache
http-outgoing-1 << Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434277835793&s=qnJNyDnalDy6YJse8/UNp7u0Edg="; Path=/; Expires=Sun, 14-Jun-2015 10:30:35 GMT; HttpOnly
http-outgoing-1 << Location: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
http-outgoing-1 << Content-Type: application/octet-stream
http-outgoing-1 << Content-Length: 0
http-outgoing-1 << Server: Jetty(6.1.26)
Connection can be kept alive indefinitely
Cookie accepted [hadoop.auth=""u=michaeljones&p=michaeljones&t=simple&e=1434277835793&s=qnJNyDnalDy6YJse8/UNp7u0Edg="", version:0, domain:localhost, path:/, expiry:Sun Jun 14 20:30:35 AEST 2015]
Redirect to: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
http-outgoing-1: Shutdown connection
Connection discarded
http-outgoing-1: Close connection
Connection released: [id: 1][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 2][route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://michaels-air.bigpond:50075
Connecting to michaels-air.bigpond/10.0.0.2:50075
Connection established 10.0.0.2:49746<->10.0.0.2:50075
Executing request PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-2 >> PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1
http-outgoing-2 >> Content-Length: 0
http-outgoing-2 >> Host: michaels-air.bigpond:50075
http-outgoing-2 >> Connection: Keep-Alive
http-outgoing-2 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-2 >> Accept-Encoding: gzip,deflate
http-outgoing-2 >> "PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1[\r][\n]"
http-outgoing-2 >> "Content-Length: 0[\r][\n]"
http-outgoing-2 >> "Host: michaels-air.bigpond:50075[\r][\n]"
http-outgoing-2 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-2 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-2 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-2 >> "[\r][\n]"
http-outgoing-2 << "HTTP/1.1 100 Continue[\r][\n]"
http-outgoing-2 << "[\r][\n]"
http-outgoing-2 << HTTP/1.1 100 Continue
http-outgoing-2 << "HTTP/1.1 201 Created[\r][\n]"
http-outgoing-2 << "Location: hdfs://localhost:9000/user/michaeljones/hello-apache-empty.txt[\r][\n]"
http-outgoing-2 << "Content-Length: 0[\r][\n]"
http-outgoing-2 << "Connection: close[\r][\n]"
http-outgoing-2 << "[\r][\n]"
http-outgoing-2 << HTTP/1.1 201 Created
http-outgoing-2 << Location: hdfs://localhost:9000/user/michaeljones/hello-apache-empty.txt
http-outgoing-2 << Content-Length: 0
http-outgoing-2 << Connection: close
http-outgoing-2: Shutdown connection
Connection discarded
http-outgoing-2: Close connection
Connection released: [id: 2][route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection manager is shutting down
Connection manager shut down
Jersey client Redirect to: hdfs://localhost:9000/user/michaeljones/hellohadoop.log
com.sun.jersey.client.property.chunkedEncodingSize: 1048576
Jersey client Redirect to: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/hello.log.2015-06-12?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 3][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://localhost:50070
Connecting to localhost/127.0.0.1:50070
Connection established 127.0.0.1:49756<->127.0.0.1:50070
Executing request PUT /webhdfs/v1/user/michaeljones/README.md?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-3 >> PUT /webhdfs/v1/user/michaeljones/README.md?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1
http-outgoing-3 >> Transfer-Encoding: chunked
http-outgoing-3 >> Content-Type: application/octet-stream
http-outgoing-3 >> Host: localhost:50070
http-outgoing-3 >> Connection: Keep-Alive
http-outgoing-3 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-3 >> Accept-Encoding: gzip,deflate
http-outgoing-3 >> "PUT /webhdfs/v1/user/michaeljones/README.md?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1[\r][\n]"
http-outgoing-3 >> "Transfer-Encoding: chunked[\r][\n]"
http-outgoing-3 >> "Content-Type: application/octet-stream[\r][\n]"
http-outgoing-3 >> "Host: localhost:50070[\r][\n]"
http-outgoing-3 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-3 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-3 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-3 >> "[\r][\n]"
http-outgoing-3 >> "1000[\r][\n]"
http-outgoing-3 >> "# Hello-Hadoop-netbeans-OS-X[\n]"
http-outgoing-3 >> "Java Maven project for playing with the HDFS API without any 3rd party hadoop plugins.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## Aim of project[\n]"
http-outgoing-3 >> "Hello world/tutorial level for programmatically operating with a pseudo distributed hadoop configuration on OS X. Hadoop 2.7 on Yosemite.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## What this project demonstrates[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "This is work in progress and so far the following functionality is demonstrated:[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "1. Direct programmatic control of the HDFS and running map reduce jobs - all unit tests run from the IDE with hadoop configuration built into this project and under git control.[\n]"
http-outgoing-3 >> "2. Uploading of files to the HDFS by implementing a Web REST API client.[\n]"
http-outgoing-3 >> "3. Layered application code for maximum re-use and ease of test driven development. The client I wrote uses an interface which has allowed me to provide both a Jersey HTTP client implementation and an Apache HTTP client implementation for comparison between the two toolkits.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "The initial difficulty was working out how to run the program in the IDE and talk to the local pseudo distributed setup without using a 3rd party Hadoop plugin. Apparently there used to be a plugin for netbeans, but it has been discontinued. I am a newbie with this technology.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "The Apache Hadoop instructions for building and running java programs are via their command line build/run utility only. Getting the yahoo hadoop HDFS tutorial program to build in the IDE wasn't too hard. However, by default it will ignore the local Hadoop configuration and only operate with the local file system in local debug mode.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## Wading through the configuration[\n]"
http-outgoing-3 >> "Hadoop is designed to work with a number of different topologies, directory locations, levels of replication, simulated environments etc. so as we would expect nothing works unless the configuration is right.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "First Hadoop needs to be installed and configured in pseudo distributed mode such that it builds and runs test programs on the command line. The hadoop documentation has instructions for doing this. Documentation is online and also included in the installation: share/doc/hadoop/index.html. However this is not enough to get it to work in the IDE.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## The netbeans project settings that are needed to run with the HDFS from the IDE:[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "1. Get log4j configured to work in the IDE. Absence of log4j configuration won't stop hadoop from running, but we won't get to see useful error messages from hadoop without it.[\n]"
http-outgoing-3 >> "2. HADOOP_HOME environment variable project run (and test) property.[\n]"
http-outgoing-3 >> "3. Duplicate hadoop configuration in the classpath. The above environment variable does not pick up the hadoop configuration from its usual place. Yahoo's only suggestion is to run from the command line via the hadoop script. The Apache HDFS API documention says that configuration is looked for in the classpath, so I took the approach of duplicating the configuration (just 2 files) instead of figuring out how to get it to look in the installation path.[\n]"
http-outgoing-3 >> "4. The correct Maven dependencies. If not all the jar depenencies are there the program may build and run, but it won't talk to the HDFS if it doesn't load the HDFS jars.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "I think that the setup of this project would probably work on Linux too.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## Working through trouble shooting the HDFS project settings[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "Issue 1 above shows up as:[\n]"
http-outgoing-3 >> "<pre><code>[\n]"
http-outgoing-3 >> "log4j:WARN No appenders could be found for logger (org.apache.hadoop.util.Shell).[\n]"
http-outgoing-3 >> "log4j:WARN Please initialize the log4j system properly.[\n]"
http-outgoing-3 >> "log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.[\n]"
http-outgoing-3 >> "</pre></code>[\n]"
http-outgoing-3 >> "This is solved by putting a log4j.properties configuration file in the classpath. For a Maven build getting files into the classpath can be achieved by putting them in src/main/resources. I don't think this is in the classpath, but the build will then copy the file into ./target/classes/ which is in the classpath.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "Issue 2 above shows up as:[\n]"
http-outgoing-3 >> "<pre><code>[\n]"
http-outgoing-3 >> "Failed to detect a valid hadoop home directory[\n]"
http-outgoing-3 >> "java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.[\n]"
http-outgoing-3 >> "</code></pre>[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "This is fixed by going into the project properties => Build => Actions => Run Project and adding the environmen[\r][\n]"
http-outgoing-3 >> "1000[\r][\n]"
http-outgoing-3 >> "t variable for HADOOP_HOME. This will result in an entry in the Maven POM. Repeat for "Test Project", "Debug Project" etc.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "Issue 3. shows up as running, but creating a file on the local file system instead of the HDFS. This was fixed       looking at the HDFS API documentation for org.apache.hadoop.conf.Configuration. This documentation is under the chapter: C API libhdfs HDFS which has a link to the HDFS API under "The APIs" (I strangely cannot find this in the main index). On my installation the HDFS API documentation link is file:///opt/local/hadoop-2.7.0/share/doc/hadoop/api/org/apache/hadoop/fs/FileSystem.html.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "This documentation told me that hadoop loads core-site.xml and core-default.xml in the classpath. Classpath for a Maven build can be reached by placing these files in the directory src/main/resources (see logging configuration above). I added hdfs-site instead of core-default (which doesn't exist on my 2.7 install) into the src/main/resources project directory.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "Issue 3 shows up as:[\n]"
http-outgoing-3 >> "<pre><code>[\n]"
http-outgoing-3 >> "java.io.IOException: "hadoop No FileSystem for scheme: hdfs".[\n]"
http-outgoing-3 >> "</code></pre>[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "This is part of the build dependency problem. The various threads on stackoverflow etc. suggested that a minimum dependency was the jar for hadoop-core. However, there is no such jar on 2.7. I ran the hadoop command to dump version and got this:[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "<pre><code>[\n]"
http-outgoing-3 >> "bin/hadoop version[\n]"
http-outgoing-3 >> "Hadoop 2.7.0[\n]"
http-outgoing-3 >> "Subversion https://git-wip-us.apache.org/repos/asf/hadoop.git -r d4c8d4d4d203c934e8074b31289a28724c0842cf[\n]"
http-outgoing-3 >> "Compiled by jenkins on 2015-04-10T18:40Z[\n]"
http-outgoing-3 >> "Compiled with protoc 2.5.0[\n]"
http-outgoing-3 >> "From source with checksum a9e90912c37a35c3195d23951fd18f[\n]"
http-outgoing-3 >> "This command was run using /opt/local/hadoop-2.7.0/share/hadoop/common/hadoop-common-2.7.0.jar[\n]"
http-outgoing-3 >> "</code></pre>[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "I noted the jar name at the end and added it as a dependency to the POM. This can either be hand coded in or right click pom.xml => Insert Code => Add Dependency => Search => query hadoop-common and select version which was 2.7.0 [jar] - central. Maven will then add dependencies to other hadoop jars in the "Dependencies" group in the project explorer. Netbeans will then download these dependencies before the next build. They go into ~/.m2/repository should they ever need to be cleaned out (Netbeans doesn't seem to have an IDE remove dependency option).[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "After doing the above project built, but showed up the "no filesystem error". I noticed that Maven had not pulled in any hdfs jars matching the jars in my share/hadoop/hdfs installation directory. So I took a guess that it needed only the top level hadoop-hdfs-2.7.0.jar and added this as a dependency to the POM and all was good :)[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## Working through trouble shooting the Map Reduce project settings[\n]"
http-outgoing-3 >> "After getting the HDFS API working in the IDE it was time to move on to getting the famous Word Count map-reduce tutorial running.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "So coded it, set the main program to the word count main as the one to run. From the IDE: project Properties => Run => Main Class. Provide input and output arguments for the word count program. I noted that the netbeans properties pop-up window does not persist these settings next time it pops up. However this setting is persistant and ends up in nbactions.xml.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "However, running the word count map reduce program resulted in an ioException:[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "<pre><code>[\n]"
http-outgoing-3 >> "Please check your configuration for mapreduce.framework.name and the correspond server addresses.[\n]"
http-outgoing-3 >> "</pre></code>[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "Because the resources directory only contains 2 configuration files from my hadoop installation I thought maybe I was missing a map reduce one. So the first thing I did was go into the configuration directory of my installation and grep all files to see if there was a configuration file with mapreduce framework property. There was not. I checked my programatic configuration dump from my test program. This property was not mentioned either. The only map reduce configuration was to do with some environment variables for heap size in one of the shell scripts. Note to self: this may be relevant and I can consider setting this in the IDE. However, that didn't look like the problem.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "I then chec[\r][\n]"
http-outgoing-3 >> "a93[\r][\n]"
http-outgoing-3 >> "ked my dependencies and noted there were no map reduce jars pulled in by Maven. So I added hadoop-mapreduce-client-core. Still not running. Checked the web and a thread on stackoverflow mentioned a number of other jars: hadoop-mapreduce-client-common and hadoop-mapreduce-client shuffle. I added just the hadoop-mapreduce-client-common and it runs :) I have a feeling that I might need some of the other jars for other API calls and that there must be a better way of working out dependencies than this trial and error. As mentioned I am a newbie with this, so if anyone has any comments feel free to email me.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## Logging from application code[\n]"
http-outgoing-3 >> "Although the hadoop libraries log correctly with a properly located log4.properties file, application code calling the log4j logger seems to ignore this file. Using the log4j logger as per instructions in the log4j manual and many online tutorials did not result in getting any logging redirected to file configured in the properties file. Instead console output only is obtained. A clue to this mystery was that a most basic of hello world netbeans maven projects which did not import any hadoop stuff also failed to log to a file and did not even give the "No appenders" warning. Then I noticed that there were org.sl4j depencies in the hadoop build, so using sl4j instead solved the problem. Once my hello world project used sl4j's LoggerFactory and had sl4j-api and sl4j-12 as a dependencies it started to use the properties file. See http://www.slf4j.org/manual.html[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## Upload a file from local storage to the HDFS via the REST API[\n]"
http-outgoing-3 >> "The WebHDFS REST API documentation which came with the installation specifies that file creation is a two stage operation where an initial PUT to the namenode is sent. This responds with a redirect to the datanode and another PUT should be made to this redirection which can contain the chunked data stream. This does not sound REST to me as it relies on holding redirection state (a fully distributed configuration could presumably return a redirection to any one of the datanodes). Hadoop say this is because of a bug in some HTTP client implementations - incorrect implementation of [0xe2][0x80][0x9c]Expect: 100-continue[0xe2][0x80][0x9d].[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "However, the 2 stage PUT not being REST seems to be a moot point, at least with the Jersey client. I do not get a redirection and a file creates/uploads all in one go.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "Since writing the above paragraph I have implemented the Apache Client back end option to my HDFS Web client interface and this client behaves differently. It does indeed cause a redirect as per Hadoop documentation. The follow up PUT to the redirected location with the chunked file stream works as per documentation.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "To be continued ...[\n]"
http-outgoing-3 >> "[\r][\n]"
http-outgoing-3 >> "0[\r][\n]"
http-outgoing-3 >> "[\r][\n]"
http-outgoing-3 << "HTTP/1.1 307 TEMPORARY_REDIRECT[\r][\n]"
http-outgoing-3 << "Cache-Control: no-cache[\r][\n]"
http-outgoing-3 << "Expires: Sun, 14 Jun 2015 00:30:36 GMT[\r][\n]"
http-outgoing-3 << "Date: Sun, 14 Jun 2015 00:30:36 GMT[\r][\n]"
http-outgoing-3 << "Pragma: no-cache[\r][\n]"
http-outgoing-3 << "Expires: Sun, 14 Jun 2015 00:30:36 GMT[\r][\n]"
http-outgoing-3 << "Date: Sun, 14 Jun 2015 00:30:36 GMT[\r][\n]"
http-outgoing-3 << "Pragma: no-cache[\r][\n]"
http-outgoing-3 << "Content-Type: application/octet-stream[\r][\n]"
http-outgoing-3 << "Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434277836393&s=6MluSSHu1a55e6tVEISuAiVnFk8="; Path=/; Expires=Sun, 14-Jun-2015 10:30:36 GMT; HttpOnly[\r][\n]"
http-outgoing-3 << "Location: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/README.md?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true[\r][\n]"
http-outgoing-3 << "Content-Length: 0[\r][\n]"
http-outgoing-3 << "Server: Jetty(6.1.26)[\r][\n]"
http-outgoing-3 << "[\r][\n]"
http-outgoing-3 << HTTP/1.1 307 TEMPORARY_REDIRECT
http-outgoing-3 << Cache-Control: no-cache
http-outgoing-3 << Expires: Sun, 14 Jun 2015 00:30:36 GMT
http-outgoing-3 << Date: Sun, 14 Jun 2015 00:30:36 GMT
http-outgoing-3 << Pragma: no-cache
http-outgoing-3 << Expires: Sun, 14 Jun 2015 00:30:36 GMT
http-outgoing-3 << Date: Sun, 14 Jun 2015 00:30:36 GMT
http-outgoing-3 << Pragma: no-cache
http-outgoing-3 << Content-Type: application/octet-stream
http-outgoing-3 << Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434277836393&s=6MluSSHu1a55e6tVEISuAiVnFk8="; Path=/; Expires=Sun, 14-Jun-2015 10:30:36 GMT; HttpOnly
http-outgoing-3 << Location: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/README.md?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
http-outgoing-3 << Content-Length: 0
http-outgoing-3 << Server: Jetty(6.1.26)
Connection can be kept alive indefinitely
Cookie accepted [hadoop.auth=""u=michaeljones&p=michaeljones&t=simple&e=1434277836393&s=6MluSSHu1a55e6tVEISuAiVnFk8="", version:0, domain:localhost, path:/, expiry:Sun Jun 14 20:30:36 AEST 2015]
Redirect to: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/README.md?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
http-outgoing-3: Shutdown connection
Connection discarded
http-outgoing-3: Close connection
Connection released: [id: 3][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 4][route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://michaels-air.bigpond:50075
Connecting to michaels-air.bigpond/10.0.0.2:50075
Connection established 10.0.0.2:49757<->10.0.0.2:50075
Executing request PUT /webhdfs/v1/user/michaeljones/README.md?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-4 >> PUT /webhdfs/v1/user/michaeljones/README.md?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1
http-outgoing-4 >> Transfer-Encoding: chunked
http-outgoing-4 >> Content-Type: application/octet-stream
http-outgoing-4 >> Host: michaels-air.bigpond:50075
http-outgoing-4 >> Connection: Keep-Alive
http-outgoing-4 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-4 >> Accept-Encoding: gzip,deflate
http-outgoing-4 >> "PUT /webhdfs/v1/user/michaeljones/README.md?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1[\r][\n]"
http-outgoing-4 >> "Transfer-Encoding: chunked[\r][\n]"
http-outgoing-4 >> "Content-Type: application/octet-stream[\r][\n]"
http-outgoing-4 >> "Host: michaels-air.bigpond:50075[\r][\n]"
http-outgoing-4 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-4 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-4 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-4 >> "[\r][\n]"
http-outgoing-4 >> "1000[\r][\n]"
http-outgoing-4 >> "# Hello-Hadoop-netbeans-OS-X[\n]"
http-outgoing-4 >> "Java Maven project for playing with the HDFS API without any 3rd party hadoop plugins.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## Aim of project[\n]"
http-outgoing-4 >> "Hello world/tutorial level for programmatically operating with a pseudo distributed hadoop configuration on OS X. Hadoop 2.7 on Yosemite.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## What this project demonstrates[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "This is work in progress and so far the following functionality is demonstrated:[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "1. Direct programmatic control of the HDFS and running map reduce jobs - all unit tests run from the IDE with hadoop configuration built into this project and under git control.[\n]"
http-outgoing-4 >> "2. Uploading of files to the HDFS by implementing a Web REST API client.[\n]"
http-outgoing-4 >> "3. Layered application code for maximum re-use and ease of test driven development. The client I wrote uses an interface which has allowed me to provide both a Jersey HTTP client implementation and an Apache HTTP client implementation for comparison between the two toolkits.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "The initial difficulty was working out how to run the program in the IDE and talk to the local pseudo distributed setup without using a 3rd party Hadoop plugin. Apparently there used to be a plugin for netbeans, but it has been discontinued. I am a newbie with this technology.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "The Apache Hadoop instructions for building and running java programs are via their command line build/run utility only. Getting the yahoo hadoop HDFS tutorial program to build in the IDE wasn't too hard. However, by default it will ignore the local Hadoop configuration and only operate with the local file system in local debug mode.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## Wading through the configuration[\n]"
http-outgoing-4 >> "Hadoop is designed to work with a number of different topologies, directory locations, levels of replication, simulated environments etc. so as we would expect nothing works unless the configuration is right.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "First Hadoop needs to be installed and configured in pseudo distributed mode such that it builds and runs test programs on the command line. The hadoop documentation has instructions for doing this. Documentation is online and also included in the installation: share/doc/hadoop/index.html. However this is not enough to get it to work in the IDE.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## The netbeans project settings that are needed to run with the HDFS from the IDE:[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "1. Get log4j configured to work in the IDE. Absence of log4j configuration won't stop hadoop from running, but we won't get to see useful error messages from hadoop without it.[\n]"
http-outgoing-4 >> "2. HADOOP_HOME environment variable project run (and test) property.[\n]"
http-outgoing-4 >> "3. Duplicate hadoop configuration in the classpath. The above environment variable does not pick up the hadoop configuration from its usual place. Yahoo's only suggestion is to run from the command line via the hadoop script. The Apache HDFS API documention says that configuration is looked for in the classpath, so I took the approach of duplicating the configuration (just 2 files) instead of figuring out how to get it to look in the installation path.[\n]"
http-outgoing-4 >> "4. The correct Maven dependencies. If not all the jar depenencies are there the program may build and run, but it won't talk to the HDFS if it doesn't load the HDFS jars.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "I think that the setup of this project would probably work on Linux too.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## Working through trouble shooting the HDFS project settings[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "Issue 1 above shows up as:[\n]"
http-outgoing-4 >> "<pre><code>[\n]"
http-outgoing-4 >> "log4j:WARN No appenders could be found for logger (org.apache.hadoop.util.Shell).[\n]"
http-outgoing-4 >> "log4j:WARN Please initialize the log4j system properly.[\n]"
http-outgoing-4 >> "log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.[\n]"
http-outgoing-4 >> "</pre></code>[\n]"
http-outgoing-4 >> "This is solved by putting a log4j.properties configuration file in the classpath. For a Maven build getting files into the classpath can be achieved by putting them in src/main/resources. I don't think this is in the classpath, but the build will then copy the file into ./target/classes/ which is in the classpath.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "Issue 2 above shows up as:[\n]"
http-outgoing-4 >> "<pre><code>[\n]"
http-outgoing-4 >> "Failed to detect a valid hadoop home directory[\n]"
http-outgoing-4 >> "java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.[\n]"
http-outgoing-4 >> "</code></pre>[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "This is fixed by going into the project properties => Build => Actions => Run Project and adding the environmen[\r][\n]"
http-outgoing-4 >> "1000[\r][\n]"
http-outgoing-4 >> "t variable for HADOOP_HOME. This will result in an entry in the Maven POM. Repeat for "Test Project", "Debug Project" etc.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "Issue 3. shows up as running, but creating a file on the local file system instead of the HDFS. This was fixed       looking at the HDFS API documentation for org.apache.hadoop.conf.Configuration. This documentation is under the chapter: C API libhdfs HDFS which has a link to the HDFS API under "The APIs" (I strangely cannot find this in the main index). On my installation the HDFS API documentation link is file:///opt/local/hadoop-2.7.0/share/doc/hadoop/api/org/apache/hadoop/fs/FileSystem.html.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "This documentation told me that hadoop loads core-site.xml and core-default.xml in the classpath. Classpath for a Maven build can be reached by placing these files in the directory src/main/resources (see logging configuration above). I added hdfs-site instead of core-default (which doesn't exist on my 2.7 install) into the src/main/resources project directory.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "Issue 3 shows up as:[\n]"
http-outgoing-4 >> "<pre><code>[\n]"
http-outgoing-4 >> "java.io.IOException: "hadoop No FileSystem for scheme: hdfs".[\n]"
http-outgoing-4 >> "</code></pre>[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "This is part of the build dependency problem. The various threads on stackoverflow etc. suggested that a minimum dependency was the jar for hadoop-core. However, there is no such jar on 2.7. I ran the hadoop command to dump version and got this:[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "<pre><code>[\n]"
http-outgoing-4 >> "bin/hadoop version[\n]"
http-outgoing-4 >> "Hadoop 2.7.0[\n]"
http-outgoing-4 >> "Subversion https://git-wip-us.apache.org/repos/asf/hadoop.git -r d4c8d4d4d203c934e8074b31289a28724c0842cf[\n]"
http-outgoing-4 >> "Compiled by jenkins on 2015-04-10T18:40Z[\n]"
http-outgoing-4 >> "Compiled with protoc 2.5.0[\n]"
http-outgoing-4 >> "From source with checksum a9e90912c37a35c3195d23951fd18f[\n]"
http-outgoing-4 >> "This command was run using /opt/local/hadoop-2.7.0/share/hadoop/common/hadoop-common-2.7.0.jar[\n]"
http-outgoing-4 >> "</code></pre>[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "I noted the jar name at the end and added it as a dependency to the POM. This can either be hand coded in or right click pom.xml => Insert Code => Add Dependency => Search => query hadoop-common and select version which was 2.7.0 [jar] - central. Maven will then add dependencies to other hadoop jars in the "Dependencies" group in the project explorer. Netbeans will then download these dependencies before the next build. They go into ~/.m2/repository should they ever need to be cleaned out (Netbeans doesn't seem to have an IDE remove dependency option).[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "After doing the above project built, but showed up the "no filesystem error". I noticed that Maven had not pulled in any hdfs jars matching the jars in my share/hadoop/hdfs installation directory. So I took a guess that it needed only the top level hadoop-hdfs-2.7.0.jar and added this as a dependency to the POM and all was good :)[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## Working through trouble shooting the Map Reduce project settings[\n]"
http-outgoing-4 >> "After getting the HDFS API working in the IDE it was time to move on to getting the famous Word Count map-reduce tutorial running.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "So coded it, set the main program to the word count main as the one to run. From the IDE: project Properties => Run => Main Class. Provide input and output arguments for the word count program. I noted that the netbeans properties pop-up window does not persist these settings next time it pops up. However this setting is persistant and ends up in nbactions.xml.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "However, running the word count map reduce program resulted in an ioException:[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "<pre><code>[\n]"
http-outgoing-4 >> "Please check your configuration for mapreduce.framework.name and the correspond server addresses.[\n]"
http-outgoing-4 >> "</pre></code>[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "Because the resources directory only contains 2 configuration files from my hadoop installation I thought maybe I was missing a map reduce one. So the first thing I did was go into the configuration directory of my installation and grep all files to see if there was a configuration file with mapreduce framework property. There was not. I checked my programatic configuration dump from my test program. This property was not mentioned either. The only map reduce configuration was to do with some environment variables for heap size in one of the shell scripts. Note to self: this may be relevant and I can consider setting this in the IDE. However, that didn't look like the problem.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "I then chec[\r][\n]"
http-outgoing-4 >> "a93[\r][\n]"
http-outgoing-4 >> "ked my dependencies and noted there were no map reduce jars pulled in by Maven. So I added hadoop-mapreduce-client-core. Still not running. Checked the web and a thread on stackoverflow mentioned a number of other jars: hadoop-mapreduce-client-common and hadoop-mapreduce-client shuffle. I added just the hadoop-mapreduce-client-common and it runs :) I have a feeling that I might need some of the other jars for other API calls and that there must be a better way of working out dependencies than this trial and error. As mentioned I am a newbie with this, so if anyone has any comments feel free to email me.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## Logging from application code[\n]"
http-outgoing-4 >> "Although the hadoop libraries log correctly with a properly located log4.properties file, application code calling the log4j logger seems to ignore this file. Using the log4j logger as per instructions in the log4j manual and many online tutorials did not result in getting any logging redirected to file configured in the properties file. Instead console output only is obtained. A clue to this mystery was that a most basic of hello world netbeans maven projects which did not import any hadoop stuff also failed to log to a file and did not even give the "No appenders" warning. Then I noticed that there were org.sl4j depencies in the hadoop build, so using sl4j instead solved the problem. Once my hello world project used sl4j's LoggerFactory and had sl4j-api and sl4j-12 as a dependencies it started to use the properties file. See http://www.slf4j.org/manual.html[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## Upload a file from local storage to the HDFS via the REST API[\n]"
http-outgoing-4 >> "The WebHDFS REST API documentation which came with the installation specifies that file creation is a two stage operation where an initial PUT to the namenode is sent. This responds with a redirect to the datanode and another PUT should be made to this redirection which can contain the chunked data stream. This does not sound REST to me as it relies on holding redirection state (a fully distributed configuration could presumably return a redirection to any one of the datanodes). Hadoop say this is because of a bug in some HTTP client implementations - incorrect implementation of [0xe2][0x80][0x9c]Expect: 100-continue[0xe2][0x80][0x9d].[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "However, the 2 stage PUT not being REST seems to be a moot point, at least with the Jersey client. I do not get a redirection and a file creates/uploads all in one go.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "Since writing the above paragraph I have implemented the Apache Client back end option to my HDFS Web client interface and this client behaves differently. It does indeed cause a redirect as per Hadoop documentation. The follow up PUT to the redirected location with the chunked file stream works as per documentation.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "To be continued ...[\n]"
http-outgoing-4 >> "[\r][\n]"
http-outgoing-4 >> "0[\r][\n]"
http-outgoing-4 >> "[\r][\n]"
http-outgoing-4 << "HTTP/1.1 100 Continue[\r][\n]"
http-outgoing-4 << "[\r][\n]"
http-outgoing-4 << HTTP/1.1 100 Continue
http-outgoing-4 << "HTTP/1.1 201 Created[\r][\n]"
http-outgoing-4 << "Location: hdfs://localhost:9000/user/michaeljones/README.md[\r][\n]"
http-outgoing-4 << "Content-Length: 0[\r][\n]"
http-outgoing-4 << "Connection: close[\r][\n]"
http-outgoing-4 << "[\r][\n]"
http-outgoing-4 << HTTP/1.1 201 Created
http-outgoing-4 << Location: hdfs://localhost:9000/user/michaeljones/README.md
http-outgoing-4 << Content-Length: 0
http-outgoing-4 << Connection: close
http-outgoing-4: Shutdown connection
Connection discarded
http-outgoing-4: Close connection
Connection released: [id: 4][route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection manager is shutting down
Connection manager shut down
com.sun.jersey.client.property.chunkedEncodingSize: 1048576
Jersey client Redirect to: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/nbactions.xml?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
com.sun.jersey.client.property.chunkedEncodingSize: 1048576
Jersey client Redirect to: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/nbactions.xml?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 0][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://localhost:50070
Connecting to localhost/127.0.0.1:50070
Connection established 127.0.0.1:49771<->127.0.0.1:50070
Executing request GET /webhdfs/v1/user/michaeljones/?user.name=michaeljones&op=LISTSTATUS HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-0 >> GET /webhdfs/v1/user/michaeljones/?user.name=michaeljones&op=LISTSTATUS HTTP/1.1
http-outgoing-0 >> accept: application/json
http-outgoing-0 >> Host: localhost:50070
http-outgoing-0 >> Connection: Keep-Alive
http-outgoing-0 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-0 >> Accept-Encoding: gzip,deflate
http-outgoing-0 >> "GET /webhdfs/v1/user/michaeljones/?user.name=michaeljones&op=LISTSTATUS HTTP/1.1[\r][\n]"
http-outgoing-0 >> "accept: application/json[\r][\n]"
http-outgoing-0 >> "Host: localhost:50070[\r][\n]"
http-outgoing-0 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-0 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-0 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-0 >> "[\r][\n]"
http-outgoing-0 << "HTTP/1.1 200 OK[\r][\n]"
http-outgoing-0 << "Cache-Control: no-cache[\r][\n]"
http-outgoing-0 << "Expires: Sun, 14 Jun 2015 00:33:05 GMT[\r][\n]"
http-outgoing-0 << "Date: Sun, 14 Jun 2015 00:33:05 GMT[\r][\n]"
http-outgoing-0 << "Pragma: no-cache[\r][\n]"
http-outgoing-0 << "Expires: Sun, 14 Jun 2015 00:33:05 GMT[\r][\n]"
http-outgoing-0 << "Date: Sun, 14 Jun 2015 00:33:05 GMT[\r][\n]"
http-outgoing-0 << "Pragma: no-cache[\r][\n]"
http-outgoing-0 << "Content-Type: application/json[\r][\n]"
http-outgoing-0 << "Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434277985472&s=Xqz0OU9jkdcOuBTWbppdc9HHdPY="; Path=/; Expires=Sun, 14-Jun-2015 10:33:05 GMT; HttpOnly[\r][\n]"
http-outgoing-0 << "Transfer-Encoding: chunked[\r][\n]"
http-outgoing-0 << "Server: Jetty(6.1.26)[\r][\n]"
http-outgoing-0 << "[\r][\n]"
http-outgoing-0 << "10C1[\r][\n]"
http-outgoing-0 << "{"FileStatuses":{"FileStatus":[[\n]"
http-outgoing-0 << "{"accessTime":1434241836497,"blockSize":134217728,"childrenNum":0,"fileId":18654,"group":"supergroup","length":10899,"modificationTime":1434241836521,"owner":"michaeljones","pathSuffix":"README.md","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434180764122,"blockSize":134217728,"childrenNum":0,"fileId":18621,"group":"supergroup","length":0,"modificationTime":1434180764129,"owner":"michaeljones","pathSuffix":"apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434240295990,"blockSize":134217728,"childrenNum":0,"fileId":18639,"group":"supergroup","length":0,"modificationTime":1434240295996,"owner":"michaeljones","pathSuffix":"empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434241835838,"blockSize":134217728,"childrenNum":0,"fileId":18651,"group":"supergroup","length":0,"modificationTime":1434241835846,"owner":"michaeljones","pathSuffix":"hello-apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434091626279,"blockSize":134217728,"childrenNum":0,"fileId":18298,"group":"supergroup","length":0,"modificationTime":1434091626286,"owner":"michaeljones","pathSuffix":"hello-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434241835761,"blockSize":134217728,"childrenNum":0,"fileId":18650,"group":"supergroup","length":0,"modificationTime":1434241835768,"owner":"michaeljones","pathSuffix":"hello-jersey-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434240296439,"blockSize":134217728,"childrenNum":0,"fileId":18641,"group":"supergroup","length":19574,"modificationTime":1434240296468,"owner":"michaeljones","pathSuffix":"hello.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434241836201,"blockSize":134217728,"childrenNum":0,"fileId":18653,"group":"supergroup","length":3678856,"modificationTime":1434241836331,"owner":"michaeljones","pathSuffix":"hello.log.2015-06-12","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434180756986,"blockSize":134217728,"childrenNum":0,"fileId":18599,"group":"supergroup","length":20,"modificationTime":1434180757588,"owner":"michaeljones","pathSuffix":"hello.txt","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434241836063,"blockSize":134217728,"childrenNum":0,"fileId":18652,"group":"supergroup","length":17984,"modificationTime":1434241836087,"owner":"michaeljones","pathSuffix":"hellohadoop.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434241837121,"blockSize":134217728,"childrenNum":0,"fileId":18655,"group":"supergroup","length":3644,"modificationTime":1434241837141,"owner":"michaeljones","pathSuffix":"nbactions.xml","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434180764163,"blockSize":134217728,"childrenNum":0,"fileId":18622,"group":"supergroup","length":2134,"modificationTime":1434180764193,"owner":"michaeljones","pathSuffix":"pom.xml","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434180758226,"blockSize":134217728,"childrenNum":0,"fileId":16388,"group":"supergroup","length":50,"modificationTime":1433119638967,"owner":"michaeljones","pathSuffix":"wcInput","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18600,"group":"supergroup","length":0,"modificationTime":1434180760247,"owner":"michaeljones","pathSuffix":"wcOutput","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},[\n]"
http-outgoing-0 << "{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18607,"group":"supergroup","length":0,"modificationTime":1434180761544,"owner":"michaeljones","pathSuffix":"wcOutputAnalysis","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},[\n]"
http-outgoing-0 << "{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18614,"group":"supergroup","length":0,"modificationTime":1434180763349,"owner":"michaeljones","pathSuffix":"wcOutputMain","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"}[\n]"
http-outgoing-0 << "]}}[\n]"
http-outgoing-0 << "[\r][\n]"
http-outgoing-0 << "0[\r][\n]"
http-outgoing-0 << "[\r][\n]"
http-outgoing-0 << HTTP/1.1 200 OK
http-outgoing-0 << Cache-Control: no-cache
http-outgoing-0 << Expires: Sun, 14 Jun 2015 00:33:05 GMT
http-outgoing-0 << Date: Sun, 14 Jun 2015 00:33:05 GMT
http-outgoing-0 << Pragma: no-cache
http-outgoing-0 << Expires: Sun, 14 Jun 2015 00:33:05 GMT
http-outgoing-0 << Date: Sun, 14 Jun 2015 00:33:05 GMT
http-outgoing-0 << Pragma: no-cache
http-outgoing-0 << Content-Type: application/json
http-outgoing-0 << Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434277985472&s=Xqz0OU9jkdcOuBTWbppdc9HHdPY="; Path=/; Expires=Sun, 14-Jun-2015 10:33:05 GMT; HttpOnly
http-outgoing-0 << Transfer-Encoding: chunked
http-outgoing-0 << Server: Jetty(6.1.26)
Connection can be kept alive indefinitely
Cookie accepted [hadoop.auth=""u=michaeljones&p=michaeljones&t=simple&e=1434277985472&s=Xqz0OU9jkdcOuBTWbppdc9HHdPY="", version:0, domain:localhost, path:/, expiry:Sun Jun 14 20:33:05 AEST 2015]
Connection [id: 0][route: {}->http://localhost:50070] can be kept alive indefinitely
Connection released: [id: 0][route: {}->http://localhost:50070][total kept alive: 1; route allocated: 1 of 2; total allocated: 1 of 20]
Connection manager is shutting down
http-outgoing-0: Close connection
http-outgoing-0: Close connection
Connection manager shut down
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 1][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://localhost:50070
Connecting to localhost/127.0.0.1:50070
Connection established 127.0.0.1:49775<->127.0.0.1:50070
Executing request PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-1 >> PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1
http-outgoing-1 >> Content-Length: 0
http-outgoing-1 >> Host: localhost:50070
http-outgoing-1 >> Connection: Keep-Alive
http-outgoing-1 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-1 >> Accept-Encoding: gzip,deflate
http-outgoing-1 >> "PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1[\r][\n]"
http-outgoing-1 >> "Content-Length: 0[\r][\n]"
http-outgoing-1 >> "Host: localhost:50070[\r][\n]"
http-outgoing-1 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-1 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-1 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-1 >> "[\r][\n]"
http-outgoing-1 << "HTTP/1.1 307 TEMPORARY_REDIRECT[\r][\n]"
http-outgoing-1 << "Cache-Control: no-cache[\r][\n]"
http-outgoing-1 << "Expires: Sun, 14 Jun 2015 00:33:06 GMT[\r][\n]"
http-outgoing-1 << "Date: Sun, 14 Jun 2015 00:33:06 GMT[\r][\n]"
http-outgoing-1 << "Pragma: no-cache[\r][\n]"
http-outgoing-1 << "Expires: Sun, 14 Jun 2015 00:33:06 GMT[\r][\n]"
http-outgoing-1 << "Date: Sun, 14 Jun 2015 00:33:06 GMT[\r][\n]"
http-outgoing-1 << "Pragma: no-cache[\r][\n]"
http-outgoing-1 << "Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434277986104&s=HflsiOX5np8nAvBBvYeSnR54cP4="; Path=/; Expires=Sun, 14-Jun-2015 10:33:06 GMT; HttpOnly[\r][\n]"
http-outgoing-1 << "Location: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true[\r][\n]"
http-outgoing-1 << "Content-Type: application/octet-stream[\r][\n]"
http-outgoing-1 << "Content-Length: 0[\r][\n]"
http-outgoing-1 << "Server: Jetty(6.1.26)[\r][\n]"
http-outgoing-1 << "[\r][\n]"
http-outgoing-1 << HTTP/1.1 307 TEMPORARY_REDIRECT
http-outgoing-1 << Cache-Control: no-cache
http-outgoing-1 << Expires: Sun, 14 Jun 2015 00:33:06 GMT
http-outgoing-1 << Date: Sun, 14 Jun 2015 00:33:06 GMT
http-outgoing-1 << Pragma: no-cache
http-outgoing-1 << Expires: Sun, 14 Jun 2015 00:33:06 GMT
http-outgoing-1 << Date: Sun, 14 Jun 2015 00:33:06 GMT
http-outgoing-1 << Pragma: no-cache
http-outgoing-1 << Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434277986104&s=HflsiOX5np8nAvBBvYeSnR54cP4="; Path=/; Expires=Sun, 14-Jun-2015 10:33:06 GMT; HttpOnly
http-outgoing-1 << Location: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
http-outgoing-1 << Content-Type: application/octet-stream
http-outgoing-1 << Content-Length: 0
http-outgoing-1 << Server: Jetty(6.1.26)
Connection can be kept alive indefinitely
Cookie accepted [hadoop.auth=""u=michaeljones&p=michaeljones&t=simple&e=1434277986104&s=HflsiOX5np8nAvBBvYeSnR54cP4="", version:0, domain:localhost, path:/, expiry:Sun Jun 14 20:33:06 AEST 2015]
Redirect to: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
http-outgoing-1: Shutdown connection
Connection discarded
http-outgoing-1: Close connection
Connection released: [id: 1][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 2][route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://michaels-air.bigpond:50075
Connecting to michaels-air.bigpond/10.0.0.2:50075
Connection established 10.0.0.2:49776<->10.0.0.2:50075
Executing request PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-2 >> PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1
http-outgoing-2 >> Content-Length: 0
http-outgoing-2 >> Host: michaels-air.bigpond:50075
http-outgoing-2 >> Connection: Keep-Alive
http-outgoing-2 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-2 >> Accept-Encoding: gzip,deflate
http-outgoing-2 >> "PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1[\r][\n]"
http-outgoing-2 >> "Content-Length: 0[\r][\n]"
http-outgoing-2 >> "Host: michaels-air.bigpond:50075[\r][\n]"
http-outgoing-2 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-2 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-2 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-2 >> "[\r][\n]"
http-outgoing-2 << "HTTP/1.1 100 Continue[\r][\n]"
http-outgoing-2 << "[\r][\n]"
http-outgoing-2 << HTTP/1.1 100 Continue
http-outgoing-2 << "HTTP/1.1 201 Created[\r][\n]"
http-outgoing-2 << "Location: hdfs://localhost:9000/user/michaeljones/hello-apache-empty.txt[\r][\n]"
http-outgoing-2 << "Content-Length: 0[\r][\n]"
http-outgoing-2 << "Connection: close[\r][\n]"
http-outgoing-2 << "[\r][\n]"
http-outgoing-2 << HTTP/1.1 201 Created
http-outgoing-2 << Location: hdfs://localhost:9000/user/michaeljones/hello-apache-empty.txt
http-outgoing-2 << Content-Length: 0
http-outgoing-2 << Connection: close
http-outgoing-2: Shutdown connection
Connection discarded
http-outgoing-2: Close connection
Connection released: [id: 2][route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection manager is shutting down
Connection manager shut down
Jersey client Redirect to: hdfs://localhost:9000/user/michaeljones/hellohadoop.log
com.sun.jersey.client.property.chunkedEncodingSize: 1048576
Jersey client Redirect to: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/hello.log.2015-06-12?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 3][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://localhost:50070
Connecting to localhost/127.0.0.1:50070
Connection established 127.0.0.1:49786<->127.0.0.1:50070
Executing request PUT /webhdfs/v1/user/michaeljones/README.md?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-3 >> PUT /webhdfs/v1/user/michaeljones/README.md?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1
http-outgoing-3 >> Transfer-Encoding: chunked
http-outgoing-3 >> Content-Type: application/octet-stream
http-outgoing-3 >> Host: localhost:50070
http-outgoing-3 >> Connection: Keep-Alive
http-outgoing-3 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-3 >> Accept-Encoding: gzip,deflate
http-outgoing-3 >> "PUT /webhdfs/v1/user/michaeljones/README.md?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1[\r][\n]"
http-outgoing-3 >> "Transfer-Encoding: chunked[\r][\n]"
http-outgoing-3 >> "Content-Type: application/octet-stream[\r][\n]"
http-outgoing-3 >> "Host: localhost:50070[\r][\n]"
http-outgoing-3 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-3 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-3 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-3 >> "[\r][\n]"
http-outgoing-3 >> "1000[\r][\n]"
http-outgoing-3 >> "# Hello-Hadoop-netbeans-OS-X[\n]"
http-outgoing-3 >> "Java Maven project for playing with the HDFS API without any 3rd party hadoop plugins.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## Aim of project[\n]"
http-outgoing-3 >> "Hello world/tutorial level for programmatically operating with a pseudo distributed hadoop configuration on OS X. Hadoop 2.7 on Yosemite.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## What this project demonstrates[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "This is work in progress and so far the following functionality is demonstrated:[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "1. Direct programmatic control of the HDFS and running map reduce jobs - all unit tests run from the IDE with hadoop configuration built into this project and under git control.[\n]"
http-outgoing-3 >> "2. Uploading of files to the HDFS by implementing a Web REST API client.[\n]"
http-outgoing-3 >> "3. Layered application code for maximum re-use and ease of test driven development. The client I wrote uses an interface which has allowed me to provide both a Jersey HTTP client implementation and an Apache HTTP client implementation for comparison between the two toolkits.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "The initial difficulty was working out how to run the program in the IDE and talk to the local pseudo distributed setup without using a 3rd party Hadoop plugin. Apparently there used to be a plugin for netbeans, but it has been discontinued. I am a newbie with this technology.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "The Apache Hadoop instructions for building and running java programs are via their command line build/run utility only. Getting the yahoo hadoop HDFS tutorial program to build in the IDE wasn't too hard. However, by default it will ignore the local Hadoop configuration and only operate with the local file system in local debug mode.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## Wading through the configuration[\n]"
http-outgoing-3 >> "Hadoop is designed to work with a number of different topologies, directory locations, levels of replication, simulated environments etc. so as we would expect nothing works unless the configuration is right.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "First Hadoop needs to be installed and configured in pseudo distributed mode such that it builds and runs test programs on the command line. The hadoop documentation has instructions for doing this. Documentation is online and also included in the installation: share/doc/hadoop/index.html. However this is not enough to get it to work in the IDE.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## The netbeans project settings that are needed to run with the HDFS from the IDE:[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "1. Get log4j configured to work in the IDE. Absence of log4j configuration won't stop hadoop from running, but we won't get to see useful error messages from hadoop without it.[\n]"
http-outgoing-3 >> "2. HADOOP_HOME environment variable project run (and test) property.[\n]"
http-outgoing-3 >> "3. Duplicate hadoop configuration in the classpath. The above environment variable does not pick up the hadoop configuration from its usual place. Yahoo's only suggestion is to run from the command line via the hadoop script. The Apache HDFS API documention says that configuration is looked for in the classpath, so I took the approach of duplicating the configuration (just 2 files) instead of figuring out how to get it to look in the installation path.[\n]"
http-outgoing-3 >> "4. The correct Maven dependencies. If not all the jar depenencies are there the program may build and run, but it won't talk to the HDFS if it doesn't load the HDFS jars.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "I think that the setup of this project would probably work on Linux too.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## Working through trouble shooting the HDFS project settings[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "Issue 1 above shows up as:[\n]"
http-outgoing-3 >> "<pre><code>[\n]"
http-outgoing-3 >> "log4j:WARN No appenders could be found for logger (org.apache.hadoop.util.Shell).[\n]"
http-outgoing-3 >> "log4j:WARN Please initialize the log4j system properly.[\n]"
http-outgoing-3 >> "log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.[\n]"
http-outgoing-3 >> "</pre></code>[\n]"
http-outgoing-3 >> "This is solved by putting a log4j.properties configuration file in the classpath. For a Maven build getting files into the classpath can be achieved by putting them in src/main/resources. I don't think this is in the classpath, but the build will then copy the file into ./target/classes/ which is in the classpath.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "Issue 2 above shows up as:[\n]"
http-outgoing-3 >> "<pre><code>[\n]"
http-outgoing-3 >> "Failed to detect a valid hadoop home directory[\n]"
http-outgoing-3 >> "java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.[\n]"
http-outgoing-3 >> "</code></pre>[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "This is fixed by going into the project properties => Build => Actions => Run Project and adding the environmen[\r][\n]"
http-outgoing-3 >> "1000[\r][\n]"
http-outgoing-3 >> "t variable for HADOOP_HOME. This will result in an entry in the Maven POM. Repeat for "Test Project", "Debug Project" etc.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "Issue 3. shows up as running, but creating a file on the local file system instead of the HDFS. This was fixed       looking at the HDFS API documentation for org.apache.hadoop.conf.Configuration. This documentation is under the chapter: C API libhdfs HDFS which has a link to the HDFS API under "The APIs" (I strangely cannot find this in the main index). On my installation the HDFS API documentation link is file:///opt/local/hadoop-2.7.0/share/doc/hadoop/api/org/apache/hadoop/fs/FileSystem.html.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "This documentation told me that hadoop loads core-site.xml and core-default.xml in the classpath. Classpath for a Maven build can be reached by placing these files in the directory src/main/resources (see logging configuration above). I added hdfs-site instead of core-default (which doesn't exist on my 2.7 install) into the src/main/resources project directory.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "Issue 3 shows up as:[\n]"
http-outgoing-3 >> "<pre><code>[\n]"
http-outgoing-3 >> "java.io.IOException: "hadoop No FileSystem for scheme: hdfs".[\n]"
http-outgoing-3 >> "</code></pre>[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "This is part of the build dependency problem. The various threads on stackoverflow etc. suggested that a minimum dependency was the jar for hadoop-core. However, there is no such jar on 2.7. I ran the hadoop command to dump version and got this:[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "<pre><code>[\n]"
http-outgoing-3 >> "bin/hadoop version[\n]"
http-outgoing-3 >> "Hadoop 2.7.0[\n]"
http-outgoing-3 >> "Subversion https://git-wip-us.apache.org/repos/asf/hadoop.git -r d4c8d4d4d203c934e8074b31289a28724c0842cf[\n]"
http-outgoing-3 >> "Compiled by jenkins on 2015-04-10T18:40Z[\n]"
http-outgoing-3 >> "Compiled with protoc 2.5.0[\n]"
http-outgoing-3 >> "From source with checksum a9e90912c37a35c3195d23951fd18f[\n]"
http-outgoing-3 >> "This command was run using /opt/local/hadoop-2.7.0/share/hadoop/common/hadoop-common-2.7.0.jar[\n]"
http-outgoing-3 >> "</code></pre>[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "I noted the jar name at the end and added it as a dependency to the POM. This can either be hand coded in or right click pom.xml => Insert Code => Add Dependency => Search => query hadoop-common and select version which was 2.7.0 [jar] - central. Maven will then add dependencies to other hadoop jars in the "Dependencies" group in the project explorer. Netbeans will then download these dependencies before the next build. They go into ~/.m2/repository should they ever need to be cleaned out (Netbeans doesn't seem to have an IDE remove dependency option).[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "After doing the above project built, but showed up the "no filesystem error". I noticed that Maven had not pulled in any hdfs jars matching the jars in my share/hadoop/hdfs installation directory. So I took a guess that it needed only the top level hadoop-hdfs-2.7.0.jar and added this as a dependency to the POM and all was good :)[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## Working through trouble shooting the Map Reduce project settings[\n]"
http-outgoing-3 >> "After getting the HDFS API working in the IDE it was time to move on to getting the famous Word Count map-reduce tutorial running.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "So coded it, set the main program to the word count main as the one to run. From the IDE: project Properties => Run => Main Class. Provide input and output arguments for the word count program. I noted that the netbeans properties pop-up window does not persist these settings next time it pops up. However this setting is persistant and ends up in nbactions.xml.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "However, running the word count map reduce program resulted in an ioException:[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "<pre><code>[\n]"
http-outgoing-3 >> "Please check your configuration for mapreduce.framework.name and the correspond server addresses.[\n]"
http-outgoing-3 >> "</pre></code>[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "Because the resources directory only contains 2 configuration files from my hadoop installation I thought maybe I was missing a map reduce one. So the first thing I did was go into the configuration directory of my installation and grep all files to see if there was a configuration file with mapreduce framework property. There was not. I checked my programatic configuration dump from my test program. This property was not mentioned either. The only map reduce configuration was to do with some environment variables for heap size in one of the shell scripts. Note to self: this may be relevant and I can consider setting this in the IDE. However, that didn't look like the problem.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "I then chec[\r][\n]"
http-outgoing-3 >> "a93[\r][\n]"
http-outgoing-3 >> "ked my dependencies and noted there were no map reduce jars pulled in by Maven. So I added hadoop-mapreduce-client-core. Still not running. Checked the web and a thread on stackoverflow mentioned a number of other jars: hadoop-mapreduce-client-common and hadoop-mapreduce-client shuffle. I added just the hadoop-mapreduce-client-common and it runs :) I have a feeling that I might need some of the other jars for other API calls and that there must be a better way of working out dependencies than this trial and error. As mentioned I am a newbie with this, so if anyone has any comments feel free to email me.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## Logging from application code[\n]"
http-outgoing-3 >> "Although the hadoop libraries log correctly with a properly located log4.properties file, application code calling the log4j logger seems to ignore this file. Using the log4j logger as per instructions in the log4j manual and many online tutorials did not result in getting any logging redirected to file configured in the properties file. Instead console output only is obtained. A clue to this mystery was that a most basic of hello world netbeans maven projects which did not import any hadoop stuff also failed to log to a file and did not even give the "No appenders" warning. Then I noticed that there were org.sl4j depencies in the hadoop build, so using sl4j instead solved the problem. Once my hello world project used sl4j's LoggerFactory and had sl4j-api and sl4j-12 as a dependencies it started to use the properties file. See http://www.slf4j.org/manual.html[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## Upload a file from local storage to the HDFS via the REST API[\n]"
http-outgoing-3 >> "The WebHDFS REST API documentation which came with the installation specifies that file creation is a two stage operation where an initial PUT to the namenode is sent. This responds with a redirect to the datanode and another PUT should be made to this redirection which can contain the chunked data stream. This does not sound REST to me as it relies on holding redirection state (a fully distributed configuration could presumably return a redirection to any one of the datanodes). Hadoop say this is because of a bug in some HTTP client implementations - incorrect implementation of [0xe2][0x80][0x9c]Expect: 100-continue[0xe2][0x80][0x9d].[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "However, the 2 stage PUT not being REST seems to be a moot point, at least with the Jersey client. I do not get a redirection and a file creates/uploads all in one go.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "Since writing the above paragraph I have implemented the Apache Client back end option to my HDFS Web client interface and this client behaves differently. It does indeed cause a redirect as per Hadoop documentation. The follow up PUT to the redirected location with the chunked file stream works as per documentation.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "To be continued ...[\n]"
http-outgoing-3 >> "[\r][\n]"
http-outgoing-3 >> "0[\r][\n]"
http-outgoing-3 >> "[\r][\n]"
http-outgoing-3 << "HTTP/1.1 307 TEMPORARY_REDIRECT[\r][\n]"
http-outgoing-3 << "Cache-Control: no-cache[\r][\n]"
http-outgoing-3 << "Expires: Sun, 14 Jun 2015 00:33:06 GMT[\r][\n]"
http-outgoing-3 << "Date: Sun, 14 Jun 2015 00:33:06 GMT[\r][\n]"
http-outgoing-3 << "Pragma: no-cache[\r][\n]"
http-outgoing-3 << "Expires: Sun, 14 Jun 2015 00:33:06 GMT[\r][\n]"
http-outgoing-3 << "Date: Sun, 14 Jun 2015 00:33:06 GMT[\r][\n]"
http-outgoing-3 << "Pragma: no-cache[\r][\n]"
http-outgoing-3 << "Content-Type: application/octet-stream[\r][\n]"
http-outgoing-3 << "Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434277986652&s=GmrLLuC6QngzNCkohYS8hZ25Nz0="; Path=/; Expires=Sun, 14-Jun-2015 10:33:06 GMT; HttpOnly[\r][\n]"
http-outgoing-3 << "Location: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/README.md?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true[\r][\n]"
http-outgoing-3 << "Content-Length: 0[\r][\n]"
http-outgoing-3 << "Server: Jetty(6.1.26)[\r][\n]"
http-outgoing-3 << "[\r][\n]"
http-outgoing-3 << HTTP/1.1 307 TEMPORARY_REDIRECT
http-outgoing-3 << Cache-Control: no-cache
http-outgoing-3 << Expires: Sun, 14 Jun 2015 00:33:06 GMT
http-outgoing-3 << Date: Sun, 14 Jun 2015 00:33:06 GMT
http-outgoing-3 << Pragma: no-cache
http-outgoing-3 << Expires: Sun, 14 Jun 2015 00:33:06 GMT
http-outgoing-3 << Date: Sun, 14 Jun 2015 00:33:06 GMT
http-outgoing-3 << Pragma: no-cache
http-outgoing-3 << Content-Type: application/octet-stream
http-outgoing-3 << Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434277986652&s=GmrLLuC6QngzNCkohYS8hZ25Nz0="; Path=/; Expires=Sun, 14-Jun-2015 10:33:06 GMT; HttpOnly
http-outgoing-3 << Location: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/README.md?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
http-outgoing-3 << Content-Length: 0
http-outgoing-3 << Server: Jetty(6.1.26)
Connection can be kept alive indefinitely
Cookie accepted [hadoop.auth=""u=michaeljones&p=michaeljones&t=simple&e=1434277986652&s=GmrLLuC6QngzNCkohYS8hZ25Nz0="", version:0, domain:localhost, path:/, expiry:Sun Jun 14 20:33:06 AEST 2015]
Redirect to: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/README.md?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
http-outgoing-3: Shutdown connection
Connection discarded
http-outgoing-3: Close connection
Connection released: [id: 3][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 4][route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://michaels-air.bigpond:50075
Connecting to michaels-air.bigpond/10.0.0.2:50075
Connection established 10.0.0.2:49787<->10.0.0.2:50075
Executing request PUT /webhdfs/v1/user/michaeljones/README.md?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-4 >> PUT /webhdfs/v1/user/michaeljones/README.md?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1
http-outgoing-4 >> Transfer-Encoding: chunked
http-outgoing-4 >> Content-Type: application/octet-stream
http-outgoing-4 >> Host: michaels-air.bigpond:50075
http-outgoing-4 >> Connection: Keep-Alive
http-outgoing-4 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-4 >> Accept-Encoding: gzip,deflate
http-outgoing-4 >> "PUT /webhdfs/v1/user/michaeljones/README.md?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1[\r][\n]"
http-outgoing-4 >> "Transfer-Encoding: chunked[\r][\n]"
http-outgoing-4 >> "Content-Type: application/octet-stream[\r][\n]"
http-outgoing-4 >> "Host: michaels-air.bigpond:50075[\r][\n]"
http-outgoing-4 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-4 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-4 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-4 >> "[\r][\n]"
http-outgoing-4 >> "1000[\r][\n]"
http-outgoing-4 >> "# Hello-Hadoop-netbeans-OS-X[\n]"
http-outgoing-4 >> "Java Maven project for playing with the HDFS API without any 3rd party hadoop plugins.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## Aim of project[\n]"
http-outgoing-4 >> "Hello world/tutorial level for programmatically operating with a pseudo distributed hadoop configuration on OS X. Hadoop 2.7 on Yosemite.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## What this project demonstrates[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "This is work in progress and so far the following functionality is demonstrated:[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "1. Direct programmatic control of the HDFS and running map reduce jobs - all unit tests run from the IDE with hadoop configuration built into this project and under git control.[\n]"
http-outgoing-4 >> "2. Uploading of files to the HDFS by implementing a Web REST API client.[\n]"
http-outgoing-4 >> "3. Layered application code for maximum re-use and ease of test driven development. The client I wrote uses an interface which has allowed me to provide both a Jersey HTTP client implementation and an Apache HTTP client implementation for comparison between the two toolkits.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "The initial difficulty was working out how to run the program in the IDE and talk to the local pseudo distributed setup without using a 3rd party Hadoop plugin. Apparently there used to be a plugin for netbeans, but it has been discontinued. I am a newbie with this technology.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "The Apache Hadoop instructions for building and running java programs are via their command line build/run utility only. Getting the yahoo hadoop HDFS tutorial program to build in the IDE wasn't too hard. However, by default it will ignore the local Hadoop configuration and only operate with the local file system in local debug mode.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## Wading through the configuration[\n]"
http-outgoing-4 >> "Hadoop is designed to work with a number of different topologies, directory locations, levels of replication, simulated environments etc. so as we would expect nothing works unless the configuration is right.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "First Hadoop needs to be installed and configured in pseudo distributed mode such that it builds and runs test programs on the command line. The hadoop documentation has instructions for doing this. Documentation is online and also included in the installation: share/doc/hadoop/index.html. However this is not enough to get it to work in the IDE.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## The netbeans project settings that are needed to run with the HDFS from the IDE:[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "1. Get log4j configured to work in the IDE. Absence of log4j configuration won't stop hadoop from running, but we won't get to see useful error messages from hadoop without it.[\n]"
http-outgoing-4 >> "2. HADOOP_HOME environment variable project run (and test) property.[\n]"
http-outgoing-4 >> "3. Duplicate hadoop configuration in the classpath. The above environment variable does not pick up the hadoop configuration from its usual place. Yahoo's only suggestion is to run from the command line via the hadoop script. The Apache HDFS API documention says that configuration is looked for in the classpath, so I took the approach of duplicating the configuration (just 2 files) instead of figuring out how to get it to look in the installation path.[\n]"
http-outgoing-4 >> "4. The correct Maven dependencies. If not all the jar depenencies are there the program may build and run, but it won't talk to the HDFS if it doesn't load the HDFS jars.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "I think that the setup of this project would probably work on Linux too.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## Working through trouble shooting the HDFS project settings[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "Issue 1 above shows up as:[\n]"
http-outgoing-4 >> "<pre><code>[\n]"
http-outgoing-4 >> "log4j:WARN No appenders could be found for logger (org.apache.hadoop.util.Shell).[\n]"
http-outgoing-4 >> "log4j:WARN Please initialize the log4j system properly.[\n]"
http-outgoing-4 >> "log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.[\n]"
http-outgoing-4 >> "</pre></code>[\n]"
http-outgoing-4 >> "This is solved by putting a log4j.properties configuration file in the classpath. For a Maven build getting files into the classpath can be achieved by putting them in src/main/resources. I don't think this is in the classpath, but the build will then copy the file into ./target/classes/ which is in the classpath.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "Issue 2 above shows up as:[\n]"
http-outgoing-4 >> "<pre><code>[\n]"
http-outgoing-4 >> "Failed to detect a valid hadoop home directory[\n]"
http-outgoing-4 >> "java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.[\n]"
http-outgoing-4 >> "</code></pre>[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "This is fixed by going into the project properties => Build => Actions => Run Project and adding the environmen[\r][\n]"
http-outgoing-4 >> "1000[\r][\n]"
http-outgoing-4 >> "t variable for HADOOP_HOME. This will result in an entry in the Maven POM. Repeat for "Test Project", "Debug Project" etc.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "Issue 3. shows up as running, but creating a file on the local file system instead of the HDFS. This was fixed       looking at the HDFS API documentation for org.apache.hadoop.conf.Configuration. This documentation is under the chapter: C API libhdfs HDFS which has a link to the HDFS API under "The APIs" (I strangely cannot find this in the main index). On my installation the HDFS API documentation link is file:///opt/local/hadoop-2.7.0/share/doc/hadoop/api/org/apache/hadoop/fs/FileSystem.html.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "This documentation told me that hadoop loads core-site.xml and core-default.xml in the classpath. Classpath for a Maven build can be reached by placing these files in the directory src/main/resources (see logging configuration above). I added hdfs-site instead of core-default (which doesn't exist on my 2.7 install) into the src/main/resources project directory.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "Issue 3 shows up as:[\n]"
http-outgoing-4 >> "<pre><code>[\n]"
http-outgoing-4 >> "java.io.IOException: "hadoop No FileSystem for scheme: hdfs".[\n]"
http-outgoing-4 >> "</code></pre>[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "This is part of the build dependency problem. The various threads on stackoverflow etc. suggested that a minimum dependency was the jar for hadoop-core. However, there is no such jar on 2.7. I ran the hadoop command to dump version and got this:[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "<pre><code>[\n]"
http-outgoing-4 >> "bin/hadoop version[\n]"
http-outgoing-4 >> "Hadoop 2.7.0[\n]"
http-outgoing-4 >> "Subversion https://git-wip-us.apache.org/repos/asf/hadoop.git -r d4c8d4d4d203c934e8074b31289a28724c0842cf[\n]"
http-outgoing-4 >> "Compiled by jenkins on 2015-04-10T18:40Z[\n]"
http-outgoing-4 >> "Compiled with protoc 2.5.0[\n]"
http-outgoing-4 >> "From source with checksum a9e90912c37a35c3195d23951fd18f[\n]"
http-outgoing-4 >> "This command was run using /opt/local/hadoop-2.7.0/share/hadoop/common/hadoop-common-2.7.0.jar[\n]"
http-outgoing-4 >> "</code></pre>[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "I noted the jar name at the end and added it as a dependency to the POM. This can either be hand coded in or right click pom.xml => Insert Code => Add Dependency => Search => query hadoop-common and select version which was 2.7.0 [jar] - central. Maven will then add dependencies to other hadoop jars in the "Dependencies" group in the project explorer. Netbeans will then download these dependencies before the next build. They go into ~/.m2/repository should they ever need to be cleaned out (Netbeans doesn't seem to have an IDE remove dependency option).[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "After doing the above project built, but showed up the "no filesystem error". I noticed that Maven had not pulled in any hdfs jars matching the jars in my share/hadoop/hdfs installation directory. So I took a guess that it needed only the top level hadoop-hdfs-2.7.0.jar and added this as a dependency to the POM and all was good :)[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## Working through trouble shooting the Map Reduce project settings[\n]"
http-outgoing-4 >> "After getting the HDFS API working in the IDE it was time to move on to getting the famous Word Count map-reduce tutorial running.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "So coded it, set the main program to the word count main as the one to run. From the IDE: project Properties => Run => Main Class. Provide input and output arguments for the word count program. I noted that the netbeans properties pop-up window does not persist these settings next time it pops up. However this setting is persistant and ends up in nbactions.xml.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "However, running the word count map reduce program resulted in an ioException:[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "<pre><code>[\n]"
http-outgoing-4 >> "Please check your configuration for mapreduce.framework.name and the correspond server addresses.[\n]"
http-outgoing-4 >> "</pre></code>[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "Because the resources directory only contains 2 configuration files from my hadoop installation I thought maybe I was missing a map reduce one. So the first thing I did was go into the configuration directory of my installation and grep all files to see if there was a configuration file with mapreduce framework property. There was not. I checked my programatic configuration dump from my test program. This property was not mentioned either. The only map reduce configuration was to do with some environment variables for heap size in one of the shell scripts. Note to self: this may be relevant and I can consider setting this in the IDE. However, that didn't look like the problem.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "I then chec[\r][\n]"
http-outgoing-4 >> "a93[\r][\n]"
http-outgoing-4 >> "ked my dependencies and noted there were no map reduce jars pulled in by Maven. So I added hadoop-mapreduce-client-core. Still not running. Checked the web and a thread on stackoverflow mentioned a number of other jars: hadoop-mapreduce-client-common and hadoop-mapreduce-client shuffle. I added just the hadoop-mapreduce-client-common and it runs :) I have a feeling that I might need some of the other jars for other API calls and that there must be a better way of working out dependencies than this trial and error. As mentioned I am a newbie with this, so if anyone has any comments feel free to email me.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## Logging from application code[\n]"
http-outgoing-4 >> "Although the hadoop libraries log correctly with a properly located log4.properties file, application code calling the log4j logger seems to ignore this file. Using the log4j logger as per instructions in the log4j manual and many online tutorials did not result in getting any logging redirected to file configured in the properties file. Instead console output only is obtained. A clue to this mystery was that a most basic of hello world netbeans maven projects which did not import any hadoop stuff also failed to log to a file and did not even give the "No appenders" warning. Then I noticed that there were org.sl4j depencies in the hadoop build, so using sl4j instead solved the problem. Once my hello world project used sl4j's LoggerFactory and had sl4j-api and sl4j-12 as a dependencies it started to use the properties file. See http://www.slf4j.org/manual.html[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## Upload a file from local storage to the HDFS via the REST API[\n]"
http-outgoing-4 >> "The WebHDFS REST API documentation which came with the installation specifies that file creation is a two stage operation where an initial PUT to the namenode is sent. This responds with a redirect to the datanode and another PUT should be made to this redirection which can contain the chunked data stream. This does not sound REST to me as it relies on holding redirection state (a fully distributed configuration could presumably return a redirection to any one of the datanodes). Hadoop say this is because of a bug in some HTTP client implementations - incorrect implementation of [0xe2][0x80][0x9c]Expect: 100-continue[0xe2][0x80][0x9d].[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "However, the 2 stage PUT not being REST seems to be a moot point, at least with the Jersey client. I do not get a redirection and a file creates/uploads all in one go.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "Since writing the above paragraph I have implemented the Apache Client back end option to my HDFS Web client interface and this client behaves differently. It does indeed cause a redirect as per Hadoop documentation. The follow up PUT to the redirected location with the chunked file stream works as per documentation.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "To be continued ...[\n]"
http-outgoing-4 >> "[\r][\n]"
http-outgoing-4 >> "0[\r][\n]"
http-outgoing-4 >> "[\r][\n]"
http-outgoing-4 << "HTTP/1.1 100 Continue[\r][\n]"
http-outgoing-4 << "[\r][\n]"
http-outgoing-4 << HTTP/1.1 100 Continue
http-outgoing-4 << "HTTP/1.1 201 Created[\r][\n]"
http-outgoing-4 << "Location: hdfs://localhost:9000/user/michaeljones/README.md[\r][\n]"
http-outgoing-4 << "Content-Length: 0[\r][\n]"
http-outgoing-4 << "Connection: close[\r][\n]"
http-outgoing-4 << "[\r][\n]"
http-outgoing-4 << HTTP/1.1 201 Created
http-outgoing-4 << Location: hdfs://localhost:9000/user/michaeljones/README.md
http-outgoing-4 << Content-Length: 0
http-outgoing-4 << Connection: close
http-outgoing-4: Shutdown connection
Connection discarded
http-outgoing-4: Close connection
Connection released: [id: 4][route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection manager is shutting down
Connection manager shut down
com.sun.jersey.client.property.chunkedEncodingSize: 1048576
Jersey client Redirect to: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/nbactions.xml?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
com.sun.jersey.client.property.chunkedEncodingSize: 1048576
Jersey client Redirect to: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/nbactions.xml?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
Connection manager is shutting down
Connection manager shut down
com.sun.jersey.client.property.chunkedEncodingSize: 1048576
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 0][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://localhost:50070
Connecting to localhost/127.0.0.1:50070
Connection established 127.0.0.1:49814<->127.0.0.1:50070
Executing request GET /webhdfs/v1/user/michaeljones/?user.name=michaeljones&op=LISTSTATUS HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-0 >> GET /webhdfs/v1/user/michaeljones/?user.name=michaeljones&op=LISTSTATUS HTTP/1.1
http-outgoing-0 >> accept: application/json
http-outgoing-0 >> Host: localhost:50070
http-outgoing-0 >> Connection: Keep-Alive
http-outgoing-0 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-0 >> Accept-Encoding: gzip,deflate
http-outgoing-0 >> "GET /webhdfs/v1/user/michaeljones/?user.name=michaeljones&op=LISTSTATUS HTTP/1.1[\r][\n]"
http-outgoing-0 >> "accept: application/json[\r][\n]"
http-outgoing-0 >> "Host: localhost:50070[\r][\n]"
http-outgoing-0 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-0 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-0 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-0 >> "[\r][\n]"
http-outgoing-0 << "HTTP/1.1 200 OK[\r][\n]"
http-outgoing-0 << "Cache-Control: no-cache[\r][\n]"
http-outgoing-0 << "Expires: Sun, 14 Jun 2015 00:35:59 GMT[\r][\n]"
http-outgoing-0 << "Date: Sun, 14 Jun 2015 00:35:59 GMT[\r][\n]"
http-outgoing-0 << "Pragma: no-cache[\r][\n]"
http-outgoing-0 << "Expires: Sun, 14 Jun 2015 00:35:59 GMT[\r][\n]"
http-outgoing-0 << "Date: Sun, 14 Jun 2015 00:35:59 GMT[\r][\n]"
http-outgoing-0 << "Pragma: no-cache[\r][\n]"
http-outgoing-0 << "Content-Type: application/json[\r][\n]"
http-outgoing-0 << "Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434278159084&s=1GHnQ/LiGUryc+zz41APQ5A1A74="; Path=/; Expires=Sun, 14-Jun-2015 10:35:59 GMT; HttpOnly[\r][\n]"
http-outgoing-0 << "Transfer-Encoding: chunked[\r][\n]"
http-outgoing-0 << "Server: Jetty(6.1.26)[\r][\n]"
http-outgoing-0 << "[\r][\n]"
http-outgoing-0 << "10C1[\r][\n]"
http-outgoing-0 << "{"FileStatuses":{"FileStatus":[[\n]"
http-outgoing-0 << "{"accessTime":1434241986723,"blockSize":134217728,"childrenNum":0,"fileId":18660,"group":"supergroup","length":10899,"modificationTime":1434241986765,"owner":"michaeljones","pathSuffix":"README.md","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434180764122,"blockSize":134217728,"childrenNum":0,"fileId":18621,"group":"supergroup","length":0,"modificationTime":1434180764129,"owner":"michaeljones","pathSuffix":"apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434240295990,"blockSize":134217728,"childrenNum":0,"fileId":18639,"group":"supergroup","length":0,"modificationTime":1434240295996,"owner":"michaeljones","pathSuffix":"empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434241986145,"blockSize":134217728,"childrenNum":0,"fileId":18657,"group":"supergroup","length":0,"modificationTime":1434241986157,"owner":"michaeljones","pathSuffix":"hello-apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434091626279,"blockSize":134217728,"childrenNum":0,"fileId":18298,"group":"supergroup","length":0,"modificationTime":1434091626286,"owner":"michaeljones","pathSuffix":"hello-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434241986005,"blockSize":134217728,"childrenNum":0,"fileId":18656,"group":"supergroup","length":0,"modificationTime":1434241986066,"owner":"michaeljones","pathSuffix":"hello-jersey-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434240296439,"blockSize":134217728,"childrenNum":0,"fileId":18641,"group":"supergroup","length":19574,"modificationTime":1434240296468,"owner":"michaeljones","pathSuffix":"hello.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434241986501,"blockSize":134217728,"childrenNum":0,"fileId":18659,"group":"supergroup","length":3678856,"modificationTime":1434241986598,"owner":"michaeljones","pathSuffix":"hello.log.2015-06-12","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434180756986,"blockSize":134217728,"childrenNum":0,"fileId":18599,"group":"supergroup","length":20,"modificationTime":1434180757588,"owner":"michaeljones","pathSuffix":"hello.txt","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434241986371,"blockSize":134217728,"childrenNum":0,"fileId":18658,"group":"supergroup","length":17984,"modificationTime":1434241986424,"owner":"michaeljones","pathSuffix":"hellohadoop.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434241987222,"blockSize":134217728,"childrenNum":0,"fileId":18661,"group":"supergroup","length":3644,"modificationTime":1434241987249,"owner":"michaeljones","pathSuffix":"nbactions.xml","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434180764163,"blockSize":134217728,"childrenNum":0,"fileId":18622,"group":"supergroup","length":2134,"modificationTime":1434180764193,"owner":"michaeljones","pathSuffix":"pom.xml","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434180758226,"blockSize":134217728,"childrenNum":0,"fileId":16388,"group":"supergroup","length":50,"modificationTime":1433119638967,"owner":"michaeljones","pathSuffix":"wcInput","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18600,"group":"supergroup","length":0,"modificationTime":1434180760247,"owner":"michaeljones","pathSuffix":"wcOutput","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},[\n]"
http-outgoing-0 << "{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18607,"group":"supergroup","length":0,"modificationTime":1434180761544,"owner":"michaeljones","pathSuffix":"wcOutputAnalysis","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},[\n]"
http-outgoing-0 << "{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18614,"group":"supergroup","length":0,"modificationTime":1434180763349,"owner":"michaeljones","pathSuffix":"wcOutputMain","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"}[\n]"
http-outgoing-0 << "]}}[\n]"
http-outgoing-0 << "[\r][\n]"
http-outgoing-0 << "0[\r][\n]"
http-outgoing-0 << "[\r][\n]"
http-outgoing-0 << HTTP/1.1 200 OK
http-outgoing-0 << Cache-Control: no-cache
http-outgoing-0 << Expires: Sun, 14 Jun 2015 00:35:59 GMT
http-outgoing-0 << Date: Sun, 14 Jun 2015 00:35:59 GMT
http-outgoing-0 << Pragma: no-cache
http-outgoing-0 << Expires: Sun, 14 Jun 2015 00:35:59 GMT
http-outgoing-0 << Date: Sun, 14 Jun 2015 00:35:59 GMT
http-outgoing-0 << Pragma: no-cache
http-outgoing-0 << Content-Type: application/json
http-outgoing-0 << Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434278159084&s=1GHnQ/LiGUryc+zz41APQ5A1A74="; Path=/; Expires=Sun, 14-Jun-2015 10:35:59 GMT; HttpOnly
http-outgoing-0 << Transfer-Encoding: chunked
http-outgoing-0 << Server: Jetty(6.1.26)
Connection can be kept alive indefinitely
Cookie accepted [hadoop.auth=""u=michaeljones&p=michaeljones&t=simple&e=1434278159084&s=1GHnQ/LiGUryc+zz41APQ5A1A74="", version:0, domain:localhost, path:/, expiry:Sun Jun 14 20:35:59 AEST 2015]
Connection [id: 0][route: {}->http://localhost:50070] can be kept alive indefinitely
Connection released: [id: 0][route: {}->http://localhost:50070][total kept alive: 1; route allocated: 1 of 2; total allocated: 1 of 20]
Connection manager is shutting down
http-outgoing-0: Close connection
http-outgoing-0: Close connection
Connection manager shut down
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 1][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://localhost:50070
Connecting to localhost/127.0.0.1:50070
Connection established 127.0.0.1:49817<->127.0.0.1:50070
Executing request PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-1 >> PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1
http-outgoing-1 >> Content-Length: 0
http-outgoing-1 >> Host: localhost:50070
http-outgoing-1 >> Connection: Keep-Alive
http-outgoing-1 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-1 >> Accept-Encoding: gzip,deflate
http-outgoing-1 >> "PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1[\r][\n]"
http-outgoing-1 >> "Content-Length: 0[\r][\n]"
http-outgoing-1 >> "Host: localhost:50070[\r][\n]"
http-outgoing-1 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-1 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-1 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-1 >> "[\r][\n]"
http-outgoing-1 << "HTTP/1.1 307 TEMPORARY_REDIRECT[\r][\n]"
http-outgoing-1 << "Cache-Control: no-cache[\r][\n]"
http-outgoing-1 << "Expires: Sun, 14 Jun 2015 00:35:59 GMT[\r][\n]"
http-outgoing-1 << "Date: Sun, 14 Jun 2015 00:35:59 GMT[\r][\n]"
http-outgoing-1 << "Pragma: no-cache[\r][\n]"
http-outgoing-1 << "Expires: Sun, 14 Jun 2015 00:35:59 GMT[\r][\n]"
http-outgoing-1 << "Date: Sun, 14 Jun 2015 00:35:59 GMT[\r][\n]"
http-outgoing-1 << "Pragma: no-cache[\r][\n]"
http-outgoing-1 << "Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434278159612&s=tojhDaV46Te5ZzCLpjT4qZGJhoc="; Path=/; Expires=Sun, 14-Jun-2015 10:35:59 GMT; HttpOnly[\r][\n]"
http-outgoing-1 << "Location: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true[\r][\n]"
http-outgoing-1 << "Content-Type: application/octet-stream[\r][\n]"
http-outgoing-1 << "Content-Length: 0[\r][\n]"
http-outgoing-1 << "Server: Jetty(6.1.26)[\r][\n]"
http-outgoing-1 << "[\r][\n]"
http-outgoing-1 << HTTP/1.1 307 TEMPORARY_REDIRECT
http-outgoing-1 << Cache-Control: no-cache
http-outgoing-1 << Expires: Sun, 14 Jun 2015 00:35:59 GMT
http-outgoing-1 << Date: Sun, 14 Jun 2015 00:35:59 GMT
http-outgoing-1 << Pragma: no-cache
http-outgoing-1 << Expires: Sun, 14 Jun 2015 00:35:59 GMT
http-outgoing-1 << Date: Sun, 14 Jun 2015 00:35:59 GMT
http-outgoing-1 << Pragma: no-cache
http-outgoing-1 << Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434278159612&s=tojhDaV46Te5ZzCLpjT4qZGJhoc="; Path=/; Expires=Sun, 14-Jun-2015 10:35:59 GMT; HttpOnly
http-outgoing-1 << Location: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
http-outgoing-1 << Content-Type: application/octet-stream
http-outgoing-1 << Content-Length: 0
http-outgoing-1 << Server: Jetty(6.1.26)
Connection can be kept alive indefinitely
Cookie accepted [hadoop.auth=""u=michaeljones&p=michaeljones&t=simple&e=1434278159612&s=tojhDaV46Te5ZzCLpjT4qZGJhoc="", version:0, domain:localhost, path:/, expiry:Sun Jun 14 20:35:59 AEST 2015]
Redirect to: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
http-outgoing-1: Shutdown connection
Connection discarded
http-outgoing-1: Close connection
Connection released: [id: 1][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 2][route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://michaels-air.bigpond:50075
Connecting to michaels-air.bigpond/10.0.0.2:50075
Connection established 10.0.0.2:49818<->10.0.0.2:50075
Executing request PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-2 >> PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1
http-outgoing-2 >> Content-Length: 0
http-outgoing-2 >> Host: michaels-air.bigpond:50075
http-outgoing-2 >> Connection: Keep-Alive
http-outgoing-2 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-2 >> Accept-Encoding: gzip,deflate
http-outgoing-2 >> "PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1[\r][\n]"
http-outgoing-2 >> "Content-Length: 0[\r][\n]"
http-outgoing-2 >> "Host: michaels-air.bigpond:50075[\r][\n]"
http-outgoing-2 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-2 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-2 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-2 >> "[\r][\n]"
http-outgoing-2 << "HTTP/1.1 100 Continue[\r][\n]"
http-outgoing-2 << "[\r][\n]"
http-outgoing-2 << HTTP/1.1 100 Continue
http-outgoing-2 << "HTTP/1.1 201 Created[\r][\n]"
http-outgoing-2 << "Location: hdfs://localhost:9000/user/michaeljones/hello-apache-empty.txt[\r][\n]"
http-outgoing-2 << "Content-Length: 0[\r][\n]"
http-outgoing-2 << "Connection: close[\r][\n]"
http-outgoing-2 << "[\r][\n]"
http-outgoing-2 << HTTP/1.1 201 Created
http-outgoing-2 << Location: hdfs://localhost:9000/user/michaeljones/hello-apache-empty.txt
http-outgoing-2 << Content-Length: 0
http-outgoing-2 << Connection: close
http-outgoing-2: Shutdown connection
Connection discarded
http-outgoing-2: Close connection
Connection released: [id: 2][route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection manager is shutting down
Connection manager shut down
Jersey client Redirect to: hdfs://localhost:9000/user/michaeljones/hellohadoop.log
com.sun.jersey.client.property.chunkedEncodingSize: 1048576
Jersey client Redirect to: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/hello.log.2015-06-12?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 3][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://localhost:50070
Connecting to localhost/127.0.0.1:50070
Connection established 127.0.0.1:49828<->127.0.0.1:50070
Executing request PUT /webhdfs/v1/user/michaeljones/README.md?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-3 >> PUT /webhdfs/v1/user/michaeljones/README.md?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1
http-outgoing-3 >> Transfer-Encoding: chunked
http-outgoing-3 >> Content-Type: application/octet-stream
http-outgoing-3 >> Host: localhost:50070
http-outgoing-3 >> Connection: Keep-Alive
http-outgoing-3 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-3 >> Accept-Encoding: gzip,deflate
http-outgoing-3 >> "PUT /webhdfs/v1/user/michaeljones/README.md?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1[\r][\n]"
http-outgoing-3 >> "Transfer-Encoding: chunked[\r][\n]"
http-outgoing-3 >> "Content-Type: application/octet-stream[\r][\n]"
http-outgoing-3 >> "Host: localhost:50070[\r][\n]"
http-outgoing-3 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-3 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-3 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-3 >> "[\r][\n]"
http-outgoing-3 >> "1000[\r][\n]"
http-outgoing-3 >> "# Hello-Hadoop-netbeans-OS-X[\n]"
http-outgoing-3 >> "Java Maven project for playing with the HDFS API without any 3rd party hadoop plugins.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## Aim of project[\n]"
http-outgoing-3 >> "Hello world/tutorial level for programmatically operating with a pseudo distributed hadoop configuration on OS X. Hadoop 2.7 on Yosemite.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## What this project demonstrates[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "This is work in progress and so far the following functionality is demonstrated:[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "1. Direct programmatic control of the HDFS and running map reduce jobs - all unit tests run from the IDE with hadoop configuration built into this project and under git control.[\n]"
http-outgoing-3 >> "2. Uploading of files to the HDFS by implementing a Web REST API client.[\n]"
http-outgoing-3 >> "3. Async file upload (at time of writing only Jersey back end implemented).[\n]"
http-outgoing-3 >> "4. Layered application code for maximum re-use and ease of test driven development. The client I wrote uses an interface which has allowed me to provide both a Jersey HTTP client implementation and an Apache HTTP client implementation for comparison between the two toolkits.[\n]"
http-outgoing-3 >> "5. Test driven development.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## Getting started[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "The initial difficulty was working out how to run the program in the IDE and talk to the local pseudo distributed setup without using a 3rd party Hadoop plugin. Apparently there used to be a plugin for netbeans, but it has been discontinued. I am a newbie with this technology.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "The Apache Hadoop instructions for building and running java programs are via their command line build/run utility only. Getting the yahoo hadoop HDFS tutorial program to build in the IDE wasn't too hard. However, by default it will ignore the local Hadoop configuration and only operate with the local file system in local debug mode.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## Wading through the configuration[\n]"
http-outgoing-3 >> "Hadoop is designed to work with a number of different topologies, directory locations, levels of replication, simulated environments etc. so as we would expect nothing works unless the configuration is right.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "First Hadoop needs to be installed and configured in pseudo distributed mode such that it builds and runs test programs on the command line. The hadoop documentation has instructions for doing this. Documentation is online and also included in the installation: share/doc/hadoop/index.html. However this is not enough to get it to work in the IDE.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## The netbeans project settings that are needed to run with the HDFS from the IDE:[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "1. Get log4j configured to work in the IDE. Absence of log4j configuration won't stop hadoop from running, but we won't get to see useful error messages from hadoop without it.[\n]"
http-outgoing-3 >> "2. HADOOP_HOME environment variable project run (and test) property.[\n]"
http-outgoing-3 >> "3. Duplicate hadoop configuration in the classpath. The above environment variable does not pick up the hadoop configuration from its usual place. Yahoo's only suggestion is to run from the command line via the hadoop script. The Apache HDFS API documention says that configuration is looked for in the classpath, so I took the approach of duplicating the configuration (just 2 files) instead of figuring out how to get it to look in the installation path.[\n]"
http-outgoing-3 >> "4. The correct Maven dependencies. If not all the jar depenencies are there the program may build and run, but it won't talk to the HDFS if it doesn't load the HDFS jars.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "I think that the setup of this project would probably work on Linux too.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## Working through trouble shooting the HDFS project settings[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "Issue 1 above shows up as:[\n]"
http-outgoing-3 >> "<pre><code>[\n]"
http-outgoing-3 >> "log4j:WARN No appenders could be found for logger (org.apache.hadoop.util.Shell).[\n]"
http-outgoing-3 >> "log4j:WARN Please initialize the log4j system properly.[\n]"
http-outgoing-3 >> "log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.[\n]"
http-outgoing-3 >> "</pre></code>[\n]"
http-outgoing-3 >> "This is solved by putting a log4j.properties configuration file in the classpath. For a Maven build getting files into the classpath can be achieved by putting them in src/main/resources. I don't think this is in the classpath, but the build will then copy the file into ./target/classes/ which is in the classpath.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "Issue 2 above shows up as:[\n]"
http-outgoing-3 >> "<pre><code>[\n]"
http-outgoing-3 >> "Failed to detect a valid hadoop home directory[\n]"
http-outgoing-3 >> "java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.[\n]"
http-outgoing-3 >> "</[\r][\n]"
http-outgoing-3 >> "1000[\r][\n]"
http-outgoing-3 >> "code></pre>[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "This is fixed by going into the project properties => Build => Actions => Run Project and adding the environment variable for HADOOP_HOME. This will result in an entry in the Maven POM. Repeat for "Test Project", "Debug Project" etc.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "Issue 3. shows up as running, but creating a file on the local file system instead of the HDFS. This was fixed       looking at the HDFS API documentation for org.apache.hadoop.conf.Configuration. This documentation is under the chapter: C API libhdfs HDFS which has a link to the HDFS API under "The APIs" (I strangely cannot find this in the main index). On my installation the HDFS API documentation link is file:///opt/local/hadoop-2.7.0/share/doc/hadoop/api/org/apache/hadoop/fs/FileSystem.html.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "This documentation told me that hadoop loads core-site.xml and core-default.xml in the classpath. Classpath for a Maven build can be reached by placing these files in the directory src/main/resources (see logging configuration above). I added hdfs-site instead of core-default (which doesn't exist on my 2.7 install) into the src/main/resources project directory.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "Issue 3 shows up as:[\n]"
http-outgoing-3 >> "<pre><code>[\n]"
http-outgoing-3 >> "java.io.IOException: "hadoop No FileSystem for scheme: hdfs".[\n]"
http-outgoing-3 >> "</code></pre>[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "This is part of the build dependency problem. The various threads on stackoverflow etc. suggested that a minimum dependency was the jar for hadoop-core. However, there is no such jar on 2.7. I ran the hadoop command to dump version and got this:[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "<pre><code>[\n]"
http-outgoing-3 >> "bin/hadoop version[\n]"
http-outgoing-3 >> "Hadoop 2.7.0[\n]"
http-outgoing-3 >> "Subversion https://git-wip-us.apache.org/repos/asf/hadoop.git -r d4c8d4d4d203c934e8074b31289a28724c0842cf[\n]"
http-outgoing-3 >> "Compiled by jenkins on 2015-04-10T18:40Z[\n]"
http-outgoing-3 >> "Compiled with protoc 2.5.0[\n]"
http-outgoing-3 >> "From source with checksum a9e90912c37a35c3195d23951fd18f[\n]"
http-outgoing-3 >> "This command was run using /opt/local/hadoop-2.7.0/share/hadoop/common/hadoop-common-2.7.0.jar[\n]"
http-outgoing-3 >> "</code></pre>[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "I noted the jar name at the end and added it as a dependency to the POM. This can either be hand coded in or right click pom.xml => Insert Code => Add Dependency => Search => query hadoop-common and select version which was 2.7.0 [jar] - central. Maven will then add dependencies to other hadoop jars in the "Dependencies" group in the project explorer. Netbeans will then download these dependencies before the next build. They go into ~/.m2/repository should they ever need to be cleaned out (Netbeans doesn't seem to have an IDE remove dependency option).[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "After doing the above project built, but showed up the "no filesystem error". I noticed that Maven had not pulled in any hdfs jars matching the jars in my share/hadoop/hdfs installation directory. So I took a guess that it needed only the top level hadoop-hdfs-2.7.0.jar and added this as a dependency to the POM and all was good :)[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## Working through trouble shooting the Map Reduce project settings[\n]"
http-outgoing-3 >> "After getting the HDFS API working in the IDE it was time to move on to getting the famous Word Count map-reduce tutorial running.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "So coded it, set the main program to the word count main as the one to run. From the IDE: project Properties => Run => Main Class. Provide input and output arguments for the word count program. I noted that the netbeans properties pop-up window does not persist these settings next time it pops up. However this setting is persistant and ends up in nbactions.xml.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "However, running the word count map reduce program resulted in an ioException:[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "<pre><code>[\n]"
http-outgoing-3 >> "Please check your configuration for mapreduce.framework.name and the correspond server addresses.[\n]"
http-outgoing-3 >> "</pre></code>[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "Because the resources directory only contains 2 configuration files from my hadoop installation I thought maybe I was missing a map reduce one. So the first thing I did was go into the configuration directory of my installation and grep all files to see if there was a configuration file with mapreduce framework property. There was not. I checked my programatic configuration dump from my test program. This property was not mentioned either. The only map reduce configuration was to do with some environment variables for heap size in one of the shell scripts. Note to sel[\r][\n]"
http-outgoing-3 >> "c47[\r][\n]"
http-outgoing-3 >> "f: this may be relevant and I can consider setting this in the IDE. However, that didn't look like the problem.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "I then checked my dependencies and noted there were no map reduce jars pulled in by Maven. So I added hadoop-mapreduce-client-core. Still not running. Checked the web and a thread on stackoverflow mentioned a number of other jars: hadoop-mapreduce-client-common and hadoop-mapreduce-client shuffle. I added just the hadoop-mapreduce-client-common and it runs :) I have a feeling that I might need some of the other jars for other API calls and that there must be a better way of working out dependencies than this trial and error. As mentioned I am a newbie with this, so if anyone has any comments feel free to email me.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## Logging from application code[\n]"
http-outgoing-3 >> "Although the hadoop libraries log correctly with a properly located log4.properties file, application code calling the log4j logger seems to ignore this file. Using the log4j logger as per instructions in the log4j manual and many online tutorials did not result in getting any logging redirected to file configured in the properties file. Instead console output only is obtained. A clue to this mystery was that a most basic of hello world netbeans maven projects which did not import any hadoop stuff also failed to log to a file and did not even give the "No appenders" warning. Then I noticed that there were org.sl4j depencies in the hadoop build, so using sl4j instead solved the problem. Once my hello world project used sl4j's LoggerFactory and had sl4j-api and sl4j-12 as a dependencies it started to use the properties file. See http://www.slf4j.org/manual.html[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## Upload a file from local storage to the HDFS via the REST API[\n]"
http-outgoing-3 >> "The WebHDFS REST API documentation which came with the installation specifies that file creation is a two stage operation where an initial PUT to the namenode is sent. This responds with a redirect to the datanode and another PUT should be made to this redirection which can contain the chunked data stream. This does not sound REST to me as it relies on holding redirection state (a fully distributed configuration could presumably return a redirection to any one of the datanodes). Hadoop say this is because of a bug in some HTTP client implementations - incorrect implementation of [0xe2][0x80][0x9c]Expect: 100-continue[0xe2][0x80][0x9d].[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "However, the 2 stage PUT not being REST seems to be a moot point, at least with the Jersey client. I do not get a redirection and a file creates/uploads all in one go.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "Since writing the above paragraph I have implemented the Apache Client back end option to my HDFS Web client interface and this client behaves differently. It does indeed cause a redirect as per Hadoop documentation. The follow up PUT to the redirected location with the chunked file stream works as per documentation.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "Since writing the above paragraph I have implemented a big chunk size setting for the HTTP chunking and this changed the behaviour of the Jersey client to always redirect. It might be that unless the chunk size option is set then the Jersey implementation does not chunk - this would be terrible for big files.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "To be continued ...[\n]"
http-outgoing-3 >> "[\r][\n]"
http-outgoing-3 >> "0[\r][\n]"
http-outgoing-3 >> "[\r][\n]"
http-outgoing-3 << "HTTP/1.1 307 TEMPORARY_REDIRECT[\r][\n]"
http-outgoing-3 << "Cache-Control: no-cache[\r][\n]"
http-outgoing-3 << "Expires: Sun, 14 Jun 2015 00:36:00 GMT[\r][\n]"
http-outgoing-3 << "Date: Sun, 14 Jun 2015 00:36:00 GMT[\r][\n]"
http-outgoing-3 << "Pragma: no-cache[\r][\n]"
http-outgoing-3 << "Expires: Sun, 14 Jun 2015 00:36:00 GMT[\r][\n]"
http-outgoing-3 << "Date: Sun, 14 Jun 2015 00:36:00 GMT[\r][\n]"
http-outgoing-3 << "Pragma: no-cache[\r][\n]"
http-outgoing-3 << "Content-Type: application/octet-stream[\r][\n]"
http-outgoing-3 << "Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434278160206&s=yuHtNR7AFz63r145I5kO1WtkF64="; Path=/; Expires=Sun, 14-Jun-2015 10:36:00 GMT; HttpOnly[\r][\n]"
http-outgoing-3 << "Location: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/README.md?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true[\r][\n]"
http-outgoing-3 << "Content-Length: 0[\r][\n]"
http-outgoing-3 << "Server: Jetty(6.1.26)[\r][\n]"
http-outgoing-3 << "[\r][\n]"
http-outgoing-3 << HTTP/1.1 307 TEMPORARY_REDIRECT
http-outgoing-3 << Cache-Control: no-cache
http-outgoing-3 << Expires: Sun, 14 Jun 2015 00:36:00 GMT
http-outgoing-3 << Date: Sun, 14 Jun 2015 00:36:00 GMT
http-outgoing-3 << Pragma: no-cache
http-outgoing-3 << Expires: Sun, 14 Jun 2015 00:36:00 GMT
http-outgoing-3 << Date: Sun, 14 Jun 2015 00:36:00 GMT
http-outgoing-3 << Pragma: no-cache
http-outgoing-3 << Content-Type: application/octet-stream
http-outgoing-3 << Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434278160206&s=yuHtNR7AFz63r145I5kO1WtkF64="; Path=/; Expires=Sun, 14-Jun-2015 10:36:00 GMT; HttpOnly
http-outgoing-3 << Location: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/README.md?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
http-outgoing-3 << Content-Length: 0
http-outgoing-3 << Server: Jetty(6.1.26)
Connection can be kept alive indefinitely
Cookie accepted [hadoop.auth=""u=michaeljones&p=michaeljones&t=simple&e=1434278160206&s=yuHtNR7AFz63r145I5kO1WtkF64="", version:0, domain:localhost, path:/, expiry:Sun Jun 14 20:36:00 AEST 2015]
Redirect to: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/README.md?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
http-outgoing-3: Shutdown connection
Connection discarded
http-outgoing-3: Close connection
Connection released: [id: 3][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 4][route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://michaels-air.bigpond:50075
Connecting to michaels-air.bigpond/10.0.0.2:50075
Connection established 10.0.0.2:49829<->10.0.0.2:50075
Executing request PUT /webhdfs/v1/user/michaeljones/README.md?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-4 >> PUT /webhdfs/v1/user/michaeljones/README.md?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1
http-outgoing-4 >> Transfer-Encoding: chunked
http-outgoing-4 >> Content-Type: application/octet-stream
http-outgoing-4 >> Host: michaels-air.bigpond:50075
http-outgoing-4 >> Connection: Keep-Alive
http-outgoing-4 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-4 >> Accept-Encoding: gzip,deflate
http-outgoing-4 >> "PUT /webhdfs/v1/user/michaeljones/README.md?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1[\r][\n]"
http-outgoing-4 >> "Transfer-Encoding: chunked[\r][\n]"
http-outgoing-4 >> "Content-Type: application/octet-stream[\r][\n]"
http-outgoing-4 >> "Host: michaels-air.bigpond:50075[\r][\n]"
http-outgoing-4 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-4 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-4 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-4 >> "[\r][\n]"
http-outgoing-4 >> "1000[\r][\n]"
http-outgoing-4 >> "# Hello-Hadoop-netbeans-OS-X[\n]"
http-outgoing-4 >> "Java Maven project for playing with the HDFS API without any 3rd party hadoop plugins.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## Aim of project[\n]"
http-outgoing-4 >> "Hello world/tutorial level for programmatically operating with a pseudo distributed hadoop configuration on OS X. Hadoop 2.7 on Yosemite.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## What this project demonstrates[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "This is work in progress and so far the following functionality is demonstrated:[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "1. Direct programmatic control of the HDFS and running map reduce jobs - all unit tests run from the IDE with hadoop configuration built into this project and under git control.[\n]"
http-outgoing-4 >> "2. Uploading of files to the HDFS by implementing a Web REST API client.[\n]"
http-outgoing-4 >> "3. Async file upload (at time of writing only Jersey back end implemented).[\n]"
http-outgoing-4 >> "4. Layered application code for maximum re-use and ease of test driven development. The client I wrote uses an interface which has allowed me to provide both a Jersey HTTP client implementation and an Apache HTTP client implementation for comparison between the two toolkits.[\n]"
http-outgoing-4 >> "5. Test driven development.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## Getting started[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "The initial difficulty was working out how to run the program in the IDE and talk to the local pseudo distributed setup without using a 3rd party Hadoop plugin. Apparently there used to be a plugin for netbeans, but it has been discontinued. I am a newbie with this technology.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "The Apache Hadoop instructions for building and running java programs are via their command line build/run utility only. Getting the yahoo hadoop HDFS tutorial program to build in the IDE wasn't too hard. However, by default it will ignore the local Hadoop configuration and only operate with the local file system in local debug mode.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## Wading through the configuration[\n]"
http-outgoing-4 >> "Hadoop is designed to work with a number of different topologies, directory locations, levels of replication, simulated environments etc. so as we would expect nothing works unless the configuration is right.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "First Hadoop needs to be installed and configured in pseudo distributed mode such that it builds and runs test programs on the command line. The hadoop documentation has instructions for doing this. Documentation is online and also included in the installation: share/doc/hadoop/index.html. However this is not enough to get it to work in the IDE.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## The netbeans project settings that are needed to run with the HDFS from the IDE:[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "1. Get log4j configured to work in the IDE. Absence of log4j configuration won't stop hadoop from running, but we won't get to see useful error messages from hadoop without it.[\n]"
http-outgoing-4 >> "2. HADOOP_HOME environment variable project run (and test) property.[\n]"
http-outgoing-4 >> "3. Duplicate hadoop configuration in the classpath. The above environment variable does not pick up the hadoop configuration from its usual place. Yahoo's only suggestion is to run from the command line via the hadoop script. The Apache HDFS API documention says that configuration is looked for in the classpath, so I took the approach of duplicating the configuration (just 2 files) instead of figuring out how to get it to look in the installation path.[\n]"
http-outgoing-4 >> "4. The correct Maven dependencies. If not all the jar depenencies are there the program may build and run, but it won't talk to the HDFS if it doesn't load the HDFS jars.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "I think that the setup of this project would probably work on Linux too.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## Working through trouble shooting the HDFS project settings[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "Issue 1 above shows up as:[\n]"
http-outgoing-4 >> "<pre><code>[\n]"
http-outgoing-4 >> "log4j:WARN No appenders could be found for logger (org.apache.hadoop.util.Shell).[\n]"
http-outgoing-4 >> "log4j:WARN Please initialize the log4j system properly.[\n]"
http-outgoing-4 >> "log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.[\n]"
http-outgoing-4 >> "</pre></code>[\n]"
http-outgoing-4 >> "This is solved by putting a log4j.properties configuration file in the classpath. For a Maven build getting files into the classpath can be achieved by putting them in src/main/resources. I don't think this is in the classpath, but the build will then copy the file into ./target/classes/ which is in the classpath.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "Issue 2 above shows up as:[\n]"
http-outgoing-4 >> "<pre><code>[\n]"
http-outgoing-4 >> "Failed to detect a valid hadoop home directory[\n]"
http-outgoing-4 >> "java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.[\n]"
http-outgoing-4 >> "</[\r][\n]"
http-outgoing-4 >> "1000[\r][\n]"
http-outgoing-4 >> "code></pre>[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "This is fixed by going into the project properties => Build => Actions => Run Project and adding the environment variable for HADOOP_HOME. This will result in an entry in the Maven POM. Repeat for "Test Project", "Debug Project" etc.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "Issue 3. shows up as running, but creating a file on the local file system instead of the HDFS. This was fixed       looking at the HDFS API documentation for org.apache.hadoop.conf.Configuration. This documentation is under the chapter: C API libhdfs HDFS which has a link to the HDFS API under "The APIs" (I strangely cannot find this in the main index). On my installation the HDFS API documentation link is file:///opt/local/hadoop-2.7.0/share/doc/hadoop/api/org/apache/hadoop/fs/FileSystem.html.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "This documentation told me that hadoop loads core-site.xml and core-default.xml in the classpath. Classpath for a Maven build can be reached by placing these files in the directory src/main/resources (see logging configuration above). I added hdfs-site instead of core-default (which doesn't exist on my 2.7 install) into the src/main/resources project directory.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "Issue 3 shows up as:[\n]"
http-outgoing-4 >> "<pre><code>[\n]"
http-outgoing-4 >> "java.io.IOException: "hadoop No FileSystem for scheme: hdfs".[\n]"
http-outgoing-4 >> "</code></pre>[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "This is part of the build dependency problem. The various threads on stackoverflow etc. suggested that a minimum dependency was the jar for hadoop-core. However, there is no such jar on 2.7. I ran the hadoop command to dump version and got this:[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "<pre><code>[\n]"
http-outgoing-4 >> "bin/hadoop version[\n]"
http-outgoing-4 >> "Hadoop 2.7.0[\n]"
http-outgoing-4 >> "Subversion https://git-wip-us.apache.org/repos/asf/hadoop.git -r d4c8d4d4d203c934e8074b31289a28724c0842cf[\n]"
http-outgoing-4 >> "Compiled by jenkins on 2015-04-10T18:40Z[\n]"
http-outgoing-4 >> "Compiled with protoc 2.5.0[\n]"
http-outgoing-4 >> "From source with checksum a9e90912c37a35c3195d23951fd18f[\n]"
http-outgoing-4 >> "This command was run using /opt/local/hadoop-2.7.0/share/hadoop/common/hadoop-common-2.7.0.jar[\n]"
http-outgoing-4 >> "</code></pre>[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "I noted the jar name at the end and added it as a dependency to the POM. This can either be hand coded in or right click pom.xml => Insert Code => Add Dependency => Search => query hadoop-common and select version which was 2.7.0 [jar] - central. Maven will then add dependencies to other hadoop jars in the "Dependencies" group in the project explorer. Netbeans will then download these dependencies before the next build. They go into ~/.m2/repository should they ever need to be cleaned out (Netbeans doesn't seem to have an IDE remove dependency option).[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "After doing the above project built, but showed up the "no filesystem error". I noticed that Maven had not pulled in any hdfs jars matching the jars in my share/hadoop/hdfs installation directory. So I took a guess that it needed only the top level hadoop-hdfs-2.7.0.jar and added this as a dependency to the POM and all was good :)[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## Working through trouble shooting the Map Reduce project settings[\n]"
http-outgoing-4 >> "After getting the HDFS API working in the IDE it was time to move on to getting the famous Word Count map-reduce tutorial running.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "So coded it, set the main program to the word count main as the one to run. From the IDE: project Properties => Run => Main Class. Provide input and output arguments for the word count program. I noted that the netbeans properties pop-up window does not persist these settings next time it pops up. However this setting is persistant and ends up in nbactions.xml.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "However, running the word count map reduce program resulted in an ioException:[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "<pre><code>[\n]"
http-outgoing-4 >> "Please check your configuration for mapreduce.framework.name and the correspond server addresses.[\n]"
http-outgoing-4 >> "</pre></code>[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "Because the resources directory only contains 2 configuration files from my hadoop installation I thought maybe I was missing a map reduce one. So the first thing I did was go into the configuration directory of my installation and grep all files to see if there was a configuration file with mapreduce framework property. There was not. I checked my programatic configuration dump from my test program. This property was not mentioned either. The only map reduce configuration was to do with some environment variables for heap size in one of the shell scripts. Note to sel[\r][\n]"
http-outgoing-4 >> "c47[\r][\n]"
http-outgoing-4 >> "f: this may be relevant and I can consider setting this in the IDE. However, that didn't look like the problem.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "I then checked my dependencies and noted there were no map reduce jars pulled in by Maven. So I added hadoop-mapreduce-client-core. Still not running. Checked the web and a thread on stackoverflow mentioned a number of other jars: hadoop-mapreduce-client-common and hadoop-mapreduce-client shuffle. I added just the hadoop-mapreduce-client-common and it runs :) I have a feeling that I might need some of the other jars for other API calls and that there must be a better way of working out dependencies than this trial and error. As mentioned I am a newbie with this, so if anyone has any comments feel free to email me.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## Logging from application code[\n]"
http-outgoing-4 >> "Although the hadoop libraries log correctly with a properly located log4.properties file, application code calling the log4j logger seems to ignore this file. Using the log4j logger as per instructions in the log4j manual and many online tutorials did not result in getting any logging redirected to file configured in the properties file. Instead console output only is obtained. A clue to this mystery was that a most basic of hello world netbeans maven projects which did not import any hadoop stuff also failed to log to a file and did not even give the "No appenders" warning. Then I noticed that there were org.sl4j depencies in the hadoop build, so using sl4j instead solved the problem. Once my hello world project used sl4j's LoggerFactory and had sl4j-api and sl4j-12 as a dependencies it started to use the properties file. See http://www.slf4j.org/manual.html[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## Upload a file from local storage to the HDFS via the REST API[\n]"
http-outgoing-4 >> "The WebHDFS REST API documentation which came with the installation specifies that file creation is a two stage operation where an initial PUT to the namenode is sent. This responds with a redirect to the datanode and another PUT should be made to this redirection which can contain the chunked data stream. This does not sound REST to me as it relies on holding redirection state (a fully distributed configuration could presumably return a redirection to any one of the datanodes). Hadoop say this is because of a bug in some HTTP client implementations - incorrect implementation of [0xe2][0x80][0x9c]Expect: 100-continue[0xe2][0x80][0x9d].[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "However, the 2 stage PUT not being REST seems to be a moot point, at least with the Jersey client. I do not get a redirection and a file creates/uploads all in one go.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "Since writing the above paragraph I have implemented the Apache Client back end option to my HDFS Web client interface and this client behaves differently. It does indeed cause a redirect as per Hadoop documentation. The follow up PUT to the redirected location with the chunked file stream works as per documentation.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "Since writing the above paragraph I have implemented a big chunk size setting for the HTTP chunking and this changed the behaviour of the Jersey client to always redirect. It might be that unless the chunk size option is set then the Jersey implementation does not chunk - this would be terrible for big files.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "To be continued ...[\n]"
http-outgoing-4 >> "[\r][\n]"
http-outgoing-4 >> "0[\r][\n]"
http-outgoing-4 >> "[\r][\n]"
http-outgoing-4 << "HTTP/1.1 100 Continue[\r][\n]"
http-outgoing-4 << "[\r][\n]"
http-outgoing-4 << "HTTP/1.1 201 Created[\r][\n]"
http-outgoing-4 << "Location: hdfs://localhost:9000/user/michaeljones/README.md[\r][\n]"
http-outgoing-4 << "Content-Length: 0[\r][\n]"
http-outgoing-4 << "Connection: close[\r][\n]"
http-outgoing-4 << "[\r][\n]"
http-outgoing-4 << HTTP/1.1 100 Continue
http-outgoing-4 << HTTP/1.1 201 Created
http-outgoing-4 << Location: hdfs://localhost:9000/user/michaeljones/README.md
http-outgoing-4 << Content-Length: 0
http-outgoing-4 << Connection: close
http-outgoing-4: Shutdown connection
Connection discarded
http-outgoing-4: Close connection
Connection released: [id: 4][route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection manager is shutting down
Connection manager shut down
com.sun.jersey.client.property.chunkedEncodingSize: 1048576
Jersey client Redirect to: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/nbactions.xml?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
com.sun.jersey.client.property.chunkedEncodingSize: 1048576
Jersey client Redirect to: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/nbactions.xml?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
Connection manager is shutting down
Connection manager shut down
com.sun.jersey.client.property.chunkedEncodingSize: 1048576
setsid is not available on this machine. So not using it.
setsid exited with exit code 0
field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, about=, sampleName=Ops, type=DEFAULT, value=[Rate of successful kerberos logins and latency (milliseconds)], valueName=Time)
field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, about=, sampleName=Ops, type=DEFAULT, value=[Rate of failed kerberos logins and latency (milliseconds)], valueName=Time)
field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, about=, sampleName=Ops, type=DEFAULT, value=[GetGroups], valueName=Time)
UgiMetrics, User and group related metrics
Kerberos krb5 configuration not found, setting default realm to empty
 Creating new Groups object
Trying to load the custom-built native-hadoop library...
Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
java.library.path=/Applications/NetBeans/NetBeans 8.0.2.app/Contents/Resources/NetBeans/webcommon/bin::/Users/michaeljones/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:.
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Falling back to shell based
Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
hadoop login
hadoop login commit
using local user:UnixPrincipal: michaeljones
Using user: "UnixPrincipal: michaeljones" with name michaeljones
User entry: "michaeljones"
UGI loginUser:michaeljones (auth:SIMPLE)
dfs.client.use.legacy.blockreader.local = false
dfs.client.read.shortcircuit = false
dfs.client.domain.socket.data.traffic = false
dfs.domain.socket.path = 
multipleLinearRandomRetry = null
rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWrapper, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@4bff64c2
getting client out of cache: org.apache.hadoop.ipc.Client@52d645b1
Both short-circuit local reads and UNIX domain socket are disabled.
DataTransferProtocol not using SaslPropertiesResolver, no QOP found in configuration for dfs.data.transfer.protection
The ping interval is 60000 ms.
Connecting to localhost/127.0.0.1:9000
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones: starting, having connections 1
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones sending #0
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones got value #0
Call: getFileInfo took 126ms
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones sending #1
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones got value #1
Call: delete took 13ms
/user/michaeljones/hello.txt: masked=rw-r--r--
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones sending #2
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones got value #2
Call: create took 4ms
computePacketChunkSize: src=/user/michaeljones/hello.txt, chunkSize=516, chunksPerPacket=126, packetSize=65016
Lease renewer daemon for [DFSClient_NONMAPREDUCE_-1796213230_1] with renew id 1 started
DFSClient writeChunk allocating new packet seqno=0, src=/user/michaeljones/hello.txt, packetSize=65016, chunksPerPacket=126, bytesCurBlock=0
Queued packet 0
Queued packet 1
Allocating new block
Waiting for ack for: 1
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones sending #3
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones got value #3
Call: addBlock took 4ms
pipeline = DatanodeInfoWithStorage[127.0.0.1:50010,DS-b42c5705-9ba4-4b14-b00b-f9194bb036f0,DISK]
Connecting to datanode 127.0.0.1:50010
Send buf size 131072
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones sending #4
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones got value #4
Call: getServerDefaults took 1ms
SASL client skipping handshake in unsecured configuration for addr = /127.0.0.1, datanodeId = DatanodeInfoWithStorage[127.0.0.1:50010,DS-b42c5705-9ba4-4b14-b00b-f9194bb036f0,DISK]
DataStreamer block BP-1045030256-10.0.0.2-1433119149314:blk_1073742327_1504 sending packet packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 20
DFSClient seqno: 0 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
DataStreamer block BP-1045030256-10.0.0.2-1433119149314:blk_1073742327_1504 sending packet packet seqno: 1 offsetInBlock: 20 lastPacketInBlock: true lastByteOffsetInBlock: 20
DFSClient seqno: 1 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
Closing old block BP-1045030256-10.0.0.2-1433119149314:blk_1073742327_1504
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones sending #5
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones got value #5
Call: complete took 3ms
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones sending #6
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones got value #6
Call: getBlockLocations took 29ms
newInfo = LocatedBlocks{
  fileLength=20
  underConstruction=false
  blocks=[LocatedBlock{BP-1045030256-10.0.0.2-1433119149314:blk_1073742327_1504; getBlockSize()=20; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-b42c5705-9ba4-4b14-b00b-f9194bb036f0,DISK]]}]
  lastLocatedBlock=LocatedBlock{BP-1045030256-10.0.0.2-1433119149314:blk_1073742327_1504; getBlockSize()=20; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-b42c5705-9ba4-4b14-b00b-f9194bb036f0,DISK]]}
  isLastBlockComplete=true}
Connecting to datanode 127.0.0.1:50010
SASL client skipping handshake in unsecured configuration for addr = /127.0.0.1, datanodeId = DatanodeInfoWithStorage[127.0.0.1:50010,DS-b42c5705-9ba4-4b14-b00b-f9194bb036f0,DISK]
testMain
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones sending #7
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones got value #7
Call: getFileInfo took 3ms
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones sending #8
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones got value #8
Call: delete took 4ms
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.connect(Job.java:1256)
Trying ClientProtocolProvider : org.apache.hadoop.mapred.LocalClientProtocolProvider
session.id is deprecated. Instead, use dfs.metrics.session-id
Initializing JVM Metrics with processName=JobTracker, sessionId=
Picked org.apache.hadoop.mapred.LocalClientProtocolProvider as the ClientProtocolProvider
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Cluster.getFileSystem(Cluster.java:162)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.submit(Job.java:1287)
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones sending #9
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones got value #9
Call: getFileInfo took 2ms
Configuring job job_local1630727290_0001 with file:/tmp/hadoop-michaeljones/mapred/staging/michaeljones1630727290/.staging/job_local1630727290_0001 as the submit dir
adding the following namenodes' delegation tokens:[hdfs://localhost:9000]
Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
default FileSystem: file:///
No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
Creating splits at file:/tmp/hadoop-michaeljones/mapred/staging/michaeljones1630727290/.staging/job_local1630727290_0001
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones sending #10
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones got value #10
Call: getFileInfo took 3ms
Time taken to get FileStatuses: 17
Total input paths to process : 1
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones sending #11
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones got value #11
Call: getBlockLocations took 7ms
Total # of splits generated by getSplits: 1, TimeTaken: 67
number of splits:1
Handling deprecation for all properties in config...
Handling deprecation for mapreduce.jobtracker.address
Handling deprecation for yarn.resourcemanager.scheduler.monitor.policies
Handling deprecation for dfs.namenode.resource.check.interval
Handling deprecation for mapreduce.jobhistory.client.thread-count
Handling deprecation for yarn.app.mapreduce.am.containerlauncher.threadpool-initial-size
Handling deprecation for mapred.child.java.opts
Handling deprecation for mapreduce.jobtracker.retiredjobs.cache.size
Handling deprecation for dfs.client.https.need-auth
Handling deprecation for yarn.admin.acl
Handling deprecation for yarn.app.mapreduce.am.job.committer.cancel-timeout
Handling deprecation for mapreduce.job.emit-timeline-data
Handling deprecation for fs.ftp.host.port
Handling deprecation for dfs.namenode.avoid.read.stale.datanode
Handling deprecation for dfs.journalnode.rpc-address
Handling deprecation for mapreduce.job.end-notification.retry.attempts
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.ttl-interval-ms
Handling deprecation for yarn.resourcemanager.leveldb-state-store.path
Handling deprecation for mapred.mapper.new-api
Handling deprecation for yarn.ipc.rpc.class
Handling deprecation for ipc.client.connection.maxidletime
Handling deprecation for yarn.nodemanager.process-kill-wait.ms
Handling deprecation for mapreduce.cluster.acls.enabled
Handling deprecation for mapreduce.jobtracker.handler.count
Handling deprecation for io.map.index.interval
Handling deprecation for dfs.namenode.https-address
Handling deprecation for mapreduce.task.profile.reduces
Handling deprecation for fs.s3n.multipart.uploads.enabled
Handling deprecation for io.seqfile.sorter.recordlimit
Handling deprecation for mapreduce.job.ubertask.maxmaps
Handling deprecation for mapreduce.tasktracker.tasks.sleeptimebeforesigkill
Handling deprecation for hadoop.util.hash.type
Handling deprecation for dfs.namenode.replication.min
Handling deprecation for yarn.nodemanager.container-manager.thread-count
Handling deprecation for mapreduce.jobtracker.jobhistory.block.size
Handling deprecation for dfs.namenode.fs-limits.min-block-size
Handling deprecation for mapreduce.app-submission.cross-platform
Handling deprecation for fs.AbstractFileSystem.file.impl
Handling deprecation for net.topology.script.number.args
Handling deprecation for yarn.resourcemanager.container-tokens.master-key-rolling-interval-secs
Handling deprecation for mapreduce.map.output.compress.codec
Handling deprecation for mapreduce.job.reducer.preempt.delay.sec
Handling deprecation for s3native.bytes-per-checksum
Handling deprecation for dfs.namenode.path.based.cache.block.map.allocation.percent
Handling deprecation for yarn.nodemanager.windows-container.memory-limit.enabled
Handling deprecation for mapreduce.input.fileinputformat.split.minsize
Handling deprecation for hadoop.security.group.mapping
Handling deprecation for mapreduce.jobtracker.system.dir
Handling deprecation for mapreduce.job.end-notification.max.attempts
Handling deprecation for mapreduce.reduce.markreset.buffer.percent
Handling deprecation for dfs.datanode.cache.revocation.polling.ms
Handling deprecation for mapreduce.reduce.speculative
Handling deprecation for yarn.nodemanager.localizer.cache.cleanup.interval-ms
Handling deprecation for dfs.namenode.lazypersist.file.scrub.interval.sec
Handling deprecation for fs.s3a.threads.core
Handling deprecation for mapreduce.jobhistory.recovery.store.fs.uri
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.start-time-read-cache-size
Handling deprecation for hadoop.registry.zk.retry.interval.ms
Handling deprecation for yarn.nodemanager.keytab
Handling deprecation for dfs.namenode.replication.interval
Handling deprecation for yarn.resourcemanager.admin.address
Handling deprecation for mapreduce.job.maps
Handling deprecation for nfs.dump.dir
Handling deprecation for mapreduce.job.user.name
Handling deprecation for mapreduce.jobtracker.maxtasks.perjob
Handling deprecation for mapreduce.job.ubertask.enable
Handling deprecation for mapreduce.job.reduce.class
Handling deprecation for yarn.nodemanager.delete.debug-delay-sec
Handling deprecation for yarn.timeline-service.ttl-enable
Handling deprecation for yarn.resourcemanager.fs.state-store.retry-policy-spec
Handling deprecation for mapreduce.reduce.skip.maxgroups
Handling deprecation for dfs.client.use.datanode.hostname
Handling deprecation for fs.trash.interval
Handling deprecation for mapreduce.job.name
Handling deprecation for mapreduce.am.max-attempts
Handling deprecation for mapreduce.jobtracker.heartbeats.in.second
Handling deprecation for yarn.resourcemanager.zk-num-retries
Handling deprecation for s3.blocksize
Handling deprecation for dfs.datanode.data.dir
Handling deprecation for mapreduce.jobtracker.persist.jobstatus.active
Handling deprecation for mapreduce.reduce.shuffle.parallelcopies
Handling deprecation for fs.s3.buffer.dir
Handling deprecation for mapreduce.jobhistory.done-dir
Handling deprecation for hadoop.security.instrumentation.requires.admin
Handling deprecation for hadoop.registry.zk.retry.ceiling.ms
Handling deprecation for nfs.rtmax
Handling deprecation for dfs.datanode.data.dir.perm
Handling deprecation for yarn.resourcemanager.container.liveness-monitor.interval-ms
Handling deprecation for yarn.nodemanager.env-whitelist
Handling deprecation for dfs.namenode.backup.address
Handling deprecation for dfs.namenode.xattrs.enabled
Handling deprecation for dfs.datanode.readahead.bytes
Handling deprecation for mapreduce.jobhistory.cleaner.enable
Handling deprecation for dfs.client.block.write.retries
Handling deprecation for mapreduce.tasktracker.http.address
Handling deprecation for yarn.nodemanager.linux-container-executor.cgroups.hierarchy
Handling deprecation for ha.failover-controller.graceful-fence.connection.retries
Handling deprecation for yarn.resourcemanager.recovery.enabled
Handling deprecation for yarn.app.mapreduce.am.container.log.backups
Handling deprecation for dfs.namenode.safemode.threshold-pct
Handling deprecation for yarn.nodemanager.disk-health-checker.interval-ms
Handling deprecation for hadoop.security.java.secure.random.algorithm
Handling deprecation for dfs.namenode.list.cache.directives.num.responses
Handling deprecation for dfs.datanode.dns.nameserver
Handling deprecation for mapreduce.cluster.temp.dir
Handling deprecation for fs.s3a.max.total.tasks
Handling deprecation for mapreduce.reduce.maxattempts
Handling deprecation for mapreduce.client.submit.file.replication
Handling deprecation for mapreduce.shuffle.port
Handling deprecation for yarn.resourcemanager.resource-tracker.client.thread-count
Handling deprecation for dfs.namenode.replication.considerLoad
Handling deprecation for dfs.namenode.edits.journal-plugin.qjournal
Handling deprecation for dfs.client.write.exclude.nodes.cache.expiry.interval.millis
Handling deprecation for yarn.nodemanager.delete.thread-count
Handling deprecation for dfs.client.mmap.cache.timeout.ms
Handling deprecation for yarn.nodemanager.admin-env
Handling deprecation for io.skip.checksum.errors
Handling deprecation for yarn.timeline-service.hostname
Handling deprecation for yarn.resourcemanager.proxy-user-privileges.enabled
Handling deprecation for mapreduce.job.speculative.speculative-cap-total-tasks
Handling deprecation for yarn.acl.enable
Handling deprecation for fs.s3a.fast.upload
Handling deprecation for file.blocksize
Handling deprecation for mapreduce.job.speculative.slowtaskthreshold
Handling deprecation for ftp.replication
Handling deprecation for yarn.sharedcache.cleaner.initial-delay-mins
Handling deprecation for s3native.client-write-packet-size
Handling deprecation for hadoop.rpc.socket.factory.class.default
Handling deprecation for file.bytes-per-checksum
Handling deprecation for dfs.datanode.slow.io.warning.threshold.ms
Handling deprecation for io.seqfile.lazydecompress
Handling deprecation for mapreduce.task.skip.start.attempts
Handling deprecation for dfs.namenode.reject-unresolved-dn-topology-mapping
Handling deprecation for hadoop.common.configuration.version
Handling deprecation for yarn.resourcemanager.client.thread-count
Handling deprecation for dfs.datanode.drop.cache.behind.reads
Handling deprecation for yarn.sharedcache.admin.address
Handling deprecation for mapreduce.job.output.value.class
Handling deprecation for mapreduce.output.fileoutputformat.outputdir
Handling deprecation for mapreduce.jobtracker.taskcache.levels
Handling deprecation for yarn.nodemanager.linux-container-executor.nonsecure-mode.user-pattern
Handling deprecation for yarn.resourcemanager.zk-timeout-ms
Handling deprecation for yarn.resourcemanager.max-completed-applications
Handling deprecation for mapreduce.job.jvm.numtasks
Handling deprecation for yarn.sharedcache.cleaner.period-mins
Handling deprecation for mapreduce.jobtracker.tasktracker.maxblacklists
Handling deprecation for dfs.namenode.top.num.users
Handling deprecation for yarn.nodemanager.linux-container-executor.cgroups.mount
Handling deprecation for yarn.sharedcache.checksum.algo.impl
Handling deprecation for mapreduce.job.end-notification.max.retry.interval
Handling deprecation for mapreduce.job.acl-view-job
Handling deprecation for mapreduce.job.classloader
Handling deprecation for yarn.log-aggregation-enable
Handling deprecation for mapreduce.reduce.shuffle.fetch.retry.interval-ms
Handling deprecation for yarn.resourcemanager.nodemanager.minimum.version
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.size
Handling deprecation for yarn.app.mapreduce.am.job.task.listener.thread-count
Handling deprecation for yarn.app.mapreduce.am.resource.cpu-vcores
Handling deprecation for dfs.namenode.edit.log.autoroll.check.interval.ms
Handling deprecation for mapreduce.output.fileoutputformat.compress.type
Handling deprecation for hadoop.hdfs.configuration.version
Handling deprecation for hadoop.security.group.mapping.ldap.search.attr.member
Handling deprecation for yarn.nodemanager.log.retain-seconds
Handling deprecation for yarn.nodemanager.local-cache.max-files-per-directory
Handling deprecation for mapreduce.job.end-notification.retry.interval
Handling deprecation for hadoop.ssl.client.conf
Handling deprecation for yarn.sharedcache.root-dir
Handling deprecation for dfs.journalnode.https-address
Handling deprecation for mapreduce.reduce.shuffle.fetch.retry.timeout-ms
Handling deprecation for dfs.bytes-per-checksum
Handling deprecation for dfs.namenode.max.objects
Handling deprecation for mapreduce.tasktracker.instrumentation
Handling deprecation for dfs.datanode.max.transfer.threads
Handling deprecation for dfs.block.access.key.update.interval
Handling deprecation for mapreduce.jobtracker.jobhistory.task.numberprogresssplits
Handling deprecation for mapreduce.map.memory.mb
Handling deprecation for ha.failover-controller.new-active.rpc-timeout.ms
Handling deprecation for hadoop.ssl.hostname.verifier
Handling deprecation for dfs.client.read.shortcircuit
Handling deprecation for dfs.datanode.hdfs-blocks-metadata.enabled
Handling deprecation for mapreduce.tasktracker.healthchecker.interval
Handling deprecation for dfs.image.transfer.chunksize
Handling deprecation for mapreduce.tasktracker.taskmemorymanager.monitoringinterval
Handling deprecation for dfs.client.https.keystore.resource
Handling deprecation for yarn.resourcemanager.connect.retry-interval.ms
Handling deprecation for yarn.timeline-service.webapp.address
Handling deprecation for s3native.blocksize
Handling deprecation for yarn.scheduler.minimum-allocation-mb
Handling deprecation for yarn.sharedcache.cleaner.resource-sleep-ms
Handling deprecation for net.topology.impl
Handling deprecation for dfs.client.failover.sleep.base.millis
Handling deprecation for dfs.permissions.superusergroup
Handling deprecation for io.seqfile.compress.blocksize
Handling deprecation for hadoop.registry.zk.retry.times
Handling deprecation for fs.AbstractFileSystem.ftp.impl
Handling deprecation for dfs.namenode.checkpoint.edits.dir
Handling deprecation for mapreduce.job.running.reduce.limit
Handling deprecation for dfs.blockreport.initialDelay
Handling deprecation for dfs.namenode.heartbeat.recheck-interval
Handling deprecation for dfs.namenode.safemode.extension
Handling deprecation for yarn.scheduler.maximum-allocation-mb
Handling deprecation for mapreduce.job.reduce.shuffle.consumer.plugin.class
Handling deprecation for yarn.nodemanager.vmem-check-enabled
Handling deprecation for mapreduce.task.io.sort.factor
Handling deprecation for mapreduce.jobtracker.persist.jobstatus.dir
Handling deprecation for dfs.client.failover.sleep.max.millis
Handling deprecation for dfs.namenode.delegation.key.update-interval
Handling deprecation for hadoop.rpc.protection
Handling deprecation for fs.permissions.umask-mode
Handling deprecation for fs.s3.sleepTimeSeconds
Handling deprecation for ha.health-monitor.rpc-timeout.ms
Handling deprecation for hadoop.http.staticuser.user
Handling deprecation for fs.s3a.connection.maximum
Handling deprecation for yarn.nodemanager.linux-container-executor.nonsecure-mode.limit-users
Handling deprecation for fs.s3a.paging.maximum
Handling deprecation for fs.AbstractFileSystem.viewfs.impl
Handling deprecation for fs.ftp.host
Handling deprecation for yarn.nodemanager.linux-container-executor.nonsecure-mode.local-user
Handling deprecation for fs.s3a.impl
Handling deprecation for hadoop.http.authentication.kerberos.keytab
Handling deprecation for dfs.namenode.fs-limits.max-blocks-per-file
Handling deprecation for mapreduce.tasktracker.http.threads
Handling deprecation for mapreduce.tasktracker.dns.nameserver
Handling deprecation for yarn.resourcemanager.am-rm-tokens.master-key-rolling-interval-secs
Handling deprecation for dfs.client.block.write.replace-datanode-on-failure.enable
Handling deprecation for io.compression.codec.bzip2.library
Handling deprecation for mapreduce.map.skip.maxrecords
Handling deprecation for dfs.client.use.legacy.blockreader.local
Handling deprecation for dfs.namenode.checkpoint.dir
Handling deprecation for dfs.namenode.top.windows.minutes
Handling deprecation for mapreduce.job.maxtaskfailures.per.tracker
Handling deprecation for net.topology.node.switch.mapping.impl
Handling deprecation for mapreduce.shuffle.max.connections
Handling deprecation for mapreduce.jobhistory.loadedjobs.cache.size
Handling deprecation for dfs.storage.policy.enabled
Handling deprecation for yarn.client.application-client-protocol.poll-interval-ms
Handling deprecation for yarn.nodemanager.localizer.address
Handling deprecation for dfs.namenode.list.cache.pools.num.responses
Handling deprecation for nfs.server.port
Handling deprecation for mapreduce.client.output.filter
Handling deprecation for yarn.timeline-service.client.best-effort
Handling deprecation for ha.zookeeper.parent-znode
Handling deprecation for mapreduce.jobtracker.persist.jobstatus.hours
Handling deprecation for yarn.sharedcache.admin.thread-count
Handling deprecation for yarn.nodemanager.resource.cpu-vcores
Handling deprecation for dfs.datanode.block-pinning.enabled
Handling deprecation for mapreduce.jobhistory.http.policy
Handling deprecation for yarn.resourcemanager.webapp.delegation-token-auth-filter.enabled
Handling deprecation for mapreduce.job.speculative.retry-after-no-speculate
Handling deprecation for fs.s3a.attempts.maximum
Handling deprecation for s3native.stream-buffer-size
Handling deprecation for io.seqfile.local.dir
Handling deprecation for yarn.log-aggregation.retain-check-interval-seconds
Handling deprecation for fs.s3n.multipart.copy.block.size
Handling deprecation for dfs.encrypt.data.transfer.cipher.key.bitlength
Handling deprecation for dfs.datanode.sync.behind.writes
Handling deprecation for yarn.resourcemanager.zk-acl
Handling deprecation for hadoop.ssl.keystores.factory.class
Handling deprecation for mapreduce.job.split.metainfo.maxsize
Handling deprecation for fs.s3.maxRetries
Handling deprecation for hadoop.security.random.device.file.path
Handling deprecation for yarn.client.nodemanager-connect.max-wait-ms
Handling deprecation for dfs.namenode.stale.datanode.interval
Handling deprecation for mapreduce.task.io.sort.mb
Handling deprecation for yarn.resourcemanager.zk-state-store.parent-path
Handling deprecation for yarn.app.mapreduce.client-am.ipc.max-retries
Handling deprecation for fs.client.resolve.remote.symlinks
Handling deprecation for yarn.nodemanager.linux-container-executor.cgroups.strict-resource-usage
Handling deprecation for hadoop.ssl.enabled.protocols
Handling deprecation for mapreduce.reduce.cpu.vcores
Handling deprecation for yarn.client.failover-retries
Handling deprecation for mapreduce.jobhistory.address
Handling deprecation for hadoop.ssl.enabled
Handling deprecation for dfs.replication.max
Handling deprecation for dfs.namenode.name.dir
Handling deprecation for dfs.datanode.https.address
Handling deprecation for ipc.client.kill.max
Handling deprecation for mapreduce.job.committer.setup.cleanup.needed
Handling deprecation for dfs.client.domain.socket.data.traffic
Handling deprecation for yarn.nodemanager.localizer.cache.target-size-mb
Handling deprecation for yarn.resourcemanager.admin.client.thread-count
Handling deprecation for dfs.block.access.token.enable
Handling deprecation for mapreduce.job.speculative.retry-after-speculate
Handling deprecation for dfs.datanode.address
Handling deprecation for mapreduce.jobtracker.restart.recover
Handling deprecation for ipc.client.connect.max.retries
Handling deprecation for yarn.timeline-service.store-class
Handling deprecation for dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
Handling deprecation for hadoop.tmp.dir
Handling deprecation for dfs.datanode.handler.count
Handling deprecation for yarn.resourcemanager.ha.automatic-failover.embedded
Handling deprecation for yarn.timeline-service.ttl-ms
Handling deprecation for mapreduce.task.profile.map.params
Handling deprecation for yarn.resourcemanager.nodemanagers.heartbeat-interval-ms
Handling deprecation for mapreduce.map.speculative
Handling deprecation for yarn.timeline-service.recovery.enabled
Handling deprecation for mapreduce.job.map.class
Handling deprecation for dfs.namenode.resource.checked.volumes.minimum
Handling deprecation for yarn.nodemanager.recovery.dir
Handling deprecation for mapreduce.job.counters.max
Handling deprecation for yarn.resourcemanager.keytab
Handling deprecation for dfs.namenode.max.extra.edits.segments.retained
Handling deprecation for dfs.webhdfs.user.provider.user.pattern
Handling deprecation for dfs.client.mmap.enabled
Handling deprecation for mapreduce.map.log.level
Handling deprecation for dfs.client.file-block-storage-locations.timeout.millis
Handling deprecation for yarn.client.max-cached-nodemanagers-proxies
Handling deprecation for yarn.app.mapreduce.am.scheduler.heartbeat.interval-ms
Handling deprecation for hadoop.fuse.timer.period
Handling deprecation for fs.trash.checkpoint.interval
Handling deprecation for yarn.sharedcache.app-checker.class
Handling deprecation for dfs.journalnode.http-address
Handling deprecation for yarn.app.mapreduce.am.staging-dir
Handling deprecation for mapreduce.tasktracker.local.dir.minspacestart
Handling deprecation for yarn.nm.liveness-monitor.expiry-interval-ms
Handling deprecation for ha.health-monitor.check-interval.ms
Handling deprecation for mapreduce.reduce.shuffle.merge.percent
Handling deprecation for dfs.namenode.retrycache.heap.percent
Handling deprecation for yarn.nodemanager.docker-container-executor.exec-name
Handling deprecation for ipc.client.connect.timeout
Handling deprecation for yarn.resourcemanager.fs.state-store.retry-interval-ms
Handling deprecation for mapreduce.output.fileoutputformat.compress
Handling deprecation for yarn.nodemanager.local-dirs
Handling deprecation for yarn.nodemanager.recovery.enabled
Handling deprecation for io.native.lib.available
Handling deprecation for yarn.sharedcache.store.in-memory.staleness-period-mins
Handling deprecation for yarn.resourcemanager.am.max-attempts
Handling deprecation for s3.replication
Handling deprecation for mapreduce.input.fileinputformat.inputdir
Handling deprecation for fs.AbstractFileSystem.har.impl
Handling deprecation for dfs.image.compress
Handling deprecation for mapreduce.job.running.map.limit
Handling deprecation for mapreduce.reduce.input.buffer.percent
Handling deprecation for yarn.nodemanager.webapp.address
Handling deprecation for dfs.datanode.available-space-volume-choosing-policy.balanced-space-preference-fraction
Handling deprecation for dfs.namenode.edit.log.autoroll.multiplier.threshold
Handling deprecation for hadoop.security.group.mapping.ldap.ssl
Handling deprecation for dfs.namenode.checkpoint.check.period
Handling deprecation for fs.defaultFS
Handling deprecation for fs.s3a.multipart.size
Handling deprecation for dfs.client.slow.io.warning.threshold.ms
Handling deprecation for yarn.app.mapreduce.am.job.committer.commit-window
Handling deprecation for hadoop.security.group.mapping.ldap.search.attr.group.name
Handling deprecation for yarn.nodemanager.disk-health-checker.max-disk-utilization-per-disk-percentage
Handling deprecation for yarn.nodemanager.container-monitor.procfs-tree.smaps-based-rss.enabled
Handling deprecation for mapreduce.job.submithostname
Handling deprecation for mapreduce.map.sort.spill.percent
Handling deprecation for hadoop.security.crypto.codec.classes.aes.ctr.nopadding
Handling deprecation for dfs.namenode.http-address
Handling deprecation for hadoop.security.groups.negative-cache.secs
Handling deprecation for hadoop.ssl.server.conf
Handling deprecation for mapreduce.ifile.readahead
Handling deprecation for s3native.replication
Handling deprecation for yarn.client.nodemanager-client-async.thread-pool-max-size
Handling deprecation for mapreduce.jobtracker.staging.root.dir
Handling deprecation for mapreduce.jobhistory.admin.address
Handling deprecation for dfs.namenode.startup.delay.block.deletion.sec
Handling deprecation for yarn.nodemanager.health-checker.interval-ms
Handling deprecation for dfs.namenode.checkpoint.max-retries
Handling deprecation for s3.stream-buffer-size
Handling deprecation for ftp.client-write-packet-size
Handling deprecation for dfs.datanode.fsdatasetcache.max.threads.per.volume
Handling deprecation for mapreduce.output.fileoutputformat.compress.codec
Handling deprecation for yarn.timeline-service.keytab
Handling deprecation for yarn.sharedcache.store.in-memory.initial-delay-mins
Handling deprecation for mapreduce.jobhistory.webapp.address
Handling deprecation for mapreduce.task.userlog.limit.kb
Handling deprecation for mapreduce.reduce.shuffle.fetch.retry.enabled
Handling deprecation for yarn.app.mapreduce.task.container.log.backups
Handling deprecation for dfs.heartbeat.interval
Handling deprecation for ha.zookeeper.session-timeout.ms
Handling deprecation for fs.s3a.connection.ssl.enabled
Handling deprecation for yarn.sharedcache.webapp.address
Handling deprecation for hadoop.http.authentication.signature.secret.file
Handling deprecation for hadoop.fuse.connection.timeout
Handling deprecation for mapreduce.input.fileinputformat.numinputfiles
Handling deprecation for yarn.nodemanager.log-aggregation.compression-type
Handling deprecation for ipc.server.max.connections
Handling deprecation for yarn.resourcemanager.work-preserving-recovery.scheduling-wait-ms
Handling deprecation for yarn.nodemanager.log-dirs
Handling deprecation for yarn.app.mapreduce.am.resource.mb
Handling deprecation for hadoop.security.groups.cache.secs
Handling deprecation for mapreduce.job.speculative.minimum-allowed-tasks
Handling deprecation for yarn.nodemanager.container-monitor.interval-ms
Handling deprecation for dfs.datanode.cache.revocation.timeout.ms
Handling deprecation for mapreduce.jobhistory.recovery.store.class
Handling deprecation for mapreduce.task.combine.progress.records
Handling deprecation for s3.client-write-packet-size
Handling deprecation for mapreduce.jobtracker.instrumentation
Handling deprecation for dfs.replication
Handling deprecation for mapreduce.shuffle.transfer.buffer.size
Handling deprecation for hadoop.security.group.mapping.ldap.directory.search.timeout
Handling deprecation for dfs.datanode.available-space-volume-choosing-policy.balanced-space-threshold
Handling deprecation for hadoop.work.around.non.threadsafe.getpwuid
Handling deprecation for yarn.app.mapreduce.client-am.ipc.max-retries-on-timeouts
Handling deprecation for yarn.nodemanager.address
Handling deprecation for mapreduce.tasktracker.taskcontroller
Handling deprecation for mapreduce.tasktracker.indexcache.mb
Handling deprecation for yarn.scheduler.maximum-allocation-vcores
Handling deprecation for mapreduce.job.reduces
Handling deprecation for yarn.nodemanager.sleep-delay-before-sigkill.ms
Handling deprecation for yarn.timeline-service.address
Handling deprecation for yarn.resourcemanager.configuration.provider-class
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.expiry
Handling deprecation for yarn.sharedcache.enabled
Handling deprecation for tfile.io.chunk.size
Handling deprecation for mapreduce.job.acl-modify-job
Handling deprecation for hadoop.registry.zk.session.timeout.ms
Handling deprecation for fs.automatic.close
Handling deprecation for ha.health-monitor.sleep-after-disconnect.ms
Handling deprecation for mapreduce.tasktracker.reduce.tasks.maximum
Handling deprecation for mapreduce.input.fileinputformat.list-status.num-threads
Handling deprecation for dfs.datanode.directoryscan.threads
Handling deprecation for dfs.datanode.directoryscan.interval
Handling deprecation for dfs.namenode.acls.enabled
Handling deprecation for dfs.client.short.circuit.replica.stale.threshold.ms
Handling deprecation for hadoop.http.authentication.token.validity
Handling deprecation for fs.s3.block.size
Handling deprecation for ha.failover-controller.graceful-fence.rpc-timeout.ms
Handling deprecation for mapreduce.tasktracker.local.dir.minspacekill
Handling deprecation for dfs.namenode.resource.du.reserved
Handling deprecation for mapreduce.jobhistory.cleaner.interval-ms
Handling deprecation for dfs.namenode.datanode.registration.ip-hostname-check
Handling deprecation for mapreduce.jobhistory.intermediate-done-dir
Handling deprecation for mapreduce.jobtracker.http.address
Handling deprecation for dfs.namenode.backup.http-address
Handling deprecation for dfs.namenode.edits.noeditlogchannelflush
Handling deprecation for mapreduce.reduce.shuffle.input.buffer.percent
Handling deprecation for mapreduce.map.maxattempts
Handling deprecation for yarn.http.policy
Handling deprecation for dfs.namenode.audit.loggers
Handling deprecation for hadoop.security.groups.cache.warn.after.ms
Handling deprecation for io.serializations
Handling deprecation for mapreduce.tasktracker.outofband.heartbeat
Handling deprecation for mapreduce.reduce.shuffle.read.timeout
Handling deprecation for hadoop.security.crypto.buffer.size
Handling deprecation for mapreduce.reduce.skip.proc.count.autoincr
Handling deprecation for mapreduce.ifile.readahead.bytes
Handling deprecation for dfs.http.policy
Handling deprecation for hadoop.registry.secure
Handling deprecation for dfs.namenode.safemode.min.datanodes
Handling deprecation for dfs.client.file-block-storage-locations.num-threads
Handling deprecation for mapreduce.cluster.local.dir
Handling deprecation for mapreduce.tasktracker.report.address
Handling deprecation for dfs.namenode.secondary.https-address
Handling deprecation for hadoop.kerberos.kinit.command
Handling deprecation for yarn.timeline-service.http-authentication.type
Handling deprecation for dfs.block.access.token.lifetime
Handling deprecation for dfs.webhdfs.enabled
Handling deprecation for dfs.namenode.delegation.token.max-lifetime
Handling deprecation for dfs.namenode.avoid.write.stale.datanode
Handling deprecation for dfs.datanode.drop.cache.behind.writes
Handling deprecation for yarn.log-aggregation.retain-seconds
Handling deprecation for mapreduce.job.complete.cancel.delegation.tokens
Handling deprecation for mapreduce.local.clientfactory.class.name
Handling deprecation for mapreduce.shuffle.connection-keep-alive.timeout
Handling deprecation for dfs.namenode.num.extra.edits.retained
Handling deprecation for yarn.scheduler.minimum-allocation-vcores
Handling deprecation for ipc.client.connect.max.retries.on.timeouts
Handling deprecation for yarn.timeline-service.client.retry-interval-ms
Handling deprecation for yarn.timeline-service.client.max-retries
Handling deprecation for fs.s3n.block.size
Handling deprecation for mapreduce.job.map.output.collector.class
Handling deprecation for ha.health-monitor.connect-retry-interval.ms
Handling deprecation for mapreduce.shuffle.max.threads
Handling deprecation for nfs.exports.allowed.hosts
Handling deprecation for dfs.client.mmap.cache.size
Handling deprecation for mapreduce.tasktracker.map.tasks.maximum
Handling deprecation for io.file.buffer.size
Handling deprecation for dfs.client.datanode-restart.timeout
Handling deprecation for io.mapfile.bloom.size
Handling deprecation for hadoop.security.kms.client.authentication.retry-count
Handling deprecation for dfs.namenode.checkpoint.txns
Handling deprecation for ipc.client.connect.retry.interval
Handling deprecation for dfs.client-write-packet-size
Handling deprecation for mapreduce.reduce.shuffle.connect.timeout
Handling deprecation for yarn.resourcemanager.fs.state-store.uri
Handling deprecation for fs.swift.impl
Handling deprecation for hadoop.registry.zk.connection.timeout.ms
Handling deprecation for mapred.queue.default.acl-administer-jobs
Handling deprecation for mapreduce.job.submithostaddress
Handling deprecation for dfs.cachereport.intervalMsec
Handling deprecation for yarn.app.mapreduce.shuffle.log.backups
Handling deprecation for yarn.app.mapreduce.am.container.log.limit.kb
Handling deprecation for yarn.nodemanager.resourcemanager.minimum.version
Handling deprecation for ftp.blocksize
Handling deprecation for yarn.resourcemanager.address
Handling deprecation for file.stream-buffer-size
Handling deprecation for yarn.resourcemanager.scheduler.monitor.enable
Handling deprecation for mapreduce.job.ubertask.maxreduces
Handling deprecation for nfs.allow.insecure.ports
Handling deprecation for yarn.sharedcache.nm.uploader.thread-count
Handling deprecation for ipc.client.idlethreshold
Handling deprecation for ftp.stream-buffer-size
Handling deprecation for yarn.sharedcache.client-server.address
Handling deprecation for dfs.client.failover.connection.retries.on.timeouts
Handling deprecation for dfs.namenode.replication.work.multiplier.per.iteration
Handling deprecation for hadoop.http.authentication.simple.anonymous.allowed
Handling deprecation for hadoop.security.authorization
Handling deprecation for yarn.client.nodemanager-connect.retry-interval-ms
Handling deprecation for yarn.am.liveness-monitor.expiry-interval-ms
Handling deprecation for fs.har.impl.disable.cache
Handling deprecation for yarn.nodemanager.linux-container-executor.resources-handler.class
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.read-cache-size
Handling deprecation for hadoop.security.authentication
Handling deprecation for dfs.image.compression.codec
Handling deprecation for mapreduce.task.files.preserve.failedtasks
Handling deprecation for dfs.client.read.shortcircuit.streams.cache.size
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.path
Handling deprecation for mapreduce.job.reduce.slowstart.completedmaps
Handling deprecation for mapreduce.jobhistory.minicluster.fixed.ports
Handling deprecation for file.replication
Handling deprecation for yarn.resourcemanager.ha.automatic-failover.enabled
Handling deprecation for mapreduce.job.userlog.retain.hours
Handling deprecation for mapreduce.jobhistory.joblist.cache.size
Handling deprecation for dfs.namenode.accesstime.precision
Handling deprecation for yarn.resourcemanager.work-preserving-recovery.enabled
Handling deprecation for dfs.namenode.fs-limits.max-xattrs-per-inode
Handling deprecation for io.mapfile.bloom.error.rate
Handling deprecation for yarn.resourcemanager.store.class
Handling deprecation for dfs.image.transfer.timeout
Handling deprecation for yarn.timeline-service.leveldb-state-store.path
Handling deprecation for nfs.wtmax
Handling deprecation for mapreduce.job.combine.class
Handling deprecation for dfs.namenode.support.allow.format
Handling deprecation for fs.s3a.multipart.purge
Handling deprecation for dfs.secondary.namenode.kerberos.internal.spnego.principal
Handling deprecation for fs.s3a.connection.establish.timeout
Handling deprecation for dfs.stream-buffer-size
Handling deprecation for dfs.namenode.invalidate.work.pct.per.iteration
Handling deprecation for yarn.nodemanager.container-executor.class
Handling deprecation for fs.s3a.multipart.purge.age
Handling deprecation for yarn.resourcemanager.scheduler.client.thread-count
Handling deprecation for dfs.namenode.top.enabled
Handling deprecation for yarn.app.mapreduce.shuffle.log.separate
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.low-watermark
Handling deprecation for fs.s3a.fast.buffer.size
Handling deprecation for hadoop.user.group.static.mapping.overrides
Handling deprecation for tfile.fs.input.buffer.size
Handling deprecation for dfs.client.cached.conn.retry
Handling deprecation for hadoop.http.authentication.type
Handling deprecation for dfs.namenode.list.encryption.zones.num.responses
Handling deprecation for mapreduce.map.cpu.vcores
Handling deprecation for dfs.namenode.path.based.cache.refresh.interval.ms
Handling deprecation for dfs.namenode.decommission.interval
Handling deprecation for dfs.namenode.fs-limits.max-directory-items
Handling deprecation for yarn.resourcemanager.zk-retry-interval-ms
Handling deprecation for ftp.bytes-per-checksum
Handling deprecation for dfs.ha.log-roll.period
Handling deprecation for dfs.user.home.dir.prefix
Handling deprecation for ipc.client.fallback-to-simple-auth-allowed
Handling deprecation for yarn.nodemanager.pmem-check-enabled
Handling deprecation for yarn.nodemanager.remote-app-log-dir
Handling deprecation for dfs.namenode.inotify.max.events.per.rpc
Handling deprecation for mapreduce.task.profile.maps
Handling deprecation for mapreduce.shuffle.ssl.file.buffer.size
Handling deprecation for mapreduce.tasktracker.healthchecker.script.timeout
Handling deprecation for yarn.timeline-service.webapp.https.address
Handling deprecation for yarn.nodemanager.resource.percentage-physical-cpu-limit
Handling deprecation for yarn.app.mapreduce.am.command-opts
Handling deprecation for dfs.namenode.fs-limits.max-xattr-size
Handling deprecation for dfs.datanode.http.address
Handling deprecation for dfs.namenode.blocks.per.postponedblocks.rescan
Handling deprecation for yarn.sharedcache.nm.uploader.replication.factor
Handling deprecation for hadoop.registry.zk.root
Handling deprecation for hadoop.jetty.logs.serve.aliases
Handling deprecation for yarn.client.failover-proxy-provider
Handling deprecation for mapreduce.jobhistory.admin.acl
Handling deprecation for yarn.app.mapreduce.am.hard-kill-timeout-ms
Handling deprecation for yarn.nodemanager.remote-app-log-dir-suffix
Handling deprecation for mapreduce.jobhistory.principal
Handling deprecation for yarn.resourcemanager.webapp.address
Handling deprecation for mapreduce.jobhistory.recovery.enable
Handling deprecation for yarn.sharedcache.store.in-memory.check-period-mins
Handling deprecation for nfs.mountd.port
Handling deprecation for mapreduce.reduce.merge.inmem.threshold
Handling deprecation for fs.df.interval
Handling deprecation for yarn.timeline-service.enabled
Handling deprecation for mapreduce.jobtracker.jobhistory.lru.cache.size
Handling deprecation for mapreduce.task.profile
Handling deprecation for mapreduce.job.output.key.class
Handling deprecation for yarn.nodemanager.hostname
Handling deprecation for dfs.namenode.num.checkpoints.retained
Handling deprecation for mapreduce.job.queuename
Handling deprecation for mapreduce.jobhistory.max-age-ms
Handling deprecation for mapreduce.job.token.tracking.ids.enabled
Handling deprecation for yarn.nodemanager.localizer.client.thread-count
Handling deprecation for yarn.sharedcache.uploader.server.thread-count
Handling deprecation for dfs.client.mmap.retry.timeout.ms
Handling deprecation for mapreduce.jobhistory.move.thread-count
Handling deprecation for dfs.permissions.enabled
Handling deprecation for dfs.blockreport.split.threshold
Handling deprecation for fs.AbstractFileSystem.hdfs.impl
Handling deprecation for dfs.datanode.balance.bandwidthPerSec
Handling deprecation for dfs.block.scanner.volume.bytes.per.second
Handling deprecation for hadoop.http.filter.initializers
Handling deprecation for yarn.timeline-service.http-authentication.simple.anonymous.allowed
Handling deprecation for dfs.default.chunk.view.size
Handling deprecation for yarn.sharedcache.client-server.thread-count
Handling deprecation for yarn.resourcemanager.resource-tracker.address
Handling deprecation for mapreduce.job.working.dir
Handling deprecation for mapreduce.jobhistory.datestring.cache.size
Handling deprecation for mapreduce.task.profile.params
Handling deprecation for dfs.namenode.decommission.blocks.per.interval
Handling deprecation for dfs.namenode.handler.count
Handling deprecation for dfs.image.transfer.bandwidthPerSec
Handling deprecation for rpc.metrics.quantile.enable
Handling deprecation for mapreduce.jobtracker.expire.trackers.interval
Handling deprecation for mapreduce.task.timeout
Handling deprecation for yarn.app.mapreduce.client.max-retries
Handling deprecation for yarn.nodemanager.resource.memory-mb
Handling deprecation for yarn.nodemanager.disk-health-checker.min-healthy-disks
Handling deprecation for dfs.datanode.failed.volumes.tolerated
Handling deprecation for yarn.timeline-service.handler-thread-count
Handling deprecation for ipc.server.listen.queue.size
Handling deprecation for fs.s3a.threads.max
Handling deprecation for yarn.resourcemanager.connect.max-wait.ms
Handling deprecation for mapreduce.fileoutputcommitter.algorithm.version
Handling deprecation for mapreduce.framework.name
Handling deprecation for mapreduce.map.skip.proc.count.autoincr
Handling deprecation for mapreduce.job.max.split.locations
Handling deprecation for yarn.resourcemanager.scheduler.class
Handling deprecation for yarn.resourcemanager.system-metrics-publisher.enabled
Handling deprecation for dfs.blocksize
Handling deprecation for yarn.sharedcache.nested-level
Handling deprecation for mapreduce.shuffle.connection-keep-alive.enable
Handling deprecation for fs.s3a.threads.keepalivetime
Handling deprecation for fs.s3a.connection.timeout
Handling deprecation for file.client-write-packet-size
Handling deprecation for ha.failover-controller.cli-check.rpc-timeout.ms
Handling deprecation for ha.zookeeper.acl
Handling deprecation for dfs.namenode.write.stale.datanode.ratio
Handling deprecation for dfs.encrypt.data.transfer
Handling deprecation for dfs.datanode.shared.file.descriptor.paths
Handling deprecation for mapreduce.input.lineinputformat.linespermap
Handling deprecation for yarn.resourcemanager.delayed.delegation-token.removal-interval-ms
Handling deprecation for yarn.nodemanager.localizer.fetch.thread-count
Handling deprecation for dfs.client.failover.max.attempts
Handling deprecation for yarn.resourcemanager.scheduler.address
Handling deprecation for dfs.client.read.shortcircuit.streams.cache.expiry.ms
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.start-time-write-cache-size
Handling deprecation for yarn.nodemanager.health-checker.script.timeout-ms
Handling deprecation for yarn.resourcemanager.fs.state-store.num-retries
Handling deprecation for hadoop.ssl.require.client.cert
Handling deprecation for hadoop.security.uid.cache.secs
Handling deprecation for mapreduce.jobhistory.keytab
Handling deprecation for dfs.client.read.shortcircuit.skip.checksum
Handling deprecation for yarn.resourcemanager.ha.automatic-failover.zk-base-path
Handling deprecation for mapreduce.shuffle.ssl.enabled
Handling deprecation for mapreduce.reduce.log.level
Handling deprecation for hadoop.registry.rm.enabled
Handling deprecation for mapreduce.tasktracker.dns.interface
Handling deprecation for yarn.resourcemanager.system-metrics-publisher.dispatcher.pool-size
Handling deprecation for mapreduce.job.speculative.speculative-cap-running-tasks
Handling deprecation for dfs.datanode.block.id.layout.upgrade.threads
Handling deprecation for dfs.datanode.use.datanode.hostname
Handling deprecation for dfs.client.context
Handling deprecation for yarn.resourcemanager.ha.enabled
Handling deprecation for mapred.reducer.new-api
Handling deprecation for dfs.namenode.delegation.token.renew-interval
Handling deprecation for dfs.blockreport.intervalMsec
Handling deprecation for fs.s3a.multipart.threshold
Handling deprecation for mapreduce.reduce.shuffle.memory.limit.percent
Handling deprecation for dfs.https.server.keystore.resource
Handling deprecation for io.map.index.skip
Handling deprecation for mapreduce.job.hdfs-servers
Handling deprecation for mapreduce.jobtracker.taskscheduler
Handling deprecation for dfs.namenode.kerberos.internal.spnego.principal
Handling deprecation for yarn.resourcemanager.state-store.max-completed-applications
Handling deprecation for mapreduce.map.output.compress
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.num.refill.threads
Handling deprecation for fs.s3n.multipart.uploads.block.size
Handling deprecation for mapreduce.task.merge.progress.records
Handling deprecation for dfs.datanode.dns.interface
Handling deprecation for map.sort.class
Handling deprecation for yarn.nodemanager.aux-services.mapreduce_shuffle.class
Handling deprecation for tfile.fs.output.buffer.size
Handling deprecation for fs.du.interval
Handling deprecation for dfs.client.failover.connection.retries
Handling deprecation for dfs.namenode.top.window.num.buckets
Handling deprecation for mapreduce.job.dir
Handling deprecation for fs.s3a.buffer.dir
Handling deprecation for mapreduce.reduce.shuffle.retry-delay.max.ms
Handling deprecation for yarn.sharedcache.uploader.server.address
Handling deprecation for mapreduce.client.progressmonitor.pollinterval
Handling deprecation for yarn.app.mapreduce.shuffle.log.limit.kb
Handling deprecation for dfs.datanode.max.locked.memory
Handling deprecation for dfs.namenode.retrycache.expirytime.millis
Handling deprecation for dfs.datanode.scan.period.hours
Handling deprecation for dfs.client.block.write.replace-datanode-on-failure.best-effort
Handling deprecation for mapreduce.jobhistory.move.interval-ms
Handling deprecation for dfs.ha.fencing.ssh.connect-timeout
Handling deprecation for yarn.nodemanager.log-aggregation.roll-monitoring-interval-seconds
Handling deprecation for dfs.namenode.fs-limits.max-component-length
Handling deprecation for hadoop.registry.zk.quorum
Handling deprecation for dfs.namenode.enable.retrycache
Handling deprecation for dfs.datanode.du.reserved
Handling deprecation for yarn.timeline-service.state-store-class
Handling deprecation for dfs.datanode.ipc.address
Handling deprecation for hadoop.registry.system.acls
Handling deprecation for dfs.client.block.write.replace-datanode-on-failure.policy
Handling deprecation for dfs.namenode.path.based.cache.retry.interval.ms
Handling deprecation for hadoop.security.crypto.cipher.suite
Handling deprecation for dfs.ha.tail-edits.period
Handling deprecation for mapreduce.task.profile.reduce.params
Handling deprecation for hadoop.registry.jaas.context
Handling deprecation for yarn.resourcemanager.hostname
Handling deprecation for mapreduce.reduce.memory.mb
Handling deprecation for hadoop.security.group.mapping.ldap.search.filter.group
Handling deprecation for hadoop.http.authentication.kerberos.principal
Handling deprecation for hadoop.security.group.mapping.ldap.search.filter.user
Handling deprecation for yarn.nodemanager.disk-health-checker.min-free-space-per-disk-mb
Handling deprecation for dfs.namenode.edits.dir
Handling deprecation for yarn.client.failover-retries-on-socket-timeouts
Handling deprecation for dfs.namenode.decommission.max.concurrent.tracked.nodes
Handling deprecation for mapreduce.client.completion.pollinterval
Handling deprecation for dfs.namenode.name.dir.restore
Handling deprecation for dfs.namenode.secondary.http-address
Handling deprecation for mapreduce.jobhistory.recovery.store.leveldb.path
Handling deprecation for yarn.sharedcache.store.class
Handling deprecation for s3.bytes-per-checksum
Handling deprecation for yarn.nodemanager.windows-container.cpu-limit.enabled
Handling deprecation for yarn.resourcemanager.webapp.https.address
Handling deprecation for yarn.nodemanager.vmem-pmem-ratio
Handling deprecation for dfs.namenode.checkpoint.period
Handling deprecation for dfs.ha.automatic-failover.enabled
Submitting tokens for job: job_local1630727290_0001
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.fs.FileContext.getAbstractFileSystem(FileContext.java:331)
Handling deprecation for all properties in config...
Handling deprecation for mapreduce.jobtracker.address
Handling deprecation for yarn.resourcemanager.scheduler.monitor.policies
Handling deprecation for dfs.namenode.resource.check.interval
Handling deprecation for mapreduce.jobhistory.client.thread-count
Handling deprecation for yarn.app.mapreduce.am.containerlauncher.threadpool-initial-size
Handling deprecation for mapred.child.java.opts
Handling deprecation for mapreduce.jobtracker.retiredjobs.cache.size
Handling deprecation for dfs.client.https.need-auth
Handling deprecation for yarn.admin.acl
Handling deprecation for yarn.app.mapreduce.am.job.committer.cancel-timeout
Handling deprecation for mapreduce.job.emit-timeline-data
Handling deprecation for fs.ftp.host.port
Handling deprecation for dfs.namenode.avoid.read.stale.datanode
Handling deprecation for dfs.journalnode.rpc-address
Handling deprecation for mapreduce.job.end-notification.retry.attempts
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.ttl-interval-ms
Handling deprecation for yarn.resourcemanager.leveldb-state-store.path
Handling deprecation for mapred.mapper.new-api
Handling deprecation for yarn.ipc.rpc.class
Handling deprecation for ipc.client.connection.maxidletime
Handling deprecation for yarn.nodemanager.process-kill-wait.ms
Handling deprecation for mapreduce.cluster.acls.enabled
Handling deprecation for mapreduce.jobtracker.handler.count
Handling deprecation for io.map.index.interval
Handling deprecation for dfs.namenode.https-address
Handling deprecation for mapreduce.task.profile.reduces
Handling deprecation for fs.s3n.multipart.uploads.enabled
Handling deprecation for io.seqfile.sorter.recordlimit
Handling deprecation for mapreduce.job.ubertask.maxmaps
Handling deprecation for mapreduce.tasktracker.tasks.sleeptimebeforesigkill
Handling deprecation for hadoop.util.hash.type
Handling deprecation for dfs.namenode.replication.min
Handling deprecation for yarn.nodemanager.container-manager.thread-count
Handling deprecation for mapreduce.jobtracker.jobhistory.block.size
Handling deprecation for dfs.namenode.fs-limits.min-block-size
Handling deprecation for mapreduce.app-submission.cross-platform
Handling deprecation for fs.AbstractFileSystem.file.impl
Handling deprecation for net.topology.script.number.args
Handling deprecation for yarn.resourcemanager.container-tokens.master-key-rolling-interval-secs
Handling deprecation for mapreduce.map.output.compress.codec
Handling deprecation for mapreduce.job.reducer.preempt.delay.sec
Handling deprecation for s3native.bytes-per-checksum
Handling deprecation for dfs.namenode.path.based.cache.block.map.allocation.percent
Handling deprecation for yarn.nodemanager.windows-container.memory-limit.enabled
Handling deprecation for mapreduce.input.fileinputformat.split.minsize
Handling deprecation for hadoop.security.group.mapping
Handling deprecation for mapreduce.jobtracker.system.dir
Handling deprecation for mapreduce.job.end-notification.max.attempts
Handling deprecation for mapreduce.reduce.markreset.buffer.percent
Handling deprecation for dfs.datanode.cache.revocation.polling.ms
Handling deprecation for mapreduce.reduce.speculative
Handling deprecation for yarn.nodemanager.localizer.cache.cleanup.interval-ms
Handling deprecation for dfs.namenode.lazypersist.file.scrub.interval.sec
Handling deprecation for fs.s3a.threads.core
Handling deprecation for mapreduce.jobhistory.recovery.store.fs.uri
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.start-time-read-cache-size
Handling deprecation for hadoop.registry.zk.retry.interval.ms
Handling deprecation for yarn.nodemanager.keytab
Handling deprecation for dfs.namenode.replication.interval
Handling deprecation for yarn.resourcemanager.admin.address
Handling deprecation for mapreduce.job.maps
Handling deprecation for nfs.dump.dir
Handling deprecation for mapreduce.job.user.name
Handling deprecation for mapreduce.jobtracker.maxtasks.perjob
Handling deprecation for mapreduce.job.ubertask.enable
Handling deprecation for mapreduce.job.reduce.class
Handling deprecation for yarn.nodemanager.delete.debug-delay-sec
Handling deprecation for yarn.timeline-service.ttl-enable
Handling deprecation for yarn.resourcemanager.fs.state-store.retry-policy-spec
Handling deprecation for mapreduce.reduce.skip.maxgroups
Handling deprecation for dfs.client.use.datanode.hostname
Handling deprecation for fs.trash.interval
Handling deprecation for mapreduce.job.name
Handling deprecation for mapreduce.am.max-attempts
Handling deprecation for mapreduce.jobtracker.heartbeats.in.second
Handling deprecation for yarn.resourcemanager.zk-num-retries
Handling deprecation for s3.blocksize
Handling deprecation for dfs.datanode.data.dir
Handling deprecation for mapreduce.jobtracker.persist.jobstatus.active
Handling deprecation for mapreduce.reduce.shuffle.parallelcopies
Handling deprecation for fs.s3.buffer.dir
Handling deprecation for mapreduce.jobhistory.done-dir
Handling deprecation for hadoop.security.instrumentation.requires.admin
Handling deprecation for hadoop.registry.zk.retry.ceiling.ms
Handling deprecation for nfs.rtmax
Handling deprecation for dfs.datanode.data.dir.perm
Handling deprecation for yarn.resourcemanager.container.liveness-monitor.interval-ms
Handling deprecation for yarn.nodemanager.env-whitelist
Handling deprecation for dfs.namenode.backup.address
Handling deprecation for dfs.namenode.xattrs.enabled
Handling deprecation for dfs.datanode.readahead.bytes
Handling deprecation for mapreduce.jobhistory.cleaner.enable
Handling deprecation for dfs.client.block.write.retries
Handling deprecation for mapreduce.tasktracker.http.address
Handling deprecation for yarn.nodemanager.linux-container-executor.cgroups.hierarchy
Handling deprecation for ha.failover-controller.graceful-fence.connection.retries
Handling deprecation for yarn.resourcemanager.recovery.enabled
Handling deprecation for yarn.app.mapreduce.am.container.log.backups
Handling deprecation for dfs.namenode.safemode.threshold-pct
Handling deprecation for yarn.nodemanager.disk-health-checker.interval-ms
Handling deprecation for hadoop.security.java.secure.random.algorithm
Handling deprecation for dfs.namenode.list.cache.directives.num.responses
Handling deprecation for dfs.datanode.dns.nameserver
Handling deprecation for mapreduce.cluster.temp.dir
Handling deprecation for fs.s3a.max.total.tasks
Handling deprecation for mapreduce.reduce.maxattempts
Handling deprecation for mapreduce.client.submit.file.replication
Handling deprecation for mapreduce.shuffle.port
Handling deprecation for yarn.resourcemanager.resource-tracker.client.thread-count
Handling deprecation for dfs.namenode.replication.considerLoad
Handling deprecation for dfs.namenode.edits.journal-plugin.qjournal
Handling deprecation for dfs.client.write.exclude.nodes.cache.expiry.interval.millis
Handling deprecation for yarn.nodemanager.delete.thread-count
Handling deprecation for dfs.client.mmap.cache.timeout.ms
Handling deprecation for yarn.nodemanager.admin-env
Handling deprecation for io.skip.checksum.errors
Handling deprecation for yarn.timeline-service.hostname
Handling deprecation for yarn.resourcemanager.proxy-user-privileges.enabled
Handling deprecation for mapreduce.job.speculative.speculative-cap-total-tasks
Handling deprecation for yarn.acl.enable
Handling deprecation for fs.s3a.fast.upload
Handling deprecation for file.blocksize
Handling deprecation for mapreduce.job.speculative.slowtaskthreshold
Handling deprecation for ftp.replication
Handling deprecation for yarn.sharedcache.cleaner.initial-delay-mins
Handling deprecation for s3native.client-write-packet-size
Handling deprecation for hadoop.rpc.socket.factory.class.default
Handling deprecation for file.bytes-per-checksum
Handling deprecation for dfs.datanode.slow.io.warning.threshold.ms
Handling deprecation for io.seqfile.lazydecompress
Handling deprecation for mapreduce.task.skip.start.attempts
Handling deprecation for dfs.namenode.reject-unresolved-dn-topology-mapping
Handling deprecation for hadoop.common.configuration.version
Handling deprecation for yarn.resourcemanager.client.thread-count
Handling deprecation for dfs.datanode.drop.cache.behind.reads
Handling deprecation for yarn.sharedcache.admin.address
Handling deprecation for mapreduce.job.output.value.class
Handling deprecation for mapreduce.output.fileoutputformat.outputdir
Handling deprecation for mapreduce.jobtracker.taskcache.levels
Handling deprecation for yarn.nodemanager.linux-container-executor.nonsecure-mode.user-pattern
Handling deprecation for yarn.resourcemanager.zk-timeout-ms
Handling deprecation for yarn.resourcemanager.max-completed-applications
Handling deprecation for mapreduce.job.jvm.numtasks
Handling deprecation for yarn.sharedcache.cleaner.period-mins
Handling deprecation for mapreduce.jobtracker.tasktracker.maxblacklists
Handling deprecation for dfs.namenode.top.num.users
Handling deprecation for yarn.nodemanager.linux-container-executor.cgroups.mount
Handling deprecation for yarn.sharedcache.checksum.algo.impl
Handling deprecation for mapreduce.job.end-notification.max.retry.interval
Handling deprecation for mapreduce.job.acl-view-job
Handling deprecation for mapreduce.job.classloader
Handling deprecation for yarn.log-aggregation-enable
Handling deprecation for mapreduce.reduce.shuffle.fetch.retry.interval-ms
Handling deprecation for yarn.resourcemanager.nodemanager.minimum.version
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.size
Handling deprecation for yarn.app.mapreduce.am.job.task.listener.thread-count
Handling deprecation for yarn.app.mapreduce.am.resource.cpu-vcores
Handling deprecation for dfs.namenode.edit.log.autoroll.check.interval.ms
Handling deprecation for mapreduce.output.fileoutputformat.compress.type
Handling deprecation for hadoop.hdfs.configuration.version
Handling deprecation for hadoop.security.group.mapping.ldap.search.attr.member
Handling deprecation for yarn.nodemanager.log.retain-seconds
Handling deprecation for yarn.nodemanager.local-cache.max-files-per-directory
Handling deprecation for mapreduce.job.end-notification.retry.interval
Handling deprecation for hadoop.ssl.client.conf
Handling deprecation for yarn.sharedcache.root-dir
Handling deprecation for dfs.journalnode.https-address
Handling deprecation for mapreduce.reduce.shuffle.fetch.retry.timeout-ms
Handling deprecation for dfs.bytes-per-checksum
Handling deprecation for dfs.namenode.max.objects
Handling deprecation for mapreduce.tasktracker.instrumentation
Handling deprecation for dfs.datanode.max.transfer.threads
Handling deprecation for dfs.block.access.key.update.interval
Handling deprecation for mapreduce.jobtracker.jobhistory.task.numberprogresssplits
Handling deprecation for mapreduce.map.memory.mb
Handling deprecation for ha.failover-controller.new-active.rpc-timeout.ms
Handling deprecation for hadoop.ssl.hostname.verifier
Handling deprecation for dfs.client.read.shortcircuit
Handling deprecation for dfs.datanode.hdfs-blocks-metadata.enabled
Handling deprecation for mapreduce.tasktracker.healthchecker.interval
Handling deprecation for dfs.image.transfer.chunksize
Handling deprecation for mapreduce.tasktracker.taskmemorymanager.monitoringinterval
Handling deprecation for dfs.client.https.keystore.resource
Handling deprecation for yarn.resourcemanager.connect.retry-interval.ms
Handling deprecation for yarn.timeline-service.webapp.address
Handling deprecation for s3native.blocksize
Handling deprecation for yarn.scheduler.minimum-allocation-mb
Handling deprecation for yarn.sharedcache.cleaner.resource-sleep-ms
Handling deprecation for net.topology.impl
Handling deprecation for dfs.client.failover.sleep.base.millis
Handling deprecation for dfs.permissions.superusergroup
Handling deprecation for io.seqfile.compress.blocksize
Handling deprecation for hadoop.registry.zk.retry.times
Handling deprecation for fs.AbstractFileSystem.ftp.impl
Handling deprecation for dfs.namenode.checkpoint.edits.dir
Handling deprecation for mapreduce.job.running.reduce.limit
Handling deprecation for dfs.blockreport.initialDelay
Handling deprecation for dfs.namenode.heartbeat.recheck-interval
Handling deprecation for dfs.namenode.safemode.extension
Handling deprecation for yarn.scheduler.maximum-allocation-mb
Handling deprecation for mapreduce.job.reduce.shuffle.consumer.plugin.class
Handling deprecation for yarn.nodemanager.vmem-check-enabled
Handling deprecation for mapreduce.task.io.sort.factor
Handling deprecation for mapreduce.jobtracker.persist.jobstatus.dir
Handling deprecation for dfs.client.failover.sleep.max.millis
Handling deprecation for dfs.namenode.delegation.key.update-interval
Handling deprecation for hadoop.rpc.protection
Handling deprecation for fs.permissions.umask-mode
Handling deprecation for fs.s3.sleepTimeSeconds
Handling deprecation for ha.health-monitor.rpc-timeout.ms
Handling deprecation for hadoop.http.staticuser.user
Handling deprecation for fs.s3a.connection.maximum
Handling deprecation for yarn.nodemanager.linux-container-executor.nonsecure-mode.limit-users
Handling deprecation for fs.s3a.paging.maximum
Handling deprecation for fs.AbstractFileSystem.viewfs.impl
Handling deprecation for fs.ftp.host
Handling deprecation for yarn.nodemanager.linux-container-executor.nonsecure-mode.local-user
Handling deprecation for fs.s3a.impl
Handling deprecation for hadoop.http.authentication.kerberos.keytab
Handling deprecation for dfs.namenode.fs-limits.max-blocks-per-file
Handling deprecation for mapreduce.tasktracker.http.threads
Handling deprecation for mapreduce.tasktracker.dns.nameserver
Handling deprecation for yarn.resourcemanager.am-rm-tokens.master-key-rolling-interval-secs
Handling deprecation for dfs.client.block.write.replace-datanode-on-failure.enable
Handling deprecation for io.compression.codec.bzip2.library
Handling deprecation for mapreduce.map.skip.maxrecords
Handling deprecation for dfs.client.use.legacy.blockreader.local
Handling deprecation for dfs.namenode.checkpoint.dir
Handling deprecation for dfs.namenode.top.windows.minutes
Handling deprecation for mapreduce.job.maxtaskfailures.per.tracker
Handling deprecation for net.topology.node.switch.mapping.impl
Handling deprecation for mapreduce.shuffle.max.connections
Handling deprecation for mapreduce.jobhistory.loadedjobs.cache.size
Handling deprecation for dfs.storage.policy.enabled
Handling deprecation for yarn.client.application-client-protocol.poll-interval-ms
Handling deprecation for yarn.nodemanager.localizer.address
Handling deprecation for dfs.namenode.list.cache.pools.num.responses
Handling deprecation for nfs.server.port
Handling deprecation for mapreduce.client.output.filter
Handling deprecation for yarn.timeline-service.client.best-effort
Handling deprecation for ha.zookeeper.parent-znode
Handling deprecation for mapreduce.jobtracker.persist.jobstatus.hours
Handling deprecation for yarn.sharedcache.admin.thread-count
Handling deprecation for yarn.nodemanager.resource.cpu-vcores
Handling deprecation for dfs.datanode.block-pinning.enabled
Handling deprecation for mapreduce.jobhistory.http.policy
Handling deprecation for yarn.resourcemanager.webapp.delegation-token-auth-filter.enabled
Handling deprecation for mapreduce.job.speculative.retry-after-no-speculate
Handling deprecation for fs.s3a.attempts.maximum
Handling deprecation for s3native.stream-buffer-size
Handling deprecation for io.seqfile.local.dir
Handling deprecation for yarn.log-aggregation.retain-check-interval-seconds
Handling deprecation for fs.s3n.multipart.copy.block.size
Handling deprecation for dfs.encrypt.data.transfer.cipher.key.bitlength
Handling deprecation for dfs.datanode.sync.behind.writes
Handling deprecation for yarn.resourcemanager.zk-acl
Handling deprecation for hadoop.ssl.keystores.factory.class
Handling deprecation for mapreduce.job.split.metainfo.maxsize
Handling deprecation for fs.s3.maxRetries
Handling deprecation for hadoop.security.random.device.file.path
Handling deprecation for yarn.client.nodemanager-connect.max-wait-ms
Handling deprecation for dfs.namenode.stale.datanode.interval
Handling deprecation for mapreduce.task.io.sort.mb
Handling deprecation for yarn.resourcemanager.zk-state-store.parent-path
Handling deprecation for yarn.app.mapreduce.client-am.ipc.max-retries
Handling deprecation for fs.client.resolve.remote.symlinks
Handling deprecation for yarn.nodemanager.linux-container-executor.cgroups.strict-resource-usage
Handling deprecation for hadoop.ssl.enabled.protocols
Handling deprecation for mapreduce.reduce.cpu.vcores
Handling deprecation for yarn.client.failover-retries
Handling deprecation for mapreduce.jobhistory.address
Handling deprecation for hadoop.ssl.enabled
Handling deprecation for dfs.replication.max
Handling deprecation for dfs.namenode.name.dir
Handling deprecation for dfs.datanode.https.address
Handling deprecation for ipc.client.kill.max
Handling deprecation for mapreduce.job.committer.setup.cleanup.needed
Handling deprecation for dfs.client.domain.socket.data.traffic
Handling deprecation for yarn.nodemanager.localizer.cache.target-size-mb
Handling deprecation for yarn.resourcemanager.admin.client.thread-count
Handling deprecation for dfs.block.access.token.enable
Handling deprecation for mapreduce.job.speculative.retry-after-speculate
Handling deprecation for dfs.datanode.address
Handling deprecation for mapreduce.jobtracker.restart.recover
Handling deprecation for ipc.client.connect.max.retries
Handling deprecation for yarn.timeline-service.store-class
Handling deprecation for dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
Handling deprecation for hadoop.tmp.dir
Handling deprecation for dfs.datanode.handler.count
Handling deprecation for yarn.resourcemanager.ha.automatic-failover.embedded
Handling deprecation for yarn.timeline-service.ttl-ms
Handling deprecation for mapreduce.task.profile.map.params
Handling deprecation for yarn.resourcemanager.nodemanagers.heartbeat-interval-ms
Handling deprecation for mapreduce.map.speculative
Handling deprecation for yarn.timeline-service.recovery.enabled
Handling deprecation for mapreduce.job.map.class
Handling deprecation for dfs.namenode.resource.checked.volumes.minimum
Handling deprecation for yarn.nodemanager.recovery.dir
Handling deprecation for mapreduce.job.counters.max
Handling deprecation for yarn.resourcemanager.keytab
Handling deprecation for dfs.namenode.max.extra.edits.segments.retained
Handling deprecation for dfs.webhdfs.user.provider.user.pattern
Handling deprecation for dfs.client.mmap.enabled
Handling deprecation for mapreduce.map.log.level
Handling deprecation for dfs.client.file-block-storage-locations.timeout.millis
Handling deprecation for yarn.client.max-cached-nodemanagers-proxies
Handling deprecation for yarn.app.mapreduce.am.scheduler.heartbeat.interval-ms
Handling deprecation for hadoop.fuse.timer.period
Handling deprecation for fs.trash.checkpoint.interval
Handling deprecation for yarn.sharedcache.app-checker.class
Handling deprecation for dfs.journalnode.http-address
Handling deprecation for yarn.app.mapreduce.am.staging-dir
Handling deprecation for mapreduce.tasktracker.local.dir.minspacestart
Handling deprecation for yarn.nm.liveness-monitor.expiry-interval-ms
Handling deprecation for ha.health-monitor.check-interval.ms
Handling deprecation for mapreduce.reduce.shuffle.merge.percent
Handling deprecation for dfs.namenode.retrycache.heap.percent
Handling deprecation for yarn.nodemanager.docker-container-executor.exec-name
Handling deprecation for ipc.client.connect.timeout
Handling deprecation for yarn.resourcemanager.fs.state-store.retry-interval-ms
Handling deprecation for mapreduce.output.fileoutputformat.compress
Handling deprecation for yarn.nodemanager.local-dirs
Handling deprecation for yarn.nodemanager.recovery.enabled
Handling deprecation for io.native.lib.available
Handling deprecation for yarn.sharedcache.store.in-memory.staleness-period-mins
Handling deprecation for yarn.resourcemanager.am.max-attempts
Handling deprecation for s3.replication
Handling deprecation for mapreduce.input.fileinputformat.inputdir
Handling deprecation for fs.AbstractFileSystem.har.impl
Handling deprecation for dfs.image.compress
Handling deprecation for mapreduce.job.running.map.limit
Handling deprecation for mapreduce.reduce.input.buffer.percent
Handling deprecation for yarn.nodemanager.webapp.address
Handling deprecation for dfs.datanode.available-space-volume-choosing-policy.balanced-space-preference-fraction
Handling deprecation for dfs.namenode.edit.log.autoroll.multiplier.threshold
Handling deprecation for hadoop.security.group.mapping.ldap.ssl
Handling deprecation for dfs.namenode.checkpoint.check.period
Handling deprecation for fs.defaultFS
Handling deprecation for fs.s3a.multipart.size
Handling deprecation for dfs.client.slow.io.warning.threshold.ms
Handling deprecation for yarn.app.mapreduce.am.job.committer.commit-window
Handling deprecation for hadoop.security.group.mapping.ldap.search.attr.group.name
Handling deprecation for yarn.nodemanager.disk-health-checker.max-disk-utilization-per-disk-percentage
Handling deprecation for yarn.nodemanager.container-monitor.procfs-tree.smaps-based-rss.enabled
Handling deprecation for mapreduce.job.submithostname
Handling deprecation for mapreduce.map.sort.spill.percent
Handling deprecation for hadoop.security.crypto.codec.classes.aes.ctr.nopadding
Handling deprecation for dfs.namenode.http-address
Handling deprecation for hadoop.security.groups.negative-cache.secs
Handling deprecation for hadoop.ssl.server.conf
Handling deprecation for mapreduce.ifile.readahead
Handling deprecation for s3native.replication
Handling deprecation for yarn.client.nodemanager-client-async.thread-pool-max-size
Handling deprecation for mapreduce.jobtracker.staging.root.dir
Handling deprecation for mapreduce.jobhistory.admin.address
Handling deprecation for dfs.namenode.startup.delay.block.deletion.sec
Handling deprecation for yarn.nodemanager.health-checker.interval-ms
Handling deprecation for dfs.namenode.checkpoint.max-retries
Handling deprecation for s3.stream-buffer-size
Handling deprecation for ftp.client-write-packet-size
Handling deprecation for dfs.datanode.fsdatasetcache.max.threads.per.volume
Handling deprecation for mapreduce.output.fileoutputformat.compress.codec
Handling deprecation for yarn.timeline-service.keytab
Handling deprecation for yarn.sharedcache.store.in-memory.initial-delay-mins
Handling deprecation for mapreduce.jobhistory.webapp.address
Handling deprecation for mapreduce.task.userlog.limit.kb
Handling deprecation for mapreduce.reduce.shuffle.fetch.retry.enabled
Handling deprecation for yarn.app.mapreduce.task.container.log.backups
Handling deprecation for dfs.heartbeat.interval
Handling deprecation for ha.zookeeper.session-timeout.ms
Handling deprecation for fs.s3a.connection.ssl.enabled
Handling deprecation for yarn.sharedcache.webapp.address
Handling deprecation for hadoop.http.authentication.signature.secret.file
Handling deprecation for hadoop.fuse.connection.timeout
Handling deprecation for mapreduce.input.fileinputformat.numinputfiles
Handling deprecation for yarn.nodemanager.log-aggregation.compression-type
Handling deprecation for ipc.server.max.connections
Handling deprecation for yarn.resourcemanager.work-preserving-recovery.scheduling-wait-ms
Handling deprecation for yarn.nodemanager.log-dirs
Handling deprecation for yarn.app.mapreduce.am.resource.mb
Handling deprecation for hadoop.security.groups.cache.secs
Handling deprecation for mapreduce.job.speculative.minimum-allowed-tasks
Handling deprecation for yarn.nodemanager.container-monitor.interval-ms
Handling deprecation for dfs.datanode.cache.revocation.timeout.ms
Handling deprecation for mapreduce.jobhistory.recovery.store.class
Handling deprecation for mapreduce.task.combine.progress.records
Handling deprecation for s3.client-write-packet-size
Handling deprecation for mapreduce.jobtracker.instrumentation
Handling deprecation for dfs.replication
Handling deprecation for mapreduce.shuffle.transfer.buffer.size
Handling deprecation for hadoop.security.group.mapping.ldap.directory.search.timeout
Handling deprecation for dfs.datanode.available-space-volume-choosing-policy.balanced-space-threshold
Handling deprecation for hadoop.work.around.non.threadsafe.getpwuid
Handling deprecation for yarn.app.mapreduce.client-am.ipc.max-retries-on-timeouts
Handling deprecation for yarn.nodemanager.address
Handling deprecation for mapreduce.tasktracker.taskcontroller
Handling deprecation for mapreduce.tasktracker.indexcache.mb
Handling deprecation for yarn.scheduler.maximum-allocation-vcores
Handling deprecation for mapreduce.job.reduces
Handling deprecation for yarn.nodemanager.sleep-delay-before-sigkill.ms
Handling deprecation for yarn.timeline-service.address
Handling deprecation for yarn.resourcemanager.configuration.provider-class
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.expiry
Handling deprecation for yarn.sharedcache.enabled
Handling deprecation for tfile.io.chunk.size
Handling deprecation for mapreduce.job.acl-modify-job
Handling deprecation for hadoop.registry.zk.session.timeout.ms
Handling deprecation for fs.automatic.close
Handling deprecation for ha.health-monitor.sleep-after-disconnect.ms
Handling deprecation for mapreduce.tasktracker.reduce.tasks.maximum
Handling deprecation for mapreduce.input.fileinputformat.list-status.num-threads
Handling deprecation for dfs.datanode.directoryscan.threads
Handling deprecation for dfs.datanode.directoryscan.interval
Handling deprecation for dfs.namenode.acls.enabled
Handling deprecation for dfs.client.short.circuit.replica.stale.threshold.ms
Handling deprecation for hadoop.http.authentication.token.validity
Handling deprecation for fs.s3.block.size
Handling deprecation for ha.failover-controller.graceful-fence.rpc-timeout.ms
Handling deprecation for mapreduce.tasktracker.local.dir.minspacekill
Handling deprecation for dfs.namenode.resource.du.reserved
Handling deprecation for mapreduce.jobhistory.cleaner.interval-ms
Handling deprecation for dfs.namenode.datanode.registration.ip-hostname-check
Handling deprecation for mapreduce.jobhistory.intermediate-done-dir
Handling deprecation for mapreduce.jobtracker.http.address
Handling deprecation for dfs.namenode.backup.http-address
Handling deprecation for dfs.namenode.edits.noeditlogchannelflush
Handling deprecation for mapreduce.reduce.shuffle.input.buffer.percent
Handling deprecation for mapreduce.map.maxattempts
Handling deprecation for yarn.http.policy
Handling deprecation for dfs.namenode.audit.loggers
Handling deprecation for hadoop.security.groups.cache.warn.after.ms
Handling deprecation for io.serializations
Handling deprecation for mapreduce.tasktracker.outofband.heartbeat
Handling deprecation for mapreduce.reduce.shuffle.read.timeout
Handling deprecation for hadoop.security.crypto.buffer.size
Handling deprecation for mapreduce.reduce.skip.proc.count.autoincr
Handling deprecation for mapreduce.ifile.readahead.bytes
Handling deprecation for dfs.http.policy
Handling deprecation for hadoop.registry.secure
Handling deprecation for dfs.namenode.safemode.min.datanodes
Handling deprecation for dfs.client.file-block-storage-locations.num-threads
Handling deprecation for mapreduce.cluster.local.dir
Handling deprecation for mapreduce.tasktracker.report.address
Handling deprecation for dfs.namenode.secondary.https-address
Handling deprecation for hadoop.kerberos.kinit.command
Handling deprecation for yarn.timeline-service.http-authentication.type
Handling deprecation for dfs.block.access.token.lifetime
Handling deprecation for dfs.webhdfs.enabled
Handling deprecation for dfs.namenode.delegation.token.max-lifetime
Handling deprecation for dfs.namenode.avoid.write.stale.datanode
Handling deprecation for dfs.datanode.drop.cache.behind.writes
Handling deprecation for yarn.log-aggregation.retain-seconds
Handling deprecation for mapreduce.job.complete.cancel.delegation.tokens
Handling deprecation for mapreduce.local.clientfactory.class.name
Handling deprecation for mapreduce.shuffle.connection-keep-alive.timeout
Handling deprecation for dfs.namenode.num.extra.edits.retained
Handling deprecation for yarn.scheduler.minimum-allocation-vcores
Handling deprecation for ipc.client.connect.max.retries.on.timeouts
Handling deprecation for yarn.timeline-service.client.retry-interval-ms
Handling deprecation for yarn.timeline-service.client.max-retries
Handling deprecation for fs.s3n.block.size
Handling deprecation for mapreduce.job.map.output.collector.class
Handling deprecation for ha.health-monitor.connect-retry-interval.ms
Handling deprecation for mapreduce.shuffle.max.threads
Handling deprecation for nfs.exports.allowed.hosts
Handling deprecation for dfs.client.mmap.cache.size
Handling deprecation for mapreduce.tasktracker.map.tasks.maximum
Handling deprecation for io.file.buffer.size
Handling deprecation for dfs.client.datanode-restart.timeout
Handling deprecation for io.mapfile.bloom.size
Handling deprecation for hadoop.security.kms.client.authentication.retry-count
Handling deprecation for dfs.namenode.checkpoint.txns
Handling deprecation for ipc.client.connect.retry.interval
Handling deprecation for dfs.client-write-packet-size
Handling deprecation for mapreduce.reduce.shuffle.connect.timeout
Handling deprecation for yarn.resourcemanager.fs.state-store.uri
Handling deprecation for fs.swift.impl
Handling deprecation for hadoop.registry.zk.connection.timeout.ms
Handling deprecation for mapred.queue.default.acl-administer-jobs
Handling deprecation for mapreduce.job.submithostaddress
Handling deprecation for dfs.cachereport.intervalMsec
Handling deprecation for yarn.app.mapreduce.shuffle.log.backups
Handling deprecation for yarn.app.mapreduce.am.container.log.limit.kb
Handling deprecation for yarn.nodemanager.resourcemanager.minimum.version
Handling deprecation for ftp.blocksize
Handling deprecation for yarn.resourcemanager.address
Handling deprecation for file.stream-buffer-size
Handling deprecation for yarn.resourcemanager.scheduler.monitor.enable
Handling deprecation for mapreduce.job.ubertask.maxreduces
Handling deprecation for nfs.allow.insecure.ports
Handling deprecation for yarn.sharedcache.nm.uploader.thread-count
Handling deprecation for ipc.client.idlethreshold
Handling deprecation for ftp.stream-buffer-size
Handling deprecation for yarn.sharedcache.client-server.address
Handling deprecation for dfs.client.failover.connection.retries.on.timeouts
Handling deprecation for dfs.namenode.replication.work.multiplier.per.iteration
Handling deprecation for hadoop.http.authentication.simple.anonymous.allowed
Handling deprecation for hadoop.security.authorization
Handling deprecation for yarn.client.nodemanager-connect.retry-interval-ms
Handling deprecation for yarn.am.liveness-monitor.expiry-interval-ms
Handling deprecation for fs.har.impl.disable.cache
Handling deprecation for yarn.nodemanager.linux-container-executor.resources-handler.class
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.read-cache-size
Handling deprecation for hadoop.security.authentication
Handling deprecation for dfs.image.compression.codec
Handling deprecation for mapreduce.task.files.preserve.failedtasks
Handling deprecation for dfs.client.read.shortcircuit.streams.cache.size
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.path
Handling deprecation for mapreduce.job.reduce.slowstart.completedmaps
Handling deprecation for mapreduce.jobhistory.minicluster.fixed.ports
Handling deprecation for file.replication
Handling deprecation for yarn.resourcemanager.ha.automatic-failover.enabled
Handling deprecation for mapreduce.job.userlog.retain.hours
Handling deprecation for mapreduce.jobhistory.joblist.cache.size
Handling deprecation for dfs.namenode.accesstime.precision
Handling deprecation for yarn.resourcemanager.work-preserving-recovery.enabled
Handling deprecation for dfs.namenode.fs-limits.max-xattrs-per-inode
Handling deprecation for io.mapfile.bloom.error.rate
Handling deprecation for yarn.resourcemanager.store.class
Handling deprecation for dfs.image.transfer.timeout
Handling deprecation for yarn.timeline-service.leveldb-state-store.path
Handling deprecation for nfs.wtmax
Handling deprecation for mapreduce.job.combine.class
Handling deprecation for dfs.namenode.support.allow.format
Handling deprecation for fs.s3a.multipart.purge
Handling deprecation for dfs.secondary.namenode.kerberos.internal.spnego.principal
Handling deprecation for fs.s3a.connection.establish.timeout
Handling deprecation for dfs.stream-buffer-size
Handling deprecation for dfs.namenode.invalidate.work.pct.per.iteration
Handling deprecation for yarn.nodemanager.container-executor.class
Handling deprecation for fs.s3a.multipart.purge.age
Handling deprecation for yarn.resourcemanager.scheduler.client.thread-count
Handling deprecation for dfs.namenode.top.enabled
Handling deprecation for yarn.app.mapreduce.shuffle.log.separate
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.low-watermark
Handling deprecation for fs.s3a.fast.buffer.size
Handling deprecation for hadoop.user.group.static.mapping.overrides
Handling deprecation for tfile.fs.input.buffer.size
Handling deprecation for dfs.client.cached.conn.retry
Handling deprecation for hadoop.http.authentication.type
Handling deprecation for dfs.namenode.list.encryption.zones.num.responses
Handling deprecation for mapreduce.map.cpu.vcores
Handling deprecation for dfs.namenode.path.based.cache.refresh.interval.ms
Handling deprecation for dfs.namenode.decommission.interval
Handling deprecation for dfs.namenode.fs-limits.max-directory-items
Handling deprecation for yarn.resourcemanager.zk-retry-interval-ms
Handling deprecation for ftp.bytes-per-checksum
Handling deprecation for dfs.ha.log-roll.period
Handling deprecation for dfs.user.home.dir.prefix
Handling deprecation for ipc.client.fallback-to-simple-auth-allowed
Handling deprecation for yarn.nodemanager.pmem-check-enabled
Handling deprecation for yarn.nodemanager.remote-app-log-dir
Handling deprecation for dfs.namenode.inotify.max.events.per.rpc
Handling deprecation for mapreduce.task.profile.maps
Handling deprecation for mapreduce.shuffle.ssl.file.buffer.size
Handling deprecation for mapreduce.tasktracker.healthchecker.script.timeout
Handling deprecation for yarn.timeline-service.webapp.https.address
Handling deprecation for yarn.nodemanager.resource.percentage-physical-cpu-limit
Handling deprecation for yarn.app.mapreduce.am.command-opts
Handling deprecation for dfs.namenode.fs-limits.max-xattr-size
Handling deprecation for dfs.datanode.http.address
Handling deprecation for dfs.namenode.blocks.per.postponedblocks.rescan
Handling deprecation for yarn.sharedcache.nm.uploader.replication.factor
Handling deprecation for hadoop.registry.zk.root
Handling deprecation for hadoop.jetty.logs.serve.aliases
Handling deprecation for yarn.client.failover-proxy-provider
Handling deprecation for mapreduce.jobhistory.admin.acl
Handling deprecation for yarn.app.mapreduce.am.hard-kill-timeout-ms
Handling deprecation for yarn.nodemanager.remote-app-log-dir-suffix
Handling deprecation for mapreduce.jobhistory.principal
Handling deprecation for yarn.resourcemanager.webapp.address
Handling deprecation for mapreduce.jobhistory.recovery.enable
Handling deprecation for yarn.sharedcache.store.in-memory.check-period-mins
Handling deprecation for nfs.mountd.port
Handling deprecation for mapreduce.reduce.merge.inmem.threshold
Handling deprecation for fs.df.interval
Handling deprecation for yarn.timeline-service.enabled
Handling deprecation for mapreduce.jobtracker.jobhistory.lru.cache.size
Handling deprecation for mapreduce.task.profile
Handling deprecation for mapreduce.job.output.key.class
Handling deprecation for yarn.nodemanager.hostname
Handling deprecation for dfs.namenode.num.checkpoints.retained
Handling deprecation for mapreduce.job.queuename
Handling deprecation for mapreduce.jobhistory.max-age-ms
Handling deprecation for mapreduce.job.token.tracking.ids.enabled
Handling deprecation for yarn.nodemanager.localizer.client.thread-count
Handling deprecation for yarn.sharedcache.uploader.server.thread-count
Handling deprecation for dfs.client.mmap.retry.timeout.ms
Handling deprecation for mapreduce.jobhistory.move.thread-count
Handling deprecation for dfs.permissions.enabled
Handling deprecation for dfs.blockreport.split.threshold
Handling deprecation for fs.AbstractFileSystem.hdfs.impl
Handling deprecation for dfs.datanode.balance.bandwidthPerSec
Handling deprecation for dfs.block.scanner.volume.bytes.per.second
Handling deprecation for hadoop.http.filter.initializers
Handling deprecation for yarn.timeline-service.http-authentication.simple.anonymous.allowed
Handling deprecation for dfs.default.chunk.view.size
Handling deprecation for yarn.sharedcache.client-server.thread-count
Handling deprecation for yarn.resourcemanager.resource-tracker.address
Handling deprecation for mapreduce.job.working.dir
Handling deprecation for mapreduce.jobhistory.datestring.cache.size
Handling deprecation for mapreduce.task.profile.params
Handling deprecation for dfs.namenode.decommission.blocks.per.interval
Handling deprecation for dfs.namenode.handler.count
Handling deprecation for dfs.image.transfer.bandwidthPerSec
Handling deprecation for rpc.metrics.quantile.enable
Handling deprecation for mapreduce.jobtracker.expire.trackers.interval
Handling deprecation for mapreduce.task.timeout
Handling deprecation for yarn.app.mapreduce.client.max-retries
Handling deprecation for yarn.nodemanager.resource.memory-mb
Handling deprecation for yarn.nodemanager.disk-health-checker.min-healthy-disks
Handling deprecation for dfs.datanode.failed.volumes.tolerated
Handling deprecation for yarn.timeline-service.handler-thread-count
Handling deprecation for ipc.server.listen.queue.size
Handling deprecation for fs.s3a.threads.max
Handling deprecation for yarn.resourcemanager.connect.max-wait.ms
Handling deprecation for mapreduce.fileoutputcommitter.algorithm.version
Handling deprecation for mapreduce.framework.name
Handling deprecation for mapreduce.map.skip.proc.count.autoincr
Handling deprecation for mapreduce.job.max.split.locations
Handling deprecation for yarn.resourcemanager.scheduler.class
Handling deprecation for yarn.resourcemanager.system-metrics-publisher.enabled
Handling deprecation for dfs.blocksize
Handling deprecation for yarn.sharedcache.nested-level
Handling deprecation for mapreduce.shuffle.connection-keep-alive.enable
Handling deprecation for fs.s3a.threads.keepalivetime
Handling deprecation for fs.s3a.connection.timeout
Handling deprecation for file.client-write-packet-size
Handling deprecation for ha.failover-controller.cli-check.rpc-timeout.ms
Handling deprecation for ha.zookeeper.acl
Handling deprecation for dfs.namenode.write.stale.datanode.ratio
Handling deprecation for dfs.encrypt.data.transfer
Handling deprecation for dfs.datanode.shared.file.descriptor.paths
Handling deprecation for mapreduce.input.lineinputformat.linespermap
Handling deprecation for yarn.resourcemanager.delayed.delegation-token.removal-interval-ms
Handling deprecation for yarn.nodemanager.localizer.fetch.thread-count
Handling deprecation for dfs.client.failover.max.attempts
Handling deprecation for yarn.resourcemanager.scheduler.address
Handling deprecation for dfs.client.read.shortcircuit.streams.cache.expiry.ms
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.start-time-write-cache-size
Handling deprecation for yarn.nodemanager.health-checker.script.timeout-ms
Handling deprecation for yarn.resourcemanager.fs.state-store.num-retries
Handling deprecation for hadoop.ssl.require.client.cert
Handling deprecation for hadoop.security.uid.cache.secs
Handling deprecation for mapreduce.jobhistory.keytab
Handling deprecation for dfs.client.read.shortcircuit.skip.checksum
Handling deprecation for yarn.resourcemanager.ha.automatic-failover.zk-base-path
Handling deprecation for mapreduce.shuffle.ssl.enabled
Handling deprecation for mapreduce.reduce.log.level
Handling deprecation for hadoop.registry.rm.enabled
Handling deprecation for mapreduce.tasktracker.dns.interface
Handling deprecation for yarn.resourcemanager.system-metrics-publisher.dispatcher.pool-size
Handling deprecation for mapreduce.job.speculative.speculative-cap-running-tasks
Handling deprecation for dfs.datanode.block.id.layout.upgrade.threads
Handling deprecation for dfs.datanode.use.datanode.hostname
Handling deprecation for dfs.client.context
Handling deprecation for yarn.resourcemanager.ha.enabled
Handling deprecation for mapred.reducer.new-api
Handling deprecation for dfs.namenode.delegation.token.renew-interval
Handling deprecation for dfs.blockreport.intervalMsec
Handling deprecation for fs.s3a.multipart.threshold
Handling deprecation for mapreduce.reduce.shuffle.memory.limit.percent
Handling deprecation for dfs.https.server.keystore.resource
Handling deprecation for io.map.index.skip
Handling deprecation for mapreduce.job.hdfs-servers
Handling deprecation for mapreduce.jobtracker.taskscheduler
Handling deprecation for dfs.namenode.kerberos.internal.spnego.principal
Handling deprecation for yarn.resourcemanager.state-store.max-completed-applications
Handling deprecation for mapreduce.map.output.compress
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.num.refill.threads
Handling deprecation for fs.s3n.multipart.uploads.block.size
Handling deprecation for mapreduce.task.merge.progress.records
Handling deprecation for dfs.datanode.dns.interface
Handling deprecation for map.sort.class
Handling deprecation for yarn.nodemanager.aux-services.mapreduce_shuffle.class
Handling deprecation for tfile.fs.output.buffer.size
Handling deprecation for fs.du.interval
Handling deprecation for dfs.client.failover.connection.retries
Handling deprecation for dfs.namenode.top.window.num.buckets
Handling deprecation for mapreduce.job.dir
Handling deprecation for fs.s3a.buffer.dir
Handling deprecation for mapreduce.reduce.shuffle.retry-delay.max.ms
Handling deprecation for yarn.sharedcache.uploader.server.address
Handling deprecation for mapreduce.client.progressmonitor.pollinterval
Handling deprecation for yarn.app.mapreduce.shuffle.log.limit.kb
Handling deprecation for dfs.datanode.max.locked.memory
Handling deprecation for dfs.namenode.retrycache.expirytime.millis
Handling deprecation for dfs.datanode.scan.period.hours
Handling deprecation for dfs.client.block.write.replace-datanode-on-failure.best-effort
Handling deprecation for mapreduce.jobhistory.move.interval-ms
Handling deprecation for dfs.ha.fencing.ssh.connect-timeout
Handling deprecation for yarn.nodemanager.log-aggregation.roll-monitoring-interval-seconds
Handling deprecation for dfs.namenode.fs-limits.max-component-length
Handling deprecation for hadoop.registry.zk.quorum
Handling deprecation for dfs.namenode.enable.retrycache
Handling deprecation for dfs.datanode.du.reserved
Handling deprecation for yarn.timeline-service.state-store-class
Handling deprecation for dfs.datanode.ipc.address
Handling deprecation for hadoop.registry.system.acls
Handling deprecation for dfs.client.block.write.replace-datanode-on-failure.policy
Handling deprecation for dfs.namenode.path.based.cache.retry.interval.ms
Handling deprecation for hadoop.security.crypto.cipher.suite
Handling deprecation for dfs.ha.tail-edits.period
Handling deprecation for mapreduce.task.profile.reduce.params
Handling deprecation for hadoop.registry.jaas.context
Handling deprecation for yarn.resourcemanager.hostname
Handling deprecation for mapreduce.reduce.memory.mb
Handling deprecation for hadoop.security.group.mapping.ldap.search.filter.group
Handling deprecation for hadoop.http.authentication.kerberos.principal
Handling deprecation for hadoop.security.group.mapping.ldap.search.filter.user
Handling deprecation for yarn.nodemanager.disk-health-checker.min-free-space-per-disk-mb
Handling deprecation for dfs.namenode.edits.dir
Handling deprecation for yarn.client.failover-retries-on-socket-timeouts
Handling deprecation for dfs.namenode.decommission.max.concurrent.tracked.nodes
Handling deprecation for mapreduce.client.completion.pollinterval
Handling deprecation for dfs.namenode.name.dir.restore
Handling deprecation for dfs.namenode.secondary.http-address
Handling deprecation for mapreduce.jobhistory.recovery.store.leveldb.path
Handling deprecation for yarn.sharedcache.store.class
Handling deprecation for s3.bytes-per-checksum
Handling deprecation for yarn.nodemanager.windows-container.cpu-limit.enabled
Handling deprecation for yarn.resourcemanager.webapp.https.address
Handling deprecation for yarn.nodemanager.vmem-pmem-ratio
Handling deprecation for dfs.namenode.checkpoint.period
Handling deprecation for dfs.ha.automatic-failover.enabled
The url to track the job: http://localhost:8080/
Running job: job_local1630727290_0001
OutputCommitter set in config null
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
File Output Committer Algorithm version is 1
OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
/user/michaeljones/wcOutputMain/_temporary/0: masked=rwxr-xr-x
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones sending #12
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones got value #12
Call: mkdirs took 20ms
Starting mapper thread pool executor.
Max local threads: 1
Map tasks to process: 1
Starting task: attempt_local1630727290_0001_m_000000_0
Waiting for map tasks
currentIndex 0   0:0
mapreduce.cluster.local.dir for child : /tmp/hadoop-michaeljones/mapred/local/localRunner//michaeljones/jobcache/job_local1630727290_0001/attempt_local1630727290_0001_m_000000_0
using new api for output committer
File Output Committer Algorithm version is 1
ProcfsBasedProcessTree currently is supported only on Linux.
 Using ResourceCalculatorProcessTree : null
Processing split: hdfs://localhost:9000/user/michaeljones/wcInput:0+50
Trying map output collector class: org.apache.hadoop.mapred.MapTask$MapOutputBuffer
(EQUATOR) 0 kvi 26214396(104857584)
mapreduce.task.io.sort.mb: 100
soft limit at 83886080
bufstart = 0; bufvoid = 104857600
kvstart = 26214396; length = 6553600
Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones sending #13
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones got value #13
Call: getBlockLocations took 2ms
newInfo = LocatedBlocks{
  fileLength=50
  underConstruction=false
  blocks=[LocatedBlock{BP-1045030256-10.0.0.2-1433119149314:blk_1073741825_1002; getBlockSize()=50; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-b42c5705-9ba4-4b14-b00b-f9194bb036f0,DISK]]}]
  lastLocatedBlock=LocatedBlock{BP-1045030256-10.0.0.2-1433119149314:blk_1073741825_1002; getBlockSize()=50; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-b42c5705-9ba4-4b14-b00b-f9194bb036f0,DISK]]}
  isLastBlockComplete=true}
Connecting to datanode 127.0.0.1:50010

Starting flush of map output
Spilling map output
bufstart = 0; bufend = 82; bufvoid = 104857600
kvstart = 26214396(104857584); kvend = 26214368(104857472); length = 29/6553600
Finished spill 0
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
Job job_local1630727290_0001 running in uber mode : false
 map 0% reduce 0%
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.getTaskCompletionEvents(Job.java:670)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
Task:attempt_local1630727290_0001_m_000000_0 is done. And is in the process of committing
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones sending #14
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones got value #14
Call: getFileInfo took 8ms
map
Task 'attempt_local1630727290_0001_m_000000_0' done.
Finishing task: attempt_local1630727290_0001_m_000000_0
map task executor complete.
Starting reduce thread pool executor.
Max local threads: 1
Reduce tasks to process: 1
Waiting for reduce tasks
Starting task: attempt_local1630727290_0001_r_000000_0
currentIndex 0   0:0
mapreduce.cluster.local.dir for child : /tmp/hadoop-michaeljones/mapred/local/localRunner//michaeljones/jobcache/job_local1630727290_0001/attempt_local1630727290_0001_r_000000_0
using new api for output committer
File Output Committer Algorithm version is 1
ProcfsBasedProcessTree currently is supported only on Linux.
 Using ResourceCalculatorProcessTree : null
Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@71bd84be
MergerManager: memoryLimit=668309888, maxSingleShuffleLimit=167077472, mergeThreshold=441084544, ioSortFactor=10, memToMemMergeOutputsThreshold=10
attempt_local1630727290_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
Got 0 map completion events from 0
GetMapEventsThread about to sleep for 1000
LocalFetcher 1 going to fetch: attempt_local1630727290_0001_m_000000_0
attempt_local1630727290_0001_m_000000_0: Proceeding with shuffle since usedMemory (0) is lesser than memoryLimit (668309888).CommitMemory is (0)
localfetcher#1 about to shuffle output of map attempt_local1630727290_0001_m_000000_0 decomp: 63 len: 67 to MEMORY
Read 63 bytes from map-output for attempt_local1630727290_0001_m_000000_0
closeInMemoryFile -> map-output of size: 63, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->63
map attempt_local1630727290_0001_m_000000_0 done 1 / 1 copied.
EventFetcher is interrupted.. Returning
1 / 1 copied.
finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
Merging 1 sorted segments
Down to the last merge-pass, with 1 segments left of total size: 57 bytes
Merged 1 segments, 63 bytes to disk to satisfy reduce memory limit
Disk file: /tmp/hadoop-michaeljones/mapred/local/localRunner/michaeljones/jobcache/job_local1630727290_0001/attempt_local1630727290_0001_r_000000_0/output/map_0.out.merged Length is 67
Merging 1 files, 67 bytes from disk
Merging 0 segments, 0 bytes from memory into reduce
Merging 1 sorted segments
Down to the last merge-pass, with 1 segments left of total size: 57 bytes
1 / 1 copied.
/user/michaeljones/wcOutputMain/_temporary/0/_temporary/attempt_local1630727290_0001_r_000000_0/part-r-00000: masked=rw-r--r--
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones sending #15
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones got value #15
Call: create took 7ms
computePacketChunkSize: src=/user/michaeljones/wcOutputMain/_temporary/0/_temporary/attempt_local1630727290_0001_r_000000_0/part-r-00000, chunkSize=516, chunksPerPacket=126, packetSize=65016
mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
DFSClient writeChunk allocating new packet seqno=0, src=/user/michaeljones/wcOutputMain/_temporary/0/_temporary/attempt_local1630727290_0001_r_000000_0/part-r-00000, packetSize=65016, chunksPerPacket=126, bytesCurBlock=0
Queued packet 0
Allocating new block
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones sending #16
Queued packet 1
Waiting for ack for: 1
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones got value #16
Call: addBlock took 4ms
pipeline = DatanodeInfoWithStorage[127.0.0.1:50010,DS-b42c5705-9ba4-4b14-b00b-f9194bb036f0,DISK]
Connecting to datanode 127.0.0.1:50010
Send buf size 131072
SASL client skipping handshake in unsecured configuration for addr = /127.0.0.1, datanodeId = DatanodeInfoWithStorage[127.0.0.1:50010,DS-b42c5705-9ba4-4b14-b00b-f9194bb036f0,DISK]
DataStreamer block BP-1045030256-10.0.0.2-1433119149314:blk_1073742328_1505 sending packet packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 41
DFSClient seqno: 0 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
DataStreamer block BP-1045030256-10.0.0.2-1433119149314:blk_1073742328_1505 sending packet packet seqno: 1 offsetInBlock: 41 lastPacketInBlock: true lastByteOffsetInBlock: 41
DFSClient seqno: 1 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
Closing old block BP-1045030256-10.0.0.2-1433119149314:blk_1073742328_1505
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones sending #17
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones got value #17
Call: complete took 3ms
Task:attempt_local1630727290_0001_r_000000_0 is done. And is in the process of committing
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones sending #18
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones got value #18
Call: getFileInfo took 2ms
1 / 1 copied.
Task attempt_local1630727290_0001_r_000000_0 is allowed to commit now
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones sending #19
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones got value #19
Call: getFileInfo took 2ms
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones sending #20
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones got value #20
Call: getFileInfo took 2ms
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones sending #21
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones got value #21
Call: rename took 32ms
Saved output of task 'attempt_local1630727290_0001_r_000000_0' to hdfs://localhost:9000/user/michaeljones/wcOutputMain/_temporary/0/task_local1630727290_0001_r_000000
reduce > reduce
Task 'attempt_local1630727290_0001_r_000000_0' done.
Finishing task: attempt_local1630727290_0001_r_000000_0
reduce task executor complete.
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones sending #22
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones got value #22
Call: getListing took 3ms
Merging data from FileStatus{path=hdfs://localhost:9000/user/michaeljones/wcOutputMain/_temporary/0/task_local1630727290_0001_r_000000; isDirectory=true; modification_time=1434242168082; access_time=0; owner=michaeljones; group=supergroup; permission=rwxr-xr-x; isSymlink=false} to hdfs://localhost:9000/user/michaeljones/wcOutputMain
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones sending #23
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones got value #23
Call: getFileInfo took 7ms
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones sending #24
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones got value #24
Call: getListing took 5ms
Merging data from FileStatus{path=hdfs://localhost:9000/user/michaeljones/wcOutputMain/_temporary/0/task_local1630727290_0001_r_000000/part-r-00000; isDirectory=false; length=41; replication=1; blocksize=134217728; modification_time=1434242168120; access_time=1434242168082; owner=michaeljones; group=supergroup; permission=rw-r--r--; isSymlink=false} to hdfs://localhost:9000/user/michaeljones/wcOutputMain/part-r-00000
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones sending #25
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones got value #25
Call: getFileInfo took 2ms
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones sending #26
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones got value #26
Call: rename took 5ms
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones sending #27
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones got value #27
Call: delete took 5ms
/user/michaeljones/wcOutputMain/_SUCCESS: masked=rw-r--r--
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones sending #28
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones got value #28
Call: create took 4ms
computePacketChunkSize: src=/user/michaeljones/wcOutputMain/_SUCCESS, chunkSize=516, chunksPerPacket=126, packetSize=65016
Waiting for ack for: -1
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones sending #29
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones got value #29
Call: complete took 3ms
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.fs.FileContext.getAbstractFileSystem(FileContext.java:331)
 map 100% reduce 100%
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.getTaskCompletionEvents(Job.java:670)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.getTaskCompletionEvents(Job.java:670)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
Job job_local1630727290_0001 completed successfully
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.getCounters(Job.java:758)
Counters: 35
	File System Counters
		FILE: Number of bytes read=520
		FILE: Number of bytes written=565643
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=140
		HDFS: Number of bytes written=81
		HDFS: Number of read operations=19
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=10
	Map-Reduce Framework
		Map input records=2
		Map output records=8
		Map output bytes=82
		Map output materialized bytes=67
		Input split bytes=112
		Combine input records=8
		Combine output records=5
		Reduce input groups=5
		Reduce shuffle bytes=67
		Reduce input records=5
		Reduce output records=5
		Spilled Records=10
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=778
		Total committed heap usage (bytes)=874512384
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=50
	File Output Format Counters 
		Bytes Written=41
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
RunJobAsync
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones sending #30
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones got value #30
Call: getFileInfo took 4ms
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones sending #31
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones got value #31
Call: delete took 6ms
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.connect(Job.java:1256)
Trying ClientProtocolProvider : org.apache.hadoop.mapred.LocalClientProtocolProvider
Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
Picked org.apache.hadoop.mapred.LocalClientProtocolProvider as the ClientProtocolProvider
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Cluster.getFileSystem(Cluster.java:162)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.submit(Job.java:1287)
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones sending #32
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones got value #32
Call: getFileInfo took 2ms
Configuring job job_local881914384_0002 with file:/tmp/hadoop-michaeljones/mapred/staging/michaeljones881914384/.staging/job_local881914384_0002 as the submit dir
adding the following namenodes' delegation tokens:[hdfs://localhost:9000]
Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
default FileSystem: file:///
No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
Creating splits at file:/tmp/hadoop-michaeljones/mapred/staging/michaeljones881914384/.staging/job_local881914384_0002
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones sending #33
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones got value #33
Call: getFileInfo took 3ms
Time taken to get FileStatuses: 3
Total input paths to process : 1
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones sending #34
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones got value #34
Call: getBlockLocations took 4ms
Total # of splits generated by getSplits: 1, TimeTaken: 8
number of splits:1
Handling deprecation for all properties in config...
Handling deprecation for mapreduce.jobtracker.address
Handling deprecation for yarn.resourcemanager.scheduler.monitor.policies
Handling deprecation for dfs.namenode.resource.check.interval
Handling deprecation for mapreduce.jobhistory.client.thread-count
Handling deprecation for yarn.app.mapreduce.am.containerlauncher.threadpool-initial-size
Handling deprecation for mapred.child.java.opts
Handling deprecation for mapreduce.jobtracker.retiredjobs.cache.size
Handling deprecation for dfs.client.https.need-auth
Handling deprecation for yarn.admin.acl
Handling deprecation for yarn.app.mapreduce.am.job.committer.cancel-timeout
Handling deprecation for mapreduce.job.emit-timeline-data
Handling deprecation for fs.ftp.host.port
Handling deprecation for dfs.namenode.avoid.read.stale.datanode
Handling deprecation for dfs.journalnode.rpc-address
Handling deprecation for mapreduce.job.end-notification.retry.attempts
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.ttl-interval-ms
Handling deprecation for yarn.resourcemanager.leveldb-state-store.path
Handling deprecation for mapred.mapper.new-api
Handling deprecation for yarn.ipc.rpc.class
Handling deprecation for ipc.client.connection.maxidletime
Handling deprecation for yarn.nodemanager.process-kill-wait.ms
Handling deprecation for mapreduce.cluster.acls.enabled
Handling deprecation for mapreduce.jobtracker.handler.count
Handling deprecation for io.map.index.interval
Handling deprecation for dfs.namenode.https-address
Handling deprecation for mapreduce.task.profile.reduces
Handling deprecation for fs.s3n.multipart.uploads.enabled
Handling deprecation for io.seqfile.sorter.recordlimit
Handling deprecation for mapreduce.job.ubertask.maxmaps
Handling deprecation for mapreduce.tasktracker.tasks.sleeptimebeforesigkill
Handling deprecation for hadoop.util.hash.type
Handling deprecation for dfs.namenode.replication.min
Handling deprecation for yarn.nodemanager.container-manager.thread-count
Handling deprecation for mapreduce.jobtracker.jobhistory.block.size
Handling deprecation for dfs.namenode.fs-limits.min-block-size
Handling deprecation for mapreduce.app-submission.cross-platform
Handling deprecation for fs.AbstractFileSystem.file.impl
Handling deprecation for net.topology.script.number.args
Handling deprecation for yarn.resourcemanager.container-tokens.master-key-rolling-interval-secs
Handling deprecation for mapreduce.map.output.compress.codec
Handling deprecation for mapreduce.job.reducer.preempt.delay.sec
Handling deprecation for s3native.bytes-per-checksum
Handling deprecation for dfs.namenode.path.based.cache.block.map.allocation.percent
Handling deprecation for yarn.nodemanager.windows-container.memory-limit.enabled
Handling deprecation for mapreduce.input.fileinputformat.split.minsize
Handling deprecation for hadoop.security.group.mapping
Handling deprecation for mapreduce.jobtracker.system.dir
Handling deprecation for mapreduce.job.end-notification.max.attempts
Handling deprecation for mapreduce.reduce.markreset.buffer.percent
Handling deprecation for dfs.datanode.cache.revocation.polling.ms
Handling deprecation for mapreduce.reduce.speculative
Handling deprecation for yarn.nodemanager.localizer.cache.cleanup.interval-ms
Handling deprecation for dfs.namenode.lazypersist.file.scrub.interval.sec
Handling deprecation for fs.s3a.threads.core
Handling deprecation for mapreduce.jobhistory.recovery.store.fs.uri
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.start-time-read-cache-size
Handling deprecation for hadoop.registry.zk.retry.interval.ms
Handling deprecation for yarn.nodemanager.keytab
Handling deprecation for dfs.namenode.replication.interval
Handling deprecation for yarn.resourcemanager.admin.address
Handling deprecation for mapreduce.job.maps
Handling deprecation for nfs.dump.dir
Handling deprecation for mapreduce.job.user.name
Handling deprecation for mapreduce.jobtracker.maxtasks.perjob
Handling deprecation for mapreduce.job.ubertask.enable
Handling deprecation for mapreduce.job.reduce.class
Handling deprecation for yarn.nodemanager.delete.debug-delay-sec
Handling deprecation for yarn.timeline-service.ttl-enable
Handling deprecation for yarn.resourcemanager.fs.state-store.retry-policy-spec
Handling deprecation for mapreduce.reduce.skip.maxgroups
Handling deprecation for dfs.client.use.datanode.hostname
Handling deprecation for fs.trash.interval
Handling deprecation for mapreduce.job.name
Handling deprecation for mapreduce.am.max-attempts
Handling deprecation for mapreduce.jobtracker.heartbeats.in.second
Handling deprecation for yarn.resourcemanager.zk-num-retries
Handling deprecation for s3.blocksize
Handling deprecation for dfs.datanode.data.dir
Handling deprecation for mapreduce.jobtracker.persist.jobstatus.active
Handling deprecation for mapreduce.reduce.shuffle.parallelcopies
Handling deprecation for fs.s3.buffer.dir
Handling deprecation for mapreduce.jobhistory.done-dir
Handling deprecation for hadoop.security.instrumentation.requires.admin
Handling deprecation for hadoop.registry.zk.retry.ceiling.ms
Handling deprecation for nfs.rtmax
Handling deprecation for dfs.datanode.data.dir.perm
Handling deprecation for yarn.resourcemanager.container.liveness-monitor.interval-ms
Handling deprecation for yarn.nodemanager.env-whitelist
Handling deprecation for dfs.namenode.backup.address
Handling deprecation for dfs.namenode.xattrs.enabled
Handling deprecation for dfs.datanode.readahead.bytes
Handling deprecation for mapreduce.jobhistory.cleaner.enable
Handling deprecation for dfs.client.block.write.retries
Handling deprecation for mapreduce.tasktracker.http.address
Handling deprecation for yarn.nodemanager.linux-container-executor.cgroups.hierarchy
Handling deprecation for ha.failover-controller.graceful-fence.connection.retries
Handling deprecation for yarn.resourcemanager.recovery.enabled
Handling deprecation for yarn.app.mapreduce.am.container.log.backups
Handling deprecation for dfs.namenode.safemode.threshold-pct
Handling deprecation for yarn.nodemanager.disk-health-checker.interval-ms
Handling deprecation for hadoop.security.java.secure.random.algorithm
Handling deprecation for dfs.namenode.list.cache.directives.num.responses
Handling deprecation for dfs.datanode.dns.nameserver
Handling deprecation for mapreduce.cluster.temp.dir
Handling deprecation for fs.s3a.max.total.tasks
Handling deprecation for mapreduce.reduce.maxattempts
Handling deprecation for mapreduce.client.submit.file.replication
Handling deprecation for mapreduce.shuffle.port
Handling deprecation for yarn.resourcemanager.resource-tracker.client.thread-count
Handling deprecation for dfs.namenode.replication.considerLoad
Handling deprecation for dfs.namenode.edits.journal-plugin.qjournal
Handling deprecation for dfs.client.write.exclude.nodes.cache.expiry.interval.millis
Handling deprecation for yarn.nodemanager.delete.thread-count
Handling deprecation for dfs.client.mmap.cache.timeout.ms
Handling deprecation for yarn.nodemanager.admin-env
Handling deprecation for io.skip.checksum.errors
Handling deprecation for yarn.timeline-service.hostname
Handling deprecation for yarn.resourcemanager.proxy-user-privileges.enabled
Handling deprecation for mapreduce.job.speculative.speculative-cap-total-tasks
Handling deprecation for yarn.acl.enable
Handling deprecation for fs.s3a.fast.upload
Handling deprecation for file.blocksize
Handling deprecation for mapreduce.job.speculative.slowtaskthreshold
Handling deprecation for ftp.replication
Handling deprecation for yarn.sharedcache.cleaner.initial-delay-mins
Handling deprecation for s3native.client-write-packet-size
Handling deprecation for hadoop.rpc.socket.factory.class.default
Handling deprecation for file.bytes-per-checksum
Handling deprecation for dfs.datanode.slow.io.warning.threshold.ms
Handling deprecation for io.seqfile.lazydecompress
Handling deprecation for mapreduce.task.skip.start.attempts
Handling deprecation for dfs.namenode.reject-unresolved-dn-topology-mapping
Handling deprecation for hadoop.common.configuration.version
Handling deprecation for yarn.resourcemanager.client.thread-count
Handling deprecation for dfs.datanode.drop.cache.behind.reads
Handling deprecation for yarn.sharedcache.admin.address
Handling deprecation for mapreduce.job.output.value.class
Handling deprecation for mapreduce.output.fileoutputformat.outputdir
Handling deprecation for mapreduce.jobtracker.taskcache.levels
Handling deprecation for yarn.nodemanager.linux-container-executor.nonsecure-mode.user-pattern
Handling deprecation for yarn.resourcemanager.zk-timeout-ms
Handling deprecation for yarn.resourcemanager.max-completed-applications
Handling deprecation for mapreduce.job.jvm.numtasks
Handling deprecation for yarn.sharedcache.cleaner.period-mins
Handling deprecation for mapreduce.jobtracker.tasktracker.maxblacklists
Handling deprecation for dfs.namenode.top.num.users
Handling deprecation for yarn.nodemanager.linux-container-executor.cgroups.mount
Handling deprecation for yarn.sharedcache.checksum.algo.impl
Handling deprecation for mapreduce.job.end-notification.max.retry.interval
Handling deprecation for mapreduce.job.acl-view-job
Handling deprecation for mapreduce.job.classloader
Handling deprecation for yarn.log-aggregation-enable
Handling deprecation for mapreduce.reduce.shuffle.fetch.retry.interval-ms
Handling deprecation for yarn.resourcemanager.nodemanager.minimum.version
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.size
Handling deprecation for yarn.app.mapreduce.am.job.task.listener.thread-count
Handling deprecation for yarn.app.mapreduce.am.resource.cpu-vcores
Handling deprecation for dfs.namenode.edit.log.autoroll.check.interval.ms
Handling deprecation for mapreduce.output.fileoutputformat.compress.type
Handling deprecation for hadoop.hdfs.configuration.version
Handling deprecation for hadoop.security.group.mapping.ldap.search.attr.member
Handling deprecation for yarn.nodemanager.log.retain-seconds
Handling deprecation for yarn.nodemanager.local-cache.max-files-per-directory
Handling deprecation for mapreduce.job.end-notification.retry.interval
Handling deprecation for hadoop.ssl.client.conf
Handling deprecation for yarn.sharedcache.root-dir
Handling deprecation for dfs.journalnode.https-address
Handling deprecation for mapreduce.reduce.shuffle.fetch.retry.timeout-ms
Handling deprecation for dfs.bytes-per-checksum
Handling deprecation for dfs.namenode.max.objects
Handling deprecation for mapreduce.tasktracker.instrumentation
Handling deprecation for dfs.datanode.max.transfer.threads
Handling deprecation for dfs.block.access.key.update.interval
Handling deprecation for mapreduce.jobtracker.jobhistory.task.numberprogresssplits
Handling deprecation for mapreduce.map.memory.mb
Handling deprecation for ha.failover-controller.new-active.rpc-timeout.ms
Handling deprecation for hadoop.ssl.hostname.verifier
Handling deprecation for dfs.client.read.shortcircuit
Handling deprecation for dfs.datanode.hdfs-blocks-metadata.enabled
Handling deprecation for mapreduce.tasktracker.healthchecker.interval
Handling deprecation for dfs.image.transfer.chunksize
Handling deprecation for mapreduce.tasktracker.taskmemorymanager.monitoringinterval
Handling deprecation for dfs.client.https.keystore.resource
Handling deprecation for yarn.resourcemanager.connect.retry-interval.ms
Handling deprecation for yarn.timeline-service.webapp.address
Handling deprecation for s3native.blocksize
Handling deprecation for yarn.scheduler.minimum-allocation-mb
Handling deprecation for yarn.sharedcache.cleaner.resource-sleep-ms
Handling deprecation for net.topology.impl
Handling deprecation for dfs.client.failover.sleep.base.millis
Handling deprecation for dfs.permissions.superusergroup
Handling deprecation for io.seqfile.compress.blocksize
Handling deprecation for hadoop.registry.zk.retry.times
Handling deprecation for fs.AbstractFileSystem.ftp.impl
Handling deprecation for dfs.namenode.checkpoint.edits.dir
Handling deprecation for mapreduce.job.running.reduce.limit
Handling deprecation for dfs.blockreport.initialDelay
Handling deprecation for dfs.namenode.heartbeat.recheck-interval
Handling deprecation for dfs.namenode.safemode.extension
Handling deprecation for yarn.scheduler.maximum-allocation-mb
Handling deprecation for mapreduce.job.reduce.shuffle.consumer.plugin.class
Handling deprecation for yarn.nodemanager.vmem-check-enabled
Handling deprecation for mapreduce.task.io.sort.factor
Handling deprecation for mapreduce.jobtracker.persist.jobstatus.dir
Handling deprecation for dfs.client.failover.sleep.max.millis
Handling deprecation for dfs.namenode.delegation.key.update-interval
Handling deprecation for hadoop.rpc.protection
Handling deprecation for fs.permissions.umask-mode
Handling deprecation for fs.s3.sleepTimeSeconds
Handling deprecation for ha.health-monitor.rpc-timeout.ms
Handling deprecation for hadoop.http.staticuser.user
Handling deprecation for fs.s3a.connection.maximum
Handling deprecation for yarn.nodemanager.linux-container-executor.nonsecure-mode.limit-users
Handling deprecation for fs.s3a.paging.maximum
Handling deprecation for fs.AbstractFileSystem.viewfs.impl
Handling deprecation for fs.ftp.host
Handling deprecation for yarn.nodemanager.linux-container-executor.nonsecure-mode.local-user
Handling deprecation for fs.s3a.impl
Handling deprecation for hadoop.http.authentication.kerberos.keytab
Handling deprecation for dfs.namenode.fs-limits.max-blocks-per-file
Handling deprecation for mapreduce.tasktracker.http.threads
Handling deprecation for mapreduce.tasktracker.dns.nameserver
Handling deprecation for yarn.resourcemanager.am-rm-tokens.master-key-rolling-interval-secs
Handling deprecation for dfs.client.block.write.replace-datanode-on-failure.enable
Handling deprecation for io.compression.codec.bzip2.library
Handling deprecation for mapreduce.map.skip.maxrecords
Handling deprecation for dfs.client.use.legacy.blockreader.local
Handling deprecation for dfs.namenode.checkpoint.dir
Handling deprecation for dfs.namenode.top.windows.minutes
Handling deprecation for mapreduce.job.maxtaskfailures.per.tracker
Handling deprecation for net.topology.node.switch.mapping.impl
Handling deprecation for mapreduce.shuffle.max.connections
Handling deprecation for mapreduce.jobhistory.loadedjobs.cache.size
Handling deprecation for dfs.storage.policy.enabled
Handling deprecation for yarn.client.application-client-protocol.poll-interval-ms
Handling deprecation for yarn.nodemanager.localizer.address
Handling deprecation for dfs.namenode.list.cache.pools.num.responses
Handling deprecation for nfs.server.port
Handling deprecation for mapreduce.client.output.filter
Handling deprecation for yarn.timeline-service.client.best-effort
Handling deprecation for ha.zookeeper.parent-znode
Handling deprecation for mapreduce.jobtracker.persist.jobstatus.hours
Handling deprecation for yarn.sharedcache.admin.thread-count
Handling deprecation for yarn.nodemanager.resource.cpu-vcores
Handling deprecation for dfs.datanode.block-pinning.enabled
Handling deprecation for mapreduce.jobhistory.http.policy
Handling deprecation for yarn.resourcemanager.webapp.delegation-token-auth-filter.enabled
Handling deprecation for mapreduce.job.speculative.retry-after-no-speculate
Handling deprecation for fs.s3a.attempts.maximum
Handling deprecation for s3native.stream-buffer-size
Handling deprecation for io.seqfile.local.dir
Handling deprecation for yarn.log-aggregation.retain-check-interval-seconds
Handling deprecation for fs.s3n.multipart.copy.block.size
Handling deprecation for dfs.encrypt.data.transfer.cipher.key.bitlength
Handling deprecation for dfs.datanode.sync.behind.writes
Handling deprecation for yarn.resourcemanager.zk-acl
Handling deprecation for hadoop.ssl.keystores.factory.class
Handling deprecation for mapreduce.job.split.metainfo.maxsize
Handling deprecation for fs.s3.maxRetries
Handling deprecation for hadoop.security.random.device.file.path
Handling deprecation for yarn.client.nodemanager-connect.max-wait-ms
Handling deprecation for dfs.namenode.stale.datanode.interval
Handling deprecation for mapreduce.task.io.sort.mb
Handling deprecation for yarn.resourcemanager.zk-state-store.parent-path
Handling deprecation for yarn.app.mapreduce.client-am.ipc.max-retries
Handling deprecation for fs.client.resolve.remote.symlinks
Handling deprecation for yarn.nodemanager.linux-container-executor.cgroups.strict-resource-usage
Handling deprecation for hadoop.ssl.enabled.protocols
Handling deprecation for mapreduce.reduce.cpu.vcores
Handling deprecation for yarn.client.failover-retries
Handling deprecation for mapreduce.jobhistory.address
Handling deprecation for hadoop.ssl.enabled
Handling deprecation for dfs.replication.max
Handling deprecation for dfs.namenode.name.dir
Handling deprecation for dfs.datanode.https.address
Handling deprecation for ipc.client.kill.max
Handling deprecation for mapreduce.job.committer.setup.cleanup.needed
Handling deprecation for dfs.client.domain.socket.data.traffic
Handling deprecation for yarn.nodemanager.localizer.cache.target-size-mb
Handling deprecation for yarn.resourcemanager.admin.client.thread-count
Handling deprecation for dfs.block.access.token.enable
Handling deprecation for mapreduce.job.speculative.retry-after-speculate
Handling deprecation for dfs.datanode.address
Handling deprecation for mapreduce.jobtracker.restart.recover
Handling deprecation for ipc.client.connect.max.retries
Handling deprecation for yarn.timeline-service.store-class
Handling deprecation for dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
Handling deprecation for hadoop.tmp.dir
Handling deprecation for dfs.datanode.handler.count
Handling deprecation for yarn.resourcemanager.ha.automatic-failover.embedded
Handling deprecation for yarn.timeline-service.ttl-ms
Handling deprecation for mapreduce.task.profile.map.params
Handling deprecation for yarn.resourcemanager.nodemanagers.heartbeat-interval-ms
Handling deprecation for mapreduce.map.speculative
Handling deprecation for yarn.timeline-service.recovery.enabled
Handling deprecation for mapreduce.job.map.class
Handling deprecation for dfs.namenode.resource.checked.volumes.minimum
Handling deprecation for yarn.nodemanager.recovery.dir
Handling deprecation for mapreduce.job.counters.max
Handling deprecation for yarn.resourcemanager.keytab
Handling deprecation for dfs.namenode.max.extra.edits.segments.retained
Handling deprecation for dfs.webhdfs.user.provider.user.pattern
Handling deprecation for dfs.client.mmap.enabled
Handling deprecation for mapreduce.map.log.level
Handling deprecation for dfs.client.file-block-storage-locations.timeout.millis
Handling deprecation for yarn.client.max-cached-nodemanagers-proxies
Handling deprecation for yarn.app.mapreduce.am.scheduler.heartbeat.interval-ms
Handling deprecation for hadoop.fuse.timer.period
Handling deprecation for fs.trash.checkpoint.interval
Handling deprecation for yarn.sharedcache.app-checker.class
Handling deprecation for dfs.journalnode.http-address
Handling deprecation for yarn.app.mapreduce.am.staging-dir
Handling deprecation for mapreduce.tasktracker.local.dir.minspacestart
Handling deprecation for yarn.nm.liveness-monitor.expiry-interval-ms
Handling deprecation for ha.health-monitor.check-interval.ms
Handling deprecation for mapreduce.reduce.shuffle.merge.percent
Handling deprecation for dfs.namenode.retrycache.heap.percent
Handling deprecation for yarn.nodemanager.docker-container-executor.exec-name
Handling deprecation for ipc.client.connect.timeout
Handling deprecation for yarn.resourcemanager.fs.state-store.retry-interval-ms
Handling deprecation for mapreduce.output.fileoutputformat.compress
Handling deprecation for yarn.nodemanager.local-dirs
Handling deprecation for yarn.nodemanager.recovery.enabled
Handling deprecation for io.native.lib.available
Handling deprecation for yarn.sharedcache.store.in-memory.staleness-period-mins
Handling deprecation for yarn.resourcemanager.am.max-attempts
Handling deprecation for s3.replication
Handling deprecation for mapreduce.input.fileinputformat.inputdir
Handling deprecation for fs.AbstractFileSystem.har.impl
Handling deprecation for dfs.image.compress
Handling deprecation for mapreduce.job.running.map.limit
Handling deprecation for mapreduce.reduce.input.buffer.percent
Handling deprecation for yarn.nodemanager.webapp.address
Handling deprecation for dfs.datanode.available-space-volume-choosing-policy.balanced-space-preference-fraction
Handling deprecation for dfs.namenode.edit.log.autoroll.multiplier.threshold
Handling deprecation for hadoop.security.group.mapping.ldap.ssl
Handling deprecation for dfs.namenode.checkpoint.check.period
Handling deprecation for fs.defaultFS
Handling deprecation for fs.s3a.multipart.size
Handling deprecation for dfs.client.slow.io.warning.threshold.ms
Handling deprecation for yarn.app.mapreduce.am.job.committer.commit-window
Handling deprecation for hadoop.security.group.mapping.ldap.search.attr.group.name
Handling deprecation for yarn.nodemanager.disk-health-checker.max-disk-utilization-per-disk-percentage
Handling deprecation for yarn.nodemanager.container-monitor.procfs-tree.smaps-based-rss.enabled
Handling deprecation for mapreduce.job.submithostname
Handling deprecation for mapreduce.map.sort.spill.percent
Handling deprecation for hadoop.security.crypto.codec.classes.aes.ctr.nopadding
Handling deprecation for dfs.namenode.http-address
Handling deprecation for hadoop.security.groups.negative-cache.secs
Handling deprecation for hadoop.ssl.server.conf
Handling deprecation for mapreduce.ifile.readahead
Handling deprecation for s3native.replication
Handling deprecation for yarn.client.nodemanager-client-async.thread-pool-max-size
Handling deprecation for mapreduce.jobtracker.staging.root.dir
Handling deprecation for mapreduce.jobhistory.admin.address
Handling deprecation for dfs.namenode.startup.delay.block.deletion.sec
Handling deprecation for yarn.nodemanager.health-checker.interval-ms
Handling deprecation for dfs.namenode.checkpoint.max-retries
Handling deprecation for s3.stream-buffer-size
Handling deprecation for ftp.client-write-packet-size
Handling deprecation for dfs.datanode.fsdatasetcache.max.threads.per.volume
Handling deprecation for mapreduce.output.fileoutputformat.compress.codec
Handling deprecation for yarn.timeline-service.keytab
Handling deprecation for yarn.sharedcache.store.in-memory.initial-delay-mins
Handling deprecation for mapreduce.jobhistory.webapp.address
Handling deprecation for mapreduce.task.userlog.limit.kb
Handling deprecation for mapreduce.reduce.shuffle.fetch.retry.enabled
Handling deprecation for yarn.app.mapreduce.task.container.log.backups
Handling deprecation for dfs.heartbeat.interval
Handling deprecation for ha.zookeeper.session-timeout.ms
Handling deprecation for fs.s3a.connection.ssl.enabled
Handling deprecation for yarn.sharedcache.webapp.address
Handling deprecation for hadoop.http.authentication.signature.secret.file
Handling deprecation for hadoop.fuse.connection.timeout
Handling deprecation for mapreduce.input.fileinputformat.numinputfiles
Handling deprecation for yarn.nodemanager.log-aggregation.compression-type
Handling deprecation for ipc.server.max.connections
Handling deprecation for yarn.resourcemanager.work-preserving-recovery.scheduling-wait-ms
Handling deprecation for yarn.nodemanager.log-dirs
Handling deprecation for yarn.app.mapreduce.am.resource.mb
Handling deprecation for hadoop.security.groups.cache.secs
Handling deprecation for mapreduce.job.speculative.minimum-allowed-tasks
Handling deprecation for yarn.nodemanager.container-monitor.interval-ms
Handling deprecation for dfs.datanode.cache.revocation.timeout.ms
Handling deprecation for mapreduce.jobhistory.recovery.store.class
Handling deprecation for mapreduce.task.combine.progress.records
Handling deprecation for s3.client-write-packet-size
Handling deprecation for mapreduce.jobtracker.instrumentation
Handling deprecation for dfs.replication
Handling deprecation for mapreduce.shuffle.transfer.buffer.size
Handling deprecation for hadoop.security.group.mapping.ldap.directory.search.timeout
Handling deprecation for dfs.datanode.available-space-volume-choosing-policy.balanced-space-threshold
Handling deprecation for hadoop.work.around.non.threadsafe.getpwuid
Handling deprecation for yarn.app.mapreduce.client-am.ipc.max-retries-on-timeouts
Handling deprecation for yarn.nodemanager.address
Handling deprecation for mapreduce.tasktracker.taskcontroller
Handling deprecation for mapreduce.tasktracker.indexcache.mb
Handling deprecation for yarn.scheduler.maximum-allocation-vcores
Handling deprecation for mapreduce.job.reduces
Handling deprecation for yarn.nodemanager.sleep-delay-before-sigkill.ms
Handling deprecation for yarn.timeline-service.address
Handling deprecation for yarn.resourcemanager.configuration.provider-class
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.expiry
Handling deprecation for yarn.sharedcache.enabled
Handling deprecation for tfile.io.chunk.size
Handling deprecation for mapreduce.job.acl-modify-job
Handling deprecation for hadoop.registry.zk.session.timeout.ms
Handling deprecation for fs.automatic.close
Handling deprecation for ha.health-monitor.sleep-after-disconnect.ms
Handling deprecation for mapreduce.tasktracker.reduce.tasks.maximum
Handling deprecation for mapreduce.input.fileinputformat.list-status.num-threads
Handling deprecation for dfs.datanode.directoryscan.threads
Handling deprecation for dfs.datanode.directoryscan.interval
Handling deprecation for dfs.namenode.acls.enabled
Handling deprecation for dfs.client.short.circuit.replica.stale.threshold.ms
Handling deprecation for hadoop.http.authentication.token.validity
Handling deprecation for fs.s3.block.size
Handling deprecation for ha.failover-controller.graceful-fence.rpc-timeout.ms
Handling deprecation for mapreduce.tasktracker.local.dir.minspacekill
Handling deprecation for dfs.namenode.resource.du.reserved
Handling deprecation for mapreduce.jobhistory.cleaner.interval-ms
Handling deprecation for dfs.namenode.datanode.registration.ip-hostname-check
Handling deprecation for mapreduce.jobhistory.intermediate-done-dir
Handling deprecation for mapreduce.jobtracker.http.address
Handling deprecation for dfs.namenode.backup.http-address
Handling deprecation for dfs.namenode.edits.noeditlogchannelflush
Handling deprecation for mapreduce.reduce.shuffle.input.buffer.percent
Handling deprecation for mapreduce.map.maxattempts
Handling deprecation for yarn.http.policy
Handling deprecation for dfs.namenode.audit.loggers
Handling deprecation for hadoop.security.groups.cache.warn.after.ms
Handling deprecation for io.serializations
Handling deprecation for mapreduce.tasktracker.outofband.heartbeat
Handling deprecation for mapreduce.reduce.shuffle.read.timeout
Handling deprecation for hadoop.security.crypto.buffer.size
Handling deprecation for mapreduce.reduce.skip.proc.count.autoincr
Handling deprecation for mapreduce.ifile.readahead.bytes
Handling deprecation for dfs.http.policy
Handling deprecation for hadoop.registry.secure
Handling deprecation for dfs.namenode.safemode.min.datanodes
Handling deprecation for dfs.client.file-block-storage-locations.num-threads
Handling deprecation for mapreduce.cluster.local.dir
Handling deprecation for mapreduce.tasktracker.report.address
Handling deprecation for dfs.namenode.secondary.https-address
Handling deprecation for hadoop.kerberos.kinit.command
Handling deprecation for yarn.timeline-service.http-authentication.type
Handling deprecation for dfs.block.access.token.lifetime
Handling deprecation for dfs.webhdfs.enabled
Handling deprecation for dfs.namenode.delegation.token.max-lifetime
Handling deprecation for dfs.namenode.avoid.write.stale.datanode
Handling deprecation for dfs.datanode.drop.cache.behind.writes
Handling deprecation for yarn.log-aggregation.retain-seconds
Handling deprecation for mapreduce.job.complete.cancel.delegation.tokens
Handling deprecation for mapreduce.local.clientfactory.class.name
Handling deprecation for mapreduce.shuffle.connection-keep-alive.timeout
Handling deprecation for dfs.namenode.num.extra.edits.retained
Handling deprecation for yarn.scheduler.minimum-allocation-vcores
Handling deprecation for ipc.client.connect.max.retries.on.timeouts
Handling deprecation for yarn.timeline-service.client.retry-interval-ms
Handling deprecation for yarn.timeline-service.client.max-retries
Handling deprecation for fs.s3n.block.size
Handling deprecation for mapreduce.job.map.output.collector.class
Handling deprecation for ha.health-monitor.connect-retry-interval.ms
Handling deprecation for mapreduce.shuffle.max.threads
Handling deprecation for nfs.exports.allowed.hosts
Handling deprecation for dfs.client.mmap.cache.size
Handling deprecation for mapreduce.tasktracker.map.tasks.maximum
Handling deprecation for io.file.buffer.size
Handling deprecation for dfs.client.datanode-restart.timeout
Handling deprecation for io.mapfile.bloom.size
Handling deprecation for hadoop.security.kms.client.authentication.retry-count
Handling deprecation for dfs.namenode.checkpoint.txns
Handling deprecation for ipc.client.connect.retry.interval
Handling deprecation for dfs.client-write-packet-size
Handling deprecation for mapreduce.reduce.shuffle.connect.timeout
Handling deprecation for yarn.resourcemanager.fs.state-store.uri
Handling deprecation for fs.swift.impl
Handling deprecation for hadoop.registry.zk.connection.timeout.ms
Handling deprecation for mapred.queue.default.acl-administer-jobs
Handling deprecation for mapreduce.job.submithostaddress
Handling deprecation for dfs.cachereport.intervalMsec
Handling deprecation for yarn.app.mapreduce.shuffle.log.backups
Handling deprecation for yarn.app.mapreduce.am.container.log.limit.kb
Handling deprecation for yarn.nodemanager.resourcemanager.minimum.version
Handling deprecation for ftp.blocksize
Handling deprecation for yarn.resourcemanager.address
Handling deprecation for file.stream-buffer-size
Handling deprecation for yarn.resourcemanager.scheduler.monitor.enable
Handling deprecation for mapreduce.job.ubertask.maxreduces
Handling deprecation for nfs.allow.insecure.ports
Handling deprecation for yarn.sharedcache.nm.uploader.thread-count
Handling deprecation for ipc.client.idlethreshold
Handling deprecation for ftp.stream-buffer-size
Handling deprecation for yarn.sharedcache.client-server.address
Handling deprecation for dfs.client.failover.connection.retries.on.timeouts
Handling deprecation for dfs.namenode.replication.work.multiplier.per.iteration
Handling deprecation for hadoop.http.authentication.simple.anonymous.allowed
Handling deprecation for hadoop.security.authorization
Handling deprecation for yarn.client.nodemanager-connect.retry-interval-ms
Handling deprecation for yarn.am.liveness-monitor.expiry-interval-ms
Handling deprecation for fs.har.impl.disable.cache
Handling deprecation for yarn.nodemanager.linux-container-executor.resources-handler.class
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.read-cache-size
Handling deprecation for hadoop.security.authentication
Handling deprecation for dfs.image.compression.codec
Handling deprecation for mapreduce.task.files.preserve.failedtasks
Handling deprecation for dfs.client.read.shortcircuit.streams.cache.size
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.path
Handling deprecation for mapreduce.job.reduce.slowstart.completedmaps
Handling deprecation for mapreduce.jobhistory.minicluster.fixed.ports
Handling deprecation for file.replication
Handling deprecation for yarn.resourcemanager.ha.automatic-failover.enabled
Handling deprecation for mapreduce.job.userlog.retain.hours
Handling deprecation for mapreduce.jobhistory.joblist.cache.size
Handling deprecation for dfs.namenode.accesstime.precision
Handling deprecation for yarn.resourcemanager.work-preserving-recovery.enabled
Handling deprecation for dfs.namenode.fs-limits.max-xattrs-per-inode
Handling deprecation for io.mapfile.bloom.error.rate
Handling deprecation for yarn.resourcemanager.store.class
Handling deprecation for dfs.image.transfer.timeout
Handling deprecation for yarn.timeline-service.leveldb-state-store.path
Handling deprecation for nfs.wtmax
Handling deprecation for mapreduce.job.combine.class
Handling deprecation for dfs.namenode.support.allow.format
Handling deprecation for fs.s3a.multipart.purge
Handling deprecation for dfs.secondary.namenode.kerberos.internal.spnego.principal
Handling deprecation for fs.s3a.connection.establish.timeout
Handling deprecation for dfs.stream-buffer-size
Handling deprecation for dfs.namenode.invalidate.work.pct.per.iteration
Handling deprecation for yarn.nodemanager.container-executor.class
Handling deprecation for fs.s3a.multipart.purge.age
Handling deprecation for yarn.resourcemanager.scheduler.client.thread-count
Handling deprecation for dfs.namenode.top.enabled
Handling deprecation for yarn.app.mapreduce.shuffle.log.separate
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.low-watermark
Handling deprecation for fs.s3a.fast.buffer.size
Handling deprecation for hadoop.user.group.static.mapping.overrides
Handling deprecation for tfile.fs.input.buffer.size
Handling deprecation for dfs.client.cached.conn.retry
Handling deprecation for hadoop.http.authentication.type
Handling deprecation for dfs.namenode.list.encryption.zones.num.responses
Handling deprecation for mapreduce.map.cpu.vcores
Handling deprecation for dfs.namenode.path.based.cache.refresh.interval.ms
Handling deprecation for dfs.namenode.decommission.interval
Handling deprecation for dfs.namenode.fs-limits.max-directory-items
Handling deprecation for yarn.resourcemanager.zk-retry-interval-ms
Handling deprecation for ftp.bytes-per-checksum
Handling deprecation for dfs.ha.log-roll.period
Handling deprecation for dfs.user.home.dir.prefix
Handling deprecation for ipc.client.fallback-to-simple-auth-allowed
Handling deprecation for yarn.nodemanager.pmem-check-enabled
Handling deprecation for yarn.nodemanager.remote-app-log-dir
Handling deprecation for dfs.namenode.inotify.max.events.per.rpc
Handling deprecation for mapreduce.task.profile.maps
Handling deprecation for mapreduce.shuffle.ssl.file.buffer.size
Handling deprecation for mapreduce.tasktracker.healthchecker.script.timeout
Handling deprecation for yarn.timeline-service.webapp.https.address
Handling deprecation for yarn.nodemanager.resource.percentage-physical-cpu-limit
Handling deprecation for yarn.app.mapreduce.am.command-opts
Handling deprecation for dfs.namenode.fs-limits.max-xattr-size
Handling deprecation for dfs.datanode.http.address
Handling deprecation for dfs.namenode.blocks.per.postponedblocks.rescan
Handling deprecation for yarn.sharedcache.nm.uploader.replication.factor
Handling deprecation for hadoop.registry.zk.root
Handling deprecation for hadoop.jetty.logs.serve.aliases
Handling deprecation for yarn.client.failover-proxy-provider
Handling deprecation for mapreduce.jobhistory.admin.acl
Handling deprecation for yarn.app.mapreduce.am.hard-kill-timeout-ms
Handling deprecation for yarn.nodemanager.remote-app-log-dir-suffix
Handling deprecation for mapreduce.jobhistory.principal
Handling deprecation for yarn.resourcemanager.webapp.address
Handling deprecation for mapreduce.jobhistory.recovery.enable
Handling deprecation for yarn.sharedcache.store.in-memory.check-period-mins
Handling deprecation for nfs.mountd.port
Handling deprecation for mapreduce.reduce.merge.inmem.threshold
Handling deprecation for fs.df.interval
Handling deprecation for yarn.timeline-service.enabled
Handling deprecation for mapreduce.jobtracker.jobhistory.lru.cache.size
Handling deprecation for mapreduce.task.profile
Handling deprecation for mapreduce.job.output.key.class
Handling deprecation for yarn.nodemanager.hostname
Handling deprecation for dfs.namenode.num.checkpoints.retained
Handling deprecation for mapreduce.job.queuename
Handling deprecation for mapreduce.jobhistory.max-age-ms
Handling deprecation for mapreduce.job.token.tracking.ids.enabled
Handling deprecation for yarn.nodemanager.localizer.client.thread-count
Handling deprecation for yarn.sharedcache.uploader.server.thread-count
Handling deprecation for dfs.client.mmap.retry.timeout.ms
Handling deprecation for mapreduce.jobhistory.move.thread-count
Handling deprecation for dfs.permissions.enabled
Handling deprecation for dfs.blockreport.split.threshold
Handling deprecation for fs.AbstractFileSystem.hdfs.impl
Handling deprecation for dfs.datanode.balance.bandwidthPerSec
Handling deprecation for dfs.block.scanner.volume.bytes.per.second
Handling deprecation for hadoop.http.filter.initializers
Handling deprecation for yarn.timeline-service.http-authentication.simple.anonymous.allowed
Handling deprecation for dfs.default.chunk.view.size
Handling deprecation for yarn.sharedcache.client-server.thread-count
Handling deprecation for yarn.resourcemanager.resource-tracker.address
Handling deprecation for mapreduce.job.working.dir
Handling deprecation for mapreduce.jobhistory.datestring.cache.size
Handling deprecation for mapreduce.task.profile.params
Handling deprecation for dfs.namenode.decommission.blocks.per.interval
Handling deprecation for dfs.namenode.handler.count
Handling deprecation for dfs.image.transfer.bandwidthPerSec
Handling deprecation for rpc.metrics.quantile.enable
Handling deprecation for mapreduce.jobtracker.expire.trackers.interval
Handling deprecation for mapreduce.task.timeout
Handling deprecation for yarn.app.mapreduce.client.max-retries
Handling deprecation for yarn.nodemanager.resource.memory-mb
Handling deprecation for yarn.nodemanager.disk-health-checker.min-healthy-disks
Handling deprecation for dfs.datanode.failed.volumes.tolerated
Handling deprecation for yarn.timeline-service.handler-thread-count
Handling deprecation for ipc.server.listen.queue.size
Handling deprecation for fs.s3a.threads.max
Handling deprecation for yarn.resourcemanager.connect.max-wait.ms
Handling deprecation for mapreduce.fileoutputcommitter.algorithm.version
Handling deprecation for mapreduce.framework.name
Handling deprecation for mapreduce.map.skip.proc.count.autoincr
Handling deprecation for mapreduce.job.max.split.locations
Handling deprecation for yarn.resourcemanager.scheduler.class
Handling deprecation for yarn.resourcemanager.system-metrics-publisher.enabled
Handling deprecation for dfs.blocksize
Handling deprecation for yarn.sharedcache.nested-level
Handling deprecation for mapreduce.shuffle.connection-keep-alive.enable
Handling deprecation for fs.s3a.threads.keepalivetime
Handling deprecation for fs.s3a.connection.timeout
Handling deprecation for file.client-write-packet-size
Handling deprecation for ha.failover-controller.cli-check.rpc-timeout.ms
Handling deprecation for ha.zookeeper.acl
Handling deprecation for dfs.namenode.write.stale.datanode.ratio
Handling deprecation for dfs.encrypt.data.transfer
Handling deprecation for dfs.datanode.shared.file.descriptor.paths
Handling deprecation for mapreduce.input.lineinputformat.linespermap
Handling deprecation for yarn.resourcemanager.delayed.delegation-token.removal-interval-ms
Handling deprecation for yarn.nodemanager.localizer.fetch.thread-count
Handling deprecation for dfs.client.failover.max.attempts
Handling deprecation for yarn.resourcemanager.scheduler.address
Handling deprecation for dfs.client.read.shortcircuit.streams.cache.expiry.ms
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.start-time-write-cache-size
Handling deprecation for yarn.nodemanager.health-checker.script.timeout-ms
Handling deprecation for yarn.resourcemanager.fs.state-store.num-retries
Handling deprecation for hadoop.ssl.require.client.cert
Handling deprecation for hadoop.security.uid.cache.secs
Handling deprecation for mapreduce.jobhistory.keytab
Handling deprecation for dfs.client.read.shortcircuit.skip.checksum
Handling deprecation for yarn.resourcemanager.ha.automatic-failover.zk-base-path
Handling deprecation for mapreduce.shuffle.ssl.enabled
Handling deprecation for mapreduce.reduce.log.level
Handling deprecation for hadoop.registry.rm.enabled
Handling deprecation for mapreduce.tasktracker.dns.interface
Handling deprecation for yarn.resourcemanager.system-metrics-publisher.dispatcher.pool-size
Handling deprecation for mapreduce.job.speculative.speculative-cap-running-tasks
Handling deprecation for dfs.datanode.block.id.layout.upgrade.threads
Handling deprecation for dfs.datanode.use.datanode.hostname
Handling deprecation for dfs.client.context
Handling deprecation for yarn.resourcemanager.ha.enabled
Handling deprecation for mapred.reducer.new-api
Handling deprecation for dfs.namenode.delegation.token.renew-interval
Handling deprecation for dfs.blockreport.intervalMsec
Handling deprecation for fs.s3a.multipart.threshold
Handling deprecation for mapreduce.reduce.shuffle.memory.limit.percent
Handling deprecation for dfs.https.server.keystore.resource
Handling deprecation for io.map.index.skip
Handling deprecation for mapreduce.job.hdfs-servers
Handling deprecation for mapreduce.jobtracker.taskscheduler
Handling deprecation for dfs.namenode.kerberos.internal.spnego.principal
Handling deprecation for yarn.resourcemanager.state-store.max-completed-applications
Handling deprecation for mapreduce.map.output.compress
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.num.refill.threads
Handling deprecation for fs.s3n.multipart.uploads.block.size
Handling deprecation for mapreduce.task.merge.progress.records
Handling deprecation for dfs.datanode.dns.interface
Handling deprecation for map.sort.class
Handling deprecation for yarn.nodemanager.aux-services.mapreduce_shuffle.class
Handling deprecation for tfile.fs.output.buffer.size
Handling deprecation for fs.du.interval
Handling deprecation for dfs.client.failover.connection.retries
Handling deprecation for dfs.namenode.top.window.num.buckets
Handling deprecation for mapreduce.job.dir
Handling deprecation for fs.s3a.buffer.dir
Handling deprecation for mapreduce.reduce.shuffle.retry-delay.max.ms
Handling deprecation for yarn.sharedcache.uploader.server.address
Handling deprecation for mapreduce.client.progressmonitor.pollinterval
Handling deprecation for yarn.app.mapreduce.shuffle.log.limit.kb
Handling deprecation for dfs.datanode.max.locked.memory
Handling deprecation for dfs.namenode.retrycache.expirytime.millis
Handling deprecation for dfs.datanode.scan.period.hours
Handling deprecation for dfs.client.block.write.replace-datanode-on-failure.best-effort
Handling deprecation for mapreduce.jobhistory.move.interval-ms
Handling deprecation for dfs.ha.fencing.ssh.connect-timeout
Handling deprecation for yarn.nodemanager.log-aggregation.roll-monitoring-interval-seconds
Handling deprecation for dfs.namenode.fs-limits.max-component-length
Handling deprecation for hadoop.registry.zk.quorum
Handling deprecation for dfs.namenode.enable.retrycache
Handling deprecation for dfs.datanode.du.reserved
Handling deprecation for yarn.timeline-service.state-store-class
Handling deprecation for dfs.datanode.ipc.address
Handling deprecation for hadoop.registry.system.acls
Handling deprecation for dfs.client.block.write.replace-datanode-on-failure.policy
Handling deprecation for dfs.namenode.path.based.cache.retry.interval.ms
Handling deprecation for hadoop.security.crypto.cipher.suite
Handling deprecation for dfs.ha.tail-edits.period
Handling deprecation for mapreduce.task.profile.reduce.params
Handling deprecation for hadoop.registry.jaas.context
Handling deprecation for yarn.resourcemanager.hostname
Handling deprecation for mapreduce.reduce.memory.mb
Handling deprecation for hadoop.security.group.mapping.ldap.search.filter.group
Handling deprecation for hadoop.http.authentication.kerberos.principal
Handling deprecation for hadoop.security.group.mapping.ldap.search.filter.user
Handling deprecation for yarn.nodemanager.disk-health-checker.min-free-space-per-disk-mb
Handling deprecation for dfs.namenode.edits.dir
Handling deprecation for yarn.client.failover-retries-on-socket-timeouts
Handling deprecation for dfs.namenode.decommission.max.concurrent.tracked.nodes
Handling deprecation for mapreduce.client.completion.pollinterval
Handling deprecation for dfs.namenode.name.dir.restore
Handling deprecation for dfs.namenode.secondary.http-address
Handling deprecation for mapreduce.jobhistory.recovery.store.leveldb.path
Handling deprecation for yarn.sharedcache.store.class
Handling deprecation for s3.bytes-per-checksum
Handling deprecation for yarn.nodemanager.windows-container.cpu-limit.enabled
Handling deprecation for yarn.resourcemanager.webapp.https.address
Handling deprecation for yarn.nodemanager.vmem-pmem-ratio
Handling deprecation for dfs.namenode.checkpoint.period
Handling deprecation for dfs.ha.automatic-failover.enabled
Submitting tokens for job: job_local881914384_0002
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.fs.FileContext.getAbstractFileSystem(FileContext.java:331)
Handling deprecation for all properties in config...
Handling deprecation for mapreduce.jobtracker.address
Handling deprecation for yarn.resourcemanager.scheduler.monitor.policies
Handling deprecation for dfs.namenode.resource.check.interval
Handling deprecation for mapreduce.jobhistory.client.thread-count
Handling deprecation for yarn.app.mapreduce.am.containerlauncher.threadpool-initial-size
Handling deprecation for mapred.child.java.opts
Handling deprecation for mapreduce.jobtracker.retiredjobs.cache.size
Handling deprecation for dfs.client.https.need-auth
Handling deprecation for yarn.admin.acl
Handling deprecation for yarn.app.mapreduce.am.job.committer.cancel-timeout
Handling deprecation for mapreduce.job.emit-timeline-data
Handling deprecation for fs.ftp.host.port
Handling deprecation for dfs.namenode.avoid.read.stale.datanode
Handling deprecation for dfs.journalnode.rpc-address
Handling deprecation for mapreduce.job.end-notification.retry.attempts
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.ttl-interval-ms
Handling deprecation for yarn.resourcemanager.leveldb-state-store.path
Handling deprecation for mapred.mapper.new-api
Handling deprecation for yarn.ipc.rpc.class
Handling deprecation for ipc.client.connection.maxidletime
Handling deprecation for yarn.nodemanager.process-kill-wait.ms
Handling deprecation for mapreduce.cluster.acls.enabled
Handling deprecation for mapreduce.jobtracker.handler.count
Handling deprecation for io.map.index.interval
Handling deprecation for dfs.namenode.https-address
Handling deprecation for mapreduce.task.profile.reduces
Handling deprecation for fs.s3n.multipart.uploads.enabled
Handling deprecation for io.seqfile.sorter.recordlimit
Handling deprecation for mapreduce.job.ubertask.maxmaps
Handling deprecation for mapreduce.tasktracker.tasks.sleeptimebeforesigkill
Handling deprecation for hadoop.util.hash.type
Handling deprecation for dfs.namenode.replication.min
Handling deprecation for yarn.nodemanager.container-manager.thread-count
Handling deprecation for mapreduce.jobtracker.jobhistory.block.size
Handling deprecation for dfs.namenode.fs-limits.min-block-size
Handling deprecation for mapreduce.app-submission.cross-platform
Handling deprecation for fs.AbstractFileSystem.file.impl
Handling deprecation for net.topology.script.number.args
Handling deprecation for yarn.resourcemanager.container-tokens.master-key-rolling-interval-secs
Handling deprecation for mapreduce.map.output.compress.codec
Handling deprecation for mapreduce.job.reducer.preempt.delay.sec
Handling deprecation for s3native.bytes-per-checksum
Handling deprecation for dfs.namenode.path.based.cache.block.map.allocation.percent
Handling deprecation for yarn.nodemanager.windows-container.memory-limit.enabled
Handling deprecation for mapreduce.input.fileinputformat.split.minsize
Handling deprecation for hadoop.security.group.mapping
Handling deprecation for mapreduce.jobtracker.system.dir
Handling deprecation for mapreduce.job.end-notification.max.attempts
Handling deprecation for mapreduce.reduce.markreset.buffer.percent
Handling deprecation for dfs.datanode.cache.revocation.polling.ms
Handling deprecation for mapreduce.reduce.speculative
Handling deprecation for yarn.nodemanager.localizer.cache.cleanup.interval-ms
Handling deprecation for dfs.namenode.lazypersist.file.scrub.interval.sec
Handling deprecation for fs.s3a.threads.core
Handling deprecation for mapreduce.jobhistory.recovery.store.fs.uri
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.start-time-read-cache-size
Handling deprecation for hadoop.registry.zk.retry.interval.ms
Handling deprecation for yarn.nodemanager.keytab
Handling deprecation for dfs.namenode.replication.interval
Handling deprecation for yarn.resourcemanager.admin.address
Handling deprecation for mapreduce.job.maps
Handling deprecation for nfs.dump.dir
Handling deprecation for mapreduce.job.user.name
Handling deprecation for mapreduce.jobtracker.maxtasks.perjob
Handling deprecation for mapreduce.job.ubertask.enable
Handling deprecation for mapreduce.job.reduce.class
Handling deprecation for yarn.nodemanager.delete.debug-delay-sec
Handling deprecation for yarn.timeline-service.ttl-enable
Handling deprecation for yarn.resourcemanager.fs.state-store.retry-policy-spec
Handling deprecation for mapreduce.reduce.skip.maxgroups
Handling deprecation for dfs.client.use.datanode.hostname
Handling deprecation for fs.trash.interval
Handling deprecation for mapreduce.job.name
Handling deprecation for mapreduce.am.max-attempts
Handling deprecation for mapreduce.jobtracker.heartbeats.in.second
Handling deprecation for yarn.resourcemanager.zk-num-retries
Handling deprecation for s3.blocksize
Handling deprecation for dfs.datanode.data.dir
Handling deprecation for mapreduce.jobtracker.persist.jobstatus.active
Handling deprecation for mapreduce.reduce.shuffle.parallelcopies
Handling deprecation for fs.s3.buffer.dir
Handling deprecation for mapreduce.jobhistory.done-dir
Handling deprecation for hadoop.security.instrumentation.requires.admin
Handling deprecation for hadoop.registry.zk.retry.ceiling.ms
Handling deprecation for nfs.rtmax
Handling deprecation for dfs.datanode.data.dir.perm
Handling deprecation for yarn.resourcemanager.container.liveness-monitor.interval-ms
Handling deprecation for yarn.nodemanager.env-whitelist
Handling deprecation for dfs.namenode.backup.address
Handling deprecation for dfs.namenode.xattrs.enabled
Handling deprecation for dfs.datanode.readahead.bytes
Handling deprecation for mapreduce.jobhistory.cleaner.enable
Handling deprecation for dfs.client.block.write.retries
Handling deprecation for mapreduce.tasktracker.http.address
Handling deprecation for yarn.nodemanager.linux-container-executor.cgroups.hierarchy
Handling deprecation for ha.failover-controller.graceful-fence.connection.retries
Handling deprecation for yarn.resourcemanager.recovery.enabled
Handling deprecation for yarn.app.mapreduce.am.container.log.backups
Handling deprecation for dfs.namenode.safemode.threshold-pct
Handling deprecation for yarn.nodemanager.disk-health-checker.interval-ms
Handling deprecation for hadoop.security.java.secure.random.algorithm
Handling deprecation for dfs.namenode.list.cache.directives.num.responses
Handling deprecation for dfs.datanode.dns.nameserver
Handling deprecation for mapreduce.cluster.temp.dir
Handling deprecation for fs.s3a.max.total.tasks
Handling deprecation for mapreduce.reduce.maxattempts
Handling deprecation for mapreduce.client.submit.file.replication
Handling deprecation for mapreduce.shuffle.port
Handling deprecation for yarn.resourcemanager.resource-tracker.client.thread-count
Handling deprecation for dfs.namenode.replication.considerLoad
Handling deprecation for dfs.namenode.edits.journal-plugin.qjournal
Handling deprecation for dfs.client.write.exclude.nodes.cache.expiry.interval.millis
Handling deprecation for yarn.nodemanager.delete.thread-count
Handling deprecation for dfs.client.mmap.cache.timeout.ms
Handling deprecation for yarn.nodemanager.admin-env
Handling deprecation for io.skip.checksum.errors
Handling deprecation for yarn.timeline-service.hostname
Handling deprecation for yarn.resourcemanager.proxy-user-privileges.enabled
Handling deprecation for mapreduce.job.speculative.speculative-cap-total-tasks
Handling deprecation for yarn.acl.enable
Handling deprecation for fs.s3a.fast.upload
Handling deprecation for file.blocksize
Handling deprecation for mapreduce.job.speculative.slowtaskthreshold
Handling deprecation for ftp.replication
Handling deprecation for yarn.sharedcache.cleaner.initial-delay-mins
Handling deprecation for s3native.client-write-packet-size
Handling deprecation for hadoop.rpc.socket.factory.class.default
Handling deprecation for file.bytes-per-checksum
Handling deprecation for dfs.datanode.slow.io.warning.threshold.ms
Handling deprecation for io.seqfile.lazydecompress
Handling deprecation for mapreduce.task.skip.start.attempts
Handling deprecation for dfs.namenode.reject-unresolved-dn-topology-mapping
Handling deprecation for hadoop.common.configuration.version
Handling deprecation for yarn.resourcemanager.client.thread-count
Handling deprecation for dfs.datanode.drop.cache.behind.reads
Handling deprecation for yarn.sharedcache.admin.address
Handling deprecation for mapreduce.job.output.value.class
Handling deprecation for mapreduce.output.fileoutputformat.outputdir
Handling deprecation for mapreduce.jobtracker.taskcache.levels
Handling deprecation for yarn.nodemanager.linux-container-executor.nonsecure-mode.user-pattern
Handling deprecation for yarn.resourcemanager.zk-timeout-ms
Handling deprecation for yarn.resourcemanager.max-completed-applications
Handling deprecation for mapreduce.job.jvm.numtasks
Handling deprecation for yarn.sharedcache.cleaner.period-mins
Handling deprecation for mapreduce.jobtracker.tasktracker.maxblacklists
Handling deprecation for dfs.namenode.top.num.users
Handling deprecation for yarn.nodemanager.linux-container-executor.cgroups.mount
Handling deprecation for yarn.sharedcache.checksum.algo.impl
Handling deprecation for mapreduce.job.end-notification.max.retry.interval
Handling deprecation for mapreduce.job.acl-view-job
Handling deprecation for mapreduce.job.classloader
Handling deprecation for yarn.log-aggregation-enable
Handling deprecation for mapreduce.reduce.shuffle.fetch.retry.interval-ms
Handling deprecation for yarn.resourcemanager.nodemanager.minimum.version
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.size
Handling deprecation for yarn.app.mapreduce.am.job.task.listener.thread-count
Handling deprecation for yarn.app.mapreduce.am.resource.cpu-vcores
Handling deprecation for dfs.namenode.edit.log.autoroll.check.interval.ms
Handling deprecation for mapreduce.output.fileoutputformat.compress.type
Handling deprecation for hadoop.hdfs.configuration.version
Handling deprecation for hadoop.security.group.mapping.ldap.search.attr.member
Handling deprecation for yarn.nodemanager.log.retain-seconds
Handling deprecation for yarn.nodemanager.local-cache.max-files-per-directory
Handling deprecation for mapreduce.job.end-notification.retry.interval
Handling deprecation for hadoop.ssl.client.conf
Handling deprecation for yarn.sharedcache.root-dir
Handling deprecation for dfs.journalnode.https-address
Handling deprecation for mapreduce.reduce.shuffle.fetch.retry.timeout-ms
Handling deprecation for dfs.bytes-per-checksum
Handling deprecation for dfs.namenode.max.objects
Handling deprecation for mapreduce.tasktracker.instrumentation
Handling deprecation for dfs.datanode.max.transfer.threads
Handling deprecation for dfs.block.access.key.update.interval
Handling deprecation for mapreduce.jobtracker.jobhistory.task.numberprogresssplits
Handling deprecation for mapreduce.map.memory.mb
Handling deprecation for ha.failover-controller.new-active.rpc-timeout.ms
Handling deprecation for hadoop.ssl.hostname.verifier
Handling deprecation for dfs.client.read.shortcircuit
Handling deprecation for dfs.datanode.hdfs-blocks-metadata.enabled
Handling deprecation for mapreduce.tasktracker.healthchecker.interval
Handling deprecation for dfs.image.transfer.chunksize
Handling deprecation for mapreduce.tasktracker.taskmemorymanager.monitoringinterval
Handling deprecation for dfs.client.https.keystore.resource
Handling deprecation for yarn.resourcemanager.connect.retry-interval.ms
Handling deprecation for yarn.timeline-service.webapp.address
Handling deprecation for s3native.blocksize
Handling deprecation for yarn.scheduler.minimum-allocation-mb
Handling deprecation for yarn.sharedcache.cleaner.resource-sleep-ms
Handling deprecation for net.topology.impl
Handling deprecation for dfs.client.failover.sleep.base.millis
Handling deprecation for dfs.permissions.superusergroup
Handling deprecation for io.seqfile.compress.blocksize
Handling deprecation for hadoop.registry.zk.retry.times
Handling deprecation for fs.AbstractFileSystem.ftp.impl
Handling deprecation for dfs.namenode.checkpoint.edits.dir
Handling deprecation for mapreduce.job.running.reduce.limit
Handling deprecation for dfs.blockreport.initialDelay
Handling deprecation for dfs.namenode.heartbeat.recheck-interval
Handling deprecation for dfs.namenode.safemode.extension
Handling deprecation for yarn.scheduler.maximum-allocation-mb
Handling deprecation for mapreduce.job.reduce.shuffle.consumer.plugin.class
Handling deprecation for yarn.nodemanager.vmem-check-enabled
Handling deprecation for mapreduce.task.io.sort.factor
Handling deprecation for mapreduce.jobtracker.persist.jobstatus.dir
Handling deprecation for dfs.client.failover.sleep.max.millis
Handling deprecation for dfs.namenode.delegation.key.update-interval
Handling deprecation for hadoop.rpc.protection
Handling deprecation for fs.permissions.umask-mode
Handling deprecation for fs.s3.sleepTimeSeconds
Handling deprecation for ha.health-monitor.rpc-timeout.ms
Handling deprecation for hadoop.http.staticuser.user
Handling deprecation for fs.s3a.connection.maximum
Handling deprecation for yarn.nodemanager.linux-container-executor.nonsecure-mode.limit-users
Handling deprecation for fs.s3a.paging.maximum
Handling deprecation for fs.AbstractFileSystem.viewfs.impl
Handling deprecation for fs.ftp.host
Handling deprecation for yarn.nodemanager.linux-container-executor.nonsecure-mode.local-user
Handling deprecation for fs.s3a.impl
Handling deprecation for hadoop.http.authentication.kerberos.keytab
Handling deprecation for dfs.namenode.fs-limits.max-blocks-per-file
Handling deprecation for mapreduce.tasktracker.http.threads
Handling deprecation for mapreduce.tasktracker.dns.nameserver
Handling deprecation for yarn.resourcemanager.am-rm-tokens.master-key-rolling-interval-secs
Handling deprecation for dfs.client.block.write.replace-datanode-on-failure.enable
Handling deprecation for io.compression.codec.bzip2.library
Handling deprecation for mapreduce.map.skip.maxrecords
Handling deprecation for dfs.client.use.legacy.blockreader.local
Handling deprecation for dfs.namenode.checkpoint.dir
Handling deprecation for dfs.namenode.top.windows.minutes
Handling deprecation for mapreduce.job.maxtaskfailures.per.tracker
Handling deprecation for net.topology.node.switch.mapping.impl
Handling deprecation for mapreduce.shuffle.max.connections
Handling deprecation for mapreduce.jobhistory.loadedjobs.cache.size
Handling deprecation for dfs.storage.policy.enabled
Handling deprecation for yarn.client.application-client-protocol.poll-interval-ms
Handling deprecation for yarn.nodemanager.localizer.address
Handling deprecation for dfs.namenode.list.cache.pools.num.responses
Handling deprecation for nfs.server.port
Handling deprecation for mapreduce.client.output.filter
Handling deprecation for yarn.timeline-service.client.best-effort
Handling deprecation for ha.zookeeper.parent-znode
Handling deprecation for mapreduce.jobtracker.persist.jobstatus.hours
Handling deprecation for yarn.sharedcache.admin.thread-count
Handling deprecation for yarn.nodemanager.resource.cpu-vcores
Handling deprecation for dfs.datanode.block-pinning.enabled
Handling deprecation for mapreduce.jobhistory.http.policy
Handling deprecation for yarn.resourcemanager.webapp.delegation-token-auth-filter.enabled
Handling deprecation for mapreduce.job.speculative.retry-after-no-speculate
Handling deprecation for fs.s3a.attempts.maximum
Handling deprecation for s3native.stream-buffer-size
Handling deprecation for io.seqfile.local.dir
Handling deprecation for yarn.log-aggregation.retain-check-interval-seconds
Handling deprecation for fs.s3n.multipart.copy.block.size
Handling deprecation for dfs.encrypt.data.transfer.cipher.key.bitlength
Handling deprecation for dfs.datanode.sync.behind.writes
Handling deprecation for yarn.resourcemanager.zk-acl
Handling deprecation for hadoop.ssl.keystores.factory.class
Handling deprecation for mapreduce.job.split.metainfo.maxsize
Handling deprecation for fs.s3.maxRetries
Handling deprecation for hadoop.security.random.device.file.path
Handling deprecation for yarn.client.nodemanager-connect.max-wait-ms
Handling deprecation for dfs.namenode.stale.datanode.interval
Handling deprecation for mapreduce.task.io.sort.mb
Handling deprecation for yarn.resourcemanager.zk-state-store.parent-path
Handling deprecation for yarn.app.mapreduce.client-am.ipc.max-retries
Handling deprecation for fs.client.resolve.remote.symlinks
Handling deprecation for yarn.nodemanager.linux-container-executor.cgroups.strict-resource-usage
Handling deprecation for hadoop.ssl.enabled.protocols
Handling deprecation for mapreduce.reduce.cpu.vcores
Handling deprecation for yarn.client.failover-retries
Handling deprecation for mapreduce.jobhistory.address
Handling deprecation for hadoop.ssl.enabled
Handling deprecation for dfs.replication.max
Handling deprecation for dfs.namenode.name.dir
Handling deprecation for dfs.datanode.https.address
Handling deprecation for ipc.client.kill.max
Handling deprecation for mapreduce.job.committer.setup.cleanup.needed
Handling deprecation for dfs.client.domain.socket.data.traffic
Handling deprecation for yarn.nodemanager.localizer.cache.target-size-mb
Handling deprecation for yarn.resourcemanager.admin.client.thread-count
Handling deprecation for dfs.block.access.token.enable
Handling deprecation for mapreduce.job.speculative.retry-after-speculate
Handling deprecation for dfs.datanode.address
Handling deprecation for mapreduce.jobtracker.restart.recover
Handling deprecation for ipc.client.connect.max.retries
Handling deprecation for yarn.timeline-service.store-class
Handling deprecation for dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
Handling deprecation for hadoop.tmp.dir
Handling deprecation for dfs.datanode.handler.count
Handling deprecation for yarn.resourcemanager.ha.automatic-failover.embedded
Handling deprecation for yarn.timeline-service.ttl-ms
Handling deprecation for mapreduce.task.profile.map.params
Handling deprecation for yarn.resourcemanager.nodemanagers.heartbeat-interval-ms
Handling deprecation for mapreduce.map.speculative
Handling deprecation for yarn.timeline-service.recovery.enabled
Handling deprecation for mapreduce.job.map.class
Handling deprecation for dfs.namenode.resource.checked.volumes.minimum
Handling deprecation for yarn.nodemanager.recovery.dir
Handling deprecation for mapreduce.job.counters.max
Handling deprecation for yarn.resourcemanager.keytab
Handling deprecation for dfs.namenode.max.extra.edits.segments.retained
Handling deprecation for dfs.webhdfs.user.provider.user.pattern
Handling deprecation for dfs.client.mmap.enabled
Handling deprecation for mapreduce.map.log.level
Handling deprecation for dfs.client.file-block-storage-locations.timeout.millis
Handling deprecation for yarn.client.max-cached-nodemanagers-proxies
Handling deprecation for yarn.app.mapreduce.am.scheduler.heartbeat.interval-ms
Handling deprecation for hadoop.fuse.timer.period
Handling deprecation for fs.trash.checkpoint.interval
Handling deprecation for yarn.sharedcache.app-checker.class
Handling deprecation for dfs.journalnode.http-address
Handling deprecation for yarn.app.mapreduce.am.staging-dir
Handling deprecation for mapreduce.tasktracker.local.dir.minspacestart
Handling deprecation for yarn.nm.liveness-monitor.expiry-interval-ms
Handling deprecation for ha.health-monitor.check-interval.ms
Handling deprecation for mapreduce.reduce.shuffle.merge.percent
Handling deprecation for dfs.namenode.retrycache.heap.percent
Handling deprecation for yarn.nodemanager.docker-container-executor.exec-name
Handling deprecation for ipc.client.connect.timeout
Handling deprecation for yarn.resourcemanager.fs.state-store.retry-interval-ms
Handling deprecation for mapreduce.output.fileoutputformat.compress
Handling deprecation for yarn.nodemanager.local-dirs
Handling deprecation for yarn.nodemanager.recovery.enabled
Handling deprecation for io.native.lib.available
Handling deprecation for yarn.sharedcache.store.in-memory.staleness-period-mins
Handling deprecation for yarn.resourcemanager.am.max-attempts
Handling deprecation for s3.replication
Handling deprecation for mapreduce.input.fileinputformat.inputdir
Handling deprecation for fs.AbstractFileSystem.har.impl
Handling deprecation for dfs.image.compress
Handling deprecation for mapreduce.job.running.map.limit
Handling deprecation for mapreduce.reduce.input.buffer.percent
Handling deprecation for yarn.nodemanager.webapp.address
Handling deprecation for dfs.datanode.available-space-volume-choosing-policy.balanced-space-preference-fraction
Handling deprecation for dfs.namenode.edit.log.autoroll.multiplier.threshold
Handling deprecation for hadoop.security.group.mapping.ldap.ssl
Handling deprecation for dfs.namenode.checkpoint.check.period
Handling deprecation for fs.defaultFS
Handling deprecation for fs.s3a.multipart.size
Handling deprecation for dfs.client.slow.io.warning.threshold.ms
Handling deprecation for yarn.app.mapreduce.am.job.committer.commit-window
Handling deprecation for hadoop.security.group.mapping.ldap.search.attr.group.name
Handling deprecation for yarn.nodemanager.disk-health-checker.max-disk-utilization-per-disk-percentage
Handling deprecation for yarn.nodemanager.container-monitor.procfs-tree.smaps-based-rss.enabled
Handling deprecation for mapreduce.job.submithostname
Handling deprecation for mapreduce.map.sort.spill.percent
Handling deprecation for hadoop.security.crypto.codec.classes.aes.ctr.nopadding
Handling deprecation for dfs.namenode.http-address
Handling deprecation for hadoop.security.groups.negative-cache.secs
Handling deprecation for hadoop.ssl.server.conf
Handling deprecation for mapreduce.ifile.readahead
Handling deprecation for s3native.replication
Handling deprecation for yarn.client.nodemanager-client-async.thread-pool-max-size
Handling deprecation for mapreduce.jobtracker.staging.root.dir
Handling deprecation for mapreduce.jobhistory.admin.address
Handling deprecation for dfs.namenode.startup.delay.block.deletion.sec
Handling deprecation for yarn.nodemanager.health-checker.interval-ms
Handling deprecation for dfs.namenode.checkpoint.max-retries
Handling deprecation for s3.stream-buffer-size
Handling deprecation for ftp.client-write-packet-size
Handling deprecation for dfs.datanode.fsdatasetcache.max.threads.per.volume
Handling deprecation for mapreduce.output.fileoutputformat.compress.codec
Handling deprecation for yarn.timeline-service.keytab
Handling deprecation for yarn.sharedcache.store.in-memory.initial-delay-mins
Handling deprecation for mapreduce.jobhistory.webapp.address
Handling deprecation for mapreduce.task.userlog.limit.kb
Handling deprecation for mapreduce.reduce.shuffle.fetch.retry.enabled
Handling deprecation for yarn.app.mapreduce.task.container.log.backups
Handling deprecation for dfs.heartbeat.interval
Handling deprecation for ha.zookeeper.session-timeout.ms
Handling deprecation for fs.s3a.connection.ssl.enabled
Handling deprecation for yarn.sharedcache.webapp.address
Handling deprecation for hadoop.http.authentication.signature.secret.file
Handling deprecation for hadoop.fuse.connection.timeout
Handling deprecation for mapreduce.input.fileinputformat.numinputfiles
Handling deprecation for yarn.nodemanager.log-aggregation.compression-type
Handling deprecation for ipc.server.max.connections
Handling deprecation for yarn.resourcemanager.work-preserving-recovery.scheduling-wait-ms
Handling deprecation for yarn.nodemanager.log-dirs
Handling deprecation for yarn.app.mapreduce.am.resource.mb
Handling deprecation for hadoop.security.groups.cache.secs
Handling deprecation for mapreduce.job.speculative.minimum-allowed-tasks
Handling deprecation for yarn.nodemanager.container-monitor.interval-ms
Handling deprecation for dfs.datanode.cache.revocation.timeout.ms
Handling deprecation for mapreduce.jobhistory.recovery.store.class
Handling deprecation for mapreduce.task.combine.progress.records
Handling deprecation for s3.client-write-packet-size
Handling deprecation for mapreduce.jobtracker.instrumentation
Handling deprecation for dfs.replication
Handling deprecation for mapreduce.shuffle.transfer.buffer.size
Handling deprecation for hadoop.security.group.mapping.ldap.directory.search.timeout
Handling deprecation for dfs.datanode.available-space-volume-choosing-policy.balanced-space-threshold
Handling deprecation for hadoop.work.around.non.threadsafe.getpwuid
Handling deprecation for yarn.app.mapreduce.client-am.ipc.max-retries-on-timeouts
Handling deprecation for yarn.nodemanager.address
Handling deprecation for mapreduce.tasktracker.taskcontroller
Handling deprecation for mapreduce.tasktracker.indexcache.mb
Handling deprecation for yarn.scheduler.maximum-allocation-vcores
Handling deprecation for mapreduce.job.reduces
Handling deprecation for yarn.nodemanager.sleep-delay-before-sigkill.ms
Handling deprecation for yarn.timeline-service.address
Handling deprecation for yarn.resourcemanager.configuration.provider-class
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.expiry
Handling deprecation for yarn.sharedcache.enabled
Handling deprecation for tfile.io.chunk.size
Handling deprecation for mapreduce.job.acl-modify-job
Handling deprecation for hadoop.registry.zk.session.timeout.ms
Handling deprecation for fs.automatic.close
Handling deprecation for ha.health-monitor.sleep-after-disconnect.ms
Handling deprecation for mapreduce.tasktracker.reduce.tasks.maximum
Handling deprecation for mapreduce.input.fileinputformat.list-status.num-threads
Handling deprecation for dfs.datanode.directoryscan.threads
Handling deprecation for dfs.datanode.directoryscan.interval
Handling deprecation for dfs.namenode.acls.enabled
Handling deprecation for dfs.client.short.circuit.replica.stale.threshold.ms
Handling deprecation for hadoop.http.authentication.token.validity
Handling deprecation for fs.s3.block.size
Handling deprecation for ha.failover-controller.graceful-fence.rpc-timeout.ms
Handling deprecation for mapreduce.tasktracker.local.dir.minspacekill
Handling deprecation for dfs.namenode.resource.du.reserved
Handling deprecation for mapreduce.jobhistory.cleaner.interval-ms
Handling deprecation for dfs.namenode.datanode.registration.ip-hostname-check
Handling deprecation for mapreduce.jobhistory.intermediate-done-dir
Handling deprecation for mapreduce.jobtracker.http.address
Handling deprecation for dfs.namenode.backup.http-address
Handling deprecation for dfs.namenode.edits.noeditlogchannelflush
Handling deprecation for mapreduce.reduce.shuffle.input.buffer.percent
Handling deprecation for mapreduce.map.maxattempts
Handling deprecation for yarn.http.policy
Handling deprecation for dfs.namenode.audit.loggers
Handling deprecation for hadoop.security.groups.cache.warn.after.ms
Handling deprecation for io.serializations
Handling deprecation for mapreduce.tasktracker.outofband.heartbeat
Handling deprecation for mapreduce.reduce.shuffle.read.timeout
Handling deprecation for hadoop.security.crypto.buffer.size
Handling deprecation for mapreduce.reduce.skip.proc.count.autoincr
Handling deprecation for mapreduce.ifile.readahead.bytes
Handling deprecation for dfs.http.policy
Handling deprecation for hadoop.registry.secure
Handling deprecation for dfs.namenode.safemode.min.datanodes
Handling deprecation for dfs.client.file-block-storage-locations.num-threads
Handling deprecation for mapreduce.cluster.local.dir
Handling deprecation for mapreduce.tasktracker.report.address
Handling deprecation for dfs.namenode.secondary.https-address
Handling deprecation for hadoop.kerberos.kinit.command
Handling deprecation for yarn.timeline-service.http-authentication.type
Handling deprecation for dfs.block.access.token.lifetime
Handling deprecation for dfs.webhdfs.enabled
Handling deprecation for dfs.namenode.delegation.token.max-lifetime
Handling deprecation for dfs.namenode.avoid.write.stale.datanode
Handling deprecation for dfs.datanode.drop.cache.behind.writes
Handling deprecation for yarn.log-aggregation.retain-seconds
Handling deprecation for mapreduce.job.complete.cancel.delegation.tokens
Handling deprecation for mapreduce.local.clientfactory.class.name
Handling deprecation for mapreduce.shuffle.connection-keep-alive.timeout
Handling deprecation for dfs.namenode.num.extra.edits.retained
Handling deprecation for yarn.scheduler.minimum-allocation-vcores
Handling deprecation for ipc.client.connect.max.retries.on.timeouts
Handling deprecation for yarn.timeline-service.client.retry-interval-ms
Handling deprecation for yarn.timeline-service.client.max-retries
Handling deprecation for fs.s3n.block.size
Handling deprecation for mapreduce.job.map.output.collector.class
Handling deprecation for ha.health-monitor.connect-retry-interval.ms
Handling deprecation for mapreduce.shuffle.max.threads
Handling deprecation for nfs.exports.allowed.hosts
Handling deprecation for dfs.client.mmap.cache.size
Handling deprecation for mapreduce.tasktracker.map.tasks.maximum
Handling deprecation for io.file.buffer.size
Handling deprecation for dfs.client.datanode-restart.timeout
Handling deprecation for io.mapfile.bloom.size
Handling deprecation for hadoop.security.kms.client.authentication.retry-count
Handling deprecation for dfs.namenode.checkpoint.txns
Handling deprecation for ipc.client.connect.retry.interval
Handling deprecation for dfs.client-write-packet-size
Handling deprecation for mapreduce.reduce.shuffle.connect.timeout
Handling deprecation for yarn.resourcemanager.fs.state-store.uri
Handling deprecation for fs.swift.impl
Handling deprecation for hadoop.registry.zk.connection.timeout.ms
Handling deprecation for mapred.queue.default.acl-administer-jobs
Handling deprecation for mapreduce.job.submithostaddress
Handling deprecation for dfs.cachereport.intervalMsec
Handling deprecation for yarn.app.mapreduce.shuffle.log.backups
Handling deprecation for yarn.app.mapreduce.am.container.log.limit.kb
Handling deprecation for yarn.nodemanager.resourcemanager.minimum.version
Handling deprecation for ftp.blocksize
Handling deprecation for yarn.resourcemanager.address
Handling deprecation for file.stream-buffer-size
Handling deprecation for yarn.resourcemanager.scheduler.monitor.enable
Handling deprecation for mapreduce.job.ubertask.maxreduces
Handling deprecation for nfs.allow.insecure.ports
Handling deprecation for yarn.sharedcache.nm.uploader.thread-count
Handling deprecation for ipc.client.idlethreshold
Handling deprecation for ftp.stream-buffer-size
Handling deprecation for yarn.sharedcache.client-server.address
Handling deprecation for dfs.client.failover.connection.retries.on.timeouts
Handling deprecation for dfs.namenode.replication.work.multiplier.per.iteration
Handling deprecation for hadoop.http.authentication.simple.anonymous.allowed
Handling deprecation for hadoop.security.authorization
Handling deprecation for yarn.client.nodemanager-connect.retry-interval-ms
Handling deprecation for yarn.am.liveness-monitor.expiry-interval-ms
Handling deprecation for fs.har.impl.disable.cache
Handling deprecation for yarn.nodemanager.linux-container-executor.resources-handler.class
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.read-cache-size
Handling deprecation for hadoop.security.authentication
Handling deprecation for dfs.image.compression.codec
Handling deprecation for mapreduce.task.files.preserve.failedtasks
Handling deprecation for dfs.client.read.shortcircuit.streams.cache.size
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.path
Handling deprecation for mapreduce.job.reduce.slowstart.completedmaps
Handling deprecation for mapreduce.jobhistory.minicluster.fixed.ports
Handling deprecation for file.replication
Handling deprecation for yarn.resourcemanager.ha.automatic-failover.enabled
Handling deprecation for mapreduce.job.userlog.retain.hours
Handling deprecation for mapreduce.jobhistory.joblist.cache.size
Handling deprecation for dfs.namenode.accesstime.precision
Handling deprecation for yarn.resourcemanager.work-preserving-recovery.enabled
Handling deprecation for dfs.namenode.fs-limits.max-xattrs-per-inode
Handling deprecation for io.mapfile.bloom.error.rate
Handling deprecation for yarn.resourcemanager.store.class
Handling deprecation for dfs.image.transfer.timeout
Handling deprecation for yarn.timeline-service.leveldb-state-store.path
Handling deprecation for nfs.wtmax
Handling deprecation for mapreduce.job.combine.class
Handling deprecation for dfs.namenode.support.allow.format
Handling deprecation for fs.s3a.multipart.purge
Handling deprecation for dfs.secondary.namenode.kerberos.internal.spnego.principal
Handling deprecation for fs.s3a.connection.establish.timeout
Handling deprecation for dfs.stream-buffer-size
Handling deprecation for dfs.namenode.invalidate.work.pct.per.iteration
Handling deprecation for yarn.nodemanager.container-executor.class
Handling deprecation for fs.s3a.multipart.purge.age
Handling deprecation for yarn.resourcemanager.scheduler.client.thread-count
Handling deprecation for dfs.namenode.top.enabled
Handling deprecation for yarn.app.mapreduce.shuffle.log.separate
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.low-watermark
Handling deprecation for fs.s3a.fast.buffer.size
Handling deprecation for hadoop.user.group.static.mapping.overrides
Handling deprecation for tfile.fs.input.buffer.size
Handling deprecation for dfs.client.cached.conn.retry
Handling deprecation for hadoop.http.authentication.type
Handling deprecation for dfs.namenode.list.encryption.zones.num.responses
Handling deprecation for mapreduce.map.cpu.vcores
Handling deprecation for dfs.namenode.path.based.cache.refresh.interval.ms
Handling deprecation for dfs.namenode.decommission.interval
Handling deprecation for dfs.namenode.fs-limits.max-directory-items
Handling deprecation for yarn.resourcemanager.zk-retry-interval-ms
Handling deprecation for ftp.bytes-per-checksum
Handling deprecation for dfs.ha.log-roll.period
Handling deprecation for dfs.user.home.dir.prefix
Handling deprecation for ipc.client.fallback-to-simple-auth-allowed
Handling deprecation for yarn.nodemanager.pmem-check-enabled
Handling deprecation for yarn.nodemanager.remote-app-log-dir
Handling deprecation for dfs.namenode.inotify.max.events.per.rpc
Handling deprecation for mapreduce.task.profile.maps
Handling deprecation for mapreduce.shuffle.ssl.file.buffer.size
Handling deprecation for mapreduce.tasktracker.healthchecker.script.timeout
Handling deprecation for yarn.timeline-service.webapp.https.address
Handling deprecation for yarn.nodemanager.resource.percentage-physical-cpu-limit
Handling deprecation for yarn.app.mapreduce.am.command-opts
Handling deprecation for dfs.namenode.fs-limits.max-xattr-size
Handling deprecation for dfs.datanode.http.address
Handling deprecation for dfs.namenode.blocks.per.postponedblocks.rescan
Handling deprecation for yarn.sharedcache.nm.uploader.replication.factor
Handling deprecation for hadoop.registry.zk.root
Handling deprecation for hadoop.jetty.logs.serve.aliases
Handling deprecation for yarn.client.failover-proxy-provider
Handling deprecation for mapreduce.jobhistory.admin.acl
Handling deprecation for yarn.app.mapreduce.am.hard-kill-timeout-ms
Handling deprecation for yarn.nodemanager.remote-app-log-dir-suffix
Handling deprecation for mapreduce.jobhistory.principal
Handling deprecation for yarn.resourcemanager.webapp.address
Handling deprecation for mapreduce.jobhistory.recovery.enable
Handling deprecation for yarn.sharedcache.store.in-memory.check-period-mins
Handling deprecation for nfs.mountd.port
Handling deprecation for mapreduce.reduce.merge.inmem.threshold
Handling deprecation for fs.df.interval
Handling deprecation for yarn.timeline-service.enabled
Handling deprecation for mapreduce.jobtracker.jobhistory.lru.cache.size
Handling deprecation for mapreduce.task.profile
Handling deprecation for mapreduce.job.output.key.class
Handling deprecation for yarn.nodemanager.hostname
Handling deprecation for dfs.namenode.num.checkpoints.retained
Handling deprecation for mapreduce.job.queuename
Handling deprecation for mapreduce.jobhistory.max-age-ms
Handling deprecation for mapreduce.job.token.tracking.ids.enabled
Handling deprecation for yarn.nodemanager.localizer.client.thread-count
Handling deprecation for yarn.sharedcache.uploader.server.thread-count
Handling deprecation for dfs.client.mmap.retry.timeout.ms
Handling deprecation for mapreduce.jobhistory.move.thread-count
Handling deprecation for dfs.permissions.enabled
Handling deprecation for dfs.blockreport.split.threshold
Handling deprecation for fs.AbstractFileSystem.hdfs.impl
Handling deprecation for dfs.datanode.balance.bandwidthPerSec
Handling deprecation for dfs.block.scanner.volume.bytes.per.second
Handling deprecation for hadoop.http.filter.initializers
Handling deprecation for yarn.timeline-service.http-authentication.simple.anonymous.allowed
Handling deprecation for dfs.default.chunk.view.size
Handling deprecation for yarn.sharedcache.client-server.thread-count
Handling deprecation for yarn.resourcemanager.resource-tracker.address
Handling deprecation for mapreduce.job.working.dir
Handling deprecation for mapreduce.jobhistory.datestring.cache.size
Handling deprecation for mapreduce.task.profile.params
Handling deprecation for dfs.namenode.decommission.blocks.per.interval
Handling deprecation for dfs.namenode.handler.count
Handling deprecation for dfs.image.transfer.bandwidthPerSec
Handling deprecation for rpc.metrics.quantile.enable
Handling deprecation for mapreduce.jobtracker.expire.trackers.interval
Handling deprecation for mapreduce.task.timeout
Handling deprecation for yarn.app.mapreduce.client.max-retries
Handling deprecation for yarn.nodemanager.resource.memory-mb
Handling deprecation for yarn.nodemanager.disk-health-checker.min-healthy-disks
Handling deprecation for dfs.datanode.failed.volumes.tolerated
Handling deprecation for yarn.timeline-service.handler-thread-count
Handling deprecation for ipc.server.listen.queue.size
Handling deprecation for fs.s3a.threads.max
Handling deprecation for yarn.resourcemanager.connect.max-wait.ms
Handling deprecation for mapreduce.fileoutputcommitter.algorithm.version
Handling deprecation for mapreduce.framework.name
Handling deprecation for mapreduce.map.skip.proc.count.autoincr
Handling deprecation for mapreduce.job.max.split.locations
Handling deprecation for yarn.resourcemanager.scheduler.class
Handling deprecation for yarn.resourcemanager.system-metrics-publisher.enabled
Handling deprecation for dfs.blocksize
Handling deprecation for yarn.sharedcache.nested-level
Handling deprecation for mapreduce.shuffle.connection-keep-alive.enable
Handling deprecation for fs.s3a.threads.keepalivetime
Handling deprecation for fs.s3a.connection.timeout
Handling deprecation for file.client-write-packet-size
Handling deprecation for ha.failover-controller.cli-check.rpc-timeout.ms
Handling deprecation for ha.zookeeper.acl
Handling deprecation for dfs.namenode.write.stale.datanode.ratio
Handling deprecation for dfs.encrypt.data.transfer
Handling deprecation for dfs.datanode.shared.file.descriptor.paths
Handling deprecation for mapreduce.input.lineinputformat.linespermap
Handling deprecation for yarn.resourcemanager.delayed.delegation-token.removal-interval-ms
Handling deprecation for yarn.nodemanager.localizer.fetch.thread-count
Handling deprecation for dfs.client.failover.max.attempts
Handling deprecation for yarn.resourcemanager.scheduler.address
Handling deprecation for dfs.client.read.shortcircuit.streams.cache.expiry.ms
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.start-time-write-cache-size
Handling deprecation for yarn.nodemanager.health-checker.script.timeout-ms
Handling deprecation for yarn.resourcemanager.fs.state-store.num-retries
Handling deprecation for hadoop.ssl.require.client.cert
Handling deprecation for hadoop.security.uid.cache.secs
Handling deprecation for mapreduce.jobhistory.keytab
Handling deprecation for dfs.client.read.shortcircuit.skip.checksum
Handling deprecation for yarn.resourcemanager.ha.automatic-failover.zk-base-path
Handling deprecation for mapreduce.shuffle.ssl.enabled
Handling deprecation for mapreduce.reduce.log.level
Handling deprecation for hadoop.registry.rm.enabled
Handling deprecation for mapreduce.tasktracker.dns.interface
Handling deprecation for yarn.resourcemanager.system-metrics-publisher.dispatcher.pool-size
Handling deprecation for mapreduce.job.speculative.speculative-cap-running-tasks
Handling deprecation for dfs.datanode.block.id.layout.upgrade.threads
Handling deprecation for dfs.datanode.use.datanode.hostname
Handling deprecation for dfs.client.context
Handling deprecation for yarn.resourcemanager.ha.enabled
Handling deprecation for mapred.reducer.new-api
Handling deprecation for dfs.namenode.delegation.token.renew-interval
Handling deprecation for dfs.blockreport.intervalMsec
Handling deprecation for fs.s3a.multipart.threshold
Handling deprecation for mapreduce.reduce.shuffle.memory.limit.percent
Handling deprecation for dfs.https.server.keystore.resource
Handling deprecation for io.map.index.skip
Handling deprecation for mapreduce.job.hdfs-servers
Handling deprecation for mapreduce.jobtracker.taskscheduler
Handling deprecation for dfs.namenode.kerberos.internal.spnego.principal
Handling deprecation for yarn.resourcemanager.state-store.max-completed-applications
Handling deprecation for mapreduce.map.output.compress
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.num.refill.threads
Handling deprecation for fs.s3n.multipart.uploads.block.size
Handling deprecation for mapreduce.task.merge.progress.records
Handling deprecation for dfs.datanode.dns.interface
Handling deprecation for map.sort.class
Handling deprecation for yarn.nodemanager.aux-services.mapreduce_shuffle.class
Handling deprecation for tfile.fs.output.buffer.size
Handling deprecation for fs.du.interval
Handling deprecation for dfs.client.failover.connection.retries
Handling deprecation for dfs.namenode.top.window.num.buckets
Handling deprecation for mapreduce.job.dir
Handling deprecation for fs.s3a.buffer.dir
Handling deprecation for mapreduce.reduce.shuffle.retry-delay.max.ms
Handling deprecation for yarn.sharedcache.uploader.server.address
Handling deprecation for mapreduce.client.progressmonitor.pollinterval
Handling deprecation for yarn.app.mapreduce.shuffle.log.limit.kb
Handling deprecation for dfs.datanode.max.locked.memory
Handling deprecation for dfs.namenode.retrycache.expirytime.millis
Handling deprecation for dfs.datanode.scan.period.hours
Handling deprecation for dfs.client.block.write.replace-datanode-on-failure.best-effort
Handling deprecation for mapreduce.jobhistory.move.interval-ms
Handling deprecation for dfs.ha.fencing.ssh.connect-timeout
Handling deprecation for yarn.nodemanager.log-aggregation.roll-monitoring-interval-seconds
Handling deprecation for dfs.namenode.fs-limits.max-component-length
Handling deprecation for hadoop.registry.zk.quorum
Handling deprecation for dfs.namenode.enable.retrycache
Handling deprecation for dfs.datanode.du.reserved
Handling deprecation for yarn.timeline-service.state-store-class
Handling deprecation for dfs.datanode.ipc.address
Handling deprecation for hadoop.registry.system.acls
Handling deprecation for dfs.client.block.write.replace-datanode-on-failure.policy
Handling deprecation for dfs.namenode.path.based.cache.retry.interval.ms
Handling deprecation for hadoop.security.crypto.cipher.suite
Handling deprecation for dfs.ha.tail-edits.period
Handling deprecation for mapreduce.task.profile.reduce.params
Handling deprecation for hadoop.registry.jaas.context
Handling deprecation for yarn.resourcemanager.hostname
Handling deprecation for mapreduce.reduce.memory.mb
Handling deprecation for hadoop.security.group.mapping.ldap.search.filter.group
Handling deprecation for hadoop.http.authentication.kerberos.principal
Handling deprecation for hadoop.security.group.mapping.ldap.search.filter.user
Handling deprecation for yarn.nodemanager.disk-health-checker.min-free-space-per-disk-mb
Handling deprecation for dfs.namenode.edits.dir
Handling deprecation for yarn.client.failover-retries-on-socket-timeouts
Handling deprecation for dfs.namenode.decommission.max.concurrent.tracked.nodes
Handling deprecation for mapreduce.client.completion.pollinterval
Handling deprecation for dfs.namenode.name.dir.restore
Handling deprecation for dfs.namenode.secondary.http-address
Handling deprecation for mapreduce.jobhistory.recovery.store.leveldb.path
Handling deprecation for yarn.sharedcache.store.class
Handling deprecation for s3.bytes-per-checksum
Handling deprecation for yarn.nodemanager.windows-container.cpu-limit.enabled
Handling deprecation for yarn.resourcemanager.webapp.https.address
Handling deprecation for yarn.nodemanager.vmem-pmem-ratio
Handling deprecation for dfs.namenode.checkpoint.period
Handling deprecation for dfs.ha.automatic-failover.enabled
The url to track the job: http://localhost:8080/
Running job: job_local881914384_0002
OutputCommitter set in config null
File Output Committer Algorithm version is 1
OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
/user/michaeljones/wcOutput/_temporary/0: masked=rwxr-xr-x
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones sending #35
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones got value #35
Call: mkdirs took 5ms
Starting mapper thread pool executor.
Max local threads: 1
Map tasks to process: 1
Waiting for map tasks
Starting task: attempt_local881914384_0002_m_000000_0
currentIndex 0   0:0
mapreduce.cluster.local.dir for child : /tmp/hadoop-michaeljones/mapred/local/localRunner//michaeljones/jobcache/job_local881914384_0002/attempt_local881914384_0002_m_000000_0
using new api for output committer
File Output Committer Algorithm version is 1
ProcfsBasedProcessTree currently is supported only on Linux.
 Using ResourceCalculatorProcessTree : null
Processing split: hdfs://localhost:9000/user/michaeljones/wcInput:0+50
Trying map output collector class: org.apache.hadoop.mapred.MapTask$MapOutputBuffer
(EQUATOR) 0 kvi 26214396(104857584)
mapreduce.task.io.sort.mb: 100
soft limit at 83886080
bufstart = 0; bufvoid = 104857600
kvstart = 26214396; length = 6553600
Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones sending #36
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones got value #36
Call: getBlockLocations took 2ms
newInfo = LocatedBlocks{
  fileLength=50
  underConstruction=false
  blocks=[LocatedBlock{BP-1045030256-10.0.0.2-1433119149314:blk_1073741825_1002; getBlockSize()=50; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-b42c5705-9ba4-4b14-b00b-f9194bb036f0,DISK]]}]
  lastLocatedBlock=LocatedBlock{BP-1045030256-10.0.0.2-1433119149314:blk_1073741825_1002; getBlockSize()=50; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-b42c5705-9ba4-4b14-b00b-f9194bb036f0,DISK]]}
  isLastBlockComplete=true}
Connecting to datanode 127.0.0.1:50010

Starting flush of map output
Spilling map output
bufstart = 0; bufend = 82; bufvoid = 104857600
kvstart = 26214396(104857584); kvend = 26214368(104857472); length = 29/6553600
Finished spill 0
Task:attempt_local881914384_0002_m_000000_0 is done. And is in the process of committing
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones sending #37
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones got value #37
Call: getFileInfo took 2ms
map
Task 'attempt_local881914384_0002_m_000000_0' done.
Finishing task: attempt_local881914384_0002_m_000000_0
map task executor complete.
Starting reduce thread pool executor.
Max local threads: 1
Reduce tasks to process: 1
Waiting for reduce tasks
Starting task: attempt_local881914384_0002_r_000000_0
currentIndex 0   0:0
mapreduce.cluster.local.dir for child : /tmp/hadoop-michaeljones/mapred/local/localRunner//michaeljones/jobcache/job_local881914384_0002/attempt_local881914384_0002_r_000000_0
using new api for output committer
File Output Committer Algorithm version is 1
ProcfsBasedProcessTree currently is supported only on Linux.
 Using ResourceCalculatorProcessTree : null
Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@4b72d916
MergerManager: memoryLimit=668309888, maxSingleShuffleLimit=167077472, mergeThreshold=441084544, ioSortFactor=10, memToMemMergeOutputsThreshold=10
attempt_local881914384_0002_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
Got 0 map completion events from 0
GetMapEventsThread about to sleep for 1000
LocalFetcher 2 going to fetch: attempt_local881914384_0002_m_000000_0
attempt_local881914384_0002_m_000000_0: Proceeding with shuffle since usedMemory (0) is lesser than memoryLimit (668309888).CommitMemory is (0)
localfetcher#2 about to shuffle output of map attempt_local881914384_0002_m_000000_0 decomp: 63 len: 67 to MEMORY
Read 63 bytes from map-output for attempt_local881914384_0002_m_000000_0
closeInMemoryFile -> map-output of size: 63, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->63
map attempt_local881914384_0002_m_000000_0 done 1 / 1 copied.
EventFetcher is interrupted.. Returning
1 / 1 copied.
finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
Merging 1 sorted segments
Down to the last merge-pass, with 1 segments left of total size: 57 bytes
Merged 1 segments, 63 bytes to disk to satisfy reduce memory limit
Disk file: /tmp/hadoop-michaeljones/mapred/local/localRunner/michaeljones/jobcache/job_local881914384_0002/attempt_local881914384_0002_r_000000_0/output/map_0.out.merged Length is 67
Merging 1 files, 67 bytes from disk
Merging 0 segments, 0 bytes from memory into reduce
Merging 1 sorted segments
Down to the last merge-pass, with 1 segments left of total size: 57 bytes
1 / 1 copied.
/user/michaeljones/wcOutput/_temporary/0/_temporary/attempt_local881914384_0002_r_000000_0/part-r-00000: masked=rw-r--r--
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones sending #38
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones got value #38
Call: create took 5ms
computePacketChunkSize: src=/user/michaeljones/wcOutput/_temporary/0/_temporary/attempt_local881914384_0002_r_000000_0/part-r-00000, chunkSize=516, chunksPerPacket=126, packetSize=65016
DFSClient writeChunk allocating new packet seqno=0, src=/user/michaeljones/wcOutput/_temporary/0/_temporary/attempt_local881914384_0002_r_000000_0/part-r-00000, packetSize=65016, chunksPerPacket=126, bytesCurBlock=0
Queued packet 0
Queued packet 1
Waiting for ack for: 1
Allocating new block
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones sending #39
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones got value #39
Call: addBlock took 3ms
pipeline = DatanodeInfoWithStorage[127.0.0.1:50010,DS-b42c5705-9ba4-4b14-b00b-f9194bb036f0,DISK]
Connecting to datanode 127.0.0.1:50010
Send buf size 131072
SASL client skipping handshake in unsecured configuration for addr = /127.0.0.1, datanodeId = DatanodeInfoWithStorage[127.0.0.1:50010,DS-b42c5705-9ba4-4b14-b00b-f9194bb036f0,DISK]
DataStreamer block BP-1045030256-10.0.0.2-1433119149314:blk_1073742329_1506 sending packet packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 41
DFSClient seqno: 0 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
DataStreamer block BP-1045030256-10.0.0.2-1433119149314:blk_1073742329_1506 sending packet packet seqno: 1 offsetInBlock: 41 lastPacketInBlock: true lastByteOffsetInBlock: 41
DFSClient seqno: 1 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
Closing old block BP-1045030256-10.0.0.2-1433119149314:blk_1073742329_1506
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones sending #40
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones got value #40
Call: complete took 4ms
Task:attempt_local881914384_0002_r_000000_0 is done. And is in the process of committing
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones sending #41
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones got value #41
Call: getFileInfo took 2ms
1 / 1 copied.
Task attempt_local881914384_0002_r_000000_0 is allowed to commit now
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones sending #42
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones got value #42
Call: getFileInfo took 2ms
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones sending #43
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones got value #43
Call: getFileInfo took 2ms
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones sending #44
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones got value #44
Call: rename took 4ms
Saved output of task 'attempt_local881914384_0002_r_000000_0' to hdfs://localhost:9000/user/michaeljones/wcOutput/_temporary/0/task_local881914384_0002_r_000000
reduce > reduce
Task 'attempt_local881914384_0002_r_000000_0' done.
Finishing task: attempt_local881914384_0002_r_000000_0
reduce task executor complete.
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones sending #45
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones got value #45
Call: getListing took 2ms
Merging data from FileStatus{path=hdfs://localhost:9000/user/michaeljones/wcOutput/_temporary/0/task_local881914384_0002_r_000000; isDirectory=true; modification_time=1434242169714; access_time=0; owner=michaeljones; group=supergroup; permission=rwxr-xr-x; isSymlink=false} to hdfs://localhost:9000/user/michaeljones/wcOutput
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones sending #46
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones got value #46
Call: getFileInfo took 2ms
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones sending #47
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones got value #47
Call: getListing took 2ms
Merging data from FileStatus{path=hdfs://localhost:9000/user/michaeljones/wcOutput/_temporary/0/task_local881914384_0002_r_000000/part-r-00000; isDirectory=false; length=41; replication=1; blocksize=134217728; modification_time=1434242169749; access_time=1434242169714; owner=michaeljones; group=supergroup; permission=rw-r--r--; isSymlink=false} to hdfs://localhost:9000/user/michaeljones/wcOutput/part-r-00000
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones sending #48
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones got value #48
Call: getFileInfo took 3ms
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones sending #49
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones got value #49
Call: rename took 3ms
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones sending #50
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones got value #50
Call: delete took 4ms
/user/michaeljones/wcOutput/_SUCCESS: masked=rw-r--r--
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones sending #51
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones got value #51
Call: create took 4ms
computePacketChunkSize: src=/user/michaeljones/wcOutput/_SUCCESS, chunkSize=516, chunksPerPacket=126, packetSize=65016
Waiting for ack for: -1
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones sending #52
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones got value #52
Call: complete took 2ms
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.fs.FileContext.getAbstractFileSystem(FileContext.java:331)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
Job job_local881914384_0002 running in uber mode : false
 map 100% reduce 100%
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.getTaskCompletionEvents(Job.java:670)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.getTaskCompletionEvents(Job.java:670)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
Job job_local881914384_0002 completed successfully
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.getCounters(Job.java:758)
Counters: 35
	File System Counters
		FILE: Number of bytes read=1206
		FILE: Number of bytes written=1128413
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=240
		HDFS: Number of bytes written=163
		HDFS: Number of read operations=45
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=24
	Map-Reduce Framework
		Map input records=2
		Map output records=8
		Map output bytes=82
		Map output materialized bytes=67
		Input split bytes=112
		Combine input records=8
		Combine output records=5
		Reduce input groups=5
		Reduce shuffle bytes=67
		Reduce input records=5
		Reduce output records=5
		Spilled Records=10
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=874512384
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=50
	File Output Format Counters 
		Bytes Written=41
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
RunJobAnalysisAsync
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones sending #53
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones got value #53
Call: getFileInfo took 4ms
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones sending #54
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones got value #54
Call: delete took 5ms
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.connect(Job.java:1256)
Trying ClientProtocolProvider : org.apache.hadoop.mapred.LocalClientProtocolProvider
Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
Picked org.apache.hadoop.mapred.LocalClientProtocolProvider as the ClientProtocolProvider
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Cluster.getFileSystem(Cluster.java:162)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.submit(Job.java:1287)
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones sending #55
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones got value #55
Call: getFileInfo took 2ms
Configuring job job_local1634792945_0003 with file:/tmp/hadoop-michaeljones/mapred/staging/michaeljones1634792945/.staging/job_local1634792945_0003 as the submit dir
adding the following namenodes' delegation tokens:[hdfs://localhost:9000]
Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
default FileSystem: file:///
No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
Creating splits at file:/tmp/hadoop-michaeljones/mapred/staging/michaeljones1634792945/.staging/job_local1634792945_0003
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones sending #56
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones got value #56
Call: getFileInfo took 2ms
Time taken to get FileStatuses: 3
Total input paths to process : 1
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones sending #57
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones got value #57
Call: getBlockLocations took 4ms
Total # of splits generated by getSplits: 1, TimeTaken: 8
number of splits:1
Handling deprecation for all properties in config...
Handling deprecation for mapreduce.jobtracker.address
Handling deprecation for yarn.resourcemanager.scheduler.monitor.policies
Handling deprecation for dfs.namenode.resource.check.interval
Handling deprecation for mapreduce.jobhistory.client.thread-count
Handling deprecation for yarn.app.mapreduce.am.containerlauncher.threadpool-initial-size
Handling deprecation for mapred.child.java.opts
Handling deprecation for mapreduce.jobtracker.retiredjobs.cache.size
Handling deprecation for dfs.client.https.need-auth
Handling deprecation for yarn.admin.acl
Handling deprecation for yarn.app.mapreduce.am.job.committer.cancel-timeout
Handling deprecation for mapreduce.job.emit-timeline-data
Handling deprecation for fs.ftp.host.port
Handling deprecation for dfs.namenode.avoid.read.stale.datanode
Handling deprecation for dfs.journalnode.rpc-address
Handling deprecation for mapreduce.job.end-notification.retry.attempts
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.ttl-interval-ms
Handling deprecation for yarn.resourcemanager.leveldb-state-store.path
Handling deprecation for mapred.mapper.new-api
Handling deprecation for yarn.ipc.rpc.class
Handling deprecation for ipc.client.connection.maxidletime
Handling deprecation for yarn.nodemanager.process-kill-wait.ms
Handling deprecation for mapreduce.cluster.acls.enabled
Handling deprecation for mapreduce.jobtracker.handler.count
Handling deprecation for io.map.index.interval
Handling deprecation for dfs.namenode.https-address
Handling deprecation for mapreduce.task.profile.reduces
Handling deprecation for fs.s3n.multipart.uploads.enabled
Handling deprecation for io.seqfile.sorter.recordlimit
Handling deprecation for mapreduce.job.ubertask.maxmaps
Handling deprecation for mapreduce.tasktracker.tasks.sleeptimebeforesigkill
Handling deprecation for hadoop.util.hash.type
Handling deprecation for dfs.namenode.replication.min
Handling deprecation for yarn.nodemanager.container-manager.thread-count
Handling deprecation for mapreduce.jobtracker.jobhistory.block.size
Handling deprecation for dfs.namenode.fs-limits.min-block-size
Handling deprecation for mapreduce.app-submission.cross-platform
Handling deprecation for fs.AbstractFileSystem.file.impl
Handling deprecation for net.topology.script.number.args
Handling deprecation for yarn.resourcemanager.container-tokens.master-key-rolling-interval-secs
Handling deprecation for mapreduce.map.output.compress.codec
Handling deprecation for mapreduce.job.reducer.preempt.delay.sec
Handling deprecation for s3native.bytes-per-checksum
Handling deprecation for dfs.namenode.path.based.cache.block.map.allocation.percent
Handling deprecation for yarn.nodemanager.windows-container.memory-limit.enabled
Handling deprecation for mapreduce.input.fileinputformat.split.minsize
Handling deprecation for hadoop.security.group.mapping
Handling deprecation for mapreduce.jobtracker.system.dir
Handling deprecation for mapreduce.job.end-notification.max.attempts
Handling deprecation for mapreduce.reduce.markreset.buffer.percent
Handling deprecation for dfs.datanode.cache.revocation.polling.ms
Handling deprecation for mapreduce.reduce.speculative
Handling deprecation for yarn.nodemanager.localizer.cache.cleanup.interval-ms
Handling deprecation for dfs.namenode.lazypersist.file.scrub.interval.sec
Handling deprecation for fs.s3a.threads.core
Handling deprecation for mapreduce.jobhistory.recovery.store.fs.uri
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.start-time-read-cache-size
Handling deprecation for hadoop.registry.zk.retry.interval.ms
Handling deprecation for yarn.nodemanager.keytab
Handling deprecation for dfs.namenode.replication.interval
Handling deprecation for yarn.resourcemanager.admin.address
Handling deprecation for mapreduce.job.maps
Handling deprecation for nfs.dump.dir
Handling deprecation for mapreduce.job.user.name
Handling deprecation for mapreduce.jobtracker.maxtasks.perjob
Handling deprecation for mapreduce.job.ubertask.enable
Handling deprecation for mapreduce.job.reduce.class
Handling deprecation for yarn.nodemanager.delete.debug-delay-sec
Handling deprecation for yarn.timeline-service.ttl-enable
Handling deprecation for yarn.resourcemanager.fs.state-store.retry-policy-spec
Handling deprecation for mapreduce.reduce.skip.maxgroups
Handling deprecation for dfs.client.use.datanode.hostname
Handling deprecation for fs.trash.interval
Handling deprecation for mapreduce.job.name
Handling deprecation for mapreduce.am.max-attempts
Handling deprecation for mapreduce.jobtracker.heartbeats.in.second
Handling deprecation for yarn.resourcemanager.zk-num-retries
Handling deprecation for s3.blocksize
Handling deprecation for dfs.datanode.data.dir
Handling deprecation for mapreduce.jobtracker.persist.jobstatus.active
Handling deprecation for mapreduce.reduce.shuffle.parallelcopies
Handling deprecation for fs.s3.buffer.dir
Handling deprecation for mapreduce.jobhistory.done-dir
Handling deprecation for hadoop.security.instrumentation.requires.admin
Handling deprecation for hadoop.registry.zk.retry.ceiling.ms
Handling deprecation for nfs.rtmax
Handling deprecation for dfs.datanode.data.dir.perm
Handling deprecation for yarn.resourcemanager.container.liveness-monitor.interval-ms
Handling deprecation for yarn.nodemanager.env-whitelist
Handling deprecation for dfs.namenode.backup.address
Handling deprecation for dfs.namenode.xattrs.enabled
Handling deprecation for dfs.datanode.readahead.bytes
Handling deprecation for mapreduce.jobhistory.cleaner.enable
Handling deprecation for dfs.client.block.write.retries
Handling deprecation for mapreduce.tasktracker.http.address
Handling deprecation for yarn.nodemanager.linux-container-executor.cgroups.hierarchy
Handling deprecation for ha.failover-controller.graceful-fence.connection.retries
Handling deprecation for yarn.resourcemanager.recovery.enabled
Handling deprecation for yarn.app.mapreduce.am.container.log.backups
Handling deprecation for dfs.namenode.safemode.threshold-pct
Handling deprecation for yarn.nodemanager.disk-health-checker.interval-ms
Handling deprecation for hadoop.security.java.secure.random.algorithm
Handling deprecation for dfs.namenode.list.cache.directives.num.responses
Handling deprecation for dfs.datanode.dns.nameserver
Handling deprecation for mapreduce.cluster.temp.dir
Handling deprecation for fs.s3a.max.total.tasks
Handling deprecation for mapreduce.reduce.maxattempts
Handling deprecation for mapreduce.client.submit.file.replication
Handling deprecation for mapreduce.shuffle.port
Handling deprecation for yarn.resourcemanager.resource-tracker.client.thread-count
Handling deprecation for dfs.namenode.replication.considerLoad
Handling deprecation for dfs.namenode.edits.journal-plugin.qjournal
Handling deprecation for dfs.client.write.exclude.nodes.cache.expiry.interval.millis
Handling deprecation for yarn.nodemanager.delete.thread-count
Handling deprecation for dfs.client.mmap.cache.timeout.ms
Handling deprecation for yarn.nodemanager.admin-env
Handling deprecation for io.skip.checksum.errors
Handling deprecation for yarn.timeline-service.hostname
Handling deprecation for yarn.resourcemanager.proxy-user-privileges.enabled
Handling deprecation for mapreduce.job.speculative.speculative-cap-total-tasks
Handling deprecation for yarn.acl.enable
Handling deprecation for fs.s3a.fast.upload
Handling deprecation for file.blocksize
Handling deprecation for mapreduce.job.speculative.slowtaskthreshold
Handling deprecation for ftp.replication
Handling deprecation for yarn.sharedcache.cleaner.initial-delay-mins
Handling deprecation for s3native.client-write-packet-size
Handling deprecation for hadoop.rpc.socket.factory.class.default
Handling deprecation for file.bytes-per-checksum
Handling deprecation for dfs.datanode.slow.io.warning.threshold.ms
Handling deprecation for io.seqfile.lazydecompress
Handling deprecation for mapreduce.task.skip.start.attempts
Handling deprecation for dfs.namenode.reject-unresolved-dn-topology-mapping
Handling deprecation for hadoop.common.configuration.version
Handling deprecation for yarn.resourcemanager.client.thread-count
Handling deprecation for dfs.datanode.drop.cache.behind.reads
Handling deprecation for yarn.sharedcache.admin.address
Handling deprecation for mapreduce.job.output.value.class
Handling deprecation for mapreduce.output.fileoutputformat.outputdir
Handling deprecation for mapreduce.jobtracker.taskcache.levels
Handling deprecation for yarn.nodemanager.linux-container-executor.nonsecure-mode.user-pattern
Handling deprecation for yarn.resourcemanager.zk-timeout-ms
Handling deprecation for yarn.resourcemanager.max-completed-applications
Handling deprecation for mapreduce.job.jvm.numtasks
Handling deprecation for yarn.sharedcache.cleaner.period-mins
Handling deprecation for mapreduce.jobtracker.tasktracker.maxblacklists
Handling deprecation for dfs.namenode.top.num.users
Handling deprecation for yarn.nodemanager.linux-container-executor.cgroups.mount
Handling deprecation for yarn.sharedcache.checksum.algo.impl
Handling deprecation for mapreduce.job.end-notification.max.retry.interval
Handling deprecation for mapreduce.job.acl-view-job
Handling deprecation for mapreduce.job.classloader
Handling deprecation for yarn.log-aggregation-enable
Handling deprecation for mapreduce.reduce.shuffle.fetch.retry.interval-ms
Handling deprecation for yarn.resourcemanager.nodemanager.minimum.version
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.size
Handling deprecation for yarn.app.mapreduce.am.job.task.listener.thread-count
Handling deprecation for yarn.app.mapreduce.am.resource.cpu-vcores
Handling deprecation for dfs.namenode.edit.log.autoroll.check.interval.ms
Handling deprecation for mapreduce.output.fileoutputformat.compress.type
Handling deprecation for hadoop.hdfs.configuration.version
Handling deprecation for hadoop.security.group.mapping.ldap.search.attr.member
Handling deprecation for yarn.nodemanager.log.retain-seconds
Handling deprecation for yarn.nodemanager.local-cache.max-files-per-directory
Handling deprecation for mapreduce.job.end-notification.retry.interval
Handling deprecation for hadoop.ssl.client.conf
Handling deprecation for yarn.sharedcache.root-dir
Handling deprecation for dfs.journalnode.https-address
Handling deprecation for mapreduce.reduce.shuffle.fetch.retry.timeout-ms
Handling deprecation for dfs.bytes-per-checksum
Handling deprecation for dfs.namenode.max.objects
Handling deprecation for mapreduce.tasktracker.instrumentation
Handling deprecation for dfs.datanode.max.transfer.threads
Handling deprecation for dfs.block.access.key.update.interval
Handling deprecation for mapreduce.jobtracker.jobhistory.task.numberprogresssplits
Handling deprecation for mapreduce.map.memory.mb
Handling deprecation for ha.failover-controller.new-active.rpc-timeout.ms
Handling deprecation for hadoop.ssl.hostname.verifier
Handling deprecation for dfs.client.read.shortcircuit
Handling deprecation for dfs.datanode.hdfs-blocks-metadata.enabled
Handling deprecation for mapreduce.tasktracker.healthchecker.interval
Handling deprecation for dfs.image.transfer.chunksize
Handling deprecation for mapreduce.tasktracker.taskmemorymanager.monitoringinterval
Handling deprecation for dfs.client.https.keystore.resource
Handling deprecation for yarn.resourcemanager.connect.retry-interval.ms
Handling deprecation for yarn.timeline-service.webapp.address
Handling deprecation for s3native.blocksize
Handling deprecation for yarn.scheduler.minimum-allocation-mb
Handling deprecation for yarn.sharedcache.cleaner.resource-sleep-ms
Handling deprecation for net.topology.impl
Handling deprecation for dfs.client.failover.sleep.base.millis
Handling deprecation for dfs.permissions.superusergroup
Handling deprecation for io.seqfile.compress.blocksize
Handling deprecation for hadoop.registry.zk.retry.times
Handling deprecation for fs.AbstractFileSystem.ftp.impl
Handling deprecation for dfs.namenode.checkpoint.edits.dir
Handling deprecation for mapreduce.job.running.reduce.limit
Handling deprecation for dfs.blockreport.initialDelay
Handling deprecation for dfs.namenode.heartbeat.recheck-interval
Handling deprecation for dfs.namenode.safemode.extension
Handling deprecation for yarn.scheduler.maximum-allocation-mb
Handling deprecation for mapreduce.job.reduce.shuffle.consumer.plugin.class
Handling deprecation for yarn.nodemanager.vmem-check-enabled
Handling deprecation for mapreduce.task.io.sort.factor
Handling deprecation for mapreduce.jobtracker.persist.jobstatus.dir
Handling deprecation for dfs.client.failover.sleep.max.millis
Handling deprecation for dfs.namenode.delegation.key.update-interval
Handling deprecation for hadoop.rpc.protection
Handling deprecation for fs.permissions.umask-mode
Handling deprecation for fs.s3.sleepTimeSeconds
Handling deprecation for ha.health-monitor.rpc-timeout.ms
Handling deprecation for hadoop.http.staticuser.user
Handling deprecation for fs.s3a.connection.maximum
Handling deprecation for yarn.nodemanager.linux-container-executor.nonsecure-mode.limit-users
Handling deprecation for fs.s3a.paging.maximum
Handling deprecation for fs.AbstractFileSystem.viewfs.impl
Handling deprecation for fs.ftp.host
Handling deprecation for yarn.nodemanager.linux-container-executor.nonsecure-mode.local-user
Handling deprecation for fs.s3a.impl
Handling deprecation for hadoop.http.authentication.kerberos.keytab
Handling deprecation for dfs.namenode.fs-limits.max-blocks-per-file
Handling deprecation for mapreduce.tasktracker.http.threads
Handling deprecation for mapreduce.tasktracker.dns.nameserver
Handling deprecation for yarn.resourcemanager.am-rm-tokens.master-key-rolling-interval-secs
Handling deprecation for dfs.client.block.write.replace-datanode-on-failure.enable
Handling deprecation for io.compression.codec.bzip2.library
Handling deprecation for mapreduce.map.skip.maxrecords
Handling deprecation for dfs.client.use.legacy.blockreader.local
Handling deprecation for dfs.namenode.checkpoint.dir
Handling deprecation for dfs.namenode.top.windows.minutes
Handling deprecation for mapreduce.job.maxtaskfailures.per.tracker
Handling deprecation for net.topology.node.switch.mapping.impl
Handling deprecation for mapreduce.shuffle.max.connections
Handling deprecation for mapreduce.jobhistory.loadedjobs.cache.size
Handling deprecation for dfs.storage.policy.enabled
Handling deprecation for yarn.client.application-client-protocol.poll-interval-ms
Handling deprecation for yarn.nodemanager.localizer.address
Handling deprecation for dfs.namenode.list.cache.pools.num.responses
Handling deprecation for nfs.server.port
Handling deprecation for mapreduce.client.output.filter
Handling deprecation for yarn.timeline-service.client.best-effort
Handling deprecation for ha.zookeeper.parent-znode
Handling deprecation for mapreduce.jobtracker.persist.jobstatus.hours
Handling deprecation for yarn.sharedcache.admin.thread-count
Handling deprecation for yarn.nodemanager.resource.cpu-vcores
Handling deprecation for dfs.datanode.block-pinning.enabled
Handling deprecation for mapreduce.jobhistory.http.policy
Handling deprecation for yarn.resourcemanager.webapp.delegation-token-auth-filter.enabled
Handling deprecation for mapreduce.job.speculative.retry-after-no-speculate
Handling deprecation for fs.s3a.attempts.maximum
Handling deprecation for s3native.stream-buffer-size
Handling deprecation for io.seqfile.local.dir
Handling deprecation for yarn.log-aggregation.retain-check-interval-seconds
Handling deprecation for fs.s3n.multipart.copy.block.size
Handling deprecation for dfs.encrypt.data.transfer.cipher.key.bitlength
Handling deprecation for dfs.datanode.sync.behind.writes
Handling deprecation for yarn.resourcemanager.zk-acl
Handling deprecation for hadoop.ssl.keystores.factory.class
Handling deprecation for mapreduce.job.split.metainfo.maxsize
Handling deprecation for fs.s3.maxRetries
Handling deprecation for hadoop.security.random.device.file.path
Handling deprecation for yarn.client.nodemanager-connect.max-wait-ms
Handling deprecation for dfs.namenode.stale.datanode.interval
Handling deprecation for mapreduce.task.io.sort.mb
Handling deprecation for yarn.resourcemanager.zk-state-store.parent-path
Handling deprecation for yarn.app.mapreduce.client-am.ipc.max-retries
Handling deprecation for fs.client.resolve.remote.symlinks
Handling deprecation for yarn.nodemanager.linux-container-executor.cgroups.strict-resource-usage
Handling deprecation for hadoop.ssl.enabled.protocols
Handling deprecation for mapreduce.reduce.cpu.vcores
Handling deprecation for yarn.client.failover-retries
Handling deprecation for mapreduce.jobhistory.address
Handling deprecation for hadoop.ssl.enabled
Handling deprecation for dfs.replication.max
Handling deprecation for dfs.namenode.name.dir
Handling deprecation for dfs.datanode.https.address
Handling deprecation for ipc.client.kill.max
Handling deprecation for mapreduce.job.committer.setup.cleanup.needed
Handling deprecation for dfs.client.domain.socket.data.traffic
Handling deprecation for yarn.nodemanager.localizer.cache.target-size-mb
Handling deprecation for yarn.resourcemanager.admin.client.thread-count
Handling deprecation for dfs.block.access.token.enable
Handling deprecation for mapreduce.job.speculative.retry-after-speculate
Handling deprecation for dfs.datanode.address
Handling deprecation for mapreduce.jobtracker.restart.recover
Handling deprecation for ipc.client.connect.max.retries
Handling deprecation for yarn.timeline-service.store-class
Handling deprecation for dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
Handling deprecation for hadoop.tmp.dir
Handling deprecation for dfs.datanode.handler.count
Handling deprecation for yarn.resourcemanager.ha.automatic-failover.embedded
Handling deprecation for yarn.timeline-service.ttl-ms
Handling deprecation for mapreduce.task.profile.map.params
Handling deprecation for yarn.resourcemanager.nodemanagers.heartbeat-interval-ms
Handling deprecation for mapreduce.map.speculative
Handling deprecation for yarn.timeline-service.recovery.enabled
Handling deprecation for mapreduce.job.map.class
Handling deprecation for dfs.namenode.resource.checked.volumes.minimum
Handling deprecation for yarn.nodemanager.recovery.dir
Handling deprecation for mapreduce.job.counters.max
Handling deprecation for yarn.resourcemanager.keytab
Handling deprecation for dfs.namenode.max.extra.edits.segments.retained
Handling deprecation for dfs.webhdfs.user.provider.user.pattern
Handling deprecation for dfs.client.mmap.enabled
Handling deprecation for mapreduce.map.log.level
Handling deprecation for dfs.client.file-block-storage-locations.timeout.millis
Handling deprecation for yarn.client.max-cached-nodemanagers-proxies
Handling deprecation for yarn.app.mapreduce.am.scheduler.heartbeat.interval-ms
Handling deprecation for hadoop.fuse.timer.period
Handling deprecation for fs.trash.checkpoint.interval
Handling deprecation for yarn.sharedcache.app-checker.class
Handling deprecation for dfs.journalnode.http-address
Handling deprecation for yarn.app.mapreduce.am.staging-dir
Handling deprecation for mapreduce.tasktracker.local.dir.minspacestart
Handling deprecation for yarn.nm.liveness-monitor.expiry-interval-ms
Handling deprecation for ha.health-monitor.check-interval.ms
Handling deprecation for mapreduce.reduce.shuffle.merge.percent
Handling deprecation for dfs.namenode.retrycache.heap.percent
Handling deprecation for yarn.nodemanager.docker-container-executor.exec-name
Handling deprecation for ipc.client.connect.timeout
Handling deprecation for yarn.resourcemanager.fs.state-store.retry-interval-ms
Handling deprecation for mapreduce.output.fileoutputformat.compress
Handling deprecation for yarn.nodemanager.local-dirs
Handling deprecation for yarn.nodemanager.recovery.enabled
Handling deprecation for io.native.lib.available
Handling deprecation for yarn.sharedcache.store.in-memory.staleness-period-mins
Handling deprecation for yarn.resourcemanager.am.max-attempts
Handling deprecation for s3.replication
Handling deprecation for mapreduce.input.fileinputformat.inputdir
Handling deprecation for fs.AbstractFileSystem.har.impl
Handling deprecation for dfs.image.compress
Handling deprecation for mapreduce.job.running.map.limit
Handling deprecation for mapreduce.reduce.input.buffer.percent
Handling deprecation for yarn.nodemanager.webapp.address
Handling deprecation for dfs.datanode.available-space-volume-choosing-policy.balanced-space-preference-fraction
Handling deprecation for dfs.namenode.edit.log.autoroll.multiplier.threshold
Handling deprecation for hadoop.security.group.mapping.ldap.ssl
Handling deprecation for dfs.namenode.checkpoint.check.period
Handling deprecation for fs.defaultFS
Handling deprecation for fs.s3a.multipart.size
Handling deprecation for dfs.client.slow.io.warning.threshold.ms
Handling deprecation for yarn.app.mapreduce.am.job.committer.commit-window
Handling deprecation for hadoop.security.group.mapping.ldap.search.attr.group.name
Handling deprecation for yarn.nodemanager.disk-health-checker.max-disk-utilization-per-disk-percentage
Handling deprecation for yarn.nodemanager.container-monitor.procfs-tree.smaps-based-rss.enabled
Handling deprecation for mapreduce.job.submithostname
Handling deprecation for mapreduce.map.sort.spill.percent
Handling deprecation for hadoop.security.crypto.codec.classes.aes.ctr.nopadding
Handling deprecation for dfs.namenode.http-address
Handling deprecation for hadoop.security.groups.negative-cache.secs
Handling deprecation for hadoop.ssl.server.conf
Handling deprecation for mapreduce.ifile.readahead
Handling deprecation for s3native.replication
Handling deprecation for yarn.client.nodemanager-client-async.thread-pool-max-size
Handling deprecation for mapreduce.jobtracker.staging.root.dir
Handling deprecation for mapreduce.jobhistory.admin.address
Handling deprecation for dfs.namenode.startup.delay.block.deletion.sec
Handling deprecation for yarn.nodemanager.health-checker.interval-ms
Handling deprecation for dfs.namenode.checkpoint.max-retries
Handling deprecation for s3.stream-buffer-size
Handling deprecation for ftp.client-write-packet-size
Handling deprecation for dfs.datanode.fsdatasetcache.max.threads.per.volume
Handling deprecation for mapreduce.output.fileoutputformat.compress.codec
Handling deprecation for yarn.timeline-service.keytab
Handling deprecation for yarn.sharedcache.store.in-memory.initial-delay-mins
Handling deprecation for mapreduce.jobhistory.webapp.address
Handling deprecation for mapreduce.task.userlog.limit.kb
Handling deprecation for mapreduce.reduce.shuffle.fetch.retry.enabled
Handling deprecation for yarn.app.mapreduce.task.container.log.backups
Handling deprecation for dfs.heartbeat.interval
Handling deprecation for ha.zookeeper.session-timeout.ms
Handling deprecation for fs.s3a.connection.ssl.enabled
Handling deprecation for yarn.sharedcache.webapp.address
Handling deprecation for hadoop.http.authentication.signature.secret.file
Handling deprecation for hadoop.fuse.connection.timeout
Handling deprecation for mapreduce.input.fileinputformat.numinputfiles
Handling deprecation for yarn.nodemanager.log-aggregation.compression-type
Handling deprecation for ipc.server.max.connections
Handling deprecation for yarn.resourcemanager.work-preserving-recovery.scheduling-wait-ms
Handling deprecation for yarn.nodemanager.log-dirs
Handling deprecation for yarn.app.mapreduce.am.resource.mb
Handling deprecation for hadoop.security.groups.cache.secs
Handling deprecation for mapreduce.job.speculative.minimum-allowed-tasks
Handling deprecation for yarn.nodemanager.container-monitor.interval-ms
Handling deprecation for dfs.datanode.cache.revocation.timeout.ms
Handling deprecation for mapreduce.jobhistory.recovery.store.class
Handling deprecation for mapreduce.task.combine.progress.records
Handling deprecation for s3.client-write-packet-size
Handling deprecation for mapreduce.jobtracker.instrumentation
Handling deprecation for dfs.replication
Handling deprecation for mapreduce.shuffle.transfer.buffer.size
Handling deprecation for hadoop.security.group.mapping.ldap.directory.search.timeout
Handling deprecation for dfs.datanode.available-space-volume-choosing-policy.balanced-space-threshold
Handling deprecation for hadoop.work.around.non.threadsafe.getpwuid
Handling deprecation for yarn.app.mapreduce.client-am.ipc.max-retries-on-timeouts
Handling deprecation for yarn.nodemanager.address
Handling deprecation for mapreduce.tasktracker.taskcontroller
Handling deprecation for mapreduce.tasktracker.indexcache.mb
Handling deprecation for yarn.scheduler.maximum-allocation-vcores
Handling deprecation for mapreduce.job.reduces
Handling deprecation for yarn.nodemanager.sleep-delay-before-sigkill.ms
Handling deprecation for yarn.timeline-service.address
Handling deprecation for yarn.resourcemanager.configuration.provider-class
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.expiry
Handling deprecation for yarn.sharedcache.enabled
Handling deprecation for tfile.io.chunk.size
Handling deprecation for mapreduce.job.acl-modify-job
Handling deprecation for hadoop.registry.zk.session.timeout.ms
Handling deprecation for fs.automatic.close
Handling deprecation for ha.health-monitor.sleep-after-disconnect.ms
Handling deprecation for mapreduce.tasktracker.reduce.tasks.maximum
Handling deprecation for mapreduce.input.fileinputformat.list-status.num-threads
Handling deprecation for dfs.datanode.directoryscan.threads
Handling deprecation for dfs.datanode.directoryscan.interval
Handling deprecation for dfs.namenode.acls.enabled
Handling deprecation for dfs.client.short.circuit.replica.stale.threshold.ms
Handling deprecation for hadoop.http.authentication.token.validity
Handling deprecation for fs.s3.block.size
Handling deprecation for ha.failover-controller.graceful-fence.rpc-timeout.ms
Handling deprecation for mapreduce.tasktracker.local.dir.minspacekill
Handling deprecation for dfs.namenode.resource.du.reserved
Handling deprecation for mapreduce.jobhistory.cleaner.interval-ms
Handling deprecation for dfs.namenode.datanode.registration.ip-hostname-check
Handling deprecation for mapreduce.jobhistory.intermediate-done-dir
Handling deprecation for mapreduce.jobtracker.http.address
Handling deprecation for dfs.namenode.backup.http-address
Handling deprecation for dfs.namenode.edits.noeditlogchannelflush
Handling deprecation for mapreduce.reduce.shuffle.input.buffer.percent
Handling deprecation for mapreduce.map.maxattempts
Handling deprecation for yarn.http.policy
Handling deprecation for dfs.namenode.audit.loggers
Handling deprecation for hadoop.security.groups.cache.warn.after.ms
Handling deprecation for io.serializations
Handling deprecation for mapreduce.tasktracker.outofband.heartbeat
Handling deprecation for mapreduce.reduce.shuffle.read.timeout
Handling deprecation for hadoop.security.crypto.buffer.size
Handling deprecation for mapreduce.reduce.skip.proc.count.autoincr
Handling deprecation for mapreduce.ifile.readahead.bytes
Handling deprecation for dfs.http.policy
Handling deprecation for hadoop.registry.secure
Handling deprecation for dfs.namenode.safemode.min.datanodes
Handling deprecation for dfs.client.file-block-storage-locations.num-threads
Handling deprecation for mapreduce.cluster.local.dir
Handling deprecation for mapreduce.tasktracker.report.address
Handling deprecation for dfs.namenode.secondary.https-address
Handling deprecation for hadoop.kerberos.kinit.command
Handling deprecation for yarn.timeline-service.http-authentication.type
Handling deprecation for dfs.block.access.token.lifetime
Handling deprecation for dfs.webhdfs.enabled
Handling deprecation for dfs.namenode.delegation.token.max-lifetime
Handling deprecation for dfs.namenode.avoid.write.stale.datanode
Handling deprecation for dfs.datanode.drop.cache.behind.writes
Handling deprecation for yarn.log-aggregation.retain-seconds
Handling deprecation for mapreduce.job.complete.cancel.delegation.tokens
Handling deprecation for mapreduce.local.clientfactory.class.name
Handling deprecation for mapreduce.shuffle.connection-keep-alive.timeout
Handling deprecation for dfs.namenode.num.extra.edits.retained
Handling deprecation for yarn.scheduler.minimum-allocation-vcores
Handling deprecation for ipc.client.connect.max.retries.on.timeouts
Handling deprecation for yarn.timeline-service.client.retry-interval-ms
Handling deprecation for yarn.timeline-service.client.max-retries
Handling deprecation for fs.s3n.block.size
Handling deprecation for mapreduce.job.map.output.collector.class
Handling deprecation for ha.health-monitor.connect-retry-interval.ms
Handling deprecation for mapreduce.shuffle.max.threads
Handling deprecation for nfs.exports.allowed.hosts
Handling deprecation for dfs.client.mmap.cache.size
Handling deprecation for mapreduce.tasktracker.map.tasks.maximum
Handling deprecation for io.file.buffer.size
Handling deprecation for dfs.client.datanode-restart.timeout
Handling deprecation for io.mapfile.bloom.size
Handling deprecation for hadoop.security.kms.client.authentication.retry-count
Handling deprecation for dfs.namenode.checkpoint.txns
Handling deprecation for ipc.client.connect.retry.interval
Handling deprecation for dfs.client-write-packet-size
Handling deprecation for mapreduce.reduce.shuffle.connect.timeout
Handling deprecation for yarn.resourcemanager.fs.state-store.uri
Handling deprecation for fs.swift.impl
Handling deprecation for hadoop.registry.zk.connection.timeout.ms
Handling deprecation for mapred.queue.default.acl-administer-jobs
Handling deprecation for mapreduce.job.submithostaddress
Handling deprecation for dfs.cachereport.intervalMsec
Handling deprecation for yarn.app.mapreduce.shuffle.log.backups
Handling deprecation for yarn.app.mapreduce.am.container.log.limit.kb
Handling deprecation for yarn.nodemanager.resourcemanager.minimum.version
Handling deprecation for ftp.blocksize
Handling deprecation for yarn.resourcemanager.address
Handling deprecation for file.stream-buffer-size
Handling deprecation for yarn.resourcemanager.scheduler.monitor.enable
Handling deprecation for mapreduce.job.ubertask.maxreduces
Handling deprecation for nfs.allow.insecure.ports
Handling deprecation for yarn.sharedcache.nm.uploader.thread-count
Handling deprecation for ipc.client.idlethreshold
Handling deprecation for ftp.stream-buffer-size
Handling deprecation for yarn.sharedcache.client-server.address
Handling deprecation for dfs.client.failover.connection.retries.on.timeouts
Handling deprecation for dfs.namenode.replication.work.multiplier.per.iteration
Handling deprecation for hadoop.http.authentication.simple.anonymous.allowed
Handling deprecation for hadoop.security.authorization
Handling deprecation for yarn.client.nodemanager-connect.retry-interval-ms
Handling deprecation for yarn.am.liveness-monitor.expiry-interval-ms
Handling deprecation for fs.har.impl.disable.cache
Handling deprecation for yarn.nodemanager.linux-container-executor.resources-handler.class
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.read-cache-size
Handling deprecation for hadoop.security.authentication
Handling deprecation for dfs.image.compression.codec
Handling deprecation for mapreduce.task.files.preserve.failedtasks
Handling deprecation for dfs.client.read.shortcircuit.streams.cache.size
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.path
Handling deprecation for mapreduce.job.reduce.slowstart.completedmaps
Handling deprecation for mapreduce.jobhistory.minicluster.fixed.ports
Handling deprecation for file.replication
Handling deprecation for yarn.resourcemanager.ha.automatic-failover.enabled
Handling deprecation for mapreduce.job.userlog.retain.hours
Handling deprecation for mapreduce.jobhistory.joblist.cache.size
Handling deprecation for dfs.namenode.accesstime.precision
Handling deprecation for yarn.resourcemanager.work-preserving-recovery.enabled
Handling deprecation for dfs.namenode.fs-limits.max-xattrs-per-inode
Handling deprecation for io.mapfile.bloom.error.rate
Handling deprecation for yarn.resourcemanager.store.class
Handling deprecation for dfs.image.transfer.timeout
Handling deprecation for yarn.timeline-service.leveldb-state-store.path
Handling deprecation for nfs.wtmax
Handling deprecation for mapreduce.job.combine.class
Handling deprecation for dfs.namenode.support.allow.format
Handling deprecation for fs.s3a.multipart.purge
Handling deprecation for dfs.secondary.namenode.kerberos.internal.spnego.principal
Handling deprecation for fs.s3a.connection.establish.timeout
Handling deprecation for dfs.stream-buffer-size
Handling deprecation for dfs.namenode.invalidate.work.pct.per.iteration
Handling deprecation for yarn.nodemanager.container-executor.class
Handling deprecation for fs.s3a.multipart.purge.age
Handling deprecation for yarn.resourcemanager.scheduler.client.thread-count
Handling deprecation for dfs.namenode.top.enabled
Handling deprecation for yarn.app.mapreduce.shuffle.log.separate
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.low-watermark
Handling deprecation for fs.s3a.fast.buffer.size
Handling deprecation for hadoop.user.group.static.mapping.overrides
Handling deprecation for tfile.fs.input.buffer.size
Handling deprecation for dfs.client.cached.conn.retry
Handling deprecation for hadoop.http.authentication.type
Handling deprecation for dfs.namenode.list.encryption.zones.num.responses
Handling deprecation for mapreduce.map.cpu.vcores
Handling deprecation for dfs.namenode.path.based.cache.refresh.interval.ms
Handling deprecation for dfs.namenode.decommission.interval
Handling deprecation for dfs.namenode.fs-limits.max-directory-items
Handling deprecation for yarn.resourcemanager.zk-retry-interval-ms
Handling deprecation for ftp.bytes-per-checksum
Handling deprecation for dfs.ha.log-roll.period
Handling deprecation for dfs.user.home.dir.prefix
Handling deprecation for ipc.client.fallback-to-simple-auth-allowed
Handling deprecation for yarn.nodemanager.pmem-check-enabled
Handling deprecation for yarn.nodemanager.remote-app-log-dir
Handling deprecation for dfs.namenode.inotify.max.events.per.rpc
Handling deprecation for mapreduce.task.profile.maps
Handling deprecation for mapreduce.shuffle.ssl.file.buffer.size
Handling deprecation for mapreduce.tasktracker.healthchecker.script.timeout
Handling deprecation for yarn.timeline-service.webapp.https.address
Handling deprecation for yarn.nodemanager.resource.percentage-physical-cpu-limit
Handling deprecation for yarn.app.mapreduce.am.command-opts
Handling deprecation for dfs.namenode.fs-limits.max-xattr-size
Handling deprecation for dfs.datanode.http.address
Handling deprecation for dfs.namenode.blocks.per.postponedblocks.rescan
Handling deprecation for yarn.sharedcache.nm.uploader.replication.factor
Handling deprecation for hadoop.registry.zk.root
Handling deprecation for hadoop.jetty.logs.serve.aliases
Handling deprecation for yarn.client.failover-proxy-provider
Handling deprecation for mapreduce.jobhistory.admin.acl
Handling deprecation for yarn.app.mapreduce.am.hard-kill-timeout-ms
Handling deprecation for yarn.nodemanager.remote-app-log-dir-suffix
Handling deprecation for mapreduce.jobhistory.principal
Handling deprecation for yarn.resourcemanager.webapp.address
Handling deprecation for mapreduce.jobhistory.recovery.enable
Handling deprecation for yarn.sharedcache.store.in-memory.check-period-mins
Handling deprecation for nfs.mountd.port
Handling deprecation for mapreduce.reduce.merge.inmem.threshold
Handling deprecation for fs.df.interval
Handling deprecation for yarn.timeline-service.enabled
Handling deprecation for mapreduce.jobtracker.jobhistory.lru.cache.size
Handling deprecation for mapreduce.task.profile
Handling deprecation for mapreduce.job.output.key.class
Handling deprecation for yarn.nodemanager.hostname
Handling deprecation for dfs.namenode.num.checkpoints.retained
Handling deprecation for mapreduce.job.queuename
Handling deprecation for mapreduce.jobhistory.max-age-ms
Handling deprecation for mapreduce.job.token.tracking.ids.enabled
Handling deprecation for yarn.nodemanager.localizer.client.thread-count
Handling deprecation for yarn.sharedcache.uploader.server.thread-count
Handling deprecation for dfs.client.mmap.retry.timeout.ms
Handling deprecation for mapreduce.jobhistory.move.thread-count
Handling deprecation for dfs.permissions.enabled
Handling deprecation for dfs.blockreport.split.threshold
Handling deprecation for fs.AbstractFileSystem.hdfs.impl
Handling deprecation for dfs.datanode.balance.bandwidthPerSec
Handling deprecation for dfs.block.scanner.volume.bytes.per.second
Handling deprecation for hadoop.http.filter.initializers
Handling deprecation for yarn.timeline-service.http-authentication.simple.anonymous.allowed
Handling deprecation for dfs.default.chunk.view.size
Handling deprecation for yarn.sharedcache.client-server.thread-count
Handling deprecation for yarn.resourcemanager.resource-tracker.address
Handling deprecation for mapreduce.job.working.dir
Handling deprecation for mapreduce.jobhistory.datestring.cache.size
Handling deprecation for mapreduce.task.profile.params
Handling deprecation for dfs.namenode.decommission.blocks.per.interval
Handling deprecation for dfs.namenode.handler.count
Handling deprecation for dfs.image.transfer.bandwidthPerSec
Handling deprecation for rpc.metrics.quantile.enable
Handling deprecation for mapreduce.jobtracker.expire.trackers.interval
Handling deprecation for mapreduce.task.timeout
Handling deprecation for yarn.app.mapreduce.client.max-retries
Handling deprecation for yarn.nodemanager.resource.memory-mb
Handling deprecation for yarn.nodemanager.disk-health-checker.min-healthy-disks
Handling deprecation for dfs.datanode.failed.volumes.tolerated
Handling deprecation for yarn.timeline-service.handler-thread-count
Handling deprecation for ipc.server.listen.queue.size
Handling deprecation for fs.s3a.threads.max
Handling deprecation for yarn.resourcemanager.connect.max-wait.ms
Handling deprecation for mapreduce.fileoutputcommitter.algorithm.version
Handling deprecation for mapreduce.framework.name
Handling deprecation for mapreduce.map.skip.proc.count.autoincr
Handling deprecation for mapreduce.job.max.split.locations
Handling deprecation for yarn.resourcemanager.scheduler.class
Handling deprecation for yarn.resourcemanager.system-metrics-publisher.enabled
Handling deprecation for dfs.blocksize
Handling deprecation for yarn.sharedcache.nested-level
Handling deprecation for mapreduce.shuffle.connection-keep-alive.enable
Handling deprecation for fs.s3a.threads.keepalivetime
Handling deprecation for fs.s3a.connection.timeout
Handling deprecation for file.client-write-packet-size
Handling deprecation for ha.failover-controller.cli-check.rpc-timeout.ms
Handling deprecation for ha.zookeeper.acl
Handling deprecation for dfs.namenode.write.stale.datanode.ratio
Handling deprecation for dfs.encrypt.data.transfer
Handling deprecation for dfs.datanode.shared.file.descriptor.paths
Handling deprecation for mapreduce.input.lineinputformat.linespermap
Handling deprecation for yarn.resourcemanager.delayed.delegation-token.removal-interval-ms
Handling deprecation for yarn.nodemanager.localizer.fetch.thread-count
Handling deprecation for dfs.client.failover.max.attempts
Handling deprecation for yarn.resourcemanager.scheduler.address
Handling deprecation for dfs.client.read.shortcircuit.streams.cache.expiry.ms
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.start-time-write-cache-size
Handling deprecation for yarn.nodemanager.health-checker.script.timeout-ms
Handling deprecation for yarn.resourcemanager.fs.state-store.num-retries
Handling deprecation for hadoop.ssl.require.client.cert
Handling deprecation for hadoop.security.uid.cache.secs
Handling deprecation for mapreduce.jobhistory.keytab
Handling deprecation for dfs.client.read.shortcircuit.skip.checksum
Handling deprecation for yarn.resourcemanager.ha.automatic-failover.zk-base-path
Handling deprecation for mapreduce.shuffle.ssl.enabled
Handling deprecation for mapreduce.reduce.log.level
Handling deprecation for hadoop.registry.rm.enabled
Handling deprecation for mapreduce.tasktracker.dns.interface
Handling deprecation for yarn.resourcemanager.system-metrics-publisher.dispatcher.pool-size
Handling deprecation for mapreduce.job.speculative.speculative-cap-running-tasks
Handling deprecation for dfs.datanode.block.id.layout.upgrade.threads
Handling deprecation for dfs.datanode.use.datanode.hostname
Handling deprecation for dfs.client.context
Handling deprecation for yarn.resourcemanager.ha.enabled
Handling deprecation for mapred.reducer.new-api
Handling deprecation for dfs.namenode.delegation.token.renew-interval
Handling deprecation for dfs.blockreport.intervalMsec
Handling deprecation for fs.s3a.multipart.threshold
Handling deprecation for mapreduce.reduce.shuffle.memory.limit.percent
Handling deprecation for dfs.https.server.keystore.resource
Handling deprecation for io.map.index.skip
Handling deprecation for mapreduce.job.hdfs-servers
Handling deprecation for mapreduce.jobtracker.taskscheduler
Handling deprecation for dfs.namenode.kerberos.internal.spnego.principal
Handling deprecation for yarn.resourcemanager.state-store.max-completed-applications
Handling deprecation for mapreduce.map.output.compress
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.num.refill.threads
Handling deprecation for fs.s3n.multipart.uploads.block.size
Handling deprecation for mapreduce.task.merge.progress.records
Handling deprecation for dfs.datanode.dns.interface
Handling deprecation for map.sort.class
Handling deprecation for yarn.nodemanager.aux-services.mapreduce_shuffle.class
Handling deprecation for tfile.fs.output.buffer.size
Handling deprecation for fs.du.interval
Handling deprecation for dfs.client.failover.connection.retries
Handling deprecation for dfs.namenode.top.window.num.buckets
Handling deprecation for mapreduce.job.dir
Handling deprecation for fs.s3a.buffer.dir
Handling deprecation for mapreduce.reduce.shuffle.retry-delay.max.ms
Handling deprecation for yarn.sharedcache.uploader.server.address
Handling deprecation for mapreduce.client.progressmonitor.pollinterval
Handling deprecation for yarn.app.mapreduce.shuffle.log.limit.kb
Handling deprecation for dfs.datanode.max.locked.memory
Handling deprecation for dfs.namenode.retrycache.expirytime.millis
Handling deprecation for dfs.datanode.scan.period.hours
Handling deprecation for dfs.client.block.write.replace-datanode-on-failure.best-effort
Handling deprecation for mapreduce.jobhistory.move.interval-ms
Handling deprecation for dfs.ha.fencing.ssh.connect-timeout
Handling deprecation for yarn.nodemanager.log-aggregation.roll-monitoring-interval-seconds
Handling deprecation for dfs.namenode.fs-limits.max-component-length
Handling deprecation for hadoop.registry.zk.quorum
Handling deprecation for dfs.namenode.enable.retrycache
Handling deprecation for dfs.datanode.du.reserved
Handling deprecation for yarn.timeline-service.state-store-class
Handling deprecation for dfs.datanode.ipc.address
Handling deprecation for hadoop.registry.system.acls
Handling deprecation for dfs.client.block.write.replace-datanode-on-failure.policy
Handling deprecation for dfs.namenode.path.based.cache.retry.interval.ms
Handling deprecation for hadoop.security.crypto.cipher.suite
Handling deprecation for dfs.ha.tail-edits.period
Handling deprecation for mapreduce.task.profile.reduce.params
Handling deprecation for hadoop.registry.jaas.context
Handling deprecation for yarn.resourcemanager.hostname
Handling deprecation for mapreduce.reduce.memory.mb
Handling deprecation for hadoop.security.group.mapping.ldap.search.filter.group
Handling deprecation for hadoop.http.authentication.kerberos.principal
Handling deprecation for hadoop.security.group.mapping.ldap.search.filter.user
Handling deprecation for yarn.nodemanager.disk-health-checker.min-free-space-per-disk-mb
Handling deprecation for dfs.namenode.edits.dir
Handling deprecation for yarn.client.failover-retries-on-socket-timeouts
Handling deprecation for dfs.namenode.decommission.max.concurrent.tracked.nodes
Handling deprecation for mapreduce.client.completion.pollinterval
Handling deprecation for dfs.namenode.name.dir.restore
Handling deprecation for dfs.namenode.secondary.http-address
Handling deprecation for mapreduce.jobhistory.recovery.store.leveldb.path
Handling deprecation for yarn.sharedcache.store.class
Handling deprecation for s3.bytes-per-checksum
Handling deprecation for yarn.nodemanager.windows-container.cpu-limit.enabled
Handling deprecation for yarn.resourcemanager.webapp.https.address
Handling deprecation for yarn.nodemanager.vmem-pmem-ratio
Handling deprecation for dfs.namenode.checkpoint.period
Handling deprecation for dfs.ha.automatic-failover.enabled
Submitting tokens for job: job_local1634792945_0003
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.fs.FileContext.getAbstractFileSystem(FileContext.java:331)
Handling deprecation for all properties in config...
Handling deprecation for mapreduce.jobtracker.address
Handling deprecation for yarn.resourcemanager.scheduler.monitor.policies
Handling deprecation for dfs.namenode.resource.check.interval
Handling deprecation for mapreduce.jobhistory.client.thread-count
Handling deprecation for yarn.app.mapreduce.am.containerlauncher.threadpool-initial-size
Handling deprecation for mapred.child.java.opts
Handling deprecation for mapreduce.jobtracker.retiredjobs.cache.size
Handling deprecation for dfs.client.https.need-auth
Handling deprecation for yarn.admin.acl
Handling deprecation for yarn.app.mapreduce.am.job.committer.cancel-timeout
Handling deprecation for mapreduce.job.emit-timeline-data
Handling deprecation for fs.ftp.host.port
Handling deprecation for dfs.namenode.avoid.read.stale.datanode
Handling deprecation for dfs.journalnode.rpc-address
Handling deprecation for mapreduce.job.end-notification.retry.attempts
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.ttl-interval-ms
Handling deprecation for yarn.resourcemanager.leveldb-state-store.path
Handling deprecation for mapred.mapper.new-api
Handling deprecation for yarn.ipc.rpc.class
Handling deprecation for ipc.client.connection.maxidletime
Handling deprecation for yarn.nodemanager.process-kill-wait.ms
Handling deprecation for mapreduce.cluster.acls.enabled
Handling deprecation for mapreduce.jobtracker.handler.count
Handling deprecation for io.map.index.interval
Handling deprecation for dfs.namenode.https-address
Handling deprecation for mapreduce.task.profile.reduces
Handling deprecation for fs.s3n.multipart.uploads.enabled
Handling deprecation for io.seqfile.sorter.recordlimit
Handling deprecation for mapreduce.job.ubertask.maxmaps
Handling deprecation for mapreduce.tasktracker.tasks.sleeptimebeforesigkill
Handling deprecation for hadoop.util.hash.type
Handling deprecation for dfs.namenode.replication.min
Handling deprecation for yarn.nodemanager.container-manager.thread-count
Handling deprecation for mapreduce.jobtracker.jobhistory.block.size
Handling deprecation for dfs.namenode.fs-limits.min-block-size
Handling deprecation for mapreduce.app-submission.cross-platform
Handling deprecation for fs.AbstractFileSystem.file.impl
Handling deprecation for net.topology.script.number.args
Handling deprecation for yarn.resourcemanager.container-tokens.master-key-rolling-interval-secs
Handling deprecation for mapreduce.map.output.compress.codec
Handling deprecation for mapreduce.job.reducer.preempt.delay.sec
Handling deprecation for s3native.bytes-per-checksum
Handling deprecation for dfs.namenode.path.based.cache.block.map.allocation.percent
Handling deprecation for yarn.nodemanager.windows-container.memory-limit.enabled
Handling deprecation for mapreduce.input.fileinputformat.split.minsize
Handling deprecation for hadoop.security.group.mapping
Handling deprecation for mapreduce.jobtracker.system.dir
Handling deprecation for mapreduce.job.end-notification.max.attempts
Handling deprecation for mapreduce.reduce.markreset.buffer.percent
Handling deprecation for dfs.datanode.cache.revocation.polling.ms
Handling deprecation for mapreduce.reduce.speculative
Handling deprecation for yarn.nodemanager.localizer.cache.cleanup.interval-ms
Handling deprecation for dfs.namenode.lazypersist.file.scrub.interval.sec
Handling deprecation for fs.s3a.threads.core
Handling deprecation for mapreduce.jobhistory.recovery.store.fs.uri
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.start-time-read-cache-size
Handling deprecation for hadoop.registry.zk.retry.interval.ms
Handling deprecation for yarn.nodemanager.keytab
Handling deprecation for dfs.namenode.replication.interval
Handling deprecation for yarn.resourcemanager.admin.address
Handling deprecation for mapreduce.job.maps
Handling deprecation for nfs.dump.dir
Handling deprecation for mapreduce.job.user.name
Handling deprecation for mapreduce.jobtracker.maxtasks.perjob
Handling deprecation for mapreduce.job.ubertask.enable
Handling deprecation for mapreduce.job.reduce.class
Handling deprecation for yarn.nodemanager.delete.debug-delay-sec
Handling deprecation for yarn.timeline-service.ttl-enable
Handling deprecation for yarn.resourcemanager.fs.state-store.retry-policy-spec
Handling deprecation for mapreduce.reduce.skip.maxgroups
Handling deprecation for dfs.client.use.datanode.hostname
Handling deprecation for fs.trash.interval
Handling deprecation for mapreduce.job.name
Handling deprecation for mapreduce.am.max-attempts
Handling deprecation for mapreduce.jobtracker.heartbeats.in.second
Handling deprecation for yarn.resourcemanager.zk-num-retries
Handling deprecation for s3.blocksize
Handling deprecation for dfs.datanode.data.dir
Handling deprecation for mapreduce.jobtracker.persist.jobstatus.active
Handling deprecation for mapreduce.reduce.shuffle.parallelcopies
Handling deprecation for fs.s3.buffer.dir
Handling deprecation for mapreduce.jobhistory.done-dir
Handling deprecation for hadoop.security.instrumentation.requires.admin
Handling deprecation for hadoop.registry.zk.retry.ceiling.ms
Handling deprecation for nfs.rtmax
Handling deprecation for dfs.datanode.data.dir.perm
Handling deprecation for yarn.resourcemanager.container.liveness-monitor.interval-ms
Handling deprecation for yarn.nodemanager.env-whitelist
Handling deprecation for dfs.namenode.backup.address
Handling deprecation for dfs.namenode.xattrs.enabled
Handling deprecation for dfs.datanode.readahead.bytes
Handling deprecation for mapreduce.jobhistory.cleaner.enable
Handling deprecation for dfs.client.block.write.retries
Handling deprecation for mapreduce.tasktracker.http.address
Handling deprecation for yarn.nodemanager.linux-container-executor.cgroups.hierarchy
Handling deprecation for ha.failover-controller.graceful-fence.connection.retries
Handling deprecation for yarn.resourcemanager.recovery.enabled
Handling deprecation for yarn.app.mapreduce.am.container.log.backups
Handling deprecation for dfs.namenode.safemode.threshold-pct
Handling deprecation for yarn.nodemanager.disk-health-checker.interval-ms
Handling deprecation for hadoop.security.java.secure.random.algorithm
Handling deprecation for dfs.namenode.list.cache.directives.num.responses
Handling deprecation for dfs.datanode.dns.nameserver
Handling deprecation for mapreduce.cluster.temp.dir
Handling deprecation for fs.s3a.max.total.tasks
Handling deprecation for mapreduce.reduce.maxattempts
Handling deprecation for mapreduce.client.submit.file.replication
Handling deprecation for mapreduce.shuffle.port
Handling deprecation for yarn.resourcemanager.resource-tracker.client.thread-count
Handling deprecation for dfs.namenode.replication.considerLoad
Handling deprecation for dfs.namenode.edits.journal-plugin.qjournal
Handling deprecation for dfs.client.write.exclude.nodes.cache.expiry.interval.millis
Handling deprecation for yarn.nodemanager.delete.thread-count
Handling deprecation for dfs.client.mmap.cache.timeout.ms
Handling deprecation for yarn.nodemanager.admin-env
Handling deprecation for io.skip.checksum.errors
Handling deprecation for yarn.timeline-service.hostname
Handling deprecation for yarn.resourcemanager.proxy-user-privileges.enabled
Handling deprecation for mapreduce.job.speculative.speculative-cap-total-tasks
Handling deprecation for yarn.acl.enable
Handling deprecation for fs.s3a.fast.upload
Handling deprecation for file.blocksize
Handling deprecation for mapreduce.job.speculative.slowtaskthreshold
Handling deprecation for ftp.replication
Handling deprecation for yarn.sharedcache.cleaner.initial-delay-mins
Handling deprecation for s3native.client-write-packet-size
Handling deprecation for hadoop.rpc.socket.factory.class.default
Handling deprecation for file.bytes-per-checksum
Handling deprecation for dfs.datanode.slow.io.warning.threshold.ms
Handling deprecation for io.seqfile.lazydecompress
Handling deprecation for mapreduce.task.skip.start.attempts
Handling deprecation for dfs.namenode.reject-unresolved-dn-topology-mapping
Handling deprecation for hadoop.common.configuration.version
Handling deprecation for yarn.resourcemanager.client.thread-count
Handling deprecation for dfs.datanode.drop.cache.behind.reads
Handling deprecation for yarn.sharedcache.admin.address
Handling deprecation for mapreduce.job.output.value.class
Handling deprecation for mapreduce.output.fileoutputformat.outputdir
Handling deprecation for mapreduce.jobtracker.taskcache.levels
Handling deprecation for yarn.nodemanager.linux-container-executor.nonsecure-mode.user-pattern
Handling deprecation for yarn.resourcemanager.zk-timeout-ms
Handling deprecation for yarn.resourcemanager.max-completed-applications
Handling deprecation for mapreduce.job.jvm.numtasks
Handling deprecation for yarn.sharedcache.cleaner.period-mins
Handling deprecation for mapreduce.jobtracker.tasktracker.maxblacklists
Handling deprecation for dfs.namenode.top.num.users
Handling deprecation for yarn.nodemanager.linux-container-executor.cgroups.mount
Handling deprecation for yarn.sharedcache.checksum.algo.impl
Handling deprecation for mapreduce.job.end-notification.max.retry.interval
Handling deprecation for mapreduce.job.acl-view-job
Handling deprecation for mapreduce.job.classloader
Handling deprecation for yarn.log-aggregation-enable
Handling deprecation for mapreduce.reduce.shuffle.fetch.retry.interval-ms
Handling deprecation for yarn.resourcemanager.nodemanager.minimum.version
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.size
Handling deprecation for yarn.app.mapreduce.am.job.task.listener.thread-count
Handling deprecation for yarn.app.mapreduce.am.resource.cpu-vcores
Handling deprecation for dfs.namenode.edit.log.autoroll.check.interval.ms
Handling deprecation for mapreduce.output.fileoutputformat.compress.type
Handling deprecation for hadoop.hdfs.configuration.version
Handling deprecation for hadoop.security.group.mapping.ldap.search.attr.member
Handling deprecation for yarn.nodemanager.log.retain-seconds
Handling deprecation for yarn.nodemanager.local-cache.max-files-per-directory
Handling deprecation for mapreduce.job.end-notification.retry.interval
Handling deprecation for hadoop.ssl.client.conf
Handling deprecation for yarn.sharedcache.root-dir
Handling deprecation for dfs.journalnode.https-address
Handling deprecation for mapreduce.reduce.shuffle.fetch.retry.timeout-ms
Handling deprecation for dfs.bytes-per-checksum
Handling deprecation for dfs.namenode.max.objects
Handling deprecation for mapreduce.tasktracker.instrumentation
Handling deprecation for dfs.datanode.max.transfer.threads
Handling deprecation for dfs.block.access.key.update.interval
Handling deprecation for mapreduce.jobtracker.jobhistory.task.numberprogresssplits
Handling deprecation for mapreduce.map.memory.mb
Handling deprecation for ha.failover-controller.new-active.rpc-timeout.ms
Handling deprecation for hadoop.ssl.hostname.verifier
Handling deprecation for dfs.client.read.shortcircuit
Handling deprecation for dfs.datanode.hdfs-blocks-metadata.enabled
Handling deprecation for mapreduce.tasktracker.healthchecker.interval
Handling deprecation for dfs.image.transfer.chunksize
Handling deprecation for mapreduce.tasktracker.taskmemorymanager.monitoringinterval
Handling deprecation for dfs.client.https.keystore.resource
Handling deprecation for yarn.resourcemanager.connect.retry-interval.ms
Handling deprecation for yarn.timeline-service.webapp.address
Handling deprecation for s3native.blocksize
Handling deprecation for yarn.scheduler.minimum-allocation-mb
Handling deprecation for yarn.sharedcache.cleaner.resource-sleep-ms
Handling deprecation for net.topology.impl
Handling deprecation for dfs.client.failover.sleep.base.millis
Handling deprecation for dfs.permissions.superusergroup
Handling deprecation for io.seqfile.compress.blocksize
Handling deprecation for hadoop.registry.zk.retry.times
Handling deprecation for fs.AbstractFileSystem.ftp.impl
Handling deprecation for dfs.namenode.checkpoint.edits.dir
Handling deprecation for mapreduce.job.running.reduce.limit
Handling deprecation for dfs.blockreport.initialDelay
Handling deprecation for dfs.namenode.heartbeat.recheck-interval
Handling deprecation for dfs.namenode.safemode.extension
Handling deprecation for yarn.scheduler.maximum-allocation-mb
Handling deprecation for mapreduce.job.reduce.shuffle.consumer.plugin.class
Handling deprecation for yarn.nodemanager.vmem-check-enabled
Handling deprecation for mapreduce.task.io.sort.factor
Handling deprecation for mapreduce.jobtracker.persist.jobstatus.dir
Handling deprecation for dfs.client.failover.sleep.max.millis
Handling deprecation for dfs.namenode.delegation.key.update-interval
Handling deprecation for hadoop.rpc.protection
Handling deprecation for fs.permissions.umask-mode
Handling deprecation for fs.s3.sleepTimeSeconds
Handling deprecation for ha.health-monitor.rpc-timeout.ms
Handling deprecation for hadoop.http.staticuser.user
Handling deprecation for fs.s3a.connection.maximum
Handling deprecation for yarn.nodemanager.linux-container-executor.nonsecure-mode.limit-users
Handling deprecation for fs.s3a.paging.maximum
Handling deprecation for fs.AbstractFileSystem.viewfs.impl
Handling deprecation for fs.ftp.host
Handling deprecation for yarn.nodemanager.linux-container-executor.nonsecure-mode.local-user
Handling deprecation for fs.s3a.impl
Handling deprecation for hadoop.http.authentication.kerberos.keytab
Handling deprecation for dfs.namenode.fs-limits.max-blocks-per-file
Handling deprecation for mapreduce.tasktracker.http.threads
Handling deprecation for mapreduce.tasktracker.dns.nameserver
Handling deprecation for yarn.resourcemanager.am-rm-tokens.master-key-rolling-interval-secs
Handling deprecation for dfs.client.block.write.replace-datanode-on-failure.enable
Handling deprecation for io.compression.codec.bzip2.library
Handling deprecation for mapreduce.map.skip.maxrecords
Handling deprecation for dfs.client.use.legacy.blockreader.local
Handling deprecation for dfs.namenode.checkpoint.dir
Handling deprecation for dfs.namenode.top.windows.minutes
Handling deprecation for mapreduce.job.maxtaskfailures.per.tracker
Handling deprecation for net.topology.node.switch.mapping.impl
Handling deprecation for mapreduce.shuffle.max.connections
Handling deprecation for mapreduce.jobhistory.loadedjobs.cache.size
Handling deprecation for dfs.storage.policy.enabled
Handling deprecation for yarn.client.application-client-protocol.poll-interval-ms
Handling deprecation for yarn.nodemanager.localizer.address
Handling deprecation for dfs.namenode.list.cache.pools.num.responses
Handling deprecation for nfs.server.port
Handling deprecation for mapreduce.client.output.filter
Handling deprecation for yarn.timeline-service.client.best-effort
Handling deprecation for ha.zookeeper.parent-znode
Handling deprecation for mapreduce.jobtracker.persist.jobstatus.hours
Handling deprecation for yarn.sharedcache.admin.thread-count
Handling deprecation for yarn.nodemanager.resource.cpu-vcores
Handling deprecation for dfs.datanode.block-pinning.enabled
Handling deprecation for mapreduce.jobhistory.http.policy
Handling deprecation for yarn.resourcemanager.webapp.delegation-token-auth-filter.enabled
Handling deprecation for mapreduce.job.speculative.retry-after-no-speculate
Handling deprecation for fs.s3a.attempts.maximum
Handling deprecation for s3native.stream-buffer-size
Handling deprecation for io.seqfile.local.dir
Handling deprecation for yarn.log-aggregation.retain-check-interval-seconds
Handling deprecation for fs.s3n.multipart.copy.block.size
Handling deprecation for dfs.encrypt.data.transfer.cipher.key.bitlength
Handling deprecation for dfs.datanode.sync.behind.writes
Handling deprecation for yarn.resourcemanager.zk-acl
Handling deprecation for hadoop.ssl.keystores.factory.class
Handling deprecation for mapreduce.job.split.metainfo.maxsize
Handling deprecation for fs.s3.maxRetries
Handling deprecation for hadoop.security.random.device.file.path
Handling deprecation for yarn.client.nodemanager-connect.max-wait-ms
Handling deprecation for dfs.namenode.stale.datanode.interval
Handling deprecation for mapreduce.task.io.sort.mb
Handling deprecation for yarn.resourcemanager.zk-state-store.parent-path
Handling deprecation for yarn.app.mapreduce.client-am.ipc.max-retries
Handling deprecation for fs.client.resolve.remote.symlinks
Handling deprecation for yarn.nodemanager.linux-container-executor.cgroups.strict-resource-usage
Handling deprecation for hadoop.ssl.enabled.protocols
Handling deprecation for mapreduce.reduce.cpu.vcores
Handling deprecation for yarn.client.failover-retries
Handling deprecation for mapreduce.jobhistory.address
Handling deprecation for hadoop.ssl.enabled
Handling deprecation for dfs.replication.max
Handling deprecation for dfs.namenode.name.dir
Handling deprecation for dfs.datanode.https.address
Handling deprecation for ipc.client.kill.max
Handling deprecation for mapreduce.job.committer.setup.cleanup.needed
Handling deprecation for dfs.client.domain.socket.data.traffic
Handling deprecation for yarn.nodemanager.localizer.cache.target-size-mb
Handling deprecation for yarn.resourcemanager.admin.client.thread-count
Handling deprecation for dfs.block.access.token.enable
Handling deprecation for mapreduce.job.speculative.retry-after-speculate
Handling deprecation for dfs.datanode.address
Handling deprecation for mapreduce.jobtracker.restart.recover
Handling deprecation for ipc.client.connect.max.retries
Handling deprecation for yarn.timeline-service.store-class
Handling deprecation for dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
Handling deprecation for hadoop.tmp.dir
Handling deprecation for dfs.datanode.handler.count
Handling deprecation for yarn.resourcemanager.ha.automatic-failover.embedded
Handling deprecation for yarn.timeline-service.ttl-ms
Handling deprecation for mapreduce.task.profile.map.params
Handling deprecation for yarn.resourcemanager.nodemanagers.heartbeat-interval-ms
Handling deprecation for mapreduce.map.speculative
Handling deprecation for yarn.timeline-service.recovery.enabled
Handling deprecation for mapreduce.job.map.class
Handling deprecation for dfs.namenode.resource.checked.volumes.minimum
Handling deprecation for yarn.nodemanager.recovery.dir
Handling deprecation for mapreduce.job.counters.max
Handling deprecation for yarn.resourcemanager.keytab
Handling deprecation for dfs.namenode.max.extra.edits.segments.retained
Handling deprecation for dfs.webhdfs.user.provider.user.pattern
Handling deprecation for dfs.client.mmap.enabled
Handling deprecation for mapreduce.map.log.level
Handling deprecation for dfs.client.file-block-storage-locations.timeout.millis
Handling deprecation for yarn.client.max-cached-nodemanagers-proxies
Handling deprecation for yarn.app.mapreduce.am.scheduler.heartbeat.interval-ms
Handling deprecation for hadoop.fuse.timer.period
Handling deprecation for fs.trash.checkpoint.interval
Handling deprecation for yarn.sharedcache.app-checker.class
Handling deprecation for dfs.journalnode.http-address
Handling deprecation for yarn.app.mapreduce.am.staging-dir
Handling deprecation for mapreduce.tasktracker.local.dir.minspacestart
Handling deprecation for yarn.nm.liveness-monitor.expiry-interval-ms
Handling deprecation for ha.health-monitor.check-interval.ms
Handling deprecation for mapreduce.reduce.shuffle.merge.percent
Handling deprecation for dfs.namenode.retrycache.heap.percent
Handling deprecation for yarn.nodemanager.docker-container-executor.exec-name
Handling deprecation for ipc.client.connect.timeout
Handling deprecation for yarn.resourcemanager.fs.state-store.retry-interval-ms
Handling deprecation for mapreduce.output.fileoutputformat.compress
Handling deprecation for yarn.nodemanager.local-dirs
Handling deprecation for yarn.nodemanager.recovery.enabled
Handling deprecation for io.native.lib.available
Handling deprecation for yarn.sharedcache.store.in-memory.staleness-period-mins
Handling deprecation for yarn.resourcemanager.am.max-attempts
Handling deprecation for s3.replication
Handling deprecation for mapreduce.input.fileinputformat.inputdir
Handling deprecation for fs.AbstractFileSystem.har.impl
Handling deprecation for dfs.image.compress
Handling deprecation for mapreduce.job.running.map.limit
Handling deprecation for mapreduce.reduce.input.buffer.percent
Handling deprecation for yarn.nodemanager.webapp.address
Handling deprecation for dfs.datanode.available-space-volume-choosing-policy.balanced-space-preference-fraction
Handling deprecation for dfs.namenode.edit.log.autoroll.multiplier.threshold
Handling deprecation for hadoop.security.group.mapping.ldap.ssl
Handling deprecation for dfs.namenode.checkpoint.check.period
Handling deprecation for fs.defaultFS
Handling deprecation for fs.s3a.multipart.size
Handling deprecation for dfs.client.slow.io.warning.threshold.ms
Handling deprecation for yarn.app.mapreduce.am.job.committer.commit-window
Handling deprecation for hadoop.security.group.mapping.ldap.search.attr.group.name
Handling deprecation for yarn.nodemanager.disk-health-checker.max-disk-utilization-per-disk-percentage
Handling deprecation for yarn.nodemanager.container-monitor.procfs-tree.smaps-based-rss.enabled
Handling deprecation for mapreduce.job.submithostname
Handling deprecation for mapreduce.map.sort.spill.percent
Handling deprecation for hadoop.security.crypto.codec.classes.aes.ctr.nopadding
Handling deprecation for dfs.namenode.http-address
Handling deprecation for hadoop.security.groups.negative-cache.secs
Handling deprecation for hadoop.ssl.server.conf
Handling deprecation for mapreduce.ifile.readahead
Handling deprecation for s3native.replication
Handling deprecation for yarn.client.nodemanager-client-async.thread-pool-max-size
Handling deprecation for mapreduce.jobtracker.staging.root.dir
Handling deprecation for mapreduce.jobhistory.admin.address
Handling deprecation for dfs.namenode.startup.delay.block.deletion.sec
Handling deprecation for yarn.nodemanager.health-checker.interval-ms
Handling deprecation for dfs.namenode.checkpoint.max-retries
Handling deprecation for s3.stream-buffer-size
Handling deprecation for ftp.client-write-packet-size
Handling deprecation for dfs.datanode.fsdatasetcache.max.threads.per.volume
Handling deprecation for mapreduce.output.fileoutputformat.compress.codec
Handling deprecation for yarn.timeline-service.keytab
Handling deprecation for yarn.sharedcache.store.in-memory.initial-delay-mins
Handling deprecation for mapreduce.jobhistory.webapp.address
Handling deprecation for mapreduce.task.userlog.limit.kb
Handling deprecation for mapreduce.reduce.shuffle.fetch.retry.enabled
Handling deprecation for yarn.app.mapreduce.task.container.log.backups
Handling deprecation for dfs.heartbeat.interval
Handling deprecation for ha.zookeeper.session-timeout.ms
Handling deprecation for fs.s3a.connection.ssl.enabled
Handling deprecation for yarn.sharedcache.webapp.address
Handling deprecation for hadoop.http.authentication.signature.secret.file
Handling deprecation for hadoop.fuse.connection.timeout
Handling deprecation for mapreduce.input.fileinputformat.numinputfiles
Handling deprecation for yarn.nodemanager.log-aggregation.compression-type
Handling deprecation for ipc.server.max.connections
Handling deprecation for yarn.resourcemanager.work-preserving-recovery.scheduling-wait-ms
Handling deprecation for yarn.nodemanager.log-dirs
Handling deprecation for yarn.app.mapreduce.am.resource.mb
Handling deprecation for hadoop.security.groups.cache.secs
Handling deprecation for mapreduce.job.speculative.minimum-allowed-tasks
Handling deprecation for yarn.nodemanager.container-monitor.interval-ms
Handling deprecation for dfs.datanode.cache.revocation.timeout.ms
Handling deprecation for mapreduce.jobhistory.recovery.store.class
Handling deprecation for mapreduce.task.combine.progress.records
Handling deprecation for s3.client-write-packet-size
Handling deprecation for mapreduce.jobtracker.instrumentation
Handling deprecation for dfs.replication
Handling deprecation for mapreduce.shuffle.transfer.buffer.size
Handling deprecation for hadoop.security.group.mapping.ldap.directory.search.timeout
Handling deprecation for dfs.datanode.available-space-volume-choosing-policy.balanced-space-threshold
Handling deprecation for hadoop.work.around.non.threadsafe.getpwuid
Handling deprecation for yarn.app.mapreduce.client-am.ipc.max-retries-on-timeouts
Handling deprecation for yarn.nodemanager.address
Handling deprecation for mapreduce.tasktracker.taskcontroller
Handling deprecation for mapreduce.tasktracker.indexcache.mb
Handling deprecation for yarn.scheduler.maximum-allocation-vcores
Handling deprecation for mapreduce.job.reduces
Handling deprecation for yarn.nodemanager.sleep-delay-before-sigkill.ms
Handling deprecation for yarn.timeline-service.address
Handling deprecation for yarn.resourcemanager.configuration.provider-class
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.expiry
Handling deprecation for yarn.sharedcache.enabled
Handling deprecation for tfile.io.chunk.size
Handling deprecation for mapreduce.job.acl-modify-job
Handling deprecation for hadoop.registry.zk.session.timeout.ms
Handling deprecation for fs.automatic.close
Handling deprecation for ha.health-monitor.sleep-after-disconnect.ms
Handling deprecation for mapreduce.tasktracker.reduce.tasks.maximum
Handling deprecation for mapreduce.input.fileinputformat.list-status.num-threads
Handling deprecation for dfs.datanode.directoryscan.threads
Handling deprecation for dfs.datanode.directoryscan.interval
Handling deprecation for dfs.namenode.acls.enabled
Handling deprecation for dfs.client.short.circuit.replica.stale.threshold.ms
Handling deprecation for hadoop.http.authentication.token.validity
Handling deprecation for fs.s3.block.size
Handling deprecation for ha.failover-controller.graceful-fence.rpc-timeout.ms
Handling deprecation for mapreduce.tasktracker.local.dir.minspacekill
Handling deprecation for dfs.namenode.resource.du.reserved
Handling deprecation for mapreduce.jobhistory.cleaner.interval-ms
Handling deprecation for dfs.namenode.datanode.registration.ip-hostname-check
Handling deprecation for mapreduce.jobhistory.intermediate-done-dir
Handling deprecation for mapreduce.jobtracker.http.address
Handling deprecation for dfs.namenode.backup.http-address
Handling deprecation for dfs.namenode.edits.noeditlogchannelflush
Handling deprecation for mapreduce.reduce.shuffle.input.buffer.percent
Handling deprecation for mapreduce.map.maxattempts
Handling deprecation for yarn.http.policy
Handling deprecation for dfs.namenode.audit.loggers
Handling deprecation for hadoop.security.groups.cache.warn.after.ms
Handling deprecation for io.serializations
Handling deprecation for mapreduce.tasktracker.outofband.heartbeat
Handling deprecation for mapreduce.reduce.shuffle.read.timeout
Handling deprecation for hadoop.security.crypto.buffer.size
Handling deprecation for mapreduce.reduce.skip.proc.count.autoincr
Handling deprecation for mapreduce.ifile.readahead.bytes
Handling deprecation for dfs.http.policy
Handling deprecation for hadoop.registry.secure
Handling deprecation for dfs.namenode.safemode.min.datanodes
Handling deprecation for dfs.client.file-block-storage-locations.num-threads
Handling deprecation for mapreduce.cluster.local.dir
Handling deprecation for mapreduce.tasktracker.report.address
Handling deprecation for dfs.namenode.secondary.https-address
Handling deprecation for hadoop.kerberos.kinit.command
Handling deprecation for yarn.timeline-service.http-authentication.type
Handling deprecation for dfs.block.access.token.lifetime
Handling deprecation for dfs.webhdfs.enabled
Handling deprecation for dfs.namenode.delegation.token.max-lifetime
Handling deprecation for dfs.namenode.avoid.write.stale.datanode
Handling deprecation for dfs.datanode.drop.cache.behind.writes
Handling deprecation for yarn.log-aggregation.retain-seconds
Handling deprecation for mapreduce.job.complete.cancel.delegation.tokens
Handling deprecation for mapreduce.local.clientfactory.class.name
Handling deprecation for mapreduce.shuffle.connection-keep-alive.timeout
Handling deprecation for dfs.namenode.num.extra.edits.retained
Handling deprecation for yarn.scheduler.minimum-allocation-vcores
Handling deprecation for ipc.client.connect.max.retries.on.timeouts
Handling deprecation for yarn.timeline-service.client.retry-interval-ms
Handling deprecation for yarn.timeline-service.client.max-retries
Handling deprecation for fs.s3n.block.size
Handling deprecation for mapreduce.job.map.output.collector.class
Handling deprecation for ha.health-monitor.connect-retry-interval.ms
Handling deprecation for mapreduce.shuffle.max.threads
Handling deprecation for nfs.exports.allowed.hosts
Handling deprecation for dfs.client.mmap.cache.size
Handling deprecation for mapreduce.tasktracker.map.tasks.maximum
Handling deprecation for io.file.buffer.size
Handling deprecation for dfs.client.datanode-restart.timeout
Handling deprecation for io.mapfile.bloom.size
Handling deprecation for hadoop.security.kms.client.authentication.retry-count
Handling deprecation for dfs.namenode.checkpoint.txns
Handling deprecation for ipc.client.connect.retry.interval
Handling deprecation for dfs.client-write-packet-size
Handling deprecation for mapreduce.reduce.shuffle.connect.timeout
Handling deprecation for yarn.resourcemanager.fs.state-store.uri
Handling deprecation for fs.swift.impl
Handling deprecation for hadoop.registry.zk.connection.timeout.ms
Handling deprecation for mapred.queue.default.acl-administer-jobs
Handling deprecation for mapreduce.job.submithostaddress
Handling deprecation for dfs.cachereport.intervalMsec
Handling deprecation for yarn.app.mapreduce.shuffle.log.backups
Handling deprecation for yarn.app.mapreduce.am.container.log.limit.kb
Handling deprecation for yarn.nodemanager.resourcemanager.minimum.version
Handling deprecation for ftp.blocksize
Handling deprecation for yarn.resourcemanager.address
Handling deprecation for file.stream-buffer-size
Handling deprecation for yarn.resourcemanager.scheduler.monitor.enable
Handling deprecation for mapreduce.job.ubertask.maxreduces
Handling deprecation for nfs.allow.insecure.ports
Handling deprecation for yarn.sharedcache.nm.uploader.thread-count
Handling deprecation for ipc.client.idlethreshold
Handling deprecation for ftp.stream-buffer-size
Handling deprecation for yarn.sharedcache.client-server.address
Handling deprecation for dfs.client.failover.connection.retries.on.timeouts
Handling deprecation for dfs.namenode.replication.work.multiplier.per.iteration
Handling deprecation for hadoop.http.authentication.simple.anonymous.allowed
Handling deprecation for hadoop.security.authorization
Handling deprecation for yarn.client.nodemanager-connect.retry-interval-ms
Handling deprecation for yarn.am.liveness-monitor.expiry-interval-ms
Handling deprecation for fs.har.impl.disable.cache
Handling deprecation for yarn.nodemanager.linux-container-executor.resources-handler.class
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.read-cache-size
Handling deprecation for hadoop.security.authentication
Handling deprecation for dfs.image.compression.codec
Handling deprecation for mapreduce.task.files.preserve.failedtasks
Handling deprecation for dfs.client.read.shortcircuit.streams.cache.size
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.path
Handling deprecation for mapreduce.job.reduce.slowstart.completedmaps
Handling deprecation for mapreduce.jobhistory.minicluster.fixed.ports
Handling deprecation for file.replication
Handling deprecation for yarn.resourcemanager.ha.automatic-failover.enabled
Handling deprecation for mapreduce.job.userlog.retain.hours
Handling deprecation for mapreduce.jobhistory.joblist.cache.size
Handling deprecation for dfs.namenode.accesstime.precision
Handling deprecation for yarn.resourcemanager.work-preserving-recovery.enabled
Handling deprecation for dfs.namenode.fs-limits.max-xattrs-per-inode
Handling deprecation for io.mapfile.bloom.error.rate
Handling deprecation for yarn.resourcemanager.store.class
Handling deprecation for dfs.image.transfer.timeout
Handling deprecation for yarn.timeline-service.leveldb-state-store.path
Handling deprecation for nfs.wtmax
Handling deprecation for mapreduce.job.combine.class
Handling deprecation for dfs.namenode.support.allow.format
Handling deprecation for fs.s3a.multipart.purge
Handling deprecation for dfs.secondary.namenode.kerberos.internal.spnego.principal
Handling deprecation for fs.s3a.connection.establish.timeout
Handling deprecation for dfs.stream-buffer-size
Handling deprecation for dfs.namenode.invalidate.work.pct.per.iteration
Handling deprecation for yarn.nodemanager.container-executor.class
Handling deprecation for fs.s3a.multipart.purge.age
Handling deprecation for yarn.resourcemanager.scheduler.client.thread-count
Handling deprecation for dfs.namenode.top.enabled
Handling deprecation for yarn.app.mapreduce.shuffle.log.separate
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.low-watermark
Handling deprecation for fs.s3a.fast.buffer.size
Handling deprecation for hadoop.user.group.static.mapping.overrides
Handling deprecation for tfile.fs.input.buffer.size
Handling deprecation for dfs.client.cached.conn.retry
Handling deprecation for hadoop.http.authentication.type
Handling deprecation for dfs.namenode.list.encryption.zones.num.responses
Handling deprecation for mapreduce.map.cpu.vcores
Handling deprecation for dfs.namenode.path.based.cache.refresh.interval.ms
Handling deprecation for dfs.namenode.decommission.interval
Handling deprecation for dfs.namenode.fs-limits.max-directory-items
Handling deprecation for yarn.resourcemanager.zk-retry-interval-ms
Handling deprecation for ftp.bytes-per-checksum
Handling deprecation for dfs.ha.log-roll.period
Handling deprecation for dfs.user.home.dir.prefix
Handling deprecation for ipc.client.fallback-to-simple-auth-allowed
Handling deprecation for yarn.nodemanager.pmem-check-enabled
Handling deprecation for yarn.nodemanager.remote-app-log-dir
Handling deprecation for dfs.namenode.inotify.max.events.per.rpc
Handling deprecation for mapreduce.task.profile.maps
Handling deprecation for mapreduce.shuffle.ssl.file.buffer.size
Handling deprecation for mapreduce.tasktracker.healthchecker.script.timeout
Handling deprecation for yarn.timeline-service.webapp.https.address
Handling deprecation for yarn.nodemanager.resource.percentage-physical-cpu-limit
Handling deprecation for yarn.app.mapreduce.am.command-opts
Handling deprecation for dfs.namenode.fs-limits.max-xattr-size
Handling deprecation for dfs.datanode.http.address
Handling deprecation for dfs.namenode.blocks.per.postponedblocks.rescan
Handling deprecation for yarn.sharedcache.nm.uploader.replication.factor
Handling deprecation for hadoop.registry.zk.root
Handling deprecation for hadoop.jetty.logs.serve.aliases
Handling deprecation for yarn.client.failover-proxy-provider
Handling deprecation for mapreduce.jobhistory.admin.acl
Handling deprecation for yarn.app.mapreduce.am.hard-kill-timeout-ms
Handling deprecation for yarn.nodemanager.remote-app-log-dir-suffix
Handling deprecation for mapreduce.jobhistory.principal
Handling deprecation for yarn.resourcemanager.webapp.address
Handling deprecation for mapreduce.jobhistory.recovery.enable
Handling deprecation for yarn.sharedcache.store.in-memory.check-period-mins
Handling deprecation for nfs.mountd.port
Handling deprecation for mapreduce.reduce.merge.inmem.threshold
Handling deprecation for fs.df.interval
Handling deprecation for yarn.timeline-service.enabled
Handling deprecation for mapreduce.jobtracker.jobhistory.lru.cache.size
Handling deprecation for mapreduce.task.profile
Handling deprecation for mapreduce.job.output.key.class
Handling deprecation for yarn.nodemanager.hostname
Handling deprecation for dfs.namenode.num.checkpoints.retained
Handling deprecation for mapreduce.job.queuename
Handling deprecation for mapreduce.jobhistory.max-age-ms
Handling deprecation for mapreduce.job.token.tracking.ids.enabled
Handling deprecation for yarn.nodemanager.localizer.client.thread-count
Handling deprecation for yarn.sharedcache.uploader.server.thread-count
Handling deprecation for dfs.client.mmap.retry.timeout.ms
Handling deprecation for mapreduce.jobhistory.move.thread-count
Handling deprecation for dfs.permissions.enabled
Handling deprecation for dfs.blockreport.split.threshold
Handling deprecation for fs.AbstractFileSystem.hdfs.impl
Handling deprecation for dfs.datanode.balance.bandwidthPerSec
Handling deprecation for dfs.block.scanner.volume.bytes.per.second
Handling deprecation for hadoop.http.filter.initializers
Handling deprecation for yarn.timeline-service.http-authentication.simple.anonymous.allowed
Handling deprecation for dfs.default.chunk.view.size
Handling deprecation for yarn.sharedcache.client-server.thread-count
Handling deprecation for yarn.resourcemanager.resource-tracker.address
Handling deprecation for mapreduce.job.working.dir
Handling deprecation for mapreduce.jobhistory.datestring.cache.size
Handling deprecation for mapreduce.task.profile.params
Handling deprecation for dfs.namenode.decommission.blocks.per.interval
Handling deprecation for dfs.namenode.handler.count
Handling deprecation for dfs.image.transfer.bandwidthPerSec
Handling deprecation for rpc.metrics.quantile.enable
Handling deprecation for mapreduce.jobtracker.expire.trackers.interval
Handling deprecation for mapreduce.task.timeout
Handling deprecation for yarn.app.mapreduce.client.max-retries
Handling deprecation for yarn.nodemanager.resource.memory-mb
Handling deprecation for yarn.nodemanager.disk-health-checker.min-healthy-disks
Handling deprecation for dfs.datanode.failed.volumes.tolerated
Handling deprecation for yarn.timeline-service.handler-thread-count
Handling deprecation for ipc.server.listen.queue.size
Handling deprecation for fs.s3a.threads.max
Handling deprecation for yarn.resourcemanager.connect.max-wait.ms
Handling deprecation for mapreduce.fileoutputcommitter.algorithm.version
Handling deprecation for mapreduce.framework.name
Handling deprecation for mapreduce.map.skip.proc.count.autoincr
Handling deprecation for mapreduce.job.max.split.locations
Handling deprecation for yarn.resourcemanager.scheduler.class
Handling deprecation for yarn.resourcemanager.system-metrics-publisher.enabled
Handling deprecation for dfs.blocksize
Handling deprecation for yarn.sharedcache.nested-level
Handling deprecation for mapreduce.shuffle.connection-keep-alive.enable
Handling deprecation for fs.s3a.threads.keepalivetime
Handling deprecation for fs.s3a.connection.timeout
Handling deprecation for file.client-write-packet-size
Handling deprecation for ha.failover-controller.cli-check.rpc-timeout.ms
Handling deprecation for ha.zookeeper.acl
Handling deprecation for dfs.namenode.write.stale.datanode.ratio
Handling deprecation for dfs.encrypt.data.transfer
Handling deprecation for dfs.datanode.shared.file.descriptor.paths
Handling deprecation for mapreduce.input.lineinputformat.linespermap
Handling deprecation for yarn.resourcemanager.delayed.delegation-token.removal-interval-ms
Handling deprecation for yarn.nodemanager.localizer.fetch.thread-count
Handling deprecation for dfs.client.failover.max.attempts
Handling deprecation for yarn.resourcemanager.scheduler.address
Handling deprecation for dfs.client.read.shortcircuit.streams.cache.expiry.ms
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.start-time-write-cache-size
Handling deprecation for yarn.nodemanager.health-checker.script.timeout-ms
Handling deprecation for yarn.resourcemanager.fs.state-store.num-retries
Handling deprecation for hadoop.ssl.require.client.cert
Handling deprecation for hadoop.security.uid.cache.secs
Handling deprecation for mapreduce.jobhistory.keytab
Handling deprecation for dfs.client.read.shortcircuit.skip.checksum
Handling deprecation for yarn.resourcemanager.ha.automatic-failover.zk-base-path
Handling deprecation for mapreduce.shuffle.ssl.enabled
Handling deprecation for mapreduce.reduce.log.level
Handling deprecation for hadoop.registry.rm.enabled
Handling deprecation for mapreduce.tasktracker.dns.interface
Handling deprecation for yarn.resourcemanager.system-metrics-publisher.dispatcher.pool-size
Handling deprecation for mapreduce.job.speculative.speculative-cap-running-tasks
Handling deprecation for dfs.datanode.block.id.layout.upgrade.threads
Handling deprecation for dfs.datanode.use.datanode.hostname
Handling deprecation for dfs.client.context
Handling deprecation for yarn.resourcemanager.ha.enabled
Handling deprecation for mapred.reducer.new-api
Handling deprecation for dfs.namenode.delegation.token.renew-interval
Handling deprecation for dfs.blockreport.intervalMsec
Handling deprecation for fs.s3a.multipart.threshold
Handling deprecation for mapreduce.reduce.shuffle.memory.limit.percent
Handling deprecation for dfs.https.server.keystore.resource
Handling deprecation for io.map.index.skip
Handling deprecation for mapreduce.job.hdfs-servers
Handling deprecation for mapreduce.jobtracker.taskscheduler
Handling deprecation for dfs.namenode.kerberos.internal.spnego.principal
Handling deprecation for yarn.resourcemanager.state-store.max-completed-applications
Handling deprecation for mapreduce.map.output.compress
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.num.refill.threads
Handling deprecation for fs.s3n.multipart.uploads.block.size
Handling deprecation for mapreduce.task.merge.progress.records
Handling deprecation for dfs.datanode.dns.interface
Handling deprecation for map.sort.class
Handling deprecation for yarn.nodemanager.aux-services.mapreduce_shuffle.class
Handling deprecation for tfile.fs.output.buffer.size
Handling deprecation for fs.du.interval
Handling deprecation for dfs.client.failover.connection.retries
Handling deprecation for dfs.namenode.top.window.num.buckets
Handling deprecation for mapreduce.job.dir
Handling deprecation for fs.s3a.buffer.dir
Handling deprecation for mapreduce.reduce.shuffle.retry-delay.max.ms
Handling deprecation for yarn.sharedcache.uploader.server.address
Handling deprecation for mapreduce.client.progressmonitor.pollinterval
Handling deprecation for yarn.app.mapreduce.shuffle.log.limit.kb
Handling deprecation for dfs.datanode.max.locked.memory
Handling deprecation for dfs.namenode.retrycache.expirytime.millis
Handling deprecation for dfs.datanode.scan.period.hours
Handling deprecation for dfs.client.block.write.replace-datanode-on-failure.best-effort
Handling deprecation for mapreduce.jobhistory.move.interval-ms
Handling deprecation for dfs.ha.fencing.ssh.connect-timeout
Handling deprecation for yarn.nodemanager.log-aggregation.roll-monitoring-interval-seconds
Handling deprecation for dfs.namenode.fs-limits.max-component-length
Handling deprecation for hadoop.registry.zk.quorum
Handling deprecation for dfs.namenode.enable.retrycache
Handling deprecation for dfs.datanode.du.reserved
Handling deprecation for yarn.timeline-service.state-store-class
Handling deprecation for dfs.datanode.ipc.address
Handling deprecation for hadoop.registry.system.acls
Handling deprecation for dfs.client.block.write.replace-datanode-on-failure.policy
Handling deprecation for dfs.namenode.path.based.cache.retry.interval.ms
Handling deprecation for hadoop.security.crypto.cipher.suite
Handling deprecation for dfs.ha.tail-edits.period
Handling deprecation for mapreduce.task.profile.reduce.params
Handling deprecation for hadoop.registry.jaas.context
Handling deprecation for yarn.resourcemanager.hostname
Handling deprecation for mapreduce.reduce.memory.mb
Handling deprecation for hadoop.security.group.mapping.ldap.search.filter.group
Handling deprecation for hadoop.http.authentication.kerberos.principal
Handling deprecation for hadoop.security.group.mapping.ldap.search.filter.user
Handling deprecation for yarn.nodemanager.disk-health-checker.min-free-space-per-disk-mb
Handling deprecation for dfs.namenode.edits.dir
Handling deprecation for yarn.client.failover-retries-on-socket-timeouts
Handling deprecation for dfs.namenode.decommission.max.concurrent.tracked.nodes
Handling deprecation for mapreduce.client.completion.pollinterval
Handling deprecation for dfs.namenode.name.dir.restore
Handling deprecation for dfs.namenode.secondary.http-address
Handling deprecation for mapreduce.jobhistory.recovery.store.leveldb.path
Handling deprecation for yarn.sharedcache.store.class
Handling deprecation for s3.bytes-per-checksum
Handling deprecation for yarn.nodemanager.windows-container.cpu-limit.enabled
Handling deprecation for yarn.resourcemanager.webapp.https.address
Handling deprecation for yarn.nodemanager.vmem-pmem-ratio
Handling deprecation for dfs.namenode.checkpoint.period
Handling deprecation for dfs.ha.automatic-failover.enabled
The url to track the job: http://localhost:8080/
Running job: job_local1634792945_0003
OutputCommitter set in config null
File Output Committer Algorithm version is 1
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
/user/michaeljones/wcOutputAnalysis/_temporary/0: masked=rwxr-xr-x
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones sending #58
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones got value #58
Call: mkdirs took 5ms
Starting mapper thread pool executor.
Max local threads: 1
Map tasks to process: 1
Waiting for map tasks
Starting task: attempt_local1634792945_0003_m_000000_0
currentIndex 0   0:0
mapreduce.cluster.local.dir for child : /tmp/hadoop-michaeljones/mapred/local/localRunner//michaeljones/jobcache/job_local1634792945_0003/attempt_local1634792945_0003_m_000000_0
using new api for output committer
File Output Committer Algorithm version is 1
ProcfsBasedProcessTree currently is supported only on Linux.
 Using ResourceCalculatorProcessTree : null
Processing split: hdfs://localhost:9000/user/michaeljones/wcInput:0+50
Trying map output collector class: org.apache.hadoop.mapred.MapTask$MapOutputBuffer
(EQUATOR) 0 kvi 26214396(104857584)
mapreduce.task.io.sort.mb: 100
soft limit at 83886080
bufstart = 0; bufvoid = 104857600
kvstart = 26214396; length = 6553600
Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones sending #59
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones got value #59
Call: getBlockLocations took 3ms
newInfo = LocatedBlocks{
  fileLength=50
  underConstruction=false
  blocks=[LocatedBlock{BP-1045030256-10.0.0.2-1433119149314:blk_1073741825_1002; getBlockSize()=50; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-b42c5705-9ba4-4b14-b00b-f9194bb036f0,DISK]]}]
  lastLocatedBlock=LocatedBlock{BP-1045030256-10.0.0.2-1433119149314:blk_1073741825_1002; getBlockSize()=50; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-b42c5705-9ba4-4b14-b00b-f9194bb036f0,DISK]]}
  isLastBlockComplete=true}
Connecting to datanode 127.0.0.1:50010

Starting flush of map output
Spilling map output
bufstart = 0; bufend = 82; bufvoid = 104857600
kvstart = 26214396(104857584); kvend = 26214368(104857472); length = 29/6553600
IntSumCombinerAnalyser-Bye[1]
IntSumCombinerAnalyser-Goodbye[1]
IntSumCombinerAnalyser-Hadoop[1,1]
IntSumCombinerAnalyser-Hello[1,1]
IntSumCombinerAnalyser-World[1,1]
Finished spill 0
Task:attempt_local1634792945_0003_m_000000_0 is done. And is in the process of committing
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones sending #60
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones got value #60
Call: getFileInfo took 2ms
map
Task 'attempt_local1634792945_0003_m_000000_0' done.
Finishing task: attempt_local1634792945_0003_m_000000_0
map task executor complete.
Starting reduce thread pool executor.
Max local threads: 1
Reduce tasks to process: 1
Waiting for reduce tasks
Starting task: attempt_local1634792945_0003_r_000000_0
currentIndex 0   0:0
mapreduce.cluster.local.dir for child : /tmp/hadoop-michaeljones/mapred/local/localRunner//michaeljones/jobcache/job_local1634792945_0003/attempt_local1634792945_0003_r_000000_0
using new api for output committer
File Output Committer Algorithm version is 1
ProcfsBasedProcessTree currently is supported only on Linux.
 Using ResourceCalculatorProcessTree : null
Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@6fff55c2
MergerManager: memoryLimit=668309888, maxSingleShuffleLimit=167077472, mergeThreshold=441084544, ioSortFactor=10, memToMemMergeOutputsThreshold=10
attempt_local1634792945_0003_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
Got 0 map completion events from 0
GetMapEventsThread about to sleep for 1000
LocalFetcher 3 going to fetch: attempt_local1634792945_0003_m_000000_0
attempt_local1634792945_0003_m_000000_0: Proceeding with shuffle since usedMemory (0) is lesser than memoryLimit (668309888).CommitMemory is (0)
localfetcher#3 about to shuffle output of map attempt_local1634792945_0003_m_000000_0 decomp: 63 len: 67 to MEMORY
Read 63 bytes from map-output for attempt_local1634792945_0003_m_000000_0
closeInMemoryFile -> map-output of size: 63, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->63
map attempt_local1634792945_0003_m_000000_0 done 1 / 1 copied.
EventFetcher is interrupted.. Returning
1 / 1 copied.
finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
Merging 1 sorted segments
Down to the last merge-pass, with 1 segments left of total size: 57 bytes
Merged 1 segments, 63 bytes to disk to satisfy reduce memory limit
Disk file: /tmp/hadoop-michaeljones/mapred/local/localRunner/michaeljones/jobcache/job_local1634792945_0003/attempt_local1634792945_0003_r_000000_0/output/map_0.out.merged Length is 67
Merging 1 files, 67 bytes from disk
Merging 0 segments, 0 bytes from memory into reduce
Merging 1 sorted segments
Down to the last merge-pass, with 1 segments left of total size: 57 bytes
1 / 1 copied.
/user/michaeljones/wcOutputAnalysis/_temporary/0/_temporary/attempt_local1634792945_0003_r_000000_0/part-r-00000: masked=rw-r--r--
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones sending #61
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones got value #61
Call: create took 4ms
computePacketChunkSize: src=/user/michaeljones/wcOutputAnalysis/_temporary/0/_temporary/attempt_local1634792945_0003_r_000000_0/part-r-00000, chunkSize=516, chunksPerPacket=126, packetSize=65016
IntSumReducerAnalyser-Bye[1]
IntSumReducerAnalyser-Goodbye[1]
IntSumReducerAnalyser-Hadoop[2]
IntSumReducerAnalyser-Hello[2]
IntSumReducerAnalyser-World[2]
DFSClient writeChunk allocating new packet seqno=0, src=/user/michaeljones/wcOutputAnalysis/_temporary/0/_temporary/attempt_local1634792945_0003_r_000000_0/part-r-00000, packetSize=65016, chunksPerPacket=126, bytesCurBlock=0
Queued packet 0
Queued packet 1
Waiting for ack for: 1
Allocating new block
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones sending #62
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones got value #62
Call: addBlock took 3ms
pipeline = DatanodeInfoWithStorage[127.0.0.1:50010,DS-b42c5705-9ba4-4b14-b00b-f9194bb036f0,DISK]
Connecting to datanode 127.0.0.1:50010
Send buf size 131072
SASL client skipping handshake in unsecured configuration for addr = /127.0.0.1, datanodeId = DatanodeInfoWithStorage[127.0.0.1:50010,DS-b42c5705-9ba4-4b14-b00b-f9194bb036f0,DISK]
DataStreamer block BP-1045030256-10.0.0.2-1433119149314:blk_1073742330_1507 sending packet packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 41
DFSClient seqno: 0 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
DataStreamer block BP-1045030256-10.0.0.2-1433119149314:blk_1073742330_1507 sending packet packet seqno: 1 offsetInBlock: 41 lastPacketInBlock: true lastByteOffsetInBlock: 41
DFSClient seqno: 1 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
Closing old block BP-1045030256-10.0.0.2-1433119149314:blk_1073742330_1507
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones sending #63
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones got value #63
Call: complete took 3ms
Task:attempt_local1634792945_0003_r_000000_0 is done. And is in the process of committing
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones sending #64
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones got value #64
Call: getFileInfo took 2ms
1 / 1 copied.
Task attempt_local1634792945_0003_r_000000_0 is allowed to commit now
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones sending #65
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones got value #65
Call: getFileInfo took 2ms
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones sending #66
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones got value #66
Call: getFileInfo took 2ms
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones sending #67
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones got value #67
Call: rename took 3ms
Saved output of task 'attempt_local1634792945_0003_r_000000_0' to hdfs://localhost:9000/user/michaeljones/wcOutputAnalysis/_temporary/0/task_local1634792945_0003_r_000000
reduce > reduce
Task 'attempt_local1634792945_0003_r_000000_0' done.
Finishing task: attempt_local1634792945_0003_r_000000_0
reduce task executor complete.
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones sending #68
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones got value #68
Call: getListing took 3ms
Merging data from FileStatus{path=hdfs://localhost:9000/user/michaeljones/wcOutputAnalysis/_temporary/0/task_local1634792945_0003_r_000000; isDirectory=true; modification_time=1434242171758; access_time=0; owner=michaeljones; group=supergroup; permission=rwxr-xr-x; isSymlink=false} to hdfs://localhost:9000/user/michaeljones/wcOutputAnalysis
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones sending #69
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones got value #69
Call: getFileInfo took 2ms
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones sending #70
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones got value #70
Call: getListing took 2ms
Merging data from FileStatus{path=hdfs://localhost:9000/user/michaeljones/wcOutputAnalysis/_temporary/0/task_local1634792945_0003_r_000000/part-r-00000; isDirectory=false; length=41; replication=1; blocksize=134217728; modification_time=1434242171780; access_time=1434242171758; owner=michaeljones; group=supergroup; permission=rw-r--r--; isSymlink=false} to hdfs://localhost:9000/user/michaeljones/wcOutputAnalysis/part-r-00000
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones sending #71
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones got value #71
Call: getFileInfo took 2ms
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones sending #72
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones got value #72
Call: rename took 4ms
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones sending #73
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones got value #73
Call: delete took 3ms
/user/michaeljones/wcOutputAnalysis/_SUCCESS: masked=rw-r--r--
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones sending #74
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones got value #74
Call: create took 4ms
computePacketChunkSize: src=/user/michaeljones/wcOutputAnalysis/_SUCCESS, chunkSize=516, chunksPerPacket=126, packetSize=65016
Waiting for ack for: -1
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones sending #75
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones got value #75
Call: complete took 7ms
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.fs.FileContext.getAbstractFileSystem(FileContext.java:331)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
Job job_local1634792945_0003 running in uber mode : false
 map 100% reduce 100%
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.getTaskCompletionEvents(Job.java:670)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.getTaskCompletionEvents(Job.java:670)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
Job job_local1634792945_0003 completed successfully
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.getCounters(Job.java:758)
Counters: 35
	File System Counters
		FILE: Number of bytes read=1892
		FILE: Number of bytes written=1694207
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=340
		HDFS: Number of bytes written=245
		HDFS: Number of read operations=71
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=38
	Map-Reduce Framework
		Map input records=2
		Map output records=8
		Map output bytes=82
		Map output materialized bytes=67
		Input split bytes=112
		Combine input records=8
		Combine output records=5
		Reduce input groups=5
		Reduce shuffle bytes=67
		Reduce input records=5
		Reduce output records=5
		Spilled Records=10
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=672137216
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=50
	File Output Format Counters 
		Bytes Written=41
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 5][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://localhost:50070
Connecting to localhost/127.0.0.1:50070
Connection established 127.0.0.1:49843<->127.0.0.1:50070
Executing request GET /webhdfs/v1/user/michaeljones/?op=LISTSTATUS HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-5 >> GET /webhdfs/v1/user/michaeljones/?op=LISTSTATUS HTTP/1.1
http-outgoing-5 >> accept: application/json
http-outgoing-5 >> Host: localhost:50070
http-outgoing-5 >> Connection: Keep-Alive
http-outgoing-5 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-5 >> Accept-Encoding: gzip,deflate
http-outgoing-5 >> "GET /webhdfs/v1/user/michaeljones/?op=LISTSTATUS HTTP/1.1[\r][\n]"
http-outgoing-5 >> "accept: application/json[\r][\n]"
http-outgoing-5 >> "Host: localhost:50070[\r][\n]"
http-outgoing-5 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-5 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-5 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-5 >> "[\r][\n]"
http-outgoing-5 << "HTTP/1.1 200 OK[\r][\n]"
http-outgoing-5 << "Cache-Control: no-cache[\r][\n]"
http-outgoing-5 << "Expires: Sun, 14 Jun 2015 00:36:12 GMT[\r][\n]"
http-outgoing-5 << "Date: Sun, 14 Jun 2015 00:36:12 GMT[\r][\n]"
http-outgoing-5 << "Pragma: no-cache[\r][\n]"
http-outgoing-5 << "Expires: Sun, 14 Jun 2015 00:36:12 GMT[\r][\n]"
http-outgoing-5 << "Date: Sun, 14 Jun 2015 00:36:12 GMT[\r][\n]"
http-outgoing-5 << "Pragma: no-cache[\r][\n]"
http-outgoing-5 << "Content-Type: application/json[\r][\n]"
http-outgoing-5 << "Transfer-Encoding: chunked[\r][\n]"
http-outgoing-5 << "Server: Jetty(6.1.26)[\r][\n]"
http-outgoing-5 << "[\r][\n]"
http-outgoing-5 << "10C1[\r][\n]"
http-outgoing-5 << "{"FileStatuses":{"FileStatus":[[\n]"
http-outgoing-5 << "{"accessTime":1434242160265,"blockSize":134217728,"childrenNum":0,"fileId":18666,"group":"supergroup","length":11335,"modificationTime":1434242160307,"owner":"michaeljones","pathSuffix":"README.md","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-5 << "{"accessTime":1434180764122,"blockSize":134217728,"childrenNum":0,"fileId":18621,"group":"supergroup","length":0,"modificationTime":1434180764129,"owner":"michaeljones","pathSuffix":"apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-5 << "{"accessTime":1434240295990,"blockSize":134217728,"childrenNum":0,"fileId":18639,"group":"supergroup","length":0,"modificationTime":1434240295996,"owner":"michaeljones","pathSuffix":"empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-5 << "{"accessTime":1434242159644,"blockSize":134217728,"childrenNum":0,"fileId":18663,"group":"supergroup","length":0,"modificationTime":1434242159652,"owner":"michaeljones","pathSuffix":"hello-apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-5 << "{"accessTime":1434091626279,"blockSize":134217728,"childrenNum":0,"fileId":18298,"group":"supergroup","length":0,"modificationTime":1434091626286,"owner":"michaeljones","pathSuffix":"hello-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-5 << "{"accessTime":1434242159578,"blockSize":134217728,"childrenNum":0,"fileId":18662,"group":"supergroup","length":0,"modificationTime":1434242159585,"owner":"michaeljones","pathSuffix":"hello-jersey-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-5 << "{"accessTime":1434240296439,"blockSize":134217728,"childrenNum":0,"fileId":18641,"group":"supergroup","length":19574,"modificationTime":1434240296468,"owner":"michaeljones","pathSuffix":"hello.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-5 << "{"accessTime":1434242160010,"blockSize":134217728,"childrenNum":0,"fileId":18665,"group":"supergroup","length":3678856,"modificationTime":1434242160145,"owner":"michaeljones","pathSuffix":"hello.log.2015-06-12","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-5 << "{"accessTime":1434242164264,"blockSize":134217728,"childrenNum":0,"fileId":18668,"group":"supergroup","length":20,"modificationTime":1434242164753,"owner":"michaeljones","pathSuffix":"hello.txt","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-5 << "{"accessTime":1434242159867,"blockSize":134217728,"childrenNum":0,"fileId":18664,"group":"supergroup","length":17984,"modificationTime":1434242159894,"owner":"michaeljones","pathSuffix":"hellohadoop.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-5 << "{"accessTime":1434242160987,"blockSize":134217728,"childrenNum":0,"fileId":18667,"group":"supergroup","length":3644,"modificationTime":1434242161016,"owner":"michaeljones","pathSuffix":"nbactions.xml","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-5 << "{"accessTime":1434180764163,"blockSize":134217728,"childrenNum":0,"fileId":18622,"group":"supergroup","length":2134,"modificationTime":1434180764193,"owner":"michaeljones","pathSuffix":"pom.xml","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-5 << "{"accessTime":1434242165542,"blockSize":134217728,"childrenNum":0,"fileId":16388,"group":"supergroup","length":50,"modificationTime":1433119638967,"owner":"michaeljones","pathSuffix":"wcInput","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-5 << "{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18676,"group":"supergroup","length":0,"modificationTime":1434242169795,"owner":"michaeljones","pathSuffix":"wcOutput","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},[\n]"
http-outgoing-5 << "{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18683,"group":"supergroup","length":0,"modificationTime":1434242171819,"owner":"michaeljones","pathSuffix":"wcOutputAnalysis","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},[\n]"
http-outgoing-5 << "{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18669,"group":"supergroup","length":0,"modificationTime":1434242168288,"owner":"michaeljones","pathSuffix":"wcOutputMain","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"}[\n]"
http-outgoing-5 << "]}}[\n]"
http-outgoing-5 << "[\r][\n]"
http-outgoing-5 << HTTP/1.1 200 OK
http-outgoing-5 << Cache-Control: no-cache
http-outgoing-5 << Expires: Sun, 14 Jun 2015 00:36:12 GMT
http-outgoing-5 << Date: Sun, 14 Jun 2015 00:36:12 GMT
http-outgoing-5 << Pragma: no-cache
http-outgoing-5 << Expires: Sun, 14 Jun 2015 00:36:12 GMT
http-outgoing-5 << Date: Sun, 14 Jun 2015 00:36:12 GMT
http-outgoing-5 << Pragma: no-cache
http-outgoing-5 << Content-Type: application/json
http-outgoing-5 << Transfer-Encoding: chunked
http-outgoing-5 << Server: Jetty(6.1.26)
Connection can be kept alive indefinitely
http-outgoing-5 << "0[\r][\n]"
http-outgoing-5 << "[\r][\n]"
Connection [id: 5][route: {}->http://localhost:50070] can be kept alive indefinitely
Connection released: [id: 5][route: {}->http://localhost:50070][total kept alive: 1; route allocated: 1 of 2; total allocated: 1 of 20]
Apache client testGetStringContent
{"FileStatuses":{"FileStatus":[
{"accessTime":1434242160265,"blockSize":134217728,"childrenNum":0,"fileId":18666,"group":"supergroup","length":11335,"modificationTime":1434242160307,"owner":"michaeljones","pathSuffix":"README.md","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434180764122,"blockSize":134217728,"childrenNum":0,"fileId":18621,"group":"supergroup","length":0,"modificationTime":1434180764129,"owner":"michaeljones","pathSuffix":"apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434240295990,"blockSize":134217728,"childrenNum":0,"fileId":18639,"group":"supergroup","length":0,"modificationTime":1434240295996,"owner":"michaeljones","pathSuffix":"empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434242159644,"blockSize":134217728,"childrenNum":0,"fileId":18663,"group":"supergroup","length":0,"modificationTime":1434242159652,"owner":"michaeljones","pathSuffix":"hello-apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434091626279,"blockSize":134217728,"childrenNum":0,"fileId":18298,"group":"supergroup","length":0,"modificationTime":1434091626286,"owner":"michaeljones","pathSuffix":"hello-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434242159578,"blockSize":134217728,"childrenNum":0,"fileId":18662,"group":"supergroup","length":0,"modificationTime":1434242159585,"owner":"michaeljones","pathSuffix":"hello-jersey-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434240296439,"blockSize":134217728,"childrenNum":0,"fileId":18641,"group":"supergroup","length":19574,"modificationTime":1434240296468,"owner":"michaeljones","pathSuffix":"hello.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434242160010,"blockSize":134217728,"childrenNum":0,"fileId":18665,"group":"supergroup","length":3678856,"modificationTime":1434242160145,"owner":"michaeljones","pathSuffix":"hello.log.2015-06-12","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434242164264,"blockSize":134217728,"childrenNum":0,"fileId":18668,"group":"supergroup","length":20,"modificationTime":1434242164753,"owner":"michaeljones","pathSuffix":"hello.txt","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434242159867,"blockSize":134217728,"childrenNum":0,"fileId":18664,"group":"supergroup","length":17984,"modificationTime":1434242159894,"owner":"michaeljones","pathSuffix":"hellohadoop.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434242160987,"blockSize":134217728,"childrenNum":0,"fileId":18667,"group":"supergroup","length":3644,"modificationTime":1434242161016,"owner":"michaeljones","pathSuffix":"nbactions.xml","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434180764163,"blockSize":134217728,"childrenNum":0,"fileId":18622,"group":"supergroup","length":2134,"modificationTime":1434180764193,"owner":"michaeljones","pathSuffix":"pom.xml","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434242165542,"blockSize":134217728,"childrenNum":0,"fileId":16388,"group":"supergroup","length":50,"modificationTime":1433119638967,"owner":"michaeljones","pathSuffix":"wcInput","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18676,"group":"supergroup","length":0,"modificationTime":1434242169795,"owner":"michaeljones","pathSuffix":"wcOutput","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},
{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18683,"group":"supergroup","length":0,"modificationTime":1434242171819,"owner":"michaeljones","pathSuffix":"wcOutputAnalysis","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},
{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18669,"group":"supergroup","length":0,"modificationTime":1434242168288,"owner":"michaeljones","pathSuffix":"wcOutputMain","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"}
]}}

CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 6][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://localhost:50070
Connecting to localhost/127.0.0.1:50070
Connection manager is shutting down
http-outgoing-5: Close connection
Connection established 127.0.0.1:49844<->127.0.0.1:50070
http-outgoing-5: Close connection
Connection manager shut down
Executing request PUT /webhdfs/v1/user/michaeljones/apache-empty.txt?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-6 >> PUT /webhdfs/v1/user/michaeljones/apache-empty.txt?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1
http-outgoing-6 >> Content-Length: 0
http-outgoing-6 >> Host: localhost:50070
http-outgoing-6 >> Connection: Keep-Alive
http-outgoing-6 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-6 >> Accept-Encoding: gzip,deflate
http-outgoing-6 >> "PUT /webhdfs/v1/user/michaeljones/apache-empty.txt?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1[\r][\n]"
http-outgoing-6 >> "Content-Length: 0[\r][\n]"
http-outgoing-6 >> "Host: localhost:50070[\r][\n]"
http-outgoing-6 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-6 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-6 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-6 >> "[\r][\n]"
http-outgoing-6 << "HTTP/1.1 307 TEMPORARY_REDIRECT[\r][\n]"
http-outgoing-6 << "Cache-Control: no-cache[\r][\n]"
http-outgoing-6 << "Expires: Sun, 14 Jun 2015 00:36:12 GMT[\r][\n]"
http-outgoing-6 << "Date: Sun, 14 Jun 2015 00:36:12 GMT[\r][\n]"
http-outgoing-6 << "Pragma: no-cache[\r][\n]"
http-outgoing-6 << "Expires: Sun, 14 Jun 2015 00:36:12 GMT[\r][\n]"
http-outgoing-6 << "Date: Sun, 14 Jun 2015 00:36:12 GMT[\r][\n]"
http-outgoing-6 << "Pragma: no-cache[\r][\n]"
http-outgoing-6 << "Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434278172811&s=HmVF13Lor98R6aLBfa4lRaTyYIA="; Path=/; Expires=Sun, 14-Jun-2015 10:36:12 GMT; HttpOnly[\r][\n]"
http-outgoing-6 << "Location: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true[\r][\n]"
http-outgoing-6 << "Content-Type: application/octet-stream[\r][\n]"
http-outgoing-6 << "Content-Length: 0[\r][\n]"
http-outgoing-6 << "Server: Jetty(6.1.26)[\r][\n]"
http-outgoing-6 << "[\r][\n]"
http-outgoing-6 << HTTP/1.1 307 TEMPORARY_REDIRECT
http-outgoing-6 << Cache-Control: no-cache
http-outgoing-6 << Expires: Sun, 14 Jun 2015 00:36:12 GMT
http-outgoing-6 << Date: Sun, 14 Jun 2015 00:36:12 GMT
http-outgoing-6 << Pragma: no-cache
http-outgoing-6 << Expires: Sun, 14 Jun 2015 00:36:12 GMT
http-outgoing-6 << Date: Sun, 14 Jun 2015 00:36:12 GMT
http-outgoing-6 << Pragma: no-cache
http-outgoing-6 << Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434278172811&s=HmVF13Lor98R6aLBfa4lRaTyYIA="; Path=/; Expires=Sun, 14-Jun-2015 10:36:12 GMT; HttpOnly
http-outgoing-6 << Location: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
http-outgoing-6 << Content-Type: application/octet-stream
http-outgoing-6 << Content-Length: 0
http-outgoing-6 << Server: Jetty(6.1.26)
Connection can be kept alive indefinitely
Cookie accepted [hadoop.auth=""u=michaeljones&p=michaeljones&t=simple&e=1434278172811&s=HmVF13Lor98R6aLBfa4lRaTyYIA="", version:0, domain:localhost, path:/, expiry:Sun Jun 14 20:36:12 AEST 2015]
Redirect to: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
http-outgoing-6: Shutdown connection
Connection discarded
http-outgoing-6: Close connection
Connection released: [id: 6][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
PUT file redirect: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 7][route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://michaels-air.bigpond:50075
Connecting to Michaels-Air.BigPond/10.0.0.2:50075
Connection established 10.0.0.2:49845<->10.0.0.2:50075
Executing request PUT /webhdfs/v1/user/michaeljones/apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-7 >> PUT /webhdfs/v1/user/michaeljones/apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1
http-outgoing-7 >> Content-Length: 0
http-outgoing-7 >> Host: michaels-air.bigpond:50075
http-outgoing-7 >> Connection: Keep-Alive
http-outgoing-7 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-7 >> Accept-Encoding: gzip,deflate
http-outgoing-7 >> "PUT /webhdfs/v1/user/michaeljones/apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1[\r][\n]"
http-outgoing-7 >> "Content-Length: 0[\r][\n]"
http-outgoing-7 >> "Host: michaels-air.bigpond:50075[\r][\n]"
http-outgoing-7 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-7 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-7 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-7 >> "[\r][\n]"
http-outgoing-7 << "HTTP/1.1 100 Continue[\r][\n]"
http-outgoing-7 << "[\r][\n]"
http-outgoing-7 << HTTP/1.1 100 Continue
http-outgoing-7 << "HTTP/1.1 201 Created[\r][\n]"
http-outgoing-7 << "Location: hdfs://localhost:9000/user/michaeljones/apache-empty.txt[\r][\n]"
http-outgoing-7 << "Content-Length: 0[\r][\n]"
http-outgoing-7 << "Connection: close[\r][\n]"
http-outgoing-7 << "[\r][\n]"
http-outgoing-7 << HTTP/1.1 201 Created
http-outgoing-7 << Location: hdfs://localhost:9000/user/michaeljones/apache-empty.txt
http-outgoing-7 << Content-Length: 0
http-outgoing-7 << Connection: close
http-outgoing-7: Shutdown connection
Connection discarded
http-outgoing-7: Close connection
Connection released: [id: 7][route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 8][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://localhost:50070
Connecting to localhost/127.0.0.1:50070
Connection established 127.0.0.1:49847<->127.0.0.1:50070
Executing request PUT /webhdfs/v1/user/michaeljones/pom.xml?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-8 >> PUT /webhdfs/v1/user/michaeljones/pom.xml?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1
http-outgoing-8 >> Content-Length: 0
http-outgoing-8 >> Host: localhost:50070
http-outgoing-8 >> Connection: Keep-Alive
http-outgoing-8 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-8 >> Accept-Encoding: gzip,deflate
http-outgoing-8 >> "PUT /webhdfs/v1/user/michaeljones/pom.xml?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1[\r][\n]"
http-outgoing-8 >> "Content-Length: 0[\r][\n]"
http-outgoing-8 >> "Host: localhost:50070[\r][\n]"
http-outgoing-8 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-8 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-8 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-8 >> "[\r][\n]"
http-outgoing-8 << "HTTP/1.1 307 TEMPORARY_REDIRECT[\r][\n]"
http-outgoing-8 << "Cache-Control: no-cache[\r][\n]"
http-outgoing-8 << "Expires: Sun, 14 Jun 2015 00:36:12 GMT[\r][\n]"
http-outgoing-8 << "Date: Sun, 14 Jun 2015 00:36:12 GMT[\r][\n]"
http-outgoing-8 << "Pragma: no-cache[\r][\n]"
http-outgoing-8 << "Expires: Sun, 14 Jun 2015 00:36:12 GMT[\r][\n]"
http-outgoing-8 << "Date: Sun, 14 Jun 2015 00:36:12 GMT[\r][\n]"
http-outgoing-8 << "Pragma: no-cache[\r][\n]"
http-outgoing-8 << "Content-Type: application/octet-stream[\r][\n]"
http-outgoing-8 << "Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434278172864&s=F4d0w4EaF8Qx3emsSTVz9czB36Y="; Path=/; Expires=Sun, 14-Jun-2015 10:36:12 GMT; HttpOnly[\r][\n]"
http-outgoing-8 << "Location: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/pom.xml?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true[\r][\n]"
http-outgoing-8 << "Content-Length: 0[\r][\n]"
http-outgoing-8 << "Server: Jetty(6.1.26)[\r][\n]"
http-outgoing-8 << "[\r][\n]"
http-outgoing-8 << HTTP/1.1 307 TEMPORARY_REDIRECT
http-outgoing-8 << Cache-Control: no-cache
http-outgoing-8 << Expires: Sun, 14 Jun 2015 00:36:12 GMT
http-outgoing-8 << Date: Sun, 14 Jun 2015 00:36:12 GMT
http-outgoing-8 << Pragma: no-cache
http-outgoing-8 << Expires: Sun, 14 Jun 2015 00:36:12 GMT
http-outgoing-8 << Date: Sun, 14 Jun 2015 00:36:12 GMT
http-outgoing-8 << Pragma: no-cache
http-outgoing-8 << Content-Type: application/octet-stream
http-outgoing-8 << Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434278172864&s=F4d0w4EaF8Qx3emsSTVz9czB36Y="; Path=/; Expires=Sun, 14-Jun-2015 10:36:12 GMT; HttpOnly
http-outgoing-8 << Location: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/pom.xml?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
http-outgoing-8 << Content-Length: 0
http-outgoing-8 << Server: Jetty(6.1.26)
Connection can be kept alive indefinitely
Cookie accepted [hadoop.auth=""u=michaeljones&p=michaeljones&t=simple&e=1434278172864&s=F4d0w4EaF8Qx3emsSTVz9czB36Y="", version:0, domain:localhost, path:/, expiry:Sun Jun 14 20:36:12 AEST 2015]
Redirect to: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/pom.xml?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
http-outgoing-8: Shutdown connection
Connection discarded
http-outgoing-8: Close connection
Connection released: [id: 8][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
PUT file redirect: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/pom.xml?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 9][route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://michaels-air.bigpond:50075
Connecting to Michaels-Air.BigPond/10.0.0.2:50075
Connection established 10.0.0.2:49848<->10.0.0.2:50075
Executing request PUT /webhdfs/v1/user/michaeljones/pom.xml?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-9 >> PUT /webhdfs/v1/user/michaeljones/pom.xml?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1
http-outgoing-9 >> Transfer-Encoding: chunked
http-outgoing-9 >> Content-Type: application/octet-stream
http-outgoing-9 >> Host: michaels-air.bigpond:50075
http-outgoing-9 >> Connection: Keep-Alive
http-outgoing-9 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-9 >> Accept-Encoding: gzip,deflate
http-outgoing-9 >> "PUT /webhdfs/v1/user/michaeljones/pom.xml?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1[\r][\n]"
http-outgoing-9 >> "Transfer-Encoding: chunked[\r][\n]"
http-outgoing-9 >> "Content-Type: application/octet-stream[\r][\n]"
http-outgoing-9 >> "Host: michaels-air.bigpond:50075[\r][\n]"
http-outgoing-9 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-9 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-9 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-9 >> "[\r][\n]"
http-outgoing-9 >> "856[\r][\n]"
http-outgoing-9 >> "<?xml version="1.0" encoding="UTF-8"?>[\n]"
http-outgoing-9 >> "<project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">[\n]"
http-outgoing-9 >> "    <modelVersion>4.0.0</modelVersion>[\n]"
http-outgoing-9 >> "    <groupId>com.michaeljones</groupId>[\n]"
http-outgoing-9 >> "    <artifactId>HelloHadoopWorldMaven</artifactId>[\n]"
http-outgoing-9 >> "    <version>1.0-SNAPSHOT</version>[\n]"
http-outgoing-9 >> "    <packaging>jar</packaging>[\n]"
http-outgoing-9 >> "    <dependencies>[\n]"
http-outgoing-9 >> "        <!-- run bin/hadoop version to see the jar it was built with, which is this dependency -->[\n]"
http-outgoing-9 >> "        <dependency>[\n]"
http-outgoing-9 >> "            <groupId>org.apache.hadoop</groupId>[\n]"
http-outgoing-9 >> "            <artifactId>hadoop-common</artifactId>[\n]"
http-outgoing-9 >> "            <version>2.7.0</version>[\n]"
http-outgoing-9 >> "        </dependency>[\n]"
http-outgoing-9 >> "        <dependency>[\n]"
http-outgoing-9 >> "            <groupId>org.apache.hadoop</groupId>[\n]"
http-outgoing-9 >> "            <artifactId>hadoop-hdfs</artifactId>[\n]"
http-outgoing-9 >> "            <version>2.7.0</version>[\n]"
http-outgoing-9 >> "        </dependency>[\n]"
http-outgoing-9 >> "        <dependency>[\n]"
http-outgoing-9 >> "            <groupId>junit</groupId>[\n]"
http-outgoing-9 >> "            <artifactId>junit</artifactId>[\n]"
http-outgoing-9 >> "            <version>4.10</version>[\n]"
http-outgoing-9 >> "            <scope>test</scope>[\n]"
http-outgoing-9 >> "        </dependency>[\n]"
http-outgoing-9 >> "        <dependency>[\n]"
http-outgoing-9 >> "            <groupId>org.apache.hadoop</groupId>[\n]"
http-outgoing-9 >> "            <artifactId>hadoop-mapreduce-client-core</artifactId>[\n]"
http-outgoing-9 >> "            <version>2.7.0</version>[\n]"
http-outgoing-9 >> "        </dependency>[\n]"
http-outgoing-9 >> "        <dependency>[\n]"
http-outgoing-9 >> "            <groupId>org.apache.hadoop</groupId>[\n]"
http-outgoing-9 >> "            <artifactId>hadoop-mapreduce-client-common</artifactId>[\n]"
http-outgoing-9 >> "            <version>2.7.0</version>[\n]"
http-outgoing-9 >> "        </dependency>[\n]"
http-outgoing-9 >> "        <dependency>[\n]"
http-outgoing-9 >> "            <groupId>com.googlecode.json-simple</groupId>[\n]"
http-outgoing-9 >> "            <artifactId>json-simple</artifactId>[\n]"
http-outgoing-9 >> "            <version>1.1.1</version>[\n]"
http-outgoing-9 >> "        </dependency>[\n]"
http-outgoing-9 >> "        <dependency>[\n]"
http-outgoing-9 >> "            <groupId>org.apache.httpcomponents</groupId>[\n]"
http-outgoing-9 >> "            <artifactId>httpclient</artifactId>[\n]"
http-outgoing-9 >> "            <version>4.4-beta1</version>[\n]"
http-outgoing-9 >> "        </dependency>[\n]"
http-outgoing-9 >> "    </dependencies>[\n]"
http-outgoing-9 >> "    <properties>[\n]"
http-outgoing-9 >> "        <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>[\n]"
http-outgoing-9 >> "        <maven.compiler.source>1.7</maven.compiler.source>[\n]"
http-outgoing-9 >> "        <maven.compiler.target>1.7</maven.compiler.target>[\n]"
http-outgoing-9 >> "    </properties>[\n]"
http-outgoing-9 >> "</project>[\r][\n]"
http-outgoing-9 >> "0[\r][\n]"
http-outgoing-9 >> "[\r][\n]"
http-outgoing-9 << "HTTP/1.1 100 Continue[\r][\n]"
http-outgoing-9 << "[\r][\n]"
http-outgoing-9 << HTTP/1.1 100 Continue
http-outgoing-9 << "HTTP/1.1 201 Created[\r][\n]"
http-outgoing-9 << "Location: hdfs://localhost:9000/user/michaeljones/pom.xml[\r][\n]"
http-outgoing-9 << "Content-Length: 0[\r][\n]"
http-outgoing-9 << "Connection: close[\r][\n]"
http-outgoing-9 << "[\r][\n]"
http-outgoing-9 << HTTP/1.1 201 Created
http-outgoing-9 << Location: hdfs://localhost:9000/user/michaeljones/pom.xml
http-outgoing-9 << Content-Length: 0
http-outgoing-9 << Connection: close
http-outgoing-9: Shutdown connection
Connection discarded
http-outgoing-9: Close connection
Connection released: [id: 9][route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection manager is shutting down
Connection manager shut down
com.sun.jersey.client.property.chunkedEncodingSize: 1048576
Jersey client Redirect to: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/nbactions.xml?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
Get redirect location async: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/nbactions.xml?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
com.sun.jersey.client.property.chunkedEncodingSize: 1048576
Jersey client testGetStringContent
{"FileStatuses":{"FileStatus":[
{"accessTime":1434242160265,"blockSize":134217728,"childrenNum":0,"fileId":18666,"group":"supergroup","length":11335,"modificationTime":1434242160307,"owner":"michaeljones","pathSuffix":"README.md","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434242172845,"blockSize":134217728,"childrenNum":0,"fileId":18690,"group":"supergroup","length":0,"modificationTime":1434242172851,"owner":"michaeljones","pathSuffix":"apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434240295990,"blockSize":134217728,"childrenNum":0,"fileId":18639,"group":"supergroup","length":0,"modificationTime":1434240295996,"owner":"michaeljones","pathSuffix":"empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434242159644,"blockSize":134217728,"childrenNum":0,"fileId":18663,"group":"supergroup","length":0,"modificationTime":1434242159652,"owner":"michaeljones","pathSuffix":"hello-apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434091626279,"blockSize":134217728,"childrenNum":0,"fileId":18298,"group":"supergroup","length":0,"modificationTime":1434091626286,"owner":"michaeljones","pathSuffix":"hello-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434242159578,"blockSize":134217728,"childrenNum":0,"fileId":18662,"group":"supergroup","length":0,"modificationTime":1434242159585,"owner":"michaeljones","pathSuffix":"hello-jersey-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434240296439,"blockSize":134217728,"childrenNum":0,"fileId":18641,"group":"supergroup","length":19574,"modificationTime":1434240296468,"owner":"michaeljones","pathSuffix":"hello.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434242160010,"blockSize":134217728,"childrenNum":0,"fileId":18665,"group":"supergroup","length":3678856,"modificationTime":1434242160145,"owner":"michaeljones","pathSuffix":"hello.log.2015-06-12","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434242164264,"blockSize":134217728,"childrenNum":0,"fileId":18668,"group":"supergroup","length":20,"modificationTime":1434242164753,"owner":"michaeljones","pathSuffix":"hello.txt","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434242159867,"blockSize":134217728,"childrenNum":0,"fileId":18664,"group":"supergroup","length":17984,"modificationTime":1434242159894,"owner":"michaeljones","pathSuffix":"hellohadoop.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434242160987,"blockSize":134217728,"childrenNum":0,"fileId":18667,"group":"supergroup","length":3644,"modificationTime":1434242161016,"owner":"michaeljones","pathSuffix":"nbactions.xml","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434242172891,"blockSize":134217728,"childrenNum":0,"fileId":18691,"group":"supergroup","length":2134,"modificationTime":1434242172913,"owner":"michaeljones","pathSuffix":"pom.xml","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434242165542,"blockSize":134217728,"childrenNum":0,"fileId":16388,"group":"supergroup","length":50,"modificationTime":1433119638967,"owner":"michaeljones","pathSuffix":"wcInput","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18676,"group":"supergroup","length":0,"modificationTime":1434242169795,"owner":"michaeljones","pathSuffix":"wcOutput","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},
{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18683,"group":"supergroup","length":0,"modificationTime":1434242171819,"owner":"michaeljones","pathSuffix":"wcOutputAnalysis","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},
{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18669,"group":"supergroup","length":0,"modificationTime":1434242168288,"owner":"michaeljones","pathSuffix":"wcOutputMain","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"}
]}}

Jersey client Redirect to: hdfs://localhost:9000/user/michaeljones/hello.log
Jersey redirected to IPC: hdfs://localhost:9000/user/michaeljones/hello.log
com.sun.jersey.client.property.chunkedEncodingSize: 1048576
Jersey client Redirect to: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/nbactions.xml?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
stopping client from cache: org.apache.hadoop.ipc.Client@52d645b1
removing client from cache: org.apache.hadoop.ipc.Client@52d645b1
stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@52d645b1
Stopping client
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones: closed
IPC Client (1615801298) connection to localhost/127.0.0.1:9000 from michaeljones: stopped, remaining connections 0
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 0][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://localhost:50070
Connecting to localhost/127.0.0.1:50070
Connection established 127.0.0.1:49597<->127.0.0.1:50070
Executing request GET /webhdfs/v1/user/michaeljones/?user.name=michaeljones&op=LISTSTATUS HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-0 >> GET /webhdfs/v1/user/michaeljones/?user.name=michaeljones&op=LISTSTATUS HTTP/1.1
http-outgoing-0 >> accept: application/json
http-outgoing-0 >> Host: localhost:50070
http-outgoing-0 >> Connection: Keep-Alive
http-outgoing-0 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-0 >> Accept-Encoding: gzip,deflate
http-outgoing-0 >> "GET /webhdfs/v1/user/michaeljones/?user.name=michaeljones&op=LISTSTATUS HTTP/1.1[\r][\n]"
http-outgoing-0 >> "accept: application/json[\r][\n]"
http-outgoing-0 >> "Host: localhost:50070[\r][\n]"
http-outgoing-0 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-0 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-0 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-0 >> "[\r][\n]"
http-outgoing-0 << "HTTP/1.1 200 OK[\r][\n]"
http-outgoing-0 << "Cache-Control: no-cache[\r][\n]"
http-outgoing-0 << "Expires: Sun, 14 Jun 2015 02:19:22 GMT[\r][\n]"
http-outgoing-0 << "Date: Sun, 14 Jun 2015 02:19:22 GMT[\r][\n]"
http-outgoing-0 << "Pragma: no-cache[\r][\n]"
http-outgoing-0 << "Expires: Sun, 14 Jun 2015 02:19:22 GMT[\r][\n]"
http-outgoing-0 << "Date: Sun, 14 Jun 2015 02:19:22 GMT[\r][\n]"
http-outgoing-0 << "Pragma: no-cache[\r][\n]"
http-outgoing-0 << "Content-Type: application/json[\r][\n]"
http-outgoing-0 << "Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434284362417&s=sZFFzuwkYcnEB7xhxLt5YJd+zv4="; Path=/; Expires=Sun, 14-Jun-2015 12:19:22 GMT; HttpOnly[\r][\n]"
http-outgoing-0 << "Transfer-Encoding: chunked[\r][\n]"
http-outgoing-0 << "Server: Jetty(6.1.26)[\r][\n]"
http-outgoing-0 << "[\r][\n]"
http-outgoing-0 << "10C2[\r][\n]"
http-outgoing-0 << "{"FileStatuses":{"FileStatus":[[\n]"
http-outgoing-0 << "{"accessTime":1434242160265,"blockSize":134217728,"childrenNum":0,"fileId":18666,"group":"supergroup","length":11335,"modificationTime":1434242160307,"owner":"michaeljones","pathSuffix":"README.md","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434242172845,"blockSize":134217728,"childrenNum":0,"fileId":18690,"group":"supergroup","length":0,"modificationTime":1434242172851,"owner":"michaeljones","pathSuffix":"apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434242173486,"blockSize":134217728,"childrenNum":0,"fileId":18692,"group":"supergroup","length":0,"modificationTime":1434242173493,"owner":"michaeljones","pathSuffix":"empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434242159644,"blockSize":134217728,"childrenNum":0,"fileId":18663,"group":"supergroup","length":0,"modificationTime":1434242159652,"owner":"michaeljones","pathSuffix":"hello-apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434091626279,"blockSize":134217728,"childrenNum":0,"fileId":18298,"group":"supergroup","length":0,"modificationTime":1434091626286,"owner":"michaeljones","pathSuffix":"hello-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434242159578,"blockSize":134217728,"childrenNum":0,"fileId":18662,"group":"supergroup","length":0,"modificationTime":1434242159585,"owner":"michaeljones","pathSuffix":"hello-jersey-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434242173890,"blockSize":134217728,"childrenNum":0,"fileId":18694,"group":"supergroup","length":584846,"modificationTime":1434242173915,"owner":"michaeljones","pathSuffix":"hello.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434242160010,"blockSize":134217728,"childrenNum":0,"fileId":18665,"group":"supergroup","length":3678856,"modificationTime":1434242160145,"owner":"michaeljones","pathSuffix":"hello.log.2015-06-12","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434242164264,"blockSize":134217728,"childrenNum":0,"fileId":18668,"group":"supergroup","length":20,"modificationTime":1434242164753,"owner":"michaeljones","pathSuffix":"hello.txt","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434242159867,"blockSize":134217728,"childrenNum":0,"fileId":18664,"group":"supergroup","length":17984,"modificationTime":1434242159894,"owner":"michaeljones","pathSuffix":"hellohadoop.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434242174005,"blockSize":134217728,"childrenNum":0,"fileId":18695,"group":"supergroup","length":3644,"modificationTime":1434242174030,"owner":"michaeljones","pathSuffix":"nbactions.xml","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434242172891,"blockSize":134217728,"childrenNum":0,"fileId":18691,"group":"supergroup","length":2134,"modificationTime":1434242172913,"owner":"michaeljones","pathSuffix":"pom.xml","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434242165542,"blockSize":134217728,"childrenNum":0,"fileId":16388,"group":"supergroup","length":50,"modificationTime":1433119638967,"owner":"michaeljones","pathSuffix":"wcInput","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18676,"group":"supergroup","length":0,"modificationTime":1434242169795,"owner":"michaeljones","pathSuffix":"wcOutput","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},[\n]"
http-outgoing-0 << "{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18683,"group":"supergroup","length":0,"modificationTime":1434242171819,"owner":"michaeljones","pathSuffix":"wcOutputAnalysis","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},[\n]"
http-outgoing-0 << "{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18669,"group":"supergroup","length":0,"modificationTime":1434242168288,"owner":"michaeljones","pathSuffix":"wcOutputMain","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"}[\n]"
http-outgoing-0 << "]}}[\n]"
http-outgoing-0 << "[\r][\n]"
http-outgoing-0 << "0[\r][\n]"
http-outgoing-0 << "[\r][\n]"
http-outgoing-0 << HTTP/1.1 200 OK
http-outgoing-0 << Cache-Control: no-cache
http-outgoing-0 << Expires: Sun, 14 Jun 2015 02:19:22 GMT
http-outgoing-0 << Date: Sun, 14 Jun 2015 02:19:22 GMT
http-outgoing-0 << Pragma: no-cache
http-outgoing-0 << Expires: Sun, 14 Jun 2015 02:19:22 GMT
http-outgoing-0 << Date: Sun, 14 Jun 2015 02:19:22 GMT
http-outgoing-0 << Pragma: no-cache
http-outgoing-0 << Content-Type: application/json
http-outgoing-0 << Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434284362417&s=sZFFzuwkYcnEB7xhxLt5YJd+zv4="; Path=/; Expires=Sun, 14-Jun-2015 12:19:22 GMT; HttpOnly
http-outgoing-0 << Transfer-Encoding: chunked
http-outgoing-0 << Server: Jetty(6.1.26)
Connection can be kept alive indefinitely
Cookie accepted [hadoop.auth=""u=michaeljones&p=michaeljones&t=simple&e=1434284362417&s=sZFFzuwkYcnEB7xhxLt5YJd+zv4="", version:0, domain:localhost, path:/, expiry:Sun Jun 14 22:19:22 AEST 2015]
Connection [id: 0][route: {}->http://localhost:50070] can be kept alive indefinitely
Connection released: [id: 0][route: {}->http://localhost:50070][total kept alive: 1; route allocated: 1 of 2; total allocated: 1 of 20]
Connection manager is shutting down
http-outgoing-0: Close connection
http-outgoing-0: Close connection
Connection manager shut down
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 1][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://localhost:50070
Connecting to localhost/127.0.0.1:50070
Connection established 127.0.0.1:49601<->127.0.0.1:50070
Executing request PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-1 >> PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1
http-outgoing-1 >> Content-Length: 0
http-outgoing-1 >> Host: localhost:50070
http-outgoing-1 >> Connection: Keep-Alive
http-outgoing-1 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-1 >> Accept-Encoding: gzip,deflate
http-outgoing-1 >> "PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1[\r][\n]"
http-outgoing-1 >> "Content-Length: 0[\r][\n]"
http-outgoing-1 >> "Host: localhost:50070[\r][\n]"
http-outgoing-1 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-1 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-1 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-1 >> "[\r][\n]"
http-outgoing-1 << "HTTP/1.1 307 TEMPORARY_REDIRECT[\r][\n]"
http-outgoing-1 << "Cache-Control: no-cache[\r][\n]"
http-outgoing-1 << "Expires: Sun, 14 Jun 2015 02:19:23 GMT[\r][\n]"
http-outgoing-1 << "Date: Sun, 14 Jun 2015 02:19:23 GMT[\r][\n]"
http-outgoing-1 << "Pragma: no-cache[\r][\n]"
http-outgoing-1 << "Expires: Sun, 14 Jun 2015 02:19:23 GMT[\r][\n]"
http-outgoing-1 << "Date: Sun, 14 Jun 2015 02:19:23 GMT[\r][\n]"
http-outgoing-1 << "Pragma: no-cache[\r][\n]"
http-outgoing-1 << "Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434284363921&s=HM9A7YkRVlYp/IgzYUyX8fZv+jw="; Path=/; Expires=Sun, 14-Jun-2015 12:19:23 GMT; HttpOnly[\r][\n]"
http-outgoing-1 << "Location: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true[\r][\n]"
http-outgoing-1 << "Content-Type: application/octet-stream[\r][\n]"
http-outgoing-1 << "Content-Length: 0[\r][\n]"
http-outgoing-1 << "Server: Jetty(6.1.26)[\r][\n]"
http-outgoing-1 << "[\r][\n]"
http-outgoing-1 << HTTP/1.1 307 TEMPORARY_REDIRECT
http-outgoing-1 << Cache-Control: no-cache
http-outgoing-1 << Expires: Sun, 14 Jun 2015 02:19:23 GMT
http-outgoing-1 << Date: Sun, 14 Jun 2015 02:19:23 GMT
http-outgoing-1 << Pragma: no-cache
http-outgoing-1 << Expires: Sun, 14 Jun 2015 02:19:23 GMT
http-outgoing-1 << Date: Sun, 14 Jun 2015 02:19:23 GMT
http-outgoing-1 << Pragma: no-cache
http-outgoing-1 << Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434284363921&s=HM9A7YkRVlYp/IgzYUyX8fZv+jw="; Path=/; Expires=Sun, 14-Jun-2015 12:19:23 GMT; HttpOnly
http-outgoing-1 << Location: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
http-outgoing-1 << Content-Type: application/octet-stream
http-outgoing-1 << Content-Length: 0
http-outgoing-1 << Server: Jetty(6.1.26)
Connection can be kept alive indefinitely
Cookie accepted [hadoop.auth=""u=michaeljones&p=michaeljones&t=simple&e=1434284363921&s=HM9A7YkRVlYp/IgzYUyX8fZv+jw="", version:0, domain:localhost, path:/, expiry:Sun Jun 14 22:19:23 AEST 2015]
Redirect to: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
http-outgoing-1: Shutdown connection
Connection discarded
http-outgoing-1: Close connection
Connection released: [id: 1][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 2][route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://michaels-air.bigpond:50075
Connecting to michaels-air.bigpond/10.0.0.2:50075
Connection established 10.0.0.2:49602<->10.0.0.2:50075
Executing request PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-2 >> PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1
http-outgoing-2 >> Content-Length: 0
http-outgoing-2 >> Host: michaels-air.bigpond:50075
http-outgoing-2 >> Connection: Keep-Alive
http-outgoing-2 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-2 >> Accept-Encoding: gzip,deflate
http-outgoing-2 >> "PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1[\r][\n]"
http-outgoing-2 >> "Content-Length: 0[\r][\n]"
http-outgoing-2 >> "Host: michaels-air.bigpond:50075[\r][\n]"
http-outgoing-2 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-2 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-2 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-2 >> "[\r][\n]"
http-outgoing-2 << "HTTP/1.1 100 Continue[\r][\n]"
http-outgoing-2 << "[\r][\n]"
http-outgoing-2 << HTTP/1.1 100 Continue
http-outgoing-2 << "HTTP/1.1 201 Created[\r][\n]"
http-outgoing-2 << "Location: hdfs://localhost:9000/user/michaeljones/hello-apache-empty.txt[\r][\n]"
http-outgoing-2 << "Content-Length: 0[\r][\n]"
http-outgoing-2 << "Connection: close[\r][\n]"
http-outgoing-2 << "[\r][\n]"
http-outgoing-2 << HTTP/1.1 201 Created
http-outgoing-2 << Location: hdfs://localhost:9000/user/michaeljones/hello-apache-empty.txt
http-outgoing-2 << Content-Length: 0
http-outgoing-2 << Connection: close
http-outgoing-2: Shutdown connection
Connection discarded
http-outgoing-2: Close connection
Connection released: [id: 2][route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection manager is shutting down
Connection manager shut down
Jersey client Redirect to: hdfs://localhost:9000/user/michaeljones/hellohadoop.log
com.sun.jersey.client.property.chunkedEncodingSize: 1048576
Jersey client Redirect to: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/hello.log.2015-06-12?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 3][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://localhost:50070
Connecting to localhost/127.0.0.1:50070
Connection established 127.0.0.1:49612<->127.0.0.1:50070
Executing request PUT /webhdfs/v1/user/michaeljones/README.md?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-3 >> PUT /webhdfs/v1/user/michaeljones/README.md?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1
http-outgoing-3 >> Transfer-Encoding: chunked
http-outgoing-3 >> Content-Type: application/octet-stream
http-outgoing-3 >> Host: localhost:50070
http-outgoing-3 >> Connection: Keep-Alive
http-outgoing-3 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-3 >> Accept-Encoding: gzip,deflate
http-outgoing-3 >> "PUT /webhdfs/v1/user/michaeljones/README.md?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1[\r][\n]"
http-outgoing-3 >> "Transfer-Encoding: chunked[\r][\n]"
http-outgoing-3 >> "Content-Type: application/octet-stream[\r][\n]"
http-outgoing-3 >> "Host: localhost:50070[\r][\n]"
http-outgoing-3 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-3 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-3 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-3 >> "[\r][\n]"
http-outgoing-3 >> "1000[\r][\n]"
http-outgoing-3 >> "# Hello-Hadoop-netbeans-OS-X[\n]"
http-outgoing-3 >> "Java Maven project for playing with the HDFS API without any 3rd party hadoop plugins.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## Aim of project[\n]"
http-outgoing-3 >> "Hello world/tutorial level for programmatically operating with a pseudo distributed hadoop configuration on OS X. Hadoop 2.7 on Yosemite.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## What this project demonstrates[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "This is work in progress and so far the following functionality is demonstrated:[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "1. Direct programmatic control of the HDFS and running map reduce jobs - all unit tests run from the IDE with hadoop configuration built into this project and under git control.[\n]"
http-outgoing-3 >> "2. Uploading of files to the HDFS by implementing a Web REST API client.[\n]"
http-outgoing-3 >> "3. Async file upload (at time of writing only Jersey back end implemented).[\n]"
http-outgoing-3 >> "4. Layered application code for maximum re-use and ease of test driven development. The client I wrote uses an interface which has allowed me to provide both a Jersey HTTP client implementation and an Apache HTTP client implementation for comparison between the two toolkits.[\n]"
http-outgoing-3 >> "5. Test driven development.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## Getting started[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "The initial difficulty was working out how to run the program in the IDE and talk to the local pseudo distributed setup without using a 3rd party Hadoop plugin. Apparently there used to be a plugin for netbeans, but it has been discontinued. I am a newbie with this technology.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "The Apache Hadoop instructions for building and running java programs are via their command line build/run utility only. Getting the yahoo hadoop HDFS tutorial program to build in the IDE wasn't too hard. However, by default it will ignore the local Hadoop configuration and only operate with the local file system in local debug mode.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## Wading through the configuration[\n]"
http-outgoing-3 >> "Hadoop is designed to work with a number of different topologies, directory locations, levels of replication, simulated environments etc. so as we would expect nothing works unless the configuration is right.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "First Hadoop needs to be installed and configured in pseudo distributed mode such that it builds and runs test programs on the command line. The hadoop documentation has instructions for doing this. Documentation is online and also included in the installation: share/doc/hadoop/index.html. However this is not enough to get it to work in the IDE.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## The netbeans project settings that are needed to run with the HDFS from the IDE:[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "1. Get log4j configured to work in the IDE. Absence of log4j configuration won't stop hadoop from running, but we won't get to see useful error messages from hadoop without it.[\n]"
http-outgoing-3 >> "2. HADOOP_HOME environment variable project run (and test) property.[\n]"
http-outgoing-3 >> "3. Duplicate hadoop configuration in the classpath. The above environment variable does not pick up the hadoop configuration from its usual place. Yahoo's only suggestion is to run from the command line via the hadoop script. The Apache HDFS API documention says that configuration is looked for in the classpath, so I took the approach of duplicating the configuration (just 2 files) instead of figuring out how to get it to look in the installation path.[\n]"
http-outgoing-3 >> "4. The correct Maven dependencies. If not all the jar depenencies are there the program may build and run, but it won't talk to the HDFS if it doesn't load the HDFS jars.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "I think that the setup of this project would probably work on Linux too.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## Working through trouble shooting the HDFS project settings[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "Issue 1 above shows up as:[\n]"
http-outgoing-3 >> "<pre><code>[\n]"
http-outgoing-3 >> "log4j:WARN No appenders could be found for logger (org.apache.hadoop.util.Shell).[\n]"
http-outgoing-3 >> "log4j:WARN Please initialize the log4j system properly.[\n]"
http-outgoing-3 >> "log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.[\n]"
http-outgoing-3 >> "</pre></code>[\n]"
http-outgoing-3 >> "This is solved by putting a log4j.properties configuration file in the classpath. For a Maven build getting files into the classpath can be achieved by putting them in src/main/resources. I don't think this is in the classpath, but the build will then copy the file into ./target/classes/ which is in the classpath.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "Issue 2 above shows up as:[\n]"
http-outgoing-3 >> "<pre><code>[\n]"
http-outgoing-3 >> "Failed to detect a valid hadoop home directory[\n]"
http-outgoing-3 >> "java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.[\n]"
http-outgoing-3 >> "</[\r][\n]"
http-outgoing-3 >> "1000[\r][\n]"
http-outgoing-3 >> "code></pre>[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "This is fixed by going into the project properties => Build => Actions => Run Project and adding the environment variable for HADOOP_HOME. This will result in an entry in the Maven POM. Repeat for "Test Project", "Debug Project" etc.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "Issue 3. shows up as running, but creating a file on the local file system instead of the HDFS. This was fixed       looking at the HDFS API documentation for org.apache.hadoop.conf.Configuration. This documentation is under the chapter: C API libhdfs HDFS which has a link to the HDFS API under "The APIs" (I strangely cannot find this in the main index). On my installation the HDFS API documentation link is file:///opt/local/hadoop-2.7.0/share/doc/hadoop/api/org/apache/hadoop/fs/FileSystem.html.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "This documentation told me that hadoop loads core-site.xml and core-default.xml in the classpath. Classpath for a Maven build can be reached by placing these files in the directory src/main/resources (see logging configuration above). I added hdfs-site instead of core-default (which doesn't exist on my 2.7 install) into the src/main/resources project directory.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "Issue 3 shows up as:[\n]"
http-outgoing-3 >> "<pre><code>[\n]"
http-outgoing-3 >> "java.io.IOException: "hadoop No FileSystem for scheme: hdfs".[\n]"
http-outgoing-3 >> "</code></pre>[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "This is part of the build dependency problem. The various threads on stackoverflow etc. suggested that a minimum dependency was the jar for hadoop-core. However, there is no such jar on 2.7. I ran the hadoop command to dump version and got this:[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "<pre><code>[\n]"
http-outgoing-3 >> "bin/hadoop version[\n]"
http-outgoing-3 >> "Hadoop 2.7.0[\n]"
http-outgoing-3 >> "Subversion https://git-wip-us.apache.org/repos/asf/hadoop.git -r d4c8d4d4d203c934e8074b31289a28724c0842cf[\n]"
http-outgoing-3 >> "Compiled by jenkins on 2015-04-10T18:40Z[\n]"
http-outgoing-3 >> "Compiled with protoc 2.5.0[\n]"
http-outgoing-3 >> "From source with checksum a9e90912c37a35c3195d23951fd18f[\n]"
http-outgoing-3 >> "This command was run using /opt/local/hadoop-2.7.0/share/hadoop/common/hadoop-common-2.7.0.jar[\n]"
http-outgoing-3 >> "</code></pre>[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "I noted the jar name at the end and added it as a dependency to the POM. This can either be hand coded in or right click pom.xml => Insert Code => Add Dependency => Search => query hadoop-common and select version which was 2.7.0 [jar] - central. Maven will then add dependencies to other hadoop jars in the "Dependencies" group in the project explorer. Netbeans will then download these dependencies before the next build. They go into ~/.m2/repository should they ever need to be cleaned out (Netbeans doesn't seem to have an IDE remove dependency option).[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "After doing the above project built, but showed up the "no filesystem error". I noticed that Maven had not pulled in any hdfs jars matching the jars in my share/hadoop/hdfs installation directory. So I took a guess that it needed only the top level hadoop-hdfs-2.7.0.jar and added this as a dependency to the POM and all was good :)[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## Working through trouble shooting the Map Reduce project settings[\n]"
http-outgoing-3 >> "After getting the HDFS API working in the IDE it was time to move on to getting the famous Word Count map-reduce tutorial running.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "So coded it, set the main program to the word count main as the one to run. From the IDE: project Properties => Run => Main Class. Provide input and output arguments for the word count program. I noted that the netbeans properties pop-up window does not persist these settings next time it pops up. However this setting is persistant and ends up in nbactions.xml.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "However, running the word count map reduce program resulted in an ioException:[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "<pre><code>[\n]"
http-outgoing-3 >> "Please check your configuration for mapreduce.framework.name and the correspond server addresses.[\n]"
http-outgoing-3 >> "</pre></code>[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "Because the resources directory only contains 2 configuration files from my hadoop installation I thought maybe I was missing a map reduce one. So the first thing I did was go into the configuration directory of my installation and grep all files to see if there was a configuration file with mapreduce framework property. There was not. I checked my programatic configuration dump from my test program. This property was not mentioned either. The only map reduce configuration was to do with some environment variables for heap size in one of the shell scripts. Note to sel[\r][\n]"
http-outgoing-3 >> "c47[\r][\n]"
http-outgoing-3 >> "f: this may be relevant and I can consider setting this in the IDE. However, that didn't look like the problem.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "I then checked my dependencies and noted there were no map reduce jars pulled in by Maven. So I added hadoop-mapreduce-client-core. Still not running. Checked the web and a thread on stackoverflow mentioned a number of other jars: hadoop-mapreduce-client-common and hadoop-mapreduce-client shuffle. I added just the hadoop-mapreduce-client-common and it runs :) I have a feeling that I might need some of the other jars for other API calls and that there must be a better way of working out dependencies than this trial and error. As mentioned I am a newbie with this, so if anyone has any comments feel free to email me.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## Logging from application code[\n]"
http-outgoing-3 >> "Although the hadoop libraries log correctly with a properly located log4.properties file, application code calling the log4j logger seems to ignore this file. Using the log4j logger as per instructions in the log4j manual and many online tutorials did not result in getting any logging redirected to file configured in the properties file. Instead console output only is obtained. A clue to this mystery was that a most basic of hello world netbeans maven projects which did not import any hadoop stuff also failed to log to a file and did not even give the "No appenders" warning. Then I noticed that there were org.sl4j depencies in the hadoop build, so using sl4j instead solved the problem. Once my hello world project used sl4j's LoggerFactory and had sl4j-api and sl4j-12 as a dependencies it started to use the properties file. See http://www.slf4j.org/manual.html[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## Upload a file from local storage to the HDFS via the REST API[\n]"
http-outgoing-3 >> "The WebHDFS REST API documentation which came with the installation specifies that file creation is a two stage operation where an initial PUT to the namenode is sent. This responds with a redirect to the datanode and another PUT should be made to this redirection which can contain the chunked data stream. This does not sound REST to me as it relies on holding redirection state (a fully distributed configuration could presumably return a redirection to any one of the datanodes). Hadoop say this is because of a bug in some HTTP client implementations - incorrect implementation of [0xe2][0x80][0x9c]Expect: 100-continue[0xe2][0x80][0x9d].[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "However, the 2 stage PUT not being REST seems to be a moot point, at least with the Jersey client. I do not get a redirection and a file creates/uploads all in one go.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "Since writing the above paragraph I have implemented the Apache Client back end option to my HDFS Web client interface and this client behaves differently. It does indeed cause a redirect as per Hadoop documentation. The follow up PUT to the redirected location with the chunked file stream works as per documentation.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "Since writing the above paragraph I have implemented a big chunk size setting for the HTTP chunking and this changed the behaviour of the Jersey client to always redirect. It might be that unless the chunk size option is set then the Jersey implementation does not chunk - this would be terrible for big files.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "To be continued ...[\n]"
http-outgoing-3 >> "[\r][\n]"
http-outgoing-3 >> "0[\r][\n]"
http-outgoing-3 >> "[\r][\n]"
http-outgoing-3 << "HTTP/1.1 307 TEMPORARY_REDIRECT[\r][\n]"
http-outgoing-3 << "Cache-Control: no-cache[\r][\n]"
http-outgoing-3 << "Expires: Sun, 14 Jun 2015 02:19:25 GMT[\r][\n]"
http-outgoing-3 << "Date: Sun, 14 Jun 2015 02:19:25 GMT[\r][\n]"
http-outgoing-3 << "Pragma: no-cache[\r][\n]"
http-outgoing-3 << "Expires: Sun, 14 Jun 2015 02:19:25 GMT[\r][\n]"
http-outgoing-3 << "Date: Sun, 14 Jun 2015 02:19:25 GMT[\r][\n]"
http-outgoing-3 << "Pragma: no-cache[\r][\n]"
http-outgoing-3 << "Content-Type: application/octet-stream[\r][\n]"
http-outgoing-3 << "Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434284365347&s=5c2CaiLzHL0MrwCheSDpt+ej/no="; Path=/; Expires=Sun, 14-Jun-2015 12:19:25 GMT; HttpOnly[\r][\n]"
http-outgoing-3 << "Location: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/README.md?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true[\r][\n]"
http-outgoing-3 << "Content-Length: 0[\r][\n]"
http-outgoing-3 << "Server: Jetty(6.1.26)[\r][\n]"
http-outgoing-3 << "[\r][\n]"
http-outgoing-3 << HTTP/1.1 307 TEMPORARY_REDIRECT
http-outgoing-3 << Cache-Control: no-cache
http-outgoing-3 << Expires: Sun, 14 Jun 2015 02:19:25 GMT
http-outgoing-3 << Date: Sun, 14 Jun 2015 02:19:25 GMT
http-outgoing-3 << Pragma: no-cache
http-outgoing-3 << Expires: Sun, 14 Jun 2015 02:19:25 GMT
http-outgoing-3 << Date: Sun, 14 Jun 2015 02:19:25 GMT
http-outgoing-3 << Pragma: no-cache
http-outgoing-3 << Content-Type: application/octet-stream
http-outgoing-3 << Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434284365347&s=5c2CaiLzHL0MrwCheSDpt+ej/no="; Path=/; Expires=Sun, 14-Jun-2015 12:19:25 GMT; HttpOnly
http-outgoing-3 << Location: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/README.md?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
http-outgoing-3 << Content-Length: 0
http-outgoing-3 << Server: Jetty(6.1.26)
Connection can be kept alive indefinitely
Cookie accepted [hadoop.auth=""u=michaeljones&p=michaeljones&t=simple&e=1434284365347&s=5c2CaiLzHL0MrwCheSDpt+ej/no="", version:0, domain:localhost, path:/, expiry:Sun Jun 14 22:19:25 AEST 2015]
Redirect to: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/README.md?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
http-outgoing-3: Shutdown connection
Connection discarded
http-outgoing-3: Close connection
Connection released: [id: 3][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 4][route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://michaels-air.bigpond:50075
Connecting to michaels-air.bigpond/10.0.0.2:50075
Connection established 10.0.0.2:49613<->10.0.0.2:50075
Executing request PUT /webhdfs/v1/user/michaeljones/README.md?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-4 >> PUT /webhdfs/v1/user/michaeljones/README.md?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1
http-outgoing-4 >> Transfer-Encoding: chunked
http-outgoing-4 >> Content-Type: application/octet-stream
http-outgoing-4 >> Host: michaels-air.bigpond:50075
http-outgoing-4 >> Connection: Keep-Alive
http-outgoing-4 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-4 >> Accept-Encoding: gzip,deflate
http-outgoing-4 >> "PUT /webhdfs/v1/user/michaeljones/README.md?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1[\r][\n]"
http-outgoing-4 >> "Transfer-Encoding: chunked[\r][\n]"
http-outgoing-4 >> "Content-Type: application/octet-stream[\r][\n]"
http-outgoing-4 >> "Host: michaels-air.bigpond:50075[\r][\n]"
http-outgoing-4 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-4 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-4 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-4 >> "[\r][\n]"
http-outgoing-4 >> "1000[\r][\n]"
http-outgoing-4 >> "# Hello-Hadoop-netbeans-OS-X[\n]"
http-outgoing-4 >> "Java Maven project for playing with the HDFS API without any 3rd party hadoop plugins.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## Aim of project[\n]"
http-outgoing-4 >> "Hello world/tutorial level for programmatically operating with a pseudo distributed hadoop configuration on OS X. Hadoop 2.7 on Yosemite.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## What this project demonstrates[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "This is work in progress and so far the following functionality is demonstrated:[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "1. Direct programmatic control of the HDFS and running map reduce jobs - all unit tests run from the IDE with hadoop configuration built into this project and under git control.[\n]"
http-outgoing-4 >> "2. Uploading of files to the HDFS by implementing a Web REST API client.[\n]"
http-outgoing-4 >> "3. Async file upload (at time of writing only Jersey back end implemented).[\n]"
http-outgoing-4 >> "4. Layered application code for maximum re-use and ease of test driven development. The client I wrote uses an interface which has allowed me to provide both a Jersey HTTP client implementation and an Apache HTTP client implementation for comparison between the two toolkits.[\n]"
http-outgoing-4 >> "5. Test driven development.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## Getting started[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "The initial difficulty was working out how to run the program in the IDE and talk to the local pseudo distributed setup without using a 3rd party Hadoop plugin. Apparently there used to be a plugin for netbeans, but it has been discontinued. I am a newbie with this technology.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "The Apache Hadoop instructions for building and running java programs are via their command line build/run utility only. Getting the yahoo hadoop HDFS tutorial program to build in the IDE wasn't too hard. However, by default it will ignore the local Hadoop configuration and only operate with the local file system in local debug mode.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## Wading through the configuration[\n]"
http-outgoing-4 >> "Hadoop is designed to work with a number of different topologies, directory locations, levels of replication, simulated environments etc. so as we would expect nothing works unless the configuration is right.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "First Hadoop needs to be installed and configured in pseudo distributed mode such that it builds and runs test programs on the command line. The hadoop documentation has instructions for doing this. Documentation is online and also included in the installation: share/doc/hadoop/index.html. However this is not enough to get it to work in the IDE.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## The netbeans project settings that are needed to run with the HDFS from the IDE:[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "1. Get log4j configured to work in the IDE. Absence of log4j configuration won't stop hadoop from running, but we won't get to see useful error messages from hadoop without it.[\n]"
http-outgoing-4 >> "2. HADOOP_HOME environment variable project run (and test) property.[\n]"
http-outgoing-4 >> "3. Duplicate hadoop configuration in the classpath. The above environment variable does not pick up the hadoop configuration from its usual place. Yahoo's only suggestion is to run from the command line via the hadoop script. The Apache HDFS API documention says that configuration is looked for in the classpath, so I took the approach of duplicating the configuration (just 2 files) instead of figuring out how to get it to look in the installation path.[\n]"
http-outgoing-4 >> "4. The correct Maven dependencies. If not all the jar depenencies are there the program may build and run, but it won't talk to the HDFS if it doesn't load the HDFS jars.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "I think that the setup of this project would probably work on Linux too.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## Working through trouble shooting the HDFS project settings[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "Issue 1 above shows up as:[\n]"
http-outgoing-4 >> "<pre><code>[\n]"
http-outgoing-4 >> "log4j:WARN No appenders could be found for logger (org.apache.hadoop.util.Shell).[\n]"
http-outgoing-4 >> "log4j:WARN Please initialize the log4j system properly.[\n]"
http-outgoing-4 >> "log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.[\n]"
http-outgoing-4 >> "</pre></code>[\n]"
http-outgoing-4 >> "This is solved by putting a log4j.properties configuration file in the classpath. For a Maven build getting files into the classpath can be achieved by putting them in src/main/resources. I don't think this is in the classpath, but the build will then copy the file into ./target/classes/ which is in the classpath.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "Issue 2 above shows up as:[\n]"
http-outgoing-4 >> "<pre><code>[\n]"
http-outgoing-4 >> "Failed to detect a valid hadoop home directory[\n]"
http-outgoing-4 >> "java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.[\n]"
http-outgoing-4 >> "</[\r][\n]"
http-outgoing-4 >> "1000[\r][\n]"
http-outgoing-4 >> "code></pre>[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "This is fixed by going into the project properties => Build => Actions => Run Project and adding the environment variable for HADOOP_HOME. This will result in an entry in the Maven POM. Repeat for "Test Project", "Debug Project" etc.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "Issue 3. shows up as running, but creating a file on the local file system instead of the HDFS. This was fixed       looking at the HDFS API documentation for org.apache.hadoop.conf.Configuration. This documentation is under the chapter: C API libhdfs HDFS which has a link to the HDFS API under "The APIs" (I strangely cannot find this in the main index). On my installation the HDFS API documentation link is file:///opt/local/hadoop-2.7.0/share/doc/hadoop/api/org/apache/hadoop/fs/FileSystem.html.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "This documentation told me that hadoop loads core-site.xml and core-default.xml in the classpath. Classpath for a Maven build can be reached by placing these files in the directory src/main/resources (see logging configuration above). I added hdfs-site instead of core-default (which doesn't exist on my 2.7 install) into the src/main/resources project directory.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "Issue 3 shows up as:[\n]"
http-outgoing-4 >> "<pre><code>[\n]"
http-outgoing-4 >> "java.io.IOException: "hadoop No FileSystem for scheme: hdfs".[\n]"
http-outgoing-4 >> "</code></pre>[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "This is part of the build dependency problem. The various threads on stackoverflow etc. suggested that a minimum dependency was the jar for hadoop-core. However, there is no such jar on 2.7. I ran the hadoop command to dump version and got this:[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "<pre><code>[\n]"
http-outgoing-4 >> "bin/hadoop version[\n]"
http-outgoing-4 >> "Hadoop 2.7.0[\n]"
http-outgoing-4 >> "Subversion https://git-wip-us.apache.org/repos/asf/hadoop.git -r d4c8d4d4d203c934e8074b31289a28724c0842cf[\n]"
http-outgoing-4 >> "Compiled by jenkins on 2015-04-10T18:40Z[\n]"
http-outgoing-4 >> "Compiled with protoc 2.5.0[\n]"
http-outgoing-4 >> "From source with checksum a9e90912c37a35c3195d23951fd18f[\n]"
http-outgoing-4 >> "This command was run using /opt/local/hadoop-2.7.0/share/hadoop/common/hadoop-common-2.7.0.jar[\n]"
http-outgoing-4 >> "</code></pre>[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "I noted the jar name at the end and added it as a dependency to the POM. This can either be hand coded in or right click pom.xml => Insert Code => Add Dependency => Search => query hadoop-common and select version which was 2.7.0 [jar] - central. Maven will then add dependencies to other hadoop jars in the "Dependencies" group in the project explorer. Netbeans will then download these dependencies before the next build. They go into ~/.m2/repository should they ever need to be cleaned out (Netbeans doesn't seem to have an IDE remove dependency option).[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "After doing the above project built, but showed up the "no filesystem error". I noticed that Maven had not pulled in any hdfs jars matching the jars in my share/hadoop/hdfs installation directory. So I took a guess that it needed only the top level hadoop-hdfs-2.7.0.jar and added this as a dependency to the POM and all was good :)[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## Working through trouble shooting the Map Reduce project settings[\n]"
http-outgoing-4 >> "After getting the HDFS API working in the IDE it was time to move on to getting the famous Word Count map-reduce tutorial running.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "So coded it, set the main program to the word count main as the one to run. From the IDE: project Properties => Run => Main Class. Provide input and output arguments for the word count program. I noted that the netbeans properties pop-up window does not persist these settings next time it pops up. However this setting is persistant and ends up in nbactions.xml.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "However, running the word count map reduce program resulted in an ioException:[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "<pre><code>[\n]"
http-outgoing-4 >> "Please check your configuration for mapreduce.framework.name and the correspond server addresses.[\n]"
http-outgoing-4 >> "</pre></code>[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "Because the resources directory only contains 2 configuration files from my hadoop installation I thought maybe I was missing a map reduce one. So the first thing I did was go into the configuration directory of my installation and grep all files to see if there was a configuration file with mapreduce framework property. There was not. I checked my programatic configuration dump from my test program. This property was not mentioned either. The only map reduce configuration was to do with some environment variables for heap size in one of the shell scripts. Note to sel[\r][\n]"
http-outgoing-4 >> "c47[\r][\n]"
http-outgoing-4 >> "f: this may be relevant and I can consider setting this in the IDE. However, that didn't look like the problem.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "I then checked my dependencies and noted there were no map reduce jars pulled in by Maven. So I added hadoop-mapreduce-client-core. Still not running. Checked the web and a thread on stackoverflow mentioned a number of other jars: hadoop-mapreduce-client-common and hadoop-mapreduce-client shuffle. I added just the hadoop-mapreduce-client-common and it runs :) I have a feeling that I might need some of the other jars for other API calls and that there must be a better way of working out dependencies than this trial and error. As mentioned I am a newbie with this, so if anyone has any comments feel free to email me.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## Logging from application code[\n]"
http-outgoing-4 >> "Although the hadoop libraries log correctly with a properly located log4.properties file, application code calling the log4j logger seems to ignore this file. Using the log4j logger as per instructions in the log4j manual and many online tutorials did not result in getting any logging redirected to file configured in the properties file. Instead console output only is obtained. A clue to this mystery was that a most basic of hello world netbeans maven projects which did not import any hadoop stuff also failed to log to a file and did not even give the "No appenders" warning. Then I noticed that there were org.sl4j depencies in the hadoop build, so using sl4j instead solved the problem. Once my hello world project used sl4j's LoggerFactory and had sl4j-api and sl4j-12 as a dependencies it started to use the properties file. See http://www.slf4j.org/manual.html[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## Upload a file from local storage to the HDFS via the REST API[\n]"
http-outgoing-4 >> "The WebHDFS REST API documentation which came with the installation specifies that file creation is a two stage operation where an initial PUT to the namenode is sent. This responds with a redirect to the datanode and another PUT should be made to this redirection which can contain the chunked data stream. This does not sound REST to me as it relies on holding redirection state (a fully distributed configuration could presumably return a redirection to any one of the datanodes). Hadoop say this is because of a bug in some HTTP client implementations - incorrect implementation of [0xe2][0x80][0x9c]Expect: 100-continue[0xe2][0x80][0x9d].[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "However, the 2 stage PUT not being REST seems to be a moot point, at least with the Jersey client. I do not get a redirection and a file creates/uploads all in one go.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "Since writing the above paragraph I have implemented the Apache Client back end option to my HDFS Web client interface and this client behaves differently. It does indeed cause a redirect as per Hadoop documentation. The follow up PUT to the redirected location with the chunked file stream works as per documentation.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "Since writing the above paragraph I have implemented a big chunk size setting for the HTTP chunking and this changed the behaviour of the Jersey client to always redirect. It might be that unless the chunk size option is set then the Jersey implementation does not chunk - this would be terrible for big files.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "To be continued ...[\n]"
http-outgoing-4 >> "[\r][\n]"
http-outgoing-4 >> "0[\r][\n]"
http-outgoing-4 >> "[\r][\n]"
http-outgoing-4 << "HTTP/1.1 100 Continue[\r][\n]"
http-outgoing-4 << "[\r][\n]"
http-outgoing-4 << HTTP/1.1 100 Continue
http-outgoing-4 << "HTTP/1.1 201 Created[\r][\n]"
http-outgoing-4 << "Location: hdfs://localhost:9000/user/michaeljones/README.md[\r][\n]"
http-outgoing-4 << "Content-Length: 0[\r][\n]"
http-outgoing-4 << "Connection: close[\r][\n]"
http-outgoing-4 << "[\r][\n]"
http-outgoing-4 << HTTP/1.1 201 Created
http-outgoing-4 << Location: hdfs://localhost:9000/user/michaeljones/README.md
http-outgoing-4 << Content-Length: 0
http-outgoing-4 << Connection: close
http-outgoing-4: Shutdown connection
Connection discarded
http-outgoing-4: Close connection
Connection released: [id: 4][route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection manager is shutting down
Connection manager shut down
com.sun.jersey.client.property.chunkedEncodingSize: 1048576
Jersey client Redirect to: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/nbactions.xml?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
Connection manager is shutting down
Connection manager shut down
com.sun.jersey.client.property.chunkedEncodingSize: 1048576
Jersey client Redirect to: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/nbactions.xml?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
com.sun.jersey.client.property.chunkedEncodingSize: 1048576
Jersey client Redirect to: hdfs://localhost:9000/user/michaeljones/hellohadoop.log.2015-06-12
Jersey client Redirect to: hdfs://localhost:9000/user/michaeljones/hellohadoop.log.2015-06-13
Jersey Future: com.sun.jersey.api.client.ClientHandlerException: java.net.MalformedURLException: unknown protocol: hdfs
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 0][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://localhost:50070
Connecting to localhost/127.0.0.1:50070
Connection established 127.0.0.1:49655<->127.0.0.1:50070
Executing request GET /webhdfs/v1/user/michaeljones/?user.name=michaeljones&op=LISTSTATUS HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-0 >> GET /webhdfs/v1/user/michaeljones/?user.name=michaeljones&op=LISTSTATUS HTTP/1.1
http-outgoing-0 >> accept: application/json
http-outgoing-0 >> Host: localhost:50070
http-outgoing-0 >> Connection: Keep-Alive
http-outgoing-0 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-0 >> Accept-Encoding: gzip,deflate
http-outgoing-0 >> "GET /webhdfs/v1/user/michaeljones/?user.name=michaeljones&op=LISTSTATUS HTTP/1.1[\r][\n]"
http-outgoing-0 >> "accept: application/json[\r][\n]"
http-outgoing-0 >> "Host: localhost:50070[\r][\n]"
http-outgoing-0 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-0 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-0 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-0 >> "[\r][\n]"
http-outgoing-0 << "HTTP/1.1 200 OK[\r][\n]"
http-outgoing-0 << "Cache-Control: no-cache[\r][\n]"
http-outgoing-0 << "Expires: Sun, 14 Jun 2015 02:20:46 GMT[\r][\n]"
http-outgoing-0 << "Date: Sun, 14 Jun 2015 02:20:46 GMT[\r][\n]"
http-outgoing-0 << "Pragma: no-cache[\r][\n]"
http-outgoing-0 << "Expires: Sun, 14 Jun 2015 02:20:46 GMT[\r][\n]"
http-outgoing-0 << "Date: Sun, 14 Jun 2015 02:20:46 GMT[\r][\n]"
http-outgoing-0 << "Pragma: no-cache[\r][\n]"
http-outgoing-0 << "Content-Type: application/json[\r][\n]"
http-outgoing-0 << "Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434284446990&s=Y5brZb+0Uja2a9e+V75l+psbkQA="; Path=/; Expires=Sun, 14-Jun-2015 12:20:46 GMT; HttpOnly[\r][\n]"
http-outgoing-0 << "Transfer-Encoding: chunked[\r][\n]"
http-outgoing-0 << "Server: Jetty(6.1.26)[\r][\n]"
http-outgoing-0 << "[\r][\n]"
http-outgoing-0 << "12FC[\r][\n]"
http-outgoing-0 << "{"FileStatuses":{"FileStatus":[[\n]"
http-outgoing-0 << "{"accessTime":1434248365408,"blockSize":134217728,"childrenNum":0,"fileId":18700,"group":"supergroup","length":11335,"modificationTime":1434248365442,"owner":"michaeljones","pathSuffix":"README.md","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434242172845,"blockSize":134217728,"childrenNum":0,"fileId":18690,"group":"supergroup","length":0,"modificationTime":1434242172851,"owner":"michaeljones","pathSuffix":"apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434242173486,"blockSize":134217728,"childrenNum":0,"fileId":18692,"group":"supergroup","length":0,"modificationTime":1434242173493,"owner":"michaeljones","pathSuffix":"empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434248363946,"blockSize":134217728,"childrenNum":0,"fileId":18697,"group":"supergroup","length":0,"modificationTime":1434248363953,"owner":"michaeljones","pathSuffix":"hello-apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434091626279,"blockSize":134217728,"childrenNum":0,"fileId":18298,"group":"supergroup","length":0,"modificationTime":1434091626286,"owner":"michaeljones","pathSuffix":"hello-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434248363824,"blockSize":134217728,"childrenNum":0,"fileId":18696,"group":"supergroup","length":0,"modificationTime":1434248363890,"owner":"michaeljones","pathSuffix":"hello-jersey-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434242173890,"blockSize":134217728,"childrenNum":0,"fileId":18694,"group":"supergroup","length":584846,"modificationTime":1434242173915,"owner":"michaeljones","pathSuffix":"hello.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434248365043,"blockSize":134217728,"childrenNum":0,"fileId":18699,"group":"supergroup","length":3678856,"modificationTime":1434248365298,"owner":"michaeljones","pathSuffix":"hello.log.2015-06-12","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434242164264,"blockSize":134217728,"childrenNum":0,"fileId":18668,"group":"supergroup","length":20,"modificationTime":1434242164753,"owner":"michaeljones","pathSuffix":"hello.txt","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434248364191,"blockSize":134217728,"childrenNum":0,"fileId":18698,"group":"supergroup","length":27615,"modificationTime":1434248364913,"owner":"michaeljones","pathSuffix":"hellohadoop.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434248366326,"blockSize":134217728,"childrenNum":0,"fileId":18702,"group":"supergroup","length":102268,"modificationTime":1434248366365,"owner":"michaeljones","pathSuffix":"hellohadoop.log.2015-06-12","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434248366332,"blockSize":134217728,"childrenNum":0,"fileId":18703,"group":"supergroup","length":123003,"modificationTime":1434248366368,"owner":"michaeljones","pathSuffix":"hellohadoop.log.2015-06-13","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434248365944,"blockSize":134217728,"childrenNum":0,"fileId":18701,"group":"supergroup","length":3644,"modificationTime":1434248365974,"owner":"michaeljones","pathSuffix":"nbactions.xml","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434242172891,"blockSize":134217728,"childrenNum":0,"fileId":18691,"group":"supergroup","length":2134,"modificationTime":1434242172913,"owner":"michaeljones","pathSuffix":"pom.xml","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434242165542,"blockSize":134217728,"childrenNum":0,"fileId":16388,"group":"supergroup","length":50,"modificationTime":1433119638967,"owner":"michaeljones","pathSuffix":"wcInput","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18676,"group":"supergroup","length":0,"modificationTime":1434242169795,"owner":"michaeljones","pathSuffix":"wcOutput","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},[\n]"
http-outgoing-0 << "{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18683,"group":"supergroup","length":0,"modificationTime":1434242171819,"owner":"michaeljones","pathSuffix":"wcOutputAnalysis","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},[\n]"
http-outgoing-0 << "{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18669,"group":"supergroup","length":0,"modificationTime":1434242168288,"owner":"michaeljones","pathSuffix":"wcOutputMain","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"}[\n]"
http-outgoing-0 << "]}}[\n]"
http-outgoing-0 << "[\r][\n]"
http-outgoing-0 << "0[\r][\n]"
http-outgoing-0 << "[\r][\n]"
http-outgoing-0 << HTTP/1.1 200 OK
http-outgoing-0 << Cache-Control: no-cache
http-outgoing-0 << Expires: Sun, 14 Jun 2015 02:20:46 GMT
http-outgoing-0 << Date: Sun, 14 Jun 2015 02:20:46 GMT
http-outgoing-0 << Pragma: no-cache
http-outgoing-0 << Expires: Sun, 14 Jun 2015 02:20:46 GMT
http-outgoing-0 << Date: Sun, 14 Jun 2015 02:20:46 GMT
http-outgoing-0 << Pragma: no-cache
http-outgoing-0 << Content-Type: application/json
http-outgoing-0 << Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434284446990&s=Y5brZb+0Uja2a9e+V75l+psbkQA="; Path=/; Expires=Sun, 14-Jun-2015 12:20:46 GMT; HttpOnly
http-outgoing-0 << Transfer-Encoding: chunked
http-outgoing-0 << Server: Jetty(6.1.26)
Connection can be kept alive indefinitely
Cookie accepted [hadoop.auth=""u=michaeljones&p=michaeljones&t=simple&e=1434284446990&s=Y5brZb+0Uja2a9e+V75l+psbkQA="", version:0, domain:localhost, path:/, expiry:Sun Jun 14 22:20:46 AEST 2015]
Connection [id: 0][route: {}->http://localhost:50070] can be kept alive indefinitely
Connection released: [id: 0][route: {}->http://localhost:50070][total kept alive: 1; route allocated: 1 of 2; total allocated: 1 of 20]
Connection manager is shutting down
http-outgoing-0: Close connection
http-outgoing-0: Close connection
Connection manager shut down
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 1][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://localhost:50070
Connecting to localhost/127.0.0.1:50070
Connection established 127.0.0.1:49658<->127.0.0.1:50070
Executing request PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-1 >> PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1
http-outgoing-1 >> Content-Length: 0
http-outgoing-1 >> Host: localhost:50070
http-outgoing-1 >> Connection: Keep-Alive
http-outgoing-1 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-1 >> Accept-Encoding: gzip,deflate
http-outgoing-1 >> "PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1[\r][\n]"
http-outgoing-1 >> "Content-Length: 0[\r][\n]"
http-outgoing-1 >> "Host: localhost:50070[\r][\n]"
http-outgoing-1 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-1 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-1 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-1 >> "[\r][\n]"
http-outgoing-1 << "HTTP/1.1 307 TEMPORARY_REDIRECT[\r][\n]"
http-outgoing-1 << "Cache-Control: no-cache[\r][\n]"
http-outgoing-1 << "Expires: Sun, 14 Jun 2015 02:20:47 GMT[\r][\n]"
http-outgoing-1 << "Date: Sun, 14 Jun 2015 02:20:47 GMT[\r][\n]"
http-outgoing-1 << "Pragma: no-cache[\r][\n]"
http-outgoing-1 << "Expires: Sun, 14 Jun 2015 02:20:47 GMT[\r][\n]"
http-outgoing-1 << "Date: Sun, 14 Jun 2015 02:20:47 GMT[\r][\n]"
http-outgoing-1 << "Pragma: no-cache[\r][\n]"
http-outgoing-1 << "Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434284447655&s=1fWlLHq5sh9NCMn0wsMh7gHVHes="; Path=/; Expires=Sun, 14-Jun-2015 12:20:47 GMT; HttpOnly[\r][\n]"
http-outgoing-1 << "Location: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true[\r][\n]"
http-outgoing-1 << "Content-Type: application/octet-stream[\r][\n]"
http-outgoing-1 << "Content-Length: 0[\r][\n]"
http-outgoing-1 << "Server: Jetty(6.1.26)[\r][\n]"
http-outgoing-1 << "[\r][\n]"
http-outgoing-1 << HTTP/1.1 307 TEMPORARY_REDIRECT
http-outgoing-1 << Cache-Control: no-cache
http-outgoing-1 << Expires: Sun, 14 Jun 2015 02:20:47 GMT
http-outgoing-1 << Date: Sun, 14 Jun 2015 02:20:47 GMT
http-outgoing-1 << Pragma: no-cache
http-outgoing-1 << Expires: Sun, 14 Jun 2015 02:20:47 GMT
http-outgoing-1 << Date: Sun, 14 Jun 2015 02:20:47 GMT
http-outgoing-1 << Pragma: no-cache
http-outgoing-1 << Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434284447655&s=1fWlLHq5sh9NCMn0wsMh7gHVHes="; Path=/; Expires=Sun, 14-Jun-2015 12:20:47 GMT; HttpOnly
http-outgoing-1 << Location: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
http-outgoing-1 << Content-Type: application/octet-stream
http-outgoing-1 << Content-Length: 0
http-outgoing-1 << Server: Jetty(6.1.26)
Connection can be kept alive indefinitely
Cookie accepted [hadoop.auth=""u=michaeljones&p=michaeljones&t=simple&e=1434284447655&s=1fWlLHq5sh9NCMn0wsMh7gHVHes="", version:0, domain:localhost, path:/, expiry:Sun Jun 14 22:20:47 AEST 2015]
Redirect to: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
http-outgoing-1: Shutdown connection
Connection discarded
http-outgoing-1: Close connection
Connection released: [id: 1][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 2][route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://michaels-air.bigpond:50075
Connecting to michaels-air.bigpond/10.0.0.2:50075
Connection established 10.0.0.2:49659<->10.0.0.2:50075
Executing request PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-2 >> PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1
http-outgoing-2 >> Content-Length: 0
http-outgoing-2 >> Host: michaels-air.bigpond:50075
http-outgoing-2 >> Connection: Keep-Alive
http-outgoing-2 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-2 >> Accept-Encoding: gzip,deflate
http-outgoing-2 >> "PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1[\r][\n]"
http-outgoing-2 >> "Content-Length: 0[\r][\n]"
http-outgoing-2 >> "Host: michaels-air.bigpond:50075[\r][\n]"
http-outgoing-2 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-2 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-2 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-2 >> "[\r][\n]"
http-outgoing-2 << "HTTP/1.1 100 Continue[\r][\n]"
http-outgoing-2 << "[\r][\n]"
http-outgoing-2 << HTTP/1.1 100 Continue
http-outgoing-2 << "HTTP/1.1 201 Created[\r][\n]"
http-outgoing-2 << "Location: hdfs://localhost:9000/user/michaeljones/hello-apache-empty.txt[\r][\n]"
http-outgoing-2 << "Content-Length: 0[\r][\n]"
http-outgoing-2 << "Connection: close[\r][\n]"
http-outgoing-2 << "[\r][\n]"
http-outgoing-2 << HTTP/1.1 201 Created
http-outgoing-2 << Location: hdfs://localhost:9000/user/michaeljones/hello-apache-empty.txt
http-outgoing-2 << Content-Length: 0
http-outgoing-2 << Connection: close
http-outgoing-2: Shutdown connection
Connection discarded
http-outgoing-2: Close connection
Connection released: [id: 2][route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection manager is shutting down
Connection manager shut down
Jersey client Redirect to: hdfs://localhost:9000/user/michaeljones/hellohadoop.log
com.sun.jersey.client.property.chunkedEncodingSize: 1048576
Jersey client Redirect to: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/hello.log.2015-06-12?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 3][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://localhost:50070
Connecting to localhost/127.0.0.1:50070
Connection established 127.0.0.1:49669<->127.0.0.1:50070
Executing request PUT /webhdfs/v1/user/michaeljones/README.md?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-3 >> PUT /webhdfs/v1/user/michaeljones/README.md?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1
http-outgoing-3 >> Transfer-Encoding: chunked
http-outgoing-3 >> Content-Type: application/octet-stream
http-outgoing-3 >> Host: localhost:50070
http-outgoing-3 >> Connection: Keep-Alive
http-outgoing-3 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-3 >> Accept-Encoding: gzip,deflate
http-outgoing-3 >> "PUT /webhdfs/v1/user/michaeljones/README.md?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1[\r][\n]"
http-outgoing-3 >> "Transfer-Encoding: chunked[\r][\n]"
http-outgoing-3 >> "Content-Type: application/octet-stream[\r][\n]"
http-outgoing-3 >> "Host: localhost:50070[\r][\n]"
http-outgoing-3 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-3 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-3 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-3 >> "[\r][\n]"
http-outgoing-3 >> "1000[\r][\n]"
http-outgoing-3 >> "# Hello-Hadoop-netbeans-OS-X[\n]"
http-outgoing-3 >> "Java Maven project for playing with the HDFS API without any 3rd party hadoop plugins.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## Aim of project[\n]"
http-outgoing-3 >> "Hello world/tutorial level for programmatically operating with a pseudo distributed hadoop configuration on OS X. Hadoop 2.7 on Yosemite.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## What this project demonstrates[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "This is work in progress and so far the following functionality is demonstrated:[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "1. Direct programmatic control of the HDFS and running map reduce jobs - all unit tests run from the IDE with hadoop configuration built into this project and under git control.[\n]"
http-outgoing-3 >> "2. Uploading of files to the HDFS by implementing a Web REST API client.[\n]"
http-outgoing-3 >> "3. Async file upload (at time of writing only Jersey back end implemented).[\n]"
http-outgoing-3 >> "4. Layered application code for maximum re-use and ease of test driven development. The client I wrote uses an interface which has allowed me to provide both a Jersey HTTP client implementation and an Apache HTTP client implementation for comparison between the two toolkits.[\n]"
http-outgoing-3 >> "5. Test driven development.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## Getting started[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "The initial difficulty was working out how to run the program in the IDE and talk to the local pseudo distributed setup without using a 3rd party Hadoop plugin. Apparently there used to be a plugin for netbeans, but it has been discontinued. I am a newbie with this technology.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "The Apache Hadoop instructions for building and running java programs are via their command line build/run utility only. Getting the yahoo hadoop HDFS tutorial program to build in the IDE wasn't too hard. However, by default it will ignore the local Hadoop configuration and only operate with the local file system in local debug mode.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## Wading through the configuration[\n]"
http-outgoing-3 >> "Hadoop is designed to work with a number of different topologies, directory locations, levels of replication, simulated environments etc. so as we would expect nothing works unless the configuration is right.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "First Hadoop needs to be installed and configured in pseudo distributed mode such that it builds and runs test programs on the command line. The hadoop documentation has instructions for doing this. Documentation is online and also included in the installation: share/doc/hadoop/index.html. However this is not enough to get it to work in the IDE.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## The netbeans project settings that are needed to run with the HDFS from the IDE:[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "1. Get log4j configured to work in the IDE. Absence of log4j configuration won't stop hadoop from running, but we won't get to see useful error messages from hadoop without it.[\n]"
http-outgoing-3 >> "2. HADOOP_HOME environment variable project run (and test) property.[\n]"
http-outgoing-3 >> "3. Duplicate hadoop configuration in the classpath. The above environment variable does not pick up the hadoop configuration from its usual place. Yahoo's only suggestion is to run from the command line via the hadoop script. The Apache HDFS API documention says that configuration is looked for in the classpath, so I took the approach of duplicating the configuration (just 2 files) instead of figuring out how to get it to look in the installation path.[\n]"
http-outgoing-3 >> "4. The correct Maven dependencies. If not all the jar depenencies are there the program may build and run, but it won't talk to the HDFS if it doesn't load the HDFS jars.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "I think that the setup of this project would probably work on Linux too.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## Working through trouble shooting the HDFS project settings[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "Issue 1 above shows up as:[\n]"
http-outgoing-3 >> "<pre><code>[\n]"
http-outgoing-3 >> "log4j:WARN No appenders could be found for logger (org.apache.hadoop.util.Shell).[\n]"
http-outgoing-3 >> "log4j:WARN Please initialize the log4j system properly.[\n]"
http-outgoing-3 >> "log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.[\n]"
http-outgoing-3 >> "</pre></code>[\n]"
http-outgoing-3 >> "This is solved by putting a log4j.properties configuration file in the classpath. For a Maven build getting files into the classpath can be achieved by putting them in src/main/resources. I don't think this is in the classpath, but the build will then copy the file into ./target/classes/ which is in the classpath.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "Issue 2 above shows up as:[\n]"
http-outgoing-3 >> "<pre><code>[\n]"
http-outgoing-3 >> "Failed to detect a valid hadoop home directory[\n]"
http-outgoing-3 >> "java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.[\n]"
http-outgoing-3 >> "</[\r][\n]"
http-outgoing-3 >> "1000[\r][\n]"
http-outgoing-3 >> "code></pre>[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "This is fixed by going into the project properties => Build => Actions => Run Project and adding the environment variable for HADOOP_HOME. This will result in an entry in the Maven POM. Repeat for "Test Project", "Debug Project" etc.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "Issue 3. shows up as running, but creating a file on the local file system instead of the HDFS. This was fixed       looking at the HDFS API documentation for org.apache.hadoop.conf.Configuration. This documentation is under the chapter: C API libhdfs HDFS which has a link to the HDFS API under "The APIs" (I strangely cannot find this in the main index). On my installation the HDFS API documentation link is file:///opt/local/hadoop-2.7.0/share/doc/hadoop/api/org/apache/hadoop/fs/FileSystem.html.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "This documentation told me that hadoop loads core-site.xml and core-default.xml in the classpath. Classpath for a Maven build can be reached by placing these files in the directory src/main/resources (see logging configuration above). I added hdfs-site instead of core-default (which doesn't exist on my 2.7 install) into the src/main/resources project directory.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "Issue 3 shows up as:[\n]"
http-outgoing-3 >> "<pre><code>[\n]"
http-outgoing-3 >> "java.io.IOException: "hadoop No FileSystem for scheme: hdfs".[\n]"
http-outgoing-3 >> "</code></pre>[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "This is part of the build dependency problem. The various threads on stackoverflow etc. suggested that a minimum dependency was the jar for hadoop-core. However, there is no such jar on 2.7. I ran the hadoop command to dump version and got this:[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "<pre><code>[\n]"
http-outgoing-3 >> "bin/hadoop version[\n]"
http-outgoing-3 >> "Hadoop 2.7.0[\n]"
http-outgoing-3 >> "Subversion https://git-wip-us.apache.org/repos/asf/hadoop.git -r d4c8d4d4d203c934e8074b31289a28724c0842cf[\n]"
http-outgoing-3 >> "Compiled by jenkins on 2015-04-10T18:40Z[\n]"
http-outgoing-3 >> "Compiled with protoc 2.5.0[\n]"
http-outgoing-3 >> "From source with checksum a9e90912c37a35c3195d23951fd18f[\n]"
http-outgoing-3 >> "This command was run using /opt/local/hadoop-2.7.0/share/hadoop/common/hadoop-common-2.7.0.jar[\n]"
http-outgoing-3 >> "</code></pre>[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "I noted the jar name at the end and added it as a dependency to the POM. This can either be hand coded in or right click pom.xml => Insert Code => Add Dependency => Search => query hadoop-common and select version which was 2.7.0 [jar] - central. Maven will then add dependencies to other hadoop jars in the "Dependencies" group in the project explorer. Netbeans will then download these dependencies before the next build. They go into ~/.m2/repository should they ever need to be cleaned out (Netbeans doesn't seem to have an IDE remove dependency option).[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "After doing the above project built, but showed up the "no filesystem error". I noticed that Maven had not pulled in any hdfs jars matching the jars in my share/hadoop/hdfs installation directory. So I took a guess that it needed only the top level hadoop-hdfs-2.7.0.jar and added this as a dependency to the POM and all was good :)[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## Working through trouble shooting the Map Reduce project settings[\n]"
http-outgoing-3 >> "After getting the HDFS API working in the IDE it was time to move on to getting the famous Word Count map-reduce tutorial running.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "So coded it, set the main program to the word count main as the one to run. From the IDE: project Properties => Run => Main Class. Provide input and output arguments for the word count program. I noted that the netbeans properties pop-up window does not persist these settings next time it pops up. However this setting is persistant and ends up in nbactions.xml.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "However, running the word count map reduce program resulted in an ioException:[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "<pre><code>[\n]"
http-outgoing-3 >> "Please check your configuration for mapreduce.framework.name and the correspond server addresses.[\n]"
http-outgoing-3 >> "</pre></code>[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "Because the resources directory only contains 2 configuration files from my hadoop installation I thought maybe I was missing a map reduce one. So the first thing I did was go into the configuration directory of my installation and grep all files to see if there was a configuration file with mapreduce framework property. There was not. I checked my programatic configuration dump from my test program. This property was not mentioned either. The only map reduce configuration was to do with some environment variables for heap size in one of the shell scripts. Note to sel[\r][\n]"
http-outgoing-3 >> "c47[\r][\n]"
http-outgoing-3 >> "f: this may be relevant and I can consider setting this in the IDE. However, that didn't look like the problem.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "I then checked my dependencies and noted there were no map reduce jars pulled in by Maven. So I added hadoop-mapreduce-client-core. Still not running. Checked the web and a thread on stackoverflow mentioned a number of other jars: hadoop-mapreduce-client-common and hadoop-mapreduce-client shuffle. I added just the hadoop-mapreduce-client-common and it runs :) I have a feeling that I might need some of the other jars for other API calls and that there must be a better way of working out dependencies than this trial and error. As mentioned I am a newbie with this, so if anyone has any comments feel free to email me.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## Logging from application code[\n]"
http-outgoing-3 >> "Although the hadoop libraries log correctly with a properly located log4.properties file, application code calling the log4j logger seems to ignore this file. Using the log4j logger as per instructions in the log4j manual and many online tutorials did not result in getting any logging redirected to file configured in the properties file. Instead console output only is obtained. A clue to this mystery was that a most basic of hello world netbeans maven projects which did not import any hadoop stuff also failed to log to a file and did not even give the "No appenders" warning. Then I noticed that there were org.sl4j depencies in the hadoop build, so using sl4j instead solved the problem. Once my hello world project used sl4j's LoggerFactory and had sl4j-api and sl4j-12 as a dependencies it started to use the properties file. See http://www.slf4j.org/manual.html[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## Upload a file from local storage to the HDFS via the REST API[\n]"
http-outgoing-3 >> "The WebHDFS REST API documentation which came with the installation specifies that file creation is a two stage operation where an initial PUT to the namenode is sent. This responds with a redirect to the datanode and another PUT should be made to this redirection which can contain the chunked data stream. This does not sound REST to me as it relies on holding redirection state (a fully distributed configuration could presumably return a redirection to any one of the datanodes). Hadoop say this is because of a bug in some HTTP client implementations - incorrect implementation of [0xe2][0x80][0x9c]Expect: 100-continue[0xe2][0x80][0x9d].[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "However, the 2 stage PUT not being REST seems to be a moot point, at least with the Jersey client. I do not get a redirection and a file creates/uploads all in one go.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "Since writing the above paragraph I have implemented the Apache Client back end option to my HDFS Web client interface and this client behaves differently. It does indeed cause a redirect as per Hadoop documentation. The follow up PUT to the redirected location with the chunked file stream works as per documentation.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "Since writing the above paragraph I have implemented a big chunk size setting for the HTTP chunking and this changed the behaviour of the Jersey client to always redirect. It might be that unless the chunk size option is set then the Jersey implementation does not chunk - this would be terrible for big files.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "To be continued ...[\n]"
http-outgoing-3 >> "[\r][\n]"
http-outgoing-3 >> "0[\r][\n]"
http-outgoing-3 >> "[\r][\n]"
http-outgoing-3 << "HTTP/1.1 307 TEMPORARY_REDIRECT[\r][\n]"
http-outgoing-3 << "Cache-Control: no-cache[\r][\n]"
http-outgoing-3 << "Expires: Sun, 14 Jun 2015 02:20:48 GMT[\r][\n]"
http-outgoing-3 << "Date: Sun, 14 Jun 2015 02:20:48 GMT[\r][\n]"
http-outgoing-3 << "Pragma: no-cache[\r][\n]"
http-outgoing-3 << "Expires: Sun, 14 Jun 2015 02:20:48 GMT[\r][\n]"
http-outgoing-3 << "Date: Sun, 14 Jun 2015 02:20:48 GMT[\r][\n]"
http-outgoing-3 << "Pragma: no-cache[\r][\n]"
http-outgoing-3 << "Content-Type: application/octet-stream[\r][\n]"
http-outgoing-3 << "Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434284448287&s=FCspiPGnqO7qlDGzXNFG7cWAArU="; Path=/; Expires=Sun, 14-Jun-2015 12:20:48 GMT; HttpOnly[\r][\n]"
http-outgoing-3 << "Location: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/README.md?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true[\r][\n]"
http-outgoing-3 << "Content-Length: 0[\r][\n]"
http-outgoing-3 << "Server: Jetty(6.1.26)[\r][\n]"
http-outgoing-3 << "[\r][\n]"
http-outgoing-3 << HTTP/1.1 307 TEMPORARY_REDIRECT
http-outgoing-3 << Cache-Control: no-cache
http-outgoing-3 << Expires: Sun, 14 Jun 2015 02:20:48 GMT
http-outgoing-3 << Date: Sun, 14 Jun 2015 02:20:48 GMT
http-outgoing-3 << Pragma: no-cache
http-outgoing-3 << Expires: Sun, 14 Jun 2015 02:20:48 GMT
http-outgoing-3 << Date: Sun, 14 Jun 2015 02:20:48 GMT
http-outgoing-3 << Pragma: no-cache
http-outgoing-3 << Content-Type: application/octet-stream
http-outgoing-3 << Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434284448287&s=FCspiPGnqO7qlDGzXNFG7cWAArU="; Path=/; Expires=Sun, 14-Jun-2015 12:20:48 GMT; HttpOnly
http-outgoing-3 << Location: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/README.md?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
http-outgoing-3 << Content-Length: 0
http-outgoing-3 << Server: Jetty(6.1.26)
Connection can be kept alive indefinitely
Cookie accepted [hadoop.auth=""u=michaeljones&p=michaeljones&t=simple&e=1434284448287&s=FCspiPGnqO7qlDGzXNFG7cWAArU="", version:0, domain:localhost, path:/, expiry:Sun Jun 14 22:20:48 AEST 2015]
Redirect to: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/README.md?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
http-outgoing-3: Shutdown connection
Connection discarded
http-outgoing-3: Close connection
Connection released: [id: 3][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 4][route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://michaels-air.bigpond:50075
Connecting to michaels-air.bigpond/10.0.0.2:50075
Connection established 10.0.0.2:49670<->10.0.0.2:50075
Executing request PUT /webhdfs/v1/user/michaeljones/README.md?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-4 >> PUT /webhdfs/v1/user/michaeljones/README.md?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1
http-outgoing-4 >> Transfer-Encoding: chunked
http-outgoing-4 >> Content-Type: application/octet-stream
http-outgoing-4 >> Host: michaels-air.bigpond:50075
http-outgoing-4 >> Connection: Keep-Alive
http-outgoing-4 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-4 >> Accept-Encoding: gzip,deflate
http-outgoing-4 >> "PUT /webhdfs/v1/user/michaeljones/README.md?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1[\r][\n]"
http-outgoing-4 >> "Transfer-Encoding: chunked[\r][\n]"
http-outgoing-4 >> "Content-Type: application/octet-stream[\r][\n]"
http-outgoing-4 >> "Host: michaels-air.bigpond:50075[\r][\n]"
http-outgoing-4 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-4 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-4 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-4 >> "[\r][\n]"
http-outgoing-4 >> "1000[\r][\n]"
http-outgoing-4 >> "# Hello-Hadoop-netbeans-OS-X[\n]"
http-outgoing-4 >> "Java Maven project for playing with the HDFS API without any 3rd party hadoop plugins.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## Aim of project[\n]"
http-outgoing-4 >> "Hello world/tutorial level for programmatically operating with a pseudo distributed hadoop configuration on OS X. Hadoop 2.7 on Yosemite.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## What this project demonstrates[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "This is work in progress and so far the following functionality is demonstrated:[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "1. Direct programmatic control of the HDFS and running map reduce jobs - all unit tests run from the IDE with hadoop configuration built into this project and under git control.[\n]"
http-outgoing-4 >> "2. Uploading of files to the HDFS by implementing a Web REST API client.[\n]"
http-outgoing-4 >> "3. Async file upload (at time of writing only Jersey back end implemented).[\n]"
http-outgoing-4 >> "4. Layered application code for maximum re-use and ease of test driven development. The client I wrote uses an interface which has allowed me to provide both a Jersey HTTP client implementation and an Apache HTTP client implementation for comparison between the two toolkits.[\n]"
http-outgoing-4 >> "5. Test driven development.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## Getting started[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "The initial difficulty was working out how to run the program in the IDE and talk to the local pseudo distributed setup without using a 3rd party Hadoop plugin. Apparently there used to be a plugin for netbeans, but it has been discontinued. I am a newbie with this technology.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "The Apache Hadoop instructions for building and running java programs are via their command line build/run utility only. Getting the yahoo hadoop HDFS tutorial program to build in the IDE wasn't too hard. However, by default it will ignore the local Hadoop configuration and only operate with the local file system in local debug mode.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## Wading through the configuration[\n]"
http-outgoing-4 >> "Hadoop is designed to work with a number of different topologies, directory locations, levels of replication, simulated environments etc. so as we would expect nothing works unless the configuration is right.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "First Hadoop needs to be installed and configured in pseudo distributed mode such that it builds and runs test programs on the command line. The hadoop documentation has instructions for doing this. Documentation is online and also included in the installation: share/doc/hadoop/index.html. However this is not enough to get it to work in the IDE.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## The netbeans project settings that are needed to run with the HDFS from the IDE:[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "1. Get log4j configured to work in the IDE. Absence of log4j configuration won't stop hadoop from running, but we won't get to see useful error messages from hadoop without it.[\n]"
http-outgoing-4 >> "2. HADOOP_HOME environment variable project run (and test) property.[\n]"
http-outgoing-4 >> "3. Duplicate hadoop configuration in the classpath. The above environment variable does not pick up the hadoop configuration from its usual place. Yahoo's only suggestion is to run from the command line via the hadoop script. The Apache HDFS API documention says that configuration is looked for in the classpath, so I took the approach of duplicating the configuration (just 2 files) instead of figuring out how to get it to look in the installation path.[\n]"
http-outgoing-4 >> "4. The correct Maven dependencies. If not all the jar depenencies are there the program may build and run, but it won't talk to the HDFS if it doesn't load the HDFS jars.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "I think that the setup of this project would probably work on Linux too.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## Working through trouble shooting the HDFS project settings[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "Issue 1 above shows up as:[\n]"
http-outgoing-4 >> "<pre><code>[\n]"
http-outgoing-4 >> "log4j:WARN No appenders could be found for logger (org.apache.hadoop.util.Shell).[\n]"
http-outgoing-4 >> "log4j:WARN Please initialize the log4j system properly.[\n]"
http-outgoing-4 >> "log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.[\n]"
http-outgoing-4 >> "</pre></code>[\n]"
http-outgoing-4 >> "This is solved by putting a log4j.properties configuration file in the classpath. For a Maven build getting files into the classpath can be achieved by putting them in src/main/resources. I don't think this is in the classpath, but the build will then copy the file into ./target/classes/ which is in the classpath.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "Issue 2 above shows up as:[\n]"
http-outgoing-4 >> "<pre><code>[\n]"
http-outgoing-4 >> "Failed to detect a valid hadoop home directory[\n]"
http-outgoing-4 >> "java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.[\n]"
http-outgoing-4 >> "</[\r][\n]"
http-outgoing-4 >> "1000[\r][\n]"
http-outgoing-4 >> "code></pre>[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "This is fixed by going into the project properties => Build => Actions => Run Project and adding the environment variable for HADOOP_HOME. This will result in an entry in the Maven POM. Repeat for "Test Project", "Debug Project" etc.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "Issue 3. shows up as running, but creating a file on the local file system instead of the HDFS. This was fixed       looking at the HDFS API documentation for org.apache.hadoop.conf.Configuration. This documentation is under the chapter: C API libhdfs HDFS which has a link to the HDFS API under "The APIs" (I strangely cannot find this in the main index). On my installation the HDFS API documentation link is file:///opt/local/hadoop-2.7.0/share/doc/hadoop/api/org/apache/hadoop/fs/FileSystem.html.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "This documentation told me that hadoop loads core-site.xml and core-default.xml in the classpath. Classpath for a Maven build can be reached by placing these files in the directory src/main/resources (see logging configuration above). I added hdfs-site instead of core-default (which doesn't exist on my 2.7 install) into the src/main/resources project directory.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "Issue 3 shows up as:[\n]"
http-outgoing-4 >> "<pre><code>[\n]"
http-outgoing-4 >> "java.io.IOException: "hadoop No FileSystem for scheme: hdfs".[\n]"
http-outgoing-4 >> "</code></pre>[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "This is part of the build dependency problem. The various threads on stackoverflow etc. suggested that a minimum dependency was the jar for hadoop-core. However, there is no such jar on 2.7. I ran the hadoop command to dump version and got this:[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "<pre><code>[\n]"
http-outgoing-4 >> "bin/hadoop version[\n]"
http-outgoing-4 >> "Hadoop 2.7.0[\n]"
http-outgoing-4 >> "Subversion https://git-wip-us.apache.org/repos/asf/hadoop.git -r d4c8d4d4d203c934e8074b31289a28724c0842cf[\n]"
http-outgoing-4 >> "Compiled by jenkins on 2015-04-10T18:40Z[\n]"
http-outgoing-4 >> "Compiled with protoc 2.5.0[\n]"
http-outgoing-4 >> "From source with checksum a9e90912c37a35c3195d23951fd18f[\n]"
http-outgoing-4 >> "This command was run using /opt/local/hadoop-2.7.0/share/hadoop/common/hadoop-common-2.7.0.jar[\n]"
http-outgoing-4 >> "</code></pre>[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "I noted the jar name at the end and added it as a dependency to the POM. This can either be hand coded in or right click pom.xml => Insert Code => Add Dependency => Search => query hadoop-common and select version which was 2.7.0 [jar] - central. Maven will then add dependencies to other hadoop jars in the "Dependencies" group in the project explorer. Netbeans will then download these dependencies before the next build. They go into ~/.m2/repository should they ever need to be cleaned out (Netbeans doesn't seem to have an IDE remove dependency option).[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "After doing the above project built, but showed up the "no filesystem error". I noticed that Maven had not pulled in any hdfs jars matching the jars in my share/hadoop/hdfs installation directory. So I took a guess that it needed only the top level hadoop-hdfs-2.7.0.jar and added this as a dependency to the POM and all was good :)[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## Working through trouble shooting the Map Reduce project settings[\n]"
http-outgoing-4 >> "After getting the HDFS API working in the IDE it was time to move on to getting the famous Word Count map-reduce tutorial running.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "So coded it, set the main program to the word count main as the one to run. From the IDE: project Properties => Run => Main Class. Provide input and output arguments for the word count program. I noted that the netbeans properties pop-up window does not persist these settings next time it pops up. However this setting is persistant and ends up in nbactions.xml.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "However, running the word count map reduce program resulted in an ioException:[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "<pre><code>[\n]"
http-outgoing-4 >> "Please check your configuration for mapreduce.framework.name and the correspond server addresses.[\n]"
http-outgoing-4 >> "</pre></code>[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "Because the resources directory only contains 2 configuration files from my hadoop installation I thought maybe I was missing a map reduce one. So the first thing I did was go into the configuration directory of my installation and grep all files to see if there was a configuration file with mapreduce framework property. There was not. I checked my programatic configuration dump from my test program. This property was not mentioned either. The only map reduce configuration was to do with some environment variables for heap size in one of the shell scripts. Note to sel[\r][\n]"
http-outgoing-4 >> "c47[\r][\n]"
http-outgoing-4 >> "f: this may be relevant and I can consider setting this in the IDE. However, that didn't look like the problem.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "I then checked my dependencies and noted there were no map reduce jars pulled in by Maven. So I added hadoop-mapreduce-client-core. Still not running. Checked the web and a thread on stackoverflow mentioned a number of other jars: hadoop-mapreduce-client-common and hadoop-mapreduce-client shuffle. I added just the hadoop-mapreduce-client-common and it runs :) I have a feeling that I might need some of the other jars for other API calls and that there must be a better way of working out dependencies than this trial and error. As mentioned I am a newbie with this, so if anyone has any comments feel free to email me.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## Logging from application code[\n]"
http-outgoing-4 >> "Although the hadoop libraries log correctly with a properly located log4.properties file, application code calling the log4j logger seems to ignore this file. Using the log4j logger as per instructions in the log4j manual and many online tutorials did not result in getting any logging redirected to file configured in the properties file. Instead console output only is obtained. A clue to this mystery was that a most basic of hello world netbeans maven projects which did not import any hadoop stuff also failed to log to a file and did not even give the "No appenders" warning. Then I noticed that there were org.sl4j depencies in the hadoop build, so using sl4j instead solved the problem. Once my hello world project used sl4j's LoggerFactory and had sl4j-api and sl4j-12 as a dependencies it started to use the properties file. See http://www.slf4j.org/manual.html[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## Upload a file from local storage to the HDFS via the REST API[\n]"
http-outgoing-4 >> "The WebHDFS REST API documentation which came with the installation specifies that file creation is a two stage operation where an initial PUT to the namenode is sent. This responds with a redirect to the datanode and another PUT should be made to this redirection which can contain the chunked data stream. This does not sound REST to me as it relies on holding redirection state (a fully distributed configuration could presumably return a redirection to any one of the datanodes). Hadoop say this is because of a bug in some HTTP client implementations - incorrect implementation of [0xe2][0x80][0x9c]Expect: 100-continue[0xe2][0x80][0x9d].[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "However, the 2 stage PUT not being REST seems to be a moot point, at least with the Jersey client. I do not get a redirection and a file creates/uploads all in one go.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "Since writing the above paragraph I have implemented the Apache Client back end option to my HDFS Web client interface and this client behaves differently. It does indeed cause a redirect as per Hadoop documentation. The follow up PUT to the redirected location with the chunked file stream works as per documentation.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "Since writing the above paragraph I have implemented a big chunk size setting for the HTTP chunking and this changed the behaviour of the Jersey client to always redirect. It might be that unless the chunk size option is set then the Jersey implementation does not chunk - this would be terrible for big files.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "To be continued ...[\n]"
http-outgoing-4 >> "[\r][\n]"
http-outgoing-4 >> "0[\r][\n]"
http-outgoing-4 >> "[\r][\n]"
http-outgoing-4 << "HTTP/1.1 100 Continue[\r][\n]"
http-outgoing-4 << "[\r][\n]"
http-outgoing-4 << HTTP/1.1 100 Continue
http-outgoing-4 << "HTTP/1.1 201 Created[\r][\n]"
http-outgoing-4 << "Location: hdfs://localhost:9000/user/michaeljones/README.md[\r][\n]"
http-outgoing-4 << "Content-Length: 0[\r][\n]"
http-outgoing-4 << "Connection: close[\r][\n]"
http-outgoing-4 << "[\r][\n]"
http-outgoing-4 << HTTP/1.1 201 Created
http-outgoing-4 << Location: hdfs://localhost:9000/user/michaeljones/README.md
http-outgoing-4 << Content-Length: 0
http-outgoing-4 << Connection: close
http-outgoing-4: Shutdown connection
Connection discarded
http-outgoing-4: Close connection
Connection released: [id: 4][route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection manager is shutting down
Connection manager shut down
Connection manager is shutting down
Connection manager shut down
com.sun.jersey.client.property.chunkedEncodingSize: 1048576
Jersey client Redirect to: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/nbactions.xml?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
com.sun.jersey.client.property.chunkedEncodingSize: 1048576
Jersey client Redirect to: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/nbactions.xml?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
com.sun.jersey.client.property.chunkedEncodingSize: 1048576
Jersey client Redirect to: hdfs://localhost:9000/user/michaeljones/hellohadoop.log.2015-06-12
Jersey client Redirect to: hdfs://localhost:9000/user/michaeljones/hellohadoop.log.2015-06-13
Jersey Future: com.sun.jersey.api.client.ClientHandlerException: java.net.MalformedURLException: unknown protocol: hdfs
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 0][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://localhost:50070
Connecting to localhost/127.0.0.1:50070
Connection established 127.0.0.1:49749<->127.0.0.1:50070
Executing request GET /webhdfs/v1/user/michaeljones/?user.name=michaeljones&op=LISTSTATUS HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-0 >> GET /webhdfs/v1/user/michaeljones/?user.name=michaeljones&op=LISTSTATUS HTTP/1.1
http-outgoing-0 >> accept: application/json
http-outgoing-0 >> Host: localhost:50070
http-outgoing-0 >> Connection: Keep-Alive
http-outgoing-0 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-0 >> Accept-Encoding: gzip,deflate
http-outgoing-0 >> "GET /webhdfs/v1/user/michaeljones/?user.name=michaeljones&op=LISTSTATUS HTTP/1.1[\r][\n]"
http-outgoing-0 >> "accept: application/json[\r][\n]"
http-outgoing-0 >> "Host: localhost:50070[\r][\n]"
http-outgoing-0 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-0 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-0 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-0 >> "[\r][\n]"
http-outgoing-0 << "HTTP/1.1 200 OK[\r][\n]"
http-outgoing-0 << "Cache-Control: no-cache[\r][\n]"
http-outgoing-0 << "Expires: Sun, 14 Jun 2015 02:33:56 GMT[\r][\n]"
http-outgoing-0 << "Date: Sun, 14 Jun 2015 02:33:56 GMT[\r][\n]"
http-outgoing-0 << "Pragma: no-cache[\r][\n]"
http-outgoing-0 << "Expires: Sun, 14 Jun 2015 02:33:56 GMT[\r][\n]"
http-outgoing-0 << "Date: Sun, 14 Jun 2015 02:33:56 GMT[\r][\n]"
http-outgoing-0 << "Pragma: no-cache[\r][\n]"
http-outgoing-0 << "Content-Type: application/json[\r][\n]"
http-outgoing-0 << "Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434285236579&s=JFZnSNEkFGZRqnHLaDISCxkbXIc="; Path=/; Expires=Sun, 14-Jun-2015 12:33:56 GMT; HttpOnly[\r][\n]"
http-outgoing-0 << "Transfer-Encoding: chunked[\r][\n]"
http-outgoing-0 << "Server: Jetty(6.1.26)[\r][\n]"
http-outgoing-0 << "[\r][\n]"
http-outgoing-0 << "12FC[\r][\n]"
http-outgoing-0 << "{"FileStatuses":{"FileStatus":[[\n]"
http-outgoing-0 << "{"accessTime":1434248448396,"blockSize":134217728,"childrenNum":0,"fileId":18708,"group":"supergroup","length":11335,"modificationTime":1434248448443,"owner":"michaeljones","pathSuffix":"README.md","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434242172845,"blockSize":134217728,"childrenNum":0,"fileId":18690,"group":"supergroup","length":0,"modificationTime":1434242172851,"owner":"michaeljones","pathSuffix":"apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434242173486,"blockSize":134217728,"childrenNum":0,"fileId":18692,"group":"supergroup","length":0,"modificationTime":1434242173493,"owner":"michaeljones","pathSuffix":"empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434248447704,"blockSize":134217728,"childrenNum":0,"fileId":18705,"group":"supergroup","length":0,"modificationTime":1434248447711,"owner":"michaeljones","pathSuffix":"hello-apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434091626279,"blockSize":134217728,"childrenNum":0,"fileId":18298,"group":"supergroup","length":0,"modificationTime":1434091626286,"owner":"michaeljones","pathSuffix":"hello-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434248447601,"blockSize":134217728,"childrenNum":0,"fileId":18704,"group":"supergroup","length":0,"modificationTime":1434248447616,"owner":"michaeljones","pathSuffix":"hello-jersey-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434242173890,"blockSize":134217728,"childrenNum":0,"fileId":18694,"group":"supergroup","length":584846,"modificationTime":1434242173915,"owner":"michaeljones","pathSuffix":"hello.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434248448113,"blockSize":134217728,"childrenNum":0,"fileId":18707,"group":"supergroup","length":3678856,"modificationTime":1434248448234,"owner":"michaeljones","pathSuffix":"hello.log.2015-06-12","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434242164264,"blockSize":134217728,"childrenNum":0,"fileId":18668,"group":"supergroup","length":20,"modificationTime":1434242164753,"owner":"michaeljones","pathSuffix":"hello.txt","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434248447948,"blockSize":134217728,"childrenNum":0,"fileId":18706,"group":"supergroup","length":27615,"modificationTime":1434248448029,"owner":"michaeljones","pathSuffix":"hellohadoop.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434248449308,"blockSize":134217728,"childrenNum":0,"fileId":18710,"group":"supergroup","length":102268,"modificationTime":1434248449364,"owner":"michaeljones","pathSuffix":"hellohadoop.log.2015-06-12","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434248449320,"blockSize":134217728,"childrenNum":0,"fileId":18711,"group":"supergroup","length":123003,"modificationTime":1434248449373,"owner":"michaeljones","pathSuffix":"hellohadoop.log.2015-06-13","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434248448909,"blockSize":134217728,"childrenNum":0,"fileId":18709,"group":"supergroup","length":3644,"modificationTime":1434248448940,"owner":"michaeljones","pathSuffix":"nbactions.xml","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434242172891,"blockSize":134217728,"childrenNum":0,"fileId":18691,"group":"supergroup","length":2134,"modificationTime":1434242172913,"owner":"michaeljones","pathSuffix":"pom.xml","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434242165542,"blockSize":134217728,"childrenNum":0,"fileId":16388,"group":"supergroup","length":50,"modificationTime":1433119638967,"owner":"michaeljones","pathSuffix":"wcInput","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18676,"group":"supergroup","length":0,"modificationTime":1434242169795,"owner":"michaeljones","pathSuffix":"wcOutput","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},[\n]"
http-outgoing-0 << "{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18683,"group":"supergroup","length":0,"modificationTime":1434242171819,"owner":"michaeljones","pathSuffix":"wcOutputAnalysis","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},[\n]"
http-outgoing-0 << "{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18669,"group":"supergroup","length":0,"modificationTime":1434242168288,"owner":"michaeljones","pathSuffix":"wcOutputMain","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"}[\n]"
http-outgoing-0 << "]}}[\n]"
http-outgoing-0 << "[\r][\n]"
http-outgoing-0 << "0[\r][\n]"
http-outgoing-0 << "[\r][\n]"
http-outgoing-0 << HTTP/1.1 200 OK
http-outgoing-0 << Cache-Control: no-cache
http-outgoing-0 << Expires: Sun, 14 Jun 2015 02:33:56 GMT
http-outgoing-0 << Date: Sun, 14 Jun 2015 02:33:56 GMT
http-outgoing-0 << Pragma: no-cache
http-outgoing-0 << Expires: Sun, 14 Jun 2015 02:33:56 GMT
http-outgoing-0 << Date: Sun, 14 Jun 2015 02:33:56 GMT
http-outgoing-0 << Pragma: no-cache
http-outgoing-0 << Content-Type: application/json
http-outgoing-0 << Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434285236579&s=JFZnSNEkFGZRqnHLaDISCxkbXIc="; Path=/; Expires=Sun, 14-Jun-2015 12:33:56 GMT; HttpOnly
http-outgoing-0 << Transfer-Encoding: chunked
http-outgoing-0 << Server: Jetty(6.1.26)
Connection can be kept alive indefinitely
Cookie accepted [hadoop.auth=""u=michaeljones&p=michaeljones&t=simple&e=1434285236579&s=JFZnSNEkFGZRqnHLaDISCxkbXIc="", version:0, domain:localhost, path:/, expiry:Sun Jun 14 22:33:56 AEST 2015]
Connection [id: 0][route: {}->http://localhost:50070] can be kept alive indefinitely
Connection released: [id: 0][route: {}->http://localhost:50070][total kept alive: 1; route allocated: 1 of 2; total allocated: 1 of 20]
Connection manager is shutting down
http-outgoing-0: Close connection
http-outgoing-0: Close connection
Connection manager shut down
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 1][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://localhost:50070
Connecting to localhost/127.0.0.1:50070
Connection established 127.0.0.1:49752<->127.0.0.1:50070
Executing request PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-1 >> PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1
http-outgoing-1 >> Content-Length: 0
http-outgoing-1 >> Host: localhost:50070
http-outgoing-1 >> Connection: Keep-Alive
http-outgoing-1 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-1 >> Accept-Encoding: gzip,deflate
http-outgoing-1 >> "PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1[\r][\n]"
http-outgoing-1 >> "Content-Length: 0[\r][\n]"
http-outgoing-1 >> "Host: localhost:50070[\r][\n]"
http-outgoing-1 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-1 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-1 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-1 >> "[\r][\n]"
http-outgoing-1 << "HTTP/1.1 307 TEMPORARY_REDIRECT[\r][\n]"
http-outgoing-1 << "Cache-Control: no-cache[\r][\n]"
http-outgoing-1 << "Expires: Sun, 14 Jun 2015 02:33:57 GMT[\r][\n]"
http-outgoing-1 << "Date: Sun, 14 Jun 2015 02:33:57 GMT[\r][\n]"
http-outgoing-1 << "Pragma: no-cache[\r][\n]"
http-outgoing-1 << "Expires: Sun, 14 Jun 2015 02:33:57 GMT[\r][\n]"
http-outgoing-1 << "Date: Sun, 14 Jun 2015 02:33:57 GMT[\r][\n]"
http-outgoing-1 << "Pragma: no-cache[\r][\n]"
http-outgoing-1 << "Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434285237177&s=pgkDzVhPWHB/N5ZK+Twl1/Shi20="; Path=/; Expires=Sun, 14-Jun-2015 12:33:57 GMT; HttpOnly[\r][\n]"
http-outgoing-1 << "Location: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true[\r][\n]"
http-outgoing-1 << "Content-Type: application/octet-stream[\r][\n]"
http-outgoing-1 << "Content-Length: 0[\r][\n]"
http-outgoing-1 << "Server: Jetty(6.1.26)[\r][\n]"
http-outgoing-1 << "[\r][\n]"
http-outgoing-1 << HTTP/1.1 307 TEMPORARY_REDIRECT
http-outgoing-1 << Cache-Control: no-cache
http-outgoing-1 << Expires: Sun, 14 Jun 2015 02:33:57 GMT
http-outgoing-1 << Date: Sun, 14 Jun 2015 02:33:57 GMT
http-outgoing-1 << Pragma: no-cache
http-outgoing-1 << Expires: Sun, 14 Jun 2015 02:33:57 GMT
http-outgoing-1 << Date: Sun, 14 Jun 2015 02:33:57 GMT
http-outgoing-1 << Pragma: no-cache
http-outgoing-1 << Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434285237177&s=pgkDzVhPWHB/N5ZK+Twl1/Shi20="; Path=/; Expires=Sun, 14-Jun-2015 12:33:57 GMT; HttpOnly
http-outgoing-1 << Location: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
http-outgoing-1 << Content-Type: application/octet-stream
http-outgoing-1 << Content-Length: 0
http-outgoing-1 << Server: Jetty(6.1.26)
Connection can be kept alive indefinitely
Cookie accepted [hadoop.auth=""u=michaeljones&p=michaeljones&t=simple&e=1434285237177&s=pgkDzVhPWHB/N5ZK+Twl1/Shi20="", version:0, domain:localhost, path:/, expiry:Sun Jun 14 22:33:57 AEST 2015]
Redirect to: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
http-outgoing-1: Shutdown connection
Connection discarded
http-outgoing-1: Close connection
Connection released: [id: 1][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 2][route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://michaels-air.bigpond:50075
Connecting to michaels-air.bigpond/10.0.0.2:50075
Connection established 10.0.0.2:49753<->10.0.0.2:50075
Executing request PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-2 >> PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1
http-outgoing-2 >> Content-Length: 0
http-outgoing-2 >> Host: michaels-air.bigpond:50075
http-outgoing-2 >> Connection: Keep-Alive
http-outgoing-2 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-2 >> Accept-Encoding: gzip,deflate
http-outgoing-2 >> "PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1[\r][\n]"
http-outgoing-2 >> "Content-Length: 0[\r][\n]"
http-outgoing-2 >> "Host: michaels-air.bigpond:50075[\r][\n]"
http-outgoing-2 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-2 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-2 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-2 >> "[\r][\n]"
http-outgoing-2 << "HTTP/1.1 100 Continue[\r][\n]"
http-outgoing-2 << "[\r][\n]"
http-outgoing-2 << HTTP/1.1 100 Continue
http-outgoing-2 << "HTTP/1.1 201 Created[\r][\n]"
http-outgoing-2 << "Location: hdfs://localhost:9000/user/michaeljones/hello-apache-empty.txt[\r][\n]"
http-outgoing-2 << "Content-Length: 0[\r][\n]"
http-outgoing-2 << "Connection: close[\r][\n]"
http-outgoing-2 << "[\r][\n]"
http-outgoing-2 << HTTP/1.1 201 Created
http-outgoing-2 << Location: hdfs://localhost:9000/user/michaeljones/hello-apache-empty.txt
http-outgoing-2 << Content-Length: 0
http-outgoing-2 << Connection: close
http-outgoing-2: Shutdown connection
Connection discarded
http-outgoing-2: Close connection
Connection released: [id: 2][route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection manager is shutting down
Connection manager shut down
Jersey client Redirect to: hdfs://localhost:9000/user/michaeljones/hellohadoop.log
com.sun.jersey.client.property.chunkedEncodingSize: 1048576
Jersey client Redirect to: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/hello.log.2015-06-12?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 3][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://localhost:50070
Connecting to localhost/127.0.0.1:50070
Connection established 127.0.0.1:49763<->127.0.0.1:50070
Executing request PUT /webhdfs/v1/user/michaeljones/README.md?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-3 >> PUT /webhdfs/v1/user/michaeljones/README.md?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1
http-outgoing-3 >> Transfer-Encoding: chunked
http-outgoing-3 >> Content-Type: application/octet-stream
http-outgoing-3 >> Host: localhost:50070
http-outgoing-3 >> Connection: Keep-Alive
http-outgoing-3 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-3 >> Accept-Encoding: gzip,deflate
http-outgoing-3 >> "PUT /webhdfs/v1/user/michaeljones/README.md?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1[\r][\n]"
http-outgoing-3 >> "Transfer-Encoding: chunked[\r][\n]"
http-outgoing-3 >> "Content-Type: application/octet-stream[\r][\n]"
http-outgoing-3 >> "Host: localhost:50070[\r][\n]"
http-outgoing-3 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-3 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-3 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-3 >> "[\r][\n]"
http-outgoing-3 >> "1000[\r][\n]"
http-outgoing-3 >> "# Hello-Hadoop-netbeans-OS-X[\n]"
http-outgoing-3 >> "Java Maven project for playing with the HDFS API without any 3rd party hadoop plugins.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## Aim of project[\n]"
http-outgoing-3 >> "Hello world/tutorial level for programmatically operating with a pseudo distributed hadoop configuration on OS X. Hadoop 2.7 on Yosemite.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## What this project demonstrates[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "This is work in progress and so far the following functionality is demonstrated:[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "1. Direct programmatic control of the HDFS and running map reduce jobs - all unit tests run from the IDE with hadoop configuration built into this project and under git control.[\n]"
http-outgoing-3 >> "2. Uploading of files to the HDFS by implementing a Web REST API client.[\n]"
http-outgoing-3 >> "3. Async file upload (at time of writing only Jersey back end implemented).[\n]"
http-outgoing-3 >> "4. Layered application code for maximum re-use and ease of test driven development. The client I wrote uses an interface which has allowed me to provide both a Jersey HTTP client implementation and an Apache HTTP client implementation for comparison between the two toolkits.[\n]"
http-outgoing-3 >> "5. Test driven development.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## Getting started[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "The initial difficulty was working out how to run the program in the IDE and talk to the local pseudo distributed setup without using a 3rd party Hadoop plugin. Apparently there used to be a plugin for netbeans, but it has been discontinued. I am a newbie with this technology.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "The Apache Hadoop instructions for building and running java programs are via their command line build/run utility only. Getting the yahoo hadoop HDFS tutorial program to build in the IDE wasn't too hard. However, by default it will ignore the local Hadoop configuration and only operate with the local file system in local debug mode.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## Wading through the configuration[\n]"
http-outgoing-3 >> "Hadoop is designed to work with a number of different topologies, directory locations, levels of replication, simulated environments etc. so as we would expect nothing works unless the configuration is right.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "First Hadoop needs to be installed and configured in pseudo distributed mode such that it builds and runs test programs on the command line. The hadoop documentation has instructions for doing this. Documentation is online and also included in the installation: share/doc/hadoop/index.html. However this is not enough to get it to work in the IDE.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## The netbeans project settings that are needed to run with the HDFS from the IDE:[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "1. Get log4j configured to work in the IDE. Absence of log4j configuration won't stop hadoop from running, but we won't get to see useful error messages from hadoop without it.[\n]"
http-outgoing-3 >> "2. HADOOP_HOME environment variable project run (and test) property.[\n]"
http-outgoing-3 >> "3. Duplicate hadoop configuration in the classpath. The above environment variable does not pick up the hadoop configuration from its usual place. Yahoo's only suggestion is to run from the command line via the hadoop script. The Apache HDFS API documention says that configuration is looked for in the classpath, so I took the approach of duplicating the configuration (just 2 files) instead of figuring out how to get it to look in the installation path.[\n]"
http-outgoing-3 >> "4. The correct Maven dependencies. If not all the jar depenencies are there the program may build and run, but it won't talk to the HDFS if it doesn't load the HDFS jars.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "I think that the setup of this project would probably work on Linux too.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## Working through trouble shooting the HDFS project settings[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "Issue 1 above shows up as:[\n]"
http-outgoing-3 >> "<pre><code>[\n]"
http-outgoing-3 >> "log4j:WARN No appenders could be found for logger (org.apache.hadoop.util.Shell).[\n]"
http-outgoing-3 >> "log4j:WARN Please initialize the log4j system properly.[\n]"
http-outgoing-3 >> "log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.[\n]"
http-outgoing-3 >> "</pre></code>[\n]"
http-outgoing-3 >> "This is solved by putting a log4j.properties configuration file in the classpath. For a Maven build getting files into the classpath can be achieved by putting them in src/main/resources. I don't think this is in the classpath, but the build will then copy the file into ./target/classes/ which is in the classpath.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "Issue 2 above shows up as:[\n]"
http-outgoing-3 >> "<pre><code>[\n]"
http-outgoing-3 >> "Failed to detect a valid hadoop home directory[\n]"
http-outgoing-3 >> "java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.[\n]"
http-outgoing-3 >> "</[\r][\n]"
http-outgoing-3 >> "1000[\r][\n]"
http-outgoing-3 >> "code></pre>[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "This is fixed by going into the project properties => Build => Actions => Run Project and adding the environment variable for HADOOP_HOME. This will result in an entry in the Maven POM. Repeat for "Test Project", "Debug Project" etc.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "Issue 3. shows up as running, but creating a file on the local file system instead of the HDFS. This was fixed       looking at the HDFS API documentation for org.apache.hadoop.conf.Configuration. This documentation is under the chapter: C API libhdfs HDFS which has a link to the HDFS API under "The APIs" (I strangely cannot find this in the main index). On my installation the HDFS API documentation link is file:///opt/local/hadoop-2.7.0/share/doc/hadoop/api/org/apache/hadoop/fs/FileSystem.html.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "This documentation told me that hadoop loads core-site.xml and core-default.xml in the classpath. Classpath for a Maven build can be reached by placing these files in the directory src/main/resources (see logging configuration above). I added hdfs-site instead of core-default (which doesn't exist on my 2.7 install) into the src/main/resources project directory.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "Issue 3 shows up as:[\n]"
http-outgoing-3 >> "<pre><code>[\n]"
http-outgoing-3 >> "java.io.IOException: "hadoop No FileSystem for scheme: hdfs".[\n]"
http-outgoing-3 >> "</code></pre>[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "This is part of the build dependency problem. The various threads on stackoverflow etc. suggested that a minimum dependency was the jar for hadoop-core. However, there is no such jar on 2.7. I ran the hadoop command to dump version and got this:[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "<pre><code>[\n]"
http-outgoing-3 >> "bin/hadoop version[\n]"
http-outgoing-3 >> "Hadoop 2.7.0[\n]"
http-outgoing-3 >> "Subversion https://git-wip-us.apache.org/repos/asf/hadoop.git -r d4c8d4d4d203c934e8074b31289a28724c0842cf[\n]"
http-outgoing-3 >> "Compiled by jenkins on 2015-04-10T18:40Z[\n]"
http-outgoing-3 >> "Compiled with protoc 2.5.0[\n]"
http-outgoing-3 >> "From source with checksum a9e90912c37a35c3195d23951fd18f[\n]"
http-outgoing-3 >> "This command was run using /opt/local/hadoop-2.7.0/share/hadoop/common/hadoop-common-2.7.0.jar[\n]"
http-outgoing-3 >> "</code></pre>[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "I noted the jar name at the end and added it as a dependency to the POM. This can either be hand coded in or right click pom.xml => Insert Code => Add Dependency => Search => query hadoop-common and select version which was 2.7.0 [jar] - central. Maven will then add dependencies to other hadoop jars in the "Dependencies" group in the project explorer. Netbeans will then download these dependencies before the next build. They go into ~/.m2/repository should they ever need to be cleaned out (Netbeans doesn't seem to have an IDE remove dependency option).[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "After doing the above project built, but showed up the "no filesystem error". I noticed that Maven had not pulled in any hdfs jars matching the jars in my share/hadoop/hdfs installation directory. So I took a guess that it needed only the top level hadoop-hdfs-2.7.0.jar and added this as a dependency to the POM and all was good :)[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## Working through trouble shooting the Map Reduce project settings[\n]"
http-outgoing-3 >> "After getting the HDFS API working in the IDE it was time to move on to getting the famous Word Count map-reduce tutorial running.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "So coded it, set the main program to the word count main as the one to run. From the IDE: project Properties => Run => Main Class. Provide input and output arguments for the word count program. I noted that the netbeans properties pop-up window does not persist these settings next time it pops up. However this setting is persistant and ends up in nbactions.xml.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "However, running the word count map reduce program resulted in an ioException:[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "<pre><code>[\n]"
http-outgoing-3 >> "Please check your configuration for mapreduce.framework.name and the correspond server addresses.[\n]"
http-outgoing-3 >> "</pre></code>[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "Because the resources directory only contains 2 configuration files from my hadoop installation I thought maybe I was missing a map reduce one. So the first thing I did was go into the configuration directory of my installation and grep all files to see if there was a configuration file with mapreduce framework property. There was not. I checked my programatic configuration dump from my test program. This property was not mentioned either. The only map reduce configuration was to do with some environment variables for heap size in one of the shell scripts. Note to sel[\r][\n]"
http-outgoing-3 >> "c47[\r][\n]"
http-outgoing-3 >> "f: this may be relevant and I can consider setting this in the IDE. However, that didn't look like the problem.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "I then checked my dependencies and noted there were no map reduce jars pulled in by Maven. So I added hadoop-mapreduce-client-core. Still not running. Checked the web and a thread on stackoverflow mentioned a number of other jars: hadoop-mapreduce-client-common and hadoop-mapreduce-client shuffle. I added just the hadoop-mapreduce-client-common and it runs :) I have a feeling that I might need some of the other jars for other API calls and that there must be a better way of working out dependencies than this trial and error. As mentioned I am a newbie with this, so if anyone has any comments feel free to email me.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## Logging from application code[\n]"
http-outgoing-3 >> "Although the hadoop libraries log correctly with a properly located log4.properties file, application code calling the log4j logger seems to ignore this file. Using the log4j logger as per instructions in the log4j manual and many online tutorials did not result in getting any logging redirected to file configured in the properties file. Instead console output only is obtained. A clue to this mystery was that a most basic of hello world netbeans maven projects which did not import any hadoop stuff also failed to log to a file and did not even give the "No appenders" warning. Then I noticed that there were org.sl4j depencies in the hadoop build, so using sl4j instead solved the problem. Once my hello world project used sl4j's LoggerFactory and had sl4j-api and sl4j-12 as a dependencies it started to use the properties file. See http://www.slf4j.org/manual.html[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## Upload a file from local storage to the HDFS via the REST API[\n]"
http-outgoing-3 >> "The WebHDFS REST API documentation which came with the installation specifies that file creation is a two stage operation where an initial PUT to the namenode is sent. This responds with a redirect to the datanode and another PUT should be made to this redirection which can contain the chunked data stream. This does not sound REST to me as it relies on holding redirection state (a fully distributed configuration could presumably return a redirection to any one of the datanodes). Hadoop say this is because of a bug in some HTTP client implementations - incorrect implementation of [0xe2][0x80][0x9c]Expect: 100-continue[0xe2][0x80][0x9d].[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "However, the 2 stage PUT not being REST seems to be a moot point, at least with the Jersey client. I do not get a redirection and a file creates/uploads all in one go.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "Since writing the above paragraph I have implemented the Apache Client back end option to my HDFS Web client interface and this client behaves differently. It does indeed cause a redirect as per Hadoop documentation. The follow up PUT to the redirected location with the chunked file stream works as per documentation.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "Since writing the above paragraph I have implemented a big chunk size setting for the HTTP chunking and this changed the behaviour of the Jersey client to always redirect. It might be that unless the chunk size option is set then the Jersey implementation does not chunk - this would be terrible for big files.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "To be continued ...[\n]"
http-outgoing-3 >> "[\r][\n]"
http-outgoing-3 >> "0[\r][\n]"
http-outgoing-3 >> "[\r][\n]"
http-outgoing-3 << "HTTP/1.1 307 TEMPORARY_REDIRECT[\r][\n]"
http-outgoing-3 << "Cache-Control: no-cache[\r][\n]"
http-outgoing-3 << "Expires: Sun, 14 Jun 2015 02:33:58 GMT[\r][\n]"
http-outgoing-3 << "Date: Sun, 14 Jun 2015 02:33:58 GMT[\r][\n]"
http-outgoing-3 << "Pragma: no-cache[\r][\n]"
http-outgoing-3 << "Expires: Sun, 14 Jun 2015 02:33:58 GMT[\r][\n]"
http-outgoing-3 << "Date: Sun, 14 Jun 2015 02:33:58 GMT[\r][\n]"
http-outgoing-3 << "Pragma: no-cache[\r][\n]"
http-outgoing-3 << "Content-Type: application/octet-stream[\r][\n]"
http-outgoing-3 << "Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434285238284&s=rES3uixVOraNMa0o5hdQApkwmbA="; Path=/; Expires=Sun, 14-Jun-2015 12:33:58 GMT; HttpOnly[\r][\n]"
http-outgoing-3 << "Location: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/README.md?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true[\r][\n]"
http-outgoing-3 << "Content-Length: 0[\r][\n]"
http-outgoing-3 << "Server: Jetty(6.1.26)[\r][\n]"
http-outgoing-3 << "[\r][\n]"
http-outgoing-3 << HTTP/1.1 307 TEMPORARY_REDIRECT
http-outgoing-3 << Cache-Control: no-cache
http-outgoing-3 << Expires: Sun, 14 Jun 2015 02:33:58 GMT
http-outgoing-3 << Date: Sun, 14 Jun 2015 02:33:58 GMT
http-outgoing-3 << Pragma: no-cache
http-outgoing-3 << Expires: Sun, 14 Jun 2015 02:33:58 GMT
http-outgoing-3 << Date: Sun, 14 Jun 2015 02:33:58 GMT
http-outgoing-3 << Pragma: no-cache
http-outgoing-3 << Content-Type: application/octet-stream
http-outgoing-3 << Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434285238284&s=rES3uixVOraNMa0o5hdQApkwmbA="; Path=/; Expires=Sun, 14-Jun-2015 12:33:58 GMT; HttpOnly
http-outgoing-3 << Location: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/README.md?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
http-outgoing-3 << Content-Length: 0
http-outgoing-3 << Server: Jetty(6.1.26)
Connection can be kept alive indefinitely
Cookie accepted [hadoop.auth=""u=michaeljones&p=michaeljones&t=simple&e=1434285238284&s=rES3uixVOraNMa0o5hdQApkwmbA="", version:0, domain:localhost, path:/, expiry:Sun Jun 14 22:33:58 AEST 2015]
Redirect to: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/README.md?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
http-outgoing-3: Shutdown connection
Connection discarded
http-outgoing-3: Close connection
Connection released: [id: 3][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 4][route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://michaels-air.bigpond:50075
Connecting to michaels-air.bigpond/10.0.0.2:50075
Connection established 10.0.0.2:49764<->10.0.0.2:50075
Executing request PUT /webhdfs/v1/user/michaeljones/README.md?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-4 >> PUT /webhdfs/v1/user/michaeljones/README.md?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1
http-outgoing-4 >> Transfer-Encoding: chunked
http-outgoing-4 >> Content-Type: application/octet-stream
http-outgoing-4 >> Host: michaels-air.bigpond:50075
http-outgoing-4 >> Connection: Keep-Alive
http-outgoing-4 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-4 >> Accept-Encoding: gzip,deflate
http-outgoing-4 >> "PUT /webhdfs/v1/user/michaeljones/README.md?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1[\r][\n]"
http-outgoing-4 >> "Transfer-Encoding: chunked[\r][\n]"
http-outgoing-4 >> "Content-Type: application/octet-stream[\r][\n]"
http-outgoing-4 >> "Host: michaels-air.bigpond:50075[\r][\n]"
http-outgoing-4 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-4 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-4 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-4 >> "[\r][\n]"
http-outgoing-4 >> "1000[\r][\n]"
http-outgoing-4 >> "# Hello-Hadoop-netbeans-OS-X[\n]"
http-outgoing-4 >> "Java Maven project for playing with the HDFS API without any 3rd party hadoop plugins.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## Aim of project[\n]"
http-outgoing-4 >> "Hello world/tutorial level for programmatically operating with a pseudo distributed hadoop configuration on OS X. Hadoop 2.7 on Yosemite.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## What this project demonstrates[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "This is work in progress and so far the following functionality is demonstrated:[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "1. Direct programmatic control of the HDFS and running map reduce jobs - all unit tests run from the IDE with hadoop configuration built into this project and under git control.[\n]"
http-outgoing-4 >> "2. Uploading of files to the HDFS by implementing a Web REST API client.[\n]"
http-outgoing-4 >> "3. Async file upload (at time of writing only Jersey back end implemented).[\n]"
http-outgoing-4 >> "4. Layered application code for maximum re-use and ease of test driven development. The client I wrote uses an interface which has allowed me to provide both a Jersey HTTP client implementation and an Apache HTTP client implementation for comparison between the two toolkits.[\n]"
http-outgoing-4 >> "5. Test driven development.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## Getting started[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "The initial difficulty was working out how to run the program in the IDE and talk to the local pseudo distributed setup without using a 3rd party Hadoop plugin. Apparently there used to be a plugin for netbeans, but it has been discontinued. I am a newbie with this technology.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "The Apache Hadoop instructions for building and running java programs are via their command line build/run utility only. Getting the yahoo hadoop HDFS tutorial program to build in the IDE wasn't too hard. However, by default it will ignore the local Hadoop configuration and only operate with the local file system in local debug mode.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## Wading through the configuration[\n]"
http-outgoing-4 >> "Hadoop is designed to work with a number of different topologies, directory locations, levels of replication, simulated environments etc. so as we would expect nothing works unless the configuration is right.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "First Hadoop needs to be installed and configured in pseudo distributed mode such that it builds and runs test programs on the command line. The hadoop documentation has instructions for doing this. Documentation is online and also included in the installation: share/doc/hadoop/index.html. However this is not enough to get it to work in the IDE.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## The netbeans project settings that are needed to run with the HDFS from the IDE:[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "1. Get log4j configured to work in the IDE. Absence of log4j configuration won't stop hadoop from running, but we won't get to see useful error messages from hadoop without it.[\n]"
http-outgoing-4 >> "2. HADOOP_HOME environment variable project run (and test) property.[\n]"
http-outgoing-4 >> "3. Duplicate hadoop configuration in the classpath. The above environment variable does not pick up the hadoop configuration from its usual place. Yahoo's only suggestion is to run from the command line via the hadoop script. The Apache HDFS API documention says that configuration is looked for in the classpath, so I took the approach of duplicating the configuration (just 2 files) instead of figuring out how to get it to look in the installation path.[\n]"
http-outgoing-4 >> "4. The correct Maven dependencies. If not all the jar depenencies are there the program may build and run, but it won't talk to the HDFS if it doesn't load the HDFS jars.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "I think that the setup of this project would probably work on Linux too.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## Working through trouble shooting the HDFS project settings[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "Issue 1 above shows up as:[\n]"
http-outgoing-4 >> "<pre><code>[\n]"
http-outgoing-4 >> "log4j:WARN No appenders could be found for logger (org.apache.hadoop.util.Shell).[\n]"
http-outgoing-4 >> "log4j:WARN Please initialize the log4j system properly.[\n]"
http-outgoing-4 >> "log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.[\n]"
http-outgoing-4 >> "</pre></code>[\n]"
http-outgoing-4 >> "This is solved by putting a log4j.properties configuration file in the classpath. For a Maven build getting files into the classpath can be achieved by putting them in src/main/resources. I don't think this is in the classpath, but the build will then copy the file into ./target/classes/ which is in the classpath.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "Issue 2 above shows up as:[\n]"
http-outgoing-4 >> "<pre><code>[\n]"
http-outgoing-4 >> "Failed to detect a valid hadoop home directory[\n]"
http-outgoing-4 >> "java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.[\n]"
http-outgoing-4 >> "</[\r][\n]"
http-outgoing-4 >> "1000[\r][\n]"
http-outgoing-4 >> "code></pre>[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "This is fixed by going into the project properties => Build => Actions => Run Project and adding the environment variable for HADOOP_HOME. This will result in an entry in the Maven POM. Repeat for "Test Project", "Debug Project" etc.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "Issue 3. shows up as running, but creating a file on the local file system instead of the HDFS. This was fixed       looking at the HDFS API documentation for org.apache.hadoop.conf.Configuration. This documentation is under the chapter: C API libhdfs HDFS which has a link to the HDFS API under "The APIs" (I strangely cannot find this in the main index). On my installation the HDFS API documentation link is file:///opt/local/hadoop-2.7.0/share/doc/hadoop/api/org/apache/hadoop/fs/FileSystem.html.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "This documentation told me that hadoop loads core-site.xml and core-default.xml in the classpath. Classpath for a Maven build can be reached by placing these files in the directory src/main/resources (see logging configuration above). I added hdfs-site instead of core-default (which doesn't exist on my 2.7 install) into the src/main/resources project directory.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "Issue 3 shows up as:[\n]"
http-outgoing-4 >> "<pre><code>[\n]"
http-outgoing-4 >> "java.io.IOException: "hadoop No FileSystem for scheme: hdfs".[\n]"
http-outgoing-4 >> "</code></pre>[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "This is part of the build dependency problem. The various threads on stackoverflow etc. suggested that a minimum dependency was the jar for hadoop-core. However, there is no such jar on 2.7. I ran the hadoop command to dump version and got this:[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "<pre><code>[\n]"
http-outgoing-4 >> "bin/hadoop version[\n]"
http-outgoing-4 >> "Hadoop 2.7.0[\n]"
http-outgoing-4 >> "Subversion https://git-wip-us.apache.org/repos/asf/hadoop.git -r d4c8d4d4d203c934e8074b31289a28724c0842cf[\n]"
http-outgoing-4 >> "Compiled by jenkins on 2015-04-10T18:40Z[\n]"
http-outgoing-4 >> "Compiled with protoc 2.5.0[\n]"
http-outgoing-4 >> "From source with checksum a9e90912c37a35c3195d23951fd18f[\n]"
http-outgoing-4 >> "This command was run using /opt/local/hadoop-2.7.0/share/hadoop/common/hadoop-common-2.7.0.jar[\n]"
http-outgoing-4 >> "</code></pre>[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "I noted the jar name at the end and added it as a dependency to the POM. This can either be hand coded in or right click pom.xml => Insert Code => Add Dependency => Search => query hadoop-common and select version which was 2.7.0 [jar] - central. Maven will then add dependencies to other hadoop jars in the "Dependencies" group in the project explorer. Netbeans will then download these dependencies before the next build. They go into ~/.m2/repository should they ever need to be cleaned out (Netbeans doesn't seem to have an IDE remove dependency option).[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "After doing the above project built, but showed up the "no filesystem error". I noticed that Maven had not pulled in any hdfs jars matching the jars in my share/hadoop/hdfs installation directory. So I took a guess that it needed only the top level hadoop-hdfs-2.7.0.jar and added this as a dependency to the POM and all was good :)[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## Working through trouble shooting the Map Reduce project settings[\n]"
http-outgoing-4 >> "After getting the HDFS API working in the IDE it was time to move on to getting the famous Word Count map-reduce tutorial running.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "So coded it, set the main program to the word count main as the one to run. From the IDE: project Properties => Run => Main Class. Provide input and output arguments for the word count program. I noted that the netbeans properties pop-up window does not persist these settings next time it pops up. However this setting is persistant and ends up in nbactions.xml.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "However, running the word count map reduce program resulted in an ioException:[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "<pre><code>[\n]"
http-outgoing-4 >> "Please check your configuration for mapreduce.framework.name and the correspond server addresses.[\n]"
http-outgoing-4 >> "</pre></code>[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "Because the resources directory only contains 2 configuration files from my hadoop installation I thought maybe I was missing a map reduce one. So the first thing I did was go into the configuration directory of my installation and grep all files to see if there was a configuration file with mapreduce framework property. There was not. I checked my programatic configuration dump from my test program. This property was not mentioned either. The only map reduce configuration was to do with some environment variables for heap size in one of the shell scripts. Note to sel[\r][\n]"
http-outgoing-4 >> "c47[\r][\n]"
http-outgoing-4 >> "f: this may be relevant and I can consider setting this in the IDE. However, that didn't look like the problem.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "I then checked my dependencies and noted there were no map reduce jars pulled in by Maven. So I added hadoop-mapreduce-client-core. Still not running. Checked the web and a thread on stackoverflow mentioned a number of other jars: hadoop-mapreduce-client-common and hadoop-mapreduce-client shuffle. I added just the hadoop-mapreduce-client-common and it runs :) I have a feeling that I might need some of the other jars for other API calls and that there must be a better way of working out dependencies than this trial and error. As mentioned I am a newbie with this, so if anyone has any comments feel free to email me.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## Logging from application code[\n]"
http-outgoing-4 >> "Although the hadoop libraries log correctly with a properly located log4.properties file, application code calling the log4j logger seems to ignore this file. Using the log4j logger as per instructions in the log4j manual and many online tutorials did not result in getting any logging redirected to file configured in the properties file. Instead console output only is obtained. A clue to this mystery was that a most basic of hello world netbeans maven projects which did not import any hadoop stuff also failed to log to a file and did not even give the "No appenders" warning. Then I noticed that there were org.sl4j depencies in the hadoop build, so using sl4j instead solved the problem. Once my hello world project used sl4j's LoggerFactory and had sl4j-api and sl4j-12 as a dependencies it started to use the properties file. See http://www.slf4j.org/manual.html[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## Upload a file from local storage to the HDFS via the REST API[\n]"
http-outgoing-4 >> "The WebHDFS REST API documentation which came with the installation specifies that file creation is a two stage operation where an initial PUT to the namenode is sent. This responds with a redirect to the datanode and another PUT should be made to this redirection which can contain the chunked data stream. This does not sound REST to me as it relies on holding redirection state (a fully distributed configuration could presumably return a redirection to any one of the datanodes). Hadoop say this is because of a bug in some HTTP client implementations - incorrect implementation of [0xe2][0x80][0x9c]Expect: 100-continue[0xe2][0x80][0x9d].[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "However, the 2 stage PUT not being REST seems to be a moot point, at least with the Jersey client. I do not get a redirection and a file creates/uploads all in one go.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "Since writing the above paragraph I have implemented the Apache Client back end option to my HDFS Web client interface and this client behaves differently. It does indeed cause a redirect as per Hadoop documentation. The follow up PUT to the redirected location with the chunked file stream works as per documentation.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "Since writing the above paragraph I have implemented a big chunk size setting for the HTTP chunking and this changed the behaviour of the Jersey client to always redirect. It might be that unless the chunk size option is set then the Jersey implementation does not chunk - this would be terrible for big files.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "To be continued ...[\n]"
http-outgoing-4 >> "[\r][\n]"
http-outgoing-4 >> "0[\r][\n]"
http-outgoing-4 >> "[\r][\n]"
http-outgoing-4 << "HTTP/1.1 100 Continue[\r][\n]"
http-outgoing-4 << "[\r][\n]"
http-outgoing-4 << "HTTP/1.1 201 Created[\r][\n]"
http-outgoing-4 << "Location: hdfs://localhost:9000/user/michaeljones/README.md[\r][\n]"
http-outgoing-4 << "Content-Length: 0[\r][\n]"
http-outgoing-4 << "Connection: close[\r][\n]"
http-outgoing-4 << "[\r][\n]"
http-outgoing-4 << HTTP/1.1 100 Continue
http-outgoing-4 << HTTP/1.1 201 Created
http-outgoing-4 << Location: hdfs://localhost:9000/user/michaeljones/README.md
http-outgoing-4 << Content-Length: 0
http-outgoing-4 << Connection: close
http-outgoing-4: Shutdown connection
Connection discarded
http-outgoing-4: Close connection
Connection released: [id: 4][route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection manager is shutting down
Connection manager shut down
Connection manager is shutting down
Connection manager shut down
com.sun.jersey.client.property.chunkedEncodingSize: 1048576
Jersey client Redirect to: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/nbactions.xml?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
com.sun.jersey.client.property.chunkedEncodingSize: 1048576
Jersey client Redirect to: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/nbactions.xml?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
com.sun.jersey.client.property.chunkedEncodingSize: 1048576
Jersey client Redirect to: hdfs://localhost:9000/user/michaeljones/hellohadoop.log.2015-06-12
Jersey client Redirect to: hdfs://localhost:9000/user/michaeljones/hellohadoop.log.2015-06-13
Jersey Future: com.sun.jersey.api.client.ClientHandlerException: java.net.MalformedURLException: unknown protocol: hdfs
Jersey client testGetStringContent
{"FileStatuses":{"FileStatus":[
{"accessTime":1434249238371,"blockSize":134217728,"childrenNum":0,"fileId":18716,"group":"supergroup","length":11335,"modificationTime":1434249238403,"owner":"michaeljones","pathSuffix":"README.md","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434242172845,"blockSize":134217728,"childrenNum":0,"fileId":18690,"group":"supergroup","length":0,"modificationTime":1434242172851,"owner":"michaeljones","pathSuffix":"apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434242173486,"blockSize":134217728,"childrenNum":0,"fileId":18692,"group":"supergroup","length":0,"modificationTime":1434242173493,"owner":"michaeljones","pathSuffix":"empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434249237237,"blockSize":134217728,"childrenNum":0,"fileId":18713,"group":"supergroup","length":0,"modificationTime":1434249237244,"owner":"michaeljones","pathSuffix":"hello-apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434091626279,"blockSize":134217728,"childrenNum":0,"fileId":18298,"group":"supergroup","length":0,"modificationTime":1434091626286,"owner":"michaeljones","pathSuffix":"hello-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434249237130,"blockSize":134217728,"childrenNum":0,"fileId":18712,"group":"supergroup","length":0,"modificationTime":1434249237142,"owner":"michaeljones","pathSuffix":"hello-jersey-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434242173890,"blockSize":134217728,"childrenNum":0,"fileId":18694,"group":"supergroup","length":584846,"modificationTime":1434242173915,"owner":"michaeljones","pathSuffix":"hello.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434249237945,"blockSize":134217728,"childrenNum":0,"fileId":18715,"group":"supergroup","length":3678856,"modificationTime":1434249238225,"owner":"michaeljones","pathSuffix":"hello.log.2015-06-12","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434242164264,"blockSize":134217728,"childrenNum":0,"fileId":18668,"group":"supergroup","length":20,"modificationTime":1434242164753,"owner":"michaeljones","pathSuffix":"hello.txt","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434249237796,"blockSize":134217728,"childrenNum":0,"fileId":18714,"group":"supergroup","length":27615,"modificationTime":1434249237841,"owner":"michaeljones","pathSuffix":"hellohadoop.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434249240018,"blockSize":134217728,"childrenNum":0,"fileId":18719,"group":"supergroup","length":102268,"modificationTime":1434249240060,"owner":"michaeljones","pathSuffix":"hellohadoop.log.2015-06-12","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434249240016,"blockSize":134217728,"childrenNum":0,"fileId":18718,"group":"supergroup","length":123003,"modificationTime":1434249240061,"owner":"michaeljones","pathSuffix":"hellohadoop.log.2015-06-13","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434249239189,"blockSize":134217728,"childrenNum":0,"fileId":18717,"group":"supergroup","length":3644,"modificationTime":1434249239223,"owner":"michaeljones","pathSuffix":"nbactions.xml","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434242172891,"blockSize":134217728,"childrenNum":0,"fileId":18691,"group":"supergroup","length":2134,"modificationTime":1434242172913,"owner":"michaeljones","pathSuffix":"pom.xml","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434242165542,"blockSize":134217728,"childrenNum":0,"fileId":16388,"group":"supergroup","length":50,"modificationTime":1433119638967,"owner":"michaeljones","pathSuffix":"wcInput","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18676,"group":"supergroup","length":0,"modificationTime":1434242169795,"owner":"michaeljones","pathSuffix":"wcOutput","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},
{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18683,"group":"supergroup","length":0,"modificationTime":1434242171819,"owner":"michaeljones","pathSuffix":"wcOutputAnalysis","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},
{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18669,"group":"supergroup","length":0,"modificationTime":1434242168288,"owner":"michaeljones","pathSuffix":"wcOutputMain","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"}
]}}

Jersey client Redirect to: hdfs://localhost:9000/user/michaeljones/hello.log
Jersey redirected to IPC: hdfs://localhost:9000/user/michaeljones/hello.log
com.sun.jersey.client.property.chunkedEncodingSize: 1048576
com.sun.jersey.client.property.chunkedEncodingSize: 1048576
Jersey client Redirect to: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/nbactions.xml?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
com.sun.jersey.client.property.chunkedEncodingSize: 1048576
Jersey client Redirect to: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/nbactions.xml?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
Get redirect location async: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/nbactions.xml?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
Jersey client testGetStringContent
{"FileStatuses":{"FileStatus":[
{"accessTime":1434249238371,"blockSize":134217728,"childrenNum":0,"fileId":18716,"group":"supergroup","length":11335,"modificationTime":1434249238403,"owner":"michaeljones","pathSuffix":"README.md","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434242172845,"blockSize":134217728,"childrenNum":0,"fileId":18690,"group":"supergroup","length":0,"modificationTime":1434242172851,"owner":"michaeljones","pathSuffix":"apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434249287104,"blockSize":134217728,"childrenNum":0,"fileId":18720,"group":"supergroup","length":0,"modificationTime":1434249287112,"owner":"michaeljones","pathSuffix":"empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434249237237,"blockSize":134217728,"childrenNum":0,"fileId":18713,"group":"supergroup","length":0,"modificationTime":1434249237244,"owner":"michaeljones","pathSuffix":"hello-apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434091626279,"blockSize":134217728,"childrenNum":0,"fileId":18298,"group":"supergroup","length":0,"modificationTime":1434091626286,"owner":"michaeljones","pathSuffix":"hello-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434249237130,"blockSize":134217728,"childrenNum":0,"fileId":18712,"group":"supergroup","length":0,"modificationTime":1434249237142,"owner":"michaeljones","pathSuffix":"hello-jersey-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434249287792,"blockSize":134217728,"childrenNum":0,"fileId":18722,"group":"supergroup","length":748093,"modificationTime":1434249287826,"owner":"michaeljones","pathSuffix":"hello.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434249237945,"blockSize":134217728,"childrenNum":0,"fileId":18715,"group":"supergroup","length":3678856,"modificationTime":1434249238225,"owner":"michaeljones","pathSuffix":"hello.log.2015-06-12","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434242164264,"blockSize":134217728,"childrenNum":0,"fileId":18668,"group":"supergroup","length":20,"modificationTime":1434242164753,"owner":"michaeljones","pathSuffix":"hello.txt","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434249237796,"blockSize":134217728,"childrenNum":0,"fileId":18714,"group":"supergroup","length":27615,"modificationTime":1434249237841,"owner":"michaeljones","pathSuffix":"hellohadoop.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434249240018,"blockSize":134217728,"childrenNum":0,"fileId":18719,"group":"supergroup","length":102268,"modificationTime":1434249240060,"owner":"michaeljones","pathSuffix":"hellohadoop.log.2015-06-12","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434249240016,"blockSize":134217728,"childrenNum":0,"fileId":18718,"group":"supergroup","length":123003,"modificationTime":1434249240061,"owner":"michaeljones","pathSuffix":"hellohadoop.log.2015-06-13","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434249288621,"blockSize":134217728,"childrenNum":0,"fileId":18723,"group":"supergroup","length":3644,"modificationTime":1434249288654,"owner":"michaeljones","pathSuffix":"nbactions.xml","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434242172891,"blockSize":134217728,"childrenNum":0,"fileId":18691,"group":"supergroup","length":2134,"modificationTime":1434242172913,"owner":"michaeljones","pathSuffix":"pom.xml","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434242165542,"blockSize":134217728,"childrenNum":0,"fileId":16388,"group":"supergroup","length":50,"modificationTime":1433119638967,"owner":"michaeljones","pathSuffix":"wcInput","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18676,"group":"supergroup","length":0,"modificationTime":1434242169795,"owner":"michaeljones","pathSuffix":"wcOutput","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},
{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18683,"group":"supergroup","length":0,"modificationTime":1434242171819,"owner":"michaeljones","pathSuffix":"wcOutputAnalysis","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},
{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18669,"group":"supergroup","length":0,"modificationTime":1434242168288,"owner":"michaeljones","pathSuffix":"wcOutputMain","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"}
]}}

Jersey client Redirect to: hdfs://localhost:9000/user/michaeljones/hello.log
Jersey redirected to IPC: hdfs://localhost:9000/user/michaeljones/hello.log
com.sun.jersey.client.property.chunkedEncodingSize: 1048576
com.sun.jersey.client.property.chunkedEncodingSize: 1048576
Jersey client Redirect to: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/nbactions.xml?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
com.sun.jersey.client.property.chunkedEncodingSize: 1048576
Jersey client Redirect to: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/nbactions.xml?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
Get redirect location async: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/nbactions.xml?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 0][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://localhost:50070
Connecting to localhost/127.0.0.1:50070
Connection established 127.0.0.1:49976<->127.0.0.1:50070
Executing request GET /webhdfs/v1/user/michaeljones/?user.name=michaeljones&op=LISTSTATUS HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-0 >> GET /webhdfs/v1/user/michaeljones/?user.name=michaeljones&op=LISTSTATUS HTTP/1.1
http-outgoing-0 >> accept: application/json
http-outgoing-0 >> Host: localhost:50070
http-outgoing-0 >> Connection: Keep-Alive
http-outgoing-0 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-0 >> Accept-Encoding: gzip,deflate
http-outgoing-0 >> "GET /webhdfs/v1/user/michaeljones/?user.name=michaeljones&op=LISTSTATUS HTTP/1.1[\r][\n]"
http-outgoing-0 >> "accept: application/json[\r][\n]"
http-outgoing-0 >> "Host: localhost:50070[\r][\n]"
http-outgoing-0 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-0 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-0 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-0 >> "[\r][\n]"
http-outgoing-0 << "HTTP/1.1 200 OK[\r][\n]"
http-outgoing-0 << "Cache-Control: no-cache[\r][\n]"
http-outgoing-0 << "Expires: Sun, 14 Jun 2015 02:57:00 GMT[\r][\n]"
http-outgoing-0 << "Date: Sun, 14 Jun 2015 02:57:00 GMT[\r][\n]"
http-outgoing-0 << "Pragma: no-cache[\r][\n]"
http-outgoing-0 << "Expires: Sun, 14 Jun 2015 02:57:00 GMT[\r][\n]"
http-outgoing-0 << "Date: Sun, 14 Jun 2015 02:57:00 GMT[\r][\n]"
http-outgoing-0 << "Pragma: no-cache[\r][\n]"
http-outgoing-0 << "Content-Type: application/json[\r][\n]"
http-outgoing-0 << "Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434286620101&s=UfVj5/NBeV7mFEn1nxLNZCGST9k="; Path=/; Expires=Sun, 14-Jun-2015 12:57:00 GMT; HttpOnly[\r][\n]"
http-outgoing-0 << "Transfer-Encoding: chunked[\r][\n]"
http-outgoing-0 << "Server: Jetty(6.1.26)[\r][\n]"
http-outgoing-0 << "[\r][\n]"
http-outgoing-0 << "12FC[\r][\n]"
http-outgoing-0 << "{"FileStatuses":{"FileStatus":[[\n]"
http-outgoing-0 << "{"accessTime":1434249238371,"blockSize":134217728,"childrenNum":0,"fileId":18716,"group":"supergroup","length":11335,"modificationTime":1434249238403,"owner":"michaeljones","pathSuffix":"README.md","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434242172845,"blockSize":134217728,"childrenNum":0,"fileId":18690,"group":"supergroup","length":0,"modificationTime":1434242172851,"owner":"michaeljones","pathSuffix":"apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434250345392,"blockSize":134217728,"childrenNum":0,"fileId":18724,"group":"supergroup","length":0,"modificationTime":1434250345400,"owner":"michaeljones","pathSuffix":"empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434249237237,"blockSize":134217728,"childrenNum":0,"fileId":18713,"group":"supergroup","length":0,"modificationTime":1434249237244,"owner":"michaeljones","pathSuffix":"hello-apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434091626279,"blockSize":134217728,"childrenNum":0,"fileId":18298,"group":"supergroup","length":0,"modificationTime":1434091626286,"owner":"michaeljones","pathSuffix":"hello-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434249237130,"blockSize":134217728,"childrenNum":0,"fileId":18712,"group":"supergroup","length":0,"modificationTime":1434249237142,"owner":"michaeljones","pathSuffix":"hello-jersey-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434250345962,"blockSize":134217728,"childrenNum":0,"fileId":18726,"group":"supergroup","length":753882,"modificationTime":1434250346002,"owner":"michaeljones","pathSuffix":"hello.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434249237945,"blockSize":134217728,"childrenNum":0,"fileId":18715,"group":"supergroup","length":3678856,"modificationTime":1434249238225,"owner":"michaeljones","pathSuffix":"hello.log.2015-06-12","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434242164264,"blockSize":134217728,"childrenNum":0,"fileId":18668,"group":"supergroup","length":20,"modificationTime":1434242164753,"owner":"michaeljones","pathSuffix":"hello.txt","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434249237796,"blockSize":134217728,"childrenNum":0,"fileId":18714,"group":"supergroup","length":27615,"modificationTime":1434249237841,"owner":"michaeljones","pathSuffix":"hellohadoop.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434249240018,"blockSize":134217728,"childrenNum":0,"fileId":18719,"group":"supergroup","length":102268,"modificationTime":1434249240060,"owner":"michaeljones","pathSuffix":"hellohadoop.log.2015-06-12","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434249240016,"blockSize":134217728,"childrenNum":0,"fileId":18718,"group":"supergroup","length":123003,"modificationTime":1434249240061,"owner":"michaeljones","pathSuffix":"hellohadoop.log.2015-06-13","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434250346567,"blockSize":134217728,"childrenNum":0,"fileId":18727,"group":"supergroup","length":3644,"modificationTime":1434250346594,"owner":"michaeljones","pathSuffix":"nbactions.xml","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434242172891,"blockSize":134217728,"childrenNum":0,"fileId":18691,"group":"supergroup","length":2134,"modificationTime":1434242172913,"owner":"michaeljones","pathSuffix":"pom.xml","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434242165542,"blockSize":134217728,"childrenNum":0,"fileId":16388,"group":"supergroup","length":50,"modificationTime":1433119638967,"owner":"michaeljones","pathSuffix":"wcInput","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18676,"group":"supergroup","length":0,"modificationTime":1434242169795,"owner":"michaeljones","pathSuffix":"wcOutput","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},[\n]"
http-outgoing-0 << "{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18683,"group":"supergroup","length":0,"modificationTime":1434242171819,"owner":"michaeljones","pathSuffix":"wcOutputAnalysis","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},[\n]"
http-outgoing-0 << "{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18669,"group":"supergroup","length":0,"modificationTime":1434242168288,"owner":"michaeljones","pathSuffix":"wcOutputMain","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"}[\n]"
http-outgoing-0 << "]}}[\n]"
http-outgoing-0 << "[\r][\n]"
http-outgoing-0 << "0[\r][\n]"
http-outgoing-0 << "[\r][\n]"
http-outgoing-0 << HTTP/1.1 200 OK
http-outgoing-0 << Cache-Control: no-cache
http-outgoing-0 << Expires: Sun, 14 Jun 2015 02:57:00 GMT
http-outgoing-0 << Date: Sun, 14 Jun 2015 02:57:00 GMT
http-outgoing-0 << Pragma: no-cache
http-outgoing-0 << Expires: Sun, 14 Jun 2015 02:57:00 GMT
http-outgoing-0 << Date: Sun, 14 Jun 2015 02:57:00 GMT
http-outgoing-0 << Pragma: no-cache
http-outgoing-0 << Content-Type: application/json
http-outgoing-0 << Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434286620101&s=UfVj5/NBeV7mFEn1nxLNZCGST9k="; Path=/; Expires=Sun, 14-Jun-2015 12:57:00 GMT; HttpOnly
http-outgoing-0 << Transfer-Encoding: chunked
http-outgoing-0 << Server: Jetty(6.1.26)
Connection can be kept alive indefinitely
Cookie accepted [hadoop.auth=""u=michaeljones&p=michaeljones&t=simple&e=1434286620101&s=UfVj5/NBeV7mFEn1nxLNZCGST9k="", version:0, domain:localhost, path:/, expiry:Sun Jun 14 22:57:00 AEST 2015]
Connection [id: 0][route: {}->http://localhost:50070] can be kept alive indefinitely
Connection released: [id: 0][route: {}->http://localhost:50070][total kept alive: 1; route allocated: 1 of 2; total allocated: 1 of 20]
Connection manager is shutting down
http-outgoing-0: Close connection
http-outgoing-0: Close connection
Connection manager shut down
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 1][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://localhost:50070
Connecting to localhost/127.0.0.1:50070
Connection established 127.0.0.1:49979<->127.0.0.1:50070
Executing request PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-1 >> PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1
http-outgoing-1 >> Content-Length: 0
http-outgoing-1 >> Host: localhost:50070
http-outgoing-1 >> Connection: Keep-Alive
http-outgoing-1 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-1 >> Accept-Encoding: gzip,deflate
http-outgoing-1 >> "PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1[\r][\n]"
http-outgoing-1 >> "Content-Length: 0[\r][\n]"
http-outgoing-1 >> "Host: localhost:50070[\r][\n]"
http-outgoing-1 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-1 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-1 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-1 >> "[\r][\n]"
http-outgoing-1 << "HTTP/1.1 307 TEMPORARY_REDIRECT[\r][\n]"
http-outgoing-1 << "Cache-Control: no-cache[\r][\n]"
http-outgoing-1 << "Expires: Sun, 14 Jun 2015 02:57:00 GMT[\r][\n]"
http-outgoing-1 << "Date: Sun, 14 Jun 2015 02:57:00 GMT[\r][\n]"
http-outgoing-1 << "Pragma: no-cache[\r][\n]"
http-outgoing-1 << "Expires: Sun, 14 Jun 2015 02:57:00 GMT[\r][\n]"
http-outgoing-1 << "Date: Sun, 14 Jun 2015 02:57:00 GMT[\r][\n]"
http-outgoing-1 << "Pragma: no-cache[\r][\n]"
http-outgoing-1 << "Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434286620638&s=lwdoL290B6//CPltd/uDRtP8UMY="; Path=/; Expires=Sun, 14-Jun-2015 12:57:00 GMT; HttpOnly[\r][\n]"
http-outgoing-1 << "Location: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true[\r][\n]"
http-outgoing-1 << "Content-Type: application/octet-stream[\r][\n]"
http-outgoing-1 << "Content-Length: 0[\r][\n]"
http-outgoing-1 << "Server: Jetty(6.1.26)[\r][\n]"
http-outgoing-1 << "[\r][\n]"
http-outgoing-1 << HTTP/1.1 307 TEMPORARY_REDIRECT
http-outgoing-1 << Cache-Control: no-cache
http-outgoing-1 << Expires: Sun, 14 Jun 2015 02:57:00 GMT
http-outgoing-1 << Date: Sun, 14 Jun 2015 02:57:00 GMT
http-outgoing-1 << Pragma: no-cache
http-outgoing-1 << Expires: Sun, 14 Jun 2015 02:57:00 GMT
http-outgoing-1 << Date: Sun, 14 Jun 2015 02:57:00 GMT
http-outgoing-1 << Pragma: no-cache
http-outgoing-1 << Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434286620638&s=lwdoL290B6//CPltd/uDRtP8UMY="; Path=/; Expires=Sun, 14-Jun-2015 12:57:00 GMT; HttpOnly
http-outgoing-1 << Location: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
http-outgoing-1 << Content-Type: application/octet-stream
http-outgoing-1 << Content-Length: 0
http-outgoing-1 << Server: Jetty(6.1.26)
Connection can be kept alive indefinitely
Cookie accepted [hadoop.auth=""u=michaeljones&p=michaeljones&t=simple&e=1434286620638&s=lwdoL290B6//CPltd/uDRtP8UMY="", version:0, domain:localhost, path:/, expiry:Sun Jun 14 22:57:00 AEST 2015]
Redirect to: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
http-outgoing-1: Shutdown connection
Connection discarded
http-outgoing-1: Close connection
Connection released: [id: 1][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 2][route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://michaels-air.bigpond:50075
Connecting to michaels-air.bigpond/10.0.0.2:50075
Connection established 10.0.0.2:49980<->10.0.0.2:50075
Executing request PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-2 >> PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1
http-outgoing-2 >> Content-Length: 0
http-outgoing-2 >> Host: michaels-air.bigpond:50075
http-outgoing-2 >> Connection: Keep-Alive
http-outgoing-2 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-2 >> Accept-Encoding: gzip,deflate
http-outgoing-2 >> "PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1[\r][\n]"
http-outgoing-2 >> "Content-Length: 0[\r][\n]"
http-outgoing-2 >> "Host: michaels-air.bigpond:50075[\r][\n]"
http-outgoing-2 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-2 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-2 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-2 >> "[\r][\n]"
http-outgoing-2 << "HTTP/1.1 100 Continue[\r][\n]"
http-outgoing-2 << "[\r][\n]"
http-outgoing-2 << HTTP/1.1 100 Continue
http-outgoing-2 << "HTTP/1.1 201 Created[\r][\n]"
http-outgoing-2 << "Location: hdfs://localhost:9000/user/michaeljones/hello-apache-empty.txt[\r][\n]"
http-outgoing-2 << "Content-Length: 0[\r][\n]"
http-outgoing-2 << "Connection: close[\r][\n]"
http-outgoing-2 << "[\r][\n]"
http-outgoing-2 << HTTP/1.1 201 Created
http-outgoing-2 << Location: hdfs://localhost:9000/user/michaeljones/hello-apache-empty.txt
http-outgoing-2 << Content-Length: 0
http-outgoing-2 << Connection: close
http-outgoing-2: Shutdown connection
Connection discarded
http-outgoing-2: Close connection
Connection released: [id: 2][route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection manager is shutting down
Connection manager shut down
Jersey client Redirect to: hdfs://localhost:9000/user/michaeljones/hellohadoop.log
com.sun.jersey.client.property.chunkedEncodingSize: 1048576
Jersey client Redirect to: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/hello.log.2015-06-12?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 3][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://localhost:50070
Connecting to localhost/127.0.0.1:50070
Connection established 127.0.0.1:49990<->127.0.0.1:50070
Executing request PUT /webhdfs/v1/user/michaeljones/README.md?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-3 >> PUT /webhdfs/v1/user/michaeljones/README.md?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1
http-outgoing-3 >> Transfer-Encoding: chunked
http-outgoing-3 >> Content-Type: application/octet-stream
http-outgoing-3 >> Host: localhost:50070
http-outgoing-3 >> Connection: Keep-Alive
http-outgoing-3 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-3 >> Accept-Encoding: gzip,deflate
http-outgoing-3 >> "PUT /webhdfs/v1/user/michaeljones/README.md?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1[\r][\n]"
http-outgoing-3 >> "Transfer-Encoding: chunked[\r][\n]"
http-outgoing-3 >> "Content-Type: application/octet-stream[\r][\n]"
http-outgoing-3 >> "Host: localhost:50070[\r][\n]"
http-outgoing-3 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-3 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-3 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-3 >> "[\r][\n]"
http-outgoing-3 >> "1000[\r][\n]"
http-outgoing-3 >> "# Hello-Hadoop-netbeans-OS-X[\n]"
http-outgoing-3 >> "Java Maven project for playing with the HDFS API without any 3rd party hadoop plugins.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## Aim of project[\n]"
http-outgoing-3 >> "Hello world/tutorial level for programmatically operating with a pseudo distributed hadoop configuration on OS X. Hadoop 2.7 on Yosemite.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## What this project demonstrates[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "This is work in progress and so far the following functionality is demonstrated:[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "1. Direct programmatic control of the HDFS and running map reduce jobs - all unit tests run from the IDE with hadoop configuration built into this project and under git control.[\n]"
http-outgoing-3 >> "2. Uploading of files to the HDFS by implementing a Web REST API client.[\n]"
http-outgoing-3 >> "3. Async file upload (at time of writing only Jersey back end implemented).[\n]"
http-outgoing-3 >> "4. Layered application code for maximum re-use and ease of test driven development. The client I wrote uses an interface which has allowed me to provide both a Jersey HTTP client implementation and an Apache HTTP client implementation for comparison between the two toolkits.[\n]"
http-outgoing-3 >> "5. Test driven development.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## Getting started[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "The initial difficulty was working out how to run the program in the IDE and talk to the local pseudo distributed setup without using a 3rd party Hadoop plugin. Apparently there used to be a plugin for netbeans, but it has been discontinued. I am a newbie with this technology.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "The Apache Hadoop instructions for building and running java programs are via their command line build/run utility only. Getting the yahoo hadoop HDFS tutorial program to build in the IDE wasn't too hard. However, by default it will ignore the local Hadoop configuration and only operate with the local file system in local debug mode.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## Wading through the configuration[\n]"
http-outgoing-3 >> "Hadoop is designed to work with a number of different topologies, directory locations, levels of replication, simulated environments etc. so as we would expect nothing works unless the configuration is right.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "First Hadoop needs to be installed and configured in pseudo distributed mode such that it builds and runs test programs on the command line. The hadoop documentation has instructions for doing this. Documentation is online and also included in the installation: share/doc/hadoop/index.html. However this is not enough to get it to work in the IDE.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## The netbeans project settings that are needed to run with the HDFS from the IDE:[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "1. Get log4j configured to work in the IDE. Absence of log4j configuration won't stop hadoop from running, but we won't get to see useful error messages from hadoop without it.[\n]"
http-outgoing-3 >> "2. HADOOP_HOME environment variable project run (and test) property.[\n]"
http-outgoing-3 >> "3. Duplicate hadoop configuration in the classpath. The above environment variable does not pick up the hadoop configuration from its usual place. Yahoo's only suggestion is to run from the command line via the hadoop script. The Apache HDFS API documention says that configuration is looked for in the classpath, so I took the approach of duplicating the configuration (just 2 files) instead of figuring out how to get it to look in the installation path.[\n]"
http-outgoing-3 >> "4. The correct Maven dependencies. If not all the jar depenencies are there the program may build and run, but it won't talk to the HDFS if it doesn't load the HDFS jars.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "I think that the setup of this project would probably work on Linux too.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## Working through trouble shooting the HDFS project settings[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "Issue 1 above shows up as:[\n]"
http-outgoing-3 >> "<pre><code>[\n]"
http-outgoing-3 >> "log4j:WARN No appenders could be found for logger (org.apache.hadoop.util.Shell).[\n]"
http-outgoing-3 >> "log4j:WARN Please initialize the log4j system properly.[\n]"
http-outgoing-3 >> "log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.[\n]"
http-outgoing-3 >> "</pre></code>[\n]"
http-outgoing-3 >> "This is solved by putting a log4j.properties configuration file in the classpath. For a Maven build getting files into the classpath can be achieved by putting them in src/main/resources. I don't think this is in the classpath, but the build will then copy the file into ./target/classes/ which is in the classpath.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "Issue 2 above shows up as:[\n]"
http-outgoing-3 >> "<pre><code>[\n]"
http-outgoing-3 >> "Failed to detect a valid hadoop home directory[\n]"
http-outgoing-3 >> "java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.[\n]"
http-outgoing-3 >> "</[\r][\n]"
http-outgoing-3 >> "1000[\r][\n]"
http-outgoing-3 >> "code></pre>[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "This is fixed by going into the project properties => Build => Actions => Run Project and adding the environment variable for HADOOP_HOME. This will result in an entry in the Maven POM. Repeat for "Test Project", "Debug Project" etc.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "Issue 3. shows up as running, but creating a file on the local file system instead of the HDFS. This was fixed       looking at the HDFS API documentation for org.apache.hadoop.conf.Configuration. This documentation is under the chapter: C API libhdfs HDFS which has a link to the HDFS API under "The APIs" (I strangely cannot find this in the main index). On my installation the HDFS API documentation link is file:///opt/local/hadoop-2.7.0/share/doc/hadoop/api/org/apache/hadoop/fs/FileSystem.html.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "This documentation told me that hadoop loads core-site.xml and core-default.xml in the classpath. Classpath for a Maven build can be reached by placing these files in the directory src/main/resources (see logging configuration above). I added hdfs-site instead of core-default (which doesn't exist on my 2.7 install) into the src/main/resources project directory.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "Issue 3 shows up as:[\n]"
http-outgoing-3 >> "<pre><code>[\n]"
http-outgoing-3 >> "java.io.IOException: "hadoop No FileSystem for scheme: hdfs".[\n]"
http-outgoing-3 >> "</code></pre>[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "This is part of the build dependency problem. The various threads on stackoverflow etc. suggested that a minimum dependency was the jar for hadoop-core. However, there is no such jar on 2.7. I ran the hadoop command to dump version and got this:[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "<pre><code>[\n]"
http-outgoing-3 >> "bin/hadoop version[\n]"
http-outgoing-3 >> "Hadoop 2.7.0[\n]"
http-outgoing-3 >> "Subversion https://git-wip-us.apache.org/repos/asf/hadoop.git -r d4c8d4d4d203c934e8074b31289a28724c0842cf[\n]"
http-outgoing-3 >> "Compiled by jenkins on 2015-04-10T18:40Z[\n]"
http-outgoing-3 >> "Compiled with protoc 2.5.0[\n]"
http-outgoing-3 >> "From source with checksum a9e90912c37a35c3195d23951fd18f[\n]"
http-outgoing-3 >> "This command was run using /opt/local/hadoop-2.7.0/share/hadoop/common/hadoop-common-2.7.0.jar[\n]"
http-outgoing-3 >> "</code></pre>[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "I noted the jar name at the end and added it as a dependency to the POM. This can either be hand coded in or right click pom.xml => Insert Code => Add Dependency => Search => query hadoop-common and select version which was 2.7.0 [jar] - central. Maven will then add dependencies to other hadoop jars in the "Dependencies" group in the project explorer. Netbeans will then download these dependencies before the next build. They go into ~/.m2/repository should they ever need to be cleaned out (Netbeans doesn't seem to have an IDE remove dependency option).[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "After doing the above project built, but showed up the "no filesystem error". I noticed that Maven had not pulled in any hdfs jars matching the jars in my share/hadoop/hdfs installation directory. So I took a guess that it needed only the top level hadoop-hdfs-2.7.0.jar and added this as a dependency to the POM and all was good :)[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## Working through trouble shooting the Map Reduce project settings[\n]"
http-outgoing-3 >> "After getting the HDFS API working in the IDE it was time to move on to getting the famous Word Count map-reduce tutorial running.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "So coded it, set the main program to the word count main as the one to run. From the IDE: project Properties => Run => Main Class. Provide input and output arguments for the word count program. I noted that the netbeans properties pop-up window does not persist these settings next time it pops up. However this setting is persistant and ends up in nbactions.xml.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "However, running the word count map reduce program resulted in an ioException:[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "<pre><code>[\n]"
http-outgoing-3 >> "Please check your configuration for mapreduce.framework.name and the correspond server addresses.[\n]"
http-outgoing-3 >> "</pre></code>[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "Because the resources directory only contains 2 configuration files from my hadoop installation I thought maybe I was missing a map reduce one. So the first thing I did was go into the configuration directory of my installation and grep all files to see if there was a configuration file with mapreduce framework property. There was not. I checked my programatic configuration dump from my test program. This property was not mentioned either. The only map reduce configuration was to do with some environment variables for heap size in one of the shell scripts. Note to sel[\r][\n]"
http-outgoing-3 >> "c47[\r][\n]"
http-outgoing-3 >> "f: this may be relevant and I can consider setting this in the IDE. However, that didn't look like the problem.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "I then checked my dependencies and noted there were no map reduce jars pulled in by Maven. So I added hadoop-mapreduce-client-core. Still not running. Checked the web and a thread on stackoverflow mentioned a number of other jars: hadoop-mapreduce-client-common and hadoop-mapreduce-client shuffle. I added just the hadoop-mapreduce-client-common and it runs :) I have a feeling that I might need some of the other jars for other API calls and that there must be a better way of working out dependencies than this trial and error. As mentioned I am a newbie with this, so if anyone has any comments feel free to email me.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## Logging from application code[\n]"
http-outgoing-3 >> "Although the hadoop libraries log correctly with a properly located log4.properties file, application code calling the log4j logger seems to ignore this file. Using the log4j logger as per instructions in the log4j manual and many online tutorials did not result in getting any logging redirected to file configured in the properties file. Instead console output only is obtained. A clue to this mystery was that a most basic of hello world netbeans maven projects which did not import any hadoop stuff also failed to log to a file and did not even give the "No appenders" warning. Then I noticed that there were org.sl4j depencies in the hadoop build, so using sl4j instead solved the problem. Once my hello world project used sl4j's LoggerFactory and had sl4j-api and sl4j-12 as a dependencies it started to use the properties file. See http://www.slf4j.org/manual.html[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## Upload a file from local storage to the HDFS via the REST API[\n]"
http-outgoing-3 >> "The WebHDFS REST API documentation which came with the installation specifies that file creation is a two stage operation where an initial PUT to the namenode is sent. This responds with a redirect to the datanode and another PUT should be made to this redirection which can contain the chunked data stream. This does not sound REST to me as it relies on holding redirection state (a fully distributed configuration could presumably return a redirection to any one of the datanodes). Hadoop say this is because of a bug in some HTTP client implementations - incorrect implementation of [0xe2][0x80][0x9c]Expect: 100-continue[0xe2][0x80][0x9d].[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "However, the 2 stage PUT not being REST seems to be a moot point, at least with the Jersey client. I do not get a redirection and a file creates/uploads all in one go.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "Since writing the above paragraph I have implemented the Apache Client back end option to my HDFS Web client interface and this client behaves differently. It does indeed cause a redirect as per Hadoop documentation. The follow up PUT to the redirected location with the chunked file stream works as per documentation.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "Since writing the above paragraph I have implemented a big chunk size setting for the HTTP chunking and this changed the behaviour of the Jersey client to always redirect. It might be that unless the chunk size option is set then the Jersey implementation does not chunk - this would be terrible for big files.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "To be continued ...[\n]"
http-outgoing-3 >> "[\r][\n]"
http-outgoing-3 >> "0[\r][\n]"
http-outgoing-3 >> "[\r][\n]"
http-outgoing-3 << "HTTP/1.1 307 TEMPORARY_REDIRECT[\r][\n]"
http-outgoing-3 << "Cache-Control: no-cache[\r][\n]"
http-outgoing-3 << "Expires: Sun, 14 Jun 2015 02:57:01 GMT[\r][\n]"
http-outgoing-3 << "Date: Sun, 14 Jun 2015 02:57:01 GMT[\r][\n]"
http-outgoing-3 << "Pragma: no-cache[\r][\n]"
http-outgoing-3 << "Expires: Sun, 14 Jun 2015 02:57:01 GMT[\r][\n]"
http-outgoing-3 << "Date: Sun, 14 Jun 2015 02:57:01 GMT[\r][\n]"
http-outgoing-3 << "Pragma: no-cache[\r][\n]"
http-outgoing-3 << "Content-Type: application/octet-stream[\r][\n]"
http-outgoing-3 << "Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434286621247&s=cOBR1AlIHZF//KEkyT9oeYTjZws="; Path=/; Expires=Sun, 14-Jun-2015 12:57:01 GMT; HttpOnly[\r][\n]"
http-outgoing-3 << "Location: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/README.md?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true[\r][\n]"
http-outgoing-3 << "Content-Length: 0[\r][\n]"
http-outgoing-3 << "Server: Jetty(6.1.26)[\r][\n]"
http-outgoing-3 << "[\r][\n]"
http-outgoing-3 << HTTP/1.1 307 TEMPORARY_REDIRECT
http-outgoing-3 << Cache-Control: no-cache
http-outgoing-3 << Expires: Sun, 14 Jun 2015 02:57:01 GMT
http-outgoing-3 << Date: Sun, 14 Jun 2015 02:57:01 GMT
http-outgoing-3 << Pragma: no-cache
http-outgoing-3 << Expires: Sun, 14 Jun 2015 02:57:01 GMT
http-outgoing-3 << Date: Sun, 14 Jun 2015 02:57:01 GMT
http-outgoing-3 << Pragma: no-cache
http-outgoing-3 << Content-Type: application/octet-stream
http-outgoing-3 << Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434286621247&s=cOBR1AlIHZF//KEkyT9oeYTjZws="; Path=/; Expires=Sun, 14-Jun-2015 12:57:01 GMT; HttpOnly
http-outgoing-3 << Location: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/README.md?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
http-outgoing-3 << Content-Length: 0
http-outgoing-3 << Server: Jetty(6.1.26)
Connection can be kept alive indefinitely
Cookie accepted [hadoop.auth=""u=michaeljones&p=michaeljones&t=simple&e=1434286621247&s=cOBR1AlIHZF//KEkyT9oeYTjZws="", version:0, domain:localhost, path:/, expiry:Sun Jun 14 22:57:01 AEST 2015]
Redirect to: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/README.md?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
http-outgoing-3: Shutdown connection
Connection discarded
http-outgoing-3: Close connection
Connection released: [id: 3][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 4][route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://michaels-air.bigpond:50075
Connecting to michaels-air.bigpond/10.0.0.2:50075
Connection established 10.0.0.2:49991<->10.0.0.2:50075
Executing request PUT /webhdfs/v1/user/michaeljones/README.md?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-4 >> PUT /webhdfs/v1/user/michaeljones/README.md?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1
http-outgoing-4 >> Transfer-Encoding: chunked
http-outgoing-4 >> Content-Type: application/octet-stream
http-outgoing-4 >> Host: michaels-air.bigpond:50075
http-outgoing-4 >> Connection: Keep-Alive
http-outgoing-4 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-4 >> Accept-Encoding: gzip,deflate
http-outgoing-4 >> "PUT /webhdfs/v1/user/michaeljones/README.md?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1[\r][\n]"
http-outgoing-4 >> "Transfer-Encoding: chunked[\r][\n]"
http-outgoing-4 >> "Content-Type: application/octet-stream[\r][\n]"
http-outgoing-4 >> "Host: michaels-air.bigpond:50075[\r][\n]"
http-outgoing-4 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-4 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-4 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-4 >> "[\r][\n]"
http-outgoing-4 >> "1000[\r][\n]"
http-outgoing-4 >> "# Hello-Hadoop-netbeans-OS-X[\n]"
http-outgoing-4 >> "Java Maven project for playing with the HDFS API without any 3rd party hadoop plugins.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## Aim of project[\n]"
http-outgoing-4 >> "Hello world/tutorial level for programmatically operating with a pseudo distributed hadoop configuration on OS X. Hadoop 2.7 on Yosemite.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## What this project demonstrates[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "This is work in progress and so far the following functionality is demonstrated:[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "1. Direct programmatic control of the HDFS and running map reduce jobs - all unit tests run from the IDE with hadoop configuration built into this project and under git control.[\n]"
http-outgoing-4 >> "2. Uploading of files to the HDFS by implementing a Web REST API client.[\n]"
http-outgoing-4 >> "3. Async file upload (at time of writing only Jersey back end implemented).[\n]"
http-outgoing-4 >> "4. Layered application code for maximum re-use and ease of test driven development. The client I wrote uses an interface which has allowed me to provide both a Jersey HTTP client implementation and an Apache HTTP client implementation for comparison between the two toolkits.[\n]"
http-outgoing-4 >> "5. Test driven development.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## Getting started[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "The initial difficulty was working out how to run the program in the IDE and talk to the local pseudo distributed setup without using a 3rd party Hadoop plugin. Apparently there used to be a plugin for netbeans, but it has been discontinued. I am a newbie with this technology.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "The Apache Hadoop instructions for building and running java programs are via their command line build/run utility only. Getting the yahoo hadoop HDFS tutorial program to build in the IDE wasn't too hard. However, by default it will ignore the local Hadoop configuration and only operate with the local file system in local debug mode.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## Wading through the configuration[\n]"
http-outgoing-4 >> "Hadoop is designed to work with a number of different topologies, directory locations, levels of replication, simulated environments etc. so as we would expect nothing works unless the configuration is right.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "First Hadoop needs to be installed and configured in pseudo distributed mode such that it builds and runs test programs on the command line. The hadoop documentation has instructions for doing this. Documentation is online and also included in the installation: share/doc/hadoop/index.html. However this is not enough to get it to work in the IDE.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## The netbeans project settings that are needed to run with the HDFS from the IDE:[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "1. Get log4j configured to work in the IDE. Absence of log4j configuration won't stop hadoop from running, but we won't get to see useful error messages from hadoop without it.[\n]"
http-outgoing-4 >> "2. HADOOP_HOME environment variable project run (and test) property.[\n]"
http-outgoing-4 >> "3. Duplicate hadoop configuration in the classpath. The above environment variable does not pick up the hadoop configuration from its usual place. Yahoo's only suggestion is to run from the command line via the hadoop script. The Apache HDFS API documention says that configuration is looked for in the classpath, so I took the approach of duplicating the configuration (just 2 files) instead of figuring out how to get it to look in the installation path.[\n]"
http-outgoing-4 >> "4. The correct Maven dependencies. If not all the jar depenencies are there the program may build and run, but it won't talk to the HDFS if it doesn't load the HDFS jars.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "I think that the setup of this project would probably work on Linux too.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## Working through trouble shooting the HDFS project settings[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "Issue 1 above shows up as:[\n]"
http-outgoing-4 >> "<pre><code>[\n]"
http-outgoing-4 >> "log4j:WARN No appenders could be found for logger (org.apache.hadoop.util.Shell).[\n]"
http-outgoing-4 >> "log4j:WARN Please initialize the log4j system properly.[\n]"
http-outgoing-4 >> "log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.[\n]"
http-outgoing-4 >> "</pre></code>[\n]"
http-outgoing-4 >> "This is solved by putting a log4j.properties configuration file in the classpath. For a Maven build getting files into the classpath can be achieved by putting them in src/main/resources. I don't think this is in the classpath, but the build will then copy the file into ./target/classes/ which is in the classpath.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "Issue 2 above shows up as:[\n]"
http-outgoing-4 >> "<pre><code>[\n]"
http-outgoing-4 >> "Failed to detect a valid hadoop home directory[\n]"
http-outgoing-4 >> "java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.[\n]"
http-outgoing-4 >> "</[\r][\n]"
http-outgoing-4 >> "1000[\r][\n]"
http-outgoing-4 >> "code></pre>[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "This is fixed by going into the project properties => Build => Actions => Run Project and adding the environment variable for HADOOP_HOME. This will result in an entry in the Maven POM. Repeat for "Test Project", "Debug Project" etc.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "Issue 3. shows up as running, but creating a file on the local file system instead of the HDFS. This was fixed       looking at the HDFS API documentation for org.apache.hadoop.conf.Configuration. This documentation is under the chapter: C API libhdfs HDFS which has a link to the HDFS API under "The APIs" (I strangely cannot find this in the main index). On my installation the HDFS API documentation link is file:///opt/local/hadoop-2.7.0/share/doc/hadoop/api/org/apache/hadoop/fs/FileSystem.html.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "This documentation told me that hadoop loads core-site.xml and core-default.xml in the classpath. Classpath for a Maven build can be reached by placing these files in the directory src/main/resources (see logging configuration above). I added hdfs-site instead of core-default (which doesn't exist on my 2.7 install) into the src/main/resources project directory.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "Issue 3 shows up as:[\n]"
http-outgoing-4 >> "<pre><code>[\n]"
http-outgoing-4 >> "java.io.IOException: "hadoop No FileSystem for scheme: hdfs".[\n]"
http-outgoing-4 >> "</code></pre>[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "This is part of the build dependency problem. The various threads on stackoverflow etc. suggested that a minimum dependency was the jar for hadoop-core. However, there is no such jar on 2.7. I ran the hadoop command to dump version and got this:[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "<pre><code>[\n]"
http-outgoing-4 >> "bin/hadoop version[\n]"
http-outgoing-4 >> "Hadoop 2.7.0[\n]"
http-outgoing-4 >> "Subversion https://git-wip-us.apache.org/repos/asf/hadoop.git -r d4c8d4d4d203c934e8074b31289a28724c0842cf[\n]"
http-outgoing-4 >> "Compiled by jenkins on 2015-04-10T18:40Z[\n]"
http-outgoing-4 >> "Compiled with protoc 2.5.0[\n]"
http-outgoing-4 >> "From source with checksum a9e90912c37a35c3195d23951fd18f[\n]"
http-outgoing-4 >> "This command was run using /opt/local/hadoop-2.7.0/share/hadoop/common/hadoop-common-2.7.0.jar[\n]"
http-outgoing-4 >> "</code></pre>[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "I noted the jar name at the end and added it as a dependency to the POM. This can either be hand coded in or right click pom.xml => Insert Code => Add Dependency => Search => query hadoop-common and select version which was 2.7.0 [jar] - central. Maven will then add dependencies to other hadoop jars in the "Dependencies" group in the project explorer. Netbeans will then download these dependencies before the next build. They go into ~/.m2/repository should they ever need to be cleaned out (Netbeans doesn't seem to have an IDE remove dependency option).[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "After doing the above project built, but showed up the "no filesystem error". I noticed that Maven had not pulled in any hdfs jars matching the jars in my share/hadoop/hdfs installation directory. So I took a guess that it needed only the top level hadoop-hdfs-2.7.0.jar and added this as a dependency to the POM and all was good :)[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## Working through trouble shooting the Map Reduce project settings[\n]"
http-outgoing-4 >> "After getting the HDFS API working in the IDE it was time to move on to getting the famous Word Count map-reduce tutorial running.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "So coded it, set the main program to the word count main as the one to run. From the IDE: project Properties => Run => Main Class. Provide input and output arguments for the word count program. I noted that the netbeans properties pop-up window does not persist these settings next time it pops up. However this setting is persistant and ends up in nbactions.xml.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "However, running the word count map reduce program resulted in an ioException:[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "<pre><code>[\n]"
http-outgoing-4 >> "Please check your configuration for mapreduce.framework.name and the correspond server addresses.[\n]"
http-outgoing-4 >> "</pre></code>[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "Because the resources directory only contains 2 configuration files from my hadoop installation I thought maybe I was missing a map reduce one. So the first thing I did was go into the configuration directory of my installation and grep all files to see if there was a configuration file with mapreduce framework property. There was not. I checked my programatic configuration dump from my test program. This property was not mentioned either. The only map reduce configuration was to do with some environment variables for heap size in one of the shell scripts. Note to sel[\r][\n]"
http-outgoing-4 >> "c47[\r][\n]"
http-outgoing-4 >> "f: this may be relevant and I can consider setting this in the IDE. However, that didn't look like the problem.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "I then checked my dependencies and noted there were no map reduce jars pulled in by Maven. So I added hadoop-mapreduce-client-core. Still not running. Checked the web and a thread on stackoverflow mentioned a number of other jars: hadoop-mapreduce-client-common and hadoop-mapreduce-client shuffle. I added just the hadoop-mapreduce-client-common and it runs :) I have a feeling that I might need some of the other jars for other API calls and that there must be a better way of working out dependencies than this trial and error. As mentioned I am a newbie with this, so if anyone has any comments feel free to email me.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## Logging from application code[\n]"
http-outgoing-4 >> "Although the hadoop libraries log correctly with a properly located log4.properties file, application code calling the log4j logger seems to ignore this file. Using the log4j logger as per instructions in the log4j manual and many online tutorials did not result in getting any logging redirected to file configured in the properties file. Instead console output only is obtained. A clue to this mystery was that a most basic of hello world netbeans maven projects which did not import any hadoop stuff also failed to log to a file and did not even give the "No appenders" warning. Then I noticed that there were org.sl4j depencies in the hadoop build, so using sl4j instead solved the problem. Once my hello world project used sl4j's LoggerFactory and had sl4j-api and sl4j-12 as a dependencies it started to use the properties file. See http://www.slf4j.org/manual.html[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## Upload a file from local storage to the HDFS via the REST API[\n]"
http-outgoing-4 >> "The WebHDFS REST API documentation which came with the installation specifies that file creation is a two stage operation where an initial PUT to the namenode is sent. This responds with a redirect to the datanode and another PUT should be made to this redirection which can contain the chunked data stream. This does not sound REST to me as it relies on holding redirection state (a fully distributed configuration could presumably return a redirection to any one of the datanodes). Hadoop say this is because of a bug in some HTTP client implementations - incorrect implementation of [0xe2][0x80][0x9c]Expect: 100-continue[0xe2][0x80][0x9d].[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "However, the 2 stage PUT not being REST seems to be a moot point, at least with the Jersey client. I do not get a redirection and a file creates/uploads all in one go.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "Since writing the above paragraph I have implemented the Apache Client back end option to my HDFS Web client interface and this client behaves differently. It does indeed cause a redirect as per Hadoop documentation. The follow up PUT to the redirected location with the chunked file stream works as per documentation.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "Since writing the above paragraph I have implemented a big chunk size setting for the HTTP chunking and this changed the behaviour of the Jersey client to always redirect. It might be that unless the chunk size option is set then the Jersey implementation does not chunk - this would be terrible for big files.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "To be continued ...[\n]"
http-outgoing-4 >> "[\r][\n]"
http-outgoing-4 >> "0[\r][\n]"
http-outgoing-4 >> "[\r][\n]"
http-outgoing-4 << "HTTP/1.1 100 Continue[\r][\n]"
http-outgoing-4 << "[\r][\n]"
http-outgoing-4 << HTTP/1.1 100 Continue
http-outgoing-4 << "HTTP/1.1 201 Created[\r][\n]"
http-outgoing-4 << "Location: hdfs://localhost:9000/user/michaeljones/README.md[\r][\n]"
http-outgoing-4 << "Content-Length: 0[\r][\n]"
http-outgoing-4 << "Connection: close[\r][\n]"
http-outgoing-4 << "[\r][\n]"
http-outgoing-4 << HTTP/1.1 201 Created
http-outgoing-4 << Location: hdfs://localhost:9000/user/michaeljones/README.md
http-outgoing-4 << Content-Length: 0
http-outgoing-4 << Connection: close
http-outgoing-4: Shutdown connection
Connection discarded
http-outgoing-4: Close connection
Connection released: [id: 4][route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection manager is shutting down
Connection manager shut down
com.sun.jersey.client.property.chunkedEncodingSize: 1048576
Jersey client Redirect to: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/nbactions.xml?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
com.sun.jersey.client.property.chunkedEncodingSize: 1048576
Jersey client Redirect to: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/nbactions.xml?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
testUploadFileAsync: redirect: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/nbactions.xml?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
Connection manager is shutting down
Connection manager shut down
com.sun.jersey.client.property.chunkedEncodingSize: 1048576
Jersey client Redirect to: hdfs://localhost:9000/user/michaeljones/hellohadoop.log.2015-06-12
Jersey client Redirect to: hdfs://localhost:9000/user/michaeljones/hellohadoop.log.2015-06-13
Jersey Future: com.sun.jersey.api.client.ClientHandlerException: java.net.MalformedURLException: unknown protocol: hdfs
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 0][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://localhost:50070
Connecting to localhost/127.0.0.1:50070
Connection established 127.0.0.1:50050<->127.0.0.1:50070
Executing request GET /webhdfs/v1/user/michaeljones/?user.name=michaeljones&op=LISTSTATUS HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-0 >> GET /webhdfs/v1/user/michaeljones/?user.name=michaeljones&op=LISTSTATUS HTTP/1.1
http-outgoing-0 >> accept: application/json
http-outgoing-0 >> Host: localhost:50070
http-outgoing-0 >> Connection: Keep-Alive
http-outgoing-0 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-0 >> Accept-Encoding: gzip,deflate
http-outgoing-0 >> "GET /webhdfs/v1/user/michaeljones/?user.name=michaeljones&op=LISTSTATUS HTTP/1.1[\r][\n]"
http-outgoing-0 >> "accept: application/json[\r][\n]"
http-outgoing-0 >> "Host: localhost:50070[\r][\n]"
http-outgoing-0 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-0 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-0 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-0 >> "[\r][\n]"
http-outgoing-0 << "HTTP/1.1 200 OK[\r][\n]"
http-outgoing-0 << "Cache-Control: no-cache[\r][\n]"
http-outgoing-0 << "Expires: Sun, 14 Jun 2015 03:04:22 GMT[\r][\n]"
http-outgoing-0 << "Date: Sun, 14 Jun 2015 03:04:22 GMT[\r][\n]"
http-outgoing-0 << "Pragma: no-cache[\r][\n]"
http-outgoing-0 << "Expires: Sun, 14 Jun 2015 03:04:22 GMT[\r][\n]"
http-outgoing-0 << "Date: Sun, 14 Jun 2015 03:04:22 GMT[\r][\n]"
http-outgoing-0 << "Pragma: no-cache[\r][\n]"
http-outgoing-0 << "Content-Type: application/json[\r][\n]"
http-outgoing-0 << "Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434287062804&s=AEOEhsrel7h0+qmfdQYP+1QktS8="; Path=/; Expires=Sun, 14-Jun-2015 13:04:22 GMT; HttpOnly[\r][\n]"
http-outgoing-0 << "Transfer-Encoding: chunked[\r][\n]"
http-outgoing-0 << "Server: Jetty(6.1.26)[\r][\n]"
http-outgoing-0 << "[\r][\n]"
http-outgoing-0 << "12FC[\r][\n]"
http-outgoing-0 << "{"FileStatuses":{"FileStatus":[[\n]"
http-outgoing-0 << "{"accessTime":1434250621327,"blockSize":134217728,"childrenNum":0,"fileId":18732,"group":"supergroup","length":11335,"modificationTime":1434250621362,"owner":"michaeljones","pathSuffix":"README.md","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434242172845,"blockSize":134217728,"childrenNum":0,"fileId":18690,"group":"supergroup","length":0,"modificationTime":1434242172851,"owner":"michaeljones","pathSuffix":"apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434250345392,"blockSize":134217728,"childrenNum":0,"fileId":18724,"group":"supergroup","length":0,"modificationTime":1434250345400,"owner":"michaeljones","pathSuffix":"empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434250620698,"blockSize":134217728,"childrenNum":0,"fileId":18729,"group":"supergroup","length":0,"modificationTime":1434250620704,"owner":"michaeljones","pathSuffix":"hello-apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434091626279,"blockSize":134217728,"childrenNum":0,"fileId":18298,"group":"supergroup","length":0,"modificationTime":1434091626286,"owner":"michaeljones","pathSuffix":"hello-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434250620587,"blockSize":134217728,"childrenNum":0,"fileId":18728,"group":"supergroup","length":0,"modificationTime":1434250620597,"owner":"michaeljones","pathSuffix":"hello-jersey-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434250345962,"blockSize":134217728,"childrenNum":0,"fileId":18726,"group":"supergroup","length":753882,"modificationTime":1434250346002,"owner":"michaeljones","pathSuffix":"hello.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434250621085,"blockSize":134217728,"childrenNum":0,"fileId":18731,"group":"supergroup","length":3678856,"modificationTime":1434250621191,"owner":"michaeljones","pathSuffix":"hello.log.2015-06-12","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434242164264,"blockSize":134217728,"childrenNum":0,"fileId":18668,"group":"supergroup","length":20,"modificationTime":1434242164753,"owner":"michaeljones","pathSuffix":"hello.txt","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434250620973,"blockSize":134217728,"childrenNum":0,"fileId":18730,"group":"supergroup","length":37935,"modificationTime":1434250621006,"owner":"michaeljones","pathSuffix":"hellohadoop.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434250622327,"blockSize":134217728,"childrenNum":0,"fileId":18734,"group":"supergroup","length":102268,"modificationTime":1434250622366,"owner":"michaeljones","pathSuffix":"hellohadoop.log.2015-06-12","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434250622328,"blockSize":134217728,"childrenNum":0,"fileId":18735,"group":"supergroup","length":123003,"modificationTime":1434250622369,"owner":"michaeljones","pathSuffix":"hellohadoop.log.2015-06-13","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434250621856,"blockSize":134217728,"childrenNum":0,"fileId":18733,"group":"supergroup","length":3644,"modificationTime":1434250621883,"owner":"michaeljones","pathSuffix":"nbactions.xml","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434242172891,"blockSize":134217728,"childrenNum":0,"fileId":18691,"group":"supergroup","length":2134,"modificationTime":1434242172913,"owner":"michaeljones","pathSuffix":"pom.xml","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434242165542,"blockSize":134217728,"childrenNum":0,"fileId":16388,"group":"supergroup","length":50,"modificationTime":1433119638967,"owner":"michaeljones","pathSuffix":"wcInput","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18676,"group":"supergroup","length":0,"modificationTime":1434242169795,"owner":"michaeljones","pathSuffix":"wcOutput","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},[\n]"
http-outgoing-0 << "{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18683,"group":"supergroup","length":0,"modificationTime":1434242171819,"owner":"michaeljones","pathSuffix":"wcOutputAnalysis","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},[\n]"
http-outgoing-0 << "{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18669,"group":"supergroup","length":0,"modificationTime":1434242168288,"owner":"michaeljones","pathSuffix":"wcOutputMain","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"}[\n]"
http-outgoing-0 << "]}}[\n]"
http-outgoing-0 << "[\r][\n]"
http-outgoing-0 << "0[\r][\n]"
http-outgoing-0 << "[\r][\n]"
http-outgoing-0 << HTTP/1.1 200 OK
http-outgoing-0 << Cache-Control: no-cache
http-outgoing-0 << Expires: Sun, 14 Jun 2015 03:04:22 GMT
http-outgoing-0 << Date: Sun, 14 Jun 2015 03:04:22 GMT
http-outgoing-0 << Pragma: no-cache
http-outgoing-0 << Expires: Sun, 14 Jun 2015 03:04:22 GMT
http-outgoing-0 << Date: Sun, 14 Jun 2015 03:04:22 GMT
http-outgoing-0 << Pragma: no-cache
http-outgoing-0 << Content-Type: application/json
http-outgoing-0 << Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434287062804&s=AEOEhsrel7h0+qmfdQYP+1QktS8="; Path=/; Expires=Sun, 14-Jun-2015 13:04:22 GMT; HttpOnly
http-outgoing-0 << Transfer-Encoding: chunked
http-outgoing-0 << Server: Jetty(6.1.26)
Connection can be kept alive indefinitely
Cookie accepted [hadoop.auth=""u=michaeljones&p=michaeljones&t=simple&e=1434287062804&s=AEOEhsrel7h0+qmfdQYP+1QktS8="", version:0, domain:localhost, path:/, expiry:Sun Jun 14 23:04:22 AEST 2015]
Connection [id: 0][route: {}->http://localhost:50070] can be kept alive indefinitely
Connection released: [id: 0][route: {}->http://localhost:50070][total kept alive: 1; route allocated: 1 of 2; total allocated: 1 of 20]
Connection manager is shutting down
http-outgoing-0: Close connection
http-outgoing-0: Close connection
Connection manager shut down
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 1][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://localhost:50070
Connecting to localhost/127.0.0.1:50070
Connection established 127.0.0.1:50053<->127.0.0.1:50070
Executing request PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-1 >> PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1
http-outgoing-1 >> Content-Length: 0
http-outgoing-1 >> Host: localhost:50070
http-outgoing-1 >> Connection: Keep-Alive
http-outgoing-1 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-1 >> Accept-Encoding: gzip,deflate
http-outgoing-1 >> "PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1[\r][\n]"
http-outgoing-1 >> "Content-Length: 0[\r][\n]"
http-outgoing-1 >> "Host: localhost:50070[\r][\n]"
http-outgoing-1 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-1 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-1 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-1 >> "[\r][\n]"
http-outgoing-1 << "HTTP/1.1 307 TEMPORARY_REDIRECT[\r][\n]"
http-outgoing-1 << "Cache-Control: no-cache[\r][\n]"
http-outgoing-1 << "Expires: Sun, 14 Jun 2015 03:04:23 GMT[\r][\n]"
http-outgoing-1 << "Date: Sun, 14 Jun 2015 03:04:23 GMT[\r][\n]"
http-outgoing-1 << "Pragma: no-cache[\r][\n]"
http-outgoing-1 << "Expires: Sun, 14 Jun 2015 03:04:23 GMT[\r][\n]"
http-outgoing-1 << "Date: Sun, 14 Jun 2015 03:04:23 GMT[\r][\n]"
http-outgoing-1 << "Pragma: no-cache[\r][\n]"
http-outgoing-1 << "Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434287063311&s=MjN9O/YbqrjEnBZbr/O/WHd77/A="; Path=/; Expires=Sun, 14-Jun-2015 13:04:23 GMT; HttpOnly[\r][\n]"
http-outgoing-1 << "Location: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true[\r][\n]"
http-outgoing-1 << "Content-Type: application/octet-stream[\r][\n]"
http-outgoing-1 << "Content-Length: 0[\r][\n]"
http-outgoing-1 << "Server: Jetty(6.1.26)[\r][\n]"
http-outgoing-1 << "[\r][\n]"
http-outgoing-1 << HTTP/1.1 307 TEMPORARY_REDIRECT
http-outgoing-1 << Cache-Control: no-cache
http-outgoing-1 << Expires: Sun, 14 Jun 2015 03:04:23 GMT
http-outgoing-1 << Date: Sun, 14 Jun 2015 03:04:23 GMT
http-outgoing-1 << Pragma: no-cache
http-outgoing-1 << Expires: Sun, 14 Jun 2015 03:04:23 GMT
http-outgoing-1 << Date: Sun, 14 Jun 2015 03:04:23 GMT
http-outgoing-1 << Pragma: no-cache
http-outgoing-1 << Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434287063311&s=MjN9O/YbqrjEnBZbr/O/WHd77/A="; Path=/; Expires=Sun, 14-Jun-2015 13:04:23 GMT; HttpOnly
http-outgoing-1 << Location: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
http-outgoing-1 << Content-Type: application/octet-stream
http-outgoing-1 << Content-Length: 0
http-outgoing-1 << Server: Jetty(6.1.26)
Connection can be kept alive indefinitely
Cookie accepted [hadoop.auth=""u=michaeljones&p=michaeljones&t=simple&e=1434287063311&s=MjN9O/YbqrjEnBZbr/O/WHd77/A="", version:0, domain:localhost, path:/, expiry:Sun Jun 14 23:04:23 AEST 2015]
Redirect to: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
http-outgoing-1: Shutdown connection
Connection discarded
http-outgoing-1: Close connection
Connection released: [id: 1][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 2][route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://michaels-air.bigpond:50075
Connecting to michaels-air.bigpond/10.0.0.2:50075
Connection established 10.0.0.2:50054<->10.0.0.2:50075
Executing request PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-2 >> PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1
http-outgoing-2 >> Content-Length: 0
http-outgoing-2 >> Host: michaels-air.bigpond:50075
http-outgoing-2 >> Connection: Keep-Alive
http-outgoing-2 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-2 >> Accept-Encoding: gzip,deflate
http-outgoing-2 >> "PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1[\r][\n]"
http-outgoing-2 >> "Content-Length: 0[\r][\n]"
http-outgoing-2 >> "Host: michaels-air.bigpond:50075[\r][\n]"
http-outgoing-2 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-2 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-2 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-2 >> "[\r][\n]"
http-outgoing-2 << "HTTP/1.1 100 Continue[\r][\n]"
http-outgoing-2 << "[\r][\n]"
http-outgoing-2 << "HTTP/1.1 201 Created[\r][\n]"
http-outgoing-2 << "Location: hdfs://localhost:9000/user/michaeljones/hello-apache-empty.txt[\r][\n]"
http-outgoing-2 << "Content-Length: 0[\r][\n]"
http-outgoing-2 << "Connection: close[\r][\n]"
http-outgoing-2 << "[\r][\n]"
http-outgoing-2 << HTTP/1.1 100 Continue
http-outgoing-2 << HTTP/1.1 201 Created
http-outgoing-2 << Location: hdfs://localhost:9000/user/michaeljones/hello-apache-empty.txt
http-outgoing-2 << Content-Length: 0
http-outgoing-2 << Connection: close
http-outgoing-2: Shutdown connection
Connection discarded
http-outgoing-2: Close connection
Connection released: [id: 2][route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection manager is shutting down
Connection manager shut down
Jersey client Redirect to: hdfs://localhost:9000/user/michaeljones/hellohadoop.log
com.sun.jersey.client.property.chunkedEncodingSize: 1048576
Jersey client Redirect to: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/hello.log.2015-06-12?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 3][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://localhost:50070
Connecting to localhost/127.0.0.1:50070
Connection established 127.0.0.1:50064<->127.0.0.1:50070
Executing request PUT /webhdfs/v1/user/michaeljones/README.md?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-3 >> PUT /webhdfs/v1/user/michaeljones/README.md?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1
http-outgoing-3 >> Transfer-Encoding: chunked
http-outgoing-3 >> Content-Type: application/octet-stream
http-outgoing-3 >> Host: localhost:50070
http-outgoing-3 >> Connection: Keep-Alive
http-outgoing-3 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-3 >> Accept-Encoding: gzip,deflate
http-outgoing-3 >> "PUT /webhdfs/v1/user/michaeljones/README.md?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1[\r][\n]"
http-outgoing-3 >> "Transfer-Encoding: chunked[\r][\n]"
http-outgoing-3 >> "Content-Type: application/octet-stream[\r][\n]"
http-outgoing-3 >> "Host: localhost:50070[\r][\n]"
http-outgoing-3 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-3 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-3 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-3 >> "[\r][\n]"
http-outgoing-3 >> "1000[\r][\n]"
http-outgoing-3 >> "# Hello-Hadoop-netbeans-OS-X[\n]"
http-outgoing-3 >> "Java Maven project for playing with the HDFS API without any 3rd party hadoop plugins.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## Aim of project[\n]"
http-outgoing-3 >> "Hello world/tutorial level for programmatically operating with a pseudo distributed hadoop configuration on OS X. Hadoop 2.7 on Yosemite.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## What this project demonstrates[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "This is work in progress and so far the following functionality is demonstrated:[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "1. Direct programmatic control of the HDFS and running map reduce jobs - all unit tests run from the IDE with hadoop configuration built into this project and under git control.[\n]"
http-outgoing-3 >> "2. Uploading of files to the HDFS by implementing a Web REST API client.[\n]"
http-outgoing-3 >> "3. Async file upload (at time of writing only Jersey back end implemented).[\n]"
http-outgoing-3 >> "4. Layered application code for maximum re-use and ease of test driven development. The client I wrote uses an interface which has allowed me to provide both a Jersey HTTP client implementation and an Apache HTTP client implementation for comparison between the two toolkits.[\n]"
http-outgoing-3 >> "5. Test driven development.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## Getting started[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "The initial difficulty was working out how to run the program in the IDE and talk to the local pseudo distributed setup without using a 3rd party Hadoop plugin. Apparently there used to be a plugin for netbeans, but it has been discontinued. I am a newbie with this technology.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "The Apache Hadoop instructions for building and running java programs are via their command line build/run utility only. Getting the yahoo hadoop HDFS tutorial program to build in the IDE wasn't too hard. However, by default it will ignore the local Hadoop configuration and only operate with the local file system in local debug mode.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## Wading through the configuration[\n]"
http-outgoing-3 >> "Hadoop is designed to work with a number of different topologies, directory locations, levels of replication, simulated environments etc. so as we would expect nothing works unless the configuration is right.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "First Hadoop needs to be installed and configured in pseudo distributed mode such that it builds and runs test programs on the command line. The hadoop documentation has instructions for doing this. Documentation is online and also included in the installation: share/doc/hadoop/index.html. However this is not enough to get it to work in the IDE.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## The netbeans project settings that are needed to run with the HDFS from the IDE:[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "1. Get log4j configured to work in the IDE. Absence of log4j configuration won't stop hadoop from running, but we won't get to see useful error messages from hadoop without it.[\n]"
http-outgoing-3 >> "2. HADOOP_HOME environment variable project run (and test) property.[\n]"
http-outgoing-3 >> "3. Duplicate hadoop configuration in the classpath. The above environment variable does not pick up the hadoop configuration from its usual place. Yahoo's only suggestion is to run from the command line via the hadoop script. The Apache HDFS API documention says that configuration is looked for in the classpath, so I took the approach of duplicating the configuration (just 2 files) instead of figuring out how to get it to look in the installation path.[\n]"
http-outgoing-3 >> "4. The correct Maven dependencies. If not all the jar depenencies are there the program may build and run, but it won't talk to the HDFS if it doesn't load the HDFS jars.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "I think that the setup of this project would probably work on Linux too.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## Working through trouble shooting the HDFS project settings[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "Issue 1 above shows up as:[\n]"
http-outgoing-3 >> "<pre><code>[\n]"
http-outgoing-3 >> "log4j:WARN No appenders could be found for logger (org.apache.hadoop.util.Shell).[\n]"
http-outgoing-3 >> "log4j:WARN Please initialize the log4j system properly.[\n]"
http-outgoing-3 >> "log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.[\n]"
http-outgoing-3 >> "</pre></code>[\n]"
http-outgoing-3 >> "This is solved by putting a log4j.properties configuration file in the classpath. For a Maven build getting files into the classpath can be achieved by putting them in src/main/resources. I don't think this is in the classpath, but the build will then copy the file into ./target/classes/ which is in the classpath.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "Issue 2 above shows up as:[\n]"
http-outgoing-3 >> "<pre><code>[\n]"
http-outgoing-3 >> "Failed to detect a valid hadoop home directory[\n]"
http-outgoing-3 >> "java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.[\n]"
http-outgoing-3 >> "</[\r][\n]"
http-outgoing-3 >> "1000[\r][\n]"
http-outgoing-3 >> "code></pre>[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "This is fixed by going into the project properties => Build => Actions => Run Project and adding the environment variable for HADOOP_HOME. This will result in an entry in the Maven POM. Repeat for "Test Project", "Debug Project" etc.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "Issue 3. shows up as running, but creating a file on the local file system instead of the HDFS. This was fixed       looking at the HDFS API documentation for org.apache.hadoop.conf.Configuration. This documentation is under the chapter: C API libhdfs HDFS which has a link to the HDFS API under "The APIs" (I strangely cannot find this in the main index). On my installation the HDFS API documentation link is file:///opt/local/hadoop-2.7.0/share/doc/hadoop/api/org/apache/hadoop/fs/FileSystem.html.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "This documentation told me that hadoop loads core-site.xml and core-default.xml in the classpath. Classpath for a Maven build can be reached by placing these files in the directory src/main/resources (see logging configuration above). I added hdfs-site instead of core-default (which doesn't exist on my 2.7 install) into the src/main/resources project directory.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "Issue 3 shows up as:[\n]"
http-outgoing-3 >> "<pre><code>[\n]"
http-outgoing-3 >> "java.io.IOException: "hadoop No FileSystem for scheme: hdfs".[\n]"
http-outgoing-3 >> "</code></pre>[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "This is part of the build dependency problem. The various threads on stackoverflow etc. suggested that a minimum dependency was the jar for hadoop-core. However, there is no such jar on 2.7. I ran the hadoop command to dump version and got this:[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "<pre><code>[\n]"
http-outgoing-3 >> "bin/hadoop version[\n]"
http-outgoing-3 >> "Hadoop 2.7.0[\n]"
http-outgoing-3 >> "Subversion https://git-wip-us.apache.org/repos/asf/hadoop.git -r d4c8d4d4d203c934e8074b31289a28724c0842cf[\n]"
http-outgoing-3 >> "Compiled by jenkins on 2015-04-10T18:40Z[\n]"
http-outgoing-3 >> "Compiled with protoc 2.5.0[\n]"
http-outgoing-3 >> "From source with checksum a9e90912c37a35c3195d23951fd18f[\n]"
http-outgoing-3 >> "This command was run using /opt/local/hadoop-2.7.0/share/hadoop/common/hadoop-common-2.7.0.jar[\n]"
http-outgoing-3 >> "</code></pre>[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "I noted the jar name at the end and added it as a dependency to the POM. This can either be hand coded in or right click pom.xml => Insert Code => Add Dependency => Search => query hadoop-common and select version which was 2.7.0 [jar] - central. Maven will then add dependencies to other hadoop jars in the "Dependencies" group in the project explorer. Netbeans will then download these dependencies before the next build. They go into ~/.m2/repository should they ever need to be cleaned out (Netbeans doesn't seem to have an IDE remove dependency option).[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "After doing the above project built, but showed up the "no filesystem error". I noticed that Maven had not pulled in any hdfs jars matching the jars in my share/hadoop/hdfs installation directory. So I took a guess that it needed only the top level hadoop-hdfs-2.7.0.jar and added this as a dependency to the POM and all was good :)[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## Working through trouble shooting the Map Reduce project settings[\n]"
http-outgoing-3 >> "After getting the HDFS API working in the IDE it was time to move on to getting the famous Word Count map-reduce tutorial running.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "So coded it, set the main program to the word count main as the one to run. From the IDE: project Properties => Run => Main Class. Provide input and output arguments for the word count program. I noted that the netbeans properties pop-up window does not persist these settings next time it pops up. However this setting is persistant and ends up in nbactions.xml.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "However, running the word count map reduce program resulted in an ioException:[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "<pre><code>[\n]"
http-outgoing-3 >> "Please check your configuration for mapreduce.framework.name and the correspond server addresses.[\n]"
http-outgoing-3 >> "</pre></code>[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "Because the resources directory only contains 2 configuration files from my hadoop installation I thought maybe I was missing a map reduce one. So the first thing I did was go into the configuration directory of my installation and grep all files to see if there was a configuration file with mapreduce framework property. There was not. I checked my programatic configuration dump from my test program. This property was not mentioned either. The only map reduce configuration was to do with some environment variables for heap size in one of the shell scripts. Note to sel[\r][\n]"
http-outgoing-3 >> "c47[\r][\n]"
http-outgoing-3 >> "f: this may be relevant and I can consider setting this in the IDE. However, that didn't look like the problem.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "I then checked my dependencies and noted there were no map reduce jars pulled in by Maven. So I added hadoop-mapreduce-client-core. Still not running. Checked the web and a thread on stackoverflow mentioned a number of other jars: hadoop-mapreduce-client-common and hadoop-mapreduce-client shuffle. I added just the hadoop-mapreduce-client-common and it runs :) I have a feeling that I might need some of the other jars for other API calls and that there must be a better way of working out dependencies than this trial and error. As mentioned I am a newbie with this, so if anyone has any comments feel free to email me.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## Logging from application code[\n]"
http-outgoing-3 >> "Although the hadoop libraries log correctly with a properly located log4.properties file, application code calling the log4j logger seems to ignore this file. Using the log4j logger as per instructions in the log4j manual and many online tutorials did not result in getting any logging redirected to file configured in the properties file. Instead console output only is obtained. A clue to this mystery was that a most basic of hello world netbeans maven projects which did not import any hadoop stuff also failed to log to a file and did not even give the "No appenders" warning. Then I noticed that there were org.sl4j depencies in the hadoop build, so using sl4j instead solved the problem. Once my hello world project used sl4j's LoggerFactory and had sl4j-api and sl4j-12 as a dependencies it started to use the properties file. See http://www.slf4j.org/manual.html[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## Upload a file from local storage to the HDFS via the REST API[\n]"
http-outgoing-3 >> "The WebHDFS REST API documentation which came with the installation specifies that file creation is a two stage operation where an initial PUT to the namenode is sent. This responds with a redirect to the datanode and another PUT should be made to this redirection which can contain the chunked data stream. This does not sound REST to me as it relies on holding redirection state (a fully distributed configuration could presumably return a redirection to any one of the datanodes). Hadoop say this is because of a bug in some HTTP client implementations - incorrect implementation of [0xe2][0x80][0x9c]Expect: 100-continue[0xe2][0x80][0x9d].[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "However, the 2 stage PUT not being REST seems to be a moot point, at least with the Jersey client. I do not get a redirection and a file creates/uploads all in one go.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "Since writing the above paragraph I have implemented the Apache Client back end option to my HDFS Web client interface and this client behaves differently. It does indeed cause a redirect as per Hadoop documentation. The follow up PUT to the redirected location with the chunked file stream works as per documentation.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "Since writing the above paragraph I have implemented a big chunk size setting for the HTTP chunking and this changed the behaviour of the Jersey client to always redirect. It might be that unless the chunk size option is set then the Jersey implementation does not chunk - this would be terrible for big files.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "To be continued ...[\n]"
http-outgoing-3 >> "[\r][\n]"
http-outgoing-3 >> "0[\r][\n]"
http-outgoing-3 >> "[\r][\n]"
http-outgoing-3 << "HTTP/1.1 307 TEMPORARY_REDIRECT[\r][\n]"
http-outgoing-3 << "Cache-Control: no-cache[\r][\n]"
http-outgoing-3 << "Expires: Sun, 14 Jun 2015 03:04:24 GMT[\r][\n]"
http-outgoing-3 << "Date: Sun, 14 Jun 2015 03:04:24 GMT[\r][\n]"
http-outgoing-3 << "Pragma: no-cache[\r][\n]"
http-outgoing-3 << "Expires: Sun, 14 Jun 2015 03:04:24 GMT[\r][\n]"
http-outgoing-3 << "Date: Sun, 14 Jun 2015 03:04:24 GMT[\r][\n]"
http-outgoing-3 << "Pragma: no-cache[\r][\n]"
http-outgoing-3 << "Content-Type: application/octet-stream[\r][\n]"
http-outgoing-3 << "Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434287064010&s=4kgZV1G1+rCAz05R4yAcqUXywGI="; Path=/; Expires=Sun, 14-Jun-2015 13:04:24 GMT; HttpOnly[\r][\n]"
http-outgoing-3 << "Location: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/README.md?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true[\r][\n]"
http-outgoing-3 << "Content-Length: 0[\r][\n]"
http-outgoing-3 << "Server: Jetty(6.1.26)[\r][\n]"
http-outgoing-3 << "[\r][\n]"
http-outgoing-3 << HTTP/1.1 307 TEMPORARY_REDIRECT
http-outgoing-3 << Cache-Control: no-cache
http-outgoing-3 << Expires: Sun, 14 Jun 2015 03:04:24 GMT
http-outgoing-3 << Date: Sun, 14 Jun 2015 03:04:24 GMT
http-outgoing-3 << Pragma: no-cache
http-outgoing-3 << Expires: Sun, 14 Jun 2015 03:04:24 GMT
http-outgoing-3 << Date: Sun, 14 Jun 2015 03:04:24 GMT
http-outgoing-3 << Pragma: no-cache
http-outgoing-3 << Content-Type: application/octet-stream
http-outgoing-3 << Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434287064010&s=4kgZV1G1+rCAz05R4yAcqUXywGI="; Path=/; Expires=Sun, 14-Jun-2015 13:04:24 GMT; HttpOnly
http-outgoing-3 << Location: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/README.md?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
http-outgoing-3 << Content-Length: 0
http-outgoing-3 << Server: Jetty(6.1.26)
Connection can be kept alive indefinitely
Cookie accepted [hadoop.auth=""u=michaeljones&p=michaeljones&t=simple&e=1434287064010&s=4kgZV1G1+rCAz05R4yAcqUXywGI="", version:0, domain:localhost, path:/, expiry:Sun Jun 14 23:04:24 AEST 2015]
Redirect to: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/README.md?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
http-outgoing-3: Shutdown connection
Connection discarded
http-outgoing-3: Close connection
Connection released: [id: 3][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 4][route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://michaels-air.bigpond:50075
Connecting to michaels-air.bigpond/10.0.0.2:50075
Connection established 10.0.0.2:50065<->10.0.0.2:50075
Executing request PUT /webhdfs/v1/user/michaeljones/README.md?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-4 >> PUT /webhdfs/v1/user/michaeljones/README.md?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1
http-outgoing-4 >> Transfer-Encoding: chunked
http-outgoing-4 >> Content-Type: application/octet-stream
http-outgoing-4 >> Host: michaels-air.bigpond:50075
http-outgoing-4 >> Connection: Keep-Alive
http-outgoing-4 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-4 >> Accept-Encoding: gzip,deflate
http-outgoing-4 >> "PUT /webhdfs/v1/user/michaeljones/README.md?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1[\r][\n]"
http-outgoing-4 >> "Transfer-Encoding: chunked[\r][\n]"
http-outgoing-4 >> "Content-Type: application/octet-stream[\r][\n]"
http-outgoing-4 >> "Host: michaels-air.bigpond:50075[\r][\n]"
http-outgoing-4 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-4 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-4 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-4 >> "[\r][\n]"
http-outgoing-4 >> "1000[\r][\n]"
http-outgoing-4 >> "# Hello-Hadoop-netbeans-OS-X[\n]"
http-outgoing-4 >> "Java Maven project for playing with the HDFS API without any 3rd party hadoop plugins.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## Aim of project[\n]"
http-outgoing-4 >> "Hello world/tutorial level for programmatically operating with a pseudo distributed hadoop configuration on OS X. Hadoop 2.7 on Yosemite.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## What this project demonstrates[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "This is work in progress and so far the following functionality is demonstrated:[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "1. Direct programmatic control of the HDFS and running map reduce jobs - all unit tests run from the IDE with hadoop configuration built into this project and under git control.[\n]"
http-outgoing-4 >> "2. Uploading of files to the HDFS by implementing a Web REST API client.[\n]"
http-outgoing-4 >> "3. Async file upload (at time of writing only Jersey back end implemented).[\n]"
http-outgoing-4 >> "4. Layered application code for maximum re-use and ease of test driven development. The client I wrote uses an interface which has allowed me to provide both a Jersey HTTP client implementation and an Apache HTTP client implementation for comparison between the two toolkits.[\n]"
http-outgoing-4 >> "5. Test driven development.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## Getting started[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "The initial difficulty was working out how to run the program in the IDE and talk to the local pseudo distributed setup without using a 3rd party Hadoop plugin. Apparently there used to be a plugin for netbeans, but it has been discontinued. I am a newbie with this technology.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "The Apache Hadoop instructions for building and running java programs are via their command line build/run utility only. Getting the yahoo hadoop HDFS tutorial program to build in the IDE wasn't too hard. However, by default it will ignore the local Hadoop configuration and only operate with the local file system in local debug mode.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## Wading through the configuration[\n]"
http-outgoing-4 >> "Hadoop is designed to work with a number of different topologies, directory locations, levels of replication, simulated environments etc. so as we would expect nothing works unless the configuration is right.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "First Hadoop needs to be installed and configured in pseudo distributed mode such that it builds and runs test programs on the command line. The hadoop documentation has instructions for doing this. Documentation is online and also included in the installation: share/doc/hadoop/index.html. However this is not enough to get it to work in the IDE.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## The netbeans project settings that are needed to run with the HDFS from the IDE:[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "1. Get log4j configured to work in the IDE. Absence of log4j configuration won't stop hadoop from running, but we won't get to see useful error messages from hadoop without it.[\n]"
http-outgoing-4 >> "2. HADOOP_HOME environment variable project run (and test) property.[\n]"
http-outgoing-4 >> "3. Duplicate hadoop configuration in the classpath. The above environment variable does not pick up the hadoop configuration from its usual place. Yahoo's only suggestion is to run from the command line via the hadoop script. The Apache HDFS API documention says that configuration is looked for in the classpath, so I took the approach of duplicating the configuration (just 2 files) instead of figuring out how to get it to look in the installation path.[\n]"
http-outgoing-4 >> "4. The correct Maven dependencies. If not all the jar depenencies are there the program may build and run, but it won't talk to the HDFS if it doesn't load the HDFS jars.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "I think that the setup of this project would probably work on Linux too.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## Working through trouble shooting the HDFS project settings[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "Issue 1 above shows up as:[\n]"
http-outgoing-4 >> "<pre><code>[\n]"
http-outgoing-4 >> "log4j:WARN No appenders could be found for logger (org.apache.hadoop.util.Shell).[\n]"
http-outgoing-4 >> "log4j:WARN Please initialize the log4j system properly.[\n]"
http-outgoing-4 >> "log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.[\n]"
http-outgoing-4 >> "</pre></code>[\n]"
http-outgoing-4 >> "This is solved by putting a log4j.properties configuration file in the classpath. For a Maven build getting files into the classpath can be achieved by putting them in src/main/resources. I don't think this is in the classpath, but the build will then copy the file into ./target/classes/ which is in the classpath.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "Issue 2 above shows up as:[\n]"
http-outgoing-4 >> "<pre><code>[\n]"
http-outgoing-4 >> "Failed to detect a valid hadoop home directory[\n]"
http-outgoing-4 >> "java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.[\n]"
http-outgoing-4 >> "</[\r][\n]"
http-outgoing-4 >> "1000[\r][\n]"
http-outgoing-4 >> "code></pre>[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "This is fixed by going into the project properties => Build => Actions => Run Project and adding the environment variable for HADOOP_HOME. This will result in an entry in the Maven POM. Repeat for "Test Project", "Debug Project" etc.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "Issue 3. shows up as running, but creating a file on the local file system instead of the HDFS. This was fixed       looking at the HDFS API documentation for org.apache.hadoop.conf.Configuration. This documentation is under the chapter: C API libhdfs HDFS which has a link to the HDFS API under "The APIs" (I strangely cannot find this in the main index). On my installation the HDFS API documentation link is file:///opt/local/hadoop-2.7.0/share/doc/hadoop/api/org/apache/hadoop/fs/FileSystem.html.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "This documentation told me that hadoop loads core-site.xml and core-default.xml in the classpath. Classpath for a Maven build can be reached by placing these files in the directory src/main/resources (see logging configuration above). I added hdfs-site instead of core-default (which doesn't exist on my 2.7 install) into the src/main/resources project directory.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "Issue 3 shows up as:[\n]"
http-outgoing-4 >> "<pre><code>[\n]"
http-outgoing-4 >> "java.io.IOException: "hadoop No FileSystem for scheme: hdfs".[\n]"
http-outgoing-4 >> "</code></pre>[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "This is part of the build dependency problem. The various threads on stackoverflow etc. suggested that a minimum dependency was the jar for hadoop-core. However, there is no such jar on 2.7. I ran the hadoop command to dump version and got this:[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "<pre><code>[\n]"
http-outgoing-4 >> "bin/hadoop version[\n]"
http-outgoing-4 >> "Hadoop 2.7.0[\n]"
http-outgoing-4 >> "Subversion https://git-wip-us.apache.org/repos/asf/hadoop.git -r d4c8d4d4d203c934e8074b31289a28724c0842cf[\n]"
http-outgoing-4 >> "Compiled by jenkins on 2015-04-10T18:40Z[\n]"
http-outgoing-4 >> "Compiled with protoc 2.5.0[\n]"
http-outgoing-4 >> "From source with checksum a9e90912c37a35c3195d23951fd18f[\n]"
http-outgoing-4 >> "This command was run using /opt/local/hadoop-2.7.0/share/hadoop/common/hadoop-common-2.7.0.jar[\n]"
http-outgoing-4 >> "</code></pre>[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "I noted the jar name at the end and added it as a dependency to the POM. This can either be hand coded in or right click pom.xml => Insert Code => Add Dependency => Search => query hadoop-common and select version which was 2.7.0 [jar] - central. Maven will then add dependencies to other hadoop jars in the "Dependencies" group in the project explorer. Netbeans will then download these dependencies before the next build. They go into ~/.m2/repository should they ever need to be cleaned out (Netbeans doesn't seem to have an IDE remove dependency option).[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "After doing the above project built, but showed up the "no filesystem error". I noticed that Maven had not pulled in any hdfs jars matching the jars in my share/hadoop/hdfs installation directory. So I took a guess that it needed only the top level hadoop-hdfs-2.7.0.jar and added this as a dependency to the POM and all was good :)[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## Working through trouble shooting the Map Reduce project settings[\n]"
http-outgoing-4 >> "After getting the HDFS API working in the IDE it was time to move on to getting the famous Word Count map-reduce tutorial running.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "So coded it, set the main program to the word count main as the one to run. From the IDE: project Properties => Run => Main Class. Provide input and output arguments for the word count program. I noted that the netbeans properties pop-up window does not persist these settings next time it pops up. However this setting is persistant and ends up in nbactions.xml.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "However, running the word count map reduce program resulted in an ioException:[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "<pre><code>[\n]"
http-outgoing-4 >> "Please check your configuration for mapreduce.framework.name and the correspond server addresses.[\n]"
http-outgoing-4 >> "</pre></code>[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "Because the resources directory only contains 2 configuration files from my hadoop installation I thought maybe I was missing a map reduce one. So the first thing I did was go into the configuration directory of my installation and grep all files to see if there was a configuration file with mapreduce framework property. There was not. I checked my programatic configuration dump from my test program. This property was not mentioned either. The only map reduce configuration was to do with some environment variables for heap size in one of the shell scripts. Note to sel[\r][\n]"
http-outgoing-4 >> "c47[\r][\n]"
http-outgoing-4 >> "f: this may be relevant and I can consider setting this in the IDE. However, that didn't look like the problem.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "I then checked my dependencies and noted there were no map reduce jars pulled in by Maven. So I added hadoop-mapreduce-client-core. Still not running. Checked the web and a thread on stackoverflow mentioned a number of other jars: hadoop-mapreduce-client-common and hadoop-mapreduce-client shuffle. I added just the hadoop-mapreduce-client-common and it runs :) I have a feeling that I might need some of the other jars for other API calls and that there must be a better way of working out dependencies than this trial and error. As mentioned I am a newbie with this, so if anyone has any comments feel free to email me.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## Logging from application code[\n]"
http-outgoing-4 >> "Although the hadoop libraries log correctly with a properly located log4.properties file, application code calling the log4j logger seems to ignore this file. Using the log4j logger as per instructions in the log4j manual and many online tutorials did not result in getting any logging redirected to file configured in the properties file. Instead console output only is obtained. A clue to this mystery was that a most basic of hello world netbeans maven projects which did not import any hadoop stuff also failed to log to a file and did not even give the "No appenders" warning. Then I noticed that there were org.sl4j depencies in the hadoop build, so using sl4j instead solved the problem. Once my hello world project used sl4j's LoggerFactory and had sl4j-api and sl4j-12 as a dependencies it started to use the properties file. See http://www.slf4j.org/manual.html[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## Upload a file from local storage to the HDFS via the REST API[\n]"
http-outgoing-4 >> "The WebHDFS REST API documentation which came with the installation specifies that file creation is a two stage operation where an initial PUT to the namenode is sent. This responds with a redirect to the datanode and another PUT should be made to this redirection which can contain the chunked data stream. This does not sound REST to me as it relies on holding redirection state (a fully distributed configuration could presumably return a redirection to any one of the datanodes). Hadoop say this is because of a bug in some HTTP client implementations - incorrect implementation of [0xe2][0x80][0x9c]Expect: 100-continue[0xe2][0x80][0x9d].[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "However, the 2 stage PUT not being REST seems to be a moot point, at least with the Jersey client. I do not get a redirection and a file creates/uploads all in one go.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "Since writing the above paragraph I have implemented the Apache Client back end option to my HDFS Web client interface and this client behaves differently. It does indeed cause a redirect as per Hadoop documentation. The follow up PUT to the redirected location with the chunked file stream works as per documentation.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "Since writing the above paragraph I have implemented a big chunk size setting for the HTTP chunking and this changed the behaviour of the Jersey client to always redirect. It might be that unless the chunk size option is set then the Jersey implementation does not chunk - this would be terrible for big files.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "To be continued ...[\n]"
http-outgoing-4 >> "[\r][\n]"
http-outgoing-4 >> "0[\r][\n]"
http-outgoing-4 >> "[\r][\n]"
http-outgoing-4 << "HTTP/1.1 100 Continue[\r][\n]"
http-outgoing-4 << "[\r][\n]"
http-outgoing-4 << HTTP/1.1 100 Continue
http-outgoing-4 << "HTTP/1.1 201 Created[\r][\n]"
http-outgoing-4 << "Location: hdfs://localhost:9000/user/michaeljones/README.md[\r][\n]"
http-outgoing-4 << "Content-Length: 0[\r][\n]"
http-outgoing-4 << "Connection: close[\r][\n]"
http-outgoing-4 << "[\r][\n]"
http-outgoing-4 << HTTP/1.1 201 Created
http-outgoing-4 << Location: hdfs://localhost:9000/user/michaeljones/README.md
http-outgoing-4 << Content-Length: 0
http-outgoing-4 << Connection: close
http-outgoing-4: Shutdown connection
Connection discarded
http-outgoing-4: Close connection
Connection released: [id: 4][route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection manager is shutting down
Connection manager shut down
Connection manager is shutting down
Connection manager shut down
com.sun.jersey.client.property.chunkedEncodingSize: 1048576
Jersey client Redirect to: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/nbactions.xml?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
com.sun.jersey.client.property.chunkedEncodingSize: 1048576
Jersey client Redirect to: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/nbactions.xml?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
testUploadFileAsync: redirect: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/nbactions.xml?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
com.sun.jersey.client.property.chunkedEncodingSize: 1048576
com.sun.jersey.client.property.chunkedEncodingSize: 1048576
Jersey client Redirect to: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/hellohadoop.log.2015-06-12?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
Jersey client Redirect to: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/hellohadoop.log.2015-06-13?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 0][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://localhost:50070
Connecting to localhost/127.0.0.1:50070
Connection established 127.0.0.1:50274<->127.0.0.1:50070
Executing request GET /webhdfs/v1/user/michaeljones/?user.name=michaeljones&op=LISTSTATUS HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-0 >> GET /webhdfs/v1/user/michaeljones/?user.name=michaeljones&op=LISTSTATUS HTTP/1.1
http-outgoing-0 >> accept: application/json
http-outgoing-0 >> Host: localhost:50070
http-outgoing-0 >> Connection: Keep-Alive
http-outgoing-0 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-0 >> Accept-Encoding: gzip,deflate
http-outgoing-0 >> "GET /webhdfs/v1/user/michaeljones/?user.name=michaeljones&op=LISTSTATUS HTTP/1.1[\r][\n]"
http-outgoing-0 >> "accept: application/json[\r][\n]"
http-outgoing-0 >> "Host: localhost:50070[\r][\n]"
http-outgoing-0 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-0 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-0 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-0 >> "[\r][\n]"
http-outgoing-0 << "HTTP/1.1 200 OK[\r][\n]"
http-outgoing-0 << "Cache-Control: no-cache[\r][\n]"
http-outgoing-0 << "Expires: Sun, 14 Jun 2015 03:39:22 GMT[\r][\n]"
http-outgoing-0 << "Date: Sun, 14 Jun 2015 03:39:22 GMT[\r][\n]"
http-outgoing-0 << "Pragma: no-cache[\r][\n]"
http-outgoing-0 << "Expires: Sun, 14 Jun 2015 03:39:22 GMT[\r][\n]"
http-outgoing-0 << "Date: Sun, 14 Jun 2015 03:39:22 GMT[\r][\n]"
http-outgoing-0 << "Pragma: no-cache[\r][\n]"
http-outgoing-0 << "Content-Type: application/json[\r][\n]"
http-outgoing-0 << "Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434289162041&s=nRvBt2RN08814KmCT3/rZ2Cu/pY="; Path=/; Expires=Sun, 14-Jun-2015 13:39:22 GMT; HttpOnly[\r][\n]"
http-outgoing-0 << "Transfer-Encoding: chunked[\r][\n]"
http-outgoing-0 << "Server: Jetty(6.1.26)[\r][\n]"
http-outgoing-0 << "[\r][\n]"
http-outgoing-0 << "12FC[\r][\n]"
http-outgoing-0 << "{"FileStatuses":{"FileStatus":[[\n]"
http-outgoing-0 << "{"accessTime":1434251064135,"blockSize":134217728,"childrenNum":0,"fileId":18740,"group":"supergroup","length":11335,"modificationTime":1434251064162,"owner":"michaeljones","pathSuffix":"README.md","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434242172845,"blockSize":134217728,"childrenNum":0,"fileId":18690,"group":"supergroup","length":0,"modificationTime":1434242172851,"owner":"michaeljones","pathSuffix":"apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434250345392,"blockSize":134217728,"childrenNum":0,"fileId":18724,"group":"supergroup","length":0,"modificationTime":1434250345400,"owner":"michaeljones","pathSuffix":"empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434251063355,"blockSize":134217728,"childrenNum":0,"fileId":18737,"group":"supergroup","length":0,"modificationTime":1434251063361,"owner":"michaeljones","pathSuffix":"hello-apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434091626279,"blockSize":134217728,"childrenNum":0,"fileId":18298,"group":"supergroup","length":0,"modificationTime":1434091626286,"owner":"michaeljones","pathSuffix":"hello-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434251063270,"blockSize":134217728,"childrenNum":0,"fileId":18736,"group":"supergroup","length":0,"modificationTime":1434251063276,"owner":"michaeljones","pathSuffix":"hello-jersey-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434250345962,"blockSize":134217728,"childrenNum":0,"fileId":18726,"group":"supergroup","length":753882,"modificationTime":1434250346002,"owner":"michaeljones","pathSuffix":"hello.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434251063746,"blockSize":134217728,"childrenNum":0,"fileId":18739,"group":"supergroup","length":3678856,"modificationTime":1434251063896,"owner":"michaeljones","pathSuffix":"hello.log.2015-06-12","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434242164264,"blockSize":134217728,"childrenNum":0,"fileId":18668,"group":"supergroup","length":20,"modificationTime":1434242164753,"owner":"michaeljones","pathSuffix":"hello.txt","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434251063623,"blockSize":134217728,"childrenNum":0,"fileId":18738,"group":"supergroup","length":38125,"modificationTime":1434251063647,"owner":"michaeljones","pathSuffix":"hellohadoop.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434251065247,"blockSize":134217728,"childrenNum":0,"fileId":18742,"group":"supergroup","length":102268,"modificationTime":1434251065287,"owner":"michaeljones","pathSuffix":"hellohadoop.log.2015-06-12","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434251065248,"blockSize":134217728,"childrenNum":0,"fileId":18743,"group":"supergroup","length":102268,"modificationTime":1434251065286,"owner":"michaeljones","pathSuffix":"hellohadoop.log.2015-06-13","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434251064739,"blockSize":134217728,"childrenNum":0,"fileId":18741,"group":"supergroup","length":3644,"modificationTime":1434251064759,"owner":"michaeljones","pathSuffix":"nbactions.xml","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434242172891,"blockSize":134217728,"childrenNum":0,"fileId":18691,"group":"supergroup","length":2134,"modificationTime":1434242172913,"owner":"michaeljones","pathSuffix":"pom.xml","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434242165542,"blockSize":134217728,"childrenNum":0,"fileId":16388,"group":"supergroup","length":50,"modificationTime":1433119638967,"owner":"michaeljones","pathSuffix":"wcInput","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18676,"group":"supergroup","length":0,"modificationTime":1434242169795,"owner":"michaeljones","pathSuffix":"wcOutput","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},[\n]"
http-outgoing-0 << "{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18683,"group":"supergroup","length":0,"modificationTime":1434242171819,"owner":"michaeljones","pathSuffix":"wcOutputAnalysis","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},[\n]"
http-outgoing-0 << "{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18669,"group":"supergroup","length":0,"modificationTime":1434242168288,"owner":"michaeljones","pathSuffix":"wcOutputMain","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"}[\n]"
http-outgoing-0 << "]}}[\n]"
http-outgoing-0 << "[\r][\n]"
http-outgoing-0 << HTTP/1.1 200 OK
http-outgoing-0 << Cache-Control: no-cache
http-outgoing-0 << Expires: Sun, 14 Jun 2015 03:39:22 GMT
http-outgoing-0 << Date: Sun, 14 Jun 2015 03:39:22 GMT
http-outgoing-0 << Pragma: no-cache
http-outgoing-0 << Expires: Sun, 14 Jun 2015 03:39:22 GMT
http-outgoing-0 << Date: Sun, 14 Jun 2015 03:39:22 GMT
http-outgoing-0 << Pragma: no-cache
http-outgoing-0 << Content-Type: application/json
http-outgoing-0 << Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434289162041&s=nRvBt2RN08814KmCT3/rZ2Cu/pY="; Path=/; Expires=Sun, 14-Jun-2015 13:39:22 GMT; HttpOnly
http-outgoing-0 << Transfer-Encoding: chunked
http-outgoing-0 << Server: Jetty(6.1.26)
Connection can be kept alive indefinitely
Cookie accepted [hadoop.auth=""u=michaeljones&p=michaeljones&t=simple&e=1434289162041&s=nRvBt2RN08814KmCT3/rZ2Cu/pY="", version:0, domain:localhost, path:/, expiry:Sun Jun 14 23:39:22 AEST 2015]
http-outgoing-0 << "0[\r][\n]"
http-outgoing-0 << "[\r][\n]"
Connection [id: 0][route: {}->http://localhost:50070] can be kept alive indefinitely
Connection released: [id: 0][route: {}->http://localhost:50070][total kept alive: 1; route allocated: 1 of 2; total allocated: 1 of 20]
Connection manager is shutting down
http-outgoing-0: Close connection
http-outgoing-0: Close connection
Connection manager shut down
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 1][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://localhost:50070
Connecting to localhost/127.0.0.1:50070
Connection established 127.0.0.1:50277<->127.0.0.1:50070
Executing request PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-1 >> PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1
http-outgoing-1 >> Content-Length: 0
http-outgoing-1 >> Host: localhost:50070
http-outgoing-1 >> Connection: Keep-Alive
http-outgoing-1 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-1 >> Accept-Encoding: gzip,deflate
http-outgoing-1 >> "PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1[\r][\n]"
http-outgoing-1 >> "Content-Length: 0[\r][\n]"
http-outgoing-1 >> "Host: localhost:50070[\r][\n]"
http-outgoing-1 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-1 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-1 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-1 >> "[\r][\n]"
http-outgoing-1 << "HTTP/1.1 307 TEMPORARY_REDIRECT[\r][\n]"
http-outgoing-1 << "Cache-Control: no-cache[\r][\n]"
http-outgoing-1 << "Expires: Sun, 14 Jun 2015 03:39:22 GMT[\r][\n]"
http-outgoing-1 << "Date: Sun, 14 Jun 2015 03:39:22 GMT[\r][\n]"
http-outgoing-1 << "Pragma: no-cache[\r][\n]"
http-outgoing-1 << "Expires: Sun, 14 Jun 2015 03:39:22 GMT[\r][\n]"
http-outgoing-1 << "Date: Sun, 14 Jun 2015 03:39:22 GMT[\r][\n]"
http-outgoing-1 << "Pragma: no-cache[\r][\n]"
http-outgoing-1 << "Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434289162505&s=BUb7gP24UZy3hj+3UegZpK/RHLw="; Path=/; Expires=Sun, 14-Jun-2015 13:39:22 GMT; HttpOnly[\r][\n]"
http-outgoing-1 << "Location: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true[\r][\n]"
http-outgoing-1 << "Content-Type: application/octet-stream[\r][\n]"
http-outgoing-1 << "Content-Length: 0[\r][\n]"
http-outgoing-1 << "Server: Jetty(6.1.26)[\r][\n]"
http-outgoing-1 << "[\r][\n]"
http-outgoing-1 << HTTP/1.1 307 TEMPORARY_REDIRECT
http-outgoing-1 << Cache-Control: no-cache
http-outgoing-1 << Expires: Sun, 14 Jun 2015 03:39:22 GMT
http-outgoing-1 << Date: Sun, 14 Jun 2015 03:39:22 GMT
http-outgoing-1 << Pragma: no-cache
http-outgoing-1 << Expires: Sun, 14 Jun 2015 03:39:22 GMT
http-outgoing-1 << Date: Sun, 14 Jun 2015 03:39:22 GMT
http-outgoing-1 << Pragma: no-cache
http-outgoing-1 << Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434289162505&s=BUb7gP24UZy3hj+3UegZpK/RHLw="; Path=/; Expires=Sun, 14-Jun-2015 13:39:22 GMT; HttpOnly
http-outgoing-1 << Location: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
http-outgoing-1 << Content-Type: application/octet-stream
http-outgoing-1 << Content-Length: 0
http-outgoing-1 << Server: Jetty(6.1.26)
Connection can be kept alive indefinitely
Cookie accepted [hadoop.auth=""u=michaeljones&p=michaeljones&t=simple&e=1434289162505&s=BUb7gP24UZy3hj+3UegZpK/RHLw="", version:0, domain:localhost, path:/, expiry:Sun Jun 14 23:39:22 AEST 2015]
Redirect to: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
http-outgoing-1: Shutdown connection
Connection discarded
http-outgoing-1: Close connection
Connection released: [id: 1][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 2][route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://michaels-air.bigpond:50075
Connecting to michaels-air.bigpond/10.0.0.2:50075
Connection established 10.0.0.2:50278<->10.0.0.2:50075
Executing request PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-2 >> PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1
http-outgoing-2 >> Content-Length: 0
http-outgoing-2 >> Host: michaels-air.bigpond:50075
http-outgoing-2 >> Connection: Keep-Alive
http-outgoing-2 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-2 >> Accept-Encoding: gzip,deflate
http-outgoing-2 >> "PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1[\r][\n]"
http-outgoing-2 >> "Content-Length: 0[\r][\n]"
http-outgoing-2 >> "Host: michaels-air.bigpond:50075[\r][\n]"
http-outgoing-2 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-2 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-2 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-2 >> "[\r][\n]"
http-outgoing-2 << "HTTP/1.1 100 Continue[\r][\n]"
http-outgoing-2 << "[\r][\n]"
http-outgoing-2 << HTTP/1.1 100 Continue
http-outgoing-2 << "HTTP/1.1 201 Created[\r][\n]"
http-outgoing-2 << "Location: hdfs://localhost:9000/user/michaeljones/hello-apache-empty.txt[\r][\n]"
http-outgoing-2 << "Content-Length: 0[\r][\n]"
http-outgoing-2 << "Connection: close[\r][\n]"
http-outgoing-2 << "[\r][\n]"
http-outgoing-2 << HTTP/1.1 201 Created
http-outgoing-2 << Location: hdfs://localhost:9000/user/michaeljones/hello-apache-empty.txt
http-outgoing-2 << Content-Length: 0
http-outgoing-2 << Connection: close
http-outgoing-2: Shutdown connection
Connection discarded
http-outgoing-2: Close connection
Connection released: [id: 2][route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection manager is shutting down
Connection manager shut down
Jersey client Redirect to: hdfs://localhost:9000/user/michaeljones/hellohadoop.log
com.sun.jersey.client.property.chunkedEncodingSize: 1048576
Jersey client Redirect to: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/hello.log.2015-06-12?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 3][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://localhost:50070
Connecting to localhost/127.0.0.1:50070
Connection established 127.0.0.1:50288<->127.0.0.1:50070
Executing request PUT /webhdfs/v1/user/michaeljones/README.md?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-3 >> PUT /webhdfs/v1/user/michaeljones/README.md?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1
http-outgoing-3 >> Transfer-Encoding: chunked
http-outgoing-3 >> Content-Type: application/octet-stream
http-outgoing-3 >> Host: localhost:50070
http-outgoing-3 >> Connection: Keep-Alive
http-outgoing-3 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-3 >> Accept-Encoding: gzip,deflate
http-outgoing-3 >> "PUT /webhdfs/v1/user/michaeljones/README.md?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1[\r][\n]"
http-outgoing-3 >> "Transfer-Encoding: chunked[\r][\n]"
http-outgoing-3 >> "Content-Type: application/octet-stream[\r][\n]"
http-outgoing-3 >> "Host: localhost:50070[\r][\n]"
http-outgoing-3 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-3 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-3 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-3 >> "[\r][\n]"
http-outgoing-3 >> "1000[\r][\n]"
http-outgoing-3 >> "# Hello-Hadoop-netbeans-OS-X[\n]"
http-outgoing-3 >> "Java Maven project for playing with the HDFS API without any 3rd party hadoop plugins.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## Aim of project[\n]"
http-outgoing-3 >> "Hello world/tutorial level for programmatically operating with a pseudo distributed hadoop configuration on OS X. Hadoop 2.7 on Yosemite.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## What this project demonstrates[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "This is work in progress and so far the following functionality is demonstrated:[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "1. Direct programmatic control of the HDFS and running map reduce jobs - all unit tests run from the IDE with hadoop configuration built into this project and under git control.[\n]"
http-outgoing-3 >> "2. Uploading of files to the HDFS by implementing a Web REST API client.[\n]"
http-outgoing-3 >> "3. Async file upload (at time of writing only Jersey back end implemented).[\n]"
http-outgoing-3 >> "4. Layered application code for maximum re-use and ease of test driven development. The client I wrote uses an interface which has allowed me to provide both a Jersey HTTP client implementation and an Apache HTTP client implementation for comparison between the two toolkits.[\n]"
http-outgoing-3 >> "5. Test driven development.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## Getting started[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "The initial difficulty was working out how to run the program in the IDE and talk to the local pseudo distributed setup without using a 3rd party Hadoop plugin. Apparently there used to be a plugin for netbeans, but it has been discontinued. I am a newbie with this technology.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "The Apache Hadoop instructions for building and running java programs are via their command line build/run utility only. Getting the yahoo hadoop HDFS tutorial program to build in the IDE wasn't too hard. However, by default it will ignore the local Hadoop configuration and only operate with the local file system in local debug mode.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## Wading through the configuration[\n]"
http-outgoing-3 >> "Hadoop is designed to work with a number of different topologies, directory locations, levels of replication, simulated environments etc. so as we would expect nothing works unless the configuration is right.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "First Hadoop needs to be installed and configured in pseudo distributed mode such that it builds and runs test programs on the command line. The hadoop documentation has instructions for doing this. Documentation is online and also included in the installation: share/doc/hadoop/index.html. However this is not enough to get it to work in the IDE.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## The netbeans project settings that are needed to run with the HDFS from the IDE:[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "1. Get log4j configured to work in the IDE. Absence of log4j configuration won't stop hadoop from running, but we won't get to see useful error messages from hadoop without it.[\n]"
http-outgoing-3 >> "2. HADOOP_HOME environment variable project run (and test) property.[\n]"
http-outgoing-3 >> "3. Duplicate hadoop configuration in the classpath. The above environment variable does not pick up the hadoop configuration from its usual place. Yahoo's only suggestion is to run from the command line via the hadoop script. The Apache HDFS API documention says that configuration is looked for in the classpath, so I took the approach of duplicating the configuration (just 2 files) instead of figuring out how to get it to look in the installation path.[\n]"
http-outgoing-3 >> "4. The correct Maven dependencies. If not all the jar depenencies are there the program may build and run, but it won't talk to the HDFS if it doesn't load the HDFS jars.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "I think that the setup of this project would probably work on Linux too.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## Working through trouble shooting the HDFS project settings[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "Issue 1 above shows up as:[\n]"
http-outgoing-3 >> "<pre><code>[\n]"
http-outgoing-3 >> "log4j:WARN No appenders could be found for logger (org.apache.hadoop.util.Shell).[\n]"
http-outgoing-3 >> "log4j:WARN Please initialize the log4j system properly.[\n]"
http-outgoing-3 >> "log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.[\n]"
http-outgoing-3 >> "</pre></code>[\n]"
http-outgoing-3 >> "This is solved by putting a log4j.properties configuration file in the classpath. For a Maven build getting files into the classpath can be achieved by putting them in src/main/resources. I don't think this is in the classpath, but the build will then copy the file into ./target/classes/ which is in the classpath.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "Issue 2 above shows up as:[\n]"
http-outgoing-3 >> "<pre><code>[\n]"
http-outgoing-3 >> "Failed to detect a valid hadoop home directory[\n]"
http-outgoing-3 >> "java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.[\n]"
http-outgoing-3 >> "</[\r][\n]"
http-outgoing-3 >> "1000[\r][\n]"
http-outgoing-3 >> "code></pre>[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "This is fixed by going into the project properties => Build => Actions => Run Project and adding the environment variable for HADOOP_HOME. This will result in an entry in the Maven POM. Repeat for "Test Project", "Debug Project" etc.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "Issue 3. shows up as running, but creating a file on the local file system instead of the HDFS. This was fixed       looking at the HDFS API documentation for org.apache.hadoop.conf.Configuration. This documentation is under the chapter: C API libhdfs HDFS which has a link to the HDFS API under "The APIs" (I strangely cannot find this in the main index). On my installation the HDFS API documentation link is file:///opt/local/hadoop-2.7.0/share/doc/hadoop/api/org/apache/hadoop/fs/FileSystem.html.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "This documentation told me that hadoop loads core-site.xml and core-default.xml in the classpath. Classpath for a Maven build can be reached by placing these files in the directory src/main/resources (see logging configuration above). I added hdfs-site instead of core-default (which doesn't exist on my 2.7 install) into the src/main/resources project directory.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "Issue 3 shows up as:[\n]"
http-outgoing-3 >> "<pre><code>[\n]"
http-outgoing-3 >> "java.io.IOException: "hadoop No FileSystem for scheme: hdfs".[\n]"
http-outgoing-3 >> "</code></pre>[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "This is part of the build dependency problem. The various threads on stackoverflow etc. suggested that a minimum dependency was the jar for hadoop-core. However, there is no such jar on 2.7. I ran the hadoop command to dump version and got this:[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "<pre><code>[\n]"
http-outgoing-3 >> "bin/hadoop version[\n]"
http-outgoing-3 >> "Hadoop 2.7.0[\n]"
http-outgoing-3 >> "Subversion https://git-wip-us.apache.org/repos/asf/hadoop.git -r d4c8d4d4d203c934e8074b31289a28724c0842cf[\n]"
http-outgoing-3 >> "Compiled by jenkins on 2015-04-10T18:40Z[\n]"
http-outgoing-3 >> "Compiled with protoc 2.5.0[\n]"
http-outgoing-3 >> "From source with checksum a9e90912c37a35c3195d23951fd18f[\n]"
http-outgoing-3 >> "This command was run using /opt/local/hadoop-2.7.0/share/hadoop/common/hadoop-common-2.7.0.jar[\n]"
http-outgoing-3 >> "</code></pre>[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "I noted the jar name at the end and added it as a dependency to the POM. This can either be hand coded in or right click pom.xml => Insert Code => Add Dependency => Search => query hadoop-common and select version which was 2.7.0 [jar] - central. Maven will then add dependencies to other hadoop jars in the "Dependencies" group in the project explorer. Netbeans will then download these dependencies before the next build. They go into ~/.m2/repository should they ever need to be cleaned out (Netbeans doesn't seem to have an IDE remove dependency option).[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "After doing the above project built, but showed up the "no filesystem error". I noticed that Maven had not pulled in any hdfs jars matching the jars in my share/hadoop/hdfs installation directory. So I took a guess that it needed only the top level hadoop-hdfs-2.7.0.jar and added this as a dependency to the POM and all was good :)[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## Working through trouble shooting the Map Reduce project settings[\n]"
http-outgoing-3 >> "After getting the HDFS API working in the IDE it was time to move on to getting the famous Word Count map-reduce tutorial running.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "So coded it, set the main program to the word count main as the one to run. From the IDE: project Properties => Run => Main Class. Provide input and output arguments for the word count program. I noted that the netbeans properties pop-up window does not persist these settings next time it pops up. However this setting is persistant and ends up in nbactions.xml.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "However, running the word count map reduce program resulted in an ioException:[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "<pre><code>[\n]"
http-outgoing-3 >> "Please check your configuration for mapreduce.framework.name and the correspond server addresses.[\n]"
http-outgoing-3 >> "</pre></code>[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "Because the resources directory only contains 2 configuration files from my hadoop installation I thought maybe I was missing a map reduce one. So the first thing I did was go into the configuration directory of my installation and grep all files to see if there was a configuration file with mapreduce framework property. There was not. I checked my programatic configuration dump from my test program. This property was not mentioned either. The only map reduce configuration was to do with some environment variables for heap size in one of the shell scripts. Note to sel[\r][\n]"
http-outgoing-3 >> "c47[\r][\n]"
http-outgoing-3 >> "f: this may be relevant and I can consider setting this in the IDE. However, that didn't look like the problem.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "I then checked my dependencies and noted there were no map reduce jars pulled in by Maven. So I added hadoop-mapreduce-client-core. Still not running. Checked the web and a thread on stackoverflow mentioned a number of other jars: hadoop-mapreduce-client-common and hadoop-mapreduce-client shuffle. I added just the hadoop-mapreduce-client-common and it runs :) I have a feeling that I might need some of the other jars for other API calls and that there must be a better way of working out dependencies than this trial and error. As mentioned I am a newbie with this, so if anyone has any comments feel free to email me.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## Logging from application code[\n]"
http-outgoing-3 >> "Although the hadoop libraries log correctly with a properly located log4.properties file, application code calling the log4j logger seems to ignore this file. Using the log4j logger as per instructions in the log4j manual and many online tutorials did not result in getting any logging redirected to file configured in the properties file. Instead console output only is obtained. A clue to this mystery was that a most basic of hello world netbeans maven projects which did not import any hadoop stuff also failed to log to a file and did not even give the "No appenders" warning. Then I noticed that there were org.sl4j depencies in the hadoop build, so using sl4j instead solved the problem. Once my hello world project used sl4j's LoggerFactory and had sl4j-api and sl4j-12 as a dependencies it started to use the properties file. See http://www.slf4j.org/manual.html[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## Upload a file from local storage to the HDFS via the REST API[\n]"
http-outgoing-3 >> "The WebHDFS REST API documentation which came with the installation specifies that file creation is a two stage operation where an initial PUT to the namenode is sent. This responds with a redirect to the datanode and another PUT should be made to this redirection which can contain the chunked data stream. This does not sound REST to me as it relies on holding redirection state (a fully distributed configuration could presumably return a redirection to any one of the datanodes). Hadoop say this is because of a bug in some HTTP client implementations - incorrect implementation of [0xe2][0x80][0x9c]Expect: 100-continue[0xe2][0x80][0x9d].[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "However, the 2 stage PUT not being REST seems to be a moot point, at least with the Jersey client. I do not get a redirection and a file creates/uploads all in one go.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "Since writing the above paragraph I have implemented the Apache Client back end option to my HDFS Web client interface and this client behaves differently. It does indeed cause a redirect as per Hadoop documentation. The follow up PUT to the redirected location with the chunked file stream works as per documentation.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "Since writing the above paragraph I have implemented a big chunk size setting for the HTTP chunking and this changed the behaviour of the Jersey client to always redirect. It might be that unless the chunk size option is set then the Jersey implementation does not chunk - this would be terrible for big files.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "To be continued ...[\n]"
http-outgoing-3 >> "[\r][\n]"
http-outgoing-3 >> "0[\r][\n]"
http-outgoing-3 >> "[\r][\n]"
http-outgoing-3 << "HTTP/1.1 307 TEMPORARY_REDIRECT[\r][\n]"
http-outgoing-3 << "Cache-Control: no-cache[\r][\n]"
http-outgoing-3 << "Expires: Sun, 14 Jun 2015 03:39:23 GMT[\r][\n]"
http-outgoing-3 << "Date: Sun, 14 Jun 2015 03:39:23 GMT[\r][\n]"
http-outgoing-3 << "Pragma: no-cache[\r][\n]"
http-outgoing-3 << "Expires: Sun, 14 Jun 2015 03:39:23 GMT[\r][\n]"
http-outgoing-3 << "Date: Sun, 14 Jun 2015 03:39:23 GMT[\r][\n]"
http-outgoing-3 << "Pragma: no-cache[\r][\n]"
http-outgoing-3 << "Content-Type: application/octet-stream[\r][\n]"
http-outgoing-3 << "Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434289163249&s=3i9HVXomV4fWQqZtJHuxUydNFx0="; Path=/; Expires=Sun, 14-Jun-2015 13:39:23 GMT; HttpOnly[\r][\n]"
http-outgoing-3 << "Location: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/README.md?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true[\r][\n]"
http-outgoing-3 << "Content-Length: 0[\r][\n]"
http-outgoing-3 << "Server: Jetty(6.1.26)[\r][\n]"
http-outgoing-3 << "[\r][\n]"
http-outgoing-3 << HTTP/1.1 307 TEMPORARY_REDIRECT
http-outgoing-3 << Cache-Control: no-cache
http-outgoing-3 << Expires: Sun, 14 Jun 2015 03:39:23 GMT
http-outgoing-3 << Date: Sun, 14 Jun 2015 03:39:23 GMT
http-outgoing-3 << Pragma: no-cache
http-outgoing-3 << Expires: Sun, 14 Jun 2015 03:39:23 GMT
http-outgoing-3 << Date: Sun, 14 Jun 2015 03:39:23 GMT
http-outgoing-3 << Pragma: no-cache
http-outgoing-3 << Content-Type: application/octet-stream
http-outgoing-3 << Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434289163249&s=3i9HVXomV4fWQqZtJHuxUydNFx0="; Path=/; Expires=Sun, 14-Jun-2015 13:39:23 GMT; HttpOnly
http-outgoing-3 << Location: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/README.md?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
http-outgoing-3 << Content-Length: 0
http-outgoing-3 << Server: Jetty(6.1.26)
Connection can be kept alive indefinitely
Cookie accepted [hadoop.auth=""u=michaeljones&p=michaeljones&t=simple&e=1434289163249&s=3i9HVXomV4fWQqZtJHuxUydNFx0="", version:0, domain:localhost, path:/, expiry:Sun Jun 14 23:39:23 AEST 2015]
Redirect to: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/README.md?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
http-outgoing-3: Shutdown connection
Connection discarded
http-outgoing-3: Close connection
Connection released: [id: 3][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 4][route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://michaels-air.bigpond:50075
Connecting to michaels-air.bigpond/10.0.0.2:50075
Connection established 10.0.0.2:50289<->10.0.0.2:50075
Executing request PUT /webhdfs/v1/user/michaeljones/README.md?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-4 >> PUT /webhdfs/v1/user/michaeljones/README.md?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1
http-outgoing-4 >> Transfer-Encoding: chunked
http-outgoing-4 >> Content-Type: application/octet-stream
http-outgoing-4 >> Host: michaels-air.bigpond:50075
http-outgoing-4 >> Connection: Keep-Alive
http-outgoing-4 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-4 >> Accept-Encoding: gzip,deflate
http-outgoing-4 >> "PUT /webhdfs/v1/user/michaeljones/README.md?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1[\r][\n]"
http-outgoing-4 >> "Transfer-Encoding: chunked[\r][\n]"
http-outgoing-4 >> "Content-Type: application/octet-stream[\r][\n]"
http-outgoing-4 >> "Host: michaels-air.bigpond:50075[\r][\n]"
http-outgoing-4 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-4 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-4 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-4 >> "[\r][\n]"
http-outgoing-4 >> "1000[\r][\n]"
http-outgoing-4 >> "# Hello-Hadoop-netbeans-OS-X[\n]"
http-outgoing-4 >> "Java Maven project for playing with the HDFS API without any 3rd party hadoop plugins.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## Aim of project[\n]"
http-outgoing-4 >> "Hello world/tutorial level for programmatically operating with a pseudo distributed hadoop configuration on OS X. Hadoop 2.7 on Yosemite.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## What this project demonstrates[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "This is work in progress and so far the following functionality is demonstrated:[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "1. Direct programmatic control of the HDFS and running map reduce jobs - all unit tests run from the IDE with hadoop configuration built into this project and under git control.[\n]"
http-outgoing-4 >> "2. Uploading of files to the HDFS by implementing a Web REST API client.[\n]"
http-outgoing-4 >> "3. Async file upload (at time of writing only Jersey back end implemented).[\n]"
http-outgoing-4 >> "4. Layered application code for maximum re-use and ease of test driven development. The client I wrote uses an interface which has allowed me to provide both a Jersey HTTP client implementation and an Apache HTTP client implementation for comparison between the two toolkits.[\n]"
http-outgoing-4 >> "5. Test driven development.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## Getting started[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "The initial difficulty was working out how to run the program in the IDE and talk to the local pseudo distributed setup without using a 3rd party Hadoop plugin. Apparently there used to be a plugin for netbeans, but it has been discontinued. I am a newbie with this technology.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "The Apache Hadoop instructions for building and running java programs are via their command line build/run utility only. Getting the yahoo hadoop HDFS tutorial program to build in the IDE wasn't too hard. However, by default it will ignore the local Hadoop configuration and only operate with the local file system in local debug mode.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## Wading through the configuration[\n]"
http-outgoing-4 >> "Hadoop is designed to work with a number of different topologies, directory locations, levels of replication, simulated environments etc. so as we would expect nothing works unless the configuration is right.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "First Hadoop needs to be installed and configured in pseudo distributed mode such that it builds and runs test programs on the command line. The hadoop documentation has instructions for doing this. Documentation is online and also included in the installation: share/doc/hadoop/index.html. However this is not enough to get it to work in the IDE.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## The netbeans project settings that are needed to run with the HDFS from the IDE:[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "1. Get log4j configured to work in the IDE. Absence of log4j configuration won't stop hadoop from running, but we won't get to see useful error messages from hadoop without it.[\n]"
http-outgoing-4 >> "2. HADOOP_HOME environment variable project run (and test) property.[\n]"
http-outgoing-4 >> "3. Duplicate hadoop configuration in the classpath. The above environment variable does not pick up the hadoop configuration from its usual place. Yahoo's only suggestion is to run from the command line via the hadoop script. The Apache HDFS API documention says that configuration is looked for in the classpath, so I took the approach of duplicating the configuration (just 2 files) instead of figuring out how to get it to look in the installation path.[\n]"
http-outgoing-4 >> "4. The correct Maven dependencies. If not all the jar depenencies are there the program may build and run, but it won't talk to the HDFS if it doesn't load the HDFS jars.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "I think that the setup of this project would probably work on Linux too.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## Working through trouble shooting the HDFS project settings[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "Issue 1 above shows up as:[\n]"
http-outgoing-4 >> "<pre><code>[\n]"
http-outgoing-4 >> "log4j:WARN No appenders could be found for logger (org.apache.hadoop.util.Shell).[\n]"
http-outgoing-4 >> "log4j:WARN Please initialize the log4j system properly.[\n]"
http-outgoing-4 >> "log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.[\n]"
http-outgoing-4 >> "</pre></code>[\n]"
http-outgoing-4 >> "This is solved by putting a log4j.properties configuration file in the classpath. For a Maven build getting files into the classpath can be achieved by putting them in src/main/resources. I don't think this is in the classpath, but the build will then copy the file into ./target/classes/ which is in the classpath.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "Issue 2 above shows up as:[\n]"
http-outgoing-4 >> "<pre><code>[\n]"
http-outgoing-4 >> "Failed to detect a valid hadoop home directory[\n]"
http-outgoing-4 >> "java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.[\n]"
http-outgoing-4 >> "</[\r][\n]"
http-outgoing-4 >> "1000[\r][\n]"
http-outgoing-4 >> "code></pre>[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "This is fixed by going into the project properties => Build => Actions => Run Project and adding the environment variable for HADOOP_HOME. This will result in an entry in the Maven POM. Repeat for "Test Project", "Debug Project" etc.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "Issue 3. shows up as running, but creating a file on the local file system instead of the HDFS. This was fixed       looking at the HDFS API documentation for org.apache.hadoop.conf.Configuration. This documentation is under the chapter: C API libhdfs HDFS which has a link to the HDFS API under "The APIs" (I strangely cannot find this in the main index). On my installation the HDFS API documentation link is file:///opt/local/hadoop-2.7.0/share/doc/hadoop/api/org/apache/hadoop/fs/FileSystem.html.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "This documentation told me that hadoop loads core-site.xml and core-default.xml in the classpath. Classpath for a Maven build can be reached by placing these files in the directory src/main/resources (see logging configuration above). I added hdfs-site instead of core-default (which doesn't exist on my 2.7 install) into the src/main/resources project directory.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "Issue 3 shows up as:[\n]"
http-outgoing-4 >> "<pre><code>[\n]"
http-outgoing-4 >> "java.io.IOException: "hadoop No FileSystem for scheme: hdfs".[\n]"
http-outgoing-4 >> "</code></pre>[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "This is part of the build dependency problem. The various threads on stackoverflow etc. suggested that a minimum dependency was the jar for hadoop-core. However, there is no such jar on 2.7. I ran the hadoop command to dump version and got this:[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "<pre><code>[\n]"
http-outgoing-4 >> "bin/hadoop version[\n]"
http-outgoing-4 >> "Hadoop 2.7.0[\n]"
http-outgoing-4 >> "Subversion https://git-wip-us.apache.org/repos/asf/hadoop.git -r d4c8d4d4d203c934e8074b31289a28724c0842cf[\n]"
http-outgoing-4 >> "Compiled by jenkins on 2015-04-10T18:40Z[\n]"
http-outgoing-4 >> "Compiled with protoc 2.5.0[\n]"
http-outgoing-4 >> "From source with checksum a9e90912c37a35c3195d23951fd18f[\n]"
http-outgoing-4 >> "This command was run using /opt/local/hadoop-2.7.0/share/hadoop/common/hadoop-common-2.7.0.jar[\n]"
http-outgoing-4 >> "</code></pre>[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "I noted the jar name at the end and added it as a dependency to the POM. This can either be hand coded in or right click pom.xml => Insert Code => Add Dependency => Search => query hadoop-common and select version which was 2.7.0 [jar] - central. Maven will then add dependencies to other hadoop jars in the "Dependencies" group in the project explorer. Netbeans will then download these dependencies before the next build. They go into ~/.m2/repository should they ever need to be cleaned out (Netbeans doesn't seem to have an IDE remove dependency option).[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "After doing the above project built, but showed up the "no filesystem error". I noticed that Maven had not pulled in any hdfs jars matching the jars in my share/hadoop/hdfs installation directory. So I took a guess that it needed only the top level hadoop-hdfs-2.7.0.jar and added this as a dependency to the POM and all was good :)[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## Working through trouble shooting the Map Reduce project settings[\n]"
http-outgoing-4 >> "After getting the HDFS API working in the IDE it was time to move on to getting the famous Word Count map-reduce tutorial running.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "So coded it, set the main program to the word count main as the one to run. From the IDE: project Properties => Run => Main Class. Provide input and output arguments for the word count program. I noted that the netbeans properties pop-up window does not persist these settings next time it pops up. However this setting is persistant and ends up in nbactions.xml.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "However, running the word count map reduce program resulted in an ioException:[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "<pre><code>[\n]"
http-outgoing-4 >> "Please check your configuration for mapreduce.framework.name and the correspond server addresses.[\n]"
http-outgoing-4 >> "</pre></code>[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "Because the resources directory only contains 2 configuration files from my hadoop installation I thought maybe I was missing a map reduce one. So the first thing I did was go into the configuration directory of my installation and grep all files to see if there was a configuration file with mapreduce framework property. There was not. I checked my programatic configuration dump from my test program. This property was not mentioned either. The only map reduce configuration was to do with some environment variables for heap size in one of the shell scripts. Note to sel[\r][\n]"
http-outgoing-4 >> "c47[\r][\n]"
http-outgoing-4 >> "f: this may be relevant and I can consider setting this in the IDE. However, that didn't look like the problem.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "I then checked my dependencies and noted there were no map reduce jars pulled in by Maven. So I added hadoop-mapreduce-client-core. Still not running. Checked the web and a thread on stackoverflow mentioned a number of other jars: hadoop-mapreduce-client-common and hadoop-mapreduce-client shuffle. I added just the hadoop-mapreduce-client-common and it runs :) I have a feeling that I might need some of the other jars for other API calls and that there must be a better way of working out dependencies than this trial and error. As mentioned I am a newbie with this, so if anyone has any comments feel free to email me.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## Logging from application code[\n]"
http-outgoing-4 >> "Although the hadoop libraries log correctly with a properly located log4.properties file, application code calling the log4j logger seems to ignore this file. Using the log4j logger as per instructions in the log4j manual and many online tutorials did not result in getting any logging redirected to file configured in the properties file. Instead console output only is obtained. A clue to this mystery was that a most basic of hello world netbeans maven projects which did not import any hadoop stuff also failed to log to a file and did not even give the "No appenders" warning. Then I noticed that there were org.sl4j depencies in the hadoop build, so using sl4j instead solved the problem. Once my hello world project used sl4j's LoggerFactory and had sl4j-api and sl4j-12 as a dependencies it started to use the properties file. See http://www.slf4j.org/manual.html[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## Upload a file from local storage to the HDFS via the REST API[\n]"
http-outgoing-4 >> "The WebHDFS REST API documentation which came with the installation specifies that file creation is a two stage operation where an initial PUT to the namenode is sent. This responds with a redirect to the datanode and another PUT should be made to this redirection which can contain the chunked data stream. This does not sound REST to me as it relies on holding redirection state (a fully distributed configuration could presumably return a redirection to any one of the datanodes). Hadoop say this is because of a bug in some HTTP client implementations - incorrect implementation of [0xe2][0x80][0x9c]Expect: 100-continue[0xe2][0x80][0x9d].[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "However, the 2 stage PUT not being REST seems to be a moot point, at least with the Jersey client. I do not get a redirection and a file creates/uploads all in one go.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "Since writing the above paragraph I have implemented the Apache Client back end option to my HDFS Web client interface and this client behaves differently. It does indeed cause a redirect as per Hadoop documentation. The follow up PUT to the redirected location with the chunked file stream works as per documentation.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "Since writing the above paragraph I have implemented a big chunk size setting for the HTTP chunking and this changed the behaviour of the Jersey client to always redirect. It might be that unless the chunk size option is set then the Jersey implementation does not chunk - this would be terrible for big files.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "To be continued ...[\n]"
http-outgoing-4 >> "[\r][\n]"
http-outgoing-4 >> "0[\r][\n]"
http-outgoing-4 >> "[\r][\n]"
http-outgoing-4 << "HTTP/1.1 100 Continue[\r][\n]"
http-outgoing-4 << "[\r][\n]"
http-outgoing-4 << HTTP/1.1 100 Continue
http-outgoing-4 << "HTTP/1.1 201 Created[\r][\n]"
http-outgoing-4 << "Location: hdfs://localhost:9000/user/michaeljones/README.md[\r][\n]"
http-outgoing-4 << "Content-Length: 0[\r][\n]"
http-outgoing-4 << "Connection: close[\r][\n]"
http-outgoing-4 << "[\r][\n]"
http-outgoing-4 << HTTP/1.1 201 Created
http-outgoing-4 << Location: hdfs://localhost:9000/user/michaeljones/README.md
http-outgoing-4 << Content-Length: 0
http-outgoing-4 << Connection: close
http-outgoing-4: Shutdown connection
Connection discarded
http-outgoing-4: Close connection
Connection released: [id: 4][route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection manager is shutting down
Connection manager shut down
com.sun.jersey.client.property.chunkedEncodingSize: 1048576
Jersey client Redirect to: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/nbactions.xml?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
com.sun.jersey.client.property.chunkedEncodingSize: 1048576
Jersey client Redirect to: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/nbactions.xml?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
testUploadFileAsync: redirect: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/nbactions.xml?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
Connection manager is shutting down
Connection manager shut down
com.sun.jersey.client.property.chunkedEncodingSize: 1048576
com.sun.jersey.client.property.chunkedEncodingSize: 1048576
Jersey client Redirect to: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/hellohadoop.log.2015-06-12?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
Jersey client Redirect to: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/hellohadoop.log.2015-06-13?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
setsid is not available on this machine. So not using it.
setsid exited with exit code 0
field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName=Ops, always=false, about=, type=DEFAULT, value=[Rate of successful kerberos logins and latency (milliseconds)], valueName=Time)
field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName=Ops, always=false, about=, type=DEFAULT, value=[Rate of failed kerberos logins and latency (milliseconds)], valueName=Time)
field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName=Ops, always=false, about=, type=DEFAULT, value=[GetGroups], valueName=Time)
UgiMetrics, User and group related metrics
Kerberos krb5 configuration not found, setting default realm to empty
 Creating new Groups object
Trying to load the custom-built native-hadoop library...
Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
java.library.path=/Applications/NetBeans/NetBeans 8.0.2.app/Contents/Resources/NetBeans/webcommon/bin::/Users/michaeljones/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:.
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Falling back to shell based
Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
hadoop login
hadoop login commit
using local user:UnixPrincipal: michaeljones
Using user: "UnixPrincipal: michaeljones" with name michaeljones
User entry: "michaeljones"
UGI loginUser:michaeljones (auth:SIMPLE)
dfs.client.use.legacy.blockreader.local = false
dfs.client.read.shortcircuit = false
dfs.client.domain.socket.data.traffic = false
dfs.domain.socket.path = 
multipleLinearRandomRetry = null
rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWrapper, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@463b4ac8
getting client out of cache: org.apache.hadoop.ipc.Client@4351c8c3
Both short-circuit local reads and UNIX domain socket are disabled.
DataTransferProtocol not using SaslPropertiesResolver, no QOP found in configuration for dfs.data.transfer.protection
The ping interval is 60000 ms.
Connecting to localhost/127.0.0.1:9000
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones: starting, having connections 1
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones sending #0
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones got value #0
Call: getFileInfo took 139ms
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones sending #1
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones got value #1
Call: delete took 24ms
/user/michaeljones/hello.txt: masked=rw-r--r--
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones sending #2
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones got value #2
Call: create took 3ms
computePacketChunkSize: src=/user/michaeljones/hello.txt, chunkSize=516, chunksPerPacket=126, packetSize=65016
Lease renewer daemon for [DFSClient_NONMAPREDUCE_-280286310_1] with renew id 1 started
DFSClient writeChunk allocating new packet seqno=0, src=/user/michaeljones/hello.txt, packetSize=65016, chunksPerPacket=126, bytesCurBlock=0
Queued packet 0
Allocating new block
Queued packet 1
Waiting for ack for: 1
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones sending #3
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones got value #3
Call: addBlock took 4ms
pipeline = DatanodeInfoWithStorage[127.0.0.1:50010,DS-b42c5705-9ba4-4b14-b00b-f9194bb036f0,DISK]
Connecting to datanode 127.0.0.1:50010
Send buf size 131072
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones sending #4
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones got value #4
Call: getServerDefaults took 2ms
SASL client skipping handshake in unsecured configuration for addr = /127.0.0.1, datanodeId = DatanodeInfoWithStorage[127.0.0.1:50010,DS-b42c5705-9ba4-4b14-b00b-f9194bb036f0,DISK]
DataStreamer block BP-1045030256-10.0.0.2-1433119149314:blk_1073742377_1554 sending packet packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 20
DFSClient seqno: 0 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
DataStreamer block BP-1045030256-10.0.0.2-1433119149314:blk_1073742377_1554 sending packet packet seqno: 1 offsetInBlock: 20 lastPacketInBlock: true lastByteOffsetInBlock: 20
DFSClient seqno: 1 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones sending #5
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones got value #5
Call: complete took 3ms
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones sending #6
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones got value #6
Call: getBlockLocations took 26ms
newInfo = LocatedBlocks{
  fileLength=20
  underConstruction=false
  blocks=[LocatedBlock{BP-1045030256-10.0.0.2-1433119149314:blk_1073742377_1554; getBlockSize()=20; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-b42c5705-9ba4-4b14-b00b-f9194bb036f0,DISK]]}]
  lastLocatedBlock=LocatedBlock{BP-1045030256-10.0.0.2-1433119149314:blk_1073742377_1554; getBlockSize()=20; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-b42c5705-9ba4-4b14-b00b-f9194bb036f0,DISK]]}
  isLastBlockComplete=true}
Connecting to datanode 127.0.0.1:50010
SASL client skipping handshake in unsecured configuration for addr = /127.0.0.1, datanodeId = DatanodeInfoWithStorage[127.0.0.1:50010,DS-b42c5705-9ba4-4b14-b00b-f9194bb036f0,DISK]
testMain
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones sending #7
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones got value #7
Call: getFileInfo took 3ms
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones sending #8
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones got value #8
Call: delete took 4ms
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.connect(Job.java:1256)
Trying ClientProtocolProvider : org.apache.hadoop.mapred.LocalClientProtocolProvider
session.id is deprecated. Instead, use dfs.metrics.session-id
Initializing JVM Metrics with processName=JobTracker, sessionId=
Picked org.apache.hadoop.mapred.LocalClientProtocolProvider as the ClientProtocolProvider
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Cluster.getFileSystem(Cluster.java:162)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.submit(Job.java:1287)
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones sending #9
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones got value #9
Call: getFileInfo took 2ms
Configuring job job_local1072276750_0001 with file:/tmp/hadoop-michaeljones/mapred/staging/michaeljones1072276750/.staging/job_local1072276750_0001 as the submit dir
adding the following namenodes' delegation tokens:[hdfs://localhost:9000]
Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
default FileSystem: file:///
No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
Creating splits at file:/tmp/hadoop-michaeljones/mapred/staging/michaeljones1072276750/.staging/job_local1072276750_0001
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones sending #10
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones got value #10
Call: getFileInfo took 2ms
Time taken to get FileStatuses: 8
Total input paths to process : 1
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones sending #11
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones got value #11
Call: getBlockLocations took 4ms
Total # of splits generated by getSplits: 1, TimeTaken: 51
number of splits:1
Handling deprecation for all properties in config...
Handling deprecation for mapreduce.jobtracker.address
Handling deprecation for yarn.resourcemanager.scheduler.monitor.policies
Handling deprecation for dfs.namenode.resource.check.interval
Handling deprecation for mapreduce.jobhistory.client.thread-count
Handling deprecation for yarn.app.mapreduce.am.containerlauncher.threadpool-initial-size
Handling deprecation for mapred.child.java.opts
Handling deprecation for mapreduce.jobtracker.retiredjobs.cache.size
Handling deprecation for dfs.client.https.need-auth
Handling deprecation for yarn.admin.acl
Handling deprecation for yarn.app.mapreduce.am.job.committer.cancel-timeout
Handling deprecation for mapreduce.job.emit-timeline-data
Handling deprecation for fs.ftp.host.port
Handling deprecation for dfs.namenode.avoid.read.stale.datanode
Handling deprecation for dfs.journalnode.rpc-address
Handling deprecation for mapreduce.job.end-notification.retry.attempts
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.ttl-interval-ms
Handling deprecation for yarn.resourcemanager.leveldb-state-store.path
Handling deprecation for mapred.mapper.new-api
Handling deprecation for yarn.ipc.rpc.class
Handling deprecation for ipc.client.connection.maxidletime
Handling deprecation for yarn.nodemanager.process-kill-wait.ms
Handling deprecation for mapreduce.cluster.acls.enabled
Handling deprecation for mapreduce.jobtracker.handler.count
Handling deprecation for io.map.index.interval
Handling deprecation for dfs.namenode.https-address
Handling deprecation for mapreduce.task.profile.reduces
Handling deprecation for fs.s3n.multipart.uploads.enabled
Handling deprecation for io.seqfile.sorter.recordlimit
Handling deprecation for mapreduce.job.ubertask.maxmaps
Handling deprecation for mapreduce.tasktracker.tasks.sleeptimebeforesigkill
Handling deprecation for hadoop.util.hash.type
Handling deprecation for dfs.namenode.replication.min
Handling deprecation for yarn.nodemanager.container-manager.thread-count
Handling deprecation for mapreduce.jobtracker.jobhistory.block.size
Handling deprecation for dfs.namenode.fs-limits.min-block-size
Handling deprecation for mapreduce.app-submission.cross-platform
Handling deprecation for fs.AbstractFileSystem.file.impl
Handling deprecation for net.topology.script.number.args
Handling deprecation for yarn.resourcemanager.container-tokens.master-key-rolling-interval-secs
Handling deprecation for mapreduce.map.output.compress.codec
Handling deprecation for mapreduce.job.reducer.preempt.delay.sec
Handling deprecation for s3native.bytes-per-checksum
Handling deprecation for dfs.namenode.path.based.cache.block.map.allocation.percent
Handling deprecation for yarn.nodemanager.windows-container.memory-limit.enabled
Handling deprecation for mapreduce.input.fileinputformat.split.minsize
Handling deprecation for hadoop.security.group.mapping
Handling deprecation for mapreduce.jobtracker.system.dir
Handling deprecation for mapreduce.job.end-notification.max.attempts
Handling deprecation for mapreduce.reduce.markreset.buffer.percent
Handling deprecation for dfs.datanode.cache.revocation.polling.ms
Handling deprecation for mapreduce.reduce.speculative
Handling deprecation for yarn.nodemanager.localizer.cache.cleanup.interval-ms
Handling deprecation for dfs.namenode.lazypersist.file.scrub.interval.sec
Handling deprecation for fs.s3a.threads.core
Handling deprecation for mapreduce.jobhistory.recovery.store.fs.uri
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.start-time-read-cache-size
Handling deprecation for hadoop.registry.zk.retry.interval.ms
Handling deprecation for yarn.nodemanager.keytab
Handling deprecation for dfs.namenode.replication.interval
Handling deprecation for yarn.resourcemanager.admin.address
Handling deprecation for mapreduce.job.maps
Handling deprecation for nfs.dump.dir
Handling deprecation for mapreduce.job.user.name
Handling deprecation for mapreduce.jobtracker.maxtasks.perjob
Handling deprecation for mapreduce.job.ubertask.enable
Handling deprecation for mapreduce.job.reduce.class
Handling deprecation for yarn.nodemanager.delete.debug-delay-sec
Handling deprecation for yarn.timeline-service.ttl-enable
Handling deprecation for yarn.resourcemanager.fs.state-store.retry-policy-spec
Handling deprecation for mapreduce.reduce.skip.maxgroups
Handling deprecation for dfs.client.use.datanode.hostname
Handling deprecation for fs.trash.interval
Handling deprecation for mapreduce.job.name
Handling deprecation for mapreduce.am.max-attempts
Handling deprecation for mapreduce.jobtracker.heartbeats.in.second
Handling deprecation for yarn.resourcemanager.zk-num-retries
Handling deprecation for s3.blocksize
Handling deprecation for dfs.datanode.data.dir
Handling deprecation for mapreduce.jobtracker.persist.jobstatus.active
Handling deprecation for mapreduce.reduce.shuffle.parallelcopies
Handling deprecation for fs.s3.buffer.dir
Handling deprecation for mapreduce.jobhistory.done-dir
Handling deprecation for hadoop.security.instrumentation.requires.admin
Handling deprecation for hadoop.registry.zk.retry.ceiling.ms
Handling deprecation for nfs.rtmax
Handling deprecation for dfs.datanode.data.dir.perm
Handling deprecation for yarn.resourcemanager.container.liveness-monitor.interval-ms
Handling deprecation for yarn.nodemanager.env-whitelist
Handling deprecation for dfs.namenode.backup.address
Handling deprecation for dfs.namenode.xattrs.enabled
Handling deprecation for dfs.datanode.readahead.bytes
Handling deprecation for mapreduce.jobhistory.cleaner.enable
Handling deprecation for dfs.client.block.write.retries
Handling deprecation for mapreduce.tasktracker.http.address
Handling deprecation for yarn.nodemanager.linux-container-executor.cgroups.hierarchy
Handling deprecation for ha.failover-controller.graceful-fence.connection.retries
Handling deprecation for yarn.resourcemanager.recovery.enabled
Handling deprecation for yarn.app.mapreduce.am.container.log.backups
Handling deprecation for dfs.namenode.safemode.threshold-pct
Handling deprecation for yarn.nodemanager.disk-health-checker.interval-ms
Handling deprecation for hadoop.security.java.secure.random.algorithm
Handling deprecation for dfs.namenode.list.cache.directives.num.responses
Handling deprecation for dfs.datanode.dns.nameserver
Handling deprecation for mapreduce.cluster.temp.dir
Handling deprecation for fs.s3a.max.total.tasks
Handling deprecation for mapreduce.reduce.maxattempts
Handling deprecation for mapreduce.client.submit.file.replication
Handling deprecation for mapreduce.shuffle.port
Handling deprecation for yarn.resourcemanager.resource-tracker.client.thread-count
Handling deprecation for dfs.namenode.replication.considerLoad
Handling deprecation for dfs.namenode.edits.journal-plugin.qjournal
Handling deprecation for dfs.client.write.exclude.nodes.cache.expiry.interval.millis
Handling deprecation for yarn.nodemanager.delete.thread-count
Handling deprecation for dfs.client.mmap.cache.timeout.ms
Handling deprecation for yarn.nodemanager.admin-env
Handling deprecation for io.skip.checksum.errors
Handling deprecation for yarn.timeline-service.hostname
Handling deprecation for yarn.resourcemanager.proxy-user-privileges.enabled
Handling deprecation for mapreduce.job.speculative.speculative-cap-total-tasks
Handling deprecation for yarn.acl.enable
Handling deprecation for fs.s3a.fast.upload
Handling deprecation for file.blocksize
Handling deprecation for mapreduce.job.speculative.slowtaskthreshold
Handling deprecation for ftp.replication
Handling deprecation for yarn.sharedcache.cleaner.initial-delay-mins
Handling deprecation for s3native.client-write-packet-size
Handling deprecation for hadoop.rpc.socket.factory.class.default
Handling deprecation for file.bytes-per-checksum
Handling deprecation for dfs.datanode.slow.io.warning.threshold.ms
Handling deprecation for io.seqfile.lazydecompress
Handling deprecation for mapreduce.task.skip.start.attempts
Handling deprecation for dfs.namenode.reject-unresolved-dn-topology-mapping
Handling deprecation for hadoop.common.configuration.version
Handling deprecation for yarn.resourcemanager.client.thread-count
Handling deprecation for dfs.datanode.drop.cache.behind.reads
Handling deprecation for yarn.sharedcache.admin.address
Handling deprecation for mapreduce.job.output.value.class
Handling deprecation for mapreduce.output.fileoutputformat.outputdir
Handling deprecation for mapreduce.jobtracker.taskcache.levels
Handling deprecation for yarn.nodemanager.linux-container-executor.nonsecure-mode.user-pattern
Handling deprecation for yarn.resourcemanager.zk-timeout-ms
Handling deprecation for yarn.resourcemanager.max-completed-applications
Handling deprecation for mapreduce.job.jvm.numtasks
Handling deprecation for yarn.sharedcache.cleaner.period-mins
Handling deprecation for mapreduce.jobtracker.tasktracker.maxblacklists
Handling deprecation for dfs.namenode.top.num.users
Handling deprecation for yarn.nodemanager.linux-container-executor.cgroups.mount
Handling deprecation for yarn.sharedcache.checksum.algo.impl
Handling deprecation for mapreduce.job.end-notification.max.retry.interval
Handling deprecation for mapreduce.job.acl-view-job
Handling deprecation for mapreduce.job.classloader
Handling deprecation for yarn.log-aggregation-enable
Handling deprecation for mapreduce.reduce.shuffle.fetch.retry.interval-ms
Handling deprecation for yarn.resourcemanager.nodemanager.minimum.version
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.size
Handling deprecation for yarn.app.mapreduce.am.job.task.listener.thread-count
Handling deprecation for yarn.app.mapreduce.am.resource.cpu-vcores
Handling deprecation for dfs.namenode.edit.log.autoroll.check.interval.ms
Handling deprecation for mapreduce.output.fileoutputformat.compress.type
Handling deprecation for hadoop.hdfs.configuration.version
Handling deprecation for hadoop.security.group.mapping.ldap.search.attr.member
Handling deprecation for yarn.nodemanager.log.retain-seconds
Handling deprecation for yarn.nodemanager.local-cache.max-files-per-directory
Handling deprecation for mapreduce.job.end-notification.retry.interval
Handling deprecation for hadoop.ssl.client.conf
Handling deprecation for yarn.sharedcache.root-dir
Handling deprecation for dfs.journalnode.https-address
Handling deprecation for mapreduce.reduce.shuffle.fetch.retry.timeout-ms
Handling deprecation for dfs.bytes-per-checksum
Handling deprecation for dfs.namenode.max.objects
Handling deprecation for mapreduce.tasktracker.instrumentation
Handling deprecation for dfs.datanode.max.transfer.threads
Handling deprecation for dfs.block.access.key.update.interval
Handling deprecation for mapreduce.jobtracker.jobhistory.task.numberprogresssplits
Handling deprecation for mapreduce.map.memory.mb
Handling deprecation for ha.failover-controller.new-active.rpc-timeout.ms
Handling deprecation for hadoop.ssl.hostname.verifier
Handling deprecation for dfs.client.read.shortcircuit
Handling deprecation for dfs.datanode.hdfs-blocks-metadata.enabled
Handling deprecation for mapreduce.tasktracker.healthchecker.interval
Handling deprecation for dfs.image.transfer.chunksize
Handling deprecation for mapreduce.tasktracker.taskmemorymanager.monitoringinterval
Handling deprecation for dfs.client.https.keystore.resource
Handling deprecation for yarn.resourcemanager.connect.retry-interval.ms
Handling deprecation for yarn.timeline-service.webapp.address
Handling deprecation for s3native.blocksize
Handling deprecation for yarn.scheduler.minimum-allocation-mb
Handling deprecation for yarn.sharedcache.cleaner.resource-sleep-ms
Handling deprecation for net.topology.impl
Handling deprecation for dfs.client.failover.sleep.base.millis
Handling deprecation for dfs.permissions.superusergroup
Handling deprecation for io.seqfile.compress.blocksize
Handling deprecation for hadoop.registry.zk.retry.times
Handling deprecation for fs.AbstractFileSystem.ftp.impl
Handling deprecation for dfs.namenode.checkpoint.edits.dir
Handling deprecation for mapreduce.job.running.reduce.limit
Handling deprecation for dfs.blockreport.initialDelay
Handling deprecation for dfs.namenode.heartbeat.recheck-interval
Handling deprecation for dfs.namenode.safemode.extension
Handling deprecation for yarn.scheduler.maximum-allocation-mb
Handling deprecation for mapreduce.job.reduce.shuffle.consumer.plugin.class
Handling deprecation for yarn.nodemanager.vmem-check-enabled
Handling deprecation for mapreduce.task.io.sort.factor
Handling deprecation for mapreduce.jobtracker.persist.jobstatus.dir
Handling deprecation for dfs.client.failover.sleep.max.millis
Handling deprecation for dfs.namenode.delegation.key.update-interval
Handling deprecation for hadoop.rpc.protection
Handling deprecation for fs.permissions.umask-mode
Handling deprecation for fs.s3.sleepTimeSeconds
Handling deprecation for ha.health-monitor.rpc-timeout.ms
Handling deprecation for hadoop.http.staticuser.user
Handling deprecation for fs.s3a.connection.maximum
Handling deprecation for yarn.nodemanager.linux-container-executor.nonsecure-mode.limit-users
Handling deprecation for fs.s3a.paging.maximum
Handling deprecation for fs.AbstractFileSystem.viewfs.impl
Handling deprecation for fs.ftp.host
Handling deprecation for yarn.nodemanager.linux-container-executor.nonsecure-mode.local-user
Handling deprecation for fs.s3a.impl
Handling deprecation for hadoop.http.authentication.kerberos.keytab
Handling deprecation for dfs.namenode.fs-limits.max-blocks-per-file
Handling deprecation for mapreduce.tasktracker.http.threads
Handling deprecation for mapreduce.tasktracker.dns.nameserver
Handling deprecation for yarn.resourcemanager.am-rm-tokens.master-key-rolling-interval-secs
Handling deprecation for dfs.client.block.write.replace-datanode-on-failure.enable
Handling deprecation for io.compression.codec.bzip2.library
Handling deprecation for mapreduce.map.skip.maxrecords
Handling deprecation for dfs.client.use.legacy.blockreader.local
Handling deprecation for dfs.namenode.checkpoint.dir
Handling deprecation for dfs.namenode.top.windows.minutes
Handling deprecation for mapreduce.job.maxtaskfailures.per.tracker
Handling deprecation for net.topology.node.switch.mapping.impl
Handling deprecation for mapreduce.shuffle.max.connections
Handling deprecation for mapreduce.jobhistory.loadedjobs.cache.size
Handling deprecation for dfs.storage.policy.enabled
Handling deprecation for yarn.client.application-client-protocol.poll-interval-ms
Handling deprecation for yarn.nodemanager.localizer.address
Handling deprecation for dfs.namenode.list.cache.pools.num.responses
Handling deprecation for nfs.server.port
Handling deprecation for mapreduce.client.output.filter
Handling deprecation for yarn.timeline-service.client.best-effort
Handling deprecation for ha.zookeeper.parent-znode
Handling deprecation for mapreduce.jobtracker.persist.jobstatus.hours
Handling deprecation for yarn.sharedcache.admin.thread-count
Handling deprecation for yarn.nodemanager.resource.cpu-vcores
Handling deprecation for dfs.datanode.block-pinning.enabled
Handling deprecation for mapreduce.jobhistory.http.policy
Handling deprecation for yarn.resourcemanager.webapp.delegation-token-auth-filter.enabled
Handling deprecation for mapreduce.job.speculative.retry-after-no-speculate
Handling deprecation for fs.s3a.attempts.maximum
Handling deprecation for s3native.stream-buffer-size
Handling deprecation for io.seqfile.local.dir
Handling deprecation for yarn.log-aggregation.retain-check-interval-seconds
Handling deprecation for fs.s3n.multipart.copy.block.size
Handling deprecation for dfs.encrypt.data.transfer.cipher.key.bitlength
Handling deprecation for dfs.datanode.sync.behind.writes
Handling deprecation for yarn.resourcemanager.zk-acl
Handling deprecation for hadoop.ssl.keystores.factory.class
Handling deprecation for mapreduce.job.split.metainfo.maxsize
Handling deprecation for fs.s3.maxRetries
Handling deprecation for hadoop.security.random.device.file.path
Handling deprecation for yarn.client.nodemanager-connect.max-wait-ms
Handling deprecation for dfs.namenode.stale.datanode.interval
Handling deprecation for mapreduce.task.io.sort.mb
Handling deprecation for yarn.resourcemanager.zk-state-store.parent-path
Handling deprecation for yarn.app.mapreduce.client-am.ipc.max-retries
Handling deprecation for fs.client.resolve.remote.symlinks
Handling deprecation for yarn.nodemanager.linux-container-executor.cgroups.strict-resource-usage
Handling deprecation for hadoop.ssl.enabled.protocols
Handling deprecation for mapreduce.reduce.cpu.vcores
Handling deprecation for yarn.client.failover-retries
Handling deprecation for mapreduce.jobhistory.address
Handling deprecation for hadoop.ssl.enabled
Handling deprecation for dfs.replication.max
Handling deprecation for dfs.namenode.name.dir
Handling deprecation for dfs.datanode.https.address
Handling deprecation for ipc.client.kill.max
Handling deprecation for mapreduce.job.committer.setup.cleanup.needed
Handling deprecation for dfs.client.domain.socket.data.traffic
Handling deprecation for yarn.nodemanager.localizer.cache.target-size-mb
Handling deprecation for yarn.resourcemanager.admin.client.thread-count
Handling deprecation for dfs.block.access.token.enable
Handling deprecation for mapreduce.job.speculative.retry-after-speculate
Handling deprecation for dfs.datanode.address
Handling deprecation for mapreduce.jobtracker.restart.recover
Handling deprecation for ipc.client.connect.max.retries
Handling deprecation for yarn.timeline-service.store-class
Handling deprecation for dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
Handling deprecation for hadoop.tmp.dir
Handling deprecation for dfs.datanode.handler.count
Handling deprecation for yarn.resourcemanager.ha.automatic-failover.embedded
Handling deprecation for yarn.timeline-service.ttl-ms
Handling deprecation for mapreduce.task.profile.map.params
Handling deprecation for yarn.resourcemanager.nodemanagers.heartbeat-interval-ms
Handling deprecation for mapreduce.map.speculative
Handling deprecation for yarn.timeline-service.recovery.enabled
Handling deprecation for mapreduce.job.map.class
Handling deprecation for dfs.namenode.resource.checked.volumes.minimum
Handling deprecation for yarn.nodemanager.recovery.dir
Handling deprecation for mapreduce.job.counters.max
Handling deprecation for yarn.resourcemanager.keytab
Handling deprecation for dfs.namenode.max.extra.edits.segments.retained
Handling deprecation for dfs.webhdfs.user.provider.user.pattern
Handling deprecation for dfs.client.mmap.enabled
Handling deprecation for mapreduce.map.log.level
Handling deprecation for dfs.client.file-block-storage-locations.timeout.millis
Handling deprecation for yarn.client.max-cached-nodemanagers-proxies
Handling deprecation for yarn.app.mapreduce.am.scheduler.heartbeat.interval-ms
Handling deprecation for hadoop.fuse.timer.period
Handling deprecation for fs.trash.checkpoint.interval
Handling deprecation for yarn.sharedcache.app-checker.class
Handling deprecation for dfs.journalnode.http-address
Handling deprecation for yarn.app.mapreduce.am.staging-dir
Handling deprecation for mapreduce.tasktracker.local.dir.minspacestart
Handling deprecation for yarn.nm.liveness-monitor.expiry-interval-ms
Handling deprecation for ha.health-monitor.check-interval.ms
Handling deprecation for mapreduce.reduce.shuffle.merge.percent
Handling deprecation for dfs.namenode.retrycache.heap.percent
Handling deprecation for yarn.nodemanager.docker-container-executor.exec-name
Handling deprecation for ipc.client.connect.timeout
Handling deprecation for yarn.resourcemanager.fs.state-store.retry-interval-ms
Handling deprecation for mapreduce.output.fileoutputformat.compress
Handling deprecation for yarn.nodemanager.local-dirs
Handling deprecation for yarn.nodemanager.recovery.enabled
Handling deprecation for io.native.lib.available
Handling deprecation for yarn.sharedcache.store.in-memory.staleness-period-mins
Handling deprecation for yarn.resourcemanager.am.max-attempts
Handling deprecation for s3.replication
Handling deprecation for mapreduce.input.fileinputformat.inputdir
Handling deprecation for fs.AbstractFileSystem.har.impl
Handling deprecation for dfs.image.compress
Handling deprecation for mapreduce.job.running.map.limit
Handling deprecation for mapreduce.reduce.input.buffer.percent
Handling deprecation for yarn.nodemanager.webapp.address
Handling deprecation for dfs.datanode.available-space-volume-choosing-policy.balanced-space-preference-fraction
Handling deprecation for dfs.namenode.edit.log.autoroll.multiplier.threshold
Handling deprecation for hadoop.security.group.mapping.ldap.ssl
Handling deprecation for dfs.namenode.checkpoint.check.period
Handling deprecation for fs.defaultFS
Handling deprecation for fs.s3a.multipart.size
Handling deprecation for dfs.client.slow.io.warning.threshold.ms
Handling deprecation for yarn.app.mapreduce.am.job.committer.commit-window
Handling deprecation for hadoop.security.group.mapping.ldap.search.attr.group.name
Handling deprecation for yarn.nodemanager.disk-health-checker.max-disk-utilization-per-disk-percentage
Handling deprecation for yarn.nodemanager.container-monitor.procfs-tree.smaps-based-rss.enabled
Handling deprecation for mapreduce.job.submithostname
Handling deprecation for mapreduce.map.sort.spill.percent
Handling deprecation for hadoop.security.crypto.codec.classes.aes.ctr.nopadding
Handling deprecation for dfs.namenode.http-address
Handling deprecation for hadoop.security.groups.negative-cache.secs
Handling deprecation for hadoop.ssl.server.conf
Handling deprecation for mapreduce.ifile.readahead
Handling deprecation for s3native.replication
Handling deprecation for yarn.client.nodemanager-client-async.thread-pool-max-size
Handling deprecation for mapreduce.jobtracker.staging.root.dir
Handling deprecation for mapreduce.jobhistory.admin.address
Handling deprecation for dfs.namenode.startup.delay.block.deletion.sec
Handling deprecation for yarn.nodemanager.health-checker.interval-ms
Handling deprecation for dfs.namenode.checkpoint.max-retries
Handling deprecation for s3.stream-buffer-size
Handling deprecation for ftp.client-write-packet-size
Handling deprecation for dfs.datanode.fsdatasetcache.max.threads.per.volume
Handling deprecation for mapreduce.output.fileoutputformat.compress.codec
Handling deprecation for yarn.timeline-service.keytab
Handling deprecation for yarn.sharedcache.store.in-memory.initial-delay-mins
Handling deprecation for mapreduce.jobhistory.webapp.address
Handling deprecation for mapreduce.task.userlog.limit.kb
Handling deprecation for mapreduce.reduce.shuffle.fetch.retry.enabled
Handling deprecation for yarn.app.mapreduce.task.container.log.backups
Handling deprecation for dfs.heartbeat.interval
Handling deprecation for ha.zookeeper.session-timeout.ms
Handling deprecation for fs.s3a.connection.ssl.enabled
Handling deprecation for yarn.sharedcache.webapp.address
Handling deprecation for hadoop.http.authentication.signature.secret.file
Handling deprecation for hadoop.fuse.connection.timeout
Handling deprecation for mapreduce.input.fileinputformat.numinputfiles
Handling deprecation for yarn.nodemanager.log-aggregation.compression-type
Handling deprecation for ipc.server.max.connections
Handling deprecation for yarn.resourcemanager.work-preserving-recovery.scheduling-wait-ms
Handling deprecation for yarn.nodemanager.log-dirs
Handling deprecation for yarn.app.mapreduce.am.resource.mb
Handling deprecation for hadoop.security.groups.cache.secs
Handling deprecation for mapreduce.job.speculative.minimum-allowed-tasks
Handling deprecation for yarn.nodemanager.container-monitor.interval-ms
Handling deprecation for dfs.datanode.cache.revocation.timeout.ms
Handling deprecation for mapreduce.jobhistory.recovery.store.class
Handling deprecation for mapreduce.task.combine.progress.records
Handling deprecation for s3.client-write-packet-size
Handling deprecation for mapreduce.jobtracker.instrumentation
Handling deprecation for dfs.replication
Handling deprecation for mapreduce.shuffle.transfer.buffer.size
Handling deprecation for hadoop.security.group.mapping.ldap.directory.search.timeout
Handling deprecation for dfs.datanode.available-space-volume-choosing-policy.balanced-space-threshold
Handling deprecation for hadoop.work.around.non.threadsafe.getpwuid
Handling deprecation for yarn.app.mapreduce.client-am.ipc.max-retries-on-timeouts
Handling deprecation for yarn.nodemanager.address
Handling deprecation for mapreduce.tasktracker.taskcontroller
Handling deprecation for mapreduce.tasktracker.indexcache.mb
Handling deprecation for yarn.scheduler.maximum-allocation-vcores
Handling deprecation for mapreduce.job.reduces
Handling deprecation for yarn.nodemanager.sleep-delay-before-sigkill.ms
Handling deprecation for yarn.timeline-service.address
Handling deprecation for yarn.resourcemanager.configuration.provider-class
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.expiry
Handling deprecation for yarn.sharedcache.enabled
Handling deprecation for tfile.io.chunk.size
Handling deprecation for mapreduce.job.acl-modify-job
Handling deprecation for hadoop.registry.zk.session.timeout.ms
Handling deprecation for fs.automatic.close
Handling deprecation for ha.health-monitor.sleep-after-disconnect.ms
Handling deprecation for mapreduce.tasktracker.reduce.tasks.maximum
Handling deprecation for mapreduce.input.fileinputformat.list-status.num-threads
Handling deprecation for dfs.datanode.directoryscan.threads
Handling deprecation for dfs.datanode.directoryscan.interval
Handling deprecation for dfs.namenode.acls.enabled
Handling deprecation for dfs.client.short.circuit.replica.stale.threshold.ms
Handling deprecation for hadoop.http.authentication.token.validity
Handling deprecation for fs.s3.block.size
Handling deprecation for ha.failover-controller.graceful-fence.rpc-timeout.ms
Handling deprecation for mapreduce.tasktracker.local.dir.minspacekill
Handling deprecation for dfs.namenode.resource.du.reserved
Handling deprecation for mapreduce.jobhistory.cleaner.interval-ms
Handling deprecation for dfs.namenode.datanode.registration.ip-hostname-check
Handling deprecation for mapreduce.jobhistory.intermediate-done-dir
Handling deprecation for mapreduce.jobtracker.http.address
Handling deprecation for dfs.namenode.backup.http-address
Handling deprecation for dfs.namenode.edits.noeditlogchannelflush
Handling deprecation for mapreduce.reduce.shuffle.input.buffer.percent
Handling deprecation for mapreduce.map.maxattempts
Handling deprecation for yarn.http.policy
Handling deprecation for dfs.namenode.audit.loggers
Handling deprecation for hadoop.security.groups.cache.warn.after.ms
Handling deprecation for io.serializations
Handling deprecation for mapreduce.tasktracker.outofband.heartbeat
Handling deprecation for mapreduce.reduce.shuffle.read.timeout
Handling deprecation for hadoop.security.crypto.buffer.size
Handling deprecation for mapreduce.reduce.skip.proc.count.autoincr
Handling deprecation for mapreduce.ifile.readahead.bytes
Handling deprecation for dfs.http.policy
Handling deprecation for hadoop.registry.secure
Handling deprecation for dfs.namenode.safemode.min.datanodes
Handling deprecation for dfs.client.file-block-storage-locations.num-threads
Handling deprecation for mapreduce.cluster.local.dir
Handling deprecation for mapreduce.tasktracker.report.address
Handling deprecation for dfs.namenode.secondary.https-address
Handling deprecation for hadoop.kerberos.kinit.command
Handling deprecation for yarn.timeline-service.http-authentication.type
Handling deprecation for dfs.block.access.token.lifetime
Handling deprecation for dfs.webhdfs.enabled
Handling deprecation for dfs.namenode.delegation.token.max-lifetime
Handling deprecation for dfs.namenode.avoid.write.stale.datanode
Handling deprecation for dfs.datanode.drop.cache.behind.writes
Handling deprecation for yarn.log-aggregation.retain-seconds
Handling deprecation for mapreduce.job.complete.cancel.delegation.tokens
Handling deprecation for mapreduce.local.clientfactory.class.name
Handling deprecation for mapreduce.shuffle.connection-keep-alive.timeout
Handling deprecation for dfs.namenode.num.extra.edits.retained
Handling deprecation for yarn.scheduler.minimum-allocation-vcores
Handling deprecation for ipc.client.connect.max.retries.on.timeouts
Handling deprecation for yarn.timeline-service.client.retry-interval-ms
Handling deprecation for yarn.timeline-service.client.max-retries
Handling deprecation for fs.s3n.block.size
Handling deprecation for mapreduce.job.map.output.collector.class
Handling deprecation for ha.health-monitor.connect-retry-interval.ms
Handling deprecation for mapreduce.shuffle.max.threads
Handling deprecation for nfs.exports.allowed.hosts
Handling deprecation for dfs.client.mmap.cache.size
Handling deprecation for mapreduce.tasktracker.map.tasks.maximum
Handling deprecation for io.file.buffer.size
Handling deprecation for dfs.client.datanode-restart.timeout
Handling deprecation for io.mapfile.bloom.size
Handling deprecation for hadoop.security.kms.client.authentication.retry-count
Handling deprecation for dfs.namenode.checkpoint.txns
Handling deprecation for ipc.client.connect.retry.interval
Handling deprecation for dfs.client-write-packet-size
Handling deprecation for mapreduce.reduce.shuffle.connect.timeout
Handling deprecation for yarn.resourcemanager.fs.state-store.uri
Handling deprecation for fs.swift.impl
Handling deprecation for hadoop.registry.zk.connection.timeout.ms
Handling deprecation for mapred.queue.default.acl-administer-jobs
Handling deprecation for mapreduce.job.submithostaddress
Handling deprecation for dfs.cachereport.intervalMsec
Handling deprecation for yarn.app.mapreduce.shuffle.log.backups
Handling deprecation for yarn.app.mapreduce.am.container.log.limit.kb
Handling deprecation for yarn.nodemanager.resourcemanager.minimum.version
Handling deprecation for ftp.blocksize
Handling deprecation for yarn.resourcemanager.address
Handling deprecation for file.stream-buffer-size
Handling deprecation for yarn.resourcemanager.scheduler.monitor.enable
Handling deprecation for mapreduce.job.ubertask.maxreduces
Handling deprecation for nfs.allow.insecure.ports
Handling deprecation for yarn.sharedcache.nm.uploader.thread-count
Handling deprecation for ipc.client.idlethreshold
Handling deprecation for ftp.stream-buffer-size
Handling deprecation for yarn.sharedcache.client-server.address
Handling deprecation for dfs.client.failover.connection.retries.on.timeouts
Handling deprecation for dfs.namenode.replication.work.multiplier.per.iteration
Handling deprecation for hadoop.http.authentication.simple.anonymous.allowed
Handling deprecation for hadoop.security.authorization
Handling deprecation for yarn.client.nodemanager-connect.retry-interval-ms
Handling deprecation for yarn.am.liveness-monitor.expiry-interval-ms
Handling deprecation for fs.har.impl.disable.cache
Handling deprecation for yarn.nodemanager.linux-container-executor.resources-handler.class
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.read-cache-size
Handling deprecation for hadoop.security.authentication
Handling deprecation for dfs.image.compression.codec
Handling deprecation for mapreduce.task.files.preserve.failedtasks
Handling deprecation for dfs.client.read.shortcircuit.streams.cache.size
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.path
Handling deprecation for mapreduce.job.reduce.slowstart.completedmaps
Handling deprecation for mapreduce.jobhistory.minicluster.fixed.ports
Handling deprecation for file.replication
Handling deprecation for yarn.resourcemanager.ha.automatic-failover.enabled
Handling deprecation for mapreduce.job.userlog.retain.hours
Handling deprecation for mapreduce.jobhistory.joblist.cache.size
Handling deprecation for dfs.namenode.accesstime.precision
Handling deprecation for yarn.resourcemanager.work-preserving-recovery.enabled
Handling deprecation for dfs.namenode.fs-limits.max-xattrs-per-inode
Handling deprecation for io.mapfile.bloom.error.rate
Handling deprecation for yarn.resourcemanager.store.class
Handling deprecation for dfs.image.transfer.timeout
Handling deprecation for yarn.timeline-service.leveldb-state-store.path
Handling deprecation for nfs.wtmax
Handling deprecation for mapreduce.job.combine.class
Handling deprecation for dfs.namenode.support.allow.format
Handling deprecation for fs.s3a.multipart.purge
Handling deprecation for dfs.secondary.namenode.kerberos.internal.spnego.principal
Handling deprecation for fs.s3a.connection.establish.timeout
Handling deprecation for dfs.stream-buffer-size
Handling deprecation for dfs.namenode.invalidate.work.pct.per.iteration
Handling deprecation for yarn.nodemanager.container-executor.class
Handling deprecation for fs.s3a.multipart.purge.age
Handling deprecation for yarn.resourcemanager.scheduler.client.thread-count
Handling deprecation for dfs.namenode.top.enabled
Handling deprecation for yarn.app.mapreduce.shuffle.log.separate
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.low-watermark
Handling deprecation for fs.s3a.fast.buffer.size
Handling deprecation for hadoop.user.group.static.mapping.overrides
Handling deprecation for tfile.fs.input.buffer.size
Handling deprecation for dfs.client.cached.conn.retry
Handling deprecation for hadoop.http.authentication.type
Handling deprecation for dfs.namenode.list.encryption.zones.num.responses
Handling deprecation for mapreduce.map.cpu.vcores
Handling deprecation for dfs.namenode.path.based.cache.refresh.interval.ms
Handling deprecation for dfs.namenode.decommission.interval
Handling deprecation for dfs.namenode.fs-limits.max-directory-items
Handling deprecation for yarn.resourcemanager.zk-retry-interval-ms
Handling deprecation for ftp.bytes-per-checksum
Handling deprecation for dfs.ha.log-roll.period
Handling deprecation for dfs.user.home.dir.prefix
Handling deprecation for ipc.client.fallback-to-simple-auth-allowed
Handling deprecation for yarn.nodemanager.pmem-check-enabled
Handling deprecation for yarn.nodemanager.remote-app-log-dir
Handling deprecation for dfs.namenode.inotify.max.events.per.rpc
Handling deprecation for mapreduce.task.profile.maps
Handling deprecation for mapreduce.shuffle.ssl.file.buffer.size
Handling deprecation for mapreduce.tasktracker.healthchecker.script.timeout
Handling deprecation for yarn.timeline-service.webapp.https.address
Handling deprecation for yarn.nodemanager.resource.percentage-physical-cpu-limit
Handling deprecation for yarn.app.mapreduce.am.command-opts
Handling deprecation for dfs.namenode.fs-limits.max-xattr-size
Handling deprecation for dfs.datanode.http.address
Handling deprecation for dfs.namenode.blocks.per.postponedblocks.rescan
Handling deprecation for yarn.sharedcache.nm.uploader.replication.factor
Handling deprecation for hadoop.registry.zk.root
Handling deprecation for hadoop.jetty.logs.serve.aliases
Handling deprecation for yarn.client.failover-proxy-provider
Handling deprecation for mapreduce.jobhistory.admin.acl
Handling deprecation for yarn.app.mapreduce.am.hard-kill-timeout-ms
Handling deprecation for yarn.nodemanager.remote-app-log-dir-suffix
Handling deprecation for mapreduce.jobhistory.principal
Handling deprecation for yarn.resourcemanager.webapp.address
Handling deprecation for mapreduce.jobhistory.recovery.enable
Handling deprecation for yarn.sharedcache.store.in-memory.check-period-mins
Handling deprecation for nfs.mountd.port
Handling deprecation for mapreduce.reduce.merge.inmem.threshold
Handling deprecation for fs.df.interval
Handling deprecation for yarn.timeline-service.enabled
Handling deprecation for mapreduce.jobtracker.jobhistory.lru.cache.size
Handling deprecation for mapreduce.task.profile
Handling deprecation for mapreduce.job.output.key.class
Handling deprecation for yarn.nodemanager.hostname
Handling deprecation for dfs.namenode.num.checkpoints.retained
Handling deprecation for mapreduce.job.queuename
Handling deprecation for mapreduce.jobhistory.max-age-ms
Handling deprecation for mapreduce.job.token.tracking.ids.enabled
Handling deprecation for yarn.nodemanager.localizer.client.thread-count
Handling deprecation for yarn.sharedcache.uploader.server.thread-count
Handling deprecation for dfs.client.mmap.retry.timeout.ms
Handling deprecation for mapreduce.jobhistory.move.thread-count
Handling deprecation for dfs.permissions.enabled
Handling deprecation for dfs.blockreport.split.threshold
Handling deprecation for fs.AbstractFileSystem.hdfs.impl
Handling deprecation for dfs.datanode.balance.bandwidthPerSec
Handling deprecation for dfs.block.scanner.volume.bytes.per.second
Handling deprecation for hadoop.http.filter.initializers
Handling deprecation for yarn.timeline-service.http-authentication.simple.anonymous.allowed
Handling deprecation for dfs.default.chunk.view.size
Handling deprecation for yarn.sharedcache.client-server.thread-count
Handling deprecation for yarn.resourcemanager.resource-tracker.address
Handling deprecation for mapreduce.job.working.dir
Handling deprecation for mapreduce.jobhistory.datestring.cache.size
Handling deprecation for mapreduce.task.profile.params
Handling deprecation for dfs.namenode.decommission.blocks.per.interval
Handling deprecation for dfs.namenode.handler.count
Handling deprecation for dfs.image.transfer.bandwidthPerSec
Handling deprecation for rpc.metrics.quantile.enable
Handling deprecation for mapreduce.jobtracker.expire.trackers.interval
Handling deprecation for mapreduce.task.timeout
Handling deprecation for yarn.app.mapreduce.client.max-retries
Handling deprecation for yarn.nodemanager.resource.memory-mb
Handling deprecation for yarn.nodemanager.disk-health-checker.min-healthy-disks
Handling deprecation for dfs.datanode.failed.volumes.tolerated
Handling deprecation for yarn.timeline-service.handler-thread-count
Handling deprecation for ipc.server.listen.queue.size
Handling deprecation for fs.s3a.threads.max
Handling deprecation for yarn.resourcemanager.connect.max-wait.ms
Handling deprecation for mapreduce.fileoutputcommitter.algorithm.version
Handling deprecation for mapreduce.framework.name
Handling deprecation for mapreduce.map.skip.proc.count.autoincr
Handling deprecation for mapreduce.job.max.split.locations
Handling deprecation for yarn.resourcemanager.scheduler.class
Handling deprecation for yarn.resourcemanager.system-metrics-publisher.enabled
Handling deprecation for dfs.blocksize
Handling deprecation for yarn.sharedcache.nested-level
Handling deprecation for mapreduce.shuffle.connection-keep-alive.enable
Handling deprecation for fs.s3a.threads.keepalivetime
Handling deprecation for fs.s3a.connection.timeout
Handling deprecation for file.client-write-packet-size
Handling deprecation for ha.failover-controller.cli-check.rpc-timeout.ms
Handling deprecation for ha.zookeeper.acl
Handling deprecation for dfs.namenode.write.stale.datanode.ratio
Handling deprecation for dfs.encrypt.data.transfer
Handling deprecation for dfs.datanode.shared.file.descriptor.paths
Handling deprecation for mapreduce.input.lineinputformat.linespermap
Handling deprecation for yarn.resourcemanager.delayed.delegation-token.removal-interval-ms
Handling deprecation for yarn.nodemanager.localizer.fetch.thread-count
Handling deprecation for dfs.client.failover.max.attempts
Handling deprecation for yarn.resourcemanager.scheduler.address
Handling deprecation for dfs.client.read.shortcircuit.streams.cache.expiry.ms
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.start-time-write-cache-size
Handling deprecation for yarn.nodemanager.health-checker.script.timeout-ms
Handling deprecation for yarn.resourcemanager.fs.state-store.num-retries
Handling deprecation for hadoop.ssl.require.client.cert
Handling deprecation for hadoop.security.uid.cache.secs
Handling deprecation for mapreduce.jobhistory.keytab
Handling deprecation for dfs.client.read.shortcircuit.skip.checksum
Handling deprecation for yarn.resourcemanager.ha.automatic-failover.zk-base-path
Handling deprecation for mapreduce.shuffle.ssl.enabled
Handling deprecation for mapreduce.reduce.log.level
Handling deprecation for hadoop.registry.rm.enabled
Handling deprecation for mapreduce.tasktracker.dns.interface
Handling deprecation for yarn.resourcemanager.system-metrics-publisher.dispatcher.pool-size
Handling deprecation for mapreduce.job.speculative.speculative-cap-running-tasks
Handling deprecation for dfs.datanode.block.id.layout.upgrade.threads
Handling deprecation for dfs.datanode.use.datanode.hostname
Handling deprecation for dfs.client.context
Handling deprecation for yarn.resourcemanager.ha.enabled
Handling deprecation for mapred.reducer.new-api
Handling deprecation for dfs.namenode.delegation.token.renew-interval
Handling deprecation for dfs.blockreport.intervalMsec
Handling deprecation for fs.s3a.multipart.threshold
Handling deprecation for mapreduce.reduce.shuffle.memory.limit.percent
Handling deprecation for dfs.https.server.keystore.resource
Handling deprecation for io.map.index.skip
Handling deprecation for mapreduce.job.hdfs-servers
Handling deprecation for mapreduce.jobtracker.taskscheduler
Handling deprecation for dfs.namenode.kerberos.internal.spnego.principal
Handling deprecation for yarn.resourcemanager.state-store.max-completed-applications
Handling deprecation for mapreduce.map.output.compress
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.num.refill.threads
Handling deprecation for fs.s3n.multipart.uploads.block.size
Handling deprecation for mapreduce.task.merge.progress.records
Handling deprecation for dfs.datanode.dns.interface
Handling deprecation for map.sort.class
Handling deprecation for yarn.nodemanager.aux-services.mapreduce_shuffle.class
Handling deprecation for tfile.fs.output.buffer.size
Handling deprecation for fs.du.interval
Handling deprecation for dfs.client.failover.connection.retries
Handling deprecation for dfs.namenode.top.window.num.buckets
Handling deprecation for mapreduce.job.dir
Handling deprecation for fs.s3a.buffer.dir
Handling deprecation for mapreduce.reduce.shuffle.retry-delay.max.ms
Handling deprecation for yarn.sharedcache.uploader.server.address
Handling deprecation for mapreduce.client.progressmonitor.pollinterval
Handling deprecation for yarn.app.mapreduce.shuffle.log.limit.kb
Handling deprecation for dfs.datanode.max.locked.memory
Handling deprecation for dfs.namenode.retrycache.expirytime.millis
Handling deprecation for dfs.datanode.scan.period.hours
Handling deprecation for dfs.client.block.write.replace-datanode-on-failure.best-effort
Handling deprecation for mapreduce.jobhistory.move.interval-ms
Handling deprecation for dfs.ha.fencing.ssh.connect-timeout
Handling deprecation for yarn.nodemanager.log-aggregation.roll-monitoring-interval-seconds
Handling deprecation for dfs.namenode.fs-limits.max-component-length
Handling deprecation for hadoop.registry.zk.quorum
Handling deprecation for dfs.namenode.enable.retrycache
Handling deprecation for dfs.datanode.du.reserved
Handling deprecation for yarn.timeline-service.state-store-class
Handling deprecation for dfs.datanode.ipc.address
Handling deprecation for hadoop.registry.system.acls
Handling deprecation for dfs.client.block.write.replace-datanode-on-failure.policy
Handling deprecation for dfs.namenode.path.based.cache.retry.interval.ms
Handling deprecation for hadoop.security.crypto.cipher.suite
Handling deprecation for dfs.ha.tail-edits.period
Handling deprecation for mapreduce.task.profile.reduce.params
Handling deprecation for hadoop.registry.jaas.context
Handling deprecation for yarn.resourcemanager.hostname
Handling deprecation for mapreduce.reduce.memory.mb
Handling deprecation for hadoop.security.group.mapping.ldap.search.filter.group
Handling deprecation for hadoop.http.authentication.kerberos.principal
Handling deprecation for hadoop.security.group.mapping.ldap.search.filter.user
Handling deprecation for yarn.nodemanager.disk-health-checker.min-free-space-per-disk-mb
Handling deprecation for dfs.namenode.edits.dir
Handling deprecation for yarn.client.failover-retries-on-socket-timeouts
Handling deprecation for dfs.namenode.decommission.max.concurrent.tracked.nodes
Handling deprecation for mapreduce.client.completion.pollinterval
Handling deprecation for dfs.namenode.name.dir.restore
Handling deprecation for dfs.namenode.secondary.http-address
Handling deprecation for mapreduce.jobhistory.recovery.store.leveldb.path
Handling deprecation for yarn.sharedcache.store.class
Handling deprecation for s3.bytes-per-checksum
Handling deprecation for yarn.nodemanager.windows-container.cpu-limit.enabled
Handling deprecation for yarn.resourcemanager.webapp.https.address
Handling deprecation for yarn.nodemanager.vmem-pmem-ratio
Handling deprecation for dfs.namenode.checkpoint.period
Handling deprecation for dfs.ha.automatic-failover.enabled
Submitting tokens for job: job_local1072276750_0001
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.fs.FileContext.getAbstractFileSystem(FileContext.java:331)
Handling deprecation for all properties in config...
Handling deprecation for mapreduce.jobtracker.address
Handling deprecation for yarn.resourcemanager.scheduler.monitor.policies
Handling deprecation for dfs.namenode.resource.check.interval
Handling deprecation for mapreduce.jobhistory.client.thread-count
Handling deprecation for yarn.app.mapreduce.am.containerlauncher.threadpool-initial-size
Handling deprecation for mapred.child.java.opts
Handling deprecation for mapreduce.jobtracker.retiredjobs.cache.size
Handling deprecation for dfs.client.https.need-auth
Handling deprecation for yarn.admin.acl
Handling deprecation for yarn.app.mapreduce.am.job.committer.cancel-timeout
Handling deprecation for mapreduce.job.emit-timeline-data
Handling deprecation for fs.ftp.host.port
Handling deprecation for dfs.namenode.avoid.read.stale.datanode
Handling deprecation for dfs.journalnode.rpc-address
Handling deprecation for mapreduce.job.end-notification.retry.attempts
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.ttl-interval-ms
Handling deprecation for yarn.resourcemanager.leveldb-state-store.path
Handling deprecation for mapred.mapper.new-api
Handling deprecation for yarn.ipc.rpc.class
Handling deprecation for ipc.client.connection.maxidletime
Handling deprecation for yarn.nodemanager.process-kill-wait.ms
Handling deprecation for mapreduce.cluster.acls.enabled
Handling deprecation for mapreduce.jobtracker.handler.count
Handling deprecation for io.map.index.interval
Handling deprecation for dfs.namenode.https-address
Handling deprecation for mapreduce.task.profile.reduces
Handling deprecation for fs.s3n.multipart.uploads.enabled
Handling deprecation for io.seqfile.sorter.recordlimit
Handling deprecation for mapreduce.job.ubertask.maxmaps
Handling deprecation for mapreduce.tasktracker.tasks.sleeptimebeforesigkill
Handling deprecation for hadoop.util.hash.type
Handling deprecation for dfs.namenode.replication.min
Handling deprecation for yarn.nodemanager.container-manager.thread-count
Handling deprecation for mapreduce.jobtracker.jobhistory.block.size
Handling deprecation for dfs.namenode.fs-limits.min-block-size
Handling deprecation for mapreduce.app-submission.cross-platform
Handling deprecation for fs.AbstractFileSystem.file.impl
Handling deprecation for net.topology.script.number.args
Handling deprecation for yarn.resourcemanager.container-tokens.master-key-rolling-interval-secs
Handling deprecation for mapreduce.map.output.compress.codec
Handling deprecation for mapreduce.job.reducer.preempt.delay.sec
Handling deprecation for s3native.bytes-per-checksum
Handling deprecation for dfs.namenode.path.based.cache.block.map.allocation.percent
Handling deprecation for yarn.nodemanager.windows-container.memory-limit.enabled
Handling deprecation for mapreduce.input.fileinputformat.split.minsize
Handling deprecation for hadoop.security.group.mapping
Handling deprecation for mapreduce.jobtracker.system.dir
Handling deprecation for mapreduce.job.end-notification.max.attempts
Handling deprecation for mapreduce.reduce.markreset.buffer.percent
Handling deprecation for dfs.datanode.cache.revocation.polling.ms
Handling deprecation for mapreduce.reduce.speculative
Handling deprecation for yarn.nodemanager.localizer.cache.cleanup.interval-ms
Handling deprecation for dfs.namenode.lazypersist.file.scrub.interval.sec
Handling deprecation for fs.s3a.threads.core
Handling deprecation for mapreduce.jobhistory.recovery.store.fs.uri
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.start-time-read-cache-size
Handling deprecation for hadoop.registry.zk.retry.interval.ms
Handling deprecation for yarn.nodemanager.keytab
Handling deprecation for dfs.namenode.replication.interval
Handling deprecation for yarn.resourcemanager.admin.address
Handling deprecation for mapreduce.job.maps
Handling deprecation for nfs.dump.dir
Handling deprecation for mapreduce.job.user.name
Handling deprecation for mapreduce.jobtracker.maxtasks.perjob
Handling deprecation for mapreduce.job.ubertask.enable
Handling deprecation for mapreduce.job.reduce.class
Handling deprecation for yarn.nodemanager.delete.debug-delay-sec
Handling deprecation for yarn.timeline-service.ttl-enable
Handling deprecation for yarn.resourcemanager.fs.state-store.retry-policy-spec
Handling deprecation for mapreduce.reduce.skip.maxgroups
Handling deprecation for dfs.client.use.datanode.hostname
Handling deprecation for fs.trash.interval
Handling deprecation for mapreduce.job.name
Handling deprecation for mapreduce.am.max-attempts
Handling deprecation for mapreduce.jobtracker.heartbeats.in.second
Handling deprecation for yarn.resourcemanager.zk-num-retries
Handling deprecation for s3.blocksize
Handling deprecation for dfs.datanode.data.dir
Handling deprecation for mapreduce.jobtracker.persist.jobstatus.active
Handling deprecation for mapreduce.reduce.shuffle.parallelcopies
Handling deprecation for fs.s3.buffer.dir
Handling deprecation for mapreduce.jobhistory.done-dir
Handling deprecation for hadoop.security.instrumentation.requires.admin
Handling deprecation for hadoop.registry.zk.retry.ceiling.ms
Handling deprecation for nfs.rtmax
Handling deprecation for dfs.datanode.data.dir.perm
Handling deprecation for yarn.resourcemanager.container.liveness-monitor.interval-ms
Handling deprecation for yarn.nodemanager.env-whitelist
Handling deprecation for dfs.namenode.backup.address
Handling deprecation for dfs.namenode.xattrs.enabled
Handling deprecation for dfs.datanode.readahead.bytes
Handling deprecation for mapreduce.jobhistory.cleaner.enable
Handling deprecation for dfs.client.block.write.retries
Handling deprecation for mapreduce.tasktracker.http.address
Handling deprecation for yarn.nodemanager.linux-container-executor.cgroups.hierarchy
Handling deprecation for ha.failover-controller.graceful-fence.connection.retries
Handling deprecation for yarn.resourcemanager.recovery.enabled
Handling deprecation for yarn.app.mapreduce.am.container.log.backups
Handling deprecation for dfs.namenode.safemode.threshold-pct
Handling deprecation for yarn.nodemanager.disk-health-checker.interval-ms
Handling deprecation for hadoop.security.java.secure.random.algorithm
Handling deprecation for dfs.namenode.list.cache.directives.num.responses
Handling deprecation for dfs.datanode.dns.nameserver
Handling deprecation for mapreduce.cluster.temp.dir
Handling deprecation for fs.s3a.max.total.tasks
Handling deprecation for mapreduce.reduce.maxattempts
Handling deprecation for mapreduce.client.submit.file.replication
Handling deprecation for mapreduce.shuffle.port
Handling deprecation for yarn.resourcemanager.resource-tracker.client.thread-count
Handling deprecation for dfs.namenode.replication.considerLoad
Handling deprecation for dfs.namenode.edits.journal-plugin.qjournal
Handling deprecation for dfs.client.write.exclude.nodes.cache.expiry.interval.millis
Handling deprecation for yarn.nodemanager.delete.thread-count
Handling deprecation for dfs.client.mmap.cache.timeout.ms
Handling deprecation for yarn.nodemanager.admin-env
Handling deprecation for io.skip.checksum.errors
Handling deprecation for yarn.timeline-service.hostname
Handling deprecation for yarn.resourcemanager.proxy-user-privileges.enabled
Handling deprecation for mapreduce.job.speculative.speculative-cap-total-tasks
Handling deprecation for yarn.acl.enable
Handling deprecation for fs.s3a.fast.upload
Handling deprecation for file.blocksize
Handling deprecation for mapreduce.job.speculative.slowtaskthreshold
Handling deprecation for ftp.replication
Handling deprecation for yarn.sharedcache.cleaner.initial-delay-mins
Handling deprecation for s3native.client-write-packet-size
Handling deprecation for hadoop.rpc.socket.factory.class.default
Handling deprecation for file.bytes-per-checksum
Handling deprecation for dfs.datanode.slow.io.warning.threshold.ms
Handling deprecation for io.seqfile.lazydecompress
Handling deprecation for mapreduce.task.skip.start.attempts
Handling deprecation for dfs.namenode.reject-unresolved-dn-topology-mapping
Handling deprecation for hadoop.common.configuration.version
Handling deprecation for yarn.resourcemanager.client.thread-count
Handling deprecation for dfs.datanode.drop.cache.behind.reads
Handling deprecation for yarn.sharedcache.admin.address
Handling deprecation for mapreduce.job.output.value.class
Handling deprecation for mapreduce.output.fileoutputformat.outputdir
Handling deprecation for mapreduce.jobtracker.taskcache.levels
Handling deprecation for yarn.nodemanager.linux-container-executor.nonsecure-mode.user-pattern
Handling deprecation for yarn.resourcemanager.zk-timeout-ms
Handling deprecation for yarn.resourcemanager.max-completed-applications
Handling deprecation for mapreduce.job.jvm.numtasks
Handling deprecation for yarn.sharedcache.cleaner.period-mins
Handling deprecation for mapreduce.jobtracker.tasktracker.maxblacklists
Handling deprecation for dfs.namenode.top.num.users
Handling deprecation for yarn.nodemanager.linux-container-executor.cgroups.mount
Handling deprecation for yarn.sharedcache.checksum.algo.impl
Handling deprecation for mapreduce.job.end-notification.max.retry.interval
Handling deprecation for mapreduce.job.acl-view-job
Handling deprecation for mapreduce.job.classloader
Handling deprecation for yarn.log-aggregation-enable
Handling deprecation for mapreduce.reduce.shuffle.fetch.retry.interval-ms
Handling deprecation for yarn.resourcemanager.nodemanager.minimum.version
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.size
Handling deprecation for yarn.app.mapreduce.am.job.task.listener.thread-count
Handling deprecation for yarn.app.mapreduce.am.resource.cpu-vcores
Handling deprecation for dfs.namenode.edit.log.autoroll.check.interval.ms
Handling deprecation for mapreduce.output.fileoutputformat.compress.type
Handling deprecation for hadoop.hdfs.configuration.version
Handling deprecation for hadoop.security.group.mapping.ldap.search.attr.member
Handling deprecation for yarn.nodemanager.log.retain-seconds
Handling deprecation for yarn.nodemanager.local-cache.max-files-per-directory
Handling deprecation for mapreduce.job.end-notification.retry.interval
Handling deprecation for hadoop.ssl.client.conf
Handling deprecation for yarn.sharedcache.root-dir
Handling deprecation for dfs.journalnode.https-address
Handling deprecation for mapreduce.reduce.shuffle.fetch.retry.timeout-ms
Handling deprecation for dfs.bytes-per-checksum
Handling deprecation for dfs.namenode.max.objects
Handling deprecation for mapreduce.tasktracker.instrumentation
Handling deprecation for dfs.datanode.max.transfer.threads
Handling deprecation for dfs.block.access.key.update.interval
Handling deprecation for mapreduce.jobtracker.jobhistory.task.numberprogresssplits
Handling deprecation for mapreduce.map.memory.mb
Handling deprecation for ha.failover-controller.new-active.rpc-timeout.ms
Handling deprecation for hadoop.ssl.hostname.verifier
Handling deprecation for dfs.client.read.shortcircuit
Handling deprecation for dfs.datanode.hdfs-blocks-metadata.enabled
Handling deprecation for mapreduce.tasktracker.healthchecker.interval
Handling deprecation for dfs.image.transfer.chunksize
Handling deprecation for mapreduce.tasktracker.taskmemorymanager.monitoringinterval
Handling deprecation for dfs.client.https.keystore.resource
Handling deprecation for yarn.resourcemanager.connect.retry-interval.ms
Handling deprecation for yarn.timeline-service.webapp.address
Handling deprecation for s3native.blocksize
Handling deprecation for yarn.scheduler.minimum-allocation-mb
Handling deprecation for yarn.sharedcache.cleaner.resource-sleep-ms
Handling deprecation for net.topology.impl
Handling deprecation for dfs.client.failover.sleep.base.millis
Handling deprecation for dfs.permissions.superusergroup
Handling deprecation for io.seqfile.compress.blocksize
Handling deprecation for hadoop.registry.zk.retry.times
Handling deprecation for fs.AbstractFileSystem.ftp.impl
Handling deprecation for dfs.namenode.checkpoint.edits.dir
Handling deprecation for mapreduce.job.running.reduce.limit
Handling deprecation for dfs.blockreport.initialDelay
Handling deprecation for dfs.namenode.heartbeat.recheck-interval
Handling deprecation for dfs.namenode.safemode.extension
Handling deprecation for yarn.scheduler.maximum-allocation-mb
Handling deprecation for mapreduce.job.reduce.shuffle.consumer.plugin.class
Handling deprecation for yarn.nodemanager.vmem-check-enabled
Handling deprecation for mapreduce.task.io.sort.factor
Handling deprecation for mapreduce.jobtracker.persist.jobstatus.dir
Handling deprecation for dfs.client.failover.sleep.max.millis
Handling deprecation for dfs.namenode.delegation.key.update-interval
Handling deprecation for hadoop.rpc.protection
Handling deprecation for fs.permissions.umask-mode
Handling deprecation for fs.s3.sleepTimeSeconds
Handling deprecation for ha.health-monitor.rpc-timeout.ms
Handling deprecation for hadoop.http.staticuser.user
Handling deprecation for fs.s3a.connection.maximum
Handling deprecation for yarn.nodemanager.linux-container-executor.nonsecure-mode.limit-users
Handling deprecation for fs.s3a.paging.maximum
Handling deprecation for fs.AbstractFileSystem.viewfs.impl
Handling deprecation for fs.ftp.host
Handling deprecation for yarn.nodemanager.linux-container-executor.nonsecure-mode.local-user
Handling deprecation for fs.s3a.impl
Handling deprecation for hadoop.http.authentication.kerberos.keytab
Handling deprecation for dfs.namenode.fs-limits.max-blocks-per-file
Handling deprecation for mapreduce.tasktracker.http.threads
Handling deprecation for mapreduce.tasktracker.dns.nameserver
Handling deprecation for yarn.resourcemanager.am-rm-tokens.master-key-rolling-interval-secs
Handling deprecation for dfs.client.block.write.replace-datanode-on-failure.enable
Handling deprecation for io.compression.codec.bzip2.library
Handling deprecation for mapreduce.map.skip.maxrecords
Handling deprecation for dfs.client.use.legacy.blockreader.local
Handling deprecation for dfs.namenode.checkpoint.dir
Handling deprecation for dfs.namenode.top.windows.minutes
Handling deprecation for mapreduce.job.maxtaskfailures.per.tracker
Handling deprecation for net.topology.node.switch.mapping.impl
Handling deprecation for mapreduce.shuffle.max.connections
Handling deprecation for mapreduce.jobhistory.loadedjobs.cache.size
Handling deprecation for dfs.storage.policy.enabled
Handling deprecation for yarn.client.application-client-protocol.poll-interval-ms
Handling deprecation for yarn.nodemanager.localizer.address
Handling deprecation for dfs.namenode.list.cache.pools.num.responses
Handling deprecation for nfs.server.port
Handling deprecation for mapreduce.client.output.filter
Handling deprecation for yarn.timeline-service.client.best-effort
Handling deprecation for ha.zookeeper.parent-znode
Handling deprecation for mapreduce.jobtracker.persist.jobstatus.hours
Handling deprecation for yarn.sharedcache.admin.thread-count
Handling deprecation for yarn.nodemanager.resource.cpu-vcores
Handling deprecation for dfs.datanode.block-pinning.enabled
Handling deprecation for mapreduce.jobhistory.http.policy
Handling deprecation for yarn.resourcemanager.webapp.delegation-token-auth-filter.enabled
Handling deprecation for mapreduce.job.speculative.retry-after-no-speculate
Handling deprecation for fs.s3a.attempts.maximum
Handling deprecation for s3native.stream-buffer-size
Handling deprecation for io.seqfile.local.dir
Handling deprecation for yarn.log-aggregation.retain-check-interval-seconds
Handling deprecation for fs.s3n.multipart.copy.block.size
Handling deprecation for dfs.encrypt.data.transfer.cipher.key.bitlength
Handling deprecation for dfs.datanode.sync.behind.writes
Handling deprecation for yarn.resourcemanager.zk-acl
Handling deprecation for hadoop.ssl.keystores.factory.class
Handling deprecation for mapreduce.job.split.metainfo.maxsize
Handling deprecation for fs.s3.maxRetries
Handling deprecation for hadoop.security.random.device.file.path
Handling deprecation for yarn.client.nodemanager-connect.max-wait-ms
Handling deprecation for dfs.namenode.stale.datanode.interval
Handling deprecation for mapreduce.task.io.sort.mb
Handling deprecation for yarn.resourcemanager.zk-state-store.parent-path
Handling deprecation for yarn.app.mapreduce.client-am.ipc.max-retries
Handling deprecation for fs.client.resolve.remote.symlinks
Handling deprecation for yarn.nodemanager.linux-container-executor.cgroups.strict-resource-usage
Handling deprecation for hadoop.ssl.enabled.protocols
Handling deprecation for mapreduce.reduce.cpu.vcores
Handling deprecation for yarn.client.failover-retries
Handling deprecation for mapreduce.jobhistory.address
Handling deprecation for hadoop.ssl.enabled
Handling deprecation for dfs.replication.max
Handling deprecation for dfs.namenode.name.dir
Handling deprecation for dfs.datanode.https.address
Handling deprecation for ipc.client.kill.max
Handling deprecation for mapreduce.job.committer.setup.cleanup.needed
Handling deprecation for dfs.client.domain.socket.data.traffic
Handling deprecation for yarn.nodemanager.localizer.cache.target-size-mb
Handling deprecation for yarn.resourcemanager.admin.client.thread-count
Handling deprecation for dfs.block.access.token.enable
Handling deprecation for mapreduce.job.speculative.retry-after-speculate
Handling deprecation for dfs.datanode.address
Handling deprecation for mapreduce.jobtracker.restart.recover
Handling deprecation for ipc.client.connect.max.retries
Handling deprecation for yarn.timeline-service.store-class
Handling deprecation for dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
Handling deprecation for hadoop.tmp.dir
Handling deprecation for dfs.datanode.handler.count
Handling deprecation for yarn.resourcemanager.ha.automatic-failover.embedded
Handling deprecation for yarn.timeline-service.ttl-ms
Handling deprecation for mapreduce.task.profile.map.params
Handling deprecation for yarn.resourcemanager.nodemanagers.heartbeat-interval-ms
Handling deprecation for mapreduce.map.speculative
Handling deprecation for yarn.timeline-service.recovery.enabled
Handling deprecation for mapreduce.job.map.class
Handling deprecation for dfs.namenode.resource.checked.volumes.minimum
Handling deprecation for yarn.nodemanager.recovery.dir
Handling deprecation for mapreduce.job.counters.max
Handling deprecation for yarn.resourcemanager.keytab
Handling deprecation for dfs.namenode.max.extra.edits.segments.retained
Handling deprecation for dfs.webhdfs.user.provider.user.pattern
Handling deprecation for dfs.client.mmap.enabled
Handling deprecation for mapreduce.map.log.level
Handling deprecation for dfs.client.file-block-storage-locations.timeout.millis
Handling deprecation for yarn.client.max-cached-nodemanagers-proxies
Handling deprecation for yarn.app.mapreduce.am.scheduler.heartbeat.interval-ms
Handling deprecation for hadoop.fuse.timer.period
Handling deprecation for fs.trash.checkpoint.interval
Handling deprecation for yarn.sharedcache.app-checker.class
Handling deprecation for dfs.journalnode.http-address
Handling deprecation for yarn.app.mapreduce.am.staging-dir
Handling deprecation for mapreduce.tasktracker.local.dir.minspacestart
Handling deprecation for yarn.nm.liveness-monitor.expiry-interval-ms
Handling deprecation for ha.health-monitor.check-interval.ms
Handling deprecation for mapreduce.reduce.shuffle.merge.percent
Handling deprecation for dfs.namenode.retrycache.heap.percent
Handling deprecation for yarn.nodemanager.docker-container-executor.exec-name
Handling deprecation for ipc.client.connect.timeout
Handling deprecation for yarn.resourcemanager.fs.state-store.retry-interval-ms
Handling deprecation for mapreduce.output.fileoutputformat.compress
Handling deprecation for yarn.nodemanager.local-dirs
Handling deprecation for yarn.nodemanager.recovery.enabled
Handling deprecation for io.native.lib.available
Handling deprecation for yarn.sharedcache.store.in-memory.staleness-period-mins
Handling deprecation for yarn.resourcemanager.am.max-attempts
Handling deprecation for s3.replication
Handling deprecation for mapreduce.input.fileinputformat.inputdir
Handling deprecation for fs.AbstractFileSystem.har.impl
Handling deprecation for dfs.image.compress
Handling deprecation for mapreduce.job.running.map.limit
Handling deprecation for mapreduce.reduce.input.buffer.percent
Handling deprecation for yarn.nodemanager.webapp.address
Handling deprecation for dfs.datanode.available-space-volume-choosing-policy.balanced-space-preference-fraction
Handling deprecation for dfs.namenode.edit.log.autoroll.multiplier.threshold
Handling deprecation for hadoop.security.group.mapping.ldap.ssl
Handling deprecation for dfs.namenode.checkpoint.check.period
Handling deprecation for fs.defaultFS
Handling deprecation for fs.s3a.multipart.size
Handling deprecation for dfs.client.slow.io.warning.threshold.ms
Handling deprecation for yarn.app.mapreduce.am.job.committer.commit-window
Handling deprecation for hadoop.security.group.mapping.ldap.search.attr.group.name
Handling deprecation for yarn.nodemanager.disk-health-checker.max-disk-utilization-per-disk-percentage
Handling deprecation for yarn.nodemanager.container-monitor.procfs-tree.smaps-based-rss.enabled
Handling deprecation for mapreduce.job.submithostname
Handling deprecation for mapreduce.map.sort.spill.percent
Handling deprecation for hadoop.security.crypto.codec.classes.aes.ctr.nopadding
Handling deprecation for dfs.namenode.http-address
Handling deprecation for hadoop.security.groups.negative-cache.secs
Handling deprecation for hadoop.ssl.server.conf
Handling deprecation for mapreduce.ifile.readahead
Handling deprecation for s3native.replication
Handling deprecation for yarn.client.nodemanager-client-async.thread-pool-max-size
Handling deprecation for mapreduce.jobtracker.staging.root.dir
Handling deprecation for mapreduce.jobhistory.admin.address
Handling deprecation for dfs.namenode.startup.delay.block.deletion.sec
Handling deprecation for yarn.nodemanager.health-checker.interval-ms
Handling deprecation for dfs.namenode.checkpoint.max-retries
Handling deprecation for s3.stream-buffer-size
Handling deprecation for ftp.client-write-packet-size
Handling deprecation for dfs.datanode.fsdatasetcache.max.threads.per.volume
Handling deprecation for mapreduce.output.fileoutputformat.compress.codec
Handling deprecation for yarn.timeline-service.keytab
Handling deprecation for yarn.sharedcache.store.in-memory.initial-delay-mins
Handling deprecation for mapreduce.jobhistory.webapp.address
Handling deprecation for mapreduce.task.userlog.limit.kb
Handling deprecation for mapreduce.reduce.shuffle.fetch.retry.enabled
Handling deprecation for yarn.app.mapreduce.task.container.log.backups
Handling deprecation for dfs.heartbeat.interval
Handling deprecation for ha.zookeeper.session-timeout.ms
Handling deprecation for fs.s3a.connection.ssl.enabled
Handling deprecation for yarn.sharedcache.webapp.address
Handling deprecation for hadoop.http.authentication.signature.secret.file
Handling deprecation for hadoop.fuse.connection.timeout
Handling deprecation for mapreduce.input.fileinputformat.numinputfiles
Handling deprecation for yarn.nodemanager.log-aggregation.compression-type
Handling deprecation for ipc.server.max.connections
Handling deprecation for yarn.resourcemanager.work-preserving-recovery.scheduling-wait-ms
Handling deprecation for yarn.nodemanager.log-dirs
Handling deprecation for yarn.app.mapreduce.am.resource.mb
Handling deprecation for hadoop.security.groups.cache.secs
Handling deprecation for mapreduce.job.speculative.minimum-allowed-tasks
Handling deprecation for yarn.nodemanager.container-monitor.interval-ms
Handling deprecation for dfs.datanode.cache.revocation.timeout.ms
Handling deprecation for mapreduce.jobhistory.recovery.store.class
Handling deprecation for mapreduce.task.combine.progress.records
Handling deprecation for s3.client-write-packet-size
Handling deprecation for mapreduce.jobtracker.instrumentation
Handling deprecation for dfs.replication
Handling deprecation for mapreduce.shuffle.transfer.buffer.size
Handling deprecation for hadoop.security.group.mapping.ldap.directory.search.timeout
Handling deprecation for dfs.datanode.available-space-volume-choosing-policy.balanced-space-threshold
Handling deprecation for hadoop.work.around.non.threadsafe.getpwuid
Handling deprecation for yarn.app.mapreduce.client-am.ipc.max-retries-on-timeouts
Handling deprecation for yarn.nodemanager.address
Handling deprecation for mapreduce.tasktracker.taskcontroller
Handling deprecation for mapreduce.tasktracker.indexcache.mb
Handling deprecation for yarn.scheduler.maximum-allocation-vcores
Handling deprecation for mapreduce.job.reduces
Handling deprecation for yarn.nodemanager.sleep-delay-before-sigkill.ms
Handling deprecation for yarn.timeline-service.address
Handling deprecation for yarn.resourcemanager.configuration.provider-class
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.expiry
Handling deprecation for yarn.sharedcache.enabled
Handling deprecation for tfile.io.chunk.size
Handling deprecation for mapreduce.job.acl-modify-job
Handling deprecation for hadoop.registry.zk.session.timeout.ms
Handling deprecation for fs.automatic.close
Handling deprecation for ha.health-monitor.sleep-after-disconnect.ms
Handling deprecation for mapreduce.tasktracker.reduce.tasks.maximum
Handling deprecation for mapreduce.input.fileinputformat.list-status.num-threads
Handling deprecation for dfs.datanode.directoryscan.threads
Handling deprecation for dfs.datanode.directoryscan.interval
Handling deprecation for dfs.namenode.acls.enabled
Handling deprecation for dfs.client.short.circuit.replica.stale.threshold.ms
Handling deprecation for hadoop.http.authentication.token.validity
Handling deprecation for fs.s3.block.size
Handling deprecation for ha.failover-controller.graceful-fence.rpc-timeout.ms
Handling deprecation for mapreduce.tasktracker.local.dir.minspacekill
Handling deprecation for dfs.namenode.resource.du.reserved
Handling deprecation for mapreduce.jobhistory.cleaner.interval-ms
Handling deprecation for dfs.namenode.datanode.registration.ip-hostname-check
Handling deprecation for mapreduce.jobhistory.intermediate-done-dir
Handling deprecation for mapreduce.jobtracker.http.address
Handling deprecation for dfs.namenode.backup.http-address
Handling deprecation for dfs.namenode.edits.noeditlogchannelflush
Handling deprecation for mapreduce.reduce.shuffle.input.buffer.percent
Handling deprecation for mapreduce.map.maxattempts
Handling deprecation for yarn.http.policy
Handling deprecation for dfs.namenode.audit.loggers
Handling deprecation for hadoop.security.groups.cache.warn.after.ms
Handling deprecation for io.serializations
Handling deprecation for mapreduce.tasktracker.outofband.heartbeat
Handling deprecation for mapreduce.reduce.shuffle.read.timeout
Handling deprecation for hadoop.security.crypto.buffer.size
Handling deprecation for mapreduce.reduce.skip.proc.count.autoincr
Handling deprecation for mapreduce.ifile.readahead.bytes
Handling deprecation for dfs.http.policy
Handling deprecation for hadoop.registry.secure
Handling deprecation for dfs.namenode.safemode.min.datanodes
Handling deprecation for dfs.client.file-block-storage-locations.num-threads
Handling deprecation for mapreduce.cluster.local.dir
Handling deprecation for mapreduce.tasktracker.report.address
Handling deprecation for dfs.namenode.secondary.https-address
Handling deprecation for hadoop.kerberos.kinit.command
Handling deprecation for yarn.timeline-service.http-authentication.type
Handling deprecation for dfs.block.access.token.lifetime
Handling deprecation for dfs.webhdfs.enabled
Handling deprecation for dfs.namenode.delegation.token.max-lifetime
Handling deprecation for dfs.namenode.avoid.write.stale.datanode
Handling deprecation for dfs.datanode.drop.cache.behind.writes
Handling deprecation for yarn.log-aggregation.retain-seconds
Handling deprecation for mapreduce.job.complete.cancel.delegation.tokens
Handling deprecation for mapreduce.local.clientfactory.class.name
Handling deprecation for mapreduce.shuffle.connection-keep-alive.timeout
Handling deprecation for dfs.namenode.num.extra.edits.retained
Handling deprecation for yarn.scheduler.minimum-allocation-vcores
Handling deprecation for ipc.client.connect.max.retries.on.timeouts
Handling deprecation for yarn.timeline-service.client.retry-interval-ms
Handling deprecation for yarn.timeline-service.client.max-retries
Handling deprecation for fs.s3n.block.size
Handling deprecation for mapreduce.job.map.output.collector.class
Handling deprecation for ha.health-monitor.connect-retry-interval.ms
Handling deprecation for mapreduce.shuffle.max.threads
Handling deprecation for nfs.exports.allowed.hosts
Handling deprecation for dfs.client.mmap.cache.size
Handling deprecation for mapreduce.tasktracker.map.tasks.maximum
Handling deprecation for io.file.buffer.size
Handling deprecation for dfs.client.datanode-restart.timeout
Handling deprecation for io.mapfile.bloom.size
Handling deprecation for hadoop.security.kms.client.authentication.retry-count
Handling deprecation for dfs.namenode.checkpoint.txns
Handling deprecation for ipc.client.connect.retry.interval
Handling deprecation for dfs.client-write-packet-size
Handling deprecation for mapreduce.reduce.shuffle.connect.timeout
Handling deprecation for yarn.resourcemanager.fs.state-store.uri
Handling deprecation for fs.swift.impl
Handling deprecation for hadoop.registry.zk.connection.timeout.ms
Handling deprecation for mapred.queue.default.acl-administer-jobs
Handling deprecation for mapreduce.job.submithostaddress
Handling deprecation for dfs.cachereport.intervalMsec
Handling deprecation for yarn.app.mapreduce.shuffle.log.backups
Handling deprecation for yarn.app.mapreduce.am.container.log.limit.kb
Handling deprecation for yarn.nodemanager.resourcemanager.minimum.version
Handling deprecation for ftp.blocksize
Handling deprecation for yarn.resourcemanager.address
Handling deprecation for file.stream-buffer-size
Handling deprecation for yarn.resourcemanager.scheduler.monitor.enable
Handling deprecation for mapreduce.job.ubertask.maxreduces
Handling deprecation for nfs.allow.insecure.ports
Handling deprecation for yarn.sharedcache.nm.uploader.thread-count
Handling deprecation for ipc.client.idlethreshold
Handling deprecation for ftp.stream-buffer-size
Handling deprecation for yarn.sharedcache.client-server.address
Handling deprecation for dfs.client.failover.connection.retries.on.timeouts
Handling deprecation for dfs.namenode.replication.work.multiplier.per.iteration
Handling deprecation for hadoop.http.authentication.simple.anonymous.allowed
Handling deprecation for hadoop.security.authorization
Handling deprecation for yarn.client.nodemanager-connect.retry-interval-ms
Handling deprecation for yarn.am.liveness-monitor.expiry-interval-ms
Handling deprecation for fs.har.impl.disable.cache
Handling deprecation for yarn.nodemanager.linux-container-executor.resources-handler.class
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.read-cache-size
Handling deprecation for hadoop.security.authentication
Handling deprecation for dfs.image.compression.codec
Handling deprecation for mapreduce.task.files.preserve.failedtasks
Handling deprecation for dfs.client.read.shortcircuit.streams.cache.size
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.path
Handling deprecation for mapreduce.job.reduce.slowstart.completedmaps
Handling deprecation for mapreduce.jobhistory.minicluster.fixed.ports
Handling deprecation for file.replication
Handling deprecation for yarn.resourcemanager.ha.automatic-failover.enabled
Handling deprecation for mapreduce.job.userlog.retain.hours
Handling deprecation for mapreduce.jobhistory.joblist.cache.size
Handling deprecation for dfs.namenode.accesstime.precision
Handling deprecation for yarn.resourcemanager.work-preserving-recovery.enabled
Handling deprecation for dfs.namenode.fs-limits.max-xattrs-per-inode
Handling deprecation for io.mapfile.bloom.error.rate
Handling deprecation for yarn.resourcemanager.store.class
Handling deprecation for dfs.image.transfer.timeout
Handling deprecation for yarn.timeline-service.leveldb-state-store.path
Handling deprecation for nfs.wtmax
Handling deprecation for mapreduce.job.combine.class
Handling deprecation for dfs.namenode.support.allow.format
Handling deprecation for fs.s3a.multipart.purge
Handling deprecation for dfs.secondary.namenode.kerberos.internal.spnego.principal
Handling deprecation for fs.s3a.connection.establish.timeout
Handling deprecation for dfs.stream-buffer-size
Handling deprecation for dfs.namenode.invalidate.work.pct.per.iteration
Handling deprecation for yarn.nodemanager.container-executor.class
Handling deprecation for fs.s3a.multipart.purge.age
Handling deprecation for yarn.resourcemanager.scheduler.client.thread-count
Handling deprecation for dfs.namenode.top.enabled
Handling deprecation for yarn.app.mapreduce.shuffle.log.separate
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.low-watermark
Handling deprecation for fs.s3a.fast.buffer.size
Handling deprecation for hadoop.user.group.static.mapping.overrides
Handling deprecation for tfile.fs.input.buffer.size
Handling deprecation for dfs.client.cached.conn.retry
Handling deprecation for hadoop.http.authentication.type
Handling deprecation for dfs.namenode.list.encryption.zones.num.responses
Handling deprecation for mapreduce.map.cpu.vcores
Handling deprecation for dfs.namenode.path.based.cache.refresh.interval.ms
Handling deprecation for dfs.namenode.decommission.interval
Handling deprecation for dfs.namenode.fs-limits.max-directory-items
Handling deprecation for yarn.resourcemanager.zk-retry-interval-ms
Handling deprecation for ftp.bytes-per-checksum
Handling deprecation for dfs.ha.log-roll.period
Handling deprecation for dfs.user.home.dir.prefix
Handling deprecation for ipc.client.fallback-to-simple-auth-allowed
Handling deprecation for yarn.nodemanager.pmem-check-enabled
Handling deprecation for yarn.nodemanager.remote-app-log-dir
Handling deprecation for dfs.namenode.inotify.max.events.per.rpc
Handling deprecation for mapreduce.task.profile.maps
Handling deprecation for mapreduce.shuffle.ssl.file.buffer.size
Handling deprecation for mapreduce.tasktracker.healthchecker.script.timeout
Handling deprecation for yarn.timeline-service.webapp.https.address
Handling deprecation for yarn.nodemanager.resource.percentage-physical-cpu-limit
Handling deprecation for yarn.app.mapreduce.am.command-opts
Handling deprecation for dfs.namenode.fs-limits.max-xattr-size
Handling deprecation for dfs.datanode.http.address
Handling deprecation for dfs.namenode.blocks.per.postponedblocks.rescan
Handling deprecation for yarn.sharedcache.nm.uploader.replication.factor
Handling deprecation for hadoop.registry.zk.root
Handling deprecation for hadoop.jetty.logs.serve.aliases
Handling deprecation for yarn.client.failover-proxy-provider
Handling deprecation for mapreduce.jobhistory.admin.acl
Handling deprecation for yarn.app.mapreduce.am.hard-kill-timeout-ms
Handling deprecation for yarn.nodemanager.remote-app-log-dir-suffix
Handling deprecation for mapreduce.jobhistory.principal
Handling deprecation for yarn.resourcemanager.webapp.address
Handling deprecation for mapreduce.jobhistory.recovery.enable
Handling deprecation for yarn.sharedcache.store.in-memory.check-period-mins
Handling deprecation for nfs.mountd.port
Handling deprecation for mapreduce.reduce.merge.inmem.threshold
Handling deprecation for fs.df.interval
Handling deprecation for yarn.timeline-service.enabled
Handling deprecation for mapreduce.jobtracker.jobhistory.lru.cache.size
Handling deprecation for mapreduce.task.profile
Handling deprecation for mapreduce.job.output.key.class
Handling deprecation for yarn.nodemanager.hostname
Handling deprecation for dfs.namenode.num.checkpoints.retained
Handling deprecation for mapreduce.job.queuename
Handling deprecation for mapreduce.jobhistory.max-age-ms
Handling deprecation for mapreduce.job.token.tracking.ids.enabled
Handling deprecation for yarn.nodemanager.localizer.client.thread-count
Handling deprecation for yarn.sharedcache.uploader.server.thread-count
Handling deprecation for dfs.client.mmap.retry.timeout.ms
Handling deprecation for mapreduce.jobhistory.move.thread-count
Handling deprecation for dfs.permissions.enabled
Handling deprecation for dfs.blockreport.split.threshold
Handling deprecation for fs.AbstractFileSystem.hdfs.impl
Handling deprecation for dfs.datanode.balance.bandwidthPerSec
Handling deprecation for dfs.block.scanner.volume.bytes.per.second
Handling deprecation for hadoop.http.filter.initializers
Handling deprecation for yarn.timeline-service.http-authentication.simple.anonymous.allowed
Handling deprecation for dfs.default.chunk.view.size
Handling deprecation for yarn.sharedcache.client-server.thread-count
Handling deprecation for yarn.resourcemanager.resource-tracker.address
Handling deprecation for mapreduce.job.working.dir
Handling deprecation for mapreduce.jobhistory.datestring.cache.size
Handling deprecation for mapreduce.task.profile.params
Handling deprecation for dfs.namenode.decommission.blocks.per.interval
Handling deprecation for dfs.namenode.handler.count
Handling deprecation for dfs.image.transfer.bandwidthPerSec
Handling deprecation for rpc.metrics.quantile.enable
Handling deprecation for mapreduce.jobtracker.expire.trackers.interval
Handling deprecation for mapreduce.task.timeout
Handling deprecation for yarn.app.mapreduce.client.max-retries
Handling deprecation for yarn.nodemanager.resource.memory-mb
Handling deprecation for yarn.nodemanager.disk-health-checker.min-healthy-disks
Handling deprecation for dfs.datanode.failed.volumes.tolerated
Handling deprecation for yarn.timeline-service.handler-thread-count
Handling deprecation for ipc.server.listen.queue.size
Handling deprecation for fs.s3a.threads.max
Handling deprecation for yarn.resourcemanager.connect.max-wait.ms
Handling deprecation for mapreduce.fileoutputcommitter.algorithm.version
Handling deprecation for mapreduce.framework.name
Handling deprecation for mapreduce.map.skip.proc.count.autoincr
Handling deprecation for mapreduce.job.max.split.locations
Handling deprecation for yarn.resourcemanager.scheduler.class
Handling deprecation for yarn.resourcemanager.system-metrics-publisher.enabled
Handling deprecation for dfs.blocksize
Handling deprecation for yarn.sharedcache.nested-level
Handling deprecation for mapreduce.shuffle.connection-keep-alive.enable
Handling deprecation for fs.s3a.threads.keepalivetime
Handling deprecation for fs.s3a.connection.timeout
Handling deprecation for file.client-write-packet-size
Handling deprecation for ha.failover-controller.cli-check.rpc-timeout.ms
Handling deprecation for ha.zookeeper.acl
Handling deprecation for dfs.namenode.write.stale.datanode.ratio
Handling deprecation for dfs.encrypt.data.transfer
Handling deprecation for dfs.datanode.shared.file.descriptor.paths
Handling deprecation for mapreduce.input.lineinputformat.linespermap
Handling deprecation for yarn.resourcemanager.delayed.delegation-token.removal-interval-ms
Handling deprecation for yarn.nodemanager.localizer.fetch.thread-count
Handling deprecation for dfs.client.failover.max.attempts
Handling deprecation for yarn.resourcemanager.scheduler.address
Handling deprecation for dfs.client.read.shortcircuit.streams.cache.expiry.ms
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.start-time-write-cache-size
Handling deprecation for yarn.nodemanager.health-checker.script.timeout-ms
Handling deprecation for yarn.resourcemanager.fs.state-store.num-retries
Handling deprecation for hadoop.ssl.require.client.cert
Handling deprecation for hadoop.security.uid.cache.secs
Handling deprecation for mapreduce.jobhistory.keytab
Handling deprecation for dfs.client.read.shortcircuit.skip.checksum
Handling deprecation for yarn.resourcemanager.ha.automatic-failover.zk-base-path
Handling deprecation for mapreduce.shuffle.ssl.enabled
Handling deprecation for mapreduce.reduce.log.level
Handling deprecation for hadoop.registry.rm.enabled
Handling deprecation for mapreduce.tasktracker.dns.interface
Handling deprecation for yarn.resourcemanager.system-metrics-publisher.dispatcher.pool-size
Handling deprecation for mapreduce.job.speculative.speculative-cap-running-tasks
Handling deprecation for dfs.datanode.block.id.layout.upgrade.threads
Handling deprecation for dfs.datanode.use.datanode.hostname
Handling deprecation for dfs.client.context
Handling deprecation for yarn.resourcemanager.ha.enabled
Handling deprecation for mapred.reducer.new-api
Handling deprecation for dfs.namenode.delegation.token.renew-interval
Handling deprecation for dfs.blockreport.intervalMsec
Handling deprecation for fs.s3a.multipart.threshold
Handling deprecation for mapreduce.reduce.shuffle.memory.limit.percent
Handling deprecation for dfs.https.server.keystore.resource
Handling deprecation for io.map.index.skip
Handling deprecation for mapreduce.job.hdfs-servers
Handling deprecation for mapreduce.jobtracker.taskscheduler
Handling deprecation for dfs.namenode.kerberos.internal.spnego.principal
Handling deprecation for yarn.resourcemanager.state-store.max-completed-applications
Handling deprecation for mapreduce.map.output.compress
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.num.refill.threads
Handling deprecation for fs.s3n.multipart.uploads.block.size
Handling deprecation for mapreduce.task.merge.progress.records
Handling deprecation for dfs.datanode.dns.interface
Handling deprecation for map.sort.class
Handling deprecation for yarn.nodemanager.aux-services.mapreduce_shuffle.class
Handling deprecation for tfile.fs.output.buffer.size
Handling deprecation for fs.du.interval
Handling deprecation for dfs.client.failover.connection.retries
Handling deprecation for dfs.namenode.top.window.num.buckets
Handling deprecation for mapreduce.job.dir
Handling deprecation for fs.s3a.buffer.dir
Handling deprecation for mapreduce.reduce.shuffle.retry-delay.max.ms
Handling deprecation for yarn.sharedcache.uploader.server.address
Handling deprecation for mapreduce.client.progressmonitor.pollinterval
Handling deprecation for yarn.app.mapreduce.shuffle.log.limit.kb
Handling deprecation for dfs.datanode.max.locked.memory
Handling deprecation for dfs.namenode.retrycache.expirytime.millis
Handling deprecation for dfs.datanode.scan.period.hours
Handling deprecation for dfs.client.block.write.replace-datanode-on-failure.best-effort
Handling deprecation for mapreduce.jobhistory.move.interval-ms
Handling deprecation for dfs.ha.fencing.ssh.connect-timeout
Handling deprecation for yarn.nodemanager.log-aggregation.roll-monitoring-interval-seconds
Handling deprecation for dfs.namenode.fs-limits.max-component-length
Handling deprecation for hadoop.registry.zk.quorum
Handling deprecation for dfs.namenode.enable.retrycache
Handling deprecation for dfs.datanode.du.reserved
Handling deprecation for yarn.timeline-service.state-store-class
Handling deprecation for dfs.datanode.ipc.address
Handling deprecation for hadoop.registry.system.acls
Handling deprecation for dfs.client.block.write.replace-datanode-on-failure.policy
Handling deprecation for dfs.namenode.path.based.cache.retry.interval.ms
Handling deprecation for hadoop.security.crypto.cipher.suite
Handling deprecation for dfs.ha.tail-edits.period
Handling deprecation for mapreduce.task.profile.reduce.params
Handling deprecation for hadoop.registry.jaas.context
Handling deprecation for yarn.resourcemanager.hostname
Handling deprecation for mapreduce.reduce.memory.mb
Handling deprecation for hadoop.security.group.mapping.ldap.search.filter.group
Handling deprecation for hadoop.http.authentication.kerberos.principal
Handling deprecation for hadoop.security.group.mapping.ldap.search.filter.user
Handling deprecation for yarn.nodemanager.disk-health-checker.min-free-space-per-disk-mb
Handling deprecation for dfs.namenode.edits.dir
Handling deprecation for yarn.client.failover-retries-on-socket-timeouts
Handling deprecation for dfs.namenode.decommission.max.concurrent.tracked.nodes
Handling deprecation for mapreduce.client.completion.pollinterval
Handling deprecation for dfs.namenode.name.dir.restore
Handling deprecation for dfs.namenode.secondary.http-address
Handling deprecation for mapreduce.jobhistory.recovery.store.leveldb.path
Handling deprecation for yarn.sharedcache.store.class
Handling deprecation for s3.bytes-per-checksum
Handling deprecation for yarn.nodemanager.windows-container.cpu-limit.enabled
Handling deprecation for yarn.resourcemanager.webapp.https.address
Handling deprecation for yarn.nodemanager.vmem-pmem-ratio
Handling deprecation for dfs.namenode.checkpoint.period
Handling deprecation for dfs.ha.automatic-failover.enabled
The url to track the job: http://localhost:8080/
OutputCommitter set in config null
Running job: job_local1072276750_0001
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
File Output Committer Algorithm version is 1
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
/user/michaeljones/wcOutputMain/_temporary/0: masked=rwxr-xr-x
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones sending #12
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones got value #12
Call: mkdirs took 37ms
Starting mapper thread pool executor.
Max local threads: 1
Map tasks to process: 1
Waiting for map tasks
Starting task: attempt_local1072276750_0001_m_000000_0
currentIndex 0   0:0
mapreduce.cluster.local.dir for child : /tmp/hadoop-michaeljones/mapred/local/localRunner//michaeljones/jobcache/job_local1072276750_0001/attempt_local1072276750_0001_m_000000_0
using new api for output committer
File Output Committer Algorithm version is 1
ProcfsBasedProcessTree currently is supported only on Linux.
 Using ResourceCalculatorProcessTree : null
Processing split: hdfs://localhost:9000/user/michaeljones/wcInput:0+50
Trying map output collector class: org.apache.hadoop.mapred.MapTask$MapOutputBuffer
(EQUATOR) 0 kvi 26214396(104857584)
mapreduce.task.io.sort.mb: 100
soft limit at 83886080
bufstart = 0; bufvoid = 104857600
kvstart = 26214396; length = 6553600
Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones sending #13
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones got value #13
Call: getBlockLocations took 2ms
newInfo = LocatedBlocks{
  fileLength=50
  underConstruction=false
  blocks=[LocatedBlock{BP-1045030256-10.0.0.2-1433119149314:blk_1073741825_1002; getBlockSize()=50; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-b42c5705-9ba4-4b14-b00b-f9194bb036f0,DISK]]}]
  lastLocatedBlock=LocatedBlock{BP-1045030256-10.0.0.2-1433119149314:blk_1073741825_1002; getBlockSize()=50; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-b42c5705-9ba4-4b14-b00b-f9194bb036f0,DISK]]}
  isLastBlockComplete=true}
Connecting to datanode 127.0.0.1:50010

Starting flush of map output
Spilling map output
bufstart = 0; bufend = 82; bufvoid = 104857600
kvstart = 26214396(104857584); kvend = 26214368(104857472); length = 29/6553600
Finished spill 0
Task:attempt_local1072276750_0001_m_000000_0 is done. And is in the process of committing
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones sending #14
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones got value #14
Call: getFileInfo took 3ms
map
Task 'attempt_local1072276750_0001_m_000000_0' done.
Finishing task: attempt_local1072276750_0001_m_000000_0
map task executor complete.
Starting reduce thread pool executor.
Max local threads: 1
Reduce tasks to process: 1
Waiting for reduce tasks
Starting task: attempt_local1072276750_0001_r_000000_0
currentIndex 0   0:0
mapreduce.cluster.local.dir for child : /tmp/hadoop-michaeljones/mapred/local/localRunner//michaeljones/jobcache/job_local1072276750_0001/attempt_local1072276750_0001_r_000000_0
using new api for output committer
File Output Committer Algorithm version is 1
ProcfsBasedProcessTree currently is supported only on Linux.
 Using ResourceCalculatorProcessTree : null
Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@62e72265
MergerManager: memoryLimit=668309888, maxSingleShuffleLimit=167077472, mergeThreshold=441084544, ioSortFactor=10, memToMemMergeOutputsThreshold=10
attempt_local1072276750_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
Got 0 map completion events from 0
GetMapEventsThread about to sleep for 1000
LocalFetcher 1 going to fetch: attempt_local1072276750_0001_m_000000_0
attempt_local1072276750_0001_m_000000_0: Proceeding with shuffle since usedMemory (0) is lesser than memoryLimit (668309888).CommitMemory is (0)
localfetcher#1 about to shuffle output of map attempt_local1072276750_0001_m_000000_0 decomp: 63 len: 67 to MEMORY
Read 63 bytes from map-output for attempt_local1072276750_0001_m_000000_0
closeInMemoryFile -> map-output of size: 63, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->63
map attempt_local1072276750_0001_m_000000_0 done 1 / 1 copied.
EventFetcher is interrupted.. Returning
1 / 1 copied.
finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
Merging 1 sorted segments
Down to the last merge-pass, with 1 segments left of total size: 57 bytes
Merged 1 segments, 63 bytes to disk to satisfy reduce memory limit
Disk file: /tmp/hadoop-michaeljones/mapred/local/localRunner/michaeljones/jobcache/job_local1072276750_0001/attempt_local1072276750_0001_r_000000_0/output/map_0.out.merged Length is 67
Merging 1 files, 67 bytes from disk
Merging 0 segments, 0 bytes from memory into reduce
Merging 1 sorted segments
Down to the last merge-pass, with 1 segments left of total size: 57 bytes
1 / 1 copied.
/user/michaeljones/wcOutputMain/_temporary/0/_temporary/attempt_local1072276750_0001_r_000000_0/part-r-00000: masked=rw-r--r--
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones sending #15
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones got value #15
Call: create took 5ms
computePacketChunkSize: src=/user/michaeljones/wcOutputMain/_temporary/0/_temporary/attempt_local1072276750_0001_r_000000_0/part-r-00000, chunkSize=516, chunksPerPacket=126, packetSize=65016
mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
DFSClient writeChunk allocating new packet seqno=0, src=/user/michaeljones/wcOutputMain/_temporary/0/_temporary/attempt_local1072276750_0001_r_000000_0/part-r-00000, packetSize=65016, chunksPerPacket=126, bytesCurBlock=0
Queued packet 0
Allocating new block
Queued packet 1
Waiting for ack for: 1
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones sending #16
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones got value #16
Call: addBlock took 4ms
pipeline = DatanodeInfoWithStorage[127.0.0.1:50010,DS-b42c5705-9ba4-4b14-b00b-f9194bb036f0,DISK]
Connecting to datanode 127.0.0.1:50010
Send buf size 131072
SASL client skipping handshake in unsecured configuration for addr = /127.0.0.1, datanodeId = DatanodeInfoWithStorage[127.0.0.1:50010,DS-b42c5705-9ba4-4b14-b00b-f9194bb036f0,DISK]
DataStreamer block BP-1045030256-10.0.0.2-1433119149314:blk_1073742378_1555 sending packet packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 41
DFSClient seqno: 0 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
DataStreamer block BP-1045030256-10.0.0.2-1433119149314:blk_1073742378_1555 sending packet packet seqno: 1 offsetInBlock: 41 lastPacketInBlock: true lastByteOffsetInBlock: 41
DFSClient seqno: 1 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
Closing old block BP-1045030256-10.0.0.2-1433119149314:blk_1073742378_1555
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones sending #17
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones got value #17
Call: complete took 3ms
Task:attempt_local1072276750_0001_r_000000_0 is done. And is in the process of committing
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones sending #18
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones got value #18
Call: getFileInfo took 2ms
1 / 1 copied.
Task attempt_local1072276750_0001_r_000000_0 is allowed to commit now
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones sending #19
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones got value #19
Call: getFileInfo took 2ms
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones sending #20
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones got value #20
Call: getFileInfo took 2ms
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones sending #21
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones got value #21
Call: rename took 22ms
Saved output of task 'attempt_local1072276750_0001_r_000000_0' to hdfs://localhost:9000/user/michaeljones/wcOutputMain/_temporary/0/task_local1072276750_0001_r_000000
reduce > reduce
Task 'attempt_local1072276750_0001_r_000000_0' done.
Finishing task: attempt_local1072276750_0001_r_000000_0
reduce task executor complete.
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones sending #22
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones got value #22
Call: getListing took 3ms
Merging data from FileStatus{path=hdfs://localhost:9000/user/michaeljones/wcOutputMain/_temporary/0/task_local1072276750_0001_r_000000; isDirectory=true; modification_time=1434253171134; access_time=0; owner=michaeljones; group=supergroup; permission=rwxr-xr-x; isSymlink=false} to hdfs://localhost:9000/user/michaeljones/wcOutputMain
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones sending #23
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones got value #23
Call: getFileInfo took 2ms
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones sending #24
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones got value #24
Call: getListing took 3ms
Merging data from FileStatus{path=hdfs://localhost:9000/user/michaeljones/wcOutputMain/_temporary/0/task_local1072276750_0001_r_000000/part-r-00000; isDirectory=false; length=41; replication=1; blocksize=134217728; modification_time=1434253171167; access_time=1434253171134; owner=michaeljones; group=supergroup; permission=rw-r--r--; isSymlink=false} to hdfs://localhost:9000/user/michaeljones/wcOutputMain/part-r-00000
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones sending #25
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones got value #25
Call: getFileInfo took 1ms
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones sending #26
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones got value #26
Call: rename took 4ms
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones sending #27
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones got value #27
Call: delete took 3ms
/user/michaeljones/wcOutputMain/_SUCCESS: masked=rw-r--r--
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones sending #28
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones got value #28
Call: create took 5ms
computePacketChunkSize: src=/user/michaeljones/wcOutputMain/_SUCCESS, chunkSize=516, chunksPerPacket=126, packetSize=65016
Waiting for ack for: -1
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones sending #29
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones got value #29
Call: complete took 3ms
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.fs.FileContext.getAbstractFileSystem(FileContext.java:331)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
Job job_local1072276750_0001 running in uber mode : false
 map 100% reduce 100%
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.getTaskCompletionEvents(Job.java:670)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.getTaskCompletionEvents(Job.java:670)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
Job job_local1072276750_0001 completed successfully
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.getCounters(Job.java:758)
Counters: 35
	File System Counters
		FILE: Number of bytes read=520
		FILE: Number of bytes written=565643
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=140
		HDFS: Number of bytes written=81
		HDFS: Number of read operations=19
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=10
	Map-Reduce Framework
		Map input records=2
		Map output records=8
		Map output bytes=82
		Map output materialized bytes=67
		Input split bytes=112
		Combine input records=8
		Combine output records=5
		Reduce input groups=5
		Reduce shuffle bytes=67
		Reduce input records=5
		Reduce output records=5
		Spilled Records=10
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=668991488
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=50
	File Output Format Counters 
		Bytes Written=41
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
RunJobAsync
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones sending #30
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones got value #30
Call: getFileInfo took 5ms
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones sending #31
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones got value #31
Call: delete took 10ms
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.connect(Job.java:1256)
Trying ClientProtocolProvider : org.apache.hadoop.mapred.LocalClientProtocolProvider
Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
Picked org.apache.hadoop.mapred.LocalClientProtocolProvider as the ClientProtocolProvider
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Cluster.getFileSystem(Cluster.java:162)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.submit(Job.java:1287)
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones sending #32
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones got value #32
Call: getFileInfo took 3ms
Configuring job job_local183065926_0002 with file:/tmp/hadoop-michaeljones/mapred/staging/michaeljones183065926/.staging/job_local183065926_0002 as the submit dir
adding the following namenodes' delegation tokens:[hdfs://localhost:9000]
Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
default FileSystem: file:///
No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
Creating splits at file:/tmp/hadoop-michaeljones/mapred/staging/michaeljones183065926/.staging/job_local183065926_0002
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones sending #33
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones got value #33
Call: getFileInfo took 6ms
Time taken to get FileStatuses: 7
Total input paths to process : 1
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones sending #34
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones got value #34
Call: getBlockLocations took 3ms
Total # of splits generated by getSplits: 1, TimeTaken: 13
number of splits:1
Handling deprecation for all properties in config...
Handling deprecation for mapreduce.jobtracker.address
Handling deprecation for yarn.resourcemanager.scheduler.monitor.policies
Handling deprecation for dfs.namenode.resource.check.interval
Handling deprecation for mapreduce.jobhistory.client.thread-count
Handling deprecation for yarn.app.mapreduce.am.containerlauncher.threadpool-initial-size
Handling deprecation for mapred.child.java.opts
Handling deprecation for mapreduce.jobtracker.retiredjobs.cache.size
Handling deprecation for dfs.client.https.need-auth
Handling deprecation for yarn.admin.acl
Handling deprecation for yarn.app.mapreduce.am.job.committer.cancel-timeout
Handling deprecation for mapreduce.job.emit-timeline-data
Handling deprecation for fs.ftp.host.port
Handling deprecation for dfs.namenode.avoid.read.stale.datanode
Handling deprecation for dfs.journalnode.rpc-address
Handling deprecation for mapreduce.job.end-notification.retry.attempts
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.ttl-interval-ms
Handling deprecation for yarn.resourcemanager.leveldb-state-store.path
Handling deprecation for mapred.mapper.new-api
Handling deprecation for yarn.ipc.rpc.class
Handling deprecation for ipc.client.connection.maxidletime
Handling deprecation for yarn.nodemanager.process-kill-wait.ms
Handling deprecation for mapreduce.cluster.acls.enabled
Handling deprecation for mapreduce.jobtracker.handler.count
Handling deprecation for io.map.index.interval
Handling deprecation for dfs.namenode.https-address
Handling deprecation for mapreduce.task.profile.reduces
Handling deprecation for fs.s3n.multipart.uploads.enabled
Handling deprecation for io.seqfile.sorter.recordlimit
Handling deprecation for mapreduce.job.ubertask.maxmaps
Handling deprecation for mapreduce.tasktracker.tasks.sleeptimebeforesigkill
Handling deprecation for hadoop.util.hash.type
Handling deprecation for dfs.namenode.replication.min
Handling deprecation for yarn.nodemanager.container-manager.thread-count
Handling deprecation for mapreduce.jobtracker.jobhistory.block.size
Handling deprecation for dfs.namenode.fs-limits.min-block-size
Handling deprecation for mapreduce.app-submission.cross-platform
Handling deprecation for fs.AbstractFileSystem.file.impl
Handling deprecation for net.topology.script.number.args
Handling deprecation for yarn.resourcemanager.container-tokens.master-key-rolling-interval-secs
Handling deprecation for mapreduce.map.output.compress.codec
Handling deprecation for mapreduce.job.reducer.preempt.delay.sec
Handling deprecation for s3native.bytes-per-checksum
Handling deprecation for dfs.namenode.path.based.cache.block.map.allocation.percent
Handling deprecation for yarn.nodemanager.windows-container.memory-limit.enabled
Handling deprecation for mapreduce.input.fileinputformat.split.minsize
Handling deprecation for hadoop.security.group.mapping
Handling deprecation for mapreduce.jobtracker.system.dir
Handling deprecation for mapreduce.job.end-notification.max.attempts
Handling deprecation for mapreduce.reduce.markreset.buffer.percent
Handling deprecation for dfs.datanode.cache.revocation.polling.ms
Handling deprecation for mapreduce.reduce.speculative
Handling deprecation for yarn.nodemanager.localizer.cache.cleanup.interval-ms
Handling deprecation for dfs.namenode.lazypersist.file.scrub.interval.sec
Handling deprecation for fs.s3a.threads.core
Handling deprecation for mapreduce.jobhistory.recovery.store.fs.uri
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.start-time-read-cache-size
Handling deprecation for hadoop.registry.zk.retry.interval.ms
Handling deprecation for yarn.nodemanager.keytab
Handling deprecation for dfs.namenode.replication.interval
Handling deprecation for yarn.resourcemanager.admin.address
Handling deprecation for mapreduce.job.maps
Handling deprecation for nfs.dump.dir
Handling deprecation for mapreduce.job.user.name
Handling deprecation for mapreduce.jobtracker.maxtasks.perjob
Handling deprecation for mapreduce.job.ubertask.enable
Handling deprecation for mapreduce.job.reduce.class
Handling deprecation for yarn.nodemanager.delete.debug-delay-sec
Handling deprecation for yarn.timeline-service.ttl-enable
Handling deprecation for yarn.resourcemanager.fs.state-store.retry-policy-spec
Handling deprecation for mapreduce.reduce.skip.maxgroups
Handling deprecation for dfs.client.use.datanode.hostname
Handling deprecation for fs.trash.interval
Handling deprecation for mapreduce.job.name
Handling deprecation for mapreduce.am.max-attempts
Handling deprecation for mapreduce.jobtracker.heartbeats.in.second
Handling deprecation for yarn.resourcemanager.zk-num-retries
Handling deprecation for s3.blocksize
Handling deprecation for dfs.datanode.data.dir
Handling deprecation for mapreduce.jobtracker.persist.jobstatus.active
Handling deprecation for mapreduce.reduce.shuffle.parallelcopies
Handling deprecation for fs.s3.buffer.dir
Handling deprecation for mapreduce.jobhistory.done-dir
Handling deprecation for hadoop.security.instrumentation.requires.admin
Handling deprecation for hadoop.registry.zk.retry.ceiling.ms
Handling deprecation for nfs.rtmax
Handling deprecation for dfs.datanode.data.dir.perm
Handling deprecation for yarn.resourcemanager.container.liveness-monitor.interval-ms
Handling deprecation for yarn.nodemanager.env-whitelist
Handling deprecation for dfs.namenode.backup.address
Handling deprecation for dfs.namenode.xattrs.enabled
Handling deprecation for dfs.datanode.readahead.bytes
Handling deprecation for mapreduce.jobhistory.cleaner.enable
Handling deprecation for dfs.client.block.write.retries
Handling deprecation for mapreduce.tasktracker.http.address
Handling deprecation for yarn.nodemanager.linux-container-executor.cgroups.hierarchy
Handling deprecation for ha.failover-controller.graceful-fence.connection.retries
Handling deprecation for yarn.resourcemanager.recovery.enabled
Handling deprecation for yarn.app.mapreduce.am.container.log.backups
Handling deprecation for dfs.namenode.safemode.threshold-pct
Handling deprecation for yarn.nodemanager.disk-health-checker.interval-ms
Handling deprecation for hadoop.security.java.secure.random.algorithm
Handling deprecation for dfs.namenode.list.cache.directives.num.responses
Handling deprecation for dfs.datanode.dns.nameserver
Handling deprecation for mapreduce.cluster.temp.dir
Handling deprecation for fs.s3a.max.total.tasks
Handling deprecation for mapreduce.reduce.maxattempts
Handling deprecation for mapreduce.client.submit.file.replication
Handling deprecation for mapreduce.shuffle.port
Handling deprecation for yarn.resourcemanager.resource-tracker.client.thread-count
Handling deprecation for dfs.namenode.replication.considerLoad
Handling deprecation for dfs.namenode.edits.journal-plugin.qjournal
Handling deprecation for dfs.client.write.exclude.nodes.cache.expiry.interval.millis
Handling deprecation for yarn.nodemanager.delete.thread-count
Handling deprecation for dfs.client.mmap.cache.timeout.ms
Handling deprecation for yarn.nodemanager.admin-env
Handling deprecation for io.skip.checksum.errors
Handling deprecation for yarn.timeline-service.hostname
Handling deprecation for yarn.resourcemanager.proxy-user-privileges.enabled
Handling deprecation for mapreduce.job.speculative.speculative-cap-total-tasks
Handling deprecation for yarn.acl.enable
Handling deprecation for fs.s3a.fast.upload
Handling deprecation for file.blocksize
Handling deprecation for mapreduce.job.speculative.slowtaskthreshold
Handling deprecation for ftp.replication
Handling deprecation for yarn.sharedcache.cleaner.initial-delay-mins
Handling deprecation for s3native.client-write-packet-size
Handling deprecation for hadoop.rpc.socket.factory.class.default
Handling deprecation for file.bytes-per-checksum
Handling deprecation for dfs.datanode.slow.io.warning.threshold.ms
Handling deprecation for io.seqfile.lazydecompress
Handling deprecation for mapreduce.task.skip.start.attempts
Handling deprecation for dfs.namenode.reject-unresolved-dn-topology-mapping
Handling deprecation for hadoop.common.configuration.version
Handling deprecation for yarn.resourcemanager.client.thread-count
Handling deprecation for dfs.datanode.drop.cache.behind.reads
Handling deprecation for yarn.sharedcache.admin.address
Handling deprecation for mapreduce.job.output.value.class
Handling deprecation for mapreduce.output.fileoutputformat.outputdir
Handling deprecation for mapreduce.jobtracker.taskcache.levels
Handling deprecation for yarn.nodemanager.linux-container-executor.nonsecure-mode.user-pattern
Handling deprecation for yarn.resourcemanager.zk-timeout-ms
Handling deprecation for yarn.resourcemanager.max-completed-applications
Handling deprecation for mapreduce.job.jvm.numtasks
Handling deprecation for yarn.sharedcache.cleaner.period-mins
Handling deprecation for mapreduce.jobtracker.tasktracker.maxblacklists
Handling deprecation for dfs.namenode.top.num.users
Handling deprecation for yarn.nodemanager.linux-container-executor.cgroups.mount
Handling deprecation for yarn.sharedcache.checksum.algo.impl
Handling deprecation for mapreduce.job.end-notification.max.retry.interval
Handling deprecation for mapreduce.job.acl-view-job
Handling deprecation for mapreduce.job.classloader
Handling deprecation for yarn.log-aggregation-enable
Handling deprecation for mapreduce.reduce.shuffle.fetch.retry.interval-ms
Handling deprecation for yarn.resourcemanager.nodemanager.minimum.version
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.size
Handling deprecation for yarn.app.mapreduce.am.job.task.listener.thread-count
Handling deprecation for yarn.app.mapreduce.am.resource.cpu-vcores
Handling deprecation for dfs.namenode.edit.log.autoroll.check.interval.ms
Handling deprecation for mapreduce.output.fileoutputformat.compress.type
Handling deprecation for hadoop.hdfs.configuration.version
Handling deprecation for hadoop.security.group.mapping.ldap.search.attr.member
Handling deprecation for yarn.nodemanager.log.retain-seconds
Handling deprecation for yarn.nodemanager.local-cache.max-files-per-directory
Handling deprecation for mapreduce.job.end-notification.retry.interval
Handling deprecation for hadoop.ssl.client.conf
Handling deprecation for yarn.sharedcache.root-dir
Handling deprecation for dfs.journalnode.https-address
Handling deprecation for mapreduce.reduce.shuffle.fetch.retry.timeout-ms
Handling deprecation for dfs.bytes-per-checksum
Handling deprecation for dfs.namenode.max.objects
Handling deprecation for mapreduce.tasktracker.instrumentation
Handling deprecation for dfs.datanode.max.transfer.threads
Handling deprecation for dfs.block.access.key.update.interval
Handling deprecation for mapreduce.jobtracker.jobhistory.task.numberprogresssplits
Handling deprecation for mapreduce.map.memory.mb
Handling deprecation for ha.failover-controller.new-active.rpc-timeout.ms
Handling deprecation for hadoop.ssl.hostname.verifier
Handling deprecation for dfs.client.read.shortcircuit
Handling deprecation for dfs.datanode.hdfs-blocks-metadata.enabled
Handling deprecation for mapreduce.tasktracker.healthchecker.interval
Handling deprecation for dfs.image.transfer.chunksize
Handling deprecation for mapreduce.tasktracker.taskmemorymanager.monitoringinterval
Handling deprecation for dfs.client.https.keystore.resource
Handling deprecation for yarn.resourcemanager.connect.retry-interval.ms
Handling deprecation for yarn.timeline-service.webapp.address
Handling deprecation for s3native.blocksize
Handling deprecation for yarn.scheduler.minimum-allocation-mb
Handling deprecation for yarn.sharedcache.cleaner.resource-sleep-ms
Handling deprecation for net.topology.impl
Handling deprecation for dfs.client.failover.sleep.base.millis
Handling deprecation for dfs.permissions.superusergroup
Handling deprecation for io.seqfile.compress.blocksize
Handling deprecation for hadoop.registry.zk.retry.times
Handling deprecation for fs.AbstractFileSystem.ftp.impl
Handling deprecation for dfs.namenode.checkpoint.edits.dir
Handling deprecation for mapreduce.job.running.reduce.limit
Handling deprecation for dfs.blockreport.initialDelay
Handling deprecation for dfs.namenode.heartbeat.recheck-interval
Handling deprecation for dfs.namenode.safemode.extension
Handling deprecation for yarn.scheduler.maximum-allocation-mb
Handling deprecation for mapreduce.job.reduce.shuffle.consumer.plugin.class
Handling deprecation for yarn.nodemanager.vmem-check-enabled
Handling deprecation for mapreduce.task.io.sort.factor
Handling deprecation for mapreduce.jobtracker.persist.jobstatus.dir
Handling deprecation for dfs.client.failover.sleep.max.millis
Handling deprecation for dfs.namenode.delegation.key.update-interval
Handling deprecation for hadoop.rpc.protection
Handling deprecation for fs.permissions.umask-mode
Handling deprecation for fs.s3.sleepTimeSeconds
Handling deprecation for ha.health-monitor.rpc-timeout.ms
Handling deprecation for hadoop.http.staticuser.user
Handling deprecation for fs.s3a.connection.maximum
Handling deprecation for yarn.nodemanager.linux-container-executor.nonsecure-mode.limit-users
Handling deprecation for fs.s3a.paging.maximum
Handling deprecation for fs.AbstractFileSystem.viewfs.impl
Handling deprecation for fs.ftp.host
Handling deprecation for yarn.nodemanager.linux-container-executor.nonsecure-mode.local-user
Handling deprecation for fs.s3a.impl
Handling deprecation for hadoop.http.authentication.kerberos.keytab
Handling deprecation for dfs.namenode.fs-limits.max-blocks-per-file
Handling deprecation for mapreduce.tasktracker.http.threads
Handling deprecation for mapreduce.tasktracker.dns.nameserver
Handling deprecation for yarn.resourcemanager.am-rm-tokens.master-key-rolling-interval-secs
Handling deprecation for dfs.client.block.write.replace-datanode-on-failure.enable
Handling deprecation for io.compression.codec.bzip2.library
Handling deprecation for mapreduce.map.skip.maxrecords
Handling deprecation for dfs.client.use.legacy.blockreader.local
Handling deprecation for dfs.namenode.checkpoint.dir
Handling deprecation for dfs.namenode.top.windows.minutes
Handling deprecation for mapreduce.job.maxtaskfailures.per.tracker
Handling deprecation for net.topology.node.switch.mapping.impl
Handling deprecation for mapreduce.shuffle.max.connections
Handling deprecation for mapreduce.jobhistory.loadedjobs.cache.size
Handling deprecation for dfs.storage.policy.enabled
Handling deprecation for yarn.client.application-client-protocol.poll-interval-ms
Handling deprecation for yarn.nodemanager.localizer.address
Handling deprecation for dfs.namenode.list.cache.pools.num.responses
Handling deprecation for nfs.server.port
Handling deprecation for mapreduce.client.output.filter
Handling deprecation for yarn.timeline-service.client.best-effort
Handling deprecation for ha.zookeeper.parent-znode
Handling deprecation for mapreduce.jobtracker.persist.jobstatus.hours
Handling deprecation for yarn.sharedcache.admin.thread-count
Handling deprecation for yarn.nodemanager.resource.cpu-vcores
Handling deprecation for dfs.datanode.block-pinning.enabled
Handling deprecation for mapreduce.jobhistory.http.policy
Handling deprecation for yarn.resourcemanager.webapp.delegation-token-auth-filter.enabled
Handling deprecation for mapreduce.job.speculative.retry-after-no-speculate
Handling deprecation for fs.s3a.attempts.maximum
Handling deprecation for s3native.stream-buffer-size
Handling deprecation for io.seqfile.local.dir
Handling deprecation for yarn.log-aggregation.retain-check-interval-seconds
Handling deprecation for fs.s3n.multipart.copy.block.size
Handling deprecation for dfs.encrypt.data.transfer.cipher.key.bitlength
Handling deprecation for dfs.datanode.sync.behind.writes
Handling deprecation for yarn.resourcemanager.zk-acl
Handling deprecation for hadoop.ssl.keystores.factory.class
Handling deprecation for mapreduce.job.split.metainfo.maxsize
Handling deprecation for fs.s3.maxRetries
Handling deprecation for hadoop.security.random.device.file.path
Handling deprecation for yarn.client.nodemanager-connect.max-wait-ms
Handling deprecation for dfs.namenode.stale.datanode.interval
Handling deprecation for mapreduce.task.io.sort.mb
Handling deprecation for yarn.resourcemanager.zk-state-store.parent-path
Handling deprecation for yarn.app.mapreduce.client-am.ipc.max-retries
Handling deprecation for fs.client.resolve.remote.symlinks
Handling deprecation for yarn.nodemanager.linux-container-executor.cgroups.strict-resource-usage
Handling deprecation for hadoop.ssl.enabled.protocols
Handling deprecation for mapreduce.reduce.cpu.vcores
Handling deprecation for yarn.client.failover-retries
Handling deprecation for mapreduce.jobhistory.address
Handling deprecation for hadoop.ssl.enabled
Handling deprecation for dfs.replication.max
Handling deprecation for dfs.namenode.name.dir
Handling deprecation for dfs.datanode.https.address
Handling deprecation for ipc.client.kill.max
Handling deprecation for mapreduce.job.committer.setup.cleanup.needed
Handling deprecation for dfs.client.domain.socket.data.traffic
Handling deprecation for yarn.nodemanager.localizer.cache.target-size-mb
Handling deprecation for yarn.resourcemanager.admin.client.thread-count
Handling deprecation for dfs.block.access.token.enable
Handling deprecation for mapreduce.job.speculative.retry-after-speculate
Handling deprecation for dfs.datanode.address
Handling deprecation for mapreduce.jobtracker.restart.recover
Handling deprecation for ipc.client.connect.max.retries
Handling deprecation for yarn.timeline-service.store-class
Handling deprecation for dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
Handling deprecation for hadoop.tmp.dir
Handling deprecation for dfs.datanode.handler.count
Handling deprecation for yarn.resourcemanager.ha.automatic-failover.embedded
Handling deprecation for yarn.timeline-service.ttl-ms
Handling deprecation for mapreduce.task.profile.map.params
Handling deprecation for yarn.resourcemanager.nodemanagers.heartbeat-interval-ms
Handling deprecation for mapreduce.map.speculative
Handling deprecation for yarn.timeline-service.recovery.enabled
Handling deprecation for mapreduce.job.map.class
Handling deprecation for dfs.namenode.resource.checked.volumes.minimum
Handling deprecation for yarn.nodemanager.recovery.dir
Handling deprecation for mapreduce.job.counters.max
Handling deprecation for yarn.resourcemanager.keytab
Handling deprecation for dfs.namenode.max.extra.edits.segments.retained
Handling deprecation for dfs.webhdfs.user.provider.user.pattern
Handling deprecation for dfs.client.mmap.enabled
Handling deprecation for mapreduce.map.log.level
Handling deprecation for dfs.client.file-block-storage-locations.timeout.millis
Handling deprecation for yarn.client.max-cached-nodemanagers-proxies
Handling deprecation for yarn.app.mapreduce.am.scheduler.heartbeat.interval-ms
Handling deprecation for hadoop.fuse.timer.period
Handling deprecation for fs.trash.checkpoint.interval
Handling deprecation for yarn.sharedcache.app-checker.class
Handling deprecation for dfs.journalnode.http-address
Handling deprecation for yarn.app.mapreduce.am.staging-dir
Handling deprecation for mapreduce.tasktracker.local.dir.minspacestart
Handling deprecation for yarn.nm.liveness-monitor.expiry-interval-ms
Handling deprecation for ha.health-monitor.check-interval.ms
Handling deprecation for mapreduce.reduce.shuffle.merge.percent
Handling deprecation for dfs.namenode.retrycache.heap.percent
Handling deprecation for yarn.nodemanager.docker-container-executor.exec-name
Handling deprecation for ipc.client.connect.timeout
Handling deprecation for yarn.resourcemanager.fs.state-store.retry-interval-ms
Handling deprecation for mapreduce.output.fileoutputformat.compress
Handling deprecation for yarn.nodemanager.local-dirs
Handling deprecation for yarn.nodemanager.recovery.enabled
Handling deprecation for io.native.lib.available
Handling deprecation for yarn.sharedcache.store.in-memory.staleness-period-mins
Handling deprecation for yarn.resourcemanager.am.max-attempts
Handling deprecation for s3.replication
Handling deprecation for mapreduce.input.fileinputformat.inputdir
Handling deprecation for fs.AbstractFileSystem.har.impl
Handling deprecation for dfs.image.compress
Handling deprecation for mapreduce.job.running.map.limit
Handling deprecation for mapreduce.reduce.input.buffer.percent
Handling deprecation for yarn.nodemanager.webapp.address
Handling deprecation for dfs.datanode.available-space-volume-choosing-policy.balanced-space-preference-fraction
Handling deprecation for dfs.namenode.edit.log.autoroll.multiplier.threshold
Handling deprecation for hadoop.security.group.mapping.ldap.ssl
Handling deprecation for dfs.namenode.checkpoint.check.period
Handling deprecation for fs.defaultFS
Handling deprecation for fs.s3a.multipart.size
Handling deprecation for dfs.client.slow.io.warning.threshold.ms
Handling deprecation for yarn.app.mapreduce.am.job.committer.commit-window
Handling deprecation for hadoop.security.group.mapping.ldap.search.attr.group.name
Handling deprecation for yarn.nodemanager.disk-health-checker.max-disk-utilization-per-disk-percentage
Handling deprecation for yarn.nodemanager.container-monitor.procfs-tree.smaps-based-rss.enabled
Handling deprecation for mapreduce.job.submithostname
Handling deprecation for mapreduce.map.sort.spill.percent
Handling deprecation for hadoop.security.crypto.codec.classes.aes.ctr.nopadding
Handling deprecation for dfs.namenode.http-address
Handling deprecation for hadoop.security.groups.negative-cache.secs
Handling deprecation for hadoop.ssl.server.conf
Handling deprecation for mapreduce.ifile.readahead
Handling deprecation for s3native.replication
Handling deprecation for yarn.client.nodemanager-client-async.thread-pool-max-size
Handling deprecation for mapreduce.jobtracker.staging.root.dir
Handling deprecation for mapreduce.jobhistory.admin.address
Handling deprecation for dfs.namenode.startup.delay.block.deletion.sec
Handling deprecation for yarn.nodemanager.health-checker.interval-ms
Handling deprecation for dfs.namenode.checkpoint.max-retries
Handling deprecation for s3.stream-buffer-size
Handling deprecation for ftp.client-write-packet-size
Handling deprecation for dfs.datanode.fsdatasetcache.max.threads.per.volume
Handling deprecation for mapreduce.output.fileoutputformat.compress.codec
Handling deprecation for yarn.timeline-service.keytab
Handling deprecation for yarn.sharedcache.store.in-memory.initial-delay-mins
Handling deprecation for mapreduce.jobhistory.webapp.address
Handling deprecation for mapreduce.task.userlog.limit.kb
Handling deprecation for mapreduce.reduce.shuffle.fetch.retry.enabled
Handling deprecation for yarn.app.mapreduce.task.container.log.backups
Handling deprecation for dfs.heartbeat.interval
Handling deprecation for ha.zookeeper.session-timeout.ms
Handling deprecation for fs.s3a.connection.ssl.enabled
Handling deprecation for yarn.sharedcache.webapp.address
Handling deprecation for hadoop.http.authentication.signature.secret.file
Handling deprecation for hadoop.fuse.connection.timeout
Handling deprecation for mapreduce.input.fileinputformat.numinputfiles
Handling deprecation for yarn.nodemanager.log-aggregation.compression-type
Handling deprecation for ipc.server.max.connections
Handling deprecation for yarn.resourcemanager.work-preserving-recovery.scheduling-wait-ms
Handling deprecation for yarn.nodemanager.log-dirs
Handling deprecation for yarn.app.mapreduce.am.resource.mb
Handling deprecation for hadoop.security.groups.cache.secs
Handling deprecation for mapreduce.job.speculative.minimum-allowed-tasks
Handling deprecation for yarn.nodemanager.container-monitor.interval-ms
Handling deprecation for dfs.datanode.cache.revocation.timeout.ms
Handling deprecation for mapreduce.jobhistory.recovery.store.class
Handling deprecation for mapreduce.task.combine.progress.records
Handling deprecation for s3.client-write-packet-size
Handling deprecation for mapreduce.jobtracker.instrumentation
Handling deprecation for dfs.replication
Handling deprecation for mapreduce.shuffle.transfer.buffer.size
Handling deprecation for hadoop.security.group.mapping.ldap.directory.search.timeout
Handling deprecation for dfs.datanode.available-space-volume-choosing-policy.balanced-space-threshold
Handling deprecation for hadoop.work.around.non.threadsafe.getpwuid
Handling deprecation for yarn.app.mapreduce.client-am.ipc.max-retries-on-timeouts
Handling deprecation for yarn.nodemanager.address
Handling deprecation for mapreduce.tasktracker.taskcontroller
Handling deprecation for mapreduce.tasktracker.indexcache.mb
Handling deprecation for yarn.scheduler.maximum-allocation-vcores
Handling deprecation for mapreduce.job.reduces
Handling deprecation for yarn.nodemanager.sleep-delay-before-sigkill.ms
Handling deprecation for yarn.timeline-service.address
Handling deprecation for yarn.resourcemanager.configuration.provider-class
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.expiry
Handling deprecation for yarn.sharedcache.enabled
Handling deprecation for tfile.io.chunk.size
Handling deprecation for mapreduce.job.acl-modify-job
Handling deprecation for hadoop.registry.zk.session.timeout.ms
Handling deprecation for fs.automatic.close
Handling deprecation for ha.health-monitor.sleep-after-disconnect.ms
Handling deprecation for mapreduce.tasktracker.reduce.tasks.maximum
Handling deprecation for mapreduce.input.fileinputformat.list-status.num-threads
Handling deprecation for dfs.datanode.directoryscan.threads
Handling deprecation for dfs.datanode.directoryscan.interval
Handling deprecation for dfs.namenode.acls.enabled
Handling deprecation for dfs.client.short.circuit.replica.stale.threshold.ms
Handling deprecation for hadoop.http.authentication.token.validity
Handling deprecation for fs.s3.block.size
Handling deprecation for ha.failover-controller.graceful-fence.rpc-timeout.ms
Handling deprecation for mapreduce.tasktracker.local.dir.minspacekill
Handling deprecation for dfs.namenode.resource.du.reserved
Handling deprecation for mapreduce.jobhistory.cleaner.interval-ms
Handling deprecation for dfs.namenode.datanode.registration.ip-hostname-check
Handling deprecation for mapreduce.jobhistory.intermediate-done-dir
Handling deprecation for mapreduce.jobtracker.http.address
Handling deprecation for dfs.namenode.backup.http-address
Handling deprecation for dfs.namenode.edits.noeditlogchannelflush
Handling deprecation for mapreduce.reduce.shuffle.input.buffer.percent
Handling deprecation for mapreduce.map.maxattempts
Handling deprecation for yarn.http.policy
Handling deprecation for dfs.namenode.audit.loggers
Handling deprecation for hadoop.security.groups.cache.warn.after.ms
Handling deprecation for io.serializations
Handling deprecation for mapreduce.tasktracker.outofband.heartbeat
Handling deprecation for mapreduce.reduce.shuffle.read.timeout
Handling deprecation for hadoop.security.crypto.buffer.size
Handling deprecation for mapreduce.reduce.skip.proc.count.autoincr
Handling deprecation for mapreduce.ifile.readahead.bytes
Handling deprecation for dfs.http.policy
Handling deprecation for hadoop.registry.secure
Handling deprecation for dfs.namenode.safemode.min.datanodes
Handling deprecation for dfs.client.file-block-storage-locations.num-threads
Handling deprecation for mapreduce.cluster.local.dir
Handling deprecation for mapreduce.tasktracker.report.address
Handling deprecation for dfs.namenode.secondary.https-address
Handling deprecation for hadoop.kerberos.kinit.command
Handling deprecation for yarn.timeline-service.http-authentication.type
Handling deprecation for dfs.block.access.token.lifetime
Handling deprecation for dfs.webhdfs.enabled
Handling deprecation for dfs.namenode.delegation.token.max-lifetime
Handling deprecation for dfs.namenode.avoid.write.stale.datanode
Handling deprecation for dfs.datanode.drop.cache.behind.writes
Handling deprecation for yarn.log-aggregation.retain-seconds
Handling deprecation for mapreduce.job.complete.cancel.delegation.tokens
Handling deprecation for mapreduce.local.clientfactory.class.name
Handling deprecation for mapreduce.shuffle.connection-keep-alive.timeout
Handling deprecation for dfs.namenode.num.extra.edits.retained
Handling deprecation for yarn.scheduler.minimum-allocation-vcores
Handling deprecation for ipc.client.connect.max.retries.on.timeouts
Handling deprecation for yarn.timeline-service.client.retry-interval-ms
Handling deprecation for yarn.timeline-service.client.max-retries
Handling deprecation for fs.s3n.block.size
Handling deprecation for mapreduce.job.map.output.collector.class
Handling deprecation for ha.health-monitor.connect-retry-interval.ms
Handling deprecation for mapreduce.shuffle.max.threads
Handling deprecation for nfs.exports.allowed.hosts
Handling deprecation for dfs.client.mmap.cache.size
Handling deprecation for mapreduce.tasktracker.map.tasks.maximum
Handling deprecation for io.file.buffer.size
Handling deprecation for dfs.client.datanode-restart.timeout
Handling deprecation for io.mapfile.bloom.size
Handling deprecation for hadoop.security.kms.client.authentication.retry-count
Handling deprecation for dfs.namenode.checkpoint.txns
Handling deprecation for ipc.client.connect.retry.interval
Handling deprecation for dfs.client-write-packet-size
Handling deprecation for mapreduce.reduce.shuffle.connect.timeout
Handling deprecation for yarn.resourcemanager.fs.state-store.uri
Handling deprecation for fs.swift.impl
Handling deprecation for hadoop.registry.zk.connection.timeout.ms
Handling deprecation for mapred.queue.default.acl-administer-jobs
Handling deprecation for mapreduce.job.submithostaddress
Handling deprecation for dfs.cachereport.intervalMsec
Handling deprecation for yarn.app.mapreduce.shuffle.log.backups
Handling deprecation for yarn.app.mapreduce.am.container.log.limit.kb
Handling deprecation for yarn.nodemanager.resourcemanager.minimum.version
Handling deprecation for ftp.blocksize
Handling deprecation for yarn.resourcemanager.address
Handling deprecation for file.stream-buffer-size
Handling deprecation for yarn.resourcemanager.scheduler.monitor.enable
Handling deprecation for mapreduce.job.ubertask.maxreduces
Handling deprecation for nfs.allow.insecure.ports
Handling deprecation for yarn.sharedcache.nm.uploader.thread-count
Handling deprecation for ipc.client.idlethreshold
Handling deprecation for ftp.stream-buffer-size
Handling deprecation for yarn.sharedcache.client-server.address
Handling deprecation for dfs.client.failover.connection.retries.on.timeouts
Handling deprecation for dfs.namenode.replication.work.multiplier.per.iteration
Handling deprecation for hadoop.http.authentication.simple.anonymous.allowed
Handling deprecation for hadoop.security.authorization
Handling deprecation for yarn.client.nodemanager-connect.retry-interval-ms
Handling deprecation for yarn.am.liveness-monitor.expiry-interval-ms
Handling deprecation for fs.har.impl.disable.cache
Handling deprecation for yarn.nodemanager.linux-container-executor.resources-handler.class
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.read-cache-size
Handling deprecation for hadoop.security.authentication
Handling deprecation for dfs.image.compression.codec
Handling deprecation for mapreduce.task.files.preserve.failedtasks
Handling deprecation for dfs.client.read.shortcircuit.streams.cache.size
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.path
Handling deprecation for mapreduce.job.reduce.slowstart.completedmaps
Handling deprecation for mapreduce.jobhistory.minicluster.fixed.ports
Handling deprecation for file.replication
Handling deprecation for yarn.resourcemanager.ha.automatic-failover.enabled
Handling deprecation for mapreduce.job.userlog.retain.hours
Handling deprecation for mapreduce.jobhistory.joblist.cache.size
Handling deprecation for dfs.namenode.accesstime.precision
Handling deprecation for yarn.resourcemanager.work-preserving-recovery.enabled
Handling deprecation for dfs.namenode.fs-limits.max-xattrs-per-inode
Handling deprecation for io.mapfile.bloom.error.rate
Handling deprecation for yarn.resourcemanager.store.class
Handling deprecation for dfs.image.transfer.timeout
Handling deprecation for yarn.timeline-service.leveldb-state-store.path
Handling deprecation for nfs.wtmax
Handling deprecation for mapreduce.job.combine.class
Handling deprecation for dfs.namenode.support.allow.format
Handling deprecation for fs.s3a.multipart.purge
Handling deprecation for dfs.secondary.namenode.kerberos.internal.spnego.principal
Handling deprecation for fs.s3a.connection.establish.timeout
Handling deprecation for dfs.stream-buffer-size
Handling deprecation for dfs.namenode.invalidate.work.pct.per.iteration
Handling deprecation for yarn.nodemanager.container-executor.class
Handling deprecation for fs.s3a.multipart.purge.age
Handling deprecation for yarn.resourcemanager.scheduler.client.thread-count
Handling deprecation for dfs.namenode.top.enabled
Handling deprecation for yarn.app.mapreduce.shuffle.log.separate
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.low-watermark
Handling deprecation for fs.s3a.fast.buffer.size
Handling deprecation for hadoop.user.group.static.mapping.overrides
Handling deprecation for tfile.fs.input.buffer.size
Handling deprecation for dfs.client.cached.conn.retry
Handling deprecation for hadoop.http.authentication.type
Handling deprecation for dfs.namenode.list.encryption.zones.num.responses
Handling deprecation for mapreduce.map.cpu.vcores
Handling deprecation for dfs.namenode.path.based.cache.refresh.interval.ms
Handling deprecation for dfs.namenode.decommission.interval
Handling deprecation for dfs.namenode.fs-limits.max-directory-items
Handling deprecation for yarn.resourcemanager.zk-retry-interval-ms
Handling deprecation for ftp.bytes-per-checksum
Handling deprecation for dfs.ha.log-roll.period
Handling deprecation for dfs.user.home.dir.prefix
Handling deprecation for ipc.client.fallback-to-simple-auth-allowed
Handling deprecation for yarn.nodemanager.pmem-check-enabled
Handling deprecation for yarn.nodemanager.remote-app-log-dir
Handling deprecation for dfs.namenode.inotify.max.events.per.rpc
Handling deprecation for mapreduce.task.profile.maps
Handling deprecation for mapreduce.shuffle.ssl.file.buffer.size
Handling deprecation for mapreduce.tasktracker.healthchecker.script.timeout
Handling deprecation for yarn.timeline-service.webapp.https.address
Handling deprecation for yarn.nodemanager.resource.percentage-physical-cpu-limit
Handling deprecation for yarn.app.mapreduce.am.command-opts
Handling deprecation for dfs.namenode.fs-limits.max-xattr-size
Handling deprecation for dfs.datanode.http.address
Handling deprecation for dfs.namenode.blocks.per.postponedblocks.rescan
Handling deprecation for yarn.sharedcache.nm.uploader.replication.factor
Handling deprecation for hadoop.registry.zk.root
Handling deprecation for hadoop.jetty.logs.serve.aliases
Handling deprecation for yarn.client.failover-proxy-provider
Handling deprecation for mapreduce.jobhistory.admin.acl
Handling deprecation for yarn.app.mapreduce.am.hard-kill-timeout-ms
Handling deprecation for yarn.nodemanager.remote-app-log-dir-suffix
Handling deprecation for mapreduce.jobhistory.principal
Handling deprecation for yarn.resourcemanager.webapp.address
Handling deprecation for mapreduce.jobhistory.recovery.enable
Handling deprecation for yarn.sharedcache.store.in-memory.check-period-mins
Handling deprecation for nfs.mountd.port
Handling deprecation for mapreduce.reduce.merge.inmem.threshold
Handling deprecation for fs.df.interval
Handling deprecation for yarn.timeline-service.enabled
Handling deprecation for mapreduce.jobtracker.jobhistory.lru.cache.size
Handling deprecation for mapreduce.task.profile
Handling deprecation for mapreduce.job.output.key.class
Handling deprecation for yarn.nodemanager.hostname
Handling deprecation for dfs.namenode.num.checkpoints.retained
Handling deprecation for mapreduce.job.queuename
Handling deprecation for mapreduce.jobhistory.max-age-ms
Handling deprecation for mapreduce.job.token.tracking.ids.enabled
Handling deprecation for yarn.nodemanager.localizer.client.thread-count
Handling deprecation for yarn.sharedcache.uploader.server.thread-count
Handling deprecation for dfs.client.mmap.retry.timeout.ms
Handling deprecation for mapreduce.jobhistory.move.thread-count
Handling deprecation for dfs.permissions.enabled
Handling deprecation for dfs.blockreport.split.threshold
Handling deprecation for fs.AbstractFileSystem.hdfs.impl
Handling deprecation for dfs.datanode.balance.bandwidthPerSec
Handling deprecation for dfs.block.scanner.volume.bytes.per.second
Handling deprecation for hadoop.http.filter.initializers
Handling deprecation for yarn.timeline-service.http-authentication.simple.anonymous.allowed
Handling deprecation for dfs.default.chunk.view.size
Handling deprecation for yarn.sharedcache.client-server.thread-count
Handling deprecation for yarn.resourcemanager.resource-tracker.address
Handling deprecation for mapreduce.job.working.dir
Handling deprecation for mapreduce.jobhistory.datestring.cache.size
Handling deprecation for mapreduce.task.profile.params
Handling deprecation for dfs.namenode.decommission.blocks.per.interval
Handling deprecation for dfs.namenode.handler.count
Handling deprecation for dfs.image.transfer.bandwidthPerSec
Handling deprecation for rpc.metrics.quantile.enable
Handling deprecation for mapreduce.jobtracker.expire.trackers.interval
Handling deprecation for mapreduce.task.timeout
Handling deprecation for yarn.app.mapreduce.client.max-retries
Handling deprecation for yarn.nodemanager.resource.memory-mb
Handling deprecation for yarn.nodemanager.disk-health-checker.min-healthy-disks
Handling deprecation for dfs.datanode.failed.volumes.tolerated
Handling deprecation for yarn.timeline-service.handler-thread-count
Handling deprecation for ipc.server.listen.queue.size
Handling deprecation for fs.s3a.threads.max
Handling deprecation for yarn.resourcemanager.connect.max-wait.ms
Handling deprecation for mapreduce.fileoutputcommitter.algorithm.version
Handling deprecation for mapreduce.framework.name
Handling deprecation for mapreduce.map.skip.proc.count.autoincr
Handling deprecation for mapreduce.job.max.split.locations
Handling deprecation for yarn.resourcemanager.scheduler.class
Handling deprecation for yarn.resourcemanager.system-metrics-publisher.enabled
Handling deprecation for dfs.blocksize
Handling deprecation for yarn.sharedcache.nested-level
Handling deprecation for mapreduce.shuffle.connection-keep-alive.enable
Handling deprecation for fs.s3a.threads.keepalivetime
Handling deprecation for fs.s3a.connection.timeout
Handling deprecation for file.client-write-packet-size
Handling deprecation for ha.failover-controller.cli-check.rpc-timeout.ms
Handling deprecation for ha.zookeeper.acl
Handling deprecation for dfs.namenode.write.stale.datanode.ratio
Handling deprecation for dfs.encrypt.data.transfer
Handling deprecation for dfs.datanode.shared.file.descriptor.paths
Handling deprecation for mapreduce.input.lineinputformat.linespermap
Handling deprecation for yarn.resourcemanager.delayed.delegation-token.removal-interval-ms
Handling deprecation for yarn.nodemanager.localizer.fetch.thread-count
Handling deprecation for dfs.client.failover.max.attempts
Handling deprecation for yarn.resourcemanager.scheduler.address
Handling deprecation for dfs.client.read.shortcircuit.streams.cache.expiry.ms
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.start-time-write-cache-size
Handling deprecation for yarn.nodemanager.health-checker.script.timeout-ms
Handling deprecation for yarn.resourcemanager.fs.state-store.num-retries
Handling deprecation for hadoop.ssl.require.client.cert
Handling deprecation for hadoop.security.uid.cache.secs
Handling deprecation for mapreduce.jobhistory.keytab
Handling deprecation for dfs.client.read.shortcircuit.skip.checksum
Handling deprecation for yarn.resourcemanager.ha.automatic-failover.zk-base-path
Handling deprecation for mapreduce.shuffle.ssl.enabled
Handling deprecation for mapreduce.reduce.log.level
Handling deprecation for hadoop.registry.rm.enabled
Handling deprecation for mapreduce.tasktracker.dns.interface
Handling deprecation for yarn.resourcemanager.system-metrics-publisher.dispatcher.pool-size
Handling deprecation for mapreduce.job.speculative.speculative-cap-running-tasks
Handling deprecation for dfs.datanode.block.id.layout.upgrade.threads
Handling deprecation for dfs.datanode.use.datanode.hostname
Handling deprecation for dfs.client.context
Handling deprecation for yarn.resourcemanager.ha.enabled
Handling deprecation for mapred.reducer.new-api
Handling deprecation for dfs.namenode.delegation.token.renew-interval
Handling deprecation for dfs.blockreport.intervalMsec
Handling deprecation for fs.s3a.multipart.threshold
Handling deprecation for mapreduce.reduce.shuffle.memory.limit.percent
Handling deprecation for dfs.https.server.keystore.resource
Handling deprecation for io.map.index.skip
Handling deprecation for mapreduce.job.hdfs-servers
Handling deprecation for mapreduce.jobtracker.taskscheduler
Handling deprecation for dfs.namenode.kerberos.internal.spnego.principal
Handling deprecation for yarn.resourcemanager.state-store.max-completed-applications
Handling deprecation for mapreduce.map.output.compress
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.num.refill.threads
Handling deprecation for fs.s3n.multipart.uploads.block.size
Handling deprecation for mapreduce.task.merge.progress.records
Handling deprecation for dfs.datanode.dns.interface
Handling deprecation for map.sort.class
Handling deprecation for yarn.nodemanager.aux-services.mapreduce_shuffle.class
Handling deprecation for tfile.fs.output.buffer.size
Handling deprecation for fs.du.interval
Handling deprecation for dfs.client.failover.connection.retries
Handling deprecation for dfs.namenode.top.window.num.buckets
Handling deprecation for mapreduce.job.dir
Handling deprecation for fs.s3a.buffer.dir
Handling deprecation for mapreduce.reduce.shuffle.retry-delay.max.ms
Handling deprecation for yarn.sharedcache.uploader.server.address
Handling deprecation for mapreduce.client.progressmonitor.pollinterval
Handling deprecation for yarn.app.mapreduce.shuffle.log.limit.kb
Handling deprecation for dfs.datanode.max.locked.memory
Handling deprecation for dfs.namenode.retrycache.expirytime.millis
Handling deprecation for dfs.datanode.scan.period.hours
Handling deprecation for dfs.client.block.write.replace-datanode-on-failure.best-effort
Handling deprecation for mapreduce.jobhistory.move.interval-ms
Handling deprecation for dfs.ha.fencing.ssh.connect-timeout
Handling deprecation for yarn.nodemanager.log-aggregation.roll-monitoring-interval-seconds
Handling deprecation for dfs.namenode.fs-limits.max-component-length
Handling deprecation for hadoop.registry.zk.quorum
Handling deprecation for dfs.namenode.enable.retrycache
Handling deprecation for dfs.datanode.du.reserved
Handling deprecation for yarn.timeline-service.state-store-class
Handling deprecation for dfs.datanode.ipc.address
Handling deprecation for hadoop.registry.system.acls
Handling deprecation for dfs.client.block.write.replace-datanode-on-failure.policy
Handling deprecation for dfs.namenode.path.based.cache.retry.interval.ms
Handling deprecation for hadoop.security.crypto.cipher.suite
Handling deprecation for dfs.ha.tail-edits.period
Handling deprecation for mapreduce.task.profile.reduce.params
Handling deprecation for hadoop.registry.jaas.context
Handling deprecation for yarn.resourcemanager.hostname
Handling deprecation for mapreduce.reduce.memory.mb
Handling deprecation for hadoop.security.group.mapping.ldap.search.filter.group
Handling deprecation for hadoop.http.authentication.kerberos.principal
Handling deprecation for hadoop.security.group.mapping.ldap.search.filter.user
Handling deprecation for yarn.nodemanager.disk-health-checker.min-free-space-per-disk-mb
Handling deprecation for dfs.namenode.edits.dir
Handling deprecation for yarn.client.failover-retries-on-socket-timeouts
Handling deprecation for dfs.namenode.decommission.max.concurrent.tracked.nodes
Handling deprecation for mapreduce.client.completion.pollinterval
Handling deprecation for dfs.namenode.name.dir.restore
Handling deprecation for dfs.namenode.secondary.http-address
Handling deprecation for mapreduce.jobhistory.recovery.store.leveldb.path
Handling deprecation for yarn.sharedcache.store.class
Handling deprecation for s3.bytes-per-checksum
Handling deprecation for yarn.nodemanager.windows-container.cpu-limit.enabled
Handling deprecation for yarn.resourcemanager.webapp.https.address
Handling deprecation for yarn.nodemanager.vmem-pmem-ratio
Handling deprecation for dfs.namenode.checkpoint.period
Handling deprecation for dfs.ha.automatic-failover.enabled
Submitting tokens for job: job_local183065926_0002
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.fs.FileContext.getAbstractFileSystem(FileContext.java:331)
Handling deprecation for all properties in config...
Handling deprecation for mapreduce.jobtracker.address
Handling deprecation for yarn.resourcemanager.scheduler.monitor.policies
Handling deprecation for dfs.namenode.resource.check.interval
Handling deprecation for mapreduce.jobhistory.client.thread-count
Handling deprecation for yarn.app.mapreduce.am.containerlauncher.threadpool-initial-size
Handling deprecation for mapred.child.java.opts
Handling deprecation for mapreduce.jobtracker.retiredjobs.cache.size
Handling deprecation for dfs.client.https.need-auth
Handling deprecation for yarn.admin.acl
Handling deprecation for yarn.app.mapreduce.am.job.committer.cancel-timeout
Handling deprecation for mapreduce.job.emit-timeline-data
Handling deprecation for fs.ftp.host.port
Handling deprecation for dfs.namenode.avoid.read.stale.datanode
Handling deprecation for dfs.journalnode.rpc-address
Handling deprecation for mapreduce.job.end-notification.retry.attempts
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.ttl-interval-ms
Handling deprecation for yarn.resourcemanager.leveldb-state-store.path
Handling deprecation for mapred.mapper.new-api
Handling deprecation for yarn.ipc.rpc.class
Handling deprecation for ipc.client.connection.maxidletime
Handling deprecation for yarn.nodemanager.process-kill-wait.ms
Handling deprecation for mapreduce.cluster.acls.enabled
Handling deprecation for mapreduce.jobtracker.handler.count
Handling deprecation for io.map.index.interval
Handling deprecation for dfs.namenode.https-address
Handling deprecation for mapreduce.task.profile.reduces
Handling deprecation for fs.s3n.multipart.uploads.enabled
Handling deprecation for io.seqfile.sorter.recordlimit
Handling deprecation for mapreduce.job.ubertask.maxmaps
Handling deprecation for mapreduce.tasktracker.tasks.sleeptimebeforesigkill
Handling deprecation for hadoop.util.hash.type
Handling deprecation for dfs.namenode.replication.min
Handling deprecation for yarn.nodemanager.container-manager.thread-count
Handling deprecation for mapreduce.jobtracker.jobhistory.block.size
Handling deprecation for dfs.namenode.fs-limits.min-block-size
Handling deprecation for mapreduce.app-submission.cross-platform
Handling deprecation for fs.AbstractFileSystem.file.impl
Handling deprecation for net.topology.script.number.args
Handling deprecation for yarn.resourcemanager.container-tokens.master-key-rolling-interval-secs
Handling deprecation for mapreduce.map.output.compress.codec
Handling deprecation for mapreduce.job.reducer.preempt.delay.sec
Handling deprecation for s3native.bytes-per-checksum
Handling deprecation for dfs.namenode.path.based.cache.block.map.allocation.percent
Handling deprecation for yarn.nodemanager.windows-container.memory-limit.enabled
Handling deprecation for mapreduce.input.fileinputformat.split.minsize
Handling deprecation for hadoop.security.group.mapping
Handling deprecation for mapreduce.jobtracker.system.dir
Handling deprecation for mapreduce.job.end-notification.max.attempts
Handling deprecation for mapreduce.reduce.markreset.buffer.percent
Handling deprecation for dfs.datanode.cache.revocation.polling.ms
Handling deprecation for mapreduce.reduce.speculative
Handling deprecation for yarn.nodemanager.localizer.cache.cleanup.interval-ms
Handling deprecation for dfs.namenode.lazypersist.file.scrub.interval.sec
Handling deprecation for fs.s3a.threads.core
Handling deprecation for mapreduce.jobhistory.recovery.store.fs.uri
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.start-time-read-cache-size
Handling deprecation for hadoop.registry.zk.retry.interval.ms
Handling deprecation for yarn.nodemanager.keytab
Handling deprecation for dfs.namenode.replication.interval
Handling deprecation for yarn.resourcemanager.admin.address
Handling deprecation for mapreduce.job.maps
Handling deprecation for nfs.dump.dir
Handling deprecation for mapreduce.job.user.name
Handling deprecation for mapreduce.jobtracker.maxtasks.perjob
Handling deprecation for mapreduce.job.ubertask.enable
Handling deprecation for mapreduce.job.reduce.class
Handling deprecation for yarn.nodemanager.delete.debug-delay-sec
Handling deprecation for yarn.timeline-service.ttl-enable
Handling deprecation for yarn.resourcemanager.fs.state-store.retry-policy-spec
Handling deprecation for mapreduce.reduce.skip.maxgroups
Handling deprecation for dfs.client.use.datanode.hostname
Handling deprecation for fs.trash.interval
Handling deprecation for mapreduce.job.name
Handling deprecation for mapreduce.am.max-attempts
Handling deprecation for mapreduce.jobtracker.heartbeats.in.second
Handling deprecation for yarn.resourcemanager.zk-num-retries
Handling deprecation for s3.blocksize
Handling deprecation for dfs.datanode.data.dir
Handling deprecation for mapreduce.jobtracker.persist.jobstatus.active
Handling deprecation for mapreduce.reduce.shuffle.parallelcopies
Handling deprecation for fs.s3.buffer.dir
Handling deprecation for mapreduce.jobhistory.done-dir
Handling deprecation for hadoop.security.instrumentation.requires.admin
Handling deprecation for hadoop.registry.zk.retry.ceiling.ms
Handling deprecation for nfs.rtmax
Handling deprecation for dfs.datanode.data.dir.perm
Handling deprecation for yarn.resourcemanager.container.liveness-monitor.interval-ms
Handling deprecation for yarn.nodemanager.env-whitelist
Handling deprecation for dfs.namenode.backup.address
Handling deprecation for dfs.namenode.xattrs.enabled
Handling deprecation for dfs.datanode.readahead.bytes
Handling deprecation for mapreduce.jobhistory.cleaner.enable
Handling deprecation for dfs.client.block.write.retries
Handling deprecation for mapreduce.tasktracker.http.address
Handling deprecation for yarn.nodemanager.linux-container-executor.cgroups.hierarchy
Handling deprecation for ha.failover-controller.graceful-fence.connection.retries
Handling deprecation for yarn.resourcemanager.recovery.enabled
Handling deprecation for yarn.app.mapreduce.am.container.log.backups
Handling deprecation for dfs.namenode.safemode.threshold-pct
Handling deprecation for yarn.nodemanager.disk-health-checker.interval-ms
Handling deprecation for hadoop.security.java.secure.random.algorithm
Handling deprecation for dfs.namenode.list.cache.directives.num.responses
Handling deprecation for dfs.datanode.dns.nameserver
Handling deprecation for mapreduce.cluster.temp.dir
Handling deprecation for fs.s3a.max.total.tasks
Handling deprecation for mapreduce.reduce.maxattempts
Handling deprecation for mapreduce.client.submit.file.replication
Handling deprecation for mapreduce.shuffle.port
Handling deprecation for yarn.resourcemanager.resource-tracker.client.thread-count
Handling deprecation for dfs.namenode.replication.considerLoad
Handling deprecation for dfs.namenode.edits.journal-plugin.qjournal
Handling deprecation for dfs.client.write.exclude.nodes.cache.expiry.interval.millis
Handling deprecation for yarn.nodemanager.delete.thread-count
Handling deprecation for dfs.client.mmap.cache.timeout.ms
Handling deprecation for yarn.nodemanager.admin-env
Handling deprecation for io.skip.checksum.errors
Handling deprecation for yarn.timeline-service.hostname
Handling deprecation for yarn.resourcemanager.proxy-user-privileges.enabled
Handling deprecation for mapreduce.job.speculative.speculative-cap-total-tasks
Handling deprecation for yarn.acl.enable
Handling deprecation for fs.s3a.fast.upload
Handling deprecation for file.blocksize
Handling deprecation for mapreduce.job.speculative.slowtaskthreshold
Handling deprecation for ftp.replication
Handling deprecation for yarn.sharedcache.cleaner.initial-delay-mins
Handling deprecation for s3native.client-write-packet-size
Handling deprecation for hadoop.rpc.socket.factory.class.default
Handling deprecation for file.bytes-per-checksum
Handling deprecation for dfs.datanode.slow.io.warning.threshold.ms
Handling deprecation for io.seqfile.lazydecompress
Handling deprecation for mapreduce.task.skip.start.attempts
Handling deprecation for dfs.namenode.reject-unresolved-dn-topology-mapping
Handling deprecation for hadoop.common.configuration.version
Handling deprecation for yarn.resourcemanager.client.thread-count
Handling deprecation for dfs.datanode.drop.cache.behind.reads
Handling deprecation for yarn.sharedcache.admin.address
Handling deprecation for mapreduce.job.output.value.class
Handling deprecation for mapreduce.output.fileoutputformat.outputdir
Handling deprecation for mapreduce.jobtracker.taskcache.levels
Handling deprecation for yarn.nodemanager.linux-container-executor.nonsecure-mode.user-pattern
Handling deprecation for yarn.resourcemanager.zk-timeout-ms
Handling deprecation for yarn.resourcemanager.max-completed-applications
Handling deprecation for mapreduce.job.jvm.numtasks
Handling deprecation for yarn.sharedcache.cleaner.period-mins
Handling deprecation for mapreduce.jobtracker.tasktracker.maxblacklists
Handling deprecation for dfs.namenode.top.num.users
Handling deprecation for yarn.nodemanager.linux-container-executor.cgroups.mount
Handling deprecation for yarn.sharedcache.checksum.algo.impl
Handling deprecation for mapreduce.job.end-notification.max.retry.interval
Handling deprecation for mapreduce.job.acl-view-job
Handling deprecation for mapreduce.job.classloader
Handling deprecation for yarn.log-aggregation-enable
Handling deprecation for mapreduce.reduce.shuffle.fetch.retry.interval-ms
Handling deprecation for yarn.resourcemanager.nodemanager.minimum.version
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.size
Handling deprecation for yarn.app.mapreduce.am.job.task.listener.thread-count
Handling deprecation for yarn.app.mapreduce.am.resource.cpu-vcores
Handling deprecation for dfs.namenode.edit.log.autoroll.check.interval.ms
Handling deprecation for mapreduce.output.fileoutputformat.compress.type
Handling deprecation for hadoop.hdfs.configuration.version
Handling deprecation for hadoop.security.group.mapping.ldap.search.attr.member
Handling deprecation for yarn.nodemanager.log.retain-seconds
Handling deprecation for yarn.nodemanager.local-cache.max-files-per-directory
Handling deprecation for mapreduce.job.end-notification.retry.interval
Handling deprecation for hadoop.ssl.client.conf
Handling deprecation for yarn.sharedcache.root-dir
Handling deprecation for dfs.journalnode.https-address
Handling deprecation for mapreduce.reduce.shuffle.fetch.retry.timeout-ms
Handling deprecation for dfs.bytes-per-checksum
Handling deprecation for dfs.namenode.max.objects
Handling deprecation for mapreduce.tasktracker.instrumentation
Handling deprecation for dfs.datanode.max.transfer.threads
Handling deprecation for dfs.block.access.key.update.interval
Handling deprecation for mapreduce.jobtracker.jobhistory.task.numberprogresssplits
Handling deprecation for mapreduce.map.memory.mb
Handling deprecation for ha.failover-controller.new-active.rpc-timeout.ms
Handling deprecation for hadoop.ssl.hostname.verifier
Handling deprecation for dfs.client.read.shortcircuit
Handling deprecation for dfs.datanode.hdfs-blocks-metadata.enabled
Handling deprecation for mapreduce.tasktracker.healthchecker.interval
Handling deprecation for dfs.image.transfer.chunksize
Handling deprecation for mapreduce.tasktracker.taskmemorymanager.monitoringinterval
Handling deprecation for dfs.client.https.keystore.resource
Handling deprecation for yarn.resourcemanager.connect.retry-interval.ms
Handling deprecation for yarn.timeline-service.webapp.address
Handling deprecation for s3native.blocksize
Handling deprecation for yarn.scheduler.minimum-allocation-mb
Handling deprecation for yarn.sharedcache.cleaner.resource-sleep-ms
Handling deprecation for net.topology.impl
Handling deprecation for dfs.client.failover.sleep.base.millis
Handling deprecation for dfs.permissions.superusergroup
Handling deprecation for io.seqfile.compress.blocksize
Handling deprecation for hadoop.registry.zk.retry.times
Handling deprecation for fs.AbstractFileSystem.ftp.impl
Handling deprecation for dfs.namenode.checkpoint.edits.dir
Handling deprecation for mapreduce.job.running.reduce.limit
Handling deprecation for dfs.blockreport.initialDelay
Handling deprecation for dfs.namenode.heartbeat.recheck-interval
Handling deprecation for dfs.namenode.safemode.extension
Handling deprecation for yarn.scheduler.maximum-allocation-mb
Handling deprecation for mapreduce.job.reduce.shuffle.consumer.plugin.class
Handling deprecation for yarn.nodemanager.vmem-check-enabled
Handling deprecation for mapreduce.task.io.sort.factor
Handling deprecation for mapreduce.jobtracker.persist.jobstatus.dir
Handling deprecation for dfs.client.failover.sleep.max.millis
Handling deprecation for dfs.namenode.delegation.key.update-interval
Handling deprecation for hadoop.rpc.protection
Handling deprecation for fs.permissions.umask-mode
Handling deprecation for fs.s3.sleepTimeSeconds
Handling deprecation for ha.health-monitor.rpc-timeout.ms
Handling deprecation for hadoop.http.staticuser.user
Handling deprecation for fs.s3a.connection.maximum
Handling deprecation for yarn.nodemanager.linux-container-executor.nonsecure-mode.limit-users
Handling deprecation for fs.s3a.paging.maximum
Handling deprecation for fs.AbstractFileSystem.viewfs.impl
Handling deprecation for fs.ftp.host
Handling deprecation for yarn.nodemanager.linux-container-executor.nonsecure-mode.local-user
Handling deprecation for fs.s3a.impl
Handling deprecation for hadoop.http.authentication.kerberos.keytab
Handling deprecation for dfs.namenode.fs-limits.max-blocks-per-file
Handling deprecation for mapreduce.tasktracker.http.threads
Handling deprecation for mapreduce.tasktracker.dns.nameserver
Handling deprecation for yarn.resourcemanager.am-rm-tokens.master-key-rolling-interval-secs
Handling deprecation for dfs.client.block.write.replace-datanode-on-failure.enable
Handling deprecation for io.compression.codec.bzip2.library
Handling deprecation for mapreduce.map.skip.maxrecords
Handling deprecation for dfs.client.use.legacy.blockreader.local
Handling deprecation for dfs.namenode.checkpoint.dir
Handling deprecation for dfs.namenode.top.windows.minutes
Handling deprecation for mapreduce.job.maxtaskfailures.per.tracker
Handling deprecation for net.topology.node.switch.mapping.impl
Handling deprecation for mapreduce.shuffle.max.connections
Handling deprecation for mapreduce.jobhistory.loadedjobs.cache.size
Handling deprecation for dfs.storage.policy.enabled
Handling deprecation for yarn.client.application-client-protocol.poll-interval-ms
Handling deprecation for yarn.nodemanager.localizer.address
Handling deprecation for dfs.namenode.list.cache.pools.num.responses
Handling deprecation for nfs.server.port
Handling deprecation for mapreduce.client.output.filter
Handling deprecation for yarn.timeline-service.client.best-effort
Handling deprecation for ha.zookeeper.parent-znode
Handling deprecation for mapreduce.jobtracker.persist.jobstatus.hours
Handling deprecation for yarn.sharedcache.admin.thread-count
Handling deprecation for yarn.nodemanager.resource.cpu-vcores
Handling deprecation for dfs.datanode.block-pinning.enabled
Handling deprecation for mapreduce.jobhistory.http.policy
Handling deprecation for yarn.resourcemanager.webapp.delegation-token-auth-filter.enabled
Handling deprecation for mapreduce.job.speculative.retry-after-no-speculate
Handling deprecation for fs.s3a.attempts.maximum
Handling deprecation for s3native.stream-buffer-size
Handling deprecation for io.seqfile.local.dir
Handling deprecation for yarn.log-aggregation.retain-check-interval-seconds
Handling deprecation for fs.s3n.multipart.copy.block.size
Handling deprecation for dfs.encrypt.data.transfer.cipher.key.bitlength
Handling deprecation for dfs.datanode.sync.behind.writes
Handling deprecation for yarn.resourcemanager.zk-acl
Handling deprecation for hadoop.ssl.keystores.factory.class
Handling deprecation for mapreduce.job.split.metainfo.maxsize
Handling deprecation for fs.s3.maxRetries
Handling deprecation for hadoop.security.random.device.file.path
Handling deprecation for yarn.client.nodemanager-connect.max-wait-ms
Handling deprecation for dfs.namenode.stale.datanode.interval
Handling deprecation for mapreduce.task.io.sort.mb
Handling deprecation for yarn.resourcemanager.zk-state-store.parent-path
Handling deprecation for yarn.app.mapreduce.client-am.ipc.max-retries
Handling deprecation for fs.client.resolve.remote.symlinks
Handling deprecation for yarn.nodemanager.linux-container-executor.cgroups.strict-resource-usage
Handling deprecation for hadoop.ssl.enabled.protocols
Handling deprecation for mapreduce.reduce.cpu.vcores
Handling deprecation for yarn.client.failover-retries
Handling deprecation for mapreduce.jobhistory.address
Handling deprecation for hadoop.ssl.enabled
Handling deprecation for dfs.replication.max
Handling deprecation for dfs.namenode.name.dir
Handling deprecation for dfs.datanode.https.address
Handling deprecation for ipc.client.kill.max
Handling deprecation for mapreduce.job.committer.setup.cleanup.needed
Handling deprecation for dfs.client.domain.socket.data.traffic
Handling deprecation for yarn.nodemanager.localizer.cache.target-size-mb
Handling deprecation for yarn.resourcemanager.admin.client.thread-count
Handling deprecation for dfs.block.access.token.enable
Handling deprecation for mapreduce.job.speculative.retry-after-speculate
Handling deprecation for dfs.datanode.address
Handling deprecation for mapreduce.jobtracker.restart.recover
Handling deprecation for ipc.client.connect.max.retries
Handling deprecation for yarn.timeline-service.store-class
Handling deprecation for dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
Handling deprecation for hadoop.tmp.dir
Handling deprecation for dfs.datanode.handler.count
Handling deprecation for yarn.resourcemanager.ha.automatic-failover.embedded
Handling deprecation for yarn.timeline-service.ttl-ms
Handling deprecation for mapreduce.task.profile.map.params
Handling deprecation for yarn.resourcemanager.nodemanagers.heartbeat-interval-ms
Handling deprecation for mapreduce.map.speculative
Handling deprecation for yarn.timeline-service.recovery.enabled
Handling deprecation for mapreduce.job.map.class
Handling deprecation for dfs.namenode.resource.checked.volumes.minimum
Handling deprecation for yarn.nodemanager.recovery.dir
Handling deprecation for mapreduce.job.counters.max
Handling deprecation for yarn.resourcemanager.keytab
Handling deprecation for dfs.namenode.max.extra.edits.segments.retained
Handling deprecation for dfs.webhdfs.user.provider.user.pattern
Handling deprecation for dfs.client.mmap.enabled
Handling deprecation for mapreduce.map.log.level
Handling deprecation for dfs.client.file-block-storage-locations.timeout.millis
Handling deprecation for yarn.client.max-cached-nodemanagers-proxies
Handling deprecation for yarn.app.mapreduce.am.scheduler.heartbeat.interval-ms
Handling deprecation for hadoop.fuse.timer.period
Handling deprecation for fs.trash.checkpoint.interval
Handling deprecation for yarn.sharedcache.app-checker.class
Handling deprecation for dfs.journalnode.http-address
Handling deprecation for yarn.app.mapreduce.am.staging-dir
Handling deprecation for mapreduce.tasktracker.local.dir.minspacestart
Handling deprecation for yarn.nm.liveness-monitor.expiry-interval-ms
Handling deprecation for ha.health-monitor.check-interval.ms
Handling deprecation for mapreduce.reduce.shuffle.merge.percent
Handling deprecation for dfs.namenode.retrycache.heap.percent
Handling deprecation for yarn.nodemanager.docker-container-executor.exec-name
Handling deprecation for ipc.client.connect.timeout
Handling deprecation for yarn.resourcemanager.fs.state-store.retry-interval-ms
Handling deprecation for mapreduce.output.fileoutputformat.compress
Handling deprecation for yarn.nodemanager.local-dirs
Handling deprecation for yarn.nodemanager.recovery.enabled
Handling deprecation for io.native.lib.available
Handling deprecation for yarn.sharedcache.store.in-memory.staleness-period-mins
Handling deprecation for yarn.resourcemanager.am.max-attempts
Handling deprecation for s3.replication
Handling deprecation for mapreduce.input.fileinputformat.inputdir
Handling deprecation for fs.AbstractFileSystem.har.impl
Handling deprecation for dfs.image.compress
Handling deprecation for mapreduce.job.running.map.limit
Handling deprecation for mapreduce.reduce.input.buffer.percent
Handling deprecation for yarn.nodemanager.webapp.address
Handling deprecation for dfs.datanode.available-space-volume-choosing-policy.balanced-space-preference-fraction
Handling deprecation for dfs.namenode.edit.log.autoroll.multiplier.threshold
Handling deprecation for hadoop.security.group.mapping.ldap.ssl
Handling deprecation for dfs.namenode.checkpoint.check.period
Handling deprecation for fs.defaultFS
Handling deprecation for fs.s3a.multipart.size
Handling deprecation for dfs.client.slow.io.warning.threshold.ms
Handling deprecation for yarn.app.mapreduce.am.job.committer.commit-window
Handling deprecation for hadoop.security.group.mapping.ldap.search.attr.group.name
Handling deprecation for yarn.nodemanager.disk-health-checker.max-disk-utilization-per-disk-percentage
Handling deprecation for yarn.nodemanager.container-monitor.procfs-tree.smaps-based-rss.enabled
Handling deprecation for mapreduce.job.submithostname
Handling deprecation for mapreduce.map.sort.spill.percent
Handling deprecation for hadoop.security.crypto.codec.classes.aes.ctr.nopadding
Handling deprecation for dfs.namenode.http-address
Handling deprecation for hadoop.security.groups.negative-cache.secs
Handling deprecation for hadoop.ssl.server.conf
Handling deprecation for mapreduce.ifile.readahead
Handling deprecation for s3native.replication
Handling deprecation for yarn.client.nodemanager-client-async.thread-pool-max-size
Handling deprecation for mapreduce.jobtracker.staging.root.dir
Handling deprecation for mapreduce.jobhistory.admin.address
Handling deprecation for dfs.namenode.startup.delay.block.deletion.sec
Handling deprecation for yarn.nodemanager.health-checker.interval-ms
Handling deprecation for dfs.namenode.checkpoint.max-retries
Handling deprecation for s3.stream-buffer-size
Handling deprecation for ftp.client-write-packet-size
Handling deprecation for dfs.datanode.fsdatasetcache.max.threads.per.volume
Handling deprecation for mapreduce.output.fileoutputformat.compress.codec
Handling deprecation for yarn.timeline-service.keytab
Handling deprecation for yarn.sharedcache.store.in-memory.initial-delay-mins
Handling deprecation for mapreduce.jobhistory.webapp.address
Handling deprecation for mapreduce.task.userlog.limit.kb
Handling deprecation for mapreduce.reduce.shuffle.fetch.retry.enabled
Handling deprecation for yarn.app.mapreduce.task.container.log.backups
Handling deprecation for dfs.heartbeat.interval
Handling deprecation for ha.zookeeper.session-timeout.ms
Handling deprecation for fs.s3a.connection.ssl.enabled
Handling deprecation for yarn.sharedcache.webapp.address
Handling deprecation for hadoop.http.authentication.signature.secret.file
Handling deprecation for hadoop.fuse.connection.timeout
Handling deprecation for mapreduce.input.fileinputformat.numinputfiles
Handling deprecation for yarn.nodemanager.log-aggregation.compression-type
Handling deprecation for ipc.server.max.connections
Handling deprecation for yarn.resourcemanager.work-preserving-recovery.scheduling-wait-ms
Handling deprecation for yarn.nodemanager.log-dirs
Handling deprecation for yarn.app.mapreduce.am.resource.mb
Handling deprecation for hadoop.security.groups.cache.secs
Handling deprecation for mapreduce.job.speculative.minimum-allowed-tasks
Handling deprecation for yarn.nodemanager.container-monitor.interval-ms
Handling deprecation for dfs.datanode.cache.revocation.timeout.ms
Handling deprecation for mapreduce.jobhistory.recovery.store.class
Handling deprecation for mapreduce.task.combine.progress.records
Handling deprecation for s3.client-write-packet-size
Handling deprecation for mapreduce.jobtracker.instrumentation
Handling deprecation for dfs.replication
Handling deprecation for mapreduce.shuffle.transfer.buffer.size
Handling deprecation for hadoop.security.group.mapping.ldap.directory.search.timeout
Handling deprecation for dfs.datanode.available-space-volume-choosing-policy.balanced-space-threshold
Handling deprecation for hadoop.work.around.non.threadsafe.getpwuid
Handling deprecation for yarn.app.mapreduce.client-am.ipc.max-retries-on-timeouts
Handling deprecation for yarn.nodemanager.address
Handling deprecation for mapreduce.tasktracker.taskcontroller
Handling deprecation for mapreduce.tasktracker.indexcache.mb
Handling deprecation for yarn.scheduler.maximum-allocation-vcores
Handling deprecation for mapreduce.job.reduces
Handling deprecation for yarn.nodemanager.sleep-delay-before-sigkill.ms
Handling deprecation for yarn.timeline-service.address
Handling deprecation for yarn.resourcemanager.configuration.provider-class
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.expiry
Handling deprecation for yarn.sharedcache.enabled
Handling deprecation for tfile.io.chunk.size
Handling deprecation for mapreduce.job.acl-modify-job
Handling deprecation for hadoop.registry.zk.session.timeout.ms
Handling deprecation for fs.automatic.close
Handling deprecation for ha.health-monitor.sleep-after-disconnect.ms
Handling deprecation for mapreduce.tasktracker.reduce.tasks.maximum
Handling deprecation for mapreduce.input.fileinputformat.list-status.num-threads
Handling deprecation for dfs.datanode.directoryscan.threads
Handling deprecation for dfs.datanode.directoryscan.interval
Handling deprecation for dfs.namenode.acls.enabled
Handling deprecation for dfs.client.short.circuit.replica.stale.threshold.ms
Handling deprecation for hadoop.http.authentication.token.validity
Handling deprecation for fs.s3.block.size
Handling deprecation for ha.failover-controller.graceful-fence.rpc-timeout.ms
Handling deprecation for mapreduce.tasktracker.local.dir.minspacekill
Handling deprecation for dfs.namenode.resource.du.reserved
Handling deprecation for mapreduce.jobhistory.cleaner.interval-ms
Handling deprecation for dfs.namenode.datanode.registration.ip-hostname-check
Handling deprecation for mapreduce.jobhistory.intermediate-done-dir
Handling deprecation for mapreduce.jobtracker.http.address
Handling deprecation for dfs.namenode.backup.http-address
Handling deprecation for dfs.namenode.edits.noeditlogchannelflush
Handling deprecation for mapreduce.reduce.shuffle.input.buffer.percent
Handling deprecation for mapreduce.map.maxattempts
Handling deprecation for yarn.http.policy
Handling deprecation for dfs.namenode.audit.loggers
Handling deprecation for hadoop.security.groups.cache.warn.after.ms
Handling deprecation for io.serializations
Handling deprecation for mapreduce.tasktracker.outofband.heartbeat
Handling deprecation for mapreduce.reduce.shuffle.read.timeout
Handling deprecation for hadoop.security.crypto.buffer.size
Handling deprecation for mapreduce.reduce.skip.proc.count.autoincr
Handling deprecation for mapreduce.ifile.readahead.bytes
Handling deprecation for dfs.http.policy
Handling deprecation for hadoop.registry.secure
Handling deprecation for dfs.namenode.safemode.min.datanodes
Handling deprecation for dfs.client.file-block-storage-locations.num-threads
Handling deprecation for mapreduce.cluster.local.dir
Handling deprecation for mapreduce.tasktracker.report.address
Handling deprecation for dfs.namenode.secondary.https-address
Handling deprecation for hadoop.kerberos.kinit.command
Handling deprecation for yarn.timeline-service.http-authentication.type
Handling deprecation for dfs.block.access.token.lifetime
Handling deprecation for dfs.webhdfs.enabled
Handling deprecation for dfs.namenode.delegation.token.max-lifetime
Handling deprecation for dfs.namenode.avoid.write.stale.datanode
Handling deprecation for dfs.datanode.drop.cache.behind.writes
Handling deprecation for yarn.log-aggregation.retain-seconds
Handling deprecation for mapreduce.job.complete.cancel.delegation.tokens
Handling deprecation for mapreduce.local.clientfactory.class.name
Handling deprecation for mapreduce.shuffle.connection-keep-alive.timeout
Handling deprecation for dfs.namenode.num.extra.edits.retained
Handling deprecation for yarn.scheduler.minimum-allocation-vcores
Handling deprecation for ipc.client.connect.max.retries.on.timeouts
Handling deprecation for yarn.timeline-service.client.retry-interval-ms
Handling deprecation for yarn.timeline-service.client.max-retries
Handling deprecation for fs.s3n.block.size
Handling deprecation for mapreduce.job.map.output.collector.class
Handling deprecation for ha.health-monitor.connect-retry-interval.ms
Handling deprecation for mapreduce.shuffle.max.threads
Handling deprecation for nfs.exports.allowed.hosts
Handling deprecation for dfs.client.mmap.cache.size
Handling deprecation for mapreduce.tasktracker.map.tasks.maximum
Handling deprecation for io.file.buffer.size
Handling deprecation for dfs.client.datanode-restart.timeout
Handling deprecation for io.mapfile.bloom.size
Handling deprecation for hadoop.security.kms.client.authentication.retry-count
Handling deprecation for dfs.namenode.checkpoint.txns
Handling deprecation for ipc.client.connect.retry.interval
Handling deprecation for dfs.client-write-packet-size
Handling deprecation for mapreduce.reduce.shuffle.connect.timeout
Handling deprecation for yarn.resourcemanager.fs.state-store.uri
Handling deprecation for fs.swift.impl
Handling deprecation for hadoop.registry.zk.connection.timeout.ms
Handling deprecation for mapred.queue.default.acl-administer-jobs
Handling deprecation for mapreduce.job.submithostaddress
Handling deprecation for dfs.cachereport.intervalMsec
Handling deprecation for yarn.app.mapreduce.shuffle.log.backups
Handling deprecation for yarn.app.mapreduce.am.container.log.limit.kb
Handling deprecation for yarn.nodemanager.resourcemanager.minimum.version
Handling deprecation for ftp.blocksize
Handling deprecation for yarn.resourcemanager.address
Handling deprecation for file.stream-buffer-size
Handling deprecation for yarn.resourcemanager.scheduler.monitor.enable
Handling deprecation for mapreduce.job.ubertask.maxreduces
Handling deprecation for nfs.allow.insecure.ports
Handling deprecation for yarn.sharedcache.nm.uploader.thread-count
Handling deprecation for ipc.client.idlethreshold
Handling deprecation for ftp.stream-buffer-size
Handling deprecation for yarn.sharedcache.client-server.address
Handling deprecation for dfs.client.failover.connection.retries.on.timeouts
Handling deprecation for dfs.namenode.replication.work.multiplier.per.iteration
Handling deprecation for hadoop.http.authentication.simple.anonymous.allowed
Handling deprecation for hadoop.security.authorization
Handling deprecation for yarn.client.nodemanager-connect.retry-interval-ms
Handling deprecation for yarn.am.liveness-monitor.expiry-interval-ms
Handling deprecation for fs.har.impl.disable.cache
Handling deprecation for yarn.nodemanager.linux-container-executor.resources-handler.class
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.read-cache-size
Handling deprecation for hadoop.security.authentication
Handling deprecation for dfs.image.compression.codec
Handling deprecation for mapreduce.task.files.preserve.failedtasks
Handling deprecation for dfs.client.read.shortcircuit.streams.cache.size
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.path
Handling deprecation for mapreduce.job.reduce.slowstart.completedmaps
Handling deprecation for mapreduce.jobhistory.minicluster.fixed.ports
Handling deprecation for file.replication
Handling deprecation for yarn.resourcemanager.ha.automatic-failover.enabled
Handling deprecation for mapreduce.job.userlog.retain.hours
Handling deprecation for mapreduce.jobhistory.joblist.cache.size
Handling deprecation for dfs.namenode.accesstime.precision
Handling deprecation for yarn.resourcemanager.work-preserving-recovery.enabled
Handling deprecation for dfs.namenode.fs-limits.max-xattrs-per-inode
Handling deprecation for io.mapfile.bloom.error.rate
Handling deprecation for yarn.resourcemanager.store.class
Handling deprecation for dfs.image.transfer.timeout
Handling deprecation for yarn.timeline-service.leveldb-state-store.path
Handling deprecation for nfs.wtmax
Handling deprecation for mapreduce.job.combine.class
Handling deprecation for dfs.namenode.support.allow.format
Handling deprecation for fs.s3a.multipart.purge
Handling deprecation for dfs.secondary.namenode.kerberos.internal.spnego.principal
Handling deprecation for fs.s3a.connection.establish.timeout
Handling deprecation for dfs.stream-buffer-size
Handling deprecation for dfs.namenode.invalidate.work.pct.per.iteration
Handling deprecation for yarn.nodemanager.container-executor.class
Handling deprecation for fs.s3a.multipart.purge.age
Handling deprecation for yarn.resourcemanager.scheduler.client.thread-count
Handling deprecation for dfs.namenode.top.enabled
Handling deprecation for yarn.app.mapreduce.shuffle.log.separate
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.low-watermark
Handling deprecation for fs.s3a.fast.buffer.size
Handling deprecation for hadoop.user.group.static.mapping.overrides
Handling deprecation for tfile.fs.input.buffer.size
Handling deprecation for dfs.client.cached.conn.retry
Handling deprecation for hadoop.http.authentication.type
Handling deprecation for dfs.namenode.list.encryption.zones.num.responses
Handling deprecation for mapreduce.map.cpu.vcores
Handling deprecation for dfs.namenode.path.based.cache.refresh.interval.ms
Handling deprecation for dfs.namenode.decommission.interval
Handling deprecation for dfs.namenode.fs-limits.max-directory-items
Handling deprecation for yarn.resourcemanager.zk-retry-interval-ms
Handling deprecation for ftp.bytes-per-checksum
Handling deprecation for dfs.ha.log-roll.period
Handling deprecation for dfs.user.home.dir.prefix
Handling deprecation for ipc.client.fallback-to-simple-auth-allowed
Handling deprecation for yarn.nodemanager.pmem-check-enabled
Handling deprecation for yarn.nodemanager.remote-app-log-dir
Handling deprecation for dfs.namenode.inotify.max.events.per.rpc
Handling deprecation for mapreduce.task.profile.maps
Handling deprecation for mapreduce.shuffle.ssl.file.buffer.size
Handling deprecation for mapreduce.tasktracker.healthchecker.script.timeout
Handling deprecation for yarn.timeline-service.webapp.https.address
Handling deprecation for yarn.nodemanager.resource.percentage-physical-cpu-limit
Handling deprecation for yarn.app.mapreduce.am.command-opts
Handling deprecation for dfs.namenode.fs-limits.max-xattr-size
Handling deprecation for dfs.datanode.http.address
Handling deprecation for dfs.namenode.blocks.per.postponedblocks.rescan
Handling deprecation for yarn.sharedcache.nm.uploader.replication.factor
Handling deprecation for hadoop.registry.zk.root
Handling deprecation for hadoop.jetty.logs.serve.aliases
Handling deprecation for yarn.client.failover-proxy-provider
Handling deprecation for mapreduce.jobhistory.admin.acl
Handling deprecation for yarn.app.mapreduce.am.hard-kill-timeout-ms
Handling deprecation for yarn.nodemanager.remote-app-log-dir-suffix
Handling deprecation for mapreduce.jobhistory.principal
Handling deprecation for yarn.resourcemanager.webapp.address
Handling deprecation for mapreduce.jobhistory.recovery.enable
Handling deprecation for yarn.sharedcache.store.in-memory.check-period-mins
Handling deprecation for nfs.mountd.port
Handling deprecation for mapreduce.reduce.merge.inmem.threshold
Handling deprecation for fs.df.interval
Handling deprecation for yarn.timeline-service.enabled
Handling deprecation for mapreduce.jobtracker.jobhistory.lru.cache.size
Handling deprecation for mapreduce.task.profile
Handling deprecation for mapreduce.job.output.key.class
Handling deprecation for yarn.nodemanager.hostname
Handling deprecation for dfs.namenode.num.checkpoints.retained
Handling deprecation for mapreduce.job.queuename
Handling deprecation for mapreduce.jobhistory.max-age-ms
Handling deprecation for mapreduce.job.token.tracking.ids.enabled
Handling deprecation for yarn.nodemanager.localizer.client.thread-count
Handling deprecation for yarn.sharedcache.uploader.server.thread-count
Handling deprecation for dfs.client.mmap.retry.timeout.ms
Handling deprecation for mapreduce.jobhistory.move.thread-count
Handling deprecation for dfs.permissions.enabled
Handling deprecation for dfs.blockreport.split.threshold
Handling deprecation for fs.AbstractFileSystem.hdfs.impl
Handling deprecation for dfs.datanode.balance.bandwidthPerSec
Handling deprecation for dfs.block.scanner.volume.bytes.per.second
Handling deprecation for hadoop.http.filter.initializers
Handling deprecation for yarn.timeline-service.http-authentication.simple.anonymous.allowed
Handling deprecation for dfs.default.chunk.view.size
Handling deprecation for yarn.sharedcache.client-server.thread-count
Handling deprecation for yarn.resourcemanager.resource-tracker.address
Handling deprecation for mapreduce.job.working.dir
Handling deprecation for mapreduce.jobhistory.datestring.cache.size
Handling deprecation for mapreduce.task.profile.params
Handling deprecation for dfs.namenode.decommission.blocks.per.interval
Handling deprecation for dfs.namenode.handler.count
Handling deprecation for dfs.image.transfer.bandwidthPerSec
Handling deprecation for rpc.metrics.quantile.enable
Handling deprecation for mapreduce.jobtracker.expire.trackers.interval
Handling deprecation for mapreduce.task.timeout
Handling deprecation for yarn.app.mapreduce.client.max-retries
Handling deprecation for yarn.nodemanager.resource.memory-mb
Handling deprecation for yarn.nodemanager.disk-health-checker.min-healthy-disks
Handling deprecation for dfs.datanode.failed.volumes.tolerated
Handling deprecation for yarn.timeline-service.handler-thread-count
Handling deprecation for ipc.server.listen.queue.size
Handling deprecation for fs.s3a.threads.max
Handling deprecation for yarn.resourcemanager.connect.max-wait.ms
Handling deprecation for mapreduce.fileoutputcommitter.algorithm.version
Handling deprecation for mapreduce.framework.name
Handling deprecation for mapreduce.map.skip.proc.count.autoincr
Handling deprecation for mapreduce.job.max.split.locations
Handling deprecation for yarn.resourcemanager.scheduler.class
Handling deprecation for yarn.resourcemanager.system-metrics-publisher.enabled
Handling deprecation for dfs.blocksize
Handling deprecation for yarn.sharedcache.nested-level
Handling deprecation for mapreduce.shuffle.connection-keep-alive.enable
Handling deprecation for fs.s3a.threads.keepalivetime
Handling deprecation for fs.s3a.connection.timeout
Handling deprecation for file.client-write-packet-size
Handling deprecation for ha.failover-controller.cli-check.rpc-timeout.ms
Handling deprecation for ha.zookeeper.acl
Handling deprecation for dfs.namenode.write.stale.datanode.ratio
Handling deprecation for dfs.encrypt.data.transfer
Handling deprecation for dfs.datanode.shared.file.descriptor.paths
Handling deprecation for mapreduce.input.lineinputformat.linespermap
Handling deprecation for yarn.resourcemanager.delayed.delegation-token.removal-interval-ms
Handling deprecation for yarn.nodemanager.localizer.fetch.thread-count
Handling deprecation for dfs.client.failover.max.attempts
Handling deprecation for yarn.resourcemanager.scheduler.address
Handling deprecation for dfs.client.read.shortcircuit.streams.cache.expiry.ms
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.start-time-write-cache-size
Handling deprecation for yarn.nodemanager.health-checker.script.timeout-ms
Handling deprecation for yarn.resourcemanager.fs.state-store.num-retries
Handling deprecation for hadoop.ssl.require.client.cert
Handling deprecation for hadoop.security.uid.cache.secs
Handling deprecation for mapreduce.jobhistory.keytab
Handling deprecation for dfs.client.read.shortcircuit.skip.checksum
Handling deprecation for yarn.resourcemanager.ha.automatic-failover.zk-base-path
Handling deprecation for mapreduce.shuffle.ssl.enabled
Handling deprecation for mapreduce.reduce.log.level
Handling deprecation for hadoop.registry.rm.enabled
Handling deprecation for mapreduce.tasktracker.dns.interface
Handling deprecation for yarn.resourcemanager.system-metrics-publisher.dispatcher.pool-size
Handling deprecation for mapreduce.job.speculative.speculative-cap-running-tasks
Handling deprecation for dfs.datanode.block.id.layout.upgrade.threads
Handling deprecation for dfs.datanode.use.datanode.hostname
Handling deprecation for dfs.client.context
Handling deprecation for yarn.resourcemanager.ha.enabled
Handling deprecation for mapred.reducer.new-api
Handling deprecation for dfs.namenode.delegation.token.renew-interval
Handling deprecation for dfs.blockreport.intervalMsec
Handling deprecation for fs.s3a.multipart.threshold
Handling deprecation for mapreduce.reduce.shuffle.memory.limit.percent
Handling deprecation for dfs.https.server.keystore.resource
Handling deprecation for io.map.index.skip
Handling deprecation for mapreduce.job.hdfs-servers
Handling deprecation for mapreduce.jobtracker.taskscheduler
Handling deprecation for dfs.namenode.kerberos.internal.spnego.principal
Handling deprecation for yarn.resourcemanager.state-store.max-completed-applications
Handling deprecation for mapreduce.map.output.compress
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.num.refill.threads
Handling deprecation for fs.s3n.multipart.uploads.block.size
Handling deprecation for mapreduce.task.merge.progress.records
Handling deprecation for dfs.datanode.dns.interface
Handling deprecation for map.sort.class
Handling deprecation for yarn.nodemanager.aux-services.mapreduce_shuffle.class
Handling deprecation for tfile.fs.output.buffer.size
Handling deprecation for fs.du.interval
Handling deprecation for dfs.client.failover.connection.retries
Handling deprecation for dfs.namenode.top.window.num.buckets
Handling deprecation for mapreduce.job.dir
Handling deprecation for fs.s3a.buffer.dir
Handling deprecation for mapreduce.reduce.shuffle.retry-delay.max.ms
Handling deprecation for yarn.sharedcache.uploader.server.address
Handling deprecation for mapreduce.client.progressmonitor.pollinterval
Handling deprecation for yarn.app.mapreduce.shuffle.log.limit.kb
Handling deprecation for dfs.datanode.max.locked.memory
Handling deprecation for dfs.namenode.retrycache.expirytime.millis
Handling deprecation for dfs.datanode.scan.period.hours
Handling deprecation for dfs.client.block.write.replace-datanode-on-failure.best-effort
Handling deprecation for mapreduce.jobhistory.move.interval-ms
Handling deprecation for dfs.ha.fencing.ssh.connect-timeout
Handling deprecation for yarn.nodemanager.log-aggregation.roll-monitoring-interval-seconds
Handling deprecation for dfs.namenode.fs-limits.max-component-length
Handling deprecation for hadoop.registry.zk.quorum
Handling deprecation for dfs.namenode.enable.retrycache
Handling deprecation for dfs.datanode.du.reserved
Handling deprecation for yarn.timeline-service.state-store-class
Handling deprecation for dfs.datanode.ipc.address
Handling deprecation for hadoop.registry.system.acls
Handling deprecation for dfs.client.block.write.replace-datanode-on-failure.policy
Handling deprecation for dfs.namenode.path.based.cache.retry.interval.ms
Handling deprecation for hadoop.security.crypto.cipher.suite
Handling deprecation for dfs.ha.tail-edits.period
Handling deprecation for mapreduce.task.profile.reduce.params
Handling deprecation for hadoop.registry.jaas.context
Handling deprecation for yarn.resourcemanager.hostname
Handling deprecation for mapreduce.reduce.memory.mb
Handling deprecation for hadoop.security.group.mapping.ldap.search.filter.group
Handling deprecation for hadoop.http.authentication.kerberos.principal
Handling deprecation for hadoop.security.group.mapping.ldap.search.filter.user
Handling deprecation for yarn.nodemanager.disk-health-checker.min-free-space-per-disk-mb
Handling deprecation for dfs.namenode.edits.dir
Handling deprecation for yarn.client.failover-retries-on-socket-timeouts
Handling deprecation for dfs.namenode.decommission.max.concurrent.tracked.nodes
Handling deprecation for mapreduce.client.completion.pollinterval
Handling deprecation for dfs.namenode.name.dir.restore
Handling deprecation for dfs.namenode.secondary.http-address
Handling deprecation for mapreduce.jobhistory.recovery.store.leveldb.path
Handling deprecation for yarn.sharedcache.store.class
Handling deprecation for s3.bytes-per-checksum
Handling deprecation for yarn.nodemanager.windows-container.cpu-limit.enabled
Handling deprecation for yarn.resourcemanager.webapp.https.address
Handling deprecation for yarn.nodemanager.vmem-pmem-ratio
Handling deprecation for dfs.namenode.checkpoint.period
Handling deprecation for dfs.ha.automatic-failover.enabled
The url to track the job: http://localhost:8080/
Running job: job_local183065926_0002
OutputCommitter set in config null
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
File Output Committer Algorithm version is 1
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
/user/michaeljones/wcOutput/_temporary/0: masked=rwxr-xr-x
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones sending #35
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones got value #35
Call: mkdirs took 6ms
Starting mapper thread pool executor.
Max local threads: 1
Map tasks to process: 1
Waiting for map tasks
Starting task: attempt_local183065926_0002_m_000000_0
currentIndex 0   0:0
mapreduce.cluster.local.dir for child : /tmp/hadoop-michaeljones/mapred/local/localRunner//michaeljones/jobcache/job_local183065926_0002/attempt_local183065926_0002_m_000000_0
using new api for output committer
File Output Committer Algorithm version is 1
ProcfsBasedProcessTree currently is supported only on Linux.
 Using ResourceCalculatorProcessTree : null
Processing split: hdfs://localhost:9000/user/michaeljones/wcInput:0+50
Trying map output collector class: org.apache.hadoop.mapred.MapTask$MapOutputBuffer
(EQUATOR) 0 kvi 26214396(104857584)
mapreduce.task.io.sort.mb: 100
soft limit at 83886080
bufstart = 0; bufvoid = 104857600
kvstart = 26214396; length = 6553600
Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones sending #36
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones got value #36
Call: getBlockLocations took 3ms
newInfo = LocatedBlocks{
  fileLength=50
  underConstruction=false
  blocks=[LocatedBlock{BP-1045030256-10.0.0.2-1433119149314:blk_1073741825_1002; getBlockSize()=50; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-b42c5705-9ba4-4b14-b00b-f9194bb036f0,DISK]]}]
  lastLocatedBlock=LocatedBlock{BP-1045030256-10.0.0.2-1433119149314:blk_1073741825_1002; getBlockSize()=50; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-b42c5705-9ba4-4b14-b00b-f9194bb036f0,DISK]]}
  isLastBlockComplete=true}
Connecting to datanode 127.0.0.1:50010

Starting flush of map output
Spilling map output
bufstart = 0; bufend = 82; bufvoid = 104857600
kvstart = 26214396(104857584); kvend = 26214368(104857472); length = 29/6553600
Finished spill 0
Task:attempt_local183065926_0002_m_000000_0 is done. And is in the process of committing
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones sending #37
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones got value #37
Call: getFileInfo took 3ms
map
Task 'attempt_local183065926_0002_m_000000_0' done.
Finishing task: attempt_local183065926_0002_m_000000_0
map task executor complete.
Starting reduce thread pool executor.
Max local threads: 1
Reduce tasks to process: 1
Waiting for reduce tasks
Starting task: attempt_local183065926_0002_r_000000_0
currentIndex 0   0:0
mapreduce.cluster.local.dir for child : /tmp/hadoop-michaeljones/mapred/local/localRunner//michaeljones/jobcache/job_local183065926_0002/attempt_local183065926_0002_r_000000_0
using new api for output committer
File Output Committer Algorithm version is 1
ProcfsBasedProcessTree currently is supported only on Linux.
 Using ResourceCalculatorProcessTree : null
Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@72c72ade
MergerManager: memoryLimit=668309888, maxSingleShuffleLimit=167077472, mergeThreshold=441084544, ioSortFactor=10, memToMemMergeOutputsThreshold=10
attempt_local183065926_0002_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
Got 0 map completion events from 0
GetMapEventsThread about to sleep for 1000
LocalFetcher 2 going to fetch: attempt_local183065926_0002_m_000000_0
attempt_local183065926_0002_m_000000_0: Proceeding with shuffle since usedMemory (0) is lesser than memoryLimit (668309888).CommitMemory is (0)
localfetcher#2 about to shuffle output of map attempt_local183065926_0002_m_000000_0 decomp: 63 len: 67 to MEMORY
Read 63 bytes from map-output for attempt_local183065926_0002_m_000000_0
closeInMemoryFile -> map-output of size: 63, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->63
map attempt_local183065926_0002_m_000000_0 done 1 / 1 copied.
EventFetcher is interrupted.. Returning
1 / 1 copied.
finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
Merging 1 sorted segments
Down to the last merge-pass, with 1 segments left of total size: 57 bytes
Merged 1 segments, 63 bytes to disk to satisfy reduce memory limit
Disk file: /tmp/hadoop-michaeljones/mapred/local/localRunner/michaeljones/jobcache/job_local183065926_0002/attempt_local183065926_0002_r_000000_0/output/map_0.out.merged Length is 67
Merging 1 files, 67 bytes from disk
Merging 0 segments, 0 bytes from memory into reduce
Merging 1 sorted segments
Down to the last merge-pass, with 1 segments left of total size: 57 bytes
1 / 1 copied.
/user/michaeljones/wcOutput/_temporary/0/_temporary/attempt_local183065926_0002_r_000000_0/part-r-00000: masked=rw-r--r--
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones sending #38
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones got value #38
Call: create took 4ms
computePacketChunkSize: src=/user/michaeljones/wcOutput/_temporary/0/_temporary/attempt_local183065926_0002_r_000000_0/part-r-00000, chunkSize=516, chunksPerPacket=126, packetSize=65016
DFSClient writeChunk allocating new packet seqno=0, src=/user/michaeljones/wcOutput/_temporary/0/_temporary/attempt_local183065926_0002_r_000000_0/part-r-00000, packetSize=65016, chunksPerPacket=126, bytesCurBlock=0
Queued packet 0
Queued packet 1
Waiting for ack for: 1
Allocating new block
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones sending #39
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones got value #39
Call: addBlock took 4ms
pipeline = DatanodeInfoWithStorage[127.0.0.1:50010,DS-b42c5705-9ba4-4b14-b00b-f9194bb036f0,DISK]
Connecting to datanode 127.0.0.1:50010
Send buf size 131072
SASL client skipping handshake in unsecured configuration for addr = /127.0.0.1, datanodeId = DatanodeInfoWithStorage[127.0.0.1:50010,DS-b42c5705-9ba4-4b14-b00b-f9194bb036f0,DISK]
DataStreamer block BP-1045030256-10.0.0.2-1433119149314:blk_1073742379_1556 sending packet packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 41
DFSClient seqno: 0 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
DataStreamer block BP-1045030256-10.0.0.2-1433119149314:blk_1073742379_1556 sending packet packet seqno: 1 offsetInBlock: 41 lastPacketInBlock: true lastByteOffsetInBlock: 41
DFSClient seqno: 1 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
Closing old block BP-1045030256-10.0.0.2-1433119149314:blk_1073742379_1556
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones sending #40
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones got value #40
Call: complete took 5ms
Task:attempt_local183065926_0002_r_000000_0 is done. And is in the process of committing
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones sending #41
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones got value #41
Call: getFileInfo took 2ms
1 / 1 copied.
Task attempt_local183065926_0002_r_000000_0 is allowed to commit now
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones sending #42
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones got value #42
Call: getFileInfo took 2ms
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones sending #43
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones got value #43
Call: getFileInfo took 1ms
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones sending #44
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones got value #44
Call: rename took 3ms
Saved output of task 'attempt_local183065926_0002_r_000000_0' to hdfs://localhost:9000/user/michaeljones/wcOutput/_temporary/0/task_local183065926_0002_r_000000
reduce > reduce
Task 'attempt_local183065926_0002_r_000000_0' done.
Finishing task: attempt_local183065926_0002_r_000000_0
reduce task executor complete.
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones sending #45
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones got value #45
Call: getListing took 2ms
Merging data from FileStatus{path=hdfs://localhost:9000/user/michaeljones/wcOutput/_temporary/0/task_local183065926_0002_r_000000; isDirectory=true; modification_time=1434253172598; access_time=0; owner=michaeljones; group=supergroup; permission=rwxr-xr-x; isSymlink=false} to hdfs://localhost:9000/user/michaeljones/wcOutput
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones sending #46
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones got value #46
Call: getFileInfo took 2ms
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones sending #47
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones got value #47
Call: getListing took 2ms
Merging data from FileStatus{path=hdfs://localhost:9000/user/michaeljones/wcOutput/_temporary/0/task_local183065926_0002_r_000000/part-r-00000; isDirectory=false; length=41; replication=1; blocksize=134217728; modification_time=1434253172620; access_time=1434253172598; owner=michaeljones; group=supergroup; permission=rw-r--r--; isSymlink=false} to hdfs://localhost:9000/user/michaeljones/wcOutput/part-r-00000
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones sending #48
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones got value #48
Call: getFileInfo took 2ms
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones sending #49
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones got value #49
Call: rename took 3ms
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones sending #50
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones got value #50
Call: delete took 10ms
/user/michaeljones/wcOutput/_SUCCESS: masked=rw-r--r--
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones sending #51
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones got value #51
Call: create took 4ms
computePacketChunkSize: src=/user/michaeljones/wcOutput/_SUCCESS, chunkSize=516, chunksPerPacket=126, packetSize=65016
Waiting for ack for: -1
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones sending #52
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones got value #52
Call: complete took 11ms
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.fs.FileContext.getAbstractFileSystem(FileContext.java:331)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
Job job_local183065926_0002 running in uber mode : false
 map 100% reduce 100%
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.getTaskCompletionEvents(Job.java:670)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.getTaskCompletionEvents(Job.java:670)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
Job job_local183065926_0002 completed successfully
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.getCounters(Job.java:758)
Counters: 35
	File System Counters
		FILE: Number of bytes read=1206
		FILE: Number of bytes written=1128413
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=240
		HDFS: Number of bytes written=163
		HDFS: Number of read operations=45
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=24
	Map-Reduce Framework
		Map input records=2
		Map output records=8
		Map output bytes=82
		Map output materialized bytes=67
		Input split bytes=112
		Combine input records=8
		Combine output records=5
		Reduce input groups=5
		Reduce shuffle bytes=67
		Reduce input records=5
		Reduce output records=5
		Spilled Records=10
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=717225984
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=50
	File Output Format Counters 
		Bytes Written=41
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
RunJobAnalysisAsync
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones sending #53
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones got value #53
Call: getFileInfo took 2ms
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones sending #54
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones got value #54
Call: delete took 2ms
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.connect(Job.java:1256)
Trying ClientProtocolProvider : org.apache.hadoop.mapred.LocalClientProtocolProvider
Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
Picked org.apache.hadoop.mapred.LocalClientProtocolProvider as the ClientProtocolProvider
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Cluster.getFileSystem(Cluster.java:162)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.submit(Job.java:1287)
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones sending #55
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones got value #55
Call: getFileInfo took 2ms
Configuring job job_local1653575348_0003 with file:/tmp/hadoop-michaeljones/mapred/staging/michaeljones1653575348/.staging/job_local1653575348_0003 as the submit dir
adding the following namenodes' delegation tokens:[hdfs://localhost:9000]
Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
default FileSystem: file:///
No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
Creating splits at file:/tmp/hadoop-michaeljones/mapred/staging/michaeljones1653575348/.staging/job_local1653575348_0003
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones sending #56
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones got value #56
Call: getFileInfo took 3ms
Time taken to get FileStatuses: 3
Total input paths to process : 1
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones sending #57
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones got value #57
Call: getBlockLocations took 3ms
Total # of splits generated by getSplits: 1, TimeTaken: 7
number of splits:1
Handling deprecation for all properties in config...
Handling deprecation for mapreduce.jobtracker.address
Handling deprecation for yarn.resourcemanager.scheduler.monitor.policies
Handling deprecation for dfs.namenode.resource.check.interval
Handling deprecation for mapreduce.jobhistory.client.thread-count
Handling deprecation for yarn.app.mapreduce.am.containerlauncher.threadpool-initial-size
Handling deprecation for mapred.child.java.opts
Handling deprecation for mapreduce.jobtracker.retiredjobs.cache.size
Handling deprecation for dfs.client.https.need-auth
Handling deprecation for yarn.admin.acl
Handling deprecation for yarn.app.mapreduce.am.job.committer.cancel-timeout
Handling deprecation for mapreduce.job.emit-timeline-data
Handling deprecation for fs.ftp.host.port
Handling deprecation for dfs.namenode.avoid.read.stale.datanode
Handling deprecation for dfs.journalnode.rpc-address
Handling deprecation for mapreduce.job.end-notification.retry.attempts
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.ttl-interval-ms
Handling deprecation for yarn.resourcemanager.leveldb-state-store.path
Handling deprecation for mapred.mapper.new-api
Handling deprecation for yarn.ipc.rpc.class
Handling deprecation for ipc.client.connection.maxidletime
Handling deprecation for yarn.nodemanager.process-kill-wait.ms
Handling deprecation for mapreduce.cluster.acls.enabled
Handling deprecation for mapreduce.jobtracker.handler.count
Handling deprecation for io.map.index.interval
Handling deprecation for dfs.namenode.https-address
Handling deprecation for mapreduce.task.profile.reduces
Handling deprecation for fs.s3n.multipart.uploads.enabled
Handling deprecation for io.seqfile.sorter.recordlimit
Handling deprecation for mapreduce.job.ubertask.maxmaps
Handling deprecation for mapreduce.tasktracker.tasks.sleeptimebeforesigkill
Handling deprecation for hadoop.util.hash.type
Handling deprecation for dfs.namenode.replication.min
Handling deprecation for yarn.nodemanager.container-manager.thread-count
Handling deprecation for mapreduce.jobtracker.jobhistory.block.size
Handling deprecation for dfs.namenode.fs-limits.min-block-size
Handling deprecation for mapreduce.app-submission.cross-platform
Handling deprecation for fs.AbstractFileSystem.file.impl
Handling deprecation for net.topology.script.number.args
Handling deprecation for yarn.resourcemanager.container-tokens.master-key-rolling-interval-secs
Handling deprecation for mapreduce.map.output.compress.codec
Handling deprecation for mapreduce.job.reducer.preempt.delay.sec
Handling deprecation for s3native.bytes-per-checksum
Handling deprecation for dfs.namenode.path.based.cache.block.map.allocation.percent
Handling deprecation for yarn.nodemanager.windows-container.memory-limit.enabled
Handling deprecation for mapreduce.input.fileinputformat.split.minsize
Handling deprecation for hadoop.security.group.mapping
Handling deprecation for mapreduce.jobtracker.system.dir
Handling deprecation for mapreduce.job.end-notification.max.attempts
Handling deprecation for mapreduce.reduce.markreset.buffer.percent
Handling deprecation for dfs.datanode.cache.revocation.polling.ms
Handling deprecation for mapreduce.reduce.speculative
Handling deprecation for yarn.nodemanager.localizer.cache.cleanup.interval-ms
Handling deprecation for dfs.namenode.lazypersist.file.scrub.interval.sec
Handling deprecation for fs.s3a.threads.core
Handling deprecation for mapreduce.jobhistory.recovery.store.fs.uri
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.start-time-read-cache-size
Handling deprecation for hadoop.registry.zk.retry.interval.ms
Handling deprecation for yarn.nodemanager.keytab
Handling deprecation for dfs.namenode.replication.interval
Handling deprecation for yarn.resourcemanager.admin.address
Handling deprecation for mapreduce.job.maps
Handling deprecation for nfs.dump.dir
Handling deprecation for mapreduce.job.user.name
Handling deprecation for mapreduce.jobtracker.maxtasks.perjob
Handling deprecation for mapreduce.job.ubertask.enable
Handling deprecation for mapreduce.job.reduce.class
Handling deprecation for yarn.nodemanager.delete.debug-delay-sec
Handling deprecation for yarn.timeline-service.ttl-enable
Handling deprecation for yarn.resourcemanager.fs.state-store.retry-policy-spec
Handling deprecation for mapreduce.reduce.skip.maxgroups
Handling deprecation for dfs.client.use.datanode.hostname
Handling deprecation for fs.trash.interval
Handling deprecation for mapreduce.job.name
Handling deprecation for mapreduce.am.max-attempts
Handling deprecation for mapreduce.jobtracker.heartbeats.in.second
Handling deprecation for yarn.resourcemanager.zk-num-retries
Handling deprecation for s3.blocksize
Handling deprecation for dfs.datanode.data.dir
Handling deprecation for mapreduce.jobtracker.persist.jobstatus.active
Handling deprecation for mapreduce.reduce.shuffle.parallelcopies
Handling deprecation for fs.s3.buffer.dir
Handling deprecation for mapreduce.jobhistory.done-dir
Handling deprecation for hadoop.security.instrumentation.requires.admin
Handling deprecation for hadoop.registry.zk.retry.ceiling.ms
Handling deprecation for nfs.rtmax
Handling deprecation for dfs.datanode.data.dir.perm
Handling deprecation for yarn.resourcemanager.container.liveness-monitor.interval-ms
Handling deprecation for yarn.nodemanager.env-whitelist
Handling deprecation for dfs.namenode.backup.address
Handling deprecation for dfs.namenode.xattrs.enabled
Handling deprecation for dfs.datanode.readahead.bytes
Handling deprecation for mapreduce.jobhistory.cleaner.enable
Handling deprecation for dfs.client.block.write.retries
Handling deprecation for mapreduce.tasktracker.http.address
Handling deprecation for yarn.nodemanager.linux-container-executor.cgroups.hierarchy
Handling deprecation for ha.failover-controller.graceful-fence.connection.retries
Handling deprecation for yarn.resourcemanager.recovery.enabled
Handling deprecation for yarn.app.mapreduce.am.container.log.backups
Handling deprecation for dfs.namenode.safemode.threshold-pct
Handling deprecation for yarn.nodemanager.disk-health-checker.interval-ms
Handling deprecation for hadoop.security.java.secure.random.algorithm
Handling deprecation for dfs.namenode.list.cache.directives.num.responses
Handling deprecation for dfs.datanode.dns.nameserver
Handling deprecation for mapreduce.cluster.temp.dir
Handling deprecation for fs.s3a.max.total.tasks
Handling deprecation for mapreduce.reduce.maxattempts
Handling deprecation for mapreduce.client.submit.file.replication
Handling deprecation for mapreduce.shuffle.port
Handling deprecation for yarn.resourcemanager.resource-tracker.client.thread-count
Handling deprecation for dfs.namenode.replication.considerLoad
Handling deprecation for dfs.namenode.edits.journal-plugin.qjournal
Handling deprecation for dfs.client.write.exclude.nodes.cache.expiry.interval.millis
Handling deprecation for yarn.nodemanager.delete.thread-count
Handling deprecation for dfs.client.mmap.cache.timeout.ms
Handling deprecation for yarn.nodemanager.admin-env
Handling deprecation for io.skip.checksum.errors
Handling deprecation for yarn.timeline-service.hostname
Handling deprecation for yarn.resourcemanager.proxy-user-privileges.enabled
Handling deprecation for mapreduce.job.speculative.speculative-cap-total-tasks
Handling deprecation for yarn.acl.enable
Handling deprecation for fs.s3a.fast.upload
Handling deprecation for file.blocksize
Handling deprecation for mapreduce.job.speculative.slowtaskthreshold
Handling deprecation for ftp.replication
Handling deprecation for yarn.sharedcache.cleaner.initial-delay-mins
Handling deprecation for s3native.client-write-packet-size
Handling deprecation for hadoop.rpc.socket.factory.class.default
Handling deprecation for file.bytes-per-checksum
Handling deprecation for dfs.datanode.slow.io.warning.threshold.ms
Handling deprecation for io.seqfile.lazydecompress
Handling deprecation for mapreduce.task.skip.start.attempts
Handling deprecation for dfs.namenode.reject-unresolved-dn-topology-mapping
Handling deprecation for hadoop.common.configuration.version
Handling deprecation for yarn.resourcemanager.client.thread-count
Handling deprecation for dfs.datanode.drop.cache.behind.reads
Handling deprecation for yarn.sharedcache.admin.address
Handling deprecation for mapreduce.job.output.value.class
Handling deprecation for mapreduce.output.fileoutputformat.outputdir
Handling deprecation for mapreduce.jobtracker.taskcache.levels
Handling deprecation for yarn.nodemanager.linux-container-executor.nonsecure-mode.user-pattern
Handling deprecation for yarn.resourcemanager.zk-timeout-ms
Handling deprecation for yarn.resourcemanager.max-completed-applications
Handling deprecation for mapreduce.job.jvm.numtasks
Handling deprecation for yarn.sharedcache.cleaner.period-mins
Handling deprecation for mapreduce.jobtracker.tasktracker.maxblacklists
Handling deprecation for dfs.namenode.top.num.users
Handling deprecation for yarn.nodemanager.linux-container-executor.cgroups.mount
Handling deprecation for yarn.sharedcache.checksum.algo.impl
Handling deprecation for mapreduce.job.end-notification.max.retry.interval
Handling deprecation for mapreduce.job.acl-view-job
Handling deprecation for mapreduce.job.classloader
Handling deprecation for yarn.log-aggregation-enable
Handling deprecation for mapreduce.reduce.shuffle.fetch.retry.interval-ms
Handling deprecation for yarn.resourcemanager.nodemanager.minimum.version
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.size
Handling deprecation for yarn.app.mapreduce.am.job.task.listener.thread-count
Handling deprecation for yarn.app.mapreduce.am.resource.cpu-vcores
Handling deprecation for dfs.namenode.edit.log.autoroll.check.interval.ms
Handling deprecation for mapreduce.output.fileoutputformat.compress.type
Handling deprecation for hadoop.hdfs.configuration.version
Handling deprecation for hadoop.security.group.mapping.ldap.search.attr.member
Handling deprecation for yarn.nodemanager.log.retain-seconds
Handling deprecation for yarn.nodemanager.local-cache.max-files-per-directory
Handling deprecation for mapreduce.job.end-notification.retry.interval
Handling deprecation for hadoop.ssl.client.conf
Handling deprecation for yarn.sharedcache.root-dir
Handling deprecation for dfs.journalnode.https-address
Handling deprecation for mapreduce.reduce.shuffle.fetch.retry.timeout-ms
Handling deprecation for dfs.bytes-per-checksum
Handling deprecation for dfs.namenode.max.objects
Handling deprecation for mapreduce.tasktracker.instrumentation
Handling deprecation for dfs.datanode.max.transfer.threads
Handling deprecation for dfs.block.access.key.update.interval
Handling deprecation for mapreduce.jobtracker.jobhistory.task.numberprogresssplits
Handling deprecation for mapreduce.map.memory.mb
Handling deprecation for ha.failover-controller.new-active.rpc-timeout.ms
Handling deprecation for hadoop.ssl.hostname.verifier
Handling deprecation for dfs.client.read.shortcircuit
Handling deprecation for dfs.datanode.hdfs-blocks-metadata.enabled
Handling deprecation for mapreduce.tasktracker.healthchecker.interval
Handling deprecation for dfs.image.transfer.chunksize
Handling deprecation for mapreduce.tasktracker.taskmemorymanager.monitoringinterval
Handling deprecation for dfs.client.https.keystore.resource
Handling deprecation for yarn.resourcemanager.connect.retry-interval.ms
Handling deprecation for yarn.timeline-service.webapp.address
Handling deprecation for s3native.blocksize
Handling deprecation for yarn.scheduler.minimum-allocation-mb
Handling deprecation for yarn.sharedcache.cleaner.resource-sleep-ms
Handling deprecation for net.topology.impl
Handling deprecation for dfs.client.failover.sleep.base.millis
Handling deprecation for dfs.permissions.superusergroup
Handling deprecation for io.seqfile.compress.blocksize
Handling deprecation for hadoop.registry.zk.retry.times
Handling deprecation for fs.AbstractFileSystem.ftp.impl
Handling deprecation for dfs.namenode.checkpoint.edits.dir
Handling deprecation for mapreduce.job.running.reduce.limit
Handling deprecation for dfs.blockreport.initialDelay
Handling deprecation for dfs.namenode.heartbeat.recheck-interval
Handling deprecation for dfs.namenode.safemode.extension
Handling deprecation for yarn.scheduler.maximum-allocation-mb
Handling deprecation for mapreduce.job.reduce.shuffle.consumer.plugin.class
Handling deprecation for yarn.nodemanager.vmem-check-enabled
Handling deprecation for mapreduce.task.io.sort.factor
Handling deprecation for mapreduce.jobtracker.persist.jobstatus.dir
Handling deprecation for dfs.client.failover.sleep.max.millis
Handling deprecation for dfs.namenode.delegation.key.update-interval
Handling deprecation for hadoop.rpc.protection
Handling deprecation for fs.permissions.umask-mode
Handling deprecation for fs.s3.sleepTimeSeconds
Handling deprecation for ha.health-monitor.rpc-timeout.ms
Handling deprecation for hadoop.http.staticuser.user
Handling deprecation for fs.s3a.connection.maximum
Handling deprecation for yarn.nodemanager.linux-container-executor.nonsecure-mode.limit-users
Handling deprecation for fs.s3a.paging.maximum
Handling deprecation for fs.AbstractFileSystem.viewfs.impl
Handling deprecation for fs.ftp.host
Handling deprecation for yarn.nodemanager.linux-container-executor.nonsecure-mode.local-user
Handling deprecation for fs.s3a.impl
Handling deprecation for hadoop.http.authentication.kerberos.keytab
Handling deprecation for dfs.namenode.fs-limits.max-blocks-per-file
Handling deprecation for mapreduce.tasktracker.http.threads
Handling deprecation for mapreduce.tasktracker.dns.nameserver
Handling deprecation for yarn.resourcemanager.am-rm-tokens.master-key-rolling-interval-secs
Handling deprecation for dfs.client.block.write.replace-datanode-on-failure.enable
Handling deprecation for io.compression.codec.bzip2.library
Handling deprecation for mapreduce.map.skip.maxrecords
Handling deprecation for dfs.client.use.legacy.blockreader.local
Handling deprecation for dfs.namenode.checkpoint.dir
Handling deprecation for dfs.namenode.top.windows.minutes
Handling deprecation for mapreduce.job.maxtaskfailures.per.tracker
Handling deprecation for net.topology.node.switch.mapping.impl
Handling deprecation for mapreduce.shuffle.max.connections
Handling deprecation for mapreduce.jobhistory.loadedjobs.cache.size
Handling deprecation for dfs.storage.policy.enabled
Handling deprecation for yarn.client.application-client-protocol.poll-interval-ms
Handling deprecation for yarn.nodemanager.localizer.address
Handling deprecation for dfs.namenode.list.cache.pools.num.responses
Handling deprecation for nfs.server.port
Handling deprecation for mapreduce.client.output.filter
Handling deprecation for yarn.timeline-service.client.best-effort
Handling deprecation for ha.zookeeper.parent-znode
Handling deprecation for mapreduce.jobtracker.persist.jobstatus.hours
Handling deprecation for yarn.sharedcache.admin.thread-count
Handling deprecation for yarn.nodemanager.resource.cpu-vcores
Handling deprecation for dfs.datanode.block-pinning.enabled
Handling deprecation for mapreduce.jobhistory.http.policy
Handling deprecation for yarn.resourcemanager.webapp.delegation-token-auth-filter.enabled
Handling deprecation for mapreduce.job.speculative.retry-after-no-speculate
Handling deprecation for fs.s3a.attempts.maximum
Handling deprecation for s3native.stream-buffer-size
Handling deprecation for io.seqfile.local.dir
Handling deprecation for yarn.log-aggregation.retain-check-interval-seconds
Handling deprecation for fs.s3n.multipart.copy.block.size
Handling deprecation for dfs.encrypt.data.transfer.cipher.key.bitlength
Handling deprecation for dfs.datanode.sync.behind.writes
Handling deprecation for yarn.resourcemanager.zk-acl
Handling deprecation for hadoop.ssl.keystores.factory.class
Handling deprecation for mapreduce.job.split.metainfo.maxsize
Handling deprecation for fs.s3.maxRetries
Handling deprecation for hadoop.security.random.device.file.path
Handling deprecation for yarn.client.nodemanager-connect.max-wait-ms
Handling deprecation for dfs.namenode.stale.datanode.interval
Handling deprecation for mapreduce.task.io.sort.mb
Handling deprecation for yarn.resourcemanager.zk-state-store.parent-path
Handling deprecation for yarn.app.mapreduce.client-am.ipc.max-retries
Handling deprecation for fs.client.resolve.remote.symlinks
Handling deprecation for yarn.nodemanager.linux-container-executor.cgroups.strict-resource-usage
Handling deprecation for hadoop.ssl.enabled.protocols
Handling deprecation for mapreduce.reduce.cpu.vcores
Handling deprecation for yarn.client.failover-retries
Handling deprecation for mapreduce.jobhistory.address
Handling deprecation for hadoop.ssl.enabled
Handling deprecation for dfs.replication.max
Handling deprecation for dfs.namenode.name.dir
Handling deprecation for dfs.datanode.https.address
Handling deprecation for ipc.client.kill.max
Handling deprecation for mapreduce.job.committer.setup.cleanup.needed
Handling deprecation for dfs.client.domain.socket.data.traffic
Handling deprecation for yarn.nodemanager.localizer.cache.target-size-mb
Handling deprecation for yarn.resourcemanager.admin.client.thread-count
Handling deprecation for dfs.block.access.token.enable
Handling deprecation for mapreduce.job.speculative.retry-after-speculate
Handling deprecation for dfs.datanode.address
Handling deprecation for mapreduce.jobtracker.restart.recover
Handling deprecation for ipc.client.connect.max.retries
Handling deprecation for yarn.timeline-service.store-class
Handling deprecation for dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
Handling deprecation for hadoop.tmp.dir
Handling deprecation for dfs.datanode.handler.count
Handling deprecation for yarn.resourcemanager.ha.automatic-failover.embedded
Handling deprecation for yarn.timeline-service.ttl-ms
Handling deprecation for mapreduce.task.profile.map.params
Handling deprecation for yarn.resourcemanager.nodemanagers.heartbeat-interval-ms
Handling deprecation for mapreduce.map.speculative
Handling deprecation for yarn.timeline-service.recovery.enabled
Handling deprecation for mapreduce.job.map.class
Handling deprecation for dfs.namenode.resource.checked.volumes.minimum
Handling deprecation for yarn.nodemanager.recovery.dir
Handling deprecation for mapreduce.job.counters.max
Handling deprecation for yarn.resourcemanager.keytab
Handling deprecation for dfs.namenode.max.extra.edits.segments.retained
Handling deprecation for dfs.webhdfs.user.provider.user.pattern
Handling deprecation for dfs.client.mmap.enabled
Handling deprecation for mapreduce.map.log.level
Handling deprecation for dfs.client.file-block-storage-locations.timeout.millis
Handling deprecation for yarn.client.max-cached-nodemanagers-proxies
Handling deprecation for yarn.app.mapreduce.am.scheduler.heartbeat.interval-ms
Handling deprecation for hadoop.fuse.timer.period
Handling deprecation for fs.trash.checkpoint.interval
Handling deprecation for yarn.sharedcache.app-checker.class
Handling deprecation for dfs.journalnode.http-address
Handling deprecation for yarn.app.mapreduce.am.staging-dir
Handling deprecation for mapreduce.tasktracker.local.dir.minspacestart
Handling deprecation for yarn.nm.liveness-monitor.expiry-interval-ms
Handling deprecation for ha.health-monitor.check-interval.ms
Handling deprecation for mapreduce.reduce.shuffle.merge.percent
Handling deprecation for dfs.namenode.retrycache.heap.percent
Handling deprecation for yarn.nodemanager.docker-container-executor.exec-name
Handling deprecation for ipc.client.connect.timeout
Handling deprecation for yarn.resourcemanager.fs.state-store.retry-interval-ms
Handling deprecation for mapreduce.output.fileoutputformat.compress
Handling deprecation for yarn.nodemanager.local-dirs
Handling deprecation for yarn.nodemanager.recovery.enabled
Handling deprecation for io.native.lib.available
Handling deprecation for yarn.sharedcache.store.in-memory.staleness-period-mins
Handling deprecation for yarn.resourcemanager.am.max-attempts
Handling deprecation for s3.replication
Handling deprecation for mapreduce.input.fileinputformat.inputdir
Handling deprecation for fs.AbstractFileSystem.har.impl
Handling deprecation for dfs.image.compress
Handling deprecation for mapreduce.job.running.map.limit
Handling deprecation for mapreduce.reduce.input.buffer.percent
Handling deprecation for yarn.nodemanager.webapp.address
Handling deprecation for dfs.datanode.available-space-volume-choosing-policy.balanced-space-preference-fraction
Handling deprecation for dfs.namenode.edit.log.autoroll.multiplier.threshold
Handling deprecation for hadoop.security.group.mapping.ldap.ssl
Handling deprecation for dfs.namenode.checkpoint.check.period
Handling deprecation for fs.defaultFS
Handling deprecation for fs.s3a.multipart.size
Handling deprecation for dfs.client.slow.io.warning.threshold.ms
Handling deprecation for yarn.app.mapreduce.am.job.committer.commit-window
Handling deprecation for hadoop.security.group.mapping.ldap.search.attr.group.name
Handling deprecation for yarn.nodemanager.disk-health-checker.max-disk-utilization-per-disk-percentage
Handling deprecation for yarn.nodemanager.container-monitor.procfs-tree.smaps-based-rss.enabled
Handling deprecation for mapreduce.job.submithostname
Handling deprecation for mapreduce.map.sort.spill.percent
Handling deprecation for hadoop.security.crypto.codec.classes.aes.ctr.nopadding
Handling deprecation for dfs.namenode.http-address
Handling deprecation for hadoop.security.groups.negative-cache.secs
Handling deprecation for hadoop.ssl.server.conf
Handling deprecation for mapreduce.ifile.readahead
Handling deprecation for s3native.replication
Handling deprecation for yarn.client.nodemanager-client-async.thread-pool-max-size
Handling deprecation for mapreduce.jobtracker.staging.root.dir
Handling deprecation for mapreduce.jobhistory.admin.address
Handling deprecation for dfs.namenode.startup.delay.block.deletion.sec
Handling deprecation for yarn.nodemanager.health-checker.interval-ms
Handling deprecation for dfs.namenode.checkpoint.max-retries
Handling deprecation for s3.stream-buffer-size
Handling deprecation for ftp.client-write-packet-size
Handling deprecation for dfs.datanode.fsdatasetcache.max.threads.per.volume
Handling deprecation for mapreduce.output.fileoutputformat.compress.codec
Handling deprecation for yarn.timeline-service.keytab
Handling deprecation for yarn.sharedcache.store.in-memory.initial-delay-mins
Handling deprecation for mapreduce.jobhistory.webapp.address
Handling deprecation for mapreduce.task.userlog.limit.kb
Handling deprecation for mapreduce.reduce.shuffle.fetch.retry.enabled
Handling deprecation for yarn.app.mapreduce.task.container.log.backups
Handling deprecation for dfs.heartbeat.interval
Handling deprecation for ha.zookeeper.session-timeout.ms
Handling deprecation for fs.s3a.connection.ssl.enabled
Handling deprecation for yarn.sharedcache.webapp.address
Handling deprecation for hadoop.http.authentication.signature.secret.file
Handling deprecation for hadoop.fuse.connection.timeout
Handling deprecation for mapreduce.input.fileinputformat.numinputfiles
Handling deprecation for yarn.nodemanager.log-aggregation.compression-type
Handling deprecation for ipc.server.max.connections
Handling deprecation for yarn.resourcemanager.work-preserving-recovery.scheduling-wait-ms
Handling deprecation for yarn.nodemanager.log-dirs
Handling deprecation for yarn.app.mapreduce.am.resource.mb
Handling deprecation for hadoop.security.groups.cache.secs
Handling deprecation for mapreduce.job.speculative.minimum-allowed-tasks
Handling deprecation for yarn.nodemanager.container-monitor.interval-ms
Handling deprecation for dfs.datanode.cache.revocation.timeout.ms
Handling deprecation for mapreduce.jobhistory.recovery.store.class
Handling deprecation for mapreduce.task.combine.progress.records
Handling deprecation for s3.client-write-packet-size
Handling deprecation for mapreduce.jobtracker.instrumentation
Handling deprecation for dfs.replication
Handling deprecation for mapreduce.shuffle.transfer.buffer.size
Handling deprecation for hadoop.security.group.mapping.ldap.directory.search.timeout
Handling deprecation for dfs.datanode.available-space-volume-choosing-policy.balanced-space-threshold
Handling deprecation for hadoop.work.around.non.threadsafe.getpwuid
Handling deprecation for yarn.app.mapreduce.client-am.ipc.max-retries-on-timeouts
Handling deprecation for yarn.nodemanager.address
Handling deprecation for mapreduce.tasktracker.taskcontroller
Handling deprecation for mapreduce.tasktracker.indexcache.mb
Handling deprecation for yarn.scheduler.maximum-allocation-vcores
Handling deprecation for mapreduce.job.reduces
Handling deprecation for yarn.nodemanager.sleep-delay-before-sigkill.ms
Handling deprecation for yarn.timeline-service.address
Handling deprecation for yarn.resourcemanager.configuration.provider-class
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.expiry
Handling deprecation for yarn.sharedcache.enabled
Handling deprecation for tfile.io.chunk.size
Handling deprecation for mapreduce.job.acl-modify-job
Handling deprecation for hadoop.registry.zk.session.timeout.ms
Handling deprecation for fs.automatic.close
Handling deprecation for ha.health-monitor.sleep-after-disconnect.ms
Handling deprecation for mapreduce.tasktracker.reduce.tasks.maximum
Handling deprecation for mapreduce.input.fileinputformat.list-status.num-threads
Handling deprecation for dfs.datanode.directoryscan.threads
Handling deprecation for dfs.datanode.directoryscan.interval
Handling deprecation for dfs.namenode.acls.enabled
Handling deprecation for dfs.client.short.circuit.replica.stale.threshold.ms
Handling deprecation for hadoop.http.authentication.token.validity
Handling deprecation for fs.s3.block.size
Handling deprecation for ha.failover-controller.graceful-fence.rpc-timeout.ms
Handling deprecation for mapreduce.tasktracker.local.dir.minspacekill
Handling deprecation for dfs.namenode.resource.du.reserved
Handling deprecation for mapreduce.jobhistory.cleaner.interval-ms
Handling deprecation for dfs.namenode.datanode.registration.ip-hostname-check
Handling deprecation for mapreduce.jobhistory.intermediate-done-dir
Handling deprecation for mapreduce.jobtracker.http.address
Handling deprecation for dfs.namenode.backup.http-address
Handling deprecation for dfs.namenode.edits.noeditlogchannelflush
Handling deprecation for mapreduce.reduce.shuffle.input.buffer.percent
Handling deprecation for mapreduce.map.maxattempts
Handling deprecation for yarn.http.policy
Handling deprecation for dfs.namenode.audit.loggers
Handling deprecation for hadoop.security.groups.cache.warn.after.ms
Handling deprecation for io.serializations
Handling deprecation for mapreduce.tasktracker.outofband.heartbeat
Handling deprecation for mapreduce.reduce.shuffle.read.timeout
Handling deprecation for hadoop.security.crypto.buffer.size
Handling deprecation for mapreduce.reduce.skip.proc.count.autoincr
Handling deprecation for mapreduce.ifile.readahead.bytes
Handling deprecation for dfs.http.policy
Handling deprecation for hadoop.registry.secure
Handling deprecation for dfs.namenode.safemode.min.datanodes
Handling deprecation for dfs.client.file-block-storage-locations.num-threads
Handling deprecation for mapreduce.cluster.local.dir
Handling deprecation for mapreduce.tasktracker.report.address
Handling deprecation for dfs.namenode.secondary.https-address
Handling deprecation for hadoop.kerberos.kinit.command
Handling deprecation for yarn.timeline-service.http-authentication.type
Handling deprecation for dfs.block.access.token.lifetime
Handling deprecation for dfs.webhdfs.enabled
Handling deprecation for dfs.namenode.delegation.token.max-lifetime
Handling deprecation for dfs.namenode.avoid.write.stale.datanode
Handling deprecation for dfs.datanode.drop.cache.behind.writes
Handling deprecation for yarn.log-aggregation.retain-seconds
Handling deprecation for mapreduce.job.complete.cancel.delegation.tokens
Handling deprecation for mapreduce.local.clientfactory.class.name
Handling deprecation for mapreduce.shuffle.connection-keep-alive.timeout
Handling deprecation for dfs.namenode.num.extra.edits.retained
Handling deprecation for yarn.scheduler.minimum-allocation-vcores
Handling deprecation for ipc.client.connect.max.retries.on.timeouts
Handling deprecation for yarn.timeline-service.client.retry-interval-ms
Handling deprecation for yarn.timeline-service.client.max-retries
Handling deprecation for fs.s3n.block.size
Handling deprecation for mapreduce.job.map.output.collector.class
Handling deprecation for ha.health-monitor.connect-retry-interval.ms
Handling deprecation for mapreduce.shuffle.max.threads
Handling deprecation for nfs.exports.allowed.hosts
Handling deprecation for dfs.client.mmap.cache.size
Handling deprecation for mapreduce.tasktracker.map.tasks.maximum
Handling deprecation for io.file.buffer.size
Handling deprecation for dfs.client.datanode-restart.timeout
Handling deprecation for io.mapfile.bloom.size
Handling deprecation for hadoop.security.kms.client.authentication.retry-count
Handling deprecation for dfs.namenode.checkpoint.txns
Handling deprecation for ipc.client.connect.retry.interval
Handling deprecation for dfs.client-write-packet-size
Handling deprecation for mapreduce.reduce.shuffle.connect.timeout
Handling deprecation for yarn.resourcemanager.fs.state-store.uri
Handling deprecation for fs.swift.impl
Handling deprecation for hadoop.registry.zk.connection.timeout.ms
Handling deprecation for mapred.queue.default.acl-administer-jobs
Handling deprecation for mapreduce.job.submithostaddress
Handling deprecation for dfs.cachereport.intervalMsec
Handling deprecation for yarn.app.mapreduce.shuffle.log.backups
Handling deprecation for yarn.app.mapreduce.am.container.log.limit.kb
Handling deprecation for yarn.nodemanager.resourcemanager.minimum.version
Handling deprecation for ftp.blocksize
Handling deprecation for yarn.resourcemanager.address
Handling deprecation for file.stream-buffer-size
Handling deprecation for yarn.resourcemanager.scheduler.monitor.enable
Handling deprecation for mapreduce.job.ubertask.maxreduces
Handling deprecation for nfs.allow.insecure.ports
Handling deprecation for yarn.sharedcache.nm.uploader.thread-count
Handling deprecation for ipc.client.idlethreshold
Handling deprecation for ftp.stream-buffer-size
Handling deprecation for yarn.sharedcache.client-server.address
Handling deprecation for dfs.client.failover.connection.retries.on.timeouts
Handling deprecation for dfs.namenode.replication.work.multiplier.per.iteration
Handling deprecation for hadoop.http.authentication.simple.anonymous.allowed
Handling deprecation for hadoop.security.authorization
Handling deprecation for yarn.client.nodemanager-connect.retry-interval-ms
Handling deprecation for yarn.am.liveness-monitor.expiry-interval-ms
Handling deprecation for fs.har.impl.disable.cache
Handling deprecation for yarn.nodemanager.linux-container-executor.resources-handler.class
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.read-cache-size
Handling deprecation for hadoop.security.authentication
Handling deprecation for dfs.image.compression.codec
Handling deprecation for mapreduce.task.files.preserve.failedtasks
Handling deprecation for dfs.client.read.shortcircuit.streams.cache.size
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.path
Handling deprecation for mapreduce.job.reduce.slowstart.completedmaps
Handling deprecation for mapreduce.jobhistory.minicluster.fixed.ports
Handling deprecation for file.replication
Handling deprecation for yarn.resourcemanager.ha.automatic-failover.enabled
Handling deprecation for mapreduce.job.userlog.retain.hours
Handling deprecation for mapreduce.jobhistory.joblist.cache.size
Handling deprecation for dfs.namenode.accesstime.precision
Handling deprecation for yarn.resourcemanager.work-preserving-recovery.enabled
Handling deprecation for dfs.namenode.fs-limits.max-xattrs-per-inode
Handling deprecation for io.mapfile.bloom.error.rate
Handling deprecation for yarn.resourcemanager.store.class
Handling deprecation for dfs.image.transfer.timeout
Handling deprecation for yarn.timeline-service.leveldb-state-store.path
Handling deprecation for nfs.wtmax
Handling deprecation for mapreduce.job.combine.class
Handling deprecation for dfs.namenode.support.allow.format
Handling deprecation for fs.s3a.multipart.purge
Handling deprecation for dfs.secondary.namenode.kerberos.internal.spnego.principal
Handling deprecation for fs.s3a.connection.establish.timeout
Handling deprecation for dfs.stream-buffer-size
Handling deprecation for dfs.namenode.invalidate.work.pct.per.iteration
Handling deprecation for yarn.nodemanager.container-executor.class
Handling deprecation for fs.s3a.multipart.purge.age
Handling deprecation for yarn.resourcemanager.scheduler.client.thread-count
Handling deprecation for dfs.namenode.top.enabled
Handling deprecation for yarn.app.mapreduce.shuffle.log.separate
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.low-watermark
Handling deprecation for fs.s3a.fast.buffer.size
Handling deprecation for hadoop.user.group.static.mapping.overrides
Handling deprecation for tfile.fs.input.buffer.size
Handling deprecation for dfs.client.cached.conn.retry
Handling deprecation for hadoop.http.authentication.type
Handling deprecation for dfs.namenode.list.encryption.zones.num.responses
Handling deprecation for mapreduce.map.cpu.vcores
Handling deprecation for dfs.namenode.path.based.cache.refresh.interval.ms
Handling deprecation for dfs.namenode.decommission.interval
Handling deprecation for dfs.namenode.fs-limits.max-directory-items
Handling deprecation for yarn.resourcemanager.zk-retry-interval-ms
Handling deprecation for ftp.bytes-per-checksum
Handling deprecation for dfs.ha.log-roll.period
Handling deprecation for dfs.user.home.dir.prefix
Handling deprecation for ipc.client.fallback-to-simple-auth-allowed
Handling deprecation for yarn.nodemanager.pmem-check-enabled
Handling deprecation for yarn.nodemanager.remote-app-log-dir
Handling deprecation for dfs.namenode.inotify.max.events.per.rpc
Handling deprecation for mapreduce.task.profile.maps
Handling deprecation for mapreduce.shuffle.ssl.file.buffer.size
Handling deprecation for mapreduce.tasktracker.healthchecker.script.timeout
Handling deprecation for yarn.timeline-service.webapp.https.address
Handling deprecation for yarn.nodemanager.resource.percentage-physical-cpu-limit
Handling deprecation for yarn.app.mapreduce.am.command-opts
Handling deprecation for dfs.namenode.fs-limits.max-xattr-size
Handling deprecation for dfs.datanode.http.address
Handling deprecation for dfs.namenode.blocks.per.postponedblocks.rescan
Handling deprecation for yarn.sharedcache.nm.uploader.replication.factor
Handling deprecation for hadoop.registry.zk.root
Handling deprecation for hadoop.jetty.logs.serve.aliases
Handling deprecation for yarn.client.failover-proxy-provider
Handling deprecation for mapreduce.jobhistory.admin.acl
Handling deprecation for yarn.app.mapreduce.am.hard-kill-timeout-ms
Handling deprecation for yarn.nodemanager.remote-app-log-dir-suffix
Handling deprecation for mapreduce.jobhistory.principal
Handling deprecation for yarn.resourcemanager.webapp.address
Handling deprecation for mapreduce.jobhistory.recovery.enable
Handling deprecation for yarn.sharedcache.store.in-memory.check-period-mins
Handling deprecation for nfs.mountd.port
Handling deprecation for mapreduce.reduce.merge.inmem.threshold
Handling deprecation for fs.df.interval
Handling deprecation for yarn.timeline-service.enabled
Handling deprecation for mapreduce.jobtracker.jobhistory.lru.cache.size
Handling deprecation for mapreduce.task.profile
Handling deprecation for mapreduce.job.output.key.class
Handling deprecation for yarn.nodemanager.hostname
Handling deprecation for dfs.namenode.num.checkpoints.retained
Handling deprecation for mapreduce.job.queuename
Handling deprecation for mapreduce.jobhistory.max-age-ms
Handling deprecation for mapreduce.job.token.tracking.ids.enabled
Handling deprecation for yarn.nodemanager.localizer.client.thread-count
Handling deprecation for yarn.sharedcache.uploader.server.thread-count
Handling deprecation for dfs.client.mmap.retry.timeout.ms
Handling deprecation for mapreduce.jobhistory.move.thread-count
Handling deprecation for dfs.permissions.enabled
Handling deprecation for dfs.blockreport.split.threshold
Handling deprecation for fs.AbstractFileSystem.hdfs.impl
Handling deprecation for dfs.datanode.balance.bandwidthPerSec
Handling deprecation for dfs.block.scanner.volume.bytes.per.second
Handling deprecation for hadoop.http.filter.initializers
Handling deprecation for yarn.timeline-service.http-authentication.simple.anonymous.allowed
Handling deprecation for dfs.default.chunk.view.size
Handling deprecation for yarn.sharedcache.client-server.thread-count
Handling deprecation for yarn.resourcemanager.resource-tracker.address
Handling deprecation for mapreduce.job.working.dir
Handling deprecation for mapreduce.jobhistory.datestring.cache.size
Handling deprecation for mapreduce.task.profile.params
Handling deprecation for dfs.namenode.decommission.blocks.per.interval
Handling deprecation for dfs.namenode.handler.count
Handling deprecation for dfs.image.transfer.bandwidthPerSec
Handling deprecation for rpc.metrics.quantile.enable
Handling deprecation for mapreduce.jobtracker.expire.trackers.interval
Handling deprecation for mapreduce.task.timeout
Handling deprecation for yarn.app.mapreduce.client.max-retries
Handling deprecation for yarn.nodemanager.resource.memory-mb
Handling deprecation for yarn.nodemanager.disk-health-checker.min-healthy-disks
Handling deprecation for dfs.datanode.failed.volumes.tolerated
Handling deprecation for yarn.timeline-service.handler-thread-count
Handling deprecation for ipc.server.listen.queue.size
Handling deprecation for fs.s3a.threads.max
Handling deprecation for yarn.resourcemanager.connect.max-wait.ms
Handling deprecation for mapreduce.fileoutputcommitter.algorithm.version
Handling deprecation for mapreduce.framework.name
Handling deprecation for mapreduce.map.skip.proc.count.autoincr
Handling deprecation for mapreduce.job.max.split.locations
Handling deprecation for yarn.resourcemanager.scheduler.class
Handling deprecation for yarn.resourcemanager.system-metrics-publisher.enabled
Handling deprecation for dfs.blocksize
Handling deprecation for yarn.sharedcache.nested-level
Handling deprecation for mapreduce.shuffle.connection-keep-alive.enable
Handling deprecation for fs.s3a.threads.keepalivetime
Handling deprecation for fs.s3a.connection.timeout
Handling deprecation for file.client-write-packet-size
Handling deprecation for ha.failover-controller.cli-check.rpc-timeout.ms
Handling deprecation for ha.zookeeper.acl
Handling deprecation for dfs.namenode.write.stale.datanode.ratio
Handling deprecation for dfs.encrypt.data.transfer
Handling deprecation for dfs.datanode.shared.file.descriptor.paths
Handling deprecation for mapreduce.input.lineinputformat.linespermap
Handling deprecation for yarn.resourcemanager.delayed.delegation-token.removal-interval-ms
Handling deprecation for yarn.nodemanager.localizer.fetch.thread-count
Handling deprecation for dfs.client.failover.max.attempts
Handling deprecation for yarn.resourcemanager.scheduler.address
Handling deprecation for dfs.client.read.shortcircuit.streams.cache.expiry.ms
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.start-time-write-cache-size
Handling deprecation for yarn.nodemanager.health-checker.script.timeout-ms
Handling deprecation for yarn.resourcemanager.fs.state-store.num-retries
Handling deprecation for hadoop.ssl.require.client.cert
Handling deprecation for hadoop.security.uid.cache.secs
Handling deprecation for mapreduce.jobhistory.keytab
Handling deprecation for dfs.client.read.shortcircuit.skip.checksum
Handling deprecation for yarn.resourcemanager.ha.automatic-failover.zk-base-path
Handling deprecation for mapreduce.shuffle.ssl.enabled
Handling deprecation for mapreduce.reduce.log.level
Handling deprecation for hadoop.registry.rm.enabled
Handling deprecation for mapreduce.tasktracker.dns.interface
Handling deprecation for yarn.resourcemanager.system-metrics-publisher.dispatcher.pool-size
Handling deprecation for mapreduce.job.speculative.speculative-cap-running-tasks
Handling deprecation for dfs.datanode.block.id.layout.upgrade.threads
Handling deprecation for dfs.datanode.use.datanode.hostname
Handling deprecation for dfs.client.context
Handling deprecation for yarn.resourcemanager.ha.enabled
Handling deprecation for mapred.reducer.new-api
Handling deprecation for dfs.namenode.delegation.token.renew-interval
Handling deprecation for dfs.blockreport.intervalMsec
Handling deprecation for fs.s3a.multipart.threshold
Handling deprecation for mapreduce.reduce.shuffle.memory.limit.percent
Handling deprecation for dfs.https.server.keystore.resource
Handling deprecation for io.map.index.skip
Handling deprecation for mapreduce.job.hdfs-servers
Handling deprecation for mapreduce.jobtracker.taskscheduler
Handling deprecation for dfs.namenode.kerberos.internal.spnego.principal
Handling deprecation for yarn.resourcemanager.state-store.max-completed-applications
Handling deprecation for mapreduce.map.output.compress
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.num.refill.threads
Handling deprecation for fs.s3n.multipart.uploads.block.size
Handling deprecation for mapreduce.task.merge.progress.records
Handling deprecation for dfs.datanode.dns.interface
Handling deprecation for map.sort.class
Handling deprecation for yarn.nodemanager.aux-services.mapreduce_shuffle.class
Handling deprecation for tfile.fs.output.buffer.size
Handling deprecation for fs.du.interval
Handling deprecation for dfs.client.failover.connection.retries
Handling deprecation for dfs.namenode.top.window.num.buckets
Handling deprecation for mapreduce.job.dir
Handling deprecation for fs.s3a.buffer.dir
Handling deprecation for mapreduce.reduce.shuffle.retry-delay.max.ms
Handling deprecation for yarn.sharedcache.uploader.server.address
Handling deprecation for mapreduce.client.progressmonitor.pollinterval
Handling deprecation for yarn.app.mapreduce.shuffle.log.limit.kb
Handling deprecation for dfs.datanode.max.locked.memory
Handling deprecation for dfs.namenode.retrycache.expirytime.millis
Handling deprecation for dfs.datanode.scan.period.hours
Handling deprecation for dfs.client.block.write.replace-datanode-on-failure.best-effort
Handling deprecation for mapreduce.jobhistory.move.interval-ms
Handling deprecation for dfs.ha.fencing.ssh.connect-timeout
Handling deprecation for yarn.nodemanager.log-aggregation.roll-monitoring-interval-seconds
Handling deprecation for dfs.namenode.fs-limits.max-component-length
Handling deprecation for hadoop.registry.zk.quorum
Handling deprecation for dfs.namenode.enable.retrycache
Handling deprecation for dfs.datanode.du.reserved
Handling deprecation for yarn.timeline-service.state-store-class
Handling deprecation for dfs.datanode.ipc.address
Handling deprecation for hadoop.registry.system.acls
Handling deprecation for dfs.client.block.write.replace-datanode-on-failure.policy
Handling deprecation for dfs.namenode.path.based.cache.retry.interval.ms
Handling deprecation for hadoop.security.crypto.cipher.suite
Handling deprecation for dfs.ha.tail-edits.period
Handling deprecation for mapreduce.task.profile.reduce.params
Handling deprecation for hadoop.registry.jaas.context
Handling deprecation for yarn.resourcemanager.hostname
Handling deprecation for mapreduce.reduce.memory.mb
Handling deprecation for hadoop.security.group.mapping.ldap.search.filter.group
Handling deprecation for hadoop.http.authentication.kerberos.principal
Handling deprecation for hadoop.security.group.mapping.ldap.search.filter.user
Handling deprecation for yarn.nodemanager.disk-health-checker.min-free-space-per-disk-mb
Handling deprecation for dfs.namenode.edits.dir
Handling deprecation for yarn.client.failover-retries-on-socket-timeouts
Handling deprecation for dfs.namenode.decommission.max.concurrent.tracked.nodes
Handling deprecation for mapreduce.client.completion.pollinterval
Handling deprecation for dfs.namenode.name.dir.restore
Handling deprecation for dfs.namenode.secondary.http-address
Handling deprecation for mapreduce.jobhistory.recovery.store.leveldb.path
Handling deprecation for yarn.sharedcache.store.class
Handling deprecation for s3.bytes-per-checksum
Handling deprecation for yarn.nodemanager.windows-container.cpu-limit.enabled
Handling deprecation for yarn.resourcemanager.webapp.https.address
Handling deprecation for yarn.nodemanager.vmem-pmem-ratio
Handling deprecation for dfs.namenode.checkpoint.period
Handling deprecation for dfs.ha.automatic-failover.enabled
Submitting tokens for job: job_local1653575348_0003
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.fs.FileContext.getAbstractFileSystem(FileContext.java:331)
Handling deprecation for all properties in config...
Handling deprecation for mapreduce.jobtracker.address
Handling deprecation for yarn.resourcemanager.scheduler.monitor.policies
Handling deprecation for dfs.namenode.resource.check.interval
Handling deprecation for mapreduce.jobhistory.client.thread-count
Handling deprecation for yarn.app.mapreduce.am.containerlauncher.threadpool-initial-size
Handling deprecation for mapred.child.java.opts
Handling deprecation for mapreduce.jobtracker.retiredjobs.cache.size
Handling deprecation for dfs.client.https.need-auth
Handling deprecation for yarn.admin.acl
Handling deprecation for yarn.app.mapreduce.am.job.committer.cancel-timeout
Handling deprecation for mapreduce.job.emit-timeline-data
Handling deprecation for fs.ftp.host.port
Handling deprecation for dfs.namenode.avoid.read.stale.datanode
Handling deprecation for dfs.journalnode.rpc-address
Handling deprecation for mapreduce.job.end-notification.retry.attempts
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.ttl-interval-ms
Handling deprecation for yarn.resourcemanager.leveldb-state-store.path
Handling deprecation for mapred.mapper.new-api
Handling deprecation for yarn.ipc.rpc.class
Handling deprecation for ipc.client.connection.maxidletime
Handling deprecation for yarn.nodemanager.process-kill-wait.ms
Handling deprecation for mapreduce.cluster.acls.enabled
Handling deprecation for mapreduce.jobtracker.handler.count
Handling deprecation for io.map.index.interval
Handling deprecation for dfs.namenode.https-address
Handling deprecation for mapreduce.task.profile.reduces
Handling deprecation for fs.s3n.multipart.uploads.enabled
Handling deprecation for io.seqfile.sorter.recordlimit
Handling deprecation for mapreduce.job.ubertask.maxmaps
Handling deprecation for mapreduce.tasktracker.tasks.sleeptimebeforesigkill
Handling deprecation for hadoop.util.hash.type
Handling deprecation for dfs.namenode.replication.min
Handling deprecation for yarn.nodemanager.container-manager.thread-count
Handling deprecation for mapreduce.jobtracker.jobhistory.block.size
Handling deprecation for dfs.namenode.fs-limits.min-block-size
Handling deprecation for mapreduce.app-submission.cross-platform
Handling deprecation for fs.AbstractFileSystem.file.impl
Handling deprecation for net.topology.script.number.args
Handling deprecation for yarn.resourcemanager.container-tokens.master-key-rolling-interval-secs
Handling deprecation for mapreduce.map.output.compress.codec
Handling deprecation for mapreduce.job.reducer.preempt.delay.sec
Handling deprecation for s3native.bytes-per-checksum
Handling deprecation for dfs.namenode.path.based.cache.block.map.allocation.percent
Handling deprecation for yarn.nodemanager.windows-container.memory-limit.enabled
Handling deprecation for mapreduce.input.fileinputformat.split.minsize
Handling deprecation for hadoop.security.group.mapping
Handling deprecation for mapreduce.jobtracker.system.dir
Handling deprecation for mapreduce.job.end-notification.max.attempts
Handling deprecation for mapreduce.reduce.markreset.buffer.percent
Handling deprecation for dfs.datanode.cache.revocation.polling.ms
Handling deprecation for mapreduce.reduce.speculative
Handling deprecation for yarn.nodemanager.localizer.cache.cleanup.interval-ms
Handling deprecation for dfs.namenode.lazypersist.file.scrub.interval.sec
Handling deprecation for fs.s3a.threads.core
Handling deprecation for mapreduce.jobhistory.recovery.store.fs.uri
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.start-time-read-cache-size
Handling deprecation for hadoop.registry.zk.retry.interval.ms
Handling deprecation for yarn.nodemanager.keytab
Handling deprecation for dfs.namenode.replication.interval
Handling deprecation for yarn.resourcemanager.admin.address
Handling deprecation for mapreduce.job.maps
Handling deprecation for nfs.dump.dir
Handling deprecation for mapreduce.job.user.name
Handling deprecation for mapreduce.jobtracker.maxtasks.perjob
Handling deprecation for mapreduce.job.ubertask.enable
Handling deprecation for mapreduce.job.reduce.class
Handling deprecation for yarn.nodemanager.delete.debug-delay-sec
Handling deprecation for yarn.timeline-service.ttl-enable
Handling deprecation for yarn.resourcemanager.fs.state-store.retry-policy-spec
Handling deprecation for mapreduce.reduce.skip.maxgroups
Handling deprecation for dfs.client.use.datanode.hostname
Handling deprecation for fs.trash.interval
Handling deprecation for mapreduce.job.name
Handling deprecation for mapreduce.am.max-attempts
Handling deprecation for mapreduce.jobtracker.heartbeats.in.second
Handling deprecation for yarn.resourcemanager.zk-num-retries
Handling deprecation for s3.blocksize
Handling deprecation for dfs.datanode.data.dir
Handling deprecation for mapreduce.jobtracker.persist.jobstatus.active
Handling deprecation for mapreduce.reduce.shuffle.parallelcopies
Handling deprecation for fs.s3.buffer.dir
Handling deprecation for mapreduce.jobhistory.done-dir
Handling deprecation for hadoop.security.instrumentation.requires.admin
Handling deprecation for hadoop.registry.zk.retry.ceiling.ms
Handling deprecation for nfs.rtmax
Handling deprecation for dfs.datanode.data.dir.perm
Handling deprecation for yarn.resourcemanager.container.liveness-monitor.interval-ms
Handling deprecation for yarn.nodemanager.env-whitelist
Handling deprecation for dfs.namenode.backup.address
Handling deprecation for dfs.namenode.xattrs.enabled
Handling deprecation for dfs.datanode.readahead.bytes
Handling deprecation for mapreduce.jobhistory.cleaner.enable
Handling deprecation for dfs.client.block.write.retries
Handling deprecation for mapreduce.tasktracker.http.address
Handling deprecation for yarn.nodemanager.linux-container-executor.cgroups.hierarchy
Handling deprecation for ha.failover-controller.graceful-fence.connection.retries
Handling deprecation for yarn.resourcemanager.recovery.enabled
Handling deprecation for yarn.app.mapreduce.am.container.log.backups
Handling deprecation for dfs.namenode.safemode.threshold-pct
Handling deprecation for yarn.nodemanager.disk-health-checker.interval-ms
Handling deprecation for hadoop.security.java.secure.random.algorithm
Handling deprecation for dfs.namenode.list.cache.directives.num.responses
Handling deprecation for dfs.datanode.dns.nameserver
Handling deprecation for mapreduce.cluster.temp.dir
Handling deprecation for fs.s3a.max.total.tasks
Handling deprecation for mapreduce.reduce.maxattempts
Handling deprecation for mapreduce.client.submit.file.replication
Handling deprecation for mapreduce.shuffle.port
Handling deprecation for yarn.resourcemanager.resource-tracker.client.thread-count
Handling deprecation for dfs.namenode.replication.considerLoad
Handling deprecation for dfs.namenode.edits.journal-plugin.qjournal
Handling deprecation for dfs.client.write.exclude.nodes.cache.expiry.interval.millis
Handling deprecation for yarn.nodemanager.delete.thread-count
Handling deprecation for dfs.client.mmap.cache.timeout.ms
Handling deprecation for yarn.nodemanager.admin-env
Handling deprecation for io.skip.checksum.errors
Handling deprecation for yarn.timeline-service.hostname
Handling deprecation for yarn.resourcemanager.proxy-user-privileges.enabled
Handling deprecation for mapreduce.job.speculative.speculative-cap-total-tasks
Handling deprecation for yarn.acl.enable
Handling deprecation for fs.s3a.fast.upload
Handling deprecation for file.blocksize
Handling deprecation for mapreduce.job.speculative.slowtaskthreshold
Handling deprecation for ftp.replication
Handling deprecation for yarn.sharedcache.cleaner.initial-delay-mins
Handling deprecation for s3native.client-write-packet-size
Handling deprecation for hadoop.rpc.socket.factory.class.default
Handling deprecation for file.bytes-per-checksum
Handling deprecation for dfs.datanode.slow.io.warning.threshold.ms
Handling deprecation for io.seqfile.lazydecompress
Handling deprecation for mapreduce.task.skip.start.attempts
Handling deprecation for dfs.namenode.reject-unresolved-dn-topology-mapping
Handling deprecation for hadoop.common.configuration.version
Handling deprecation for yarn.resourcemanager.client.thread-count
Handling deprecation for dfs.datanode.drop.cache.behind.reads
Handling deprecation for yarn.sharedcache.admin.address
Handling deprecation for mapreduce.job.output.value.class
Handling deprecation for mapreduce.output.fileoutputformat.outputdir
Handling deprecation for mapreduce.jobtracker.taskcache.levels
Handling deprecation for yarn.nodemanager.linux-container-executor.nonsecure-mode.user-pattern
Handling deprecation for yarn.resourcemanager.zk-timeout-ms
Handling deprecation for yarn.resourcemanager.max-completed-applications
Handling deprecation for mapreduce.job.jvm.numtasks
Handling deprecation for yarn.sharedcache.cleaner.period-mins
Handling deprecation for mapreduce.jobtracker.tasktracker.maxblacklists
Handling deprecation for dfs.namenode.top.num.users
Handling deprecation for yarn.nodemanager.linux-container-executor.cgroups.mount
Handling deprecation for yarn.sharedcache.checksum.algo.impl
Handling deprecation for mapreduce.job.end-notification.max.retry.interval
Handling deprecation for mapreduce.job.acl-view-job
Handling deprecation for mapreduce.job.classloader
Handling deprecation for yarn.log-aggregation-enable
Handling deprecation for mapreduce.reduce.shuffle.fetch.retry.interval-ms
Handling deprecation for yarn.resourcemanager.nodemanager.minimum.version
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.size
Handling deprecation for yarn.app.mapreduce.am.job.task.listener.thread-count
Handling deprecation for yarn.app.mapreduce.am.resource.cpu-vcores
Handling deprecation for dfs.namenode.edit.log.autoroll.check.interval.ms
Handling deprecation for mapreduce.output.fileoutputformat.compress.type
Handling deprecation for hadoop.hdfs.configuration.version
Handling deprecation for hadoop.security.group.mapping.ldap.search.attr.member
Handling deprecation for yarn.nodemanager.log.retain-seconds
Handling deprecation for yarn.nodemanager.local-cache.max-files-per-directory
Handling deprecation for mapreduce.job.end-notification.retry.interval
Handling deprecation for hadoop.ssl.client.conf
Handling deprecation for yarn.sharedcache.root-dir
Handling deprecation for dfs.journalnode.https-address
Handling deprecation for mapreduce.reduce.shuffle.fetch.retry.timeout-ms
Handling deprecation for dfs.bytes-per-checksum
Handling deprecation for dfs.namenode.max.objects
Handling deprecation for mapreduce.tasktracker.instrumentation
Handling deprecation for dfs.datanode.max.transfer.threads
Handling deprecation for dfs.block.access.key.update.interval
Handling deprecation for mapreduce.jobtracker.jobhistory.task.numberprogresssplits
Handling deprecation for mapreduce.map.memory.mb
Handling deprecation for ha.failover-controller.new-active.rpc-timeout.ms
Handling deprecation for hadoop.ssl.hostname.verifier
Handling deprecation for dfs.client.read.shortcircuit
Handling deprecation for dfs.datanode.hdfs-blocks-metadata.enabled
Handling deprecation for mapreduce.tasktracker.healthchecker.interval
Handling deprecation for dfs.image.transfer.chunksize
Handling deprecation for mapreduce.tasktracker.taskmemorymanager.monitoringinterval
Handling deprecation for dfs.client.https.keystore.resource
Handling deprecation for yarn.resourcemanager.connect.retry-interval.ms
Handling deprecation for yarn.timeline-service.webapp.address
Handling deprecation for s3native.blocksize
Handling deprecation for yarn.scheduler.minimum-allocation-mb
Handling deprecation for yarn.sharedcache.cleaner.resource-sleep-ms
Handling deprecation for net.topology.impl
Handling deprecation for dfs.client.failover.sleep.base.millis
Handling deprecation for dfs.permissions.superusergroup
Handling deprecation for io.seqfile.compress.blocksize
Handling deprecation for hadoop.registry.zk.retry.times
Handling deprecation for fs.AbstractFileSystem.ftp.impl
Handling deprecation for dfs.namenode.checkpoint.edits.dir
Handling deprecation for mapreduce.job.running.reduce.limit
Handling deprecation for dfs.blockreport.initialDelay
Handling deprecation for dfs.namenode.heartbeat.recheck-interval
Handling deprecation for dfs.namenode.safemode.extension
Handling deprecation for yarn.scheduler.maximum-allocation-mb
Handling deprecation for mapreduce.job.reduce.shuffle.consumer.plugin.class
Handling deprecation for yarn.nodemanager.vmem-check-enabled
Handling deprecation for mapreduce.task.io.sort.factor
Handling deprecation for mapreduce.jobtracker.persist.jobstatus.dir
Handling deprecation for dfs.client.failover.sleep.max.millis
Handling deprecation for dfs.namenode.delegation.key.update-interval
Handling deprecation for hadoop.rpc.protection
Handling deprecation for fs.permissions.umask-mode
Handling deprecation for fs.s3.sleepTimeSeconds
Handling deprecation for ha.health-monitor.rpc-timeout.ms
Handling deprecation for hadoop.http.staticuser.user
Handling deprecation for fs.s3a.connection.maximum
Handling deprecation for yarn.nodemanager.linux-container-executor.nonsecure-mode.limit-users
Handling deprecation for fs.s3a.paging.maximum
Handling deprecation for fs.AbstractFileSystem.viewfs.impl
Handling deprecation for fs.ftp.host
Handling deprecation for yarn.nodemanager.linux-container-executor.nonsecure-mode.local-user
Handling deprecation for fs.s3a.impl
Handling deprecation for hadoop.http.authentication.kerberos.keytab
Handling deprecation for dfs.namenode.fs-limits.max-blocks-per-file
Handling deprecation for mapreduce.tasktracker.http.threads
Handling deprecation for mapreduce.tasktracker.dns.nameserver
Handling deprecation for yarn.resourcemanager.am-rm-tokens.master-key-rolling-interval-secs
Handling deprecation for dfs.client.block.write.replace-datanode-on-failure.enable
Handling deprecation for io.compression.codec.bzip2.library
Handling deprecation for mapreduce.map.skip.maxrecords
Handling deprecation for dfs.client.use.legacy.blockreader.local
Handling deprecation for dfs.namenode.checkpoint.dir
Handling deprecation for dfs.namenode.top.windows.minutes
Handling deprecation for mapreduce.job.maxtaskfailures.per.tracker
Handling deprecation for net.topology.node.switch.mapping.impl
Handling deprecation for mapreduce.shuffle.max.connections
Handling deprecation for mapreduce.jobhistory.loadedjobs.cache.size
Handling deprecation for dfs.storage.policy.enabled
Handling deprecation for yarn.client.application-client-protocol.poll-interval-ms
Handling deprecation for yarn.nodemanager.localizer.address
Handling deprecation for dfs.namenode.list.cache.pools.num.responses
Handling deprecation for nfs.server.port
Handling deprecation for mapreduce.client.output.filter
Handling deprecation for yarn.timeline-service.client.best-effort
Handling deprecation for ha.zookeeper.parent-znode
Handling deprecation for mapreduce.jobtracker.persist.jobstatus.hours
Handling deprecation for yarn.sharedcache.admin.thread-count
Handling deprecation for yarn.nodemanager.resource.cpu-vcores
Handling deprecation for dfs.datanode.block-pinning.enabled
Handling deprecation for mapreduce.jobhistory.http.policy
Handling deprecation for yarn.resourcemanager.webapp.delegation-token-auth-filter.enabled
Handling deprecation for mapreduce.job.speculative.retry-after-no-speculate
Handling deprecation for fs.s3a.attempts.maximum
Handling deprecation for s3native.stream-buffer-size
Handling deprecation for io.seqfile.local.dir
Handling deprecation for yarn.log-aggregation.retain-check-interval-seconds
Handling deprecation for fs.s3n.multipart.copy.block.size
Handling deprecation for dfs.encrypt.data.transfer.cipher.key.bitlength
Handling deprecation for dfs.datanode.sync.behind.writes
Handling deprecation for yarn.resourcemanager.zk-acl
Handling deprecation for hadoop.ssl.keystores.factory.class
Handling deprecation for mapreduce.job.split.metainfo.maxsize
Handling deprecation for fs.s3.maxRetries
Handling deprecation for hadoop.security.random.device.file.path
Handling deprecation for yarn.client.nodemanager-connect.max-wait-ms
Handling deprecation for dfs.namenode.stale.datanode.interval
Handling deprecation for mapreduce.task.io.sort.mb
Handling deprecation for yarn.resourcemanager.zk-state-store.parent-path
Handling deprecation for yarn.app.mapreduce.client-am.ipc.max-retries
Handling deprecation for fs.client.resolve.remote.symlinks
Handling deprecation for yarn.nodemanager.linux-container-executor.cgroups.strict-resource-usage
Handling deprecation for hadoop.ssl.enabled.protocols
Handling deprecation for mapreduce.reduce.cpu.vcores
Handling deprecation for yarn.client.failover-retries
Handling deprecation for mapreduce.jobhistory.address
Handling deprecation for hadoop.ssl.enabled
Handling deprecation for dfs.replication.max
Handling deprecation for dfs.namenode.name.dir
Handling deprecation for dfs.datanode.https.address
Handling deprecation for ipc.client.kill.max
Handling deprecation for mapreduce.job.committer.setup.cleanup.needed
Handling deprecation for dfs.client.domain.socket.data.traffic
Handling deprecation for yarn.nodemanager.localizer.cache.target-size-mb
Handling deprecation for yarn.resourcemanager.admin.client.thread-count
Handling deprecation for dfs.block.access.token.enable
Handling deprecation for mapreduce.job.speculative.retry-after-speculate
Handling deprecation for dfs.datanode.address
Handling deprecation for mapreduce.jobtracker.restart.recover
Handling deprecation for ipc.client.connect.max.retries
Handling deprecation for yarn.timeline-service.store-class
Handling deprecation for dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
Handling deprecation for hadoop.tmp.dir
Handling deprecation for dfs.datanode.handler.count
Handling deprecation for yarn.resourcemanager.ha.automatic-failover.embedded
Handling deprecation for yarn.timeline-service.ttl-ms
Handling deprecation for mapreduce.task.profile.map.params
Handling deprecation for yarn.resourcemanager.nodemanagers.heartbeat-interval-ms
Handling deprecation for mapreduce.map.speculative
Handling deprecation for yarn.timeline-service.recovery.enabled
Handling deprecation for mapreduce.job.map.class
Handling deprecation for dfs.namenode.resource.checked.volumes.minimum
Handling deprecation for yarn.nodemanager.recovery.dir
Handling deprecation for mapreduce.job.counters.max
Handling deprecation for yarn.resourcemanager.keytab
Handling deprecation for dfs.namenode.max.extra.edits.segments.retained
Handling deprecation for dfs.webhdfs.user.provider.user.pattern
Handling deprecation for dfs.client.mmap.enabled
Handling deprecation for mapreduce.map.log.level
Handling deprecation for dfs.client.file-block-storage-locations.timeout.millis
Handling deprecation for yarn.client.max-cached-nodemanagers-proxies
Handling deprecation for yarn.app.mapreduce.am.scheduler.heartbeat.interval-ms
Handling deprecation for hadoop.fuse.timer.period
Handling deprecation for fs.trash.checkpoint.interval
Handling deprecation for yarn.sharedcache.app-checker.class
Handling deprecation for dfs.journalnode.http-address
Handling deprecation for yarn.app.mapreduce.am.staging-dir
Handling deprecation for mapreduce.tasktracker.local.dir.minspacestart
Handling deprecation for yarn.nm.liveness-monitor.expiry-interval-ms
Handling deprecation for ha.health-monitor.check-interval.ms
Handling deprecation for mapreduce.reduce.shuffle.merge.percent
Handling deprecation for dfs.namenode.retrycache.heap.percent
Handling deprecation for yarn.nodemanager.docker-container-executor.exec-name
Handling deprecation for ipc.client.connect.timeout
Handling deprecation for yarn.resourcemanager.fs.state-store.retry-interval-ms
Handling deprecation for mapreduce.output.fileoutputformat.compress
Handling deprecation for yarn.nodemanager.local-dirs
Handling deprecation for yarn.nodemanager.recovery.enabled
Handling deprecation for io.native.lib.available
Handling deprecation for yarn.sharedcache.store.in-memory.staleness-period-mins
Handling deprecation for yarn.resourcemanager.am.max-attempts
Handling deprecation for s3.replication
Handling deprecation for mapreduce.input.fileinputformat.inputdir
Handling deprecation for fs.AbstractFileSystem.har.impl
Handling deprecation for dfs.image.compress
Handling deprecation for mapreduce.job.running.map.limit
Handling deprecation for mapreduce.reduce.input.buffer.percent
Handling deprecation for yarn.nodemanager.webapp.address
Handling deprecation for dfs.datanode.available-space-volume-choosing-policy.balanced-space-preference-fraction
Handling deprecation for dfs.namenode.edit.log.autoroll.multiplier.threshold
Handling deprecation for hadoop.security.group.mapping.ldap.ssl
Handling deprecation for dfs.namenode.checkpoint.check.period
Handling deprecation for fs.defaultFS
Handling deprecation for fs.s3a.multipart.size
Handling deprecation for dfs.client.slow.io.warning.threshold.ms
Handling deprecation for yarn.app.mapreduce.am.job.committer.commit-window
Handling deprecation for hadoop.security.group.mapping.ldap.search.attr.group.name
Handling deprecation for yarn.nodemanager.disk-health-checker.max-disk-utilization-per-disk-percentage
Handling deprecation for yarn.nodemanager.container-monitor.procfs-tree.smaps-based-rss.enabled
Handling deprecation for mapreduce.job.submithostname
Handling deprecation for mapreduce.map.sort.spill.percent
Handling deprecation for hadoop.security.crypto.codec.classes.aes.ctr.nopadding
Handling deprecation for dfs.namenode.http-address
Handling deprecation for hadoop.security.groups.negative-cache.secs
Handling deprecation for hadoop.ssl.server.conf
Handling deprecation for mapreduce.ifile.readahead
Handling deprecation for s3native.replication
Handling deprecation for yarn.client.nodemanager-client-async.thread-pool-max-size
Handling deprecation for mapreduce.jobtracker.staging.root.dir
Handling deprecation for mapreduce.jobhistory.admin.address
Handling deprecation for dfs.namenode.startup.delay.block.deletion.sec
Handling deprecation for yarn.nodemanager.health-checker.interval-ms
Handling deprecation for dfs.namenode.checkpoint.max-retries
Handling deprecation for s3.stream-buffer-size
Handling deprecation for ftp.client-write-packet-size
Handling deprecation for dfs.datanode.fsdatasetcache.max.threads.per.volume
Handling deprecation for mapreduce.output.fileoutputformat.compress.codec
Handling deprecation for yarn.timeline-service.keytab
Handling deprecation for yarn.sharedcache.store.in-memory.initial-delay-mins
Handling deprecation for mapreduce.jobhistory.webapp.address
Handling deprecation for mapreduce.task.userlog.limit.kb
Handling deprecation for mapreduce.reduce.shuffle.fetch.retry.enabled
Handling deprecation for yarn.app.mapreduce.task.container.log.backups
Handling deprecation for dfs.heartbeat.interval
Handling deprecation for ha.zookeeper.session-timeout.ms
Handling deprecation for fs.s3a.connection.ssl.enabled
Handling deprecation for yarn.sharedcache.webapp.address
Handling deprecation for hadoop.http.authentication.signature.secret.file
Handling deprecation for hadoop.fuse.connection.timeout
Handling deprecation for mapreduce.input.fileinputformat.numinputfiles
Handling deprecation for yarn.nodemanager.log-aggregation.compression-type
Handling deprecation for ipc.server.max.connections
Handling deprecation for yarn.resourcemanager.work-preserving-recovery.scheduling-wait-ms
Handling deprecation for yarn.nodemanager.log-dirs
Handling deprecation for yarn.app.mapreduce.am.resource.mb
Handling deprecation for hadoop.security.groups.cache.secs
Handling deprecation for mapreduce.job.speculative.minimum-allowed-tasks
Handling deprecation for yarn.nodemanager.container-monitor.interval-ms
Handling deprecation for dfs.datanode.cache.revocation.timeout.ms
Handling deprecation for mapreduce.jobhistory.recovery.store.class
Handling deprecation for mapreduce.task.combine.progress.records
Handling deprecation for s3.client-write-packet-size
Handling deprecation for mapreduce.jobtracker.instrumentation
Handling deprecation for dfs.replication
Handling deprecation for mapreduce.shuffle.transfer.buffer.size
Handling deprecation for hadoop.security.group.mapping.ldap.directory.search.timeout
Handling deprecation for dfs.datanode.available-space-volume-choosing-policy.balanced-space-threshold
Handling deprecation for hadoop.work.around.non.threadsafe.getpwuid
Handling deprecation for yarn.app.mapreduce.client-am.ipc.max-retries-on-timeouts
Handling deprecation for yarn.nodemanager.address
Handling deprecation for mapreduce.tasktracker.taskcontroller
Handling deprecation for mapreduce.tasktracker.indexcache.mb
Handling deprecation for yarn.scheduler.maximum-allocation-vcores
Handling deprecation for mapreduce.job.reduces
Handling deprecation for yarn.nodemanager.sleep-delay-before-sigkill.ms
Handling deprecation for yarn.timeline-service.address
Handling deprecation for yarn.resourcemanager.configuration.provider-class
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.expiry
Handling deprecation for yarn.sharedcache.enabled
Handling deprecation for tfile.io.chunk.size
Handling deprecation for mapreduce.job.acl-modify-job
Handling deprecation for hadoop.registry.zk.session.timeout.ms
Handling deprecation for fs.automatic.close
Handling deprecation for ha.health-monitor.sleep-after-disconnect.ms
Handling deprecation for mapreduce.tasktracker.reduce.tasks.maximum
Handling deprecation for mapreduce.input.fileinputformat.list-status.num-threads
Handling deprecation for dfs.datanode.directoryscan.threads
Handling deprecation for dfs.datanode.directoryscan.interval
Handling deprecation for dfs.namenode.acls.enabled
Handling deprecation for dfs.client.short.circuit.replica.stale.threshold.ms
Handling deprecation for hadoop.http.authentication.token.validity
Handling deprecation for fs.s3.block.size
Handling deprecation for ha.failover-controller.graceful-fence.rpc-timeout.ms
Handling deprecation for mapreduce.tasktracker.local.dir.minspacekill
Handling deprecation for dfs.namenode.resource.du.reserved
Handling deprecation for mapreduce.jobhistory.cleaner.interval-ms
Handling deprecation for dfs.namenode.datanode.registration.ip-hostname-check
Handling deprecation for mapreduce.jobhistory.intermediate-done-dir
Handling deprecation for mapreduce.jobtracker.http.address
Handling deprecation for dfs.namenode.backup.http-address
Handling deprecation for dfs.namenode.edits.noeditlogchannelflush
Handling deprecation for mapreduce.reduce.shuffle.input.buffer.percent
Handling deprecation for mapreduce.map.maxattempts
Handling deprecation for yarn.http.policy
Handling deprecation for dfs.namenode.audit.loggers
Handling deprecation for hadoop.security.groups.cache.warn.after.ms
Handling deprecation for io.serializations
Handling deprecation for mapreduce.tasktracker.outofband.heartbeat
Handling deprecation for mapreduce.reduce.shuffle.read.timeout
Handling deprecation for hadoop.security.crypto.buffer.size
Handling deprecation for mapreduce.reduce.skip.proc.count.autoincr
Handling deprecation for mapreduce.ifile.readahead.bytes
Handling deprecation for dfs.http.policy
Handling deprecation for hadoop.registry.secure
Handling deprecation for dfs.namenode.safemode.min.datanodes
Handling deprecation for dfs.client.file-block-storage-locations.num-threads
Handling deprecation for mapreduce.cluster.local.dir
Handling deprecation for mapreduce.tasktracker.report.address
Handling deprecation for dfs.namenode.secondary.https-address
Handling deprecation for hadoop.kerberos.kinit.command
Handling deprecation for yarn.timeline-service.http-authentication.type
Handling deprecation for dfs.block.access.token.lifetime
Handling deprecation for dfs.webhdfs.enabled
Handling deprecation for dfs.namenode.delegation.token.max-lifetime
Handling deprecation for dfs.namenode.avoid.write.stale.datanode
Handling deprecation for dfs.datanode.drop.cache.behind.writes
Handling deprecation for yarn.log-aggregation.retain-seconds
Handling deprecation for mapreduce.job.complete.cancel.delegation.tokens
Handling deprecation for mapreduce.local.clientfactory.class.name
Handling deprecation for mapreduce.shuffle.connection-keep-alive.timeout
Handling deprecation for dfs.namenode.num.extra.edits.retained
Handling deprecation for yarn.scheduler.minimum-allocation-vcores
Handling deprecation for ipc.client.connect.max.retries.on.timeouts
Handling deprecation for yarn.timeline-service.client.retry-interval-ms
Handling deprecation for yarn.timeline-service.client.max-retries
Handling deprecation for fs.s3n.block.size
Handling deprecation for mapreduce.job.map.output.collector.class
Handling deprecation for ha.health-monitor.connect-retry-interval.ms
Handling deprecation for mapreduce.shuffle.max.threads
Handling deprecation for nfs.exports.allowed.hosts
Handling deprecation for dfs.client.mmap.cache.size
Handling deprecation for mapreduce.tasktracker.map.tasks.maximum
Handling deprecation for io.file.buffer.size
Handling deprecation for dfs.client.datanode-restart.timeout
Handling deprecation for io.mapfile.bloom.size
Handling deprecation for hadoop.security.kms.client.authentication.retry-count
Handling deprecation for dfs.namenode.checkpoint.txns
Handling deprecation for ipc.client.connect.retry.interval
Handling deprecation for dfs.client-write-packet-size
Handling deprecation for mapreduce.reduce.shuffle.connect.timeout
Handling deprecation for yarn.resourcemanager.fs.state-store.uri
Handling deprecation for fs.swift.impl
Handling deprecation for hadoop.registry.zk.connection.timeout.ms
Handling deprecation for mapred.queue.default.acl-administer-jobs
Handling deprecation for mapreduce.job.submithostaddress
Handling deprecation for dfs.cachereport.intervalMsec
Handling deprecation for yarn.app.mapreduce.shuffle.log.backups
Handling deprecation for yarn.app.mapreduce.am.container.log.limit.kb
Handling deprecation for yarn.nodemanager.resourcemanager.minimum.version
Handling deprecation for ftp.blocksize
Handling deprecation for yarn.resourcemanager.address
Handling deprecation for file.stream-buffer-size
Handling deprecation for yarn.resourcemanager.scheduler.monitor.enable
Handling deprecation for mapreduce.job.ubertask.maxreduces
Handling deprecation for nfs.allow.insecure.ports
Handling deprecation for yarn.sharedcache.nm.uploader.thread-count
Handling deprecation for ipc.client.idlethreshold
Handling deprecation for ftp.stream-buffer-size
Handling deprecation for yarn.sharedcache.client-server.address
Handling deprecation for dfs.client.failover.connection.retries.on.timeouts
Handling deprecation for dfs.namenode.replication.work.multiplier.per.iteration
Handling deprecation for hadoop.http.authentication.simple.anonymous.allowed
Handling deprecation for hadoop.security.authorization
Handling deprecation for yarn.client.nodemanager-connect.retry-interval-ms
Handling deprecation for yarn.am.liveness-monitor.expiry-interval-ms
Handling deprecation for fs.har.impl.disable.cache
Handling deprecation for yarn.nodemanager.linux-container-executor.resources-handler.class
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.read-cache-size
Handling deprecation for hadoop.security.authentication
Handling deprecation for dfs.image.compression.codec
Handling deprecation for mapreduce.task.files.preserve.failedtasks
Handling deprecation for dfs.client.read.shortcircuit.streams.cache.size
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.path
Handling deprecation for mapreduce.job.reduce.slowstart.completedmaps
Handling deprecation for mapreduce.jobhistory.minicluster.fixed.ports
Handling deprecation for file.replication
Handling deprecation for yarn.resourcemanager.ha.automatic-failover.enabled
Handling deprecation for mapreduce.job.userlog.retain.hours
Handling deprecation for mapreduce.jobhistory.joblist.cache.size
Handling deprecation for dfs.namenode.accesstime.precision
Handling deprecation for yarn.resourcemanager.work-preserving-recovery.enabled
Handling deprecation for dfs.namenode.fs-limits.max-xattrs-per-inode
Handling deprecation for io.mapfile.bloom.error.rate
Handling deprecation for yarn.resourcemanager.store.class
Handling deprecation for dfs.image.transfer.timeout
Handling deprecation for yarn.timeline-service.leveldb-state-store.path
Handling deprecation for nfs.wtmax
Handling deprecation for mapreduce.job.combine.class
Handling deprecation for dfs.namenode.support.allow.format
Handling deprecation for fs.s3a.multipart.purge
Handling deprecation for dfs.secondary.namenode.kerberos.internal.spnego.principal
Handling deprecation for fs.s3a.connection.establish.timeout
Handling deprecation for dfs.stream-buffer-size
Handling deprecation for dfs.namenode.invalidate.work.pct.per.iteration
Handling deprecation for yarn.nodemanager.container-executor.class
Handling deprecation for fs.s3a.multipart.purge.age
Handling deprecation for yarn.resourcemanager.scheduler.client.thread-count
Handling deprecation for dfs.namenode.top.enabled
Handling deprecation for yarn.app.mapreduce.shuffle.log.separate
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.low-watermark
Handling deprecation for fs.s3a.fast.buffer.size
Handling deprecation for hadoop.user.group.static.mapping.overrides
Handling deprecation for tfile.fs.input.buffer.size
Handling deprecation for dfs.client.cached.conn.retry
Handling deprecation for hadoop.http.authentication.type
Handling deprecation for dfs.namenode.list.encryption.zones.num.responses
Handling deprecation for mapreduce.map.cpu.vcores
Handling deprecation for dfs.namenode.path.based.cache.refresh.interval.ms
Handling deprecation for dfs.namenode.decommission.interval
Handling deprecation for dfs.namenode.fs-limits.max-directory-items
Handling deprecation for yarn.resourcemanager.zk-retry-interval-ms
Handling deprecation for ftp.bytes-per-checksum
Handling deprecation for dfs.ha.log-roll.period
Handling deprecation for dfs.user.home.dir.prefix
Handling deprecation for ipc.client.fallback-to-simple-auth-allowed
Handling deprecation for yarn.nodemanager.pmem-check-enabled
Handling deprecation for yarn.nodemanager.remote-app-log-dir
Handling deprecation for dfs.namenode.inotify.max.events.per.rpc
Handling deprecation for mapreduce.task.profile.maps
Handling deprecation for mapreduce.shuffle.ssl.file.buffer.size
Handling deprecation for mapreduce.tasktracker.healthchecker.script.timeout
Handling deprecation for yarn.timeline-service.webapp.https.address
Handling deprecation for yarn.nodemanager.resource.percentage-physical-cpu-limit
Handling deprecation for yarn.app.mapreduce.am.command-opts
Handling deprecation for dfs.namenode.fs-limits.max-xattr-size
Handling deprecation for dfs.datanode.http.address
Handling deprecation for dfs.namenode.blocks.per.postponedblocks.rescan
Handling deprecation for yarn.sharedcache.nm.uploader.replication.factor
Handling deprecation for hadoop.registry.zk.root
Handling deprecation for hadoop.jetty.logs.serve.aliases
Handling deprecation for yarn.client.failover-proxy-provider
Handling deprecation for mapreduce.jobhistory.admin.acl
Handling deprecation for yarn.app.mapreduce.am.hard-kill-timeout-ms
Handling deprecation for yarn.nodemanager.remote-app-log-dir-suffix
Handling deprecation for mapreduce.jobhistory.principal
Handling deprecation for yarn.resourcemanager.webapp.address
Handling deprecation for mapreduce.jobhistory.recovery.enable
Handling deprecation for yarn.sharedcache.store.in-memory.check-period-mins
Handling deprecation for nfs.mountd.port
Handling deprecation for mapreduce.reduce.merge.inmem.threshold
Handling deprecation for fs.df.interval
Handling deprecation for yarn.timeline-service.enabled
Handling deprecation for mapreduce.jobtracker.jobhistory.lru.cache.size
Handling deprecation for mapreduce.task.profile
Handling deprecation for mapreduce.job.output.key.class
Handling deprecation for yarn.nodemanager.hostname
Handling deprecation for dfs.namenode.num.checkpoints.retained
Handling deprecation for mapreduce.job.queuename
Handling deprecation for mapreduce.jobhistory.max-age-ms
Handling deprecation for mapreduce.job.token.tracking.ids.enabled
Handling deprecation for yarn.nodemanager.localizer.client.thread-count
Handling deprecation for yarn.sharedcache.uploader.server.thread-count
Handling deprecation for dfs.client.mmap.retry.timeout.ms
Handling deprecation for mapreduce.jobhistory.move.thread-count
Handling deprecation for dfs.permissions.enabled
Handling deprecation for dfs.blockreport.split.threshold
Handling deprecation for fs.AbstractFileSystem.hdfs.impl
Handling deprecation for dfs.datanode.balance.bandwidthPerSec
Handling deprecation for dfs.block.scanner.volume.bytes.per.second
Handling deprecation for hadoop.http.filter.initializers
Handling deprecation for yarn.timeline-service.http-authentication.simple.anonymous.allowed
Handling deprecation for dfs.default.chunk.view.size
Handling deprecation for yarn.sharedcache.client-server.thread-count
Handling deprecation for yarn.resourcemanager.resource-tracker.address
Handling deprecation for mapreduce.job.working.dir
Handling deprecation for mapreduce.jobhistory.datestring.cache.size
Handling deprecation for mapreduce.task.profile.params
Handling deprecation for dfs.namenode.decommission.blocks.per.interval
Handling deprecation for dfs.namenode.handler.count
Handling deprecation for dfs.image.transfer.bandwidthPerSec
Handling deprecation for rpc.metrics.quantile.enable
Handling deprecation for mapreduce.jobtracker.expire.trackers.interval
Handling deprecation for mapreduce.task.timeout
Handling deprecation for yarn.app.mapreduce.client.max-retries
Handling deprecation for yarn.nodemanager.resource.memory-mb
Handling deprecation for yarn.nodemanager.disk-health-checker.min-healthy-disks
Handling deprecation for dfs.datanode.failed.volumes.tolerated
Handling deprecation for yarn.timeline-service.handler-thread-count
Handling deprecation for ipc.server.listen.queue.size
Handling deprecation for fs.s3a.threads.max
Handling deprecation for yarn.resourcemanager.connect.max-wait.ms
Handling deprecation for mapreduce.fileoutputcommitter.algorithm.version
Handling deprecation for mapreduce.framework.name
Handling deprecation for mapreduce.map.skip.proc.count.autoincr
Handling deprecation for mapreduce.job.max.split.locations
Handling deprecation for yarn.resourcemanager.scheduler.class
Handling deprecation for yarn.resourcemanager.system-metrics-publisher.enabled
Handling deprecation for dfs.blocksize
Handling deprecation for yarn.sharedcache.nested-level
Handling deprecation for mapreduce.shuffle.connection-keep-alive.enable
Handling deprecation for fs.s3a.threads.keepalivetime
Handling deprecation for fs.s3a.connection.timeout
Handling deprecation for file.client-write-packet-size
Handling deprecation for ha.failover-controller.cli-check.rpc-timeout.ms
Handling deprecation for ha.zookeeper.acl
Handling deprecation for dfs.namenode.write.stale.datanode.ratio
Handling deprecation for dfs.encrypt.data.transfer
Handling deprecation for dfs.datanode.shared.file.descriptor.paths
Handling deprecation for mapreduce.input.lineinputformat.linespermap
Handling deprecation for yarn.resourcemanager.delayed.delegation-token.removal-interval-ms
Handling deprecation for yarn.nodemanager.localizer.fetch.thread-count
Handling deprecation for dfs.client.failover.max.attempts
Handling deprecation for yarn.resourcemanager.scheduler.address
Handling deprecation for dfs.client.read.shortcircuit.streams.cache.expiry.ms
Handling deprecation for yarn.timeline-service.leveldb-timeline-store.start-time-write-cache-size
Handling deprecation for yarn.nodemanager.health-checker.script.timeout-ms
Handling deprecation for yarn.resourcemanager.fs.state-store.num-retries
Handling deprecation for hadoop.ssl.require.client.cert
Handling deprecation for hadoop.security.uid.cache.secs
Handling deprecation for mapreduce.jobhistory.keytab
Handling deprecation for dfs.client.read.shortcircuit.skip.checksum
Handling deprecation for yarn.resourcemanager.ha.automatic-failover.zk-base-path
Handling deprecation for mapreduce.shuffle.ssl.enabled
Handling deprecation for mapreduce.reduce.log.level
Handling deprecation for hadoop.registry.rm.enabled
Handling deprecation for mapreduce.tasktracker.dns.interface
Handling deprecation for yarn.resourcemanager.system-metrics-publisher.dispatcher.pool-size
Handling deprecation for mapreduce.job.speculative.speculative-cap-running-tasks
Handling deprecation for dfs.datanode.block.id.layout.upgrade.threads
Handling deprecation for dfs.datanode.use.datanode.hostname
Handling deprecation for dfs.client.context
Handling deprecation for yarn.resourcemanager.ha.enabled
Handling deprecation for mapred.reducer.new-api
Handling deprecation for dfs.namenode.delegation.token.renew-interval
Handling deprecation for dfs.blockreport.intervalMsec
Handling deprecation for fs.s3a.multipart.threshold
Handling deprecation for mapreduce.reduce.shuffle.memory.limit.percent
Handling deprecation for dfs.https.server.keystore.resource
Handling deprecation for io.map.index.skip
Handling deprecation for mapreduce.job.hdfs-servers
Handling deprecation for mapreduce.jobtracker.taskscheduler
Handling deprecation for dfs.namenode.kerberos.internal.spnego.principal
Handling deprecation for yarn.resourcemanager.state-store.max-completed-applications
Handling deprecation for mapreduce.map.output.compress
Handling deprecation for hadoop.security.kms.client.encrypted.key.cache.num.refill.threads
Handling deprecation for fs.s3n.multipart.uploads.block.size
Handling deprecation for mapreduce.task.merge.progress.records
Handling deprecation for dfs.datanode.dns.interface
Handling deprecation for map.sort.class
Handling deprecation for yarn.nodemanager.aux-services.mapreduce_shuffle.class
Handling deprecation for tfile.fs.output.buffer.size
Handling deprecation for fs.du.interval
Handling deprecation for dfs.client.failover.connection.retries
Handling deprecation for dfs.namenode.top.window.num.buckets
Handling deprecation for mapreduce.job.dir
Handling deprecation for fs.s3a.buffer.dir
Handling deprecation for mapreduce.reduce.shuffle.retry-delay.max.ms
Handling deprecation for yarn.sharedcache.uploader.server.address
Handling deprecation for mapreduce.client.progressmonitor.pollinterval
Handling deprecation for yarn.app.mapreduce.shuffle.log.limit.kb
Handling deprecation for dfs.datanode.max.locked.memory
Handling deprecation for dfs.namenode.retrycache.expirytime.millis
Handling deprecation for dfs.datanode.scan.period.hours
Handling deprecation for dfs.client.block.write.replace-datanode-on-failure.best-effort
Handling deprecation for mapreduce.jobhistory.move.interval-ms
Handling deprecation for dfs.ha.fencing.ssh.connect-timeout
Handling deprecation for yarn.nodemanager.log-aggregation.roll-monitoring-interval-seconds
Handling deprecation for dfs.namenode.fs-limits.max-component-length
Handling deprecation for hadoop.registry.zk.quorum
Handling deprecation for dfs.namenode.enable.retrycache
Handling deprecation for dfs.datanode.du.reserved
Handling deprecation for yarn.timeline-service.state-store-class
Handling deprecation for dfs.datanode.ipc.address
Handling deprecation for hadoop.registry.system.acls
Handling deprecation for dfs.client.block.write.replace-datanode-on-failure.policy
Handling deprecation for dfs.namenode.path.based.cache.retry.interval.ms
Handling deprecation for hadoop.security.crypto.cipher.suite
Handling deprecation for dfs.ha.tail-edits.period
Handling deprecation for mapreduce.task.profile.reduce.params
Handling deprecation for hadoop.registry.jaas.context
Handling deprecation for yarn.resourcemanager.hostname
Handling deprecation for mapreduce.reduce.memory.mb
Handling deprecation for hadoop.security.group.mapping.ldap.search.filter.group
Handling deprecation for hadoop.http.authentication.kerberos.principal
Handling deprecation for hadoop.security.group.mapping.ldap.search.filter.user
Handling deprecation for yarn.nodemanager.disk-health-checker.min-free-space-per-disk-mb
Handling deprecation for dfs.namenode.edits.dir
Handling deprecation for yarn.client.failover-retries-on-socket-timeouts
Handling deprecation for dfs.namenode.decommission.max.concurrent.tracked.nodes
Handling deprecation for mapreduce.client.completion.pollinterval
Handling deprecation for dfs.namenode.name.dir.restore
Handling deprecation for dfs.namenode.secondary.http-address
Handling deprecation for mapreduce.jobhistory.recovery.store.leveldb.path
Handling deprecation for yarn.sharedcache.store.class
Handling deprecation for s3.bytes-per-checksum
Handling deprecation for yarn.nodemanager.windows-container.cpu-limit.enabled
Handling deprecation for yarn.resourcemanager.webapp.https.address
Handling deprecation for yarn.nodemanager.vmem-pmem-ratio
Handling deprecation for dfs.namenode.checkpoint.period
Handling deprecation for dfs.ha.automatic-failover.enabled
OutputCommitter set in config null
The url to track the job: http://localhost:8080/
File Output Committer Algorithm version is 1
Running job: job_local1653575348_0003
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
/user/michaeljones/wcOutputAnalysis/_temporary/0: masked=rwxr-xr-x
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones sending #58
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones got value #58
Call: mkdirs took 11ms
Starting mapper thread pool executor.
Max local threads: 1
Map tasks to process: 1
Waiting for map tasks
Starting task: attempt_local1653575348_0003_m_000000_0
currentIndex 0   0:0
mapreduce.cluster.local.dir for child : /tmp/hadoop-michaeljones/mapred/local/localRunner//michaeljones/jobcache/job_local1653575348_0003/attempt_local1653575348_0003_m_000000_0
using new api for output committer
File Output Committer Algorithm version is 1
ProcfsBasedProcessTree currently is supported only on Linux.
 Using ResourceCalculatorProcessTree : null
Processing split: hdfs://localhost:9000/user/michaeljones/wcInput:0+50
Trying map output collector class: org.apache.hadoop.mapred.MapTask$MapOutputBuffer
(EQUATOR) 0 kvi 26214396(104857584)
mapreduce.task.io.sort.mb: 100
soft limit at 83886080
bufstart = 0; bufvoid = 104857600
kvstart = 26214396; length = 6553600
Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones sending #59
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones got value #59
Call: getBlockLocations took 2ms
newInfo = LocatedBlocks{
  fileLength=50
  underConstruction=false
  blocks=[LocatedBlock{BP-1045030256-10.0.0.2-1433119149314:blk_1073741825_1002; getBlockSize()=50; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-b42c5705-9ba4-4b14-b00b-f9194bb036f0,DISK]]}]
  lastLocatedBlock=LocatedBlock{BP-1045030256-10.0.0.2-1433119149314:blk_1073741825_1002; getBlockSize()=50; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-b42c5705-9ba4-4b14-b00b-f9194bb036f0,DISK]]}
  isLastBlockComplete=true}
Connecting to datanode 127.0.0.1:50010

Starting flush of map output
Spilling map output
bufstart = 0; bufend = 82; bufvoid = 104857600
kvstart = 26214396(104857584); kvend = 26214368(104857472); length = 29/6553600
IntSumCombinerAnalyser-Bye[1]
IntSumCombinerAnalyser-Goodbye[1]
IntSumCombinerAnalyser-Hadoop[1,1]
IntSumCombinerAnalyser-Hello[1,1]
IntSumCombinerAnalyser-World[1,1]
Finished spill 0
Task:attempt_local1653575348_0003_m_000000_0 is done. And is in the process of committing
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones sending #60
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones got value #60
Call: getFileInfo took 2ms
map
Task 'attempt_local1653575348_0003_m_000000_0' done.
Finishing task: attempt_local1653575348_0003_m_000000_0
map task executor complete.
Starting reduce thread pool executor.
Max local threads: 1
Reduce tasks to process: 1
Waiting for reduce tasks
Starting task: attempt_local1653575348_0003_r_000000_0
currentIndex 0   0:0
mapreduce.cluster.local.dir for child : /tmp/hadoop-michaeljones/mapred/local/localRunner//michaeljones/jobcache/job_local1653575348_0003/attempt_local1653575348_0003_r_000000_0
using new api for output committer
File Output Committer Algorithm version is 1
ProcfsBasedProcessTree currently is supported only on Linux.
 Using ResourceCalculatorProcessTree : null
Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@2e359c7b
MergerManager: memoryLimit=668309888, maxSingleShuffleLimit=167077472, mergeThreshold=441084544, ioSortFactor=10, memToMemMergeOutputsThreshold=10
attempt_local1653575348_0003_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
Got 0 map completion events from 0
GetMapEventsThread about to sleep for 1000
LocalFetcher 3 going to fetch: attempt_local1653575348_0003_m_000000_0
attempt_local1653575348_0003_m_000000_0: Proceeding with shuffle since usedMemory (0) is lesser than memoryLimit (668309888).CommitMemory is (0)
localfetcher#3 about to shuffle output of map attempt_local1653575348_0003_m_000000_0 decomp: 63 len: 67 to MEMORY
Read 63 bytes from map-output for attempt_local1653575348_0003_m_000000_0
closeInMemoryFile -> map-output of size: 63, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->63
map attempt_local1653575348_0003_m_000000_0 done 1 / 1 copied.
EventFetcher is interrupted.. Returning
1 / 1 copied.
finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
Merging 1 sorted segments
Down to the last merge-pass, with 1 segments left of total size: 57 bytes
Merged 1 segments, 63 bytes to disk to satisfy reduce memory limit
Disk file: /tmp/hadoop-michaeljones/mapred/local/localRunner/michaeljones/jobcache/job_local1653575348_0003/attempt_local1653575348_0003_r_000000_0/output/map_0.out.merged Length is 67
Merging 1 files, 67 bytes from disk
Merging 0 segments, 0 bytes from memory into reduce
Merging 1 sorted segments
Down to the last merge-pass, with 1 segments left of total size: 57 bytes
1 / 1 copied.
/user/michaeljones/wcOutputAnalysis/_temporary/0/_temporary/attempt_local1653575348_0003_r_000000_0/part-r-00000: masked=rw-r--r--
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones sending #61
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones got value #61
Call: create took 4ms
computePacketChunkSize: src=/user/michaeljones/wcOutputAnalysis/_temporary/0/_temporary/attempt_local1653575348_0003_r_000000_0/part-r-00000, chunkSize=516, chunksPerPacket=126, packetSize=65016
IntSumReducerAnalyser-Bye[1]
IntSumReducerAnalyser-Goodbye[1]
IntSumReducerAnalyser-Hadoop[2]
IntSumReducerAnalyser-Hello[2]
IntSumReducerAnalyser-World[2]
DFSClient writeChunk allocating new packet seqno=0, src=/user/michaeljones/wcOutputAnalysis/_temporary/0/_temporary/attempt_local1653575348_0003_r_000000_0/part-r-00000, packetSize=65016, chunksPerPacket=126, bytesCurBlock=0
Queued packet 0
Queued packet 1
Waiting for ack for: 1
Allocating new block
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones sending #62
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones got value #62
Call: addBlock took 3ms
pipeline = DatanodeInfoWithStorage[127.0.0.1:50010,DS-b42c5705-9ba4-4b14-b00b-f9194bb036f0,DISK]
Connecting to datanode 127.0.0.1:50010
Send buf size 131072
SASL client skipping handshake in unsecured configuration for addr = /127.0.0.1, datanodeId = DatanodeInfoWithStorage[127.0.0.1:50010,DS-b42c5705-9ba4-4b14-b00b-f9194bb036f0,DISK]
DataStreamer block BP-1045030256-10.0.0.2-1433119149314:blk_1073742380_1557 sending packet packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 41
DFSClient seqno: 0 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
DataStreamer block BP-1045030256-10.0.0.2-1433119149314:blk_1073742380_1557 sending packet packet seqno: 1 offsetInBlock: 41 lastPacketInBlock: true lastByteOffsetInBlock: 41
DFSClient seqno: 1 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
Closing old block BP-1045030256-10.0.0.2-1433119149314:blk_1073742380_1557
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones sending #63
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones got value #63
Call: complete took 3ms
Task:attempt_local1653575348_0003_r_000000_0 is done. And is in the process of committing
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones sending #64
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones got value #64
Call: getFileInfo took 1ms
1 / 1 copied.
Task attempt_local1653575348_0003_r_000000_0 is allowed to commit now
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones sending #65
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones got value #65
Call: getFileInfo took 2ms
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones sending #66
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones got value #66
Call: getFileInfo took 2ms
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones sending #67
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones got value #67
Call: rename took 3ms
Saved output of task 'attempt_local1653575348_0003_r_000000_0' to hdfs://localhost:9000/user/michaeljones/wcOutputAnalysis/_temporary/0/task_local1653575348_0003_r_000000
reduce > reduce
Task 'attempt_local1653575348_0003_r_000000_0' done.
Finishing task: attempt_local1653575348_0003_r_000000_0
reduce task executor complete.
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones sending #68
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones got value #68
Call: getListing took 2ms
Merging data from FileStatus{path=hdfs://localhost:9000/user/michaeljones/wcOutputAnalysis/_temporary/0/task_local1653575348_0003_r_000000; isDirectory=true; modification_time=1434253174319; access_time=0; owner=michaeljones; group=supergroup; permission=rwxr-xr-x; isSymlink=false} to hdfs://localhost:9000/user/michaeljones/wcOutputAnalysis
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones sending #69
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones got value #69
Call: getFileInfo took 1ms
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones sending #70
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones got value #70
Call: getListing took 2ms
Merging data from FileStatus{path=hdfs://localhost:9000/user/michaeljones/wcOutputAnalysis/_temporary/0/task_local1653575348_0003_r_000000/part-r-00000; isDirectory=false; length=41; replication=1; blocksize=134217728; modification_time=1434253174339; access_time=1434253174319; owner=michaeljones; group=supergroup; permission=rw-r--r--; isSymlink=false} to hdfs://localhost:9000/user/michaeljones/wcOutputAnalysis/part-r-00000
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones sending #71
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones got value #71
Call: getFileInfo took 2ms
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones sending #72
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones got value #72
Call: rename took 3ms
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones sending #73
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones got value #73
Call: delete took 3ms
/user/michaeljones/wcOutputAnalysis/_SUCCESS: masked=rw-r--r--
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones sending #74
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones got value #74
Call: create took 6ms
computePacketChunkSize: src=/user/michaeljones/wcOutputAnalysis/_SUCCESS, chunkSize=516, chunksPerPacket=126, packetSize=65016
Waiting for ack for: -1
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones sending #75
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones got value #75
Call: complete took 3ms
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.fs.FileContext.getAbstractFileSystem(FileContext.java:331)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
Job job_local1653575348_0003 running in uber mode : false
 map 100% reduce 100%
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.getTaskCompletionEvents(Job.java:670)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.getTaskCompletionEvents(Job.java:670)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
Job job_local1653575348_0003 completed successfully
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.getCounters(Job.java:758)
Counters: 35
	File System Counters
		FILE: Number of bytes read=1892
		FILE: Number of bytes written=1694207
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=340
		HDFS: Number of bytes written=245
		HDFS: Number of read operations=71
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=38
	Map-Reduce Framework
		Map input records=2
		Map output records=8
		Map output bytes=82
		Map output materialized bytes=67
		Input split bytes=112
		Combine input records=8
		Combine output records=5
		Reduce input groups=5
		Reduce shuffle bytes=67
		Reduce input records=5
		Reduce output records=5
		Spilled Records=10
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=818937856
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=50
	File Output Format Counters 
		Bytes Written=41
PrivilegedAction as:michaeljones (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 5][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://localhost:50070
Connecting to localhost/127.0.0.1:50070
Connection established 127.0.0.1:50313<->127.0.0.1:50070
Executing request GET /webhdfs/v1/user/michaeljones/?op=LISTSTATUS HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-5 >> GET /webhdfs/v1/user/michaeljones/?op=LISTSTATUS HTTP/1.1
http-outgoing-5 >> accept: application/json
http-outgoing-5 >> Host: localhost:50070
http-outgoing-5 >> Connection: Keep-Alive
http-outgoing-5 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-5 >> Accept-Encoding: gzip,deflate
http-outgoing-5 >> "GET /webhdfs/v1/user/michaeljones/?op=LISTSTATUS HTTP/1.1[\r][\n]"
http-outgoing-5 >> "accept: application/json[\r][\n]"
http-outgoing-5 >> "Host: localhost:50070[\r][\n]"
http-outgoing-5 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-5 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-5 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-5 >> "[\r][\n]"
http-outgoing-5 << "HTTP/1.1 200 OK[\r][\n]"
http-outgoing-5 << "Cache-Control: no-cache[\r][\n]"
http-outgoing-5 << "Expires: Sun, 14 Jun 2015 03:39:35 GMT[\r][\n]"
http-outgoing-5 << "Date: Sun, 14 Jun 2015 03:39:35 GMT[\r][\n]"
http-outgoing-5 << "Pragma: no-cache[\r][\n]"
http-outgoing-5 << "Expires: Sun, 14 Jun 2015 03:39:35 GMT[\r][\n]"
http-outgoing-5 << "Date: Sun, 14 Jun 2015 03:39:35 GMT[\r][\n]"
http-outgoing-5 << "Pragma: no-cache[\r][\n]"
http-outgoing-5 << "Content-Type: application/json[\r][\n]"
http-outgoing-5 << "Transfer-Encoding: chunked[\r][\n]"
http-outgoing-5 << "Server: Jetty(6.1.26)[\r][\n]"
http-outgoing-5 << "[\r][\n]"
http-outgoing-5 << "12FC[\r][\n]"
http-outgoing-5 << "{"FileStatuses":{"FileStatus":[[\n]"
http-outgoing-5 << "{"accessTime":1434253163334,"blockSize":134217728,"childrenNum":0,"fileId":18748,"group":"supergroup","length":11335,"modificationTime":1434253163364,"owner":"michaeljones","pathSuffix":"README.md","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-5 << "{"accessTime":1434242172845,"blockSize":134217728,"childrenNum":0,"fileId":18690,"group":"supergroup","length":0,"modificationTime":1434242172851,"owner":"michaeljones","pathSuffix":"apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-5 << "{"accessTime":1434250345392,"blockSize":134217728,"childrenNum":0,"fileId":18724,"group":"supergroup","length":0,"modificationTime":1434250345400,"owner":"michaeljones","pathSuffix":"empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-5 << "{"accessTime":1434253162567,"blockSize":134217728,"childrenNum":0,"fileId":18745,"group":"supergroup","length":0,"modificationTime":1434253162578,"owner":"michaeljones","pathSuffix":"hello-apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-5 << "{"accessTime":1434091626279,"blockSize":134217728,"childrenNum":0,"fileId":18298,"group":"supergroup","length":0,"modificationTime":1434091626286,"owner":"michaeljones","pathSuffix":"hello-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-5 << "{"accessTime":1434253162454,"blockSize":134217728,"childrenNum":0,"fileId":18744,"group":"supergroup","length":0,"modificationTime":1434253162462,"owner":"michaeljones","pathSuffix":"hello-jersey-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-5 << "{"accessTime":1434250345962,"blockSize":134217728,"childrenNum":0,"fileId":18726,"group":"supergroup","length":753882,"modificationTime":1434250346002,"owner":"michaeljones","pathSuffix":"hello.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-5 << "{"accessTime":1434253163033,"blockSize":134217728,"childrenNum":0,"fileId":18747,"group":"supergroup","length":3678856,"modificationTime":1434253163193,"owner":"michaeljones","pathSuffix":"hello.log.2015-06-12","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-5 << "{"accessTime":1434253167917,"blockSize":134217728,"childrenNum":0,"fileId":18752,"group":"supergroup","length":20,"modificationTime":1434253168439,"owner":"michaeljones","pathSuffix":"hello.txt","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-5 << "{"accessTime":1434253162853,"blockSize":134217728,"childrenNum":0,"fileId":18746,"group":"supergroup","length":38315,"modificationTime":1434253162930,"owner":"michaeljones","pathSuffix":"hellohadoop.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-5 << "{"accessTime":1434253164356,"blockSize":134217728,"childrenNum":0,"fileId":18750,"group":"supergroup","length":102268,"modificationTime":1434253164403,"owner":"michaeljones","pathSuffix":"hellohadoop.log.2015-06-12","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-5 << "{"accessTime":1434253164359,"blockSize":134217728,"childrenNum":0,"fileId":18751,"group":"supergroup","length":102268,"modificationTime":1434253164408,"owner":"michaeljones","pathSuffix":"hellohadoop.log.2015-06-13","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-5 << "{"accessTime":1434253163937,"blockSize":134217728,"childrenNum":0,"fileId":18749,"group":"supergroup","length":3644,"modificationTime":1434253163960,"owner":"michaeljones","pathSuffix":"nbactions.xml","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-5 << "{"accessTime":1434242172891,"blockSize":134217728,"childrenNum":0,"fileId":18691,"group":"supergroup","length":2134,"modificationTime":1434242172913,"owner":"michaeljones","pathSuffix":"pom.xml","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-5 << "{"accessTime":1434253169122,"blockSize":134217728,"childrenNum":0,"fileId":16388,"group":"supergroup","length":50,"modificationTime":1433119638967,"owner":"michaeljones","pathSuffix":"wcInput","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-5 << "{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18760,"group":"supergroup","length":0,"modificationTime":1434253172670,"owner":"michaeljones","pathSuffix":"wcOutput","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},[\n]"
http-outgoing-5 << "{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18767,"group":"supergroup","length":0,"modificationTime":1434253174376,"owner":"michaeljones","pathSuffix":"wcOutputAnalysis","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},[\n]"
http-outgoing-5 << "{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18753,"group":"supergroup","length":0,"modificationTime":1434253171258,"owner":"michaeljones","pathSuffix":"wcOutputMain","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"}[\n]"
http-outgoing-5 << "]}}[\n]"
http-outgoing-5 << "[\r][\n]"
http-outgoing-5 << HTTP/1.1 200 OK
http-outgoing-5 << Cache-Control: no-cache
http-outgoing-5 << Expires: Sun, 14 Jun 2015 03:39:35 GMT
http-outgoing-5 << Date: Sun, 14 Jun 2015 03:39:35 GMT
http-outgoing-5 << Pragma: no-cache
http-outgoing-5 << Expires: Sun, 14 Jun 2015 03:39:35 GMT
http-outgoing-5 << Date: Sun, 14 Jun 2015 03:39:35 GMT
http-outgoing-5 << Pragma: no-cache
http-outgoing-5 << Content-Type: application/json
http-outgoing-5 << Transfer-Encoding: chunked
http-outgoing-5 << Server: Jetty(6.1.26)
Connection can be kept alive indefinitely
http-outgoing-5 << "0[\r][\n]"
http-outgoing-5 << "[\r][\n]"
Connection [id: 5][route: {}->http://localhost:50070] can be kept alive indefinitely
Connection released: [id: 5][route: {}->http://localhost:50070][total kept alive: 1; route allocated: 1 of 2; total allocated: 1 of 20]
Apache client testGetStringContent
{"FileStatuses":{"FileStatus":[
{"accessTime":1434253163334,"blockSize":134217728,"childrenNum":0,"fileId":18748,"group":"supergroup","length":11335,"modificationTime":1434253163364,"owner":"michaeljones","pathSuffix":"README.md","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434242172845,"blockSize":134217728,"childrenNum":0,"fileId":18690,"group":"supergroup","length":0,"modificationTime":1434242172851,"owner":"michaeljones","pathSuffix":"apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434250345392,"blockSize":134217728,"childrenNum":0,"fileId":18724,"group":"supergroup","length":0,"modificationTime":1434250345400,"owner":"michaeljones","pathSuffix":"empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434253162567,"blockSize":134217728,"childrenNum":0,"fileId":18745,"group":"supergroup","length":0,"modificationTime":1434253162578,"owner":"michaeljones","pathSuffix":"hello-apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434091626279,"blockSize":134217728,"childrenNum":0,"fileId":18298,"group":"supergroup","length":0,"modificationTime":1434091626286,"owner":"michaeljones","pathSuffix":"hello-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434253162454,"blockSize":134217728,"childrenNum":0,"fileId":18744,"group":"supergroup","length":0,"modificationTime":1434253162462,"owner":"michaeljones","pathSuffix":"hello-jersey-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434250345962,"blockSize":134217728,"childrenNum":0,"fileId":18726,"group":"supergroup","length":753882,"modificationTime":1434250346002,"owner":"michaeljones","pathSuffix":"hello.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434253163033,"blockSize":134217728,"childrenNum":0,"fileId":18747,"group":"supergroup","length":3678856,"modificationTime":1434253163193,"owner":"michaeljones","pathSuffix":"hello.log.2015-06-12","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434253167917,"blockSize":134217728,"childrenNum":0,"fileId":18752,"group":"supergroup","length":20,"modificationTime":1434253168439,"owner":"michaeljones","pathSuffix":"hello.txt","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434253162853,"blockSize":134217728,"childrenNum":0,"fileId":18746,"group":"supergroup","length":38315,"modificationTime":1434253162930,"owner":"michaeljones","pathSuffix":"hellohadoop.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434253164356,"blockSize":134217728,"childrenNum":0,"fileId":18750,"group":"supergroup","length":102268,"modificationTime":1434253164403,"owner":"michaeljones","pathSuffix":"hellohadoop.log.2015-06-12","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434253164359,"blockSize":134217728,"childrenNum":0,"fileId":18751,"group":"supergroup","length":102268,"modificationTime":1434253164408,"owner":"michaeljones","pathSuffix":"hellohadoop.log.2015-06-13","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434253163937,"blockSize":134217728,"childrenNum":0,"fileId":18749,"group":"supergroup","length":3644,"modificationTime":1434253163960,"owner":"michaeljones","pathSuffix":"nbactions.xml","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434242172891,"blockSize":134217728,"childrenNum":0,"fileId":18691,"group":"supergroup","length":2134,"modificationTime":1434242172913,"owner":"michaeljones","pathSuffix":"pom.xml","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434253169122,"blockSize":134217728,"childrenNum":0,"fileId":16388,"group":"supergroup","length":50,"modificationTime":1433119638967,"owner":"michaeljones","pathSuffix":"wcInput","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18760,"group":"supergroup","length":0,"modificationTime":1434253172670,"owner":"michaeljones","pathSuffix":"wcOutput","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},
{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18767,"group":"supergroup","length":0,"modificationTime":1434253174376,"owner":"michaeljones","pathSuffix":"wcOutputAnalysis","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},
{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18753,"group":"supergroup","length":0,"modificationTime":1434253171258,"owner":"michaeljones","pathSuffix":"wcOutputMain","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"}
]}}

CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 6][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://localhost:50070
Connecting to localhost/127.0.0.1:50070
Connection established 127.0.0.1:50314<->127.0.0.1:50070
Executing request PUT /webhdfs/v1/user/michaeljones/apache-empty.txt?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-6 >> PUT /webhdfs/v1/user/michaeljones/apache-empty.txt?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1
http-outgoing-6 >> Content-Length: 0
http-outgoing-6 >> Host: localhost:50070
http-outgoing-6 >> Connection: Keep-Alive
http-outgoing-6 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-6 >> Accept-Encoding: gzip,deflate
http-outgoing-6 >> "PUT /webhdfs/v1/user/michaeljones/apache-empty.txt?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1[\r][\n]"
http-outgoing-6 >> "Content-Length: 0[\r][\n]"
http-outgoing-6 >> "Host: localhost:50070[\r][\n]"
http-outgoing-6 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-6 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-6 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-6 >> "[\r][\n]"
http-outgoing-6 << "HTTP/1.1 307 TEMPORARY_REDIRECT[\r][\n]"
http-outgoing-6 << "Cache-Control: no-cache[\r][\n]"
http-outgoing-6 << "Expires: Sun, 14 Jun 2015 03:39:35 GMT[\r][\n]"
http-outgoing-6 << "Date: Sun, 14 Jun 2015 03:39:35 GMT[\r][\n]"
http-outgoing-6 << "Pragma: no-cache[\r][\n]"
http-outgoing-6 << "Expires: Sun, 14 Jun 2015 03:39:35 GMT[\r][\n]"
http-outgoing-6 << "Date: Sun, 14 Jun 2015 03:39:35 GMT[\r][\n]"
http-outgoing-6 << "Pragma: no-cache[\r][\n]"
http-outgoing-6 << "Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434289175358&s=Hy33xa7pTKN08lG9lPiudOPQ73M="; Path=/; Expires=Sun, 14-Jun-2015 13:39:35 GMT; HttpOnly[\r][\n]"
http-outgoing-6 << "Location: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true[\r][\n]"
http-outgoing-6 << "Content-Type: application/octet-stream[\r][\n]"
http-outgoing-6 << "Content-Length: 0[\r][\n]"
http-outgoing-6 << "Server: Jetty(6.1.26)[\r][\n]"
http-outgoing-6 << "[\r][\n]"
http-outgoing-6 << HTTP/1.1 307 TEMPORARY_REDIRECT
http-outgoing-6 << Cache-Control: no-cache
http-outgoing-6 << Expires: Sun, 14 Jun 2015 03:39:35 GMT
http-outgoing-6 << Date: Sun, 14 Jun 2015 03:39:35 GMT
http-outgoing-6 << Pragma: no-cache
http-outgoing-6 << Expires: Sun, 14 Jun 2015 03:39:35 GMT
http-outgoing-6 << Date: Sun, 14 Jun 2015 03:39:35 GMT
http-outgoing-6 << Pragma: no-cache
http-outgoing-6 << Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434289175358&s=Hy33xa7pTKN08lG9lPiudOPQ73M="; Path=/; Expires=Sun, 14-Jun-2015 13:39:35 GMT; HttpOnly
http-outgoing-6 << Location: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
http-outgoing-6 << Content-Type: application/octet-stream
http-outgoing-6 << Content-Length: 0
http-outgoing-6 << Server: Jetty(6.1.26)
Connection can be kept alive indefinitely
Cookie accepted [hadoop.auth=""u=michaeljones&p=michaeljones&t=simple&e=1434289175358&s=Hy33xa7pTKN08lG9lPiudOPQ73M="", version:0, domain:localhost, path:/, expiry:Sun Jun 14 23:39:35 AEST 2015]
Redirect to: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
http-outgoing-6: Shutdown connection
Connection discarded
http-outgoing-6: Close connection
Connection released: [id: 6][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
PUT file redirect: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 7][route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://michaels-air.bigpond:50075
Connecting to Michaels-Air.BigPond/10.0.0.2:50075
Connection established 10.0.0.2:50315<->10.0.0.2:50075
Executing request PUT /webhdfs/v1/user/michaeljones/apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-7 >> PUT /webhdfs/v1/user/michaeljones/apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1
http-outgoing-7 >> Content-Length: 0
http-outgoing-7 >> Host: michaels-air.bigpond:50075
http-outgoing-7 >> Connection: Keep-Alive
http-outgoing-7 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-7 >> Accept-Encoding: gzip,deflate
http-outgoing-7 >> "PUT /webhdfs/v1/user/michaeljones/apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1[\r][\n]"
http-outgoing-7 >> "Content-Length: 0[\r][\n]"
http-outgoing-7 >> "Host: michaels-air.bigpond:50075[\r][\n]"
http-outgoing-7 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-7 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-7 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-7 >> "[\r][\n]"
http-outgoing-7 << "HTTP/1.1 100 Continue[\r][\n]"
http-outgoing-7 << "[\r][\n]"
http-outgoing-7 << HTTP/1.1 100 Continue
http-outgoing-7 << "HTTP/1.1 201 Created[\r][\n]"
http-outgoing-7 << "Location: hdfs://localhost:9000/user/michaeljones/apache-empty.txt[\r][\n]"
http-outgoing-7 << "Content-Length: 0[\r][\n]"
http-outgoing-7 << "Connection: close[\r][\n]"
http-outgoing-7 << "[\r][\n]"
http-outgoing-7 << HTTP/1.1 201 Created
http-outgoing-7 << Location: hdfs://localhost:9000/user/michaeljones/apache-empty.txt
http-outgoing-7 << Content-Length: 0
http-outgoing-7 << Connection: close
http-outgoing-7: Shutdown connection
Connection discarded
http-outgoing-7: Close connection
Connection released: [id: 7][route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 8][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://localhost:50070
Connecting to localhost/127.0.0.1:50070
Connection established 127.0.0.1:50317<->127.0.0.1:50070
Executing request PUT /webhdfs/v1/user/michaeljones/pom.xml?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-8 >> PUT /webhdfs/v1/user/michaeljones/pom.xml?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1
http-outgoing-8 >> Content-Length: 0
http-outgoing-8 >> Host: localhost:50070
http-outgoing-8 >> Connection: Keep-Alive
http-outgoing-8 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-8 >> Accept-Encoding: gzip,deflate
http-outgoing-8 >> "PUT /webhdfs/v1/user/michaeljones/pom.xml?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1[\r][\n]"
http-outgoing-8 >> "Content-Length: 0[\r][\n]"
http-outgoing-8 >> "Host: localhost:50070[\r][\n]"
http-outgoing-8 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-8 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-8 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-8 >> "[\r][\n]"
http-outgoing-8 << "HTTP/1.1 307 TEMPORARY_REDIRECT[\r][\n]"
http-outgoing-8 << "Cache-Control: no-cache[\r][\n]"
http-outgoing-8 << "Expires: Sun, 14 Jun 2015 03:39:35 GMT[\r][\n]"
http-outgoing-8 << "Date: Sun, 14 Jun 2015 03:39:35 GMT[\r][\n]"
http-outgoing-8 << "Pragma: no-cache[\r][\n]"
http-outgoing-8 << "Expires: Sun, 14 Jun 2015 03:39:35 GMT[\r][\n]"
http-outgoing-8 << "Date: Sun, 14 Jun 2015 03:39:35 GMT[\r][\n]"
http-outgoing-8 << "Pragma: no-cache[\r][\n]"
http-outgoing-8 << "Content-Type: application/octet-stream[\r][\n]"
http-outgoing-8 << "Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434289175438&s=EgIbr1CQ+Hy8NFhGw9e8tGA9vJs="; Path=/; Expires=Sun, 14-Jun-2015 13:39:35 GMT; HttpOnly[\r][\n]"
http-outgoing-8 << "Location: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/pom.xml?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true[\r][\n]"
http-outgoing-8 << "Content-Length: 0[\r][\n]"
http-outgoing-8 << "Server: Jetty(6.1.26)[\r][\n]"
http-outgoing-8 << "[\r][\n]"
http-outgoing-8 << HTTP/1.1 307 TEMPORARY_REDIRECT
http-outgoing-8 << Cache-Control: no-cache
http-outgoing-8 << Expires: Sun, 14 Jun 2015 03:39:35 GMT
http-outgoing-8 << Date: Sun, 14 Jun 2015 03:39:35 GMT
http-outgoing-8 << Pragma: no-cache
http-outgoing-8 << Expires: Sun, 14 Jun 2015 03:39:35 GMT
http-outgoing-8 << Date: Sun, 14 Jun 2015 03:39:35 GMT
http-outgoing-8 << Pragma: no-cache
http-outgoing-8 << Content-Type: application/octet-stream
http-outgoing-8 << Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434289175438&s=EgIbr1CQ+Hy8NFhGw9e8tGA9vJs="; Path=/; Expires=Sun, 14-Jun-2015 13:39:35 GMT; HttpOnly
http-outgoing-8 << Location: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/pom.xml?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
http-outgoing-8 << Content-Length: 0
http-outgoing-8 << Server: Jetty(6.1.26)
Connection can be kept alive indefinitely
Cookie accepted [hadoop.auth=""u=michaeljones&p=michaeljones&t=simple&e=1434289175438&s=EgIbr1CQ+Hy8NFhGw9e8tGA9vJs="", version:0, domain:localhost, path:/, expiry:Sun Jun 14 23:39:35 AEST 2015]
Redirect to: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/pom.xml?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
http-outgoing-8: Shutdown connection
Connection discarded
http-outgoing-8: Close connection
Connection released: [id: 8][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
PUT file redirect: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/pom.xml?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 9][route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://michaels-air.bigpond:50075
Connecting to Michaels-Air.BigPond/10.0.0.2:50075
Connection established 10.0.0.2:50318<->10.0.0.2:50075
Executing request PUT /webhdfs/v1/user/michaeljones/pom.xml?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-9 >> PUT /webhdfs/v1/user/michaeljones/pom.xml?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1
http-outgoing-9 >> Transfer-Encoding: chunked
http-outgoing-9 >> Content-Type: application/octet-stream
http-outgoing-9 >> Host: michaels-air.bigpond:50075
http-outgoing-9 >> Connection: Keep-Alive
http-outgoing-9 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-9 >> Accept-Encoding: gzip,deflate
http-outgoing-9 >> "PUT /webhdfs/v1/user/michaeljones/pom.xml?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1[\r][\n]"
http-outgoing-9 >> "Transfer-Encoding: chunked[\r][\n]"
http-outgoing-9 >> "Content-Type: application/octet-stream[\r][\n]"
http-outgoing-9 >> "Host: michaels-air.bigpond:50075[\r][\n]"
http-outgoing-9 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-9 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-9 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-9 >> "[\r][\n]"
http-outgoing-9 >> "856[\r][\n]"
http-outgoing-9 >> "<?xml version="1.0" encoding="UTF-8"?>[\n]"
http-outgoing-9 >> "<project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">[\n]"
http-outgoing-9 >> "    <modelVersion>4.0.0</modelVersion>[\n]"
http-outgoing-9 >> "    <groupId>com.michaeljones</groupId>[\n]"
http-outgoing-9 >> "    <artifactId>HelloHadoopWorldMaven</artifactId>[\n]"
http-outgoing-9 >> "    <version>1.0-SNAPSHOT</version>[\n]"
http-outgoing-9 >> "    <packaging>jar</packaging>[\n]"
http-outgoing-9 >> "    <dependencies>[\n]"
http-outgoing-9 >> "        <!-- run bin/hadoop version to see the jar it was built with, which is this dependency -->[\n]"
http-outgoing-9 >> "        <dependency>[\n]"
http-outgoing-9 >> "            <groupId>org.apache.hadoop</groupId>[\n]"
http-outgoing-9 >> "            <artifactId>hadoop-common</artifactId>[\n]"
http-outgoing-9 >> "            <version>2.7.0</version>[\n]"
http-outgoing-9 >> "        </dependency>[\n]"
http-outgoing-9 >> "        <dependency>[\n]"
http-outgoing-9 >> "            <groupId>org.apache.hadoop</groupId>[\n]"
http-outgoing-9 >> "            <artifactId>hadoop-hdfs</artifactId>[\n]"
http-outgoing-9 >> "            <version>2.7.0</version>[\n]"
http-outgoing-9 >> "        </dependency>[\n]"
http-outgoing-9 >> "        <dependency>[\n]"
http-outgoing-9 >> "            <groupId>junit</groupId>[\n]"
http-outgoing-9 >> "            <artifactId>junit</artifactId>[\n]"
http-outgoing-9 >> "            <version>4.10</version>[\n]"
http-outgoing-9 >> "            <scope>test</scope>[\n]"
http-outgoing-9 >> "        </dependency>[\n]"
http-outgoing-9 >> "        <dependency>[\n]"
http-outgoing-9 >> "            <groupId>org.apache.hadoop</groupId>[\n]"
http-outgoing-9 >> "            <artifactId>hadoop-mapreduce-client-core</artifactId>[\n]"
http-outgoing-9 >> "            <version>2.7.0</version>[\n]"
http-outgoing-9 >> "        </dependency>[\n]"
http-outgoing-9 >> "        <dependency>[\n]"
http-outgoing-9 >> "            <groupId>org.apache.hadoop</groupId>[\n]"
http-outgoing-9 >> "            <artifactId>hadoop-mapreduce-client-common</artifactId>[\n]"
http-outgoing-9 >> "            <version>2.7.0</version>[\n]"
http-outgoing-9 >> "        </dependency>[\n]"
http-outgoing-9 >> "        <dependency>[\n]"
http-outgoing-9 >> "            <groupId>com.googlecode.json-simple</groupId>[\n]"
http-outgoing-9 >> "            <artifactId>json-simple</artifactId>[\n]"
http-outgoing-9 >> "            <version>1.1.1</version>[\n]"
http-outgoing-9 >> "        </dependency>[\n]"
http-outgoing-9 >> "        <dependency>[\n]"
http-outgoing-9 >> "            <groupId>org.apache.httpcomponents</groupId>[\n]"
http-outgoing-9 >> "            <artifactId>httpclient</artifactId>[\n]"
http-outgoing-9 >> "            <version>4.4-beta1</version>[\n]"
http-outgoing-9 >> "        </dependency>[\n]"
http-outgoing-9 >> "    </dependencies>[\n]"
http-outgoing-9 >> "    <properties>[\n]"
http-outgoing-9 >> "        <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>[\n]"
http-outgoing-9 >> "        <maven.compiler.source>1.7</maven.compiler.source>[\n]"
http-outgoing-9 >> "        <maven.compiler.target>1.7</maven.compiler.target>[\n]"
http-outgoing-9 >> "    </properties>[\n]"
http-outgoing-9 >> "</project>[\r][\n]"
http-outgoing-9 >> "0[\r][\n]"
http-outgoing-9 >> "[\r][\n]"
http-outgoing-9 << "HTTP/1.1 100 Continue[\r][\n]"
http-outgoing-9 << "[\r][\n]"
http-outgoing-9 << HTTP/1.1 100 Continue
http-outgoing-9 << "HTTP/1.1 201 Created[\r][\n]"
http-outgoing-9 << "Location: hdfs://localhost:9000/user/michaeljones/pom.xml[\r][\n]"
http-outgoing-9 << "Content-Length: 0[\r][\n]"
http-outgoing-9 << "Connection: close[\r][\n]"
http-outgoing-9 << "[\r][\n]"
http-outgoing-9 << HTTP/1.1 201 Created
http-outgoing-9 << Location: hdfs://localhost:9000/user/michaeljones/pom.xml
http-outgoing-9 << Content-Length: 0
http-outgoing-9 << Connection: close
http-outgoing-9: Shutdown connection
Connection discarded
http-outgoing-9: Close connection
Connection released: [id: 9][route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection manager is shutting down
Connection manager shut down
Jersey client testGetStringContent
{"FileStatuses":{"FileStatus":[
{"accessTime":1434253163334,"blockSize":134217728,"childrenNum":0,"fileId":18748,"group":"supergroup","length":11335,"modificationTime":1434253163364,"owner":"michaeljones","pathSuffix":"README.md","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434253175397,"blockSize":134217728,"childrenNum":0,"fileId":18774,"group":"supergroup","length":0,"modificationTime":1434253175405,"owner":"michaeljones","pathSuffix":"apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434250345392,"blockSize":134217728,"childrenNum":0,"fileId":18724,"group":"supergroup","length":0,"modificationTime":1434250345400,"owner":"michaeljones","pathSuffix":"empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434253162567,"blockSize":134217728,"childrenNum":0,"fileId":18745,"group":"supergroup","length":0,"modificationTime":1434253162578,"owner":"michaeljones","pathSuffix":"hello-apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434091626279,"blockSize":134217728,"childrenNum":0,"fileId":18298,"group":"supergroup","length":0,"modificationTime":1434091626286,"owner":"michaeljones","pathSuffix":"hello-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434253162454,"blockSize":134217728,"childrenNum":0,"fileId":18744,"group":"supergroup","length":0,"modificationTime":1434253162462,"owner":"michaeljones","pathSuffix":"hello-jersey-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434250345962,"blockSize":134217728,"childrenNum":0,"fileId":18726,"group":"supergroup","length":753882,"modificationTime":1434250346002,"owner":"michaeljones","pathSuffix":"hello.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434253163033,"blockSize":134217728,"childrenNum":0,"fileId":18747,"group":"supergroup","length":3678856,"modificationTime":1434253163193,"owner":"michaeljones","pathSuffix":"hello.log.2015-06-12","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434253167917,"blockSize":134217728,"childrenNum":0,"fileId":18752,"group":"supergroup","length":20,"modificationTime":1434253168439,"owner":"michaeljones","pathSuffix":"hello.txt","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434253162853,"blockSize":134217728,"childrenNum":0,"fileId":18746,"group":"supergroup","length":38315,"modificationTime":1434253162930,"owner":"michaeljones","pathSuffix":"hellohadoop.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434253164356,"blockSize":134217728,"childrenNum":0,"fileId":18750,"group":"supergroup","length":102268,"modificationTime":1434253164403,"owner":"michaeljones","pathSuffix":"hellohadoop.log.2015-06-12","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434253164359,"blockSize":134217728,"childrenNum":0,"fileId":18751,"group":"supergroup","length":102268,"modificationTime":1434253164408,"owner":"michaeljones","pathSuffix":"hellohadoop.log.2015-06-13","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434253163937,"blockSize":134217728,"childrenNum":0,"fileId":18749,"group":"supergroup","length":3644,"modificationTime":1434253163960,"owner":"michaeljones","pathSuffix":"nbactions.xml","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434253175494,"blockSize":134217728,"childrenNum":0,"fileId":18775,"group":"supergroup","length":2134,"modificationTime":1434253175528,"owner":"michaeljones","pathSuffix":"pom.xml","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":1434253169122,"blockSize":134217728,"childrenNum":0,"fileId":16388,"group":"supergroup","length":50,"modificationTime":1433119638967,"owner":"michaeljones","pathSuffix":"wcInput","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},
{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18760,"group":"supergroup","length":0,"modificationTime":1434253172670,"owner":"michaeljones","pathSuffix":"wcOutput","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},
{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18767,"group":"supergroup","length":0,"modificationTime":1434253174376,"owner":"michaeljones","pathSuffix":"wcOutputAnalysis","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},
{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18753,"group":"supergroup","length":0,"modificationTime":1434253171258,"owner":"michaeljones","pathSuffix":"wcOutputMain","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"}
]}}

Connection manager is shutting down
Connection manager shut down
Connection manager is shutting down
http-outgoing-5: Close connection
http-outgoing-5: Close connection
Connection manager shut down
Connection manager is shutting down
Connection manager shut down
Jersey client Redirect to: hdfs://localhost:9000/user/michaeljones/hello.log
Jersey redirected to IPC: hdfs://localhost:9000/user/michaeljones/hello.log
com.sun.jersey.client.property.chunkedEncodingSize: 1048576
Jersey client Redirect to: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/nbactions.xml?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
com.sun.jersey.client.property.chunkedEncodingSize: 1048576
Jersey client Redirect to: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/nbactions.xml?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
Get redirect location async: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/nbactions.xml?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
com.sun.jersey.client.property.chunkedEncodingSize: 1048576
stopping client from cache: org.apache.hadoop.ipc.Client@4351c8c3
removing client from cache: org.apache.hadoop.ipc.Client@4351c8c3
stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@4351c8c3
Stopping client
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones: closed
IPC Client (1800649922) connection to localhost/127.0.0.1:9000 from michaeljones: stopped, remaining connections 0
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 0][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://localhost:50070
Connecting to localhost/127.0.0.1:50070
Connection established 127.0.0.1:49434<->127.0.0.1:50070
Executing request GET /webhdfs/v1/user/michaeljones/?user.name=michaeljones&op=LISTSTATUS HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-0 >> GET /webhdfs/v1/user/michaeljones/?user.name=michaeljones&op=LISTSTATUS HTTP/1.1
http-outgoing-0 >> accept: application/json
http-outgoing-0 >> Host: localhost:50070
http-outgoing-0 >> Connection: Keep-Alive
http-outgoing-0 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-0 >> Accept-Encoding: gzip,deflate
http-outgoing-0 >> "GET /webhdfs/v1/user/michaeljones/?user.name=michaeljones&op=LISTSTATUS HTTP/1.1[\r][\n]"
http-outgoing-0 >> "accept: application/json[\r][\n]"
http-outgoing-0 >> "Host: localhost:50070[\r][\n]"
http-outgoing-0 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-0 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-0 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-0 >> "[\r][\n]"
http-outgoing-0 << "HTTP/1.1 200 OK[\r][\n]"
http-outgoing-0 << "Cache-Control: no-cache[\r][\n]"
http-outgoing-0 << "Expires: Sun, 14 Jun 2015 06:39:26 GMT[\r][\n]"
http-outgoing-0 << "Date: Sun, 14 Jun 2015 06:39:26 GMT[\r][\n]"
http-outgoing-0 << "Pragma: no-cache[\r][\n]"
http-outgoing-0 << "Expires: Sun, 14 Jun 2015 06:39:26 GMT[\r][\n]"
http-outgoing-0 << "Date: Sun, 14 Jun 2015 06:39:26 GMT[\r][\n]"
http-outgoing-0 << "Pragma: no-cache[\r][\n]"
http-outgoing-0 << "Content-Type: application/json[\r][\n]"
http-outgoing-0 << "Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434299966726&s=BTW5q6u9drBYgqlXM+S7VuU/pMk="; Path=/; Expires=Sun, 14-Jun-2015 16:39:26 GMT; HttpOnly[\r][\n]"
http-outgoing-0 << "Transfer-Encoding: chunked[\r][\n]"
http-outgoing-0 << "Server: Jetty(6.1.26)[\r][\n]"
http-outgoing-0 << "[\r][\n]"
http-outgoing-0 << "12FD[\r][\n]"
http-outgoing-0 << "{"FileStatuses":{"FileStatus":[[\n]"
http-outgoing-0 << "{"accessTime":1434253163334,"blockSize":134217728,"childrenNum":0,"fileId":18748,"group":"supergroup","length":11335,"modificationTime":1434253163364,"owner":"michaeljones","pathSuffix":"README.md","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434253175397,"blockSize":134217728,"childrenNum":0,"fileId":18774,"group":"supergroup","length":0,"modificationTime":1434253175405,"owner":"michaeljones","pathSuffix":"apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434253176088,"blockSize":134217728,"childrenNum":0,"fileId":18776,"group":"supergroup","length":0,"modificationTime":1434253176095,"owner":"michaeljones","pathSuffix":"empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434253162567,"blockSize":134217728,"childrenNum":0,"fileId":18745,"group":"supergroup","length":0,"modificationTime":1434253162578,"owner":"michaeljones","pathSuffix":"hello-apache-empty.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434091626279,"blockSize":134217728,"childrenNum":0,"fileId":18298,"group":"supergroup","length":0,"modificationTime":1434091626286,"owner":"michaeljones","pathSuffix":"hello-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434253162454,"blockSize":134217728,"childrenNum":0,"fileId":18744,"group":"supergroup","length":0,"modificationTime":1434253162462,"owner":"michaeljones","pathSuffix":"hello-jersey-emtpy.txt","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434253176773,"blockSize":134217728,"childrenNum":0,"fileId":18779,"group":"supergroup","length":1276216,"modificationTime":1434253176812,"owner":"michaeljones","pathSuffix":"hello.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434253163033,"blockSize":134217728,"childrenNum":0,"fileId":18747,"group":"supergroup","length":3678856,"modificationTime":1434253163193,"owner":"michaeljones","pathSuffix":"hello.log.2015-06-12","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434253167917,"blockSize":134217728,"childrenNum":0,"fileId":18752,"group":"supergroup","length":20,"modificationTime":1434253168439,"owner":"michaeljones","pathSuffix":"hello.txt","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434253162853,"blockSize":134217728,"childrenNum":0,"fileId":18746,"group":"supergroup","length":38315,"modificationTime":1434253162930,"owner":"michaeljones","pathSuffix":"hellohadoop.log","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434253164356,"blockSize":134217728,"childrenNum":0,"fileId":18750,"group":"supergroup","length":102268,"modificationTime":1434253164403,"owner":"michaeljones","pathSuffix":"hellohadoop.log.2015-06-12","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434253164359,"blockSize":134217728,"childrenNum":0,"fileId":18751,"group":"supergroup","length":102268,"modificationTime":1434253164408,"owner":"michaeljones","pathSuffix":"hellohadoop.log.2015-06-13","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434253176643,"blockSize":134217728,"childrenNum":0,"fileId":18778,"group":"supergroup","length":3644,"modificationTime":1434253176664,"owner":"michaeljones","pathSuffix":"nbactions.xml","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434253175494,"blockSize":134217728,"childrenNum":0,"fileId":18775,"group":"supergroup","length":2134,"modificationTime":1434253175528,"owner":"michaeljones","pathSuffix":"pom.xml","permission":"755","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":1434253169122,"blockSize":134217728,"childrenNum":0,"fileId":16388,"group":"supergroup","length":50,"modificationTime":1433119638967,"owner":"michaeljones","pathSuffix":"wcInput","permission":"644","replication":1,"storagePolicy":0,"type":"FILE"},[\n]"
http-outgoing-0 << "{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18760,"group":"supergroup","length":0,"modificationTime":1434253172670,"owner":"michaeljones","pathSuffix":"wcOutput","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},[\n]"
http-outgoing-0 << "{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18767,"group":"supergroup","length":0,"modificationTime":1434253174376,"owner":"michaeljones","pathSuffix":"wcOutputAnalysis","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"},[\n]"
http-outgoing-0 << "{"accessTime":0,"blockSize":0,"childrenNum":2,"fileId":18753,"group":"supergroup","length":0,"modificationTime":1434253171258,"owner":"michaeljones","pathSuffix":"wcOutputMain","permission":"755","replication":0,"storagePolicy":0,"type":"DIRECTORY"}[\n]"
http-outgoing-0 << "]}}[\n]"
http-outgoing-0 << "[\r][\n]"
http-outgoing-0 << HTTP/1.1 200 OK
http-outgoing-0 << Cache-Control: no-cache
http-outgoing-0 << Expires: Sun, 14 Jun 2015 06:39:26 GMT
http-outgoing-0 << Date: Sun, 14 Jun 2015 06:39:26 GMT
http-outgoing-0 << Pragma: no-cache
http-outgoing-0 << Expires: Sun, 14 Jun 2015 06:39:26 GMT
http-outgoing-0 << Date: Sun, 14 Jun 2015 06:39:26 GMT
http-outgoing-0 << Pragma: no-cache
http-outgoing-0 << Content-Type: application/json
http-outgoing-0 << Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434299966726&s=BTW5q6u9drBYgqlXM+S7VuU/pMk="; Path=/; Expires=Sun, 14-Jun-2015 16:39:26 GMT; HttpOnly
http-outgoing-0 << Transfer-Encoding: chunked
http-outgoing-0 << Server: Jetty(6.1.26)
Connection can be kept alive indefinitely
Cookie accepted [hadoop.auth=""u=michaeljones&p=michaeljones&t=simple&e=1434299966726&s=BTW5q6u9drBYgqlXM+S7VuU/pMk="", version:0, domain:localhost, path:/, expiry:Mon Jun 15 02:39:26 AEST 2015]
http-outgoing-0 << "0[\r][\n]"
http-outgoing-0 << "[\r][\n]"
Connection [id: 0][route: {}->http://localhost:50070] can be kept alive indefinitely
Connection released: [id: 0][route: {}->http://localhost:50070][total kept alive: 1; route allocated: 1 of 2; total allocated: 1 of 20]
Connection manager is shutting down
http-outgoing-0: Close connection
http-outgoing-0: Close connection
Connection manager shut down
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 1][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://localhost:50070
Connecting to localhost/127.0.0.1:50070
Connection established 127.0.0.1:49437<->127.0.0.1:50070
Executing request PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-1 >> PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1
http-outgoing-1 >> Content-Length: 0
http-outgoing-1 >> Host: localhost:50070
http-outgoing-1 >> Connection: Keep-Alive
http-outgoing-1 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-1 >> Accept-Encoding: gzip,deflate
http-outgoing-1 >> "PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1[\r][\n]"
http-outgoing-1 >> "Content-Length: 0[\r][\n]"
http-outgoing-1 >> "Host: localhost:50070[\r][\n]"
http-outgoing-1 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-1 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-1 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-1 >> "[\r][\n]"
http-outgoing-1 << "HTTP/1.1 307 TEMPORARY_REDIRECT[\r][\n]"
http-outgoing-1 << "Cache-Control: no-cache[\r][\n]"
http-outgoing-1 << "Expires: Sun, 14 Jun 2015 06:39:27 GMT[\r][\n]"
http-outgoing-1 << "Date: Sun, 14 Jun 2015 06:39:27 GMT[\r][\n]"
http-outgoing-1 << "Pragma: no-cache[\r][\n]"
http-outgoing-1 << "Expires: Sun, 14 Jun 2015 06:39:27 GMT[\r][\n]"
http-outgoing-1 << "Date: Sun, 14 Jun 2015 06:39:27 GMT[\r][\n]"
http-outgoing-1 << "Pragma: no-cache[\r][\n]"
http-outgoing-1 << "Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434299967945&s=PXWVJ+nTXFbgrFhz3t9xXBBUd5Q="; Path=/; Expires=Sun, 14-Jun-2015 16:39:27 GMT; HttpOnly[\r][\n]"
http-outgoing-1 << "Location: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true[\r][\n]"
http-outgoing-1 << "Content-Type: application/octet-stream[\r][\n]"
http-outgoing-1 << "Content-Length: 0[\r][\n]"
http-outgoing-1 << "Server: Jetty(6.1.26)[\r][\n]"
http-outgoing-1 << "[\r][\n]"
http-outgoing-1 << HTTP/1.1 307 TEMPORARY_REDIRECT
http-outgoing-1 << Cache-Control: no-cache
http-outgoing-1 << Expires: Sun, 14 Jun 2015 06:39:27 GMT
http-outgoing-1 << Date: Sun, 14 Jun 2015 06:39:27 GMT
http-outgoing-1 << Pragma: no-cache
http-outgoing-1 << Expires: Sun, 14 Jun 2015 06:39:27 GMT
http-outgoing-1 << Date: Sun, 14 Jun 2015 06:39:27 GMT
http-outgoing-1 << Pragma: no-cache
http-outgoing-1 << Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434299967945&s=PXWVJ+nTXFbgrFhz3t9xXBBUd5Q="; Path=/; Expires=Sun, 14-Jun-2015 16:39:27 GMT; HttpOnly
http-outgoing-1 << Location: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
http-outgoing-1 << Content-Type: application/octet-stream
http-outgoing-1 << Content-Length: 0
http-outgoing-1 << Server: Jetty(6.1.26)
Connection can be kept alive indefinitely
Cookie accepted [hadoop.auth=""u=michaeljones&p=michaeljones&t=simple&e=1434299967945&s=PXWVJ+nTXFbgrFhz3t9xXBBUd5Q="", version:0, domain:localhost, path:/, expiry:Mon Jun 15 02:39:27 AEST 2015]
Redirect to: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
http-outgoing-1: Shutdown connection
Connection discarded
http-outgoing-1: Close connection
Connection released: [id: 1][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 2][route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://michaels-air.bigpond:50075
Connecting to michaels-air.bigpond/10.0.0.2:50075
Connection established 10.0.0.2:49438<->10.0.0.2:50075
Executing request PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-2 >> PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1
http-outgoing-2 >> Content-Length: 0
http-outgoing-2 >> Host: michaels-air.bigpond:50075
http-outgoing-2 >> Connection: Keep-Alive
http-outgoing-2 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-2 >> Accept-Encoding: gzip,deflate
http-outgoing-2 >> "PUT /webhdfs/v1/user/michaeljones/hello-apache-empty.txt?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1[\r][\n]"
http-outgoing-2 >> "Content-Length: 0[\r][\n]"
http-outgoing-2 >> "Host: michaels-air.bigpond:50075[\r][\n]"
http-outgoing-2 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-2 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-2 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-2 >> "[\r][\n]"
http-outgoing-2 << "HTTP/1.1 100 Continue[\r][\n]"
http-outgoing-2 << "[\r][\n]"
http-outgoing-2 << HTTP/1.1 100 Continue
http-outgoing-2 << "HTTP/1.1 201 Created[\r][\n]"
http-outgoing-2 << "Location: hdfs://localhost:9000/user/michaeljones/hello-apache-empty.txt[\r][\n]"
http-outgoing-2 << "Content-Length: 0[\r][\n]"
http-outgoing-2 << "Connection: close[\r][\n]"
http-outgoing-2 << "[\r][\n]"
http-outgoing-2 << HTTP/1.1 201 Created
http-outgoing-2 << Location: hdfs://localhost:9000/user/michaeljones/hello-apache-empty.txt
http-outgoing-2 << Content-Length: 0
http-outgoing-2 << Connection: close
http-outgoing-2: Shutdown connection
Connection discarded
http-outgoing-2: Close connection
Connection released: [id: 2][route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection manager is shutting down
Connection manager shut down
Jersey client Redirect to: hdfs://localhost:9000/user/michaeljones/hellohadoop.log
com.sun.jersey.client.property.chunkedEncodingSize: 1048576
Jersey client Redirect to: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/hello.log.2015-06-12?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 3][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://localhost:50070
Connecting to localhost/127.0.0.1:50070
Connection established 127.0.0.1:49448<->127.0.0.1:50070
Executing request PUT /webhdfs/v1/user/michaeljones/README.md?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-3 >> PUT /webhdfs/v1/user/michaeljones/README.md?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1
http-outgoing-3 >> Transfer-Encoding: chunked
http-outgoing-3 >> Content-Type: application/octet-stream
http-outgoing-3 >> Host: localhost:50070
http-outgoing-3 >> Connection: Keep-Alive
http-outgoing-3 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-3 >> Accept-Encoding: gzip,deflate
http-outgoing-3 >> "PUT /webhdfs/v1/user/michaeljones/README.md?user.name=michaeljones&op=CREATE&overwrite=true HTTP/1.1[\r][\n]"
http-outgoing-3 >> "Transfer-Encoding: chunked[\r][\n]"
http-outgoing-3 >> "Content-Type: application/octet-stream[\r][\n]"
http-outgoing-3 >> "Host: localhost:50070[\r][\n]"
http-outgoing-3 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-3 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-3 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-3 >> "[\r][\n]"
http-outgoing-3 >> "1000[\r][\n]"
http-outgoing-3 >> "# Hello-Hadoop-netbeans-OS-X[\n]"
http-outgoing-3 >> "Java Maven project for playing with the HDFS API without any 3rd party hadoop plugins.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## Aim of project[\n]"
http-outgoing-3 >> "Hello world/tutorial level for programmatically operating with a pseudo distributed hadoop configuration on OS X. Hadoop 2.7 on Yosemite.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## What this project demonstrates[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "This is work in progress and so far the following functionality is demonstrated:[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "1. Direct programmatic control of the HDFS and running map reduce jobs - all unit tests run from the IDE with hadoop configuration built into this project and under git control.[\n]"
http-outgoing-3 >> "2. Uploading of files to the HDFS by implementing a Web REST API client.[\n]"
http-outgoing-3 >> "3. Async file upload (at time of writing only Jersey back end implemented).[\n]"
http-outgoing-3 >> "4. Layered application code for maximum re-use and ease of test driven development. The client I wrote uses an interface which has allowed me to provide both a Jersey HTTP client implementation and an Apache HTTP client implementation for comparison between the two toolkits.[\n]"
http-outgoing-3 >> "5. Test driven development.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## Getting started[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "The initial difficulty was working out how to run the program in the IDE and talk to the local pseudo distributed setup without using a 3rd party Hadoop plugin. Apparently there used to be a plugin for netbeans, but it has been discontinued. I am a newbie with this technology.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "The Apache Hadoop instructions for building and running java programs are via their command line build/run utility only. Getting the yahoo hadoop HDFS tutorial program to build in the IDE wasn't too hard. However, by default it will ignore the local Hadoop configuration and only operate with the local file system in local debug mode.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## Wading through the configuration[\n]"
http-outgoing-3 >> "Hadoop is designed to work with a number of different topologies, directory locations, levels of replication, simulated environments etc. so as we would expect nothing works unless the configuration is right.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "First Hadoop needs to be installed and configured in pseudo distributed mode such that it builds and runs test programs on the command line. The hadoop documentation has instructions for doing this. Documentation is online and also included in the installation: share/doc/hadoop/index.html. However this is not enough to get it to work in the IDE.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## The netbeans project settings that are needed to run with the HDFS from the IDE:[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "1. Get log4j configured to work in the IDE. Absence of log4j configuration won't stop hadoop from running, but we won't get to see useful error messages from hadoop without it.[\n]"
http-outgoing-3 >> "2. HADOOP_HOME environment variable project run (and test) property.[\n]"
http-outgoing-3 >> "3. Duplicate hadoop configuration in the classpath. The above environment variable does not pick up the hadoop configuration from its usual place. Yahoo's only suggestion is to run from the command line via the hadoop script. The Apache HDFS API documention says that configuration is looked for in the classpath, so I took the approach of duplicating the configuration (just 2 files) instead of figuring out how to get it to look in the installation path.[\n]"
http-outgoing-3 >> "4. The correct Maven dependencies. If not all the jar depenencies are there the program may build and run, but it won't talk to the HDFS if it doesn't load the HDFS jars.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "I think that the setup of this project would probably work on Linux too.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## Working through trouble shooting the HDFS project settings[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "Issue 1 above shows up as:[\n]"
http-outgoing-3 >> "<pre><code>[\n]"
http-outgoing-3 >> "log4j:WARN No appenders could be found for logger (org.apache.hadoop.util.Shell).[\n]"
http-outgoing-3 >> "log4j:WARN Please initialize the log4j system properly.[\n]"
http-outgoing-3 >> "log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.[\n]"
http-outgoing-3 >> "</pre></code>[\n]"
http-outgoing-3 >> "This is solved by putting a log4j.properties configuration file in the classpath. For a Maven build getting files into the classpath can be achieved by putting them in src/main/resources. I don't think this is in the classpath, but the build will then copy the file into ./target/classes/ which is in the classpath.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "Issue 2 above shows up as:[\n]"
http-outgoing-3 >> "<pre><code>[\n]"
http-outgoing-3 >> "Failed to detect a valid hadoop home directory[\n]"
http-outgoing-3 >> "java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.[\n]"
http-outgoing-3 >> "</[\r][\n]"
http-outgoing-3 >> "1000[\r][\n]"
http-outgoing-3 >> "code></pre>[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "This is fixed by going into the project properties => Build => Actions => Run Project and adding the environment variable for HADOOP_HOME. This will result in an entry in the Maven POM. Repeat for "Test Project", "Debug Project" etc.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "Issue 3. shows up as running, but creating a file on the local file system instead of the HDFS. This was fixed       looking at the HDFS API documentation for org.apache.hadoop.conf.Configuration. This documentation is under the chapter: C API libhdfs HDFS which has a link to the HDFS API under "The APIs" (I strangely cannot find this in the main index). On my installation the HDFS API documentation link is file:///opt/local/hadoop-2.7.0/share/doc/hadoop/api/org/apache/hadoop/fs/FileSystem.html.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "This documentation told me that hadoop loads core-site.xml and core-default.xml in the classpath. Classpath for a Maven build can be reached by placing these files in the directory src/main/resources (see logging configuration above). I added hdfs-site instead of core-default (which doesn't exist on my 2.7 install) into the src/main/resources project directory.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "Issue 3 shows up as:[\n]"
http-outgoing-3 >> "<pre><code>[\n]"
http-outgoing-3 >> "java.io.IOException: "hadoop No FileSystem for scheme: hdfs".[\n]"
http-outgoing-3 >> "</code></pre>[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "This is part of the build dependency problem. The various threads on stackoverflow etc. suggested that a minimum dependency was the jar for hadoop-core. However, there is no such jar on 2.7. I ran the hadoop command to dump version and got this:[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "<pre><code>[\n]"
http-outgoing-3 >> "bin/hadoop version[\n]"
http-outgoing-3 >> "Hadoop 2.7.0[\n]"
http-outgoing-3 >> "Subversion https://git-wip-us.apache.org/repos/asf/hadoop.git -r d4c8d4d4d203c934e8074b31289a28724c0842cf[\n]"
http-outgoing-3 >> "Compiled by jenkins on 2015-04-10T18:40Z[\n]"
http-outgoing-3 >> "Compiled with protoc 2.5.0[\n]"
http-outgoing-3 >> "From source with checksum a9e90912c37a35c3195d23951fd18f[\n]"
http-outgoing-3 >> "This command was run using /opt/local/hadoop-2.7.0/share/hadoop/common/hadoop-common-2.7.0.jar[\n]"
http-outgoing-3 >> "</code></pre>[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "I noted the jar name at the end and added it as a dependency to the POM. This can either be hand coded in or right click pom.xml => Insert Code => Add Dependency => Search => query hadoop-common and select version which was 2.7.0 [jar] - central. Maven will then add dependencies to other hadoop jars in the "Dependencies" group in the project explorer. Netbeans will then download these dependencies before the next build. They go into ~/.m2/repository should they ever need to be cleaned out (Netbeans doesn't seem to have an IDE remove dependency option).[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "After doing the above project built, but showed up the "no filesystem error". I noticed that Maven had not pulled in any hdfs jars matching the jars in my share/hadoop/hdfs installation directory. So I took a guess that it needed only the top level hadoop-hdfs-2.7.0.jar and added this as a dependency to the POM and all was good :)[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## Working through trouble shooting the Map Reduce project settings[\n]"
http-outgoing-3 >> "After getting the HDFS API working in the IDE it was time to move on to getting the famous Word Count map-reduce tutorial running.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "So coded it, set the main program to the word count main as the one to run. From the IDE: project Properties => Run => Main Class. Provide input and output arguments for the word count program. I noted that the netbeans properties pop-up window does not persist these settings next time it pops up. However this setting is persistant and ends up in nbactions.xml.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "However, running the word count map reduce program resulted in an ioException:[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "<pre><code>[\n]"
http-outgoing-3 >> "Please check your configuration for mapreduce.framework.name and the correspond server addresses.[\n]"
http-outgoing-3 >> "</pre></code>[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "Because the resources directory only contains 2 configuration files from my hadoop installation I thought maybe I was missing a map reduce one. So the first thing I did was go into the configuration directory of my installation and grep all files to see if there was a configuration file with mapreduce framework property. There was not. I checked my programatic configuration dump from my test program. This property was not mentioned either. The only map reduce configuration was to do with some environment variables for heap size in one of the shell scripts. Note to sel[\r][\n]"
http-outgoing-3 >> "c47[\r][\n]"
http-outgoing-3 >> "f: this may be relevant and I can consider setting this in the IDE. However, that didn't look like the problem.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "I then checked my dependencies and noted there were no map reduce jars pulled in by Maven. So I added hadoop-mapreduce-client-core. Still not running. Checked the web and a thread on stackoverflow mentioned a number of other jars: hadoop-mapreduce-client-common and hadoop-mapreduce-client shuffle. I added just the hadoop-mapreduce-client-common and it runs :) I have a feeling that I might need some of the other jars for other API calls and that there must be a better way of working out dependencies than this trial and error. As mentioned I am a newbie with this, so if anyone has any comments feel free to email me.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## Logging from application code[\n]"
http-outgoing-3 >> "Although the hadoop libraries log correctly with a properly located log4.properties file, application code calling the log4j logger seems to ignore this file. Using the log4j logger as per instructions in the log4j manual and many online tutorials did not result in getting any logging redirected to file configured in the properties file. Instead console output only is obtained. A clue to this mystery was that a most basic of hello world netbeans maven projects which did not import any hadoop stuff also failed to log to a file and did not even give the "No appenders" warning. Then I noticed that there were org.sl4j depencies in the hadoop build, so using sl4j instead solved the problem. Once my hello world project used sl4j's LoggerFactory and had sl4j-api and sl4j-12 as a dependencies it started to use the properties file. See http://www.slf4j.org/manual.html[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "## Upload a file from local storage to the HDFS via the REST API[\n]"
http-outgoing-3 >> "The WebHDFS REST API documentation which came with the installation specifies that file creation is a two stage operation where an initial PUT to the namenode is sent. This responds with a redirect to the datanode and another PUT should be made to this redirection which can contain the chunked data stream. This does not sound REST to me as it relies on holding redirection state (a fully distributed configuration could presumably return a redirection to any one of the datanodes). Hadoop say this is because of a bug in some HTTP client implementations - incorrect implementation of [0xe2][0x80][0x9c]Expect: 100-continue[0xe2][0x80][0x9d].[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "However, the 2 stage PUT not being REST seems to be a moot point, at least with the Jersey client. I do not get a redirection and a file creates/uploads all in one go.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "Since writing the above paragraph I have implemented the Apache Client back end option to my HDFS Web client interface and this client behaves differently. It does indeed cause a redirect as per Hadoop documentation. The follow up PUT to the redirected location with the chunked file stream works as per documentation.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "Since writing the above paragraph I have implemented a big chunk size setting for the HTTP chunking and this changed the behaviour of the Jersey client to always redirect. It might be that unless the chunk size option is set then the Jersey implementation does not chunk - this would be terrible for big files.[\n]"
http-outgoing-3 >> "[\n]"
http-outgoing-3 >> "To be continued ...[\n]"
http-outgoing-3 >> "[\r][\n]"
http-outgoing-3 >> "0[\r][\n]"
http-outgoing-3 >> "[\r][\n]"
http-outgoing-3 << "HTTP/1.1 307 TEMPORARY_REDIRECT[\r][\n]"
http-outgoing-3 << "Cache-Control: no-cache[\r][\n]"
http-outgoing-3 << "Expires: Sun, 14 Jun 2015 06:39:29 GMT[\r][\n]"
http-outgoing-3 << "Date: Sun, 14 Jun 2015 06:39:29 GMT[\r][\n]"
http-outgoing-3 << "Pragma: no-cache[\r][\n]"
http-outgoing-3 << "Expires: Sun, 14 Jun 2015 06:39:29 GMT[\r][\n]"
http-outgoing-3 << "Date: Sun, 14 Jun 2015 06:39:29 GMT[\r][\n]"
http-outgoing-3 << "Pragma: no-cache[\r][\n]"
http-outgoing-3 << "Content-Type: application/octet-stream[\r][\n]"
http-outgoing-3 << "Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434299969253&s=0LuUmtykTHfaFHoTCBDF5n0lKUs="; Path=/; Expires=Sun, 14-Jun-2015 16:39:29 GMT; HttpOnly[\r][\n]"
http-outgoing-3 << "Location: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/README.md?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true[\r][\n]"
http-outgoing-3 << "Content-Length: 0[\r][\n]"
http-outgoing-3 << "Server: Jetty(6.1.26)[\r][\n]"
http-outgoing-3 << "[\r][\n]"
http-outgoing-3 << HTTP/1.1 307 TEMPORARY_REDIRECT
http-outgoing-3 << Cache-Control: no-cache
http-outgoing-3 << Expires: Sun, 14 Jun 2015 06:39:29 GMT
http-outgoing-3 << Date: Sun, 14 Jun 2015 06:39:29 GMT
http-outgoing-3 << Pragma: no-cache
http-outgoing-3 << Expires: Sun, 14 Jun 2015 06:39:29 GMT
http-outgoing-3 << Date: Sun, 14 Jun 2015 06:39:29 GMT
http-outgoing-3 << Pragma: no-cache
http-outgoing-3 << Content-Type: application/octet-stream
http-outgoing-3 << Set-Cookie: hadoop.auth="u=michaeljones&p=michaeljones&t=simple&e=1434299969253&s=0LuUmtykTHfaFHoTCBDF5n0lKUs="; Path=/; Expires=Sun, 14-Jun-2015 16:39:29 GMT; HttpOnly
http-outgoing-3 << Location: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/README.md?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
http-outgoing-3 << Content-Length: 0
http-outgoing-3 << Server: Jetty(6.1.26)
Connection can be kept alive indefinitely
Cookie accepted [hadoop.auth=""u=michaeljones&p=michaeljones&t=simple&e=1434299969253&s=0LuUmtykTHfaFHoTCBDF5n0lKUs="", version:0, domain:localhost, path:/, expiry:Mon Jun 15 02:39:29 AEST 2015]
Redirect to: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/README.md?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
http-outgoing-3: Shutdown connection
Connection discarded
http-outgoing-3: Close connection
Connection released: [id: 3][route: {}->http://localhost:50070][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
CookieSpec selected: default
Auth cache not set in the context
Connection request: [route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection leased: [id: 4][route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
Opening connection {}->http://michaels-air.bigpond:50075
Connecting to michaels-air.bigpond/10.0.0.2:50075
Connection established 10.0.0.2:49449<->10.0.0.2:50075
Executing request PUT /webhdfs/v1/user/michaeljones/README.md?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1
Target auth state: UNCHALLENGED
Proxy auth state: UNCHALLENGED
http-outgoing-4 >> PUT /webhdfs/v1/user/michaeljones/README.md?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1
http-outgoing-4 >> Transfer-Encoding: chunked
http-outgoing-4 >> Content-Type: application/octet-stream
http-outgoing-4 >> Host: michaels-air.bigpond:50075
http-outgoing-4 >> Connection: Keep-Alive
http-outgoing-4 >> User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)
http-outgoing-4 >> Accept-Encoding: gzip,deflate
http-outgoing-4 >> "PUT /webhdfs/v1/user/michaeljones/README.md?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true HTTP/1.1[\r][\n]"
http-outgoing-4 >> "Transfer-Encoding: chunked[\r][\n]"
http-outgoing-4 >> "Content-Type: application/octet-stream[\r][\n]"
http-outgoing-4 >> "Host: michaels-air.bigpond:50075[\r][\n]"
http-outgoing-4 >> "Connection: Keep-Alive[\r][\n]"
http-outgoing-4 >> "User-Agent: Apache-HttpClient/4.4-beta1 (Java 1.5 minimum; Java/1.8.0_45)[\r][\n]"
http-outgoing-4 >> "Accept-Encoding: gzip,deflate[\r][\n]"
http-outgoing-4 >> "[\r][\n]"
http-outgoing-4 >> "1000[\r][\n]"
http-outgoing-4 >> "# Hello-Hadoop-netbeans-OS-X[\n]"
http-outgoing-4 >> "Java Maven project for playing with the HDFS API without any 3rd party hadoop plugins.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## Aim of project[\n]"
http-outgoing-4 >> "Hello world/tutorial level for programmatically operating with a pseudo distributed hadoop configuration on OS X. Hadoop 2.7 on Yosemite.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## What this project demonstrates[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "This is work in progress and so far the following functionality is demonstrated:[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "1. Direct programmatic control of the HDFS and running map reduce jobs - all unit tests run from the IDE with hadoop configuration built into this project and under git control.[\n]"
http-outgoing-4 >> "2. Uploading of files to the HDFS by implementing a Web REST API client.[\n]"
http-outgoing-4 >> "3. Async file upload (at time of writing only Jersey back end implemented).[\n]"
http-outgoing-4 >> "4. Layered application code for maximum re-use and ease of test driven development. The client I wrote uses an interface which has allowed me to provide both a Jersey HTTP client implementation and an Apache HTTP client implementation for comparison between the two toolkits.[\n]"
http-outgoing-4 >> "5. Test driven development.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## Getting started[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "The initial difficulty was working out how to run the program in the IDE and talk to the local pseudo distributed setup without using a 3rd party Hadoop plugin. Apparently there used to be a plugin for netbeans, but it has been discontinued. I am a newbie with this technology.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "The Apache Hadoop instructions for building and running java programs are via their command line build/run utility only. Getting the yahoo hadoop HDFS tutorial program to build in the IDE wasn't too hard. However, by default it will ignore the local Hadoop configuration and only operate with the local file system in local debug mode.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## Wading through the configuration[\n]"
http-outgoing-4 >> "Hadoop is designed to work with a number of different topologies, directory locations, levels of replication, simulated environments etc. so as we would expect nothing works unless the configuration is right.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "First Hadoop needs to be installed and configured in pseudo distributed mode such that it builds and runs test programs on the command line. The hadoop documentation has instructions for doing this. Documentation is online and also included in the installation: share/doc/hadoop/index.html. However this is not enough to get it to work in the IDE.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## The netbeans project settings that are needed to run with the HDFS from the IDE:[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "1. Get log4j configured to work in the IDE. Absence of log4j configuration won't stop hadoop from running, but we won't get to see useful error messages from hadoop without it.[\n]"
http-outgoing-4 >> "2. HADOOP_HOME environment variable project run (and test) property.[\n]"
http-outgoing-4 >> "3. Duplicate hadoop configuration in the classpath. The above environment variable does not pick up the hadoop configuration from its usual place. Yahoo's only suggestion is to run from the command line via the hadoop script. The Apache HDFS API documention says that configuration is looked for in the classpath, so I took the approach of duplicating the configuration (just 2 files) instead of figuring out how to get it to look in the installation path.[\n]"
http-outgoing-4 >> "4. The correct Maven dependencies. If not all the jar depenencies are there the program may build and run, but it won't talk to the HDFS if it doesn't load the HDFS jars.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "I think that the setup of this project would probably work on Linux too.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## Working through trouble shooting the HDFS project settings[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "Issue 1 above shows up as:[\n]"
http-outgoing-4 >> "<pre><code>[\n]"
http-outgoing-4 >> "log4j:WARN No appenders could be found for logger (org.apache.hadoop.util.Shell).[\n]"
http-outgoing-4 >> "log4j:WARN Please initialize the log4j system properly.[\n]"
http-outgoing-4 >> "log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.[\n]"
http-outgoing-4 >> "</pre></code>[\n]"
http-outgoing-4 >> "This is solved by putting a log4j.properties configuration file in the classpath. For a Maven build getting files into the classpath can be achieved by putting them in src/main/resources. I don't think this is in the classpath, but the build will then copy the file into ./target/classes/ which is in the classpath.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "Issue 2 above shows up as:[\n]"
http-outgoing-4 >> "<pre><code>[\n]"
http-outgoing-4 >> "Failed to detect a valid hadoop home directory[\n]"
http-outgoing-4 >> "java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.[\n]"
http-outgoing-4 >> "</[\r][\n]"
http-outgoing-4 >> "1000[\r][\n]"
http-outgoing-4 >> "code></pre>[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "This is fixed by going into the project properties => Build => Actions => Run Project and adding the environment variable for HADOOP_HOME. This will result in an entry in the Maven POM. Repeat for "Test Project", "Debug Project" etc.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "Issue 3. shows up as running, but creating a file on the local file system instead of the HDFS. This was fixed       looking at the HDFS API documentation for org.apache.hadoop.conf.Configuration. This documentation is under the chapter: C API libhdfs HDFS which has a link to the HDFS API under "The APIs" (I strangely cannot find this in the main index). On my installation the HDFS API documentation link is file:///opt/local/hadoop-2.7.0/share/doc/hadoop/api/org/apache/hadoop/fs/FileSystem.html.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "This documentation told me that hadoop loads core-site.xml and core-default.xml in the classpath. Classpath for a Maven build can be reached by placing these files in the directory src/main/resources (see logging configuration above). I added hdfs-site instead of core-default (which doesn't exist on my 2.7 install) into the src/main/resources project directory.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "Issue 3 shows up as:[\n]"
http-outgoing-4 >> "<pre><code>[\n]"
http-outgoing-4 >> "java.io.IOException: "hadoop No FileSystem for scheme: hdfs".[\n]"
http-outgoing-4 >> "</code></pre>[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "This is part of the build dependency problem. The various threads on stackoverflow etc. suggested that a minimum dependency was the jar for hadoop-core. However, there is no such jar on 2.7. I ran the hadoop command to dump version and got this:[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "<pre><code>[\n]"
http-outgoing-4 >> "bin/hadoop version[\n]"
http-outgoing-4 >> "Hadoop 2.7.0[\n]"
http-outgoing-4 >> "Subversion https://git-wip-us.apache.org/repos/asf/hadoop.git -r d4c8d4d4d203c934e8074b31289a28724c0842cf[\n]"
http-outgoing-4 >> "Compiled by jenkins on 2015-04-10T18:40Z[\n]"
http-outgoing-4 >> "Compiled with protoc 2.5.0[\n]"
http-outgoing-4 >> "From source with checksum a9e90912c37a35c3195d23951fd18f[\n]"
http-outgoing-4 >> "This command was run using /opt/local/hadoop-2.7.0/share/hadoop/common/hadoop-common-2.7.0.jar[\n]"
http-outgoing-4 >> "</code></pre>[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "I noted the jar name at the end and added it as a dependency to the POM. This can either be hand coded in or right click pom.xml => Insert Code => Add Dependency => Search => query hadoop-common and select version which was 2.7.0 [jar] - central. Maven will then add dependencies to other hadoop jars in the "Dependencies" group in the project explorer. Netbeans will then download these dependencies before the next build. They go into ~/.m2/repository should they ever need to be cleaned out (Netbeans doesn't seem to have an IDE remove dependency option).[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "After doing the above project built, but showed up the "no filesystem error". I noticed that Maven had not pulled in any hdfs jars matching the jars in my share/hadoop/hdfs installation directory. So I took a guess that it needed only the top level hadoop-hdfs-2.7.0.jar and added this as a dependency to the POM and all was good :)[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## Working through trouble shooting the Map Reduce project settings[\n]"
http-outgoing-4 >> "After getting the HDFS API working in the IDE it was time to move on to getting the famous Word Count map-reduce tutorial running.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "So coded it, set the main program to the word count main as the one to run. From the IDE: project Properties => Run => Main Class. Provide input and output arguments for the word count program. I noted that the netbeans properties pop-up window does not persist these settings next time it pops up. However this setting is persistant and ends up in nbactions.xml.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "However, running the word count map reduce program resulted in an ioException:[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "<pre><code>[\n]"
http-outgoing-4 >> "Please check your configuration for mapreduce.framework.name and the correspond server addresses.[\n]"
http-outgoing-4 >> "</pre></code>[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "Because the resources directory only contains 2 configuration files from my hadoop installation I thought maybe I was missing a map reduce one. So the first thing I did was go into the configuration directory of my installation and grep all files to see if there was a configuration file with mapreduce framework property. There was not. I checked my programatic configuration dump from my test program. This property was not mentioned either. The only map reduce configuration was to do with some environment variables for heap size in one of the shell scripts. Note to sel[\r][\n]"
http-outgoing-4 >> "c47[\r][\n]"
http-outgoing-4 >> "f: this may be relevant and I can consider setting this in the IDE. However, that didn't look like the problem.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "I then checked my dependencies and noted there were no map reduce jars pulled in by Maven. So I added hadoop-mapreduce-client-core. Still not running. Checked the web and a thread on stackoverflow mentioned a number of other jars: hadoop-mapreduce-client-common and hadoop-mapreduce-client shuffle. I added just the hadoop-mapreduce-client-common and it runs :) I have a feeling that I might need some of the other jars for other API calls and that there must be a better way of working out dependencies than this trial and error. As mentioned I am a newbie with this, so if anyone has any comments feel free to email me.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## Logging from application code[\n]"
http-outgoing-4 >> "Although the hadoop libraries log correctly with a properly located log4.properties file, application code calling the log4j logger seems to ignore this file. Using the log4j logger as per instructions in the log4j manual and many online tutorials did not result in getting any logging redirected to file configured in the properties file. Instead console output only is obtained. A clue to this mystery was that a most basic of hello world netbeans maven projects which did not import any hadoop stuff also failed to log to a file and did not even give the "No appenders" warning. Then I noticed that there were org.sl4j depencies in the hadoop build, so using sl4j instead solved the problem. Once my hello world project used sl4j's LoggerFactory and had sl4j-api and sl4j-12 as a dependencies it started to use the properties file. See http://www.slf4j.org/manual.html[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "## Upload a file from local storage to the HDFS via the REST API[\n]"
http-outgoing-4 >> "The WebHDFS REST API documentation which came with the installation specifies that file creation is a two stage operation where an initial PUT to the namenode is sent. This responds with a redirect to the datanode and another PUT should be made to this redirection which can contain the chunked data stream. This does not sound REST to me as it relies on holding redirection state (a fully distributed configuration could presumably return a redirection to any one of the datanodes). Hadoop say this is because of a bug in some HTTP client implementations - incorrect implementation of [0xe2][0x80][0x9c]Expect: 100-continue[0xe2][0x80][0x9d].[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "However, the 2 stage PUT not being REST seems to be a moot point, at least with the Jersey client. I do not get a redirection and a file creates/uploads all in one go.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "Since writing the above paragraph I have implemented the Apache Client back end option to my HDFS Web client interface and this client behaves differently. It does indeed cause a redirect as per Hadoop documentation. The follow up PUT to the redirected location with the chunked file stream works as per documentation.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "Since writing the above paragraph I have implemented a big chunk size setting for the HTTP chunking and this changed the behaviour of the Jersey client to always redirect. It might be that unless the chunk size option is set then the Jersey implementation does not chunk - this would be terrible for big files.[\n]"
http-outgoing-4 >> "[\n]"
http-outgoing-4 >> "To be continued ...[\n]"
http-outgoing-4 >> "[\r][\n]"
http-outgoing-4 >> "0[\r][\n]"
http-outgoing-4 >> "[\r][\n]"
http-outgoing-4 << "HTTP/1.1 100 Continue[\r][\n]"
http-outgoing-4 << "[\r][\n]"
http-outgoing-4 << HTTP/1.1 100 Continue
http-outgoing-4 << "HTTP/1.1 201 Created[\r][\n]"
http-outgoing-4 << "Location: hdfs://localhost:9000/user/michaeljones/README.md[\r][\n]"
http-outgoing-4 << "Content-Length: 0[\r][\n]"
http-outgoing-4 << "Connection: close[\r][\n]"
http-outgoing-4 << "[\r][\n]"
http-outgoing-4 << HTTP/1.1 201 Created
http-outgoing-4 << Location: hdfs://localhost:9000/user/michaeljones/README.md
http-outgoing-4 << Content-Length: 0
http-outgoing-4 << Connection: close
http-outgoing-4: Shutdown connection
Connection discarded
http-outgoing-4: Close connection
Connection released: [id: 4][route: {}->http://michaels-air.bigpond:50075][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
Connection manager is shutting down
Connection manager shut down
Connection manager is shutting down
Connection manager shut down
com.sun.jersey.client.property.chunkedEncodingSize: 1048576
Jersey client Redirect to: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/nbactions.xml?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
com.sun.jersey.client.property.chunkedEncodingSize: 1048576
Jersey client Redirect to: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/nbactions.xml?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
testUploadFileAsync: redirect: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/nbactions.xml?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
com.sun.jersey.client.property.chunkedEncodingSize: 1048576
com.sun.jersey.client.property.chunkedEncodingSize: 1048576
Jersey client Redirect to: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/hellohadoop.log.2015-06-11?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
Jersey client Redirect to: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/hellohadoop.log.2015-06-12?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
Jersey client Redirect to: http://michaels-air.bigpond:50075/webhdfs/v1/user/michaeljones/hellohadoop.log.2015-06-13?op=CREATE&user.name=michaeljones&namenoderpcaddress=localhost:9000&overwrite=true
